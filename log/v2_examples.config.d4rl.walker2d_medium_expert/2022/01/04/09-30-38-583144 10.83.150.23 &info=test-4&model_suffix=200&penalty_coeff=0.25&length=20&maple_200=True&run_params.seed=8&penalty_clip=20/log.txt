Logging to /nfs/project/chenxionghui/proj/MAPLE/log/v2_examples.config.d4rl.walker2d_medium_expert/2022/01/04/09-30-38-583144 10.83.150.23 &info=test-4&model_suffix=200&penalty_coeff=0.25&length=20&maple_200=True&run_params.seed=8&penalty_clip=20/
log dir: /nfs/project/chenxionghui/proj/MAPLE/log/v2_examples.config.d4rl.walker2d_medium_expert/2022/01/04/09-30-38-583144 10.83.150.23 &info=test-4&model_suffix=200&penalty_coeff=0.25&length=20&maple_200=True&run_params.seed=8&penalty_clip=20/
pkl_file: /nfs/project/chenxionghui/proj/MAPLE/archive_tester/v2_examples.config.d4rl.walker2d_medium_expert/2022/01/04/09-30-38-583144 10.83.150.23 &info=test-4&model_suffix=200&penalty_coeff=0.25&length=20&maple_200=True&run_params.seed=8&penalty_clip=20.pkl
checkpoint_dir: /nfs/project/chenxionghui/proj/MAPLE/checkpoint/v2_examples.config.d4rl.walker2d_medium_expert/2022/01/04/09-30-38-583144 10.83.150.23 &info=test-4&model_suffix=200&penalty_coeff=0.25&length=20&maple_200=True&run_params.seed=8&penalty_clip=20/
results_dir: /nfs/project/chenxionghui/proj/MAPLE/results/v2_examples.config.d4rl.walker2d_medium_expert/2022/01/04/09-30-38-583144 10.83.150.23 &info=test-4&model_suffix=200&penalty_coeff=0.25&length=20&maple_200=True&run_params.seed=8&penalty_clip=20/
key: Q_params, value: {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}
key: algorithm_params, value: DotMap(type='MAPLE', universe='gym', kwargs=DotMap(epoch_length=1000, train_every_n_steps=1, n_train_repeat=1, eval_render_mode=None, eval_n_episodes=10, eval_deterministic=True, discount=0.99, tau=0.005, reward_scale=1.0, model_train_freq=1000, model_retain_epochs=5, rollout_batch_size=50000.0, deterministic=False, num_networks=7, num_elites=5, real_ratio=0.05, target_entropy=-3, max_model_t=None, separate_mean_var=True, penalty_learned_var=True, pool_load_path='d4rl/walker2d-medium-expert-v0', pool_load_max_size=2000000, rollout_length=1, penalty_coeff=2.0, reparameterize=True, lr=0.0003, target_update_interval=1, store_extra_policy_info=False, action_prior='uniform', n_initial_exploration_steps=5000, model_load_dir='/nfs/project/chenxionghui/proj/MAPLE/models', network_kwargs=DotMap(hidden_sizes=[256, 256], activation=<function relu at 0x7f1dcd51a3b0>, output_activation=None, lstm_hidden_unit=128, embedding_size=16)), domain='walker2d', task='medium-expert-v0', exp_name='walker2d_medium_expert')
key: config, value: examples.config.d4rl.walker2d_medium_expert
key: custom_config, value: False
key: elite_num, value: -1
key: emb_size, value: 16
key: environment_params, value: {'training': {'domain': 'walker2d', 'task': 'medium-expert-v0', 'universe': 'gym', 'kwargs': {'use_neorl': False}}, 'evaluation': <function get_variant_spec_base.<locals>.<lambda> at 0x7f1e369de560>}
key: info, value: test-4
key: length, value: 20
key: load_date, value: 
key: load_task_name, value: 
key: maple_200, value: True
key: model_suffix, value: 200
key: n_epochs, value: 1000
key: not_inherit_hp, value: True
key: penalty_clip, value: 20
key: penalty_coeff, value: 0.25
key: policy, value: gaussian
key: policy_params, value: {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}
key: replay_pool_params, value: {'type': 'SimpleReplayPool', 'kwargs': {'max_size': <function get_variant_spec_base.<locals>.<lambda> at 0x7f1e369de3b0>}}
key: retrain_model, value: False
key: run_params, value: {'seed': 8, 'checkpoint_at_end': True, 'checkpoint_frequency': 20, 'checkpoint_replay_pool': False, 'info': ''}
key: sampler_params, value: {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}
key: seed, value: 8
save variable :
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/Scaler/scaler_mu:0' shape=(1, 23) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/Scaler/scaler_std:0' shape=(1, 23) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/max_log_var:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/min_log_var:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/Layer0_mean/FC_weights:0' shape=(200, 23, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/Layer0_mean/FC_biases:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/Layer1_mean/FC_weights:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/Layer1_mean/FC_biases:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/Layer2_mean/FC_weights:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/Layer2_mean/FC_biases:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/Layer3_mean/FC_weights:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/Layer3_mean/FC_biases:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/Layer4_mean/FC_weights:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/Layer4_mean/FC_biases:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/Layer0_var/FC_weights:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/Layer0_var/FC_biases:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200_1/beta1_power:0' shape=() dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200_1/beta2_power:0' shape=() dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer0_mean/FC_weights/Adam:0' shape=(200, 23, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer0_mean/FC_weights/Adam_1:0' shape=(200, 23, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer0_mean/FC_biases/Adam:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer0_mean/FC_biases/Adam_1:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer1_mean/FC_weights/Adam:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer1_mean/FC_weights/Adam_1:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer1_mean/FC_biases/Adam:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer1_mean/FC_biases/Adam_1:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer2_mean/FC_weights/Adam:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer2_mean/FC_weights/Adam_1:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer2_mean/FC_biases/Adam:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer2_mean/FC_biases/Adam_1:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer3_mean/FC_weights/Adam:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer3_mean/FC_weights/Adam_1:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer3_mean/FC_biases/Adam:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer3_mean/FC_biases/Adam_1:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer4_mean/FC_weights/Adam:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer4_mean/FC_weights/Adam_1:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer4_mean/FC_biases/Adam:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer4_mean/FC_biases/Adam_1:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer0_var/FC_weights/Adam:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer0_var/FC_weights/Adam_1:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer0_var/FC_biases/Adam:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/Layer0_var/FC_biases/Adam_1:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/max_log_var/Adam:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/max_log_var/Adam_1:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/min_log_var/Adam:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_8_200/walker2d-medium-expert-v0_smv_8_200/min_log_var/Adam_1:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'global_step:0' shape=() dtype=int64_ref>
<tf.Variable 'lstm_net_p/rnn/gru_cell/gates/kernel:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_p/rnn/gru_cell/gates/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_p/rnn/gru_cell/candidate/kernel:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_p/rnn/gru_cell/candidate/bias:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_p/dense/kernel:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_p/dense/bias:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/kernel:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/kernel:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/bias:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/kernel:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/bias:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'main/pi/dense/kernel:0' shape=(33, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/kernel:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/bias:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/kernel:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/bias:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'main/q1/dense/kernel:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/kernel:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/bias:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'main/q2/dense/kernel:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/kernel:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/bias:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'target/pi/dense/kernel:0' shape=(33, 256) dtype=float32_ref>
<tf.Variable 'target/pi/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/pi/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'target/pi/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/pi/dense_2/kernel:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'target/pi/dense_2/bias:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'target/pi/dense_3/kernel:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'target/pi/dense_3/bias:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'target/q1/dense/kernel:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'target/q1/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/q1/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'target/q1/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/q1/dense_2/kernel:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'target/q1/dense_2/bias:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'target/q2/dense/kernel:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'target/q2/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/q2/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'target/q2/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/q2/dense_2/kernel:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'target/q2/dense_2/bias:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'log_alpha:0' shape=() dtype=float32_ref>
<tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>
<tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>
<tf.Variable 'main/pi/dense/kernel/Adam:0' shape=(33, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense/kernel/Adam_1:0' shape=(33, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/kernel/Adam:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/kernel/Adam_1:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/kernel/Adam:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/kernel/Adam_1:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/bias/Adam:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/bias/Adam_1:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/kernel/Adam:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/kernel/Adam_1:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/bias/Adam:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/bias/Adam_1:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'beta1_power_1:0' shape=() dtype=float32_ref>
<tf.Variable 'beta2_power_1:0' shape=() dtype=float32_ref>
<tf.Variable 'main/q1/dense/kernel/Adam:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense/kernel/Adam_1:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/kernel/Adam:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/kernel/Adam_1:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/kernel/Adam:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/kernel/Adam_1:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/bias/Adam:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/bias/Adam_1:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/kernel/Adam:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/kernel/Adam_1:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/kernel/Adam:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/kernel/Adam_1:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/bias/Adam:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/bias/Adam_1:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/kernel/Adam:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/kernel/Adam_1:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/bias/Adam:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/bias/Adam_1:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'beta1_power_2:0' shape=() dtype=float32_ref>
<tf.Variable 'beta2_power_2:0' shape=() dtype=float32_ref>
<tf.Variable 'main/q2/dense/kernel/Adam:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense/kernel/Adam_1:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/kernel/Adam:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/kernel/Adam_1:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/kernel/Adam:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/kernel/Adam_1:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/bias/Adam:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/bias/Adam_1:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/kernel/Adam_2:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/kernel/Adam_3:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/bias/Adam_2:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/bias/Adam_3:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/kernel/Adam_2:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/kernel/Adam_3:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/bias/Adam_2:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/bias/Adam_3:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/kernel/Adam_2:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/kernel/Adam_3:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/bias/Adam_2:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/bias/Adam_3:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'beta1_power_3:0' shape=() dtype=float32_ref>
<tf.Variable 'beta2_power_3:0' shape=() dtype=float32_ref>
<tf.Variable 'log_alpha/alpha_optimizer:0' shape=() dtype=float32_ref>
<tf.Variable 'log_alpha/alpha_optimizer_1:0' shape=() dtype=float32_ref>
[WARN] 0 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.73758304 |
| epoch                          | 0          |
| evaluation/episode-length-avg  | 163        |
| evaluation/episode-length-max  | 175        |
| evaluation/episode-length-min  | 154        |
| evaluation/episode-length-std  | 7.05       |
| evaluation/return-average      | 282.63895  |
| evaluation/return-max          | 294.28754  |
| evaluation/return-min          | 273.81952  |
| evaluation/return-std          | 7.227929   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | -2.07      |
| model/origin_ret               | 45.3       |
| model/penalty_ret              | 103        |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 21450      |
| perf/AverageLength             | 163        |
| perf/AverageReturn             | 282.63895  |
| perf/NormalizedReturn          | 0.0612     |
| Q-avg                          | 16.003712  |
| Q-std                          | 21.966997  |
| Q_loss                         | 4.9606376  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 0          |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 511        |
| times/evaluation_metrics       | 0.000482   |
| times/evaluation_paths         | 5.35       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.0078     |
| times/train                    | 59.3       |
| timestep                       | 1000       |
| timesteps_total                | 1000       |
| train-steps                    | 1000       |
| training/Q/q1_loss             | 4.5229893  |
| training/sac_pi/alpha          | 0.73779804 |
| training/sac_pi/alpha_loss     | -2.0006752 |
| training/sac_pi/logp_pi        | 2.2541804  |
| training/sac_pi/pi_entropy     | 6.806127   |
| training/sac_pi/pi_global_norm | 1.1045088  |
| training/sac_pi/policy_loss    | -21.550041 |
| training/sac_pi/std            | 1.0232617  |
| training/sac_pi/valid_num      | 4081.0     |
| training/sac_Q/q1              | 14.592044  |
| training/sac_Q/q2              | 15.172693  |
| training/sac_Q/q2_loss         | 4.496916   |
| training/sac_Q/q_global_norm   | 13.725344  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.55892324 |
| epoch                          | 1          |
| evaluation/episode-length-avg  | 179        |
| evaluation/episode-length-max  | 191        |
| evaluation/episode-length-min  | 165        |
| evaluation/episode-length-std  | 9.25       |
| evaluation/return-average      | 299.96396  |
| evaluation/return-max          | 312.89648  |
| evaluation/return-min          | 285.7938   |
| evaluation/return-std          | 9.703134   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | -1.05      |
| model/origin_ret               | 61.4       |
| model/penalty_ret              | 104        |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 23046      |
| perf/AverageLength             | 179        |
| perf/AverageReturn             | 299.96396  |
| perf/NormalizedReturn          | 0.065      |
| Q-avg                          | 27.25658   |
| Q-std                          | 29.741484  |
| Q_loss                         | 12.850404  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 1          |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.00027    |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000544   |
| times/evaluation_paths         | 5.72       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 57.5       |
| timestep                       | 1000       |
| timesteps_total                | 2000       |
| train-steps                    | 2000       |
| training/Q/q1_loss             | 11.536837  |
| training/sac_pi/alpha          | 0.5590699  |
| training/sac_pi/alpha_loss     | -3.0902505 |
| training/sac_pi/logp_pi        | 3.3749547  |
| training/sac_pi/pi_entropy     | 6.502599   |
| training/sac_pi/pi_global_norm | 0.72796875 |
| training/sac_pi/policy_loss    | -35.87544  |
| training/sac_pi/std            | 0.9098516  |
| training/sac_pi/valid_num      | 4305.0     |
| training/sac_Q/q1              | 29.126379  |
| training/sac_Q/q2              | 29.54298   |
| training/sac_Q/q2_loss         | 11.558304  |
| training/sac_Q/q_global_norm   | 26.345041  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.42868236 |
| epoch                          | 2          |
| evaluation/episode-length-avg  | 196        |
| evaluation/episode-length-max  | 237        |
| evaluation/episode-length-min  | 174        |
| evaluation/episode-length-std  | 17.5       |
| evaluation/return-average      | 324.3524   |
| evaluation/return-max          | 366.29407  |
| evaluation/return-min          | 301.6794   |
| evaluation/return-std          | 18.021896  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 1.04       |
| model/origin_ret               | 82.1       |
| model/penalty_ret              | 103        |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 30458      |
| perf/AverageLength             | 196        |
| perf/AverageReturn             | 324.3524   |
| perf/NormalizedReturn          | 0.0703     |
| Q-avg                          | 36.449215  |
| Q-std                          | 38.216755  |
| Q_loss                         | 18.745926  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 2          |
| times/epoch_after_hook         | 2.02e-06   |
| times/epoch_before_hook        | 0.00011    |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000544   |
| times/evaluation_paths         | 6.45       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 57.9       |
| timestep                       | 1000       |
| timesteps_total                | 3000       |
| train-steps                    | 3000       |
| training/Q/q1_loss             | 21.825224  |
| training/sac_pi/alpha          | 0.42879212 |
| training/sac_pi/alpha_loss     | -3.9480972 |
| training/sac_pi/logp_pi        | 6.2836485  |
| training/sac_pi/pi_entropy     | 5.943638   |
| training/sac_pi/pi_global_norm | 1.0483931  |
| training/sac_pi/policy_loss    | -45.04218  |
| training/sac_pi/std            | 0.91471726 |
| training/sac_pi/valid_num      | 4195.0     |
| training/sac_Q/q1              | 34.247574  |
| training/sac_Q/q2              | 35.038654  |
| training/sac_Q/q2_loss         | 21.969236  |
| training/sac_Q/q_global_norm   | 47.949493  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.33194867 |
| epoch                          | 3          |
| evaluation/episode-length-avg  | 234        |
| evaluation/episode-length-max  | 339        |
| evaluation/episode-length-min  | 205        |
| evaluation/episode-length-std  | 37.5       |
| evaluation/return-average      | 366.50946  |
| evaluation/return-max          | 470.69598  |
| evaluation/return-min          | 337.9298   |
| evaluation/return-std          | 37.46928   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.09       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 98.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 38733      |
| perf/AverageLength             | 234        |
| perf/AverageReturn             | 366.50946  |
| perf/NormalizedReturn          | 0.0795     |
| Q-avg                          | 44.221092  |
| Q-std                          | 45.297375  |
| Q_loss                         | 25.115759  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 3          |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 6.5e-05    |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000589   |
| times/evaluation_paths         | 7.64       |
| times/timestep_after_hook      | 0.00419    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 59.3       |
| timestep                       | 1000       |
| timesteps_total                | 4000       |
| train-steps                    | 4000       |
| training/Q/q1_loss             | 28.763987  |
| training/sac_pi/alpha          | 0.3320312  |
| training/sac_pi/alpha_loss     | -4.3071303 |
| training/sac_pi/logp_pi        | 6.0982404  |
| training/sac_pi/pi_entropy     | 5.457289   |
| training/sac_pi/pi_global_norm | 0.8372052  |
| training/sac_pi/policy_loss    | -52.886875 |
| training/sac_pi/std            | 0.84662604 |
| training/sac_pi/valid_num      | 4271.0     |
| training/sac_Q/q1              | 42.34928   |
| training/sac_Q/q2              | 42.959522  |
| training/sac_Q/q2_loss         | 28.692263  |
| training/sac_Q/q_global_norm   | 65.94748   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.26004943 |
| epoch                          | 4          |
| evaluation/episode-length-avg  | 94.7       |
| evaluation/episode-length-max  | 96         |
| evaluation/episode-length-min  | 93         |
| evaluation/episode-length-std  | 0.9        |
| evaluation/return-average      | -18.68297  |
| evaluation/return-max          | -17.821589 |
| evaluation/return-min          | -19.585665 |
| evaluation/return-std          | 0.47468323 |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.4        |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 93.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 41567      |
| perf/AverageLength             | 94.7       |
| perf/AverageReturn             | -18.68297  |
| perf/NormalizedReturn          | -0.00442   |
| Q-avg                          | 46.516098  |
| Q-std                          | 44.753456  |
| Q_loss                         | 27.620432  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 4          |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000467   |
| times/evaluation_paths         | 3.06       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 58.1       |
| timestep                       | 1000       |
| timesteps_total                | 5000       |
| train-steps                    | 5000       |
| training/Q/q1_loss             | 31.036257  |
| training/sac_pi/alpha          | 0.26011172 |
| training/sac_pi/alpha_loss     | -4.4740186 |
| training/sac_pi/logp_pi        | 4.827073   |
| training/sac_pi/pi_entropy     | 5.090741   |
| training/sac_pi/pi_global_norm | 0.7561209  |
| training/sac_pi/policy_loss    | -60.922054 |
| training/sac_pi/std            | 0.7621713  |
| training/sac_pi/valid_num      | 4459.0     |
| training/sac_Q/q1              | 50.062996  |
| training/sac_Q/q2              | 51.394886  |
| training/sac_Q/q2_loss         | 31.012278  |
| training/sac_Q/q_global_norm   | 89.63757   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.20606346 |
| epoch                          | 5          |
| evaluation/episode-length-avg  | 95.3       |
| evaluation/episode-length-max  | 96         |
| evaluation/episode-length-min  | 95         |
| evaluation/episode-length-std  | 0.458      |
| evaluation/return-average      | -16.425972 |
| evaluation/return-max          | -15.736895 |
| evaluation/return-min          | -17.048075 |
| evaluation/return-std          | 0.47778293 |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.46       |
| model/origin_ret               | 83.2       |
| model/penalty_ret              | 90.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 43450      |
| perf/AverageLength             | 95.3       |
| perf/AverageReturn             | -16.425972 |
| perf/NormalizedReturn          | -0.00393   |
| Q-avg                          | 65.04344   |
| Q-std                          | 46.58034   |
| Q_loss                         | 34.88828   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 5          |
| times/epoch_after_hook         | 2.06e-06   |
| times/epoch_before_hook        | 0.000272   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000477   |
| times/evaluation_paths         | 3.12       |
| times/timestep_after_hook      | 0.00398    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 58.8       |
| timestep                       | 1000       |
| timesteps_total                | 6000       |
| train-steps                    | 6000       |
| training/Q/q1_loss             | 36.18183   |
| training/sac_pi/alpha          | 0.20610946 |
| training/sac_pi/alpha_loss     | -3.8377326 |
| training/sac_pi/logp_pi        | 3.6769805  |
| training/sac_pi/pi_entropy     | 4.5257187  |
| training/sac_pi/pi_global_norm | 0.9189149  |
| training/sac_pi/policy_loss    | -72.75672  |
| training/sac_pi/std            | 0.6385626  |
| training/sac_pi/valid_num      | 4610.0     |
| training/sac_Q/q1              | 62.84884   |
| training/sac_Q/q2              | 64.01459   |
| training/sac_Q/q2_loss         | 36.19645   |
| training/sac_Q/q_global_norm   | 119.4396   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1641544  |
| epoch                          | 6          |
| evaluation/episode-length-avg  | 145        |
| evaluation/episode-length-max  | 167        |
| evaluation/episode-length-min  | 131        |
| evaluation/episode-length-std  | 10.2       |
| evaluation/return-average      | 48.29069   |
| evaluation/return-max          | 59.55766   |
| evaluation/return-min          | 34.195282  |
| evaluation/return-std          | 8.579639   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.71       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 89.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44020      |
| perf/AverageLength             | 145        |
| perf/AverageReturn             | 48.29069   |
| perf/NormalizedReturn          | 0.0102     |
| Q-avg                          | 75.030045  |
| Q-std                          | 48.332275  |
| Q_loss                         | 30.985102  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 6          |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000109   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.00043    |
| times/evaluation_paths         | 4.7        |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 58.1       |
| timestep                       | 1000       |
| timesteps_total                | 7000       |
| train-steps                    | 7000       |
| training/Q/q1_loss             | 33.534058  |
| training/sac_pi/alpha          | 0.1641826  |
| training/sac_pi/alpha_loss     | -2.8098743 |
| training/sac_pi/logp_pi        | 3.7260063  |
| training/sac_pi/pi_entropy     | 4.255277   |
| training/sac_pi/pi_global_norm | 0.80354667 |
| training/sac_pi/policy_loss    | -82.63017  |
| training/sac_pi/std            | 0.5997729  |
| training/sac_pi/valid_num      | 4772.0     |
| training/sac_Q/q1              | 74.88097   |
| training/sac_Q/q2              | 75.25563   |
| training/sac_Q/q2_loss         | 33.484917  |
| training/sac_Q/q_global_norm   | 92.160126  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13815017 |
| epoch                          | 7          |
| evaluation/episode-length-avg  | 208        |
| evaluation/episode-length-max  | 264        |
| evaluation/episode-length-min  | 194        |
| evaluation/episode-length-std  | 19.9       |
| evaluation/return-average      | 385.00958  |
| evaluation/return-max          | 483.1737   |
| evaluation/return-min          | 344.58478  |
| evaluation/return-std          | 37.180664  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.26       |
| model/origin_ret               | 81.1       |
| model/penalty_ret              | 87.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 42380      |
| perf/AverageLength             | 208        |
| perf/AverageReturn             | 385.00958  |
| perf/NormalizedReturn          | 0.0835     |
| Q-avg                          | 79.467285  |
| Q-std                          | 46.769604  |
| Q_loss                         | 33.5976    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 7          |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 8.59e-05   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000455   |
| times/evaluation_paths         | 6.62       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 58.4       |
| timestep                       | 1000       |
| timesteps_total                | 8000       |
| train-steps                    | 8000       |
| training/Q/q1_loss             | 32.411007  |
| training/sac_pi/alpha          | 0.13817129 |
| training/sac_pi/alpha_loss     | -1.7638617 |
| training/sac_pi/logp_pi        | 3.7359924  |
| training/sac_pi/pi_entropy     | 3.7523675  |
| training/sac_pi/pi_global_norm | 0.65514535 |
| training/sac_pi/policy_loss    | -83.91375  |
| training/sac_pi/std            | 0.5239636  |
| training/sac_pi/valid_num      | 4836.0     |
| training/sac_Q/q1              | 78.14357   |
| training/sac_Q/q2              | 78.288086  |
| training/sac_Q/q2_loss         | 32.55646   |
| training/sac_Q/q_global_norm   | 102.78023  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.12179275 |
| epoch                          | 8          |
| evaluation/episode-length-avg  | 96         |
| evaluation/episode-length-max  | 110        |
| evaluation/episode-length-min  | 88         |
| evaluation/episode-length-std  | 7.9        |
| evaluation/return-average      | 10.081925  |
| evaluation/return-max          | 23.073524  |
| evaluation/return-min          | -8.203589  |
| evaluation/return-std          | 10.547563  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.8        |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 87.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44326      |
| perf/AverageLength             | 96         |
| perf/AverageReturn             | 10.081925  |
| perf/NormalizedReturn          | 0.00184    |
| Q-avg                          | 89.09245   |
| Q-std                          | 49.01531   |
| Q_loss                         | 34.989628  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 8          |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 6.95e-05   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000477   |
| times/evaluation_paths         | 3.13       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00863    |
| times/train                    | 58.6       |
| timestep                       | 1000       |
| timesteps_total                | 9000       |
| train-steps                    | 9000       |
| training/Q/q1_loss             | 37.823414  |
| training/sac_pi/alpha          | 0.12180652 |
| training/sac_pi/alpha_loss     | -1.2950206 |
| training/sac_pi/logp_pi        | 4.0850496  |
| training/sac_pi/pi_entropy     | 3.6018538  |
| training/sac_pi/pi_global_norm | 0.97080356 |
| training/sac_pi/policy_loss    | -95.677216 |
| training/sac_pi/std            | 0.5241925  |
| training/sac_pi/valid_num      | 4927.0     |
| training/sac_Q/q1              | 91.69376   |
| training/sac_Q/q2              | 91.68788   |
| training/sac_Q/q2_loss         | 37.902473  |
| training/sac_Q/q_global_norm   | 174.54872  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.11797314   |
| epoch                          | 9            |
| evaluation/episode-length-avg  | 119          |
| evaluation/episode-length-max  | 121          |
| evaluation/episode-length-min  | 118          |
| evaluation/episode-length-std  | 0.917        |
| evaluation/return-average      | 229.33867    |
| evaluation/return-max          | 233.16579    |
| evaluation/return-min          | 227.06145    |
| evaluation/return-std          | 2.0117466    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.54         |
| model/origin_ret               | 84.2         |
| model/penalty_ret              | 88.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 43813        |
| perf/AverageLength             | 119          |
| perf/AverageReturn             | 229.33867    |
| perf/NormalizedReturn          | 0.0496       |
| Q-avg                          | 101.33065    |
| Q-std                          | 45.260853    |
| Q_loss                         | 39.48274     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 9            |
| times/epoch_after_hook         | 1.74e-06     |
| times/epoch_before_hook        | 0.00031      |
| times/epoch_rollout_model      | 477          |
| times/evaluation_metrics       | 0.000527     |
| times/evaluation_paths         | 4            |
| times/timestep_after_hook      | 0.00386      |
| times/timestep_before_hook     | 0.00825      |
| times/train                    | 58           |
| timestep                       | 1000         |
| timesteps_total                | 10000        |
| train-steps                    | 10000        |
| training/Q/q1_loss             | 37.790993    |
| training/sac_pi/alpha          | 0.11797758   |
| training/sac_pi/alpha_loss     | -0.038640916 |
| training/sac_pi/logp_pi        | 4.9857025    |
| training/sac_pi/pi_entropy     | 3.7070553    |
| training/sac_pi/pi_global_norm | 1.0845027    |
| training/sac_pi/policy_loss    | -101.35745   |
| training/sac_pi/std            | 0.54519516   |
| training/sac_pi/valid_num      | 4871.0       |
| training/sac_Q/q1              | 95.38127     |
| training/sac_Q/q2              | 95.081116    |
| training/sac_Q/q2_loss         | 37.855453    |
| training/sac_Q/q_global_norm   | 128.42183    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.111866914  |
| epoch                          | 10           |
| evaluation/episode-length-avg  | 107          |
| evaluation/episode-length-max  | 119          |
| evaluation/episode-length-min  | 66           |
| evaluation/episode-length-std  | 20.2         |
| evaluation/return-average      | 91.26407     |
| evaluation/return-max          | 102.44934    |
| evaluation/return-min          | 53.440834    |
| evaluation/return-std          | 18.746347    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.68         |
| model/origin_ret               | 86.1         |
| model/penalty_ret              | 87.4         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 44318        |
| perf/AverageLength             | 107          |
| perf/AverageReturn             | 91.26407     |
| perf/NormalizedReturn          | 0.0195       |
| Q-avg                          | 106.39752    |
| Q-std                          | 52.60517     |
| Q_loss                         | 39.302967    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 10           |
| times/epoch_after_hook         | 1.94e-06     |
| times/epoch_before_hook        | 0.00011      |
| times/epoch_rollout_model      | 479          |
| times/evaluation_metrics       | 0.00048      |
| times/evaluation_paths         | 3.51         |
| times/timestep_after_hook      | 0.00392      |
| times/timestep_before_hook     | 0.00817      |
| times/train                    | 58.4         |
| timestep                       | 1000         |
| timesteps_total                | 11000        |
| train-steps                    | 11000        |
| training/Q/q1_loss             | 45.40075     |
| training/sac_pi/alpha          | 0.1118696    |
| training/sac_pi/alpha_loss     | -0.060134917 |
| training/sac_pi/logp_pi        | 5.0131936    |
| training/sac_pi/pi_entropy     | 3.49999      |
| training/sac_pi/pi_global_norm | 0.8585752    |
| training/sac_pi/policy_loss    | -111.152     |
| training/sac_pi/std            | 0.51773417   |
| training/sac_pi/valid_num      | 4907.0       |
| training/sac_Q/q1              | 106.17084    |
| training/sac_Q/q2              | 106.42007    |
| training/sac_Q/q2_loss         | 45.228832    |
| training/sac_Q/q_global_norm   | 155.16302    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.113609865 |
| epoch                          | 11          |
| evaluation/episode-length-avg  | 83.7        |
| evaluation/episode-length-max  | 91          |
| evaluation/episode-length-min  | 75          |
| evaluation/episode-length-std  | 5.53        |
| evaluation/return-average      | 154.38083   |
| evaluation/return-max          | 170.59886   |
| evaluation/return-min          | 134.44843   |
| evaluation/return-std          | 12.813825   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.7         |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 86.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 43862       |
| perf/AverageLength             | 83.7        |
| perf/AverageReturn             | 154.38083   |
| perf/NormalizedReturn          | 0.0333      |
| Q-avg                          | 108.37164   |
| Q-std                          | 58.438114   |
| Q_loss                         | 45.72568    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 11          |
| times/epoch_after_hook         | 1.95e-06    |
| times/epoch_before_hook        | 9.3e-05     |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000516    |
| times/evaluation_paths         | 2.75        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00868     |
| times/train                    | 57.8        |
| timestep                       | 1000        |
| timesteps_total                | 12000       |
| train-steps                    | 12000       |
| training/Q/q1_loss             | 41.94047    |
| training/sac_pi/alpha          | 0.11363156  |
| training/sac_pi/alpha_loss     | -0.34462798 |
| training/sac_pi/logp_pi        | 4.692731    |
| training/sac_pi/pi_entropy     | 3.2776616   |
| training/sac_pi/pi_global_norm | 1.0676664   |
| training/sac_pi/policy_loss    | -119.56762  |
| training/sac_pi/std            | 0.48963293  |
| training/sac_pi/valid_num      | 4899.0      |
| training/sac_Q/q1              | 113.61333   |
| training/sac_Q/q2              | 113.44582   |
| training/sac_Q/q2_loss         | 41.746315   |
| training/sac_Q/q_global_norm   | 160.7128    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.11835165 |
| epoch                          | 12         |
| evaluation/episode-length-avg  | 136        |
| evaluation/episode-length-max  | 143        |
| evaluation/episode-length-min  | 130        |
| evaluation/episode-length-std  | 4.49       |
| evaluation/return-average      | 315.5285   |
| evaluation/return-max          | 325.85934  |
| evaluation/return-min          | 305.96054  |
| evaluation/return-std          | 6.717497   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.57       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 88.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44415      |
| perf/AverageLength             | 136        |
| perf/AverageReturn             | 315.5285   |
| perf/NormalizedReturn          | 0.0684     |
| Q-avg                          | 109.05642  |
| Q-std                          | 61.118484  |
| Q_loss                         | 52.265713  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 12         |
| times/epoch_after_hook         | 2.04e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000483   |
| times/evaluation_paths         | 4.3        |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00883    |
| times/train                    | 57.6       |
| timestep                       | 1000       |
| timesteps_total                | 13000      |
| train-steps                    | 13000      |
| training/Q/q1_loss             | 53.83488   |
| training/sac_pi/alpha          | 0.11832313 |
| training/sac_pi/alpha_loss     | 0.818      |
| training/sac_pi/logp_pi        | 4.853822   |
| training/sac_pi/pi_entropy     | 3.6599567  |
| training/sac_pi/pi_global_norm | 0.8904796  |
| training/sac_pi/policy_loss    | -119.61222 |
| training/sac_pi/std            | 0.5095957  |
| training/sac_pi/valid_num      | 4925.0     |
| training/sac_Q/q1              | 114.94143  |
| training/sac_Q/q2              | 114.62578  |
| training/sac_Q/q2_loss         | 53.98354   |
| training/sac_Q/q_global_norm   | 193.93097  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.116290316 |
| epoch                          | 13          |
| evaluation/episode-length-avg  | 132         |
| evaluation/episode-length-max  | 139         |
| evaluation/episode-length-min  | 127         |
| evaluation/episode-length-std  | 3.85        |
| evaluation/return-average      | 296.29706   |
| evaluation/return-max          | 306.6965    |
| evaluation/return-min          | 289.7764    |
| evaluation/return-std          | 5.746732    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.79        |
| model/origin_ret               | 87.8        |
| model/penalty_ret              | 87          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 43724       |
| perf/AverageLength             | 132         |
| perf/AverageReturn             | 296.29706   |
| perf/NormalizedReturn          | 0.0642      |
| Q-avg                          | 117.80813   |
| Q-std                          | 63.024105   |
| Q_loss                         | 54.80733    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 13          |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000275    |
| times/epoch_rollout_model      | 475         |
| times/evaluation_metrics       | 0.000558    |
| times/evaluation_paths         | 4.09        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 57.8        |
| timestep                       | 1000        |
| timesteps_total                | 14000       |
| train-steps                    | 14000       |
| training/Q/q1_loss             | 60.91803    |
| training/sac_pi/alpha          | 0.11630762  |
| training/sac_pi/alpha_loss     | 0.23883672  |
| training/sac_pi/logp_pi        | 4.989569    |
| training/sac_pi/pi_entropy     | 3.3893104   |
| training/sac_pi/pi_global_norm | 1.2056006   |
| training/sac_pi/policy_loss    | -127.861824 |
| training/sac_pi/std            | 0.51967317  |
| training/sac_pi/valid_num      | 4900.0      |
| training/sac_Q/q1              | 122.23106   |
| training/sac_Q/q2              | 122.00319   |
| training/sac_Q/q2_loss         | 60.814278   |
| training/sac_Q/q_global_norm   | 217.63127   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.11614302   |
| epoch                          | 14           |
| evaluation/episode-length-avg  | 129          |
| evaluation/episode-length-max  | 133          |
| evaluation/episode-length-min  | 120          |
| evaluation/episode-length-std  | 3.68         |
| evaluation/return-average      | 294.802      |
| evaluation/return-max          | 317.26324    |
| evaluation/return-min          | 253.17584    |
| evaluation/return-std          | 21.659115    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.73         |
| model/origin_ret               | 85.5         |
| model/penalty_ret              | 85.8         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 44624        |
| perf/AverageLength             | 129          |
| perf/AverageReturn             | 294.802      |
| perf/NormalizedReturn          | 0.0639       |
| Q-avg                          | 119.83193    |
| Q-std                          | 63.001854    |
| Q_loss                         | 60.10028     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 14           |
| times/epoch_after_hook         | 1.95e-06     |
| times/epoch_before_hook        | 7.07e-05     |
| times/epoch_rollout_model      | 485          |
| times/evaluation_metrics       | 0.000546     |
| times/evaluation_paths         | 4.1          |
| times/timestep_after_hook      | 0.00372      |
| times/timestep_before_hook     | 0.0081       |
| times/train                    | 57.5         |
| timestep                       | 1000         |
| timesteps_total                | 15000        |
| train-steps                    | 15000        |
| training/Q/q1_loss             | 66.05123     |
| training/sac_pi/alpha          | 0.11615465   |
| training/sac_pi/alpha_loss     | -0.012343494 |
| training/sac_pi/logp_pi        | 5.235189     |
| training/sac_pi/pi_entropy     | 3.4617362    |
| training/sac_pi/pi_global_norm | 0.9178332    |
| training/sac_pi/policy_loss    | -127.59266   |
| training/sac_pi/std            | 0.5216834    |
| training/sac_pi/valid_num      | 4881.0       |
| training/sac_Q/q1              | 120.834496   |
| training/sac_Q/q2              | 120.97191    |
| training/sac_Q/q2_loss         | 66.33596     |
| training/sac_Q/q_global_norm   | 283.78223    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.12523422  |
| epoch                          | 15          |
| evaluation/episode-length-avg  | 205         |
| evaluation/episode-length-max  | 227         |
| evaluation/episode-length-min  | 191         |
| evaluation/episode-length-std  | 12.4        |
| evaluation/return-average      | 478.27325   |
| evaluation/return-max          | 504.4258    |
| evaluation/return-min          | 461.68787   |
| evaluation/return-std          | 14.349284   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.53        |
| model/origin_ret               | 80.6        |
| model/penalty_ret              | 84          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 44809       |
| perf/AverageLength             | 205         |
| perf/AverageReturn             | 478.27325   |
| perf/NormalizedReturn          | 0.104       |
| Q-avg                          | 119.41439   |
| Q-std                          | 59.5363     |
| Q_loss                         | 55.842564   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 15          |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000116    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000627    |
| times/evaluation_paths         | 6.77        |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 58.4        |
| timestep                       | 1000        |
| timesteps_total                | 16000       |
| train-steps                    | 16000       |
| training/Q/q1_loss             | 59.97464    |
| training/sac_pi/alpha          | 0.12526365  |
| training/sac_pi/alpha_loss     | -0.29215646 |
| training/sac_pi/logp_pi        | 5.292859    |
| training/sac_pi/pi_entropy     | 3.5015283   |
| training/sac_pi/pi_global_norm | 0.79577863  |
| training/sac_pi/policy_loss    | -131.98895  |
| training/sac_pi/std            | 0.53903747  |
| training/sac_pi/valid_num      | 4913.0      |
| training/sac_Q/q1              | 126.03445   |
| training/sac_Q/q2              | 125.5614    |
| training/sac_Q/q2_loss         | 60.042217   |
| training/sac_Q/q_global_norm   | 283.67346   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1245317  |
| epoch                          | 16         |
| evaluation/episode-length-avg  | 202        |
| evaluation/episode-length-max  | 339        |
| evaluation/episode-length-min  | 125        |
| evaluation/episode-length-std  | 75.1       |
| evaluation/return-average      | 228.94205  |
| evaluation/return-max          | 628.7912   |
| evaluation/return-min          | 62.387207  |
| evaluation/return-std          | 210.46843  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.55       |
| model/origin_ret               | 83.1       |
| model/penalty_ret              | 85.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44324      |
| perf/AverageLength             | 202        |
| perf/AverageReturn             | 228.94205  |
| perf/NormalizedReturn          | 0.0495     |
| Q-avg                          | 116.471985 |
| Q-std                          | 69.494995  |
| Q_loss                         | 63.47665   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 16         |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000105   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000545   |
| times/evaluation_paths         | 6.79       |
| times/timestep_after_hook      | 0.00411    |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 60.2       |
| timestep                       | 1000       |
| timesteps_total                | 17000      |
| train-steps                    | 17000      |
| training/Q/q1_loss             | 59.717484  |
| training/sac_pi/alpha          | 0.12451436 |
| training/sac_pi/alpha_loss     | 0.23228703 |
| training/sac_pi/logp_pi        | 5.559424   |
| training/sac_pi/pi_entropy     | 3.5769691  |
| training/sac_pi/pi_global_norm | 0.83666885 |
| training/sac_pi/policy_loss    | -129.54665 |
| training/sac_pi/std            | 0.52494997 |
| training/sac_pi/valid_num      | 4885.0     |
| training/sac_Q/q1              | 123.29509  |
| training/sac_Q/q2              | 122.98633  |
| training/sac_Q/q2_loss         | 60.53241   |
| training/sac_Q/q_global_norm   | 202.68117  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.12471844 |
| epoch                          | 17         |
| evaluation/episode-length-avg  | 114        |
| evaluation/episode-length-max  | 118        |
| evaluation/episode-length-min  | 109        |
| evaluation/episode-length-std  | 2.6        |
| evaluation/return-average      | 264.28903  |
| evaluation/return-max          | 279.41718  |
| evaluation/return-min          | 241.35637  |
| evaluation/return-std          | 10.8767805 |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.72       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 86.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 43773      |
| perf/AverageLength             | 114        |
| perf/AverageReturn             | 264.28903  |
| perf/NormalizedReturn          | 0.0572     |
| Q-avg                          | 127.059326 |
| Q-std                          | 74.86753   |
| Q_loss                         | 63.660744  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 17         |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000326   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000605   |
| times/evaluation_paths         | 3.88       |
| times/timestep_after_hook      | 0.00403    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 58.8       |
| timestep                       | 1000       |
| timesteps_total                | 18000      |
| train-steps                    | 18000      |
| training/Q/q1_loss             | 78.33476   |
| training/sac_pi/alpha          | 0.12472543 |
| training/sac_pi/alpha_loss     | -0.4892785 |
| training/sac_pi/logp_pi        | 6.5049734  |
| training/sac_pi/pi_entropy     | 3.810775   |
| training/sac_pi/pi_global_norm | 0.75393    |
| training/sac_pi/policy_loss    | -128.65778 |
| training/sac_pi/std            | 0.6089278  |
| training/sac_pi/valid_num      | 4817.0     |
| training/sac_Q/q1              | 120.239624 |
| training/sac_Q/q2              | 120.18933  |
| training/sac_Q/q2_loss         | 78.800186  |
| training/sac_Q/q_global_norm   | 247.14099  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.124984026 |
| epoch                          | 18          |
| evaluation/episode-length-avg  | 134         |
| evaluation/episode-length-max  | 144         |
| evaluation/episode-length-min  | 117         |
| evaluation/episode-length-std  | 10.3        |
| evaluation/return-average      | 339.49396   |
| evaluation/return-max          | 391.09705   |
| evaluation/return-min          | 247.22424   |
| evaluation/return-std          | 55.835133   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.69        |
| model/origin_ret               | 83.2        |
| model/penalty_ret              | 84.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 44486       |
| perf/AverageLength             | 134         |
| perf/AverageReturn             | 339.49396   |
| perf/NormalizedReturn          | 0.0736      |
| Q-avg                          | 133.84189   |
| Q-std                          | 65.74087    |
| Q_loss                         | 64.5586     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 18          |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000147    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000534    |
| times/evaluation_paths         | 4.37        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 59.2        |
| timestep                       | 1000        |
| timesteps_total                | 19000       |
| train-steps                    | 19000       |
| training/Q/q1_loss             | 83.00876    |
| training/sac_pi/alpha          | 0.124964066 |
| training/sac_pi/alpha_loss     | -0.09108008 |
| training/sac_pi/logp_pi        | 4.847654    |
| training/sac_pi/pi_entropy     | 3.5964172   |
| training/sac_pi/pi_global_norm | 0.84330523  |
| training/sac_pi/policy_loss    | -135.30235  |
| training/sac_pi/std            | 0.5161197   |
| training/sac_pi/valid_num      | 4929.0      |
| training/sac_Q/q1              | 129.91373   |
| training/sac_Q/q2              | 129.34822   |
| training/sac_Q/q2_loss         | 82.98718    |
| training/sac_Q/q_global_norm   | 238.77667   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13200504 |
| epoch                          | 19         |
| evaluation/episode-length-avg  | 58.8       |
| evaluation/episode-length-max  | 61         |
| evaluation/episode-length-min  | 57         |
| evaluation/episode-length-std  | 1.25       |
| evaluation/return-average      | 113.6767   |
| evaluation/return-max          | 119.60663  |
| evaluation/return-min          | 110.5912   |
| evaluation/return-std          | 2.787834   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.49       |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 87.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 43668      |
| perf/AverageLength             | 58.8       |
| perf/AverageReturn             | 113.6767   |
| perf/NormalizedReturn          | 0.0244     |
| Q-avg                          | 126.560326 |
| Q-std                          | 70.78519   |
| Q_loss                         | 74.52153   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 19         |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000475   |
| times/evaluation_paths         | 1.86       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 59         |
| timestep                       | 1000       |
| timesteps_total                | 20000      |
| train-steps                    | 20000      |
| training/Q/q1_loss             | 76.6339    |
| training/sac_pi/alpha          | 0.13194154 |
| training/sac_pi/alpha_loss     | 0.41526923 |
| training/sac_pi/logp_pi        | 6.1086283  |
| training/sac_pi/pi_entropy     | 3.64468    |
| training/sac_pi/pi_global_norm | 0.94274795 |
| training/sac_pi/policy_loss    | -134.85811 |
| training/sac_pi/std            | 0.5530422  |
| training/sac_pi/valid_num      | 4801.0     |
| training/sac_Q/q1              | 126.38206  |
| training/sac_Q/q2              | 125.49498  |
| training/sac_Q/q2_loss         | 77.001465  |
| training/sac_Q/q_global_norm   | 202.50009  |
--------------------------------------------------------------------------------
[WARN] 20 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.12766755 |
| epoch                          | 20         |
| evaluation/episode-length-avg  | 146        |
| evaluation/episode-length-max  | 147        |
| evaluation/episode-length-min  | 145        |
| evaluation/episode-length-std  | 0.447      |
| evaluation/return-average      | 371.90448  |
| evaluation/return-max          | 375.91827  |
| evaluation/return-min          | 365.64038  |
| evaluation/return-std          | 3.731082   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.68       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 86         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44309      |
| perf/AverageLength             | 146        |
| perf/AverageReturn             | 371.90448  |
| perf/NormalizedReturn          | 0.0807     |
| Q-avg                          | 135.82422  |
| Q-std                          | 64.99657   |
| Q_loss                         | 78.62082   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 20         |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 8.63e-05   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000517   |
| times/evaluation_paths         | 4.71       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 57.9       |
| timestep                       | 1000       |
| timesteps_total                | 21000      |
| train-steps                    | 21000      |
| training/Q/q1_loss             | 77.5372    |
| training/sac_pi/alpha          | 0.12766686 |
| training/sac_pi/alpha_loss     | 0.17665811 |
| training/sac_pi/logp_pi        | 4.621743   |
| training/sac_pi/pi_entropy     | 3.883821   |
| training/sac_pi/pi_global_norm | 0.95991635 |
| training/sac_pi/policy_loss    | -134.60503 |
| training/sac_pi/std            | 0.5328397  |
| training/sac_pi/valid_num      | 4933.0     |
| training/sac_Q/q1              | 130.09592  |
| training/sac_Q/q2              | 129.14299  |
| training/sac_Q/q2_loss         | 77.643074  |
| training/sac_Q/q_global_norm   | 247.34497  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.13206096  |
| epoch                          | 21          |
| evaluation/episode-length-avg  | 156         |
| evaluation/episode-length-max  | 157         |
| evaluation/episode-length-min  | 152         |
| evaluation/episode-length-std  | 1.28        |
| evaluation/return-average      | 487.43857   |
| evaluation/return-max          | 492.4685    |
| evaluation/return-min          | 481.5647    |
| evaluation/return-std          | 3.7110977   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.54        |
| model/origin_ret               | 80.7        |
| model/penalty_ret              | 84.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 44465       |
| perf/AverageLength             | 156         |
| perf/AverageReturn             | 487.43857   |
| perf/NormalizedReturn          | 0.106       |
| Q-avg                          | 128.65347   |
| Q-std                          | 73.59322    |
| Q_loss                         | 75.04674    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 21          |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000295    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000604    |
| times/evaluation_paths         | 5.08        |
| times/timestep_after_hook      | 0.00407     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 59.7        |
| timestep                       | 1000        |
| timesteps_total                | 22000       |
| train-steps                    | 22000       |
| training/Q/q1_loss             | 70.60261    |
| training/sac_pi/alpha          | 0.13203326  |
| training/sac_pi/alpha_loss     | 0.107315205 |
| training/sac_pi/logp_pi        | 4.751354    |
| training/sac_pi/pi_entropy     | 3.4738376   |
| training/sac_pi/pi_global_norm | 1.1751994   |
| training/sac_pi/policy_loss    | -148.59827  |
| training/sac_pi/std            | 0.49520162  |
| training/sac_pi/valid_num      | 4937.0      |
| training/sac_Q/q1              | 143.76082   |
| training/sac_Q/q2              | 143.10452   |
| training/sac_Q/q2_loss         | 71.28267    |
| training/sac_Q/q_global_norm   | 184.77304   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.13556416  |
| epoch                          | 22          |
| evaluation/episode-length-avg  | 121         |
| evaluation/episode-length-max  | 124         |
| evaluation/episode-length-min  | 119         |
| evaluation/episode-length-std  | 1.45        |
| evaluation/return-average      | 359.9821    |
| evaluation/return-max          | 369.87643   |
| evaluation/return-min          | 352.4842    |
| evaluation/return-std          | 4.7339253   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.77        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 84          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 44505       |
| perf/AverageLength             | 121         |
| perf/AverageReturn             | 359.9821    |
| perf/NormalizedReturn          | 0.0781      |
| Q-avg                          | 133.97475   |
| Q-std                          | 73.56228    |
| Q_loss                         | 75.88219    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 22          |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000564    |
| times/evaluation_paths         | 4.09        |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.0084      |
| times/train                    | 59.7        |
| timestep                       | 1000        |
| timesteps_total                | 23000       |
| train-steps                    | 23000       |
| training/Q/q1_loss             | 89.45658    |
| training/sac_pi/alpha          | 0.13558994  |
| training/sac_pi/alpha_loss     | -0.17556742 |
| training/sac_pi/logp_pi        | 4.709478    |
| training/sac_pi/pi_entropy     | 3.6908302   |
| training/sac_pi/pi_global_norm | 0.71999425  |
| training/sac_pi/policy_loss    | -139.91525  |
| training/sac_pi/std            | 0.5204003   |
| training/sac_pi/valid_num      | 4953.0      |
| training/sac_Q/q1              | 135.37253   |
| training/sac_Q/q2              | 134.81876   |
| training/sac_Q/q2_loss         | 89.42275    |
| training/sac_Q/q_global_norm   | 261.10922   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.14171551   |
| epoch                          | 23           |
| evaluation/episode-length-avg  | 68.3         |
| evaluation/episode-length-max  | 71           |
| evaluation/episode-length-min  | 64           |
| evaluation/episode-length-std  | 1.79         |
| evaluation/return-average      | 117.51959    |
| evaluation/return-max          | 125.53362    |
| evaluation/return-min          | 109.80258    |
| evaluation/return-std          | 3.800297     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.66         |
| model/origin_ret               | 83.8         |
| model/penalty_ret              | 85.6         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 44337        |
| perf/AverageLength             | 68.3         |
| perf/AverageReturn             | 117.51959    |
| perf/NormalizedReturn          | 0.0252       |
| Q-avg                          | 147.97012    |
| Q-std                          | 62.91742     |
| Q_loss                         | 77.373604    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 23           |
| times/epoch_after_hook         | 9.87e-06     |
| times/epoch_before_hook        | 0.000134     |
| times/epoch_rollout_model      | 486          |
| times/evaluation_metrics       | 0.000514     |
| times/evaluation_paths         | 2.35         |
| times/timestep_after_hook      | 0.00396      |
| times/timestep_before_hook     | 0.00831      |
| times/train                    | 59.2         |
| timestep                       | 1000         |
| timesteps_total                | 24000        |
| train-steps                    | 24000        |
| training/Q/q1_loss             | 72.575966    |
| training/sac_pi/alpha          | 0.14169753   |
| training/sac_pi/alpha_loss     | -0.036178574 |
| training/sac_pi/logp_pi        | 4.9236307    |
| training/sac_pi/pi_entropy     | 3.7018552    |
| training/sac_pi/pi_global_norm | 1.1289742    |
| training/sac_pi/policy_loss    | -145.70825   |
| training/sac_pi/std            | 0.51987785   |
| training/sac_pi/valid_num      | 4907.0       |
| training/sac_Q/q1              | 139.88899    |
| training/sac_Q/q2              | 139.64291    |
| training/sac_Q/q2_loss         | 73.04499     |
| training/sac_Q/q_global_norm   | 215.36902    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13253313 |
| epoch                          | 24         |
| evaluation/episode-length-avg  | 106        |
| evaluation/episode-length-max  | 112        |
| evaluation/episode-length-min  | 99         |
| evaluation/episode-length-std  | 5.14       |
| evaluation/return-average      | 245.01099  |
| evaluation/return-max          | 268.86255  |
| evaluation/return-min          | 221.36827  |
| evaluation/return-std          | 18.263361  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.81       |
| model/origin_ret               | 87.1       |
| model/penalty_ret              | 85.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44316      |
| perf/AverageLength             | 106        |
| perf/AverageReturn             | 245.01099  |
| perf/NormalizedReturn          | 0.053      |
| Q-avg                          | 139.13992  |
| Q-std                          | 72.05814   |
| Q_loss                         | 85.776054  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 24         |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 9e-05      |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000457   |
| times/evaluation_paths         | 3.48       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 59         |
| timestep                       | 1000       |
| timesteps_total                | 25000      |
| train-steps                    | 25000      |
| training/Q/q1_loss             | 84.068054  |
| training/sac_pi/alpha          | 0.13253534 |
| training/sac_pi/alpha_loss     | 0.0289711  |
| training/sac_pi/logp_pi        | 4.772484   |
| training/sac_pi/pi_entropy     | 3.3929284  |
| training/sac_pi/pi_global_norm | 0.90478    |
| training/sac_pi/policy_loss    | -149.3369  |
| training/sac_pi/std            | 0.48100418 |
| training/sac_pi/valid_num      | 4898.0     |
| training/sac_Q/q1              | 142.99104  |
| training/sac_Q/q2              | 142.6597   |
| training/sac_Q/q2_loss         | 84.06708   |
| training/sac_Q/q_global_norm   | 240.21689  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13392697 |
| epoch                          | 25         |
| evaluation/episode-length-avg  | 409        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 177        |
| evaluation/episode-length-std  | 325        |
| evaluation/return-average      | 1728.9238  |
| evaluation/return-max          | 5000.7676  |
| evaluation/return-min          | 510.5001   |
| evaluation/return-std          | 1750.5021  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.7        |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 85.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44571      |
| perf/AverageLength             | 409        |
| perf/AverageReturn             | 1728.9238  |
| perf/NormalizedReturn          | 0.376      |
| Q-avg                          | 137.4328   |
| Q-std                          | 71.089554  |
| Q_loss                         | 85.50236   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 25         |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000343   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000602   |
| times/evaluation_paths         | 13.4       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00895    |
| times/train                    | 58.9       |
| timestep                       | 1000       |
| timesteps_total                | 26000      |
| train-steps                    | 26000      |
| training/Q/q1_loss             | 82.889114  |
| training/sac_pi/alpha          | 0.13385707 |
| training/sac_pi/alpha_loss     | 0.5964067  |
| training/sac_pi/logp_pi        | 5.057559   |
| training/sac_pi/pi_entropy     | 3.9554107  |
| training/sac_pi/pi_global_norm | 1.115151   |
| training/sac_pi/policy_loss    | -143.38939 |
| training/sac_pi/std            | 0.55256766 |
| training/sac_pi/valid_num      | 4887.0     |
| training/sac_Q/q1              | 136.82977  |
| training/sac_Q/q2              | 136.52754  |
| training/sac_Q/q2_loss         | 83.09929   |
| training/sac_Q/q_global_norm   | 292.64407  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13015266 |
| epoch                          | 26         |
| evaluation/episode-length-avg  | 121        |
| evaluation/episode-length-max  | 123        |
| evaluation/episode-length-min  | 117        |
| evaluation/episode-length-std  | 1.96       |
| evaluation/return-average      | 287.39517  |
| evaluation/return-max          | 295.49207  |
| evaluation/return-min          | 275.2152   |
| evaluation/return-std          | 6.7879047  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.71       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 85.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44289      |
| perf/AverageLength             | 121        |
| perf/AverageReturn             | 287.39517  |
| perf/NormalizedReturn          | 0.0622     |
| Q-avg                          | 146.922    |
| Q-std                          | 69.53873   |
| Q_loss                         | 76.140114  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 26         |
| times/epoch_after_hook         | 2.08e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000695   |
| times/evaluation_paths         | 3.89       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 58.3       |
| timestep                       | 1000       |
| timesteps_total                | 27000      |
| train-steps                    | 27000      |
| training/Q/q1_loss             | 77.35086   |
| training/sac_pi/alpha          | 0.1301588  |
| training/sac_pi/alpha_loss     | 0.33238146 |
| training/sac_pi/logp_pi        | 6.141137   |
| training/sac_pi/pi_entropy     | 3.6762588  |
| training/sac_pi/pi_global_norm | 1.0656075  |
| training/sac_pi/policy_loss    | -152.19745 |
| training/sac_pi/std            | 0.5703942  |
| training/sac_pi/valid_num      | 4841.0     |
| training/sac_Q/q1              | 144.03079  |
| training/sac_Q/q2              | 143.49321  |
| training/sac_Q/q2_loss         | 77.54281   |
| training/sac_Q/q_global_norm   | 242.72792  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.13382468  |
| epoch                          | 27          |
| evaluation/episode-length-avg  | 87.5        |
| evaluation/episode-length-max  | 90          |
| evaluation/episode-length-min  | 84          |
| evaluation/episode-length-std  | 1.91        |
| evaluation/return-average      | 203.90543   |
| evaluation/return-max          | 212.8873    |
| evaluation/return-min          | 191.51663   |
| evaluation/return-std          | 6.7190347   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.7         |
| model/origin_ret               | 83.3        |
| model/penalty_ret              | 83.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 44783       |
| perf/AverageLength             | 87.5        |
| perf/AverageReturn             | 203.90543   |
| perf/NormalizedReturn          | 0.0441      |
| Q-avg                          | 139.35883   |
| Q-std                          | 70.88473    |
| Q_loss                         | 83.333206   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 27          |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.000117    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000592    |
| times/evaluation_paths         | 2.82        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 59.4        |
| timestep                       | 1000        |
| timesteps_total                | 28000       |
| train-steps                    | 28000       |
| training/Q/q1_loss             | 68.74283    |
| training/sac_pi/alpha          | 0.13383578  |
| training/sac_pi/alpha_loss     | -0.27786762 |
| training/sac_pi/logp_pi        | 5.5875425   |
| training/sac_pi/pi_entropy     | 3.6193326   |
| training/sac_pi/pi_global_norm | 2.000908    |
| training/sac_pi/policy_loss    | -143.38194  |
| training/sac_pi/std            | 0.54628116  |
| training/sac_pi/valid_num      | 4828.0      |
| training/sac_Q/q1              | 135.11746   |
| training/sac_Q/q2              | 134.26326   |
| training/sac_Q/q2_loss         | 68.69281    |
| training/sac_Q/q_global_norm   | 188.61482   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13776208 |
| epoch                          | 28         |
| evaluation/episode-length-avg  | 110        |
| evaluation/episode-length-max  | 127        |
| evaluation/episode-length-min  | 82         |
| evaluation/episode-length-std  | 11.6       |
| evaluation/return-average      | 228.73625  |
| evaluation/return-max          | 280.26025  |
| evaluation/return-min          | 138.47237  |
| evaluation/return-std          | 36.238728  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.57       |
| model/origin_ret               | 82.2       |
| model/penalty_ret              | 85.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44668      |
| perf/AverageLength             | 110        |
| perf/AverageReturn             | 228.73625  |
| perf/NormalizedReturn          | 0.0495     |
| Q-avg                          | 144.12372  |
| Q-std                          | 69.2371    |
| Q_loss                         | 74.45971   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 28         |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000154   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000505   |
| times/evaluation_paths         | 3.56       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 58.1       |
| timestep                       | 1000       |
| timesteps_total                | 29000      |
| train-steps                    | 29000      |
| training/Q/q1_loss             | 72.91783   |
| training/sac_pi/alpha          | 0.1377471  |
| training/sac_pi/alpha_loss     | 0.09349242 |
| training/sac_pi/logp_pi        | 4.446843   |
| training/sac_pi/pi_entropy     | 3.743051   |
| training/sac_pi/pi_global_norm | 0.9376757  |
| training/sac_pi/policy_loss    | -146.26129 |
| training/sac_pi/std            | 0.5231239  |
| training/sac_pi/valid_num      | 4914.0     |
| training/sac_Q/q1              | 140.6636   |
| training/sac_Q/q2              | 140.2394   |
| training/sac_Q/q2_loss         | 72.51024   |
| training/sac_Q/q_global_norm   | 238.20921  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1307602  |
| epoch                          | 29         |
| evaluation/episode-length-avg  | 216        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 108        |
| evaluation/episode-length-std  | 262        |
| evaluation/return-average      | 608.1595   |
| evaluation/return-max          | 3982.8203  |
| evaluation/return-min          | 185.32002  |
| evaluation/return-std          | 1126.5261  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.74       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 85.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44541      |
| perf/AverageLength             | 216        |
| perf/AverageReturn             | 608.1595   |
| perf/NormalizedReturn          | 0.132      |
| Q-avg                          | 148.09398  |
| Q-std                          | 71.51029   |
| Q_loss                         | 81.70557   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 29         |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000302   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000669   |
| times/evaluation_paths         | 6.97       |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 58.3       |
| timestep                       | 1000       |
| timesteps_total                | 30000      |
| train-steps                    | 30000      |
| training/Q/q1_loss             | 81.22814   |
| training/sac_pi/alpha          | 0.13075168 |
| training/sac_pi/alpha_loss     | -0.0960211 |
| training/sac_pi/logp_pi        | 4.926722   |
| training/sac_pi/pi_entropy     | 3.760938   |
| training/sac_pi/pi_global_norm | 1.3111539  |
| training/sac_pi/policy_loss    | -150.34724 |
| training/sac_pi/std            | 0.53699297 |
| training/sac_pi/valid_num      | 4945.0     |
| training/sac_Q/q1              | 144.92265  |
| training/sac_Q/q2              | 144.3863   |
| training/sac_Q/q2_loss         | 81.55478   |
| training/sac_Q/q_global_norm   | 236.082    |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13642031 |
| epoch                          | 30         |
| evaluation/episode-length-avg  | 114        |
| evaluation/episode-length-max  | 123        |
| evaluation/episode-length-min  | 110        |
| evaluation/episode-length-std  | 3.43       |
| evaluation/return-average      | 276.70453  |
| evaluation/return-max          | 295.57083  |
| evaluation/return-min          | 267.171    |
| evaluation/return-std          | 7.2438574  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.6        |
| model/origin_ret               | 81.9       |
| model/penalty_ret              | 84.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44701      |
| perf/AverageLength             | 114        |
| perf/AverageReturn             | 276.70453  |
| perf/NormalizedReturn          | 0.0599     |
| Q-avg                          | 142.03806  |
| Q-std                          | 81.66243   |
| Q_loss                         | 84.05134   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 30         |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000151   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000633   |
| times/evaluation_paths         | 3.82       |
| times/timestep_after_hook      | 0.00435    |
| times/timestep_before_hook     | 0.00863    |
| times/train                    | 59.3       |
| timestep                       | 1000       |
| timesteps_total                | 31000      |
| train-steps                    | 31000      |
| training/Q/q1_loss             | 78.92858   |
| training/sac_pi/alpha          | 0.13636465 |
| training/sac_pi/alpha_loss     | 0.93163526 |
| training/sac_pi/logp_pi        | 4.9009056  |
| training/sac_pi/pi_entropy     | 3.7622466  |
| training/sac_pi/pi_global_norm | 1.6370578  |
| training/sac_pi/policy_loss    | -158.6178  |
| training/sac_pi/std            | 0.51546174 |
| training/sac_pi/valid_num      | 4907.0     |
| training/sac_Q/q1              | 152.51181  |
| training/sac_Q/q2              | 151.99234  |
| training/sac_Q/q2_loss         | 78.64605   |
| training/sac_Q/q_global_norm   | 259.48767  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14146544  |
| epoch                          | 31          |
| evaluation/episode-length-avg  | 776         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 123         |
| evaluation/episode-length-std  | 349         |
| evaluation/return-average      | 2999.643    |
| evaluation/return-max          | 3995.1528   |
| evaluation/return-min          | 342.11948   |
| evaluation/return-std          | 1427.9822   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.89        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 84.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 44784       |
| perf/AverageLength             | 776         |
| perf/AverageReturn             | 2999.643    |
| perf/NormalizedReturn          | 0.653       |
| Q-avg                          | 139.14749   |
| Q-std                          | 77.65434    |
| Q_loss                         | 80.243614   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 31          |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000105    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000473    |
| times/evaluation_paths         | 24.7        |
| times/timestep_after_hook      | 0.00386     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 58.4        |
| timestep                       | 1000        |
| timesteps_total                | 32000       |
| train-steps                    | 32000       |
| training/Q/q1_loss             | 86.2038     |
| training/sac_pi/alpha          | 0.14147124  |
| training/sac_pi/alpha_loss     | -0.12278001 |
| training/sac_pi/logp_pi        | 5.3342586   |
| training/sac_pi/pi_entropy     | 3.9305363   |
| training/sac_pi/pi_global_norm | 1.0919774   |
| training/sac_pi/policy_loss    | -155.6434   |
| training/sac_pi/std            | 0.58318764  |
| training/sac_pi/valid_num      | 4853.0      |
| training/sac_Q/q1              | 147.8164    |
| training/sac_Q/q2              | 147.52022   |
| training/sac_Q/q2_loss         | 86.22016    |
| training/sac_Q/q_global_norm   | 197.08122   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13541378 |
| epoch                          | 32         |
| evaluation/episode-length-avg  | 166        |
| evaluation/episode-length-max  | 175        |
| evaluation/episode-length-min  | 158        |
| evaluation/episode-length-std  | 5.59       |
| evaluation/return-average      | 419.6482   |
| evaluation/return-max          | 453.16104  |
| evaluation/return-min          | 392.73972  |
| evaluation/return-std          | 16.902712  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.63       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 85.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44403      |
| perf/AverageLength             | 166        |
| perf/AverageReturn             | 419.6482   |
| perf/NormalizedReturn          | 0.0911     |
| Q-avg                          | 142.92488  |
| Q-std                          | 84.61778   |
| Q_loss                         | 72.554596  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 32         |
| times/epoch_after_hook         | 2.11e-06   |
| times/epoch_before_hook        | 0.000115   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000684   |
| times/evaluation_paths         | 5.48       |
| times/timestep_after_hook      | 0.00375    |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 57.7       |
| timestep                       | 1000       |
| timesteps_total                | 33000      |
| train-steps                    | 33000      |
| training/Q/q1_loss             | 74.98455   |
| training/sac_pi/alpha          | 0.13539265 |
| training/sac_pi/alpha_loss     | 0.3490251  |
| training/sac_pi/logp_pi        | 5.090068   |
| training/sac_pi/pi_entropy     | 3.7573388  |
| training/sac_pi/pi_global_norm | 0.90214324 |
| training/sac_pi/policy_loss    | -155.77751 |
| training/sac_pi/std            | 0.54357684 |
| training/sac_pi/valid_num      | 4921.0     |
| training/sac_Q/q1              | 149.33235  |
| training/sac_Q/q2              | 148.91632  |
| training/sac_Q/q2_loss         | 75.69638   |
| training/sac_Q/q_global_norm   | 212.96532  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.13185519  |
| epoch                          | 33          |
| evaluation/episode-length-avg  | 139         |
| evaluation/episode-length-max  | 152         |
| evaluation/episode-length-min  | 136         |
| evaluation/episode-length-std  | 4.63        |
| evaluation/return-average      | 410.41245   |
| evaluation/return-max          | 453.42706   |
| evaluation/return-min          | 398.237     |
| evaluation/return-std          | 15.140764   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.73        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 85.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 44862       |
| perf/AverageLength             | 139         |
| perf/AverageReturn             | 410.41245   |
| perf/NormalizedReturn          | 0.089       |
| Q-avg                          | 150.61565   |
| Q-std                          | 70.011635   |
| Q_loss                         | 81.330055   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 33          |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000267    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000579    |
| times/evaluation_paths         | 4.39        |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.00838     |
| times/train                    | 58.7        |
| timestep                       | 1000        |
| timesteps_total                | 34000       |
| train-steps                    | 34000       |
| training/Q/q1_loss             | 89.394455   |
| training/sac_pi/alpha          | 0.13188341  |
| training/sac_pi/alpha_loss     | -0.74549097 |
| training/sac_pi/logp_pi        | 4.5166693   |
| training/sac_pi/pi_entropy     | 3.9281502   |
| training/sac_pi/pi_global_norm | 1.3341355   |
| training/sac_pi/policy_loss    | -156.88818  |
| training/sac_pi/std            | 0.57487446  |
| training/sac_pi/valid_num      | 4903.0      |
| training/sac_Q/q1              | 150.69681   |
| training/sac_Q/q2              | 149.33257   |
| training/sac_Q/q2_loss         | 88.886566   |
| training/sac_Q/q_global_norm   | 232.42137   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14329559 |
| epoch                          | 34         |
| evaluation/episode-length-avg  | 744        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 146        |
| evaluation/episode-length-std  | 391        |
| evaluation/return-average      | 3413.7485  |
| evaluation/return-max          | 4763.438   |
| evaluation/return-min          | 337.90314  |
| evaluation/return-std          | 2013.2866  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.55       |
| model/origin_ret               | 81.1       |
| model/penalty_ret              | 83.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44868      |
| perf/AverageLength             | 744        |
| perf/AverageReturn             | 3413.7485  |
| perf/NormalizedReturn          | 0.743      |
| Q-avg                          | 138.92229  |
| Q-std                          | 82.01346   |
| Q_loss                         | 92.56278   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 34         |
| times/epoch_after_hook         | 2.03e-06   |
| times/epoch_before_hook        | 0.000114   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.00069    |
| times/evaluation_paths         | 23.8       |
| times/timestep_after_hook      | 0.00381    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 58         |
| timestep                       | 1000       |
| timesteps_total                | 35000      |
| train-steps                    | 35000      |
| training/Q/q1_loss             | 76.56064   |
| training/sac_pi/alpha          | 0.14329112 |
| training/sac_pi/alpha_loss     | 0.18931557 |
| training/sac_pi/logp_pi        | 5.070951   |
| training/sac_pi/pi_entropy     | 3.8423371  |
| training/sac_pi/pi_global_norm | 0.9061235  |
| training/sac_pi/policy_loss    | -153.45628 |
| training/sac_pi/std            | 0.55300206 |
| training/sac_pi/valid_num      | 4898.0     |
| training/sac_Q/q1              | 146.8667   |
| training/sac_Q/q2              | 145.90483  |
| training/sac_Q/q2_loss         | 77.06315   |
| training/sac_Q/q_global_norm   | 307.95044  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13134329 |
| epoch                          | 35         |
| evaluation/episode-length-avg  | 101        |
| evaluation/episode-length-max  | 102        |
| evaluation/episode-length-min  | 99         |
| evaluation/episode-length-std  | 1.08       |
| evaluation/return-average      | 163.44232  |
| evaluation/return-max          | 172.19962  |
| evaluation/return-min          | 153.33159  |
| evaluation/return-std          | 5.3519754  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.71       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 86         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44508      |
| perf/AverageLength             | 101        |
| perf/AverageReturn             | 163.44232  |
| perf/NormalizedReturn          | 0.0352     |
| Q-avg                          | 156.68839  |
| Q-std                          | 76.84116   |
| Q_loss                         | 91.66681   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 35         |
| times/epoch_after_hook         | 1.99e-06   |
| times/epoch_before_hook        | 0.00015    |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000525   |
| times/evaluation_paths         | 3.32       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 58.8       |
| timestep                       | 1000       |
| timesteps_total                | 36000      |
| train-steps                    | 36000      |
| training/Q/q1_loss             | 82.42112   |
| training/sac_pi/alpha          | 0.13131016 |
| training/sac_pi/alpha_loss     | 0.11249387 |
| training/sac_pi/logp_pi        | 5.0951447  |
| training/sac_pi/pi_entropy     | 3.8423424  |
| training/sac_pi/pi_global_norm | 2.352709   |
| training/sac_pi/policy_loss    | -155.72867 |
| training/sac_pi/std            | 0.555407   |
| training/sac_pi/valid_num      | 4900.0     |
| training/sac_Q/q1              | 149.47871  |
| training/sac_Q/q2              | 149.32443  |
| training/sac_Q/q2_loss         | 83.32163   |
| training/sac_Q/q_global_norm   | 224.70467  |
--------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.13575913    |
| epoch                          | 36            |
| evaluation/episode-length-avg  | 208           |
| evaluation/episode-length-max  | 228           |
| evaluation/episode-length-min  | 193           |
| evaluation/episode-length-std  | 11.1          |
| evaluation/return-average      | 435.21158     |
| evaluation/return-max          | 445.026       |
| evaluation/return-min          | 426.1772      |
| evaluation/return-std          | 5.82014       |
| model/max_penalty              | 7.34          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 2.5           |
| model/origin_ret               | 80.9          |
| model/penalty_ret              | 84.6          |
| model/val_loss                 | 0.35430613    |
| model/valid_num                | 44854         |
| perf/AverageLength             | 208           |
| perf/AverageReturn             | 435.21158     |
| perf/NormalizedReturn          | 0.0944        |
| Q-avg                          | 156.13829     |
| Q-std                          | 78.4479       |
| Q_loss                         | 82.25795      |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 36            |
| times/epoch_after_hook         | 1.8e-06       |
| times/epoch_before_hook        | 8.97e-05      |
| times/epoch_rollout_model      | 483           |
| times/evaluation_metrics       | 0.000581      |
| times/evaluation_paths         | 6.65          |
| times/timestep_after_hook      | 0.00363       |
| times/timestep_before_hook     | 0.008         |
| times/train                    | 58            |
| timestep                       | 1000          |
| timesteps_total                | 37000         |
| train-steps                    | 37000         |
| training/Q/q1_loss             | 74.075264     |
| training/sac_pi/alpha          | 0.13578194    |
| training/sac_pi/alpha_loss     | -0.0058215247 |
| training/sac_pi/logp_pi        | 4.4337835     |
| training/sac_pi/pi_entropy     | 3.8817272     |
| training/sac_pi/pi_global_norm | 0.91392684    |
| training/sac_pi/policy_loss    | -152.26169    |
| training/sac_pi/std            | 0.5452959     |
| training/sac_pi/valid_num      | 4942.0        |
| training/sac_Q/q1              | 146.54742     |
| training/sac_Q/q2              | 146.63574     |
| training/sac_Q/q2_loss         | 74.14768      |
| training/sac_Q/q_global_norm   | 200.71234     |
-----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1381392   |
| epoch                          | 37          |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4342.167    |
| evaluation/return-max          | 4390.8506   |
| evaluation/return-min          | 4309.711    |
| evaluation/return-std          | 20.865696   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.83        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 84.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45035       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4342.167    |
| perf/NormalizedReturn          | 0.946       |
| Q-avg                          | 147.8844    |
| Q-std                          | 84.29673    |
| Q_loss                         | 95.30644    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 37          |
| times/epoch_after_hook         | 2e-06       |
| times/epoch_before_hook        | 0.000312    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000617    |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 57.1        |
| timestep                       | 1000        |
| timesteps_total                | 38000       |
| train-steps                    | 38000       |
| training/Q/q1_loss             | 86.99165    |
| training/sac_pi/alpha          | 0.13813968  |
| training/sac_pi/alpha_loss     | -0.14286865 |
| training/sac_pi/logp_pi        | 4.547591    |
| training/sac_pi/pi_entropy     | 3.5913875   |
| training/sac_pi/pi_global_norm | 1.3350433   |
| training/sac_pi/policy_loss    | -158.17868  |
| training/sac_pi/std            | 0.5247499   |
| training/sac_pi/valid_num      | 4915.0      |
| training/sac_Q/q1              | 151.31412   |
| training/sac_Q/q2              | 150.84209   |
| training/sac_Q/q2_loss         | 86.48793    |
| training/sac_Q/q_global_norm   | 348.1475    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13760753 |
| epoch                          | 38         |
| evaluation/episode-length-avg  | 122        |
| evaluation/episode-length-max  | 126        |
| evaluation/episode-length-min  | 120        |
| evaluation/episode-length-std  | 1.89       |
| evaluation/return-average      | 272.38632  |
| evaluation/return-max          | 289.5879   |
| evaluation/return-min          | 258.3343   |
| evaluation/return-std          | 8.49978    |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.73       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 84.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44980      |
| perf/AverageLength             | 122        |
| perf/AverageReturn             | 272.38632  |
| perf/NormalizedReturn          | 0.059      |
| Q-avg                          | 145.91013  |
| Q-std                          | 80.75019   |
| Q_loss                         | 79.619644  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 38         |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000506   |
| times/evaluation_paths         | 4.04       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00869    |
| times/train                    | 57.9       |
| timestep                       | 1000       |
| timesteps_total                | 39000      |
| train-steps                    | 39000      |
| training/Q/q1_loss             | 88.19456   |
| training/sac_pi/alpha          | 0.13760924 |
| training/sac_pi/alpha_loss     | 0.95148855 |
| training/sac_pi/logp_pi        | 4.1722107  |
| training/sac_pi/pi_entropy     | 3.3705993  |
| training/sac_pi/pi_global_norm | 0.8806997  |
| training/sac_pi/policy_loss    | -161.92642 |
| training/sac_pi/std            | 0.46293622 |
| training/sac_pi/valid_num      | 5047.0     |
| training/sac_Q/q1              | 160.23744  |
| training/sac_Q/q2              | 159.73486  |
| training/sac_Q/q2_loss         | 87.669464  |
| training/sac_Q/q_global_norm   | 326.19855  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13286017 |
| epoch                          | 39         |
| evaluation/episode-length-avg  | 110        |
| evaluation/episode-length-max  | 112        |
| evaluation/episode-length-min  | 106        |
| evaluation/episode-length-std  | 1.58       |
| evaluation/return-average      | 308.63104  |
| evaluation/return-max          | 318.3528   |
| evaluation/return-min          | 301.2205   |
| evaluation/return-std          | 4.2102275  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.79       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 83.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44882      |
| perf/AverageLength             | 110        |
| perf/AverageReturn             | 308.63104  |
| perf/NormalizedReturn          | 0.0669     |
| Q-avg                          | 157.92746  |
| Q-std                          | 71.48501   |
| Q_loss                         | 85.27375   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 39         |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 8.65e-05   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000497   |
| times/evaluation_paths         | 3.55       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00809    |
| times/train                    | 57.7       |
| timestep                       | 1000       |
| timesteps_total                | 40000      |
| train-steps                    | 40000      |
| training/Q/q1_loss             | 75.93348   |
| training/sac_pi/alpha          | 0.13284163 |
| training/sac_pi/alpha_loss     | 0.01910353 |
| training/sac_pi/logp_pi        | 5.256304   |
| training/sac_pi/pi_entropy     | 3.7650485  |
| training/sac_pi/pi_global_norm | 1.0859249  |
| training/sac_pi/policy_loss    | -156.88249 |
| training/sac_pi/std            | 0.55724895 |
| training/sac_pi/valid_num      | 4896.0     |
| training/sac_Q/q1              | 150.30421  |
| training/sac_Q/q2              | 148.1122   |
| training/sac_Q/q2_loss         | 76.33025   |
| training/sac_Q/q_global_norm   | 198.10693  |
--------------------------------------------------------------------------------
[WARN] 40 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.14574467 |
| epoch                          | 40         |
| evaluation/episode-length-avg  | 309        |
| evaluation/episode-length-max  | 627        |
| evaluation/episode-length-min  | 154        |
| evaluation/episode-length-std  | 190        |
| evaluation/return-average      | 1100.6748  |
| evaluation/return-max          | 2736.8599  |
| evaluation/return-min          | 373.32132  |
| evaluation/return-std          | 948.29315  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.63       |
| model/origin_ret               | 82.8       |
| model/penalty_ret              | 84.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44629      |
| perf/AverageLength             | 309        |
| perf/AverageReturn             | 1100.6748  |
| perf/NormalizedReturn          | 0.239      |
| Q-avg                          | 145.10168  |
| Q-std                          | 77.15227   |
| Q_loss                         | 93.655495  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 40         |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 8.72e-05   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000544   |
| times/evaluation_paths         | 10.1       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00798    |
| times/train                    | 57.5       |
| timestep                       | 1000       |
| timesteps_total                | 41000      |
| train-steps                    | 41000      |
| training/Q/q1_loss             | 93.95209   |
| training/sac_pi/alpha          | 0.14569174 |
| training/sac_pi/alpha_loss     | 0.64934576 |
| training/sac_pi/logp_pi        | 4.733605   |
| training/sac_pi/pi_entropy     | 3.7539177  |
| training/sac_pi/pi_global_norm | 1.007397   |
| training/sac_pi/policy_loss    | -158.54214 |
| training/sac_pi/std            | 0.5281595  |
| training/sac_pi/valid_num      | 4995.0     |
| training/sac_Q/q1              | 154.99414  |
| training/sac_Q/q2              | 154.35876  |
| training/sac_Q/q2_loss         | 93.88784   |
| training/sac_Q/q_global_norm   | 322.3466   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1343967  |
| epoch                          | 41         |
| evaluation/episode-length-avg  | 397        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 125        |
| evaluation/episode-length-std  | 395        |
| evaluation/return-average      | 1816.6523  |
| evaluation/return-max          | 5222.8413  |
| evaluation/return-min          | 298.04123  |
| evaluation/return-std          | 2218.3687  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.71       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 85.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44068      |
| perf/AverageLength             | 397        |
| perf/AverageReturn             | 1816.6523  |
| perf/NormalizedReturn          | 0.395      |
| Q-avg                          | 147.7189   |
| Q-std                          | 79.4354    |
| Q_loss                         | 89.30464   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 41         |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000274   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000656   |
| times/evaluation_paths         | 12.6       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 58.4       |
| timestep                       | 1000       |
| timesteps_total                | 42000      |
| train-steps                    | 42000      |
| training/Q/q1_loss             | 81.967865  |
| training/sac_pi/alpha          | 0.13439086 |
| training/sac_pi/alpha_loss     | 0.14854394 |
| training/sac_pi/logp_pi        | 4.762133   |
| training/sac_pi/pi_entropy     | 3.7690995  |
| training/sac_pi/pi_global_norm | 1.8275774  |
| training/sac_pi/policy_loss    | -156.4536  |
| training/sac_pi/std            | 0.5381613  |
| training/sac_pi/valid_num      | 4916.0     |
| training/sac_Q/q1              | 150.07681  |
| training/sac_Q/q2              | 149.36133  |
| training/sac_Q/q2_loss         | 81.80892   |
| training/sac_Q/q_global_norm   | 183.78043  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.13849145   |
| epoch                          | 42           |
| evaluation/episode-length-avg  | 830          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 149          |
| evaluation/episode-length-std  | 340          |
| evaluation/return-average      | 4593.426     |
| evaluation/return-max          | 5695.076     |
| evaluation/return-min          | 403.29352    |
| evaluation/return-std          | 2093.098     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.76         |
| model/origin_ret               | 84.6         |
| model/penalty_ret              | 84.9         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 44874        |
| perf/AverageLength             | 830          |
| perf/AverageReturn             | 4593.426     |
| perf/NormalizedReturn          | 1            |
| Q-avg                          | 153.6936     |
| Q-std                          | 79.087524    |
| Q_loss                         | 89.424965    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 42           |
| times/epoch_after_hook         | 1.88e-06     |
| times/epoch_before_hook        | 0.000105     |
| times/epoch_rollout_model      | 489          |
| times/evaluation_metrics       | 0.000878     |
| times/evaluation_paths         | 27.4         |
| times/timestep_after_hook      | 0.0039       |
| times/timestep_before_hook     | 0.00931      |
| times/train                    | 57.6         |
| timestep                       | 1000         |
| timesteps_total                | 43000        |
| train-steps                    | 43000        |
| training/Q/q1_loss             | 99.01986     |
| training/sac_pi/alpha          | 0.13848531   |
| training/sac_pi/alpha_loss     | -0.034750544 |
| training/sac_pi/logp_pi        | 5.065956     |
| training/sac_pi/pi_entropy     | 3.8739562    |
| training/sac_pi/pi_global_norm | 1.1335971    |
| training/sac_pi/policy_loss    | -158.9975    |
| training/sac_pi/std            | 0.56442034   |
| training/sac_pi/valid_num      | 4907.0       |
| training/sac_Q/q1              | 152.59282    |
| training/sac_Q/q2              | 151.86765    |
| training/sac_Q/q2_loss         | 99.72771     |
| training/sac_Q/q_global_norm   | 263.37326    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1350102  |
| epoch                          | 43         |
| evaluation/episode-length-avg  | 577        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 150        |
| evaluation/episode-length-std  | 423        |
| evaluation/return-average      | 2492.8354  |
| evaluation/return-max          | 4657.674   |
| evaluation/return-min          | 373.72263  |
| evaluation/return-std          | 2101.6973  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.71       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 83.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44873      |
| perf/AverageLength             | 577        |
| perf/AverageReturn             | 2492.8354  |
| perf/NormalizedReturn          | 0.543      |
| Q-avg                          | 151.44821  |
| Q-std                          | 78.75338   |
| Q_loss                         | 99.3959    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 43         |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000579   |
| times/evaluation_paths         | 18.5       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 58.4       |
| timestep                       | 1000       |
| timesteps_total                | 44000      |
| train-steps                    | 44000      |
| training/Q/q1_loss             | 92.56322   |
| training/sac_pi/alpha          | 0.13498992 |
| training/sac_pi/alpha_loss     | 0.25839093 |
| training/sac_pi/logp_pi        | 5.178067   |
| training/sac_pi/pi_entropy     | 3.6790729  |
| training/sac_pi/pi_global_norm | 1.4525613  |
| training/sac_pi/policy_loss    | -162.58781 |
| training/sac_pi/std            | 0.5484601  |
| training/sac_pi/valid_num      | 4892.0     |
| training/sac_Q/q1              | 155.2788   |
| training/sac_Q/q2              | 154.87953  |
| training/sac_Q/q2_loss         | 92.09137   |
| training/sac_Q/q_global_norm   | 414.6642   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14002766 |
| epoch                          | 44         |
| evaluation/episode-length-avg  | 162        |
| evaluation/episode-length-max  | 186        |
| evaluation/episode-length-min  | 140        |
| evaluation/episode-length-std  | 14.4       |
| evaluation/return-average      | 351.54443  |
| evaluation/return-max          | 387.54205  |
| evaluation/return-min          | 284.4793   |
| evaluation/return-std          | 38.47087   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.75       |
| model/origin_ret               | 83.8       |
| model/penalty_ret              | 83.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45019      |
| perf/AverageLength             | 162        |
| perf/AverageReturn             | 351.54443  |
| perf/NormalizedReturn          | 0.0762     |
| Q-avg                          | 158.8081   |
| Q-std                          | 73.48863   |
| Q_loss                         | 83.90873   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 44         |
| times/epoch_after_hook         | 3.09e-06   |
| times/epoch_before_hook        | 0.000103   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000597   |
| times/evaluation_paths         | 5.21       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 58.2       |
| timestep                       | 1000       |
| timesteps_total                | 45000      |
| train-steps                    | 45000      |
| training/Q/q1_loss             | 91.230865  |
| training/sac_pi/alpha          | 0.1400241  |
| training/sac_pi/alpha_loss     | 0.1963716  |
| training/sac_pi/logp_pi        | 4.5561447  |
| training/sac_pi/pi_entropy     | 3.57146    |
| training/sac_pi/pi_global_norm | 1.0590771  |
| training/sac_pi/policy_loss    | -159.60657 |
| training/sac_pi/std            | 0.5061991  |
| training/sac_pi/valid_num      | 4970.0     |
| training/sac_Q/q1              | 154.95279  |
| training/sac_Q/q2              | 154.86685  |
| training/sac_Q/q2_loss         | 90.91392   |
| training/sac_Q/q_global_norm   | 299.4233   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14074363 |
| epoch                          | 45         |
| evaluation/episode-length-avg  | 197        |
| evaluation/episode-length-max  | 409        |
| evaluation/episode-length-min  | 171        |
| evaluation/episode-length-std  | 70.7       |
| evaluation/return-average      | 571.8921   |
| evaluation/return-max          | 1509.0797  |
| evaluation/return-min          | 462.78577  |
| evaluation/return-std          | 312.44516  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.64       |
| model/origin_ret               | 82.7       |
| model/penalty_ret              | 84.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44862      |
| perf/AverageLength             | 197        |
| perf/AverageReturn             | 571.8921   |
| perf/NormalizedReturn          | 0.124      |
| Q-avg                          | 162.54623  |
| Q-std                          | 71.2694    |
| Q_loss                         | 89.67697   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 45         |
| times/epoch_after_hook         | 1.98e-06   |
| times/epoch_before_hook        | 0.000306   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 6.47       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 57.8       |
| timestep                       | 1000       |
| timesteps_total                | 46000      |
| train-steps                    | 46000      |
| training/Q/q1_loss             | 96.40681   |
| training/sac_pi/alpha          | 0.14075154 |
| training/sac_pi/alpha_loss     | -0.3370472 |
| training/sac_pi/logp_pi        | 3.883924   |
| training/sac_pi/pi_entropy     | 3.5101342  |
| training/sac_pi/pi_global_norm | 0.98069817 |
| training/sac_pi/policy_loss    | -167.36636 |
| training/sac_pi/std            | 0.47836617 |
| training/sac_pi/valid_num      | 5022.0     |
| training/sac_Q/q1              | 164.89377  |
| training/sac_Q/q2              | 164.34523  |
| training/sac_Q/q2_loss         | 95.70363   |
| training/sac_Q/q_global_norm   | 302.16278  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14992873  |
| epoch                          | 46          |
| evaluation/episode-length-avg  | 916         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 162         |
| evaluation/episode-length-std  | 251         |
| evaluation/return-average      | 3960.8237   |
| evaluation/return-max          | 4458.9014   |
| evaluation/return-min          | 452.54486   |
| evaluation/return-std          | 1170.5645   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.73        |
| model/origin_ret               | 83.3        |
| model/penalty_ret              | 83.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 44850       |
| perf/AverageLength             | 916         |
| perf/AverageReturn             | 3960.8237   |
| perf/NormalizedReturn          | 0.862       |
| Q-avg                          | 157.16966   |
| Q-std                          | 85.96118    |
| Q_loss                         | 93.326355   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 46          |
| times/epoch_after_hook         | 1.6e-06     |
| times/epoch_before_hook        | 0.000175    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000558    |
| times/evaluation_paths         | 29.6        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 58.5        |
| timestep                       | 1000        |
| timesteps_total                | 47000       |
| train-steps                    | 47000       |
| training/Q/q1_loss             | 93.34289    |
| training/sac_pi/alpha          | 0.14996007  |
| training/sac_pi/alpha_loss     | -0.27950555 |
| training/sac_pi/logp_pi        | 4.4345617   |
| training/sac_pi/pi_entropy     | 3.833997    |
| training/sac_pi/pi_global_norm | 1.310301    |
| training/sac_pi/policy_loss    | -161.96059  |
| training/sac_pi/std            | 0.5366105   |
| training/sac_pi/valid_num      | 4953.0      |
| training/sac_Q/q1              | 156.03369   |
| training/sac_Q/q2              | 155.31969   |
| training/sac_Q/q2_loss         | 93.39881    |
| training/sac_Q/q_global_norm   | 217.9652    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14223641 |
| epoch                          | 47         |
| evaluation/episode-length-avg  | 324        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 244        |
| evaluation/episode-length-std  | 225        |
| evaluation/return-average      | 927.5047   |
| evaluation/return-max          | 4417.6777  |
| evaluation/return-min          | 534.9066   |
| evaluation/return-std          | 1163.4034  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.7        |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 85.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44396      |
| perf/AverageLength             | 324        |
| perf/AverageReturn             | 927.5047   |
| perf/NormalizedReturn          | 0.202      |
| Q-avg                          | 156.29288  |
| Q-std                          | 81.40183   |
| Q_loss                         | 88.89065   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 47         |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000116   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000636   |
| times/evaluation_paths         | 10.4       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 59         |
| timestep                       | 1000       |
| timesteps_total                | 48000      |
| train-steps                    | 48000      |
| training/Q/q1_loss             | 95.08684   |
| training/sac_pi/alpha          | 0.1422019  |
| training/sac_pi/alpha_loss     | 0.7619655  |
| training/sac_pi/logp_pi        | 5.9967     |
| training/sac_pi/pi_entropy     | 3.7850888  |
| training/sac_pi/pi_global_norm | 0.9991436  |
| training/sac_pi/policy_loss    | -154.894   |
| training/sac_pi/std            | 0.5648988  |
| training/sac_pi/valid_num      | 4874.0     |
| training/sac_Q/q1              | 147.35083  |
| training/sac_Q/q2              | 146.58723  |
| training/sac_Q/q2_loss         | 95.73215   |
| training/sac_Q/q_global_norm   | 212.32106  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14024349 |
| epoch                          | 48         |
| evaluation/episode-length-avg  | 917        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 170        |
| evaluation/episode-length-std  | 249        |
| evaluation/return-average      | 4390.1104  |
| evaluation/return-max          | 4924.149   |
| evaluation/return-min          | 376.9147   |
| evaluation/return-std          | 1338.9967  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.81       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 85.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44797      |
| perf/AverageLength             | 917        |
| perf/AverageReturn             | 4390.1104  |
| perf/NormalizedReturn          | 0.956      |
| Q-avg                          | 163.30179  |
| Q-std                          | 82.78042   |
| Q_loss                         | 82.73228   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 48         |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000117   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000605   |
| times/evaluation_paths         | 29.2       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 57.3       |
| timestep                       | 1000       |
| timesteps_total                | 49000      |
| train-steps                    | 49000      |
| training/Q/q1_loss             | 86.128006  |
| training/sac_pi/alpha          | 0.1402271  |
| training/sac_pi/alpha_loss     | 0.53856987 |
| training/sac_pi/logp_pi        | 5.2354484  |
| training/sac_pi/pi_entropy     | 3.6371913  |
| training/sac_pi/pi_global_norm | 1.2945555  |
| training/sac_pi/policy_loss    | -171.62881 |
| training/sac_pi/std            | 0.536262   |
| training/sac_pi/valid_num      | 4910.0     |
| training/sac_Q/q1              | 164.17159  |
| training/sac_Q/q2              | 163.00023  |
| training/sac_Q/q2_loss         | 86.99349   |
| training/sac_Q/q_global_norm   | 259.45227  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1414978   |
| epoch                          | 49          |
| evaluation/episode-length-avg  | 316         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 139         |
| evaluation/episode-length-std  | 342         |
| evaluation/return-average      | 1252.6537   |
| evaluation/return-max          | 4689.6113   |
| evaluation/return-min          | 382.7832    |
| evaluation/return-std          | 1713.3795   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.85        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 84.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 44951       |
| perf/AverageLength             | 316         |
| perf/AverageReturn             | 1252.6537   |
| perf/NormalizedReturn          | 0.273       |
| Q-avg                          | 151.54128   |
| Q-std                          | 86.971466   |
| Q_loss                         | 83.43249    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 49          |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000286    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000486    |
| times/evaluation_paths         | 10.1        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00805     |
| times/train                    | 57.7        |
| timestep                       | 1000        |
| timesteps_total                | 50000       |
| train-steps                    | 50000       |
| training/Q/q1_loss             | 95.48479    |
| training/sac_pi/alpha          | 0.14150935  |
| training/sac_pi/alpha_loss     | -0.12372918 |
| training/sac_pi/logp_pi        | 4.4007316   |
| training/sac_pi/pi_entropy     | 3.9049544   |
| training/sac_pi/pi_global_norm | 0.93714195  |
| training/sac_pi/policy_loss    | -158.32378  |
| training/sac_pi/std            | 0.5519349   |
| training/sac_pi/valid_num      | 4897.0      |
| training/sac_Q/q1              | 150.90305   |
| training/sac_Q/q2              | 149.94164   |
| training/sac_Q/q2_loss         | 95.60796    |
| training/sac_Q/q_global_norm   | 273.50427   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.13984193  |
| epoch                          | 50          |
| evaluation/episode-length-avg  | 385         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 119         |
| evaluation/episode-length-std  | 403         |
| evaluation/return-average      | 1532.8923   |
| evaluation/return-max          | 4573.846    |
| evaluation/return-min          | 241.4002    |
| evaluation/return-std          | 1962.769    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.69        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 85.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 44737       |
| perf/AverageLength             | 385         |
| perf/AverageReturn             | 1532.8923   |
| perf/NormalizedReturn          | 0.334       |
| Q-avg                          | 156.7216    |
| Q-std                          | 79.63816    |
| Q_loss                         | 89.2726     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 50          |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.00014     |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000575    |
| times/evaluation_paths         | 12.2        |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 58.4        |
| timestep                       | 1000        |
| timesteps_total                | 51000       |
| train-steps                    | 51000       |
| training/Q/q1_loss             | 107.284935  |
| training/sac_pi/alpha          | 0.1398428   |
| training/sac_pi/alpha_loss     | -0.09722658 |
| training/sac_pi/logp_pi        | 5.3123417   |
| training/sac_pi/pi_entropy     | 3.8902893   |
| training/sac_pi/pi_global_norm | 1.1747695   |
| training/sac_pi/policy_loss    | -161.95523  |
| training/sac_pi/std            | 0.58791506  |
| training/sac_pi/valid_num      | 4848.0      |
| training/sac_Q/q1              | 151.24692   |
| training/sac_Q/q2              | 149.42941   |
| training/sac_Q/q2_loss         | 106.64237   |
| training/sac_Q/q_global_norm   | 268.77405   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.13756071  |
| epoch                          | 51          |
| evaluation/episode-length-avg  | 302         |
| evaluation/episode-length-max  | 573         |
| evaluation/episode-length-min  | 138         |
| evaluation/episode-length-std  | 180         |
| evaluation/return-average      | 1088.6677   |
| evaluation/return-max          | 2262.8052   |
| evaluation/return-min          | 390.8411    |
| evaluation/return-std          | 766.6442    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.82        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 84.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45290       |
| perf/AverageLength             | 302         |
| perf/AverageReturn             | 1088.6677   |
| perf/NormalizedReturn          | 0.237       |
| Q-avg                          | 151.59212   |
| Q-std                          | 81.51844    |
| Q_loss                         | 81.56531    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 51          |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000584    |
| times/evaluation_paths         | 9.69        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 57.9        |
| timestep                       | 1000        |
| timesteps_total                | 52000       |
| train-steps                    | 52000       |
| training/Q/q1_loss             | 66.14204    |
| training/sac_pi/alpha          | 0.137579    |
| training/sac_pi/alpha_loss     | -0.29189444 |
| training/sac_pi/logp_pi        | 3.9864414   |
| training/sac_pi/pi_entropy     | 3.8538826   |
| training/sac_pi/pi_global_norm | 1.1245134   |
| training/sac_pi/policy_loss    | -160.79008  |
| training/sac_pi/std            | 0.533732    |
| training/sac_pi/valid_num      | 4939.0      |
| training/sac_Q/q1              | 153.9113    |
| training/sac_Q/q2              | 153.18867   |
| training/sac_Q/q2_loss         | 66.254      |
| training/sac_Q/q_global_norm   | 373.57123   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.13979271   |
| epoch                          | 52           |
| evaluation/episode-length-avg  | 113          |
| evaluation/episode-length-max  | 121          |
| evaluation/episode-length-min  | 107          |
| evaluation/episode-length-std  | 3.93         |
| evaluation/return-average      | 227.01428    |
| evaluation/return-max          | 249.49654    |
| evaluation/return-min          | 213.64946    |
| evaluation/return-std          | 10.281474    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.6          |
| model/origin_ret               | 81           |
| model/penalty_ret              | 84.5         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45087        |
| perf/AverageLength             | 113          |
| perf/AverageReturn             | 227.01428    |
| perf/NormalizedReturn          | 0.0491       |
| Q-avg                          | 155.31888    |
| Q-std                          | 86.0471      |
| Q_loss                         | 92.5372      |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 52           |
| times/epoch_after_hook         | 1.8e-06      |
| times/epoch_before_hook        | 0.000106     |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.000578     |
| times/evaluation_paths         | 3.69         |
| times/timestep_after_hook      | 0.00366      |
| times/timestep_before_hook     | 0.00799      |
| times/train                    | 57.5         |
| timestep                       | 1000         |
| timesteps_total                | 53000        |
| train-steps                    | 53000        |
| training/Q/q1_loss             | 87.52614     |
| training/sac_pi/alpha          | 0.139809     |
| training/sac_pi/alpha_loss     | -0.032315467 |
| training/sac_pi/logp_pi        | 4.7736773    |
| training/sac_pi/pi_entropy     | 3.7147515    |
| training/sac_pi/pi_global_norm | 1.1457947    |
| training/sac_pi/policy_loss    | -164.32994   |
| training/sac_pi/std            | 0.5620275    |
| training/sac_pi/valid_num      | 4918.0       |
| training/sac_Q/q1              | 156.74161    |
| training/sac_Q/q2              | 155.37119    |
| training/sac_Q/q2_loss         | 87.727455    |
| training/sac_Q/q_global_norm   | 190.68109    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13976935 |
| epoch                          | 53         |
| evaluation/episode-length-avg  | 119        |
| evaluation/episode-length-max  | 120        |
| evaluation/episode-length-min  | 118        |
| evaluation/episode-length-std  | 0.632      |
| evaluation/return-average      | 270.02216  |
| evaluation/return-max          | 279.54398  |
| evaluation/return-min          | 261.36313  |
| evaluation/return-std          | 5.0543733  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.72       |
| model/origin_ret               | 83         |
| model/penalty_ret              | 83.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45043      |
| perf/AverageLength             | 119        |
| perf/AverageReturn             | 270.02216  |
| perf/NormalizedReturn          | 0.0585     |
| Q-avg                          | 166.53531  |
| Q-std                          | 73.88366   |
| Q_loss                         | 88.25798   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 53         |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000323   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000621   |
| times/evaluation_paths         | 3.84       |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.00783    |
| times/train                    | 57.4       |
| timestep                       | 1000       |
| timesteps_total                | 54000      |
| train-steps                    | 54000      |
| training/Q/q1_loss             | 79.88849   |
| training/sac_pi/alpha          | 0.13973743 |
| training/sac_pi/alpha_loss     | 0.16372281 |
| training/sac_pi/logp_pi        | 4.827301   |
| training/sac_pi/pi_entropy     | 3.8679428  |
| training/sac_pi/pi_global_norm | 1.6978168  |
| training/sac_pi/policy_loss    | -170.91122 |
| training/sac_pi/std            | 0.56955403 |
| training/sac_pi/valid_num      | 4962.0     |
| training/sac_Q/q1              | 165.67937  |
| training/sac_Q/q2              | 163.77652  |
| training/sac_Q/q2_loss         | 79.60143   |
| training/sac_Q/q_global_norm   | 195.03871  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1367589  |
| epoch                          | 54         |
| evaluation/episode-length-avg  | 119        |
| evaluation/episode-length-max  | 123        |
| evaluation/episode-length-min  | 116        |
| evaluation/episode-length-std  | 1.79       |
| evaluation/return-average      | 253.91057  |
| evaluation/return-max          | 263.2795   |
| evaluation/return-min          | 244.06572  |
| evaluation/return-std          | 5.043879   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.82       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 84.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44787      |
| perf/AverageLength             | 119        |
| perf/AverageReturn             | 253.91057  |
| perf/NormalizedReturn          | 0.055      |
| Q-avg                          | 158.4652   |
| Q-std                          | 82.936516  |
| Q_loss                         | 105.77609  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 54         |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 6.62e-05   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000474   |
| times/evaluation_paths         | 3.87       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 57.6       |
| timestep                       | 1000       |
| timesteps_total                | 55000      |
| train-steps                    | 55000      |
| training/Q/q1_loss             | 89.41812   |
| training/sac_pi/alpha          | 0.136788   |
| training/sac_pi/alpha_loss     | 0.28326035 |
| training/sac_pi/logp_pi        | 3.7825432  |
| training/sac_pi/pi_entropy     | 3.6844106  |
| training/sac_pi/pi_global_norm | 1.2739582  |
| training/sac_pi/policy_loss    | -167.88643 |
| training/sac_pi/std            | 0.49104676 |
| training/sac_pi/valid_num      | 5021.0     |
| training/sac_Q/q1              | 165.17075  |
| training/sac_Q/q2              | 164.09286  |
| training/sac_Q/q2_loss         | 88.75256   |
| training/sac_Q/q_global_norm   | 243.35332  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13874522 |
| epoch                          | 55         |
| evaluation/episode-length-avg  | 170        |
| evaluation/episode-length-max  | 181        |
| evaluation/episode-length-min  | 160        |
| evaluation/episode-length-std  | 7.22       |
| evaluation/return-average      | 427.66278  |
| evaluation/return-max          | 446.41858  |
| evaluation/return-min          | 412.18546  |
| evaluation/return-std          | 11.083918  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.75       |
| model/origin_ret               | 83.5       |
| model/penalty_ret              | 82.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45201      |
| perf/AverageLength             | 170        |
| perf/AverageReturn             | 427.66278  |
| perf/NormalizedReturn          | 0.0928     |
| Q-avg                          | 153.57024  |
| Q-std                          | 90.74957   |
| Q_loss                         | 80.97099   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 55         |
| times/epoch_after_hook         | 2.08e-06   |
| times/epoch_before_hook        | 6.65e-05   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000492   |
| times/evaluation_paths         | 5.38       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00794    |
| times/train                    | 57.1       |
| timestep                       | 1000       |
| timesteps_total                | 56000      |
| train-steps                    | 56000      |
| training/Q/q1_loss             | 82.8392    |
| training/sac_pi/alpha          | 0.13877532 |
| training/sac_pi/alpha_loss     | -0.4433064 |
| training/sac_pi/logp_pi        | 5.1063557  |
| training/sac_pi/pi_entropy     | 3.7253678  |
| training/sac_pi/pi_global_norm | 0.9353245  |
| training/sac_pi/policy_loss    | -165.02011 |
| training/sac_pi/std            | 0.55859756 |
| training/sac_pi/valid_num      | 4897.0     |
| training/sac_Q/q1              | 155.7699   |
| training/sac_Q/q2              | 155.28711  |
| training/sac_Q/q2_loss         | 83.20671   |
| training/sac_Q/q_global_norm   | 219.53583  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.13986962  |
| epoch                          | 56          |
| evaluation/episode-length-avg  | 316         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 140         |
| evaluation/episode-length-std  | 342         |
| evaluation/return-average      | 1293.178    |
| evaluation/return-max          | 4863.085    |
| evaluation/return-min          | 402.66815   |
| evaluation/return-std          | 1742.8848   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.74        |
| model/origin_ret               | 83.8        |
| model/penalty_ret              | 83.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 44948       |
| perf/AverageLength             | 316         |
| perf/AverageReturn             | 1293.178    |
| perf/NormalizedReturn          | 0.281       |
| Q-avg                          | 158.31322   |
| Q-std                          | 83.693726   |
| Q_loss                         | 88.552284   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 56          |
| times/epoch_after_hook         | 2.03e-06    |
| times/epoch_before_hook        | 0.000113    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000503    |
| times/evaluation_paths         | 10          |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00783     |
| times/train                    | 57.4        |
| timestep                       | 1000        |
| timesteps_total                | 57000       |
| train-steps                    | 57000       |
| training/Q/q1_loss             | 88.81824    |
| training/sac_pi/alpha          | 0.13988507  |
| training/sac_pi/alpha_loss     | -0.37774843 |
| training/sac_pi/logp_pi        | 4.3424025   |
| training/sac_pi/pi_entropy     | 3.862955    |
| training/sac_pi/pi_global_norm | 1.3577118   |
| training/sac_pi/policy_loss    | -161.85072  |
| training/sac_pi/std            | 0.54909784  |
| training/sac_pi/valid_num      | 4955.0      |
| training/sac_Q/q1              | 155.04913   |
| training/sac_Q/q2              | 155.1768    |
| training/sac_Q/q2_loss         | 89.13049    |
| training/sac_Q/q_global_norm   | 217.17639   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.14048429   |
| epoch                          | 57           |
| evaluation/episode-length-avg  | 206          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 114          |
| evaluation/episode-length-std  | 265          |
| evaluation/return-average      | 838.3988     |
| evaluation/return-max          | 5207.0366    |
| evaluation/return-min          | 336.46317    |
| evaluation/return-std          | 1456.2527    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.81         |
| model/origin_ret               | 86.3         |
| model/penalty_ret              | 85.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 44946        |
| perf/AverageLength             | 206          |
| perf/AverageReturn             | 838.3988     |
| perf/NormalizedReturn          | 0.182        |
| Q-avg                          | 164.65231    |
| Q-std                          | 76.619644    |
| Q_loss                         | 88.01509     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 57           |
| times/epoch_after_hook         | 1.88e-06     |
| times/epoch_before_hook        | 0.000329     |
| times/epoch_rollout_model      | 486          |
| times/evaluation_metrics       | 0.00048      |
| times/evaluation_paths         | 6.55         |
| times/timestep_after_hook      | 0.00371      |
| times/timestep_before_hook     | 0.00822      |
| times/train                    | 57.6         |
| timestep                       | 1000         |
| timesteps_total                | 58000        |
| train-steps                    | 58000        |
| training/Q/q1_loss             | 77.30531     |
| training/sac_pi/alpha          | 0.14047787   |
| training/sac_pi/alpha_loss     | -0.119061574 |
| training/sac_pi/logp_pi        | 4.131427     |
| training/sac_pi/pi_entropy     | 3.7466912    |
| training/sac_pi/pi_global_norm | 1.2985603    |
| training/sac_pi/policy_loss    | -168.28458   |
| training/sac_pi/std            | 0.51395524   |
| training/sac_pi/valid_num      | 4984.0       |
| training/sac_Q/q1              | 163.48398    |
| training/sac_Q/q2              | 163.42697    |
| training/sac_Q/q2_loss         | 77.46125     |
| training/sac_Q/q_global_norm   | 216.2401     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13969602 |
| epoch                          | 58         |
| evaluation/episode-length-avg  | 506        |
| evaluation/episode-length-max  | 766        |
| evaluation/episode-length-min  | 141        |
| evaluation/episode-length-std  | 164        |
| evaluation/return-average      | 2087.9253  |
| evaluation/return-max          | 3306.8872  |
| evaluation/return-min          | 437.4372   |
| evaluation/return-std          | 759.07825  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.79       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 83.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45063      |
| perf/AverageLength             | 506        |
| perf/AverageReturn             | 2087.9253  |
| perf/NormalizedReturn          | 0.454      |
| Q-avg                          | 159.46318  |
| Q-std                          | 85.8684    |
| Q_loss                         | 71.77433   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 58         |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000108   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000539   |
| times/evaluation_paths         | 16.2       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00793    |
| times/train                    | 56.6       |
| timestep                       | 1000       |
| timesteps_total                | 59000      |
| train-steps                    | 59000      |
| training/Q/q1_loss             | 95.45509   |
| training/sac_pi/alpha          | 0.13968225 |
| training/sac_pi/alpha_loss     | 0.7237029  |
| training/sac_pi/logp_pi        | 5.69543    |
| training/sac_pi/pi_entropy     | 3.7639503  |
| training/sac_pi/pi_global_norm | 1.5559882  |
| training/sac_pi/policy_loss    | -169.07002 |
| training/sac_pi/std            | 0.5612077  |
| training/sac_pi/valid_num      | 4904.0     |
| training/sac_Q/q1              | 159.4802   |
| training/sac_Q/q2              | 157.99857  |
| training/sac_Q/q2_loss         | 95.49281   |
| training/sac_Q/q_global_norm   | 287.26694  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14186175 |
| epoch                          | 59         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5013.1543  |
| evaluation/return-max          | 5030.1445  |
| evaluation/return-min          | 4987.3076  |
| evaluation/return-std          | 14.196037  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.65       |
| model/origin_ret               | 81.2       |
| model/penalty_ret              | 83.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45171      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5013.1543  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 165.84311  |
| Q-std                          | 83.9786    |
| Q_loss                         | 85.124886  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 59         |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000109   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 31.4       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 57.2       |
| timestep                       | 1000       |
| timesteps_total                | 60000      |
| train-steps                    | 60000      |
| training/Q/q1_loss             | 102.216324 |
| training/sac_pi/alpha          | 0.1418501  |
| training/sac_pi/alpha_loss     | 0.14094171 |
| training/sac_pi/logp_pi        | 5.544094   |
| training/sac_pi/pi_entropy     | 3.605105   |
| training/sac_pi/pi_global_norm | 1.2697842  |
| training/sac_pi/policy_loss    | -172.75775 |
| training/sac_pi/std            | 0.55086464 |
| training/sac_pi/valid_num      | 4890.0     |
| training/sac_Q/q1              | 162.07251  |
| training/sac_Q/q2              | 159.45839  |
| training/sac_Q/q2_loss         | 102.38773  |
| training/sac_Q/q_global_norm   | 278.0931   |
--------------------------------------------------------------------------------
[WARN] 60 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.14022377 |
| epoch                          | 60         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4111.253   |
| evaluation/return-max          | 4170.072   |
| evaluation/return-min          | 4065.4133  |
| evaluation/return-std          | 35.268875  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.82       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 83.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45284      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4111.253   |
| perf/NormalizedReturn          | 0.895      |
| Q-avg                          | 165.05272  |
| Q-std                          | 83.71656   |
| Q_loss                         | 85.07379   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 60         |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000103   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000538   |
| times/evaluation_paths         | 32.1       |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 57.1       |
| timestep                       | 1000       |
| timesteps_total                | 61000      |
| train-steps                    | 61000      |
| training/Q/q1_loss             | 84.54486   |
| training/sac_pi/alpha          | 0.14022325 |
| training/sac_pi/alpha_loss     | 0.65174156 |
| training/sac_pi/logp_pi        | 4.5114465  |
| training/sac_pi/pi_entropy     | 3.5832672  |
| training/sac_pi/pi_global_norm | 1.3878958  |
| training/sac_pi/policy_loss    | -171.36719 |
| training/sac_pi/std            | 0.5113317  |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 166.02293  |
| training/sac_Q/q2              | 165.4654   |
| training/sac_Q/q2_loss         | 84.53929   |
| training/sac_Q/q_global_norm   | 286.5095   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1458837  |
| epoch                          | 61         |
| evaluation/episode-length-avg  | 136        |
| evaluation/episode-length-max  | 167        |
| evaluation/episode-length-min  | 132        |
| evaluation/episode-length-std  | 10.2       |
| evaluation/return-average      | 296.66632  |
| evaluation/return-max          | 401.88458  |
| evaluation/return-min          | 280.05     |
| evaluation/return-std          | 35.25951   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.6        |
| model/origin_ret               | 81.4       |
| model/penalty_ret              | 83.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45004      |
| perf/AverageLength             | 136        |
| perf/AverageReturn             | 296.66632  |
| perf/NormalizedReturn          | 0.0643     |
| Q-avg                          | 158.30869  |
| Q-std                          | 98.28739   |
| Q_loss                         | 91.76604   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 61         |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000324   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000491   |
| times/evaluation_paths         | 4.33       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00785    |
| times/train                    | 56.9       |
| timestep                       | 1000       |
| timesteps_total                | 62000      |
| train-steps                    | 62000      |
| training/Q/q1_loss             | 77.341484  |
| training/sac_pi/alpha          | 0.14589481 |
| training/sac_pi/alpha_loss     | 0.25156376 |
| training/sac_pi/logp_pi        | 5.0070066  |
| training/sac_pi/pi_entropy     | 3.7752633  |
| training/sac_pi/pi_global_norm | 1.4105693  |
| training/sac_pi/policy_loss    | -170.76633 |
| training/sac_pi/std            | 0.5521223  |
| training/sac_pi/valid_num      | 4916.0     |
| training/sac_Q/q1              | 163.01534  |
| training/sac_Q/q2              | 161.6614   |
| training/sac_Q/q2_loss         | 77.09443   |
| training/sac_Q/q_global_norm   | 191.62001  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.14485054   |
| epoch                          | 62           |
| evaluation/episode-length-avg  | 152          |
| evaluation/episode-length-max  | 154          |
| evaluation/episode-length-min  | 151          |
| evaluation/episode-length-std  | 0.748        |
| evaluation/return-average      | 396.9691     |
| evaluation/return-max          | 401.97144    |
| evaluation/return-min          | 391.50665    |
| evaluation/return-std          | 2.962264     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.88         |
| model/origin_ret               | 85.3         |
| model/penalty_ret              | 83           |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45167        |
| perf/AverageLength             | 152          |
| perf/AverageReturn             | 396.9691     |
| perf/NormalizedReturn          | 0.0861       |
| Q-avg                          | 165.68755    |
| Q-std                          | 79.1195      |
| Q_loss                         | 105.028145   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 62           |
| times/epoch_after_hook         | 1.86e-06     |
| times/epoch_before_hook        | 0.000105     |
| times/epoch_rollout_model      | 480          |
| times/evaluation_metrics       | 0.000485     |
| times/evaluation_paths         | 4.89         |
| times/timestep_after_hook      | 0.00371      |
| times/timestep_before_hook     | 0.00853      |
| times/train                    | 57.3         |
| timestep                       | 1000         |
| timesteps_total                | 63000        |
| train-steps                    | 63000        |
| training/Q/q1_loss             | 94.08812     |
| training/sac_pi/alpha          | 0.14483783   |
| training/sac_pi/alpha_loss     | -0.050001618 |
| training/sac_pi/logp_pi        | 4.666888     |
| training/sac_pi/pi_entropy     | 3.6447723    |
| training/sac_pi/pi_global_norm | 1.1095697    |
| training/sac_pi/policy_loss    | -173.5733    |
| training/sac_pi/std            | 0.5324892    |
| training/sac_pi/valid_num      | 4925.0       |
| training/sac_Q/q1              | 165.13795    |
| training/sac_Q/q2              | 164.72131    |
| training/sac_Q/q2_loss         | 94.43843     |
| training/sac_Q/q_global_norm   | 222.55145    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14805362  |
| epoch                          | 63          |
| evaluation/episode-length-avg  | 568         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 134         |
| evaluation/episode-length-std  | 433         |
| evaluation/return-average      | 2302.1567   |
| evaluation/return-max          | 4382.4727   |
| evaluation/return-min          | 325.4781    |
| evaluation/return-std          | 1972.6707   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.83        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 85.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 44964       |
| perf/AverageLength             | 568         |
| perf/AverageReturn             | 2302.1567   |
| perf/NormalizedReturn          | 0.501       |
| Q-avg                          | 146.73984   |
| Q-std                          | 101.34977   |
| Q_loss                         | 87.787575   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 63          |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000109    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000486    |
| times/evaluation_paths         | 17.8        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00793     |
| times/train                    | 57.3        |
| timestep                       | 1000        |
| timesteps_total                | 64000       |
| train-steps                    | 64000       |
| training/Q/q1_loss             | 87.91449    |
| training/sac_pi/alpha          | 0.14805676  |
| training/sac_pi/alpha_loss     | 0.030926164 |
| training/sac_pi/logp_pi        | 4.362334    |
| training/sac_pi/pi_entropy     | 3.6084828   |
| training/sac_pi/pi_global_norm | 1.6359322   |
| training/sac_pi/policy_loss    | -170.1432   |
| training/sac_pi/std            | 0.510146    |
| training/sac_pi/valid_num      | 5011.0      |
| training/sac_Q/q1              | 165.11406   |
| training/sac_Q/q2              | 164.70547   |
| training/sac_Q/q2_loss         | 87.974205   |
| training/sac_Q/q_global_norm   | 286.07498   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1445955   |
| epoch                          | 64          |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4848.878    |
| evaluation/return-max          | 5077.1216   |
| evaluation/return-min          | 4716.793    |
| evaluation/return-std          | 110.85975   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.76        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 83.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45228       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4848.878    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 161.28099   |
| Q-std                          | 85.00173    |
| Q_loss                         | 83.88725    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 64          |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000103    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.00054     |
| times/evaluation_paths         | 31.5        |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.00791     |
| times/train                    | 57.3        |
| timestep                       | 1000        |
| timesteps_total                | 65000       |
| train-steps                    | 65000       |
| training/Q/q1_loss             | 77.49926    |
| training/sac_pi/alpha          | 0.14460142  |
| training/sac_pi/alpha_loss     | -0.36442655 |
| training/sac_pi/logp_pi        | 4.9577265   |
| training/sac_pi/pi_entropy     | 3.88761     |
| training/sac_pi/pi_global_norm | 1.1689388   |
| training/sac_pi/policy_loss    | -172.82301  |
| training/sac_pi/std            | 0.5800428   |
| training/sac_pi/valid_num      | 4908.0      |
| training/sac_Q/q1              | 163.822     |
| training/sac_Q/q2              | 162.93184   |
| training/sac_Q/q2_loss         | 77.66183    |
| training/sac_Q/q_global_norm   | 270.63574   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14538357 |
| epoch                          | 65         |
| evaluation/episode-length-avg  | 286        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 203        |
| evaluation/episode-length-std  | 238        |
| evaluation/return-average      | 1120.1448  |
| evaluation/return-max          | 4803.2754  |
| evaluation/return-min          | 693.43567  |
| evaluation/return-std          | 1227.7557  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.78       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 83.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45094      |
| perf/AverageLength             | 286        |
| perf/AverageReturn             | 1120.1448  |
| perf/NormalizedReturn          | 0.244      |
| Q-avg                          | 164.47246  |
| Q-std                          | 82.08547   |
| Q_loss                         | 110.200714 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 65         |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.00028    |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000516   |
| times/evaluation_paths         | 9          |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.0079     |
| times/train                    | 57.3       |
| timestep                       | 1000       |
| timesteps_total                | 66000      |
| train-steps                    | 66000      |
| training/Q/q1_loss             | 100.76604  |
| training/sac_pi/alpha          | 0.14534432 |
| training/sac_pi/alpha_loss     | 0.29787752 |
| training/sac_pi/logp_pi        | 4.473689   |
| training/sac_pi/pi_entropy     | 3.9111352  |
| training/sac_pi/pi_global_norm | 1.3499483  |
| training/sac_pi/policy_loss    | -174.13568 |
| training/sac_pi/std            | 0.533641   |
| training/sac_pi/valid_num      | 4931.0     |
| training/sac_Q/q1              | 167.15178  |
| training/sac_Q/q2              | 166.61957  |
| training/sac_Q/q2_loss         | 100.55454  |
| training/sac_Q/q_global_norm   | 353.00375  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14376381  |
| epoch                          | 66          |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4090.7163   |
| evaluation/return-max          | 4148.052    |
| evaluation/return-min          | 4041.8997   |
| evaluation/return-std          | 31.72696    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.86        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 83.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45177       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4090.7163   |
| perf/NormalizedReturn          | 0.891       |
| Q-avg                          | 154.73494   |
| Q-std                          | 94.78179    |
| Q_loss                         | 81.00176    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 66          |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.00012     |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000595    |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 57.7        |
| timestep                       | 1000        |
| timesteps_total                | 67000       |
| train-steps                    | 67000       |
| training/Q/q1_loss             | 78.26102    |
| training/sac_pi/alpha          | 0.14381021  |
| training/sac_pi/alpha_loss     | -0.32725486 |
| training/sac_pi/logp_pi        | 4.715799    |
| training/sac_pi/pi_entropy     | 3.586783    |
| training/sac_pi/pi_global_norm | 1.5394135   |
| training/sac_pi/policy_loss    | -168.86562  |
| training/sac_pi/std            | 0.53229064  |
| training/sac_pi/valid_num      | 4935.0      |
| training/sac_Q/q1              | 161.58842   |
| training/sac_Q/q2              | 161.19841   |
| training/sac_Q/q2_loss         | 78.822014   |
| training/sac_Q/q_global_norm   | 260.814     |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14260662  |
| epoch                          | 67          |
| evaluation/episode-length-avg  | 130         |
| evaluation/episode-length-max  | 131         |
| evaluation/episode-length-min  | 129         |
| evaluation/episode-length-std  | 0.748       |
| evaluation/return-average      | 355.30362   |
| evaluation/return-max          | 365.11694   |
| evaluation/return-min          | 345.73462   |
| evaluation/return-std          | 5.6212378   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.71        |
| model/origin_ret               | 83.6        |
| model/penalty_ret              | 83.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45181       |
| perf/AverageLength             | 130         |
| perf/AverageReturn             | 355.30362   |
| perf/NormalizedReturn          | 0.077       |
| Q-avg                          | 162.40703   |
| Q-std                          | 83.44241    |
| Q_loss                         | 89.55223    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 67          |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000112    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000588    |
| times/evaluation_paths         | 4.17        |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 57.9        |
| timestep                       | 1000        |
| timesteps_total                | 68000       |
| train-steps                    | 68000       |
| training/Q/q1_loss             | 93.351265   |
| training/sac_pi/alpha          | 0.14262499  |
| training/sac_pi/alpha_loss     | -0.25668943 |
| training/sac_pi/logp_pi        | 4.778689    |
| training/sac_pi/pi_entropy     | 3.9118323   |
| training/sac_pi/pi_global_norm | 1.2939037   |
| training/sac_pi/policy_loss    | -173.19893  |
| training/sac_pi/std            | 0.5767295   |
| training/sac_pi/valid_num      | 4903.0      |
| training/sac_Q/q1              | 163.38899   |
| training/sac_Q/q2              | 162.30739   |
| training/sac_Q/q2_loss         | 94.300835   |
| training/sac_Q/q_global_norm   | 280.29892   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.144547   |
| epoch                          | 68         |
| evaluation/episode-length-avg  | 156        |
| evaluation/episode-length-max  | 182        |
| evaluation/episode-length-min  | 140        |
| evaluation/episode-length-std  | 10.1       |
| evaluation/return-average      | 298.4413   |
| evaluation/return-max          | 331.52454  |
| evaluation/return-min          | 271.0998   |
| evaluation/return-std          | 14.547172  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.69       |
| model/origin_ret               | 81.9       |
| model/penalty_ret              | 82.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45203      |
| perf/AverageLength             | 156        |
| perf/AverageReturn             | 298.4413   |
| perf/NormalizedReturn          | 0.0647     |
| Q-avg                          | 159.6652   |
| Q-std                          | 98.550064  |
| Q_loss                         | 92.26128   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 68         |
| times/epoch_after_hook         | 2.01e-06   |
| times/epoch_before_hook        | 8.86e-05   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000531   |
| times/evaluation_paths         | 4.96       |
| times/timestep_after_hook      | 0.00355    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 57.5       |
| timestep                       | 1000       |
| timesteps_total                | 69000      |
| train-steps                    | 69000      |
| training/Q/q1_loss             | 94.0884    |
| training/sac_pi/alpha          | 0.14455076 |
| training/sac_pi/alpha_loss     | 0.03494155 |
| training/sac_pi/logp_pi        | 4.027707   |
| training/sac_pi/pi_entropy     | 3.528777   |
| training/sac_pi/pi_global_norm | 1.0309117  |
| training/sac_pi/policy_loss    | -180.80246 |
| training/sac_pi/std            | 0.4879653  |
| training/sac_pi/valid_num      | 5032.0     |
| training/sac_Q/q1              | 177.138    |
| training/sac_Q/q2              | 176.98627  |
| training/sac_Q/q2_loss         | 94.428795  |
| training/sac_Q/q_global_norm   | 200.0921   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.13865672   |
| epoch                          | 69           |
| evaluation/episode-length-avg  | 119          |
| evaluation/episode-length-max  | 124          |
| evaluation/episode-length-min  | 113          |
| evaluation/episode-length-std  | 3.03         |
| evaluation/return-average      | 248.7299     |
| evaluation/return-max          | 265.17426    |
| evaluation/return-min          | 228.52684    |
| evaluation/return-std          | 10.115612    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.83         |
| model/origin_ret               | 85.4         |
| model/penalty_ret              | 83.8         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45048        |
| perf/AverageLength             | 119          |
| perf/AverageReturn             | 248.7299     |
| perf/NormalizedReturn          | 0.0538       |
| Q-avg                          | 162.35294    |
| Q-std                          | 90.054115    |
| Q_loss                         | 96.685814    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 69           |
| times/epoch_after_hook         | 1.86e-06     |
| times/epoch_before_hook        | 0.000327     |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.000504     |
| times/evaluation_paths         | 3.79         |
| times/timestep_after_hook      | 0.0036       |
| times/timestep_before_hook     | 0.0082       |
| times/train                    | 57.4         |
| timestep                       | 1000         |
| timesteps_total                | 70000        |
| train-steps                    | 70000        |
| training/Q/q1_loss             | 73.83457     |
| training/sac_pi/alpha          | 0.13865814   |
| training/sac_pi/alpha_loss     | -0.033047855 |
| training/sac_pi/logp_pi        | 4.4179583    |
| training/sac_pi/pi_entropy     | 3.7153504    |
| training/sac_pi/pi_global_norm | 1.4356381    |
| training/sac_pi/policy_loss    | -171.83481   |
| training/sac_pi/std            | 0.54133123   |
| training/sac_pi/valid_num      | 4936.0       |
| training/sac_Q/q1              | 164.45755    |
| training/sac_Q/q2              | 163.44568    |
| training/sac_Q/q2_loss         | 74.30532     |
| training/sac_Q/q_global_norm   | 189.30573    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14193533 |
| epoch                          | 70         |
| evaluation/episode-length-avg  | 745        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 146        |
| evaluation/episode-length-std  | 390        |
| evaluation/return-average      | 3677.2368  |
| evaluation/return-max          | 5154.1445  |
| evaluation/return-min          | 419.0949   |
| evaluation/return-std          | 2128.2212  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.76       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 83.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45085      |
| perf/AverageLength             | 745        |
| perf/AverageReturn             | 3677.2368  |
| perf/NormalizedReturn          | 0.801      |
| Q-avg                          | 164.36748  |
| Q-std                          | 93.558556  |
| Q_loss                         | 84.20616   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 70         |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000144   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000731   |
| times/evaluation_paths         | 23.5       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00796    |
| times/train                    | 57.1       |
| timestep                       | 1000       |
| timesteps_total                | 71000      |
| train-steps                    | 71000      |
| training/Q/q1_loss             | 91.664375  |
| training/sac_pi/alpha          | 0.14191982 |
| training/sac_pi/alpha_loss     | 0.40514106 |
| training/sac_pi/logp_pi        | 4.4308534  |
| training/sac_pi/pi_entropy     | 3.5848694  |
| training/sac_pi/pi_global_norm | 1.3636011  |
| training/sac_pi/policy_loss    | -173.16695 |
| training/sac_pi/std            | 0.5056874  |
| training/sac_pi/valid_num      | 5011.0     |
| training/sac_Q/q1              | 168.6729   |
| training/sac_Q/q2              | 167.64072  |
| training/sac_Q/q2_loss         | 91.556885  |
| training/sac_Q/q_global_norm   | 284.8252   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14206298  |
| epoch                          | 71          |
| evaluation/episode-length-avg  | 96.1        |
| evaluation/episode-length-max  | 97          |
| evaluation/episode-length-min  | 95          |
| evaluation/episode-length-std  | 0.7         |
| evaluation/return-average      | 190.83432   |
| evaluation/return-max          | 194.62283   |
| evaluation/return-min          | 187.08656   |
| evaluation/return-std          | 2.4380825   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.84        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 83          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45258       |
| perf/AverageLength             | 96.1        |
| perf/AverageReturn             | 190.83432   |
| perf/NormalizedReturn          | 0.0412      |
| Q-avg                          | 166.12396   |
| Q-std                          | 98.12026    |
| Q_loss                         | 91.1017     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 71          |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000441    |
| times/evaluation_paths         | 3.02        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 57.4        |
| timestep                       | 1000        |
| timesteps_total                | 72000       |
| train-steps                    | 72000       |
| training/Q/q1_loss             | 102.022385  |
| training/sac_pi/alpha          | 0.14207698  |
| training/sac_pi/alpha_loss     | -0.35150996 |
| training/sac_pi/logp_pi        | 4.462877    |
| training/sac_pi/pi_entropy     | 3.560162    |
| training/sac_pi/pi_global_norm | 1.3406897   |
| training/sac_pi/policy_loss    | -181.95253  |
| training/sac_pi/std            | 0.5255751   |
| training/sac_pi/valid_num      | 4905.0      |
| training/sac_Q/q1              | 172.606     |
| training/sac_Q/q2              | 172.41705   |
| training/sac_Q/q2_loss         | 101.447044  |
| training/sac_Q/q_global_norm   | 248.7669    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14195469  |
| epoch                          | 72          |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4708.5034   |
| evaluation/return-max          | 4805.37     |
| evaluation/return-min          | 4600.7256   |
| evaluation/return-std          | 76.50591    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.83        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 84.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45278       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4708.5034   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 165.38322   |
| Q-std                          | 84.3669     |
| Q_loss                         | 103.78341   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 72          |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 6.53e-05    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000611    |
| times/evaluation_paths         | 31.5        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00809     |
| times/train                    | 57.7        |
| timestep                       | 1000        |
| timesteps_total                | 73000       |
| train-steps                    | 73000       |
| training/Q/q1_loss             | 95.53984    |
| training/sac_pi/alpha          | 0.14196818  |
| training/sac_pi/alpha_loss     | 0.041250963 |
| training/sac_pi/logp_pi        | 5.129252    |
| training/sac_pi/pi_entropy     | 3.7012882   |
| training/sac_pi/pi_global_norm | 1.1831253   |
| training/sac_pi/policy_loss    | -175.98895  |
| training/sac_pi/std            | 0.5385139   |
| training/sac_pi/valid_num      | 4930.0      |
| training/sac_Q/q1              | 166.59831   |
| training/sac_Q/q2              | 166.79663   |
| training/sac_Q/q2_loss         | 95.64922    |
| training/sac_Q/q_global_norm   | 261.54996   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13917062 |
| epoch                          | 73         |
| evaluation/episode-length-avg  | 852        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 265        |
| evaluation/episode-length-std  | 245        |
| evaluation/return-average      | 3672.1235  |
| evaluation/return-max          | 4474.132   |
| evaluation/return-min          | 858.0591   |
| evaluation/return-std          | 1196.2009  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.77       |
| model/origin_ret               | 83.1       |
| model/penalty_ret              | 82.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45369      |
| perf/AverageLength             | 852        |
| perf/AverageReturn             | 3672.1235  |
| perf/NormalizedReturn          | 0.8        |
| Q-avg                          | 179.73792  |
| Q-std                          | 82.18409   |
| Q_loss                         | 73.637085  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 73         |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000356   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000597   |
| times/evaluation_paths         | 26.9       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00789    |
| times/train                    | 57.1       |
| timestep                       | 1000       |
| timesteps_total                | 74000      |
| train-steps                    | 74000      |
| training/Q/q1_loss             | 89.95996   |
| training/sac_pi/alpha          | 0.13918024 |
| training/sac_pi/alpha_loss     | 0.1787277  |
| training/sac_pi/logp_pi        | 5.241658   |
| training/sac_pi/pi_entropy     | 3.558928   |
| training/sac_pi/pi_global_norm | 1.3344153  |
| training/sac_pi/policy_loss    | -179.72882 |
| training/sac_pi/std            | 0.5385047  |
| training/sac_pi/valid_num      | 4939.0     |
| training/sac_Q/q1              | 171.50363  |
| training/sac_Q/q2              | 171.22623  |
| training/sac_Q/q2_loss         | 89.26897   |
| training/sac_Q/q_global_norm   | 240.95604  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14975926  |
| epoch                          | 74          |
| evaluation/episode-length-avg  | 778         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 245         |
| evaluation/episode-length-std  | 304         |
| evaluation/return-average      | 3635.463    |
| evaluation/return-max          | 4966.083    |
| evaluation/return-min          | 950.39795   |
| evaluation/return-std          | 1582.3555   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.7         |
| model/origin_ret               | 81.2        |
| model/penalty_ret              | 82.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45346       |
| perf/AverageLength             | 778         |
| perf/AverageReturn             | 3635.463    |
| perf/NormalizedReturn          | 0.792       |
| Q-avg                          | 166.01959   |
| Q-std                          | 93.09892    |
| Q_loss                         | 93.42046    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 74          |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000107    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000578    |
| times/evaluation_paths         | 24.5        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 57.3        |
| timestep                       | 1000        |
| timesteps_total                | 75000       |
| train-steps                    | 75000       |
| training/Q/q1_loss             | 85.47715    |
| training/sac_pi/alpha          | 0.1497866   |
| training/sac_pi/alpha_loss     | -0.20574155 |
| training/sac_pi/logp_pi        | 4.3663664   |
| training/sac_pi/pi_entropy     | 3.635301    |
| training/sac_pi/pi_global_norm | 1.1623329   |
| training/sac_pi/policy_loss    | -178.24844  |
| training/sac_pi/std            | 0.51658136  |
| training/sac_pi/valid_num      | 4976.0      |
| training/sac_Q/q1              | 171.66028   |
| training/sac_Q/q2              | 171.45195   |
| training/sac_Q/q2_loss         | 85.29735    |
| training/sac_Q/q_global_norm   | 232.43703   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15154782  |
| epoch                          | 75          |
| evaluation/episode-length-avg  | 742         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 136         |
| evaluation/episode-length-std  | 395         |
| evaluation/return-average      | 3300.855    |
| evaluation/return-max          | 4587.1484   |
| evaluation/return-min          | 379.75403   |
| evaluation/return-std          | 1905.8507   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.64        |
| model/origin_ret               | 82.3        |
| model/penalty_ret              | 84.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 44931       |
| perf/AverageLength             | 742         |
| perf/AverageReturn             | 3300.855    |
| perf/NormalizedReturn          | 0.719       |
| Q-avg                          | 168.65556   |
| Q-std                          | 91.33066    |
| Q_loss                         | 92.07975    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 75          |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000107    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000554    |
| times/evaluation_paths         | 23.7        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 57.8        |
| timestep                       | 1000        |
| timesteps_total                | 76000       |
| train-steps                    | 76000       |
| training/Q/q1_loss             | 73.368454   |
| training/sac_pi/alpha          | 0.15156597  |
| training/sac_pi/alpha_loss     | -0.20958947 |
| training/sac_pi/logp_pi        | 4.553545    |
| training/sac_pi/pi_entropy     | 3.914415    |
| training/sac_pi/pi_global_norm | 1.0451267   |
| training/sac_pi/policy_loss    | -168.0476   |
| training/sac_pi/std            | 0.55494684  |
| training/sac_pi/valid_num      | 4939.0      |
| training/sac_Q/q1              | 159.9783    |
| training/sac_Q/q2              | 160.04422   |
| training/sac_Q/q2_loss         | 73.89504    |
| training/sac_Q/q_global_norm   | 195.69815   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14916566  |
| epoch                          | 76          |
| evaluation/episode-length-avg  | 406         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 146         |
| evaluation/episode-length-std  | 389         |
| evaluation/return-average      | 1784.408    |
| evaluation/return-max          | 4956.282    |
| evaluation/return-min          | 431.4088    |
| evaluation/return-std          | 2031.2091   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.8         |
| model/origin_ret               | 84          |
| model/penalty_ret              | 82.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45024       |
| perf/AverageLength             | 406         |
| perf/AverageReturn             | 1784.408    |
| perf/NormalizedReturn          | 0.388       |
| Q-avg                          | 169.49397   |
| Q-std                          | 92.85335    |
| Q_loss                         | 99.421455   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 76          |
| times/epoch_after_hook         | 2.18e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000544    |
| times/evaluation_paths         | 12.8        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00802     |
| times/train                    | 57.3        |
| timestep                       | 1000        |
| timesteps_total                | 77000       |
| train-steps                    | 77000       |
| training/Q/q1_loss             | 120.91786   |
| training/sac_pi/alpha          | 0.149185    |
| training/sac_pi/alpha_loss     | -0.19872414 |
| training/sac_pi/logp_pi        | 4.007672    |
| training/sac_pi/pi_entropy     | 3.775393    |
| training/sac_pi/pi_global_norm | 1.528254    |
| training/sac_pi/policy_loss    | -176.09062  |
| training/sac_pi/std            | 0.5169284   |
| training/sac_pi/valid_num      | 4978.0      |
| training/sac_Q/q1              | 171.01318   |
| training/sac_Q/q2              | 171.21611   |
| training/sac_Q/q2_loss         | 120.787575  |
| training/sac_Q/q_global_norm   | 374.05087   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14894336 |
| epoch                          | 77         |
| evaluation/episode-length-avg  | 566        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 159        |
| evaluation/episode-length-std  | 374        |
| evaluation/return-average      | 2365.2566  |
| evaluation/return-max          | 4564.246   |
| evaluation/return-min          | 408.08038  |
| evaluation/return-std          | 1845.5443  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.86       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 83.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45157      |
| perf/AverageLength             | 566        |
| perf/AverageReturn             | 2365.2566  |
| perf/NormalizedReturn          | 0.515      |
| Q-avg                          | 164.66295  |
| Q-std                          | 94.66827   |
| Q_loss                         | 86.016235  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 77         |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000262   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 17.2       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00796    |
| times/train                    | 56.2       |
| timestep                       | 1000       |
| timesteps_total                | 78000      |
| train-steps                    | 78000      |
| training/Q/q1_loss             | 108.76455  |
| training/sac_pi/alpha          | 0.14891791 |
| training/sac_pi/alpha_loss     | 0.48147497 |
| training/sac_pi/logp_pi        | 4.7561407  |
| training/sac_pi/pi_entropy     | 3.8465526  |
| training/sac_pi/pi_global_norm | 1.2285281  |
| training/sac_pi/policy_loss    | -167.80229 |
| training/sac_pi/std            | 0.54311866 |
| training/sac_pi/valid_num      | 4939.0     |
| training/sac_Q/q1              | 159.04355  |
| training/sac_Q/q2              | 158.52994  |
| training/sac_Q/q2_loss         | 108.36661  |
| training/sac_Q/q_global_norm   | 212.58455  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15108629 |
| epoch                          | 78         |
| evaluation/episode-length-avg  | 762        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 347        |
| evaluation/episode-length-std  | 259        |
| evaluation/return-average      | 3367.2349  |
| evaluation/return-max          | 4614.724   |
| evaluation/return-min          | 1330.1364  |
| evaluation/return-std          | 1279.5663  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.77       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 85.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44657      |
| perf/AverageLength             | 762        |
| perf/AverageReturn             | 3367.2349  |
| perf/NormalizedReturn          | 0.733      |
| Q-avg                          | 158.1586   |
| Q-std                          | 92.287834  |
| Q_loss                         | 106.44346  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 78         |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.00011    |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000548   |
| times/evaluation_paths         | 24.6       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 57         |
| timestep                       | 1000       |
| timesteps_total                | 79000      |
| train-steps                    | 79000      |
| training/Q/q1_loss             | 90.56743   |
| training/sac_pi/alpha          | 0.15107869 |
| training/sac_pi/alpha_loss     | 0.24949522 |
| training/sac_pi/logp_pi        | 4.3605337  |
| training/sac_pi/pi_entropy     | 3.8286762  |
| training/sac_pi/pi_global_norm | 1.0555383  |
| training/sac_pi/policy_loss    | -179.43916 |
| training/sac_pi/std            | 0.5263176  |
| training/sac_pi/valid_num      | 4945.0     |
| training/sac_Q/q1              | 172.5308   |
| training/sac_Q/q2              | 172.63928  |
| training/sac_Q/q2_loss         | 90.97796   |
| training/sac_Q/q_global_norm   | 276.23514  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15276888   |
| epoch                          | 79           |
| evaluation/episode-length-avg  | 498          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 161          |
| evaluation/episode-length-std  | 410          |
| evaluation/return-average      | 1973.9119    |
| evaluation/return-max          | 4487.013     |
| evaluation/return-min          | 376.0005     |
| evaluation/return-std          | 1945.2173    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.81         |
| model/origin_ret               | 83.7         |
| model/penalty_ret              | 83.2         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45258        |
| perf/AverageLength             | 498          |
| perf/AverageReturn             | 1973.9119    |
| perf/NormalizedReturn          | 0.43         |
| Q-avg                          | 160.41548    |
| Q-std                          | 101.314476   |
| Q_loss                         | 102.859375   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 79           |
| times/epoch_after_hook         | 1.82e-06     |
| times/epoch_before_hook        | 0.000105     |
| times/epoch_rollout_model      | 486          |
| times/evaluation_metrics       | 0.000571     |
| times/evaluation_paths         | 15.9         |
| times/timestep_after_hook      | 0.0035       |
| times/timestep_before_hook     | 0.00802      |
| times/train                    | 57.3         |
| timestep                       | 1000         |
| timesteps_total                | 80000        |
| train-steps                    | 80000        |
| training/Q/q1_loss             | 91.3642      |
| training/sac_pi/alpha          | 0.15278813   |
| training/sac_pi/alpha_loss     | -0.027699605 |
| training/sac_pi/logp_pi        | 5.1753697    |
| training/sac_pi/pi_entropy     | 3.9642434    |
| training/sac_pi/pi_global_norm | 1.3400054    |
| training/sac_pi/policy_loss    | -175.43773   |
| training/sac_pi/std            | 0.5970117    |
| training/sac_pi/valid_num      | 4865.0       |
| training/sac_Q/q1              | 164.14961    |
| training/sac_Q/q2              | 164.37662    |
| training/sac_Q/q2_loss         | 91.23891     |
| training/sac_Q/q_global_norm   | 213.70055    |
----------------------------------------------------------------------------------
[WARN] 80 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.1502577   |
| epoch                          | 80          |
| evaluation/episode-length-avg  | 916         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 161         |
| evaluation/episode-length-std  | 252         |
| evaluation/return-average      | 4413.897    |
| evaluation/return-max          | 4908.816    |
| evaluation/return-min          | 466.0093    |
| evaluation/return-std          | 1316.2672   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.81        |
| model/origin_ret               | 83          |
| model/penalty_ret              | 83.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45362       |
| perf/AverageLength             | 916         |
| perf/AverageReturn             | 4413.897    |
| perf/NormalizedReturn          | 0.961       |
| Q-avg                          | 163.34058   |
| Q-std                          | 98.915695   |
| Q_loss                         | 98.95854    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 80          |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000107    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000558    |
| times/evaluation_paths         | 29.4        |
| times/timestep_after_hook      | 0.00376     |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 58.2        |
| timestep                       | 1000        |
| timesteps_total                | 81000       |
| train-steps                    | 81000       |
| training/Q/q1_loss             | 86.2887     |
| training/sac_pi/alpha          | 0.15023868  |
| training/sac_pi/alpha_loss     | 0.021988245 |
| training/sac_pi/logp_pi        | 4.4151106   |
| training/sac_pi/pi_entropy     | 3.9040306   |
| training/sac_pi/pi_global_norm | 1.141793    |
| training/sac_pi/policy_loss    | -177.54869  |
| training/sac_pi/std            | 0.5409068   |
| training/sac_pi/valid_num      | 4942.0      |
| training/sac_Q/q1              | 169.50557   |
| training/sac_Q/q2              | 169.63647   |
| training/sac_Q/q2_loss         | 86.523476   |
| training/sac_Q/q_global_norm   | 313.17514   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14734125 |
| epoch                          | 81         |
| evaluation/episode-length-avg  | 919        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 186        |
| evaluation/episode-length-std  | 244        |
| evaluation/return-average      | 4489.248   |
| evaluation/return-max          | 4980.1514  |
| evaluation/return-min          | 582.8968   |
| evaluation/return-std          | 1302.8179  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.86       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 83         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45149      |
| perf/AverageLength             | 919        |
| perf/AverageReturn             | 4489.248   |
| perf/NormalizedReturn          | 0.978      |
| Q-avg                          | 164.00797  |
| Q-std                          | 106.40537  |
| Q_loss                         | 101.328926 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 81         |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000276   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000563   |
| times/evaluation_paths         | 29.1       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00796    |
| times/train                    | 57.2       |
| timestep                       | 1000       |
| timesteps_total                | 82000      |
| train-steps                    | 82000      |
| training/Q/q1_loss             | 87.33561   |
| training/sac_pi/alpha          | 0.14736813 |
| training/sac_pi/alpha_loss     | -0.296483  |
| training/sac_pi/logp_pi        | 4.1755743  |
| training/sac_pi/pi_entropy     | 3.5973015  |
| training/sac_pi/pi_global_norm | 1.0259777  |
| training/sac_pi/policy_loss    | -189.42139 |
| training/sac_pi/std            | 0.5089632  |
| training/sac_pi/valid_num      | 4979.0     |
| training/sac_Q/q1              | 182.72441  |
| training/sac_Q/q2              | 183.21251  |
| training/sac_Q/q2_loss         | 87.03659   |
| training/sac_Q/q_global_norm   | 242.41884  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14669852  |
| epoch                          | 82          |
| evaluation/episode-length-avg  | 710         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 152         |
| evaluation/episode-length-std  | 361         |
| evaluation/return-average      | 3066.0903   |
| evaluation/return-max          | 4572.1704   |
| evaluation/return-min          | 400.6219    |
| evaluation/return-std          | 1785.5944   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.85        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 83.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45337       |
| perf/AverageLength             | 710         |
| perf/AverageReturn             | 3066.0903   |
| perf/NormalizedReturn          | 0.668       |
| Q-avg                          | 166.1206    |
| Q-std                          | 97.75114    |
| Q_loss                         | 82.90194    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 82          |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000103    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.00049     |
| times/evaluation_paths         | 22.4        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 57.2        |
| timestep                       | 1000        |
| timesteps_total                | 83000       |
| train-steps                    | 83000       |
| training/Q/q1_loss             | 83.19698    |
| training/sac_pi/alpha          | 0.14671719  |
| training/sac_pi/alpha_loss     | -0.30752057 |
| training/sac_pi/logp_pi        | 5.113233    |
| training/sac_pi/pi_entropy     | 3.681647    |
| training/sac_pi/pi_global_norm | 1.2877849   |
| training/sac_pi/policy_loss    | -178.13553  |
| training/sac_pi/std            | 0.56910634  |
| training/sac_pi/valid_num      | 4888.0      |
| training/sac_Q/q1              | 165.66797   |
| training/sac_Q/q2              | 165.59666   |
| training/sac_Q/q2_loss         | 83.33389    |
| training/sac_Q/q_global_norm   | 336.48367   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15192805  |
| epoch                          | 83          |
| evaluation/episode-length-avg  | 109         |
| evaluation/episode-length-max  | 110         |
| evaluation/episode-length-min  | 107         |
| evaluation/episode-length-std  | 0.872       |
| evaluation/return-average      | 201.97488   |
| evaluation/return-max          | 207.21297   |
| evaluation/return-min          | 197.41942   |
| evaluation/return-std          | 2.9692774   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.74        |
| model/origin_ret               | 82.5        |
| model/penalty_ret              | 83.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45214       |
| perf/AverageLength             | 109         |
| perf/AverageReturn             | 201.97488   |
| perf/NormalizedReturn          | 0.0436      |
| Q-avg                          | 163.44548   |
| Q-std                          | 104.21555   |
| Q_loss                         | 102.69228   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 83          |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000114    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000469    |
| times/evaluation_paths         | 3.46        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00805     |
| times/train                    | 57.1        |
| timestep                       | 1000        |
| timesteps_total                | 84000       |
| train-steps                    | 84000       |
| training/Q/q1_loss             | 107.25009   |
| training/sac_pi/alpha          | 0.15191507  |
| training/sac_pi/alpha_loss     | -0.06555408 |
| training/sac_pi/logp_pi        | 5.180071    |
| training/sac_pi/pi_entropy     | 3.896689    |
| training/sac_pi/pi_global_norm | 1.1456939   |
| training/sac_pi/policy_loss    | -175.05748  |
| training/sac_pi/std            | 0.5724331   |
| training/sac_pi/valid_num      | 4915.0      |
| training/sac_Q/q1              | 165.67522   |
| training/sac_Q/q2              | 165.88284   |
| training/sac_Q/q2_loss         | 107.81039   |
| training/sac_Q/q_global_norm   | 246.43958   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14563996  |
| epoch                          | 84          |
| evaluation/episode-length-avg  | 781         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 155         |
| evaluation/episode-length-std  | 298         |
| evaluation/return-average      | 3376.982    |
| evaluation/return-max          | 4536.86     |
| evaluation/return-min          | 396.20367   |
| evaluation/return-std          | 1415.1361   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.87        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 84          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45085       |
| perf/AverageLength             | 781         |
| perf/AverageReturn             | 3376.982    |
| perf/NormalizedReturn          | 0.735       |
| Q-avg                          | 165.51974   |
| Q-std                          | 92.65065    |
| Q_loss                         | 90.19068    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 84          |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000102    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000526    |
| times/evaluation_paths         | 24.7        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 57.7        |
| timestep                       | 1000        |
| timesteps_total                | 85000       |
| train-steps                    | 85000       |
| training/Q/q1_loss             | 80.27694    |
| training/sac_pi/alpha          | 0.14566997  |
| training/sac_pi/alpha_loss     | -0.28751335 |
| training/sac_pi/logp_pi        | 4.7839546   |
| training/sac_pi/pi_entropy     | 3.5140738   |
| training/sac_pi/pi_global_norm | 1.6427696   |
| training/sac_pi/policy_loss    | -181.6339   |
| training/sac_pi/std            | 0.5224303   |
| training/sac_pi/valid_num      | 4905.0      |
| training/sac_Q/q1              | 171.03064   |
| training/sac_Q/q2              | 171.00867   |
| training/sac_Q/q2_loss         | 80.3568     |
| training/sac_Q/q_global_norm   | 279.40417   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15145051  |
| epoch                          | 85          |
| evaluation/episode-length-avg  | 651         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 174         |
| evaluation/episode-length-std  | 325         |
| evaluation/return-average      | 3000.855    |
| evaluation/return-max          | 4951.8145   |
| evaluation/return-min          | 503.01938   |
| evaluation/return-std          | 1744.7424   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.67        |
| model/origin_ret               | 81.7        |
| model/penalty_ret              | 83.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45155       |
| perf/AverageLength             | 651         |
| perf/AverageReturn             | 3000.855    |
| perf/NormalizedReturn          | 0.653       |
| Q-avg                          | 167.77156   |
| Q-std                          | 107.04521   |
| Q_loss                         | 84.437935   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 85          |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000348    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 20.8        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.0106      |
| times/train                    | 57.3        |
| timestep                       | 1000        |
| timesteps_total                | 86000       |
| train-steps                    | 86000       |
| training/Q/q1_loss             | 97.85813    |
| training/sac_pi/alpha          | 0.15147442  |
| training/sac_pi/alpha_loss     | -0.26063544 |
| training/sac_pi/logp_pi        | 4.395246    |
| training/sac_pi/pi_entropy     | 3.926616    |
| training/sac_pi/pi_global_norm | 1.2021962   |
| training/sac_pi/policy_loss    | -161.93123  |
| training/sac_pi/std            | 0.55451715  |
| training/sac_pi/valid_num      | 4890.0      |
| training/sac_Q/q1              | 151.7081    |
| training/sac_Q/q2              | 152.0096    |
| training/sac_Q/q2_loss         | 99.29087    |
| training/sac_Q/q_global_norm   | 327.93814   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15182571  |
| epoch                          | 86          |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4592.161    |
| evaluation/return-max          | 4657.8203   |
| evaluation/return-min          | 4398.165    |
| evaluation/return-std          | 86.26218    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.8         |
| model/origin_ret               | 82.9        |
| model/penalty_ret              | 82.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45448       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4592.161    |
| perf/NormalizedReturn          | 1           |
| Q-avg                          | 173.14226   |
| Q-std                          | 89.827774   |
| Q_loss                         | 80.42728    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 86          |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000112    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000537    |
| times/evaluation_paths         | 31.3        |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.0081      |
| times/train                    | 57.4        |
| timestep                       | 1000        |
| timesteps_total                | 87000       |
| train-steps                    | 87000       |
| training/Q/q1_loss             | 82.97146    |
| training/sac_pi/alpha          | 0.15183416  |
| training/sac_pi/alpha_loss     | -0.30099672 |
| training/sac_pi/logp_pi        | 4.89366     |
| training/sac_pi/pi_entropy     | 3.8501358   |
| training/sac_pi/pi_global_norm | 1.6222597   |
| training/sac_pi/policy_loss    | -178.633    |
| training/sac_pi/std            | 0.5675754   |
| training/sac_pi/valid_num      | 4940.0      |
| training/sac_Q/q1              | 170.17087   |
| training/sac_Q/q2              | 170.44217   |
| training/sac_Q/q2_loss         | 82.71863    |
| training/sac_Q/q_global_norm   | 208.64645   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15308234 |
| epoch                          | 87         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4690.186   |
| evaluation/return-max          | 4819.253   |
| evaluation/return-min          | 4556.0293  |
| evaluation/return-std          | 64.72146   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.79       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 84.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45303      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4690.186   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 155.06442  |
| Q-std                          | 105.55237  |
| Q_loss                         | 114.10785  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 87         |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000105   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000609   |
| times/evaluation_paths         | 30.1       |
| times/timestep_after_hook      | 0.00344    |
| times/timestep_before_hook     | 0.00783    |
| times/train                    | 55.1       |
| timestep                       | 1000       |
| timesteps_total                | 88000      |
| train-steps                    | 88000      |
| training/Q/q1_loss             | 97.13182   |
| training/sac_pi/alpha          | 0.15307543 |
| training/sac_pi/alpha_loss     | 0.47406098 |
| training/sac_pi/logp_pi        | 5.7872667  |
| training/sac_pi/pi_entropy     | 3.892303   |
| training/sac_pi/pi_global_norm | 1.2142055  |
| training/sac_pi/policy_loss    | -172.71498 |
| training/sac_pi/std            | 0.57974994 |
| training/sac_pi/valid_num      | 4903.0     |
| training/sac_Q/q1              | 159.34984  |
| training/sac_Q/q2              | 159.17386  |
| training/sac_Q/q2_loss         | 96.28166   |
| training/sac_Q/q_global_norm   | 270.45602  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14648466 |
| epoch                          | 88         |
| evaluation/episode-length-avg  | 920        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 205        |
| evaluation/episode-length-std  | 238        |
| evaluation/return-average      | 3925.7427  |
| evaluation/return-max          | 4321.0684  |
| evaluation/return-min          | 658.07434  |
| evaluation/return-std          | 1089.3793  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.84       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 82.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45104      |
| perf/AverageLength             | 920        |
| perf/AverageReturn             | 3925.7427  |
| perf/NormalizedReturn          | 0.855      |
| Q-avg                          | 167.13686  |
| Q-std                          | 91.21533   |
| Q_loss                         | 88.8363    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 88         |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000108   |
| times/epoch_rollout_model      | 471        |
| times/evaluation_metrics       | 0.000525   |
| times/evaluation_paths         | 27.8       |
| times/timestep_after_hook      | 0.00351    |
| times/timestep_before_hook     | 0.00776    |
| times/train                    | 55.2       |
| timestep                       | 1000       |
| timesteps_total                | 89000      |
| train-steps                    | 89000      |
| training/Q/q1_loss             | 95.35173   |
| training/sac_pi/alpha          | 0.14646381 |
| training/sac_pi/alpha_loss     | 0.03302483 |
| training/sac_pi/logp_pi        | 4.599803   |
| training/sac_pi/pi_entropy     | 3.8001008  |
| training/sac_pi/pi_global_norm | 1.1045147  |
| training/sac_pi/policy_loss    | -177.12303 |
| training/sac_pi/std            | 0.5531138  |
| training/sac_pi/valid_num      | 4904.0     |
| training/sac_Q/q1              | 167.05916  |
| training/sac_Q/q2              | 166.61392  |
| training/sac_Q/q2_loss         | 94.6121    |
| training/sac_Q/q_global_norm   | 192.27507  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14619806 |
| epoch                          | 89         |
| evaluation/episode-length-avg  | 162        |
| evaluation/episode-length-max  | 167        |
| evaluation/episode-length-min  | 156        |
| evaluation/episode-length-std  | 3.63       |
| evaluation/return-average      | 469.37323  |
| evaluation/return-max          | 501.19287  |
| evaluation/return-min          | 437.04272  |
| evaluation/return-std          | 22.805367  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.82       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 83.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45242      |
| perf/AverageLength             | 162        |
| perf/AverageReturn             | 469.37323  |
| perf/NormalizedReturn          | 0.102      |
| Q-avg                          | 166.05847  |
| Q-std                          | 96.57786   |
| Q_loss                         | 122.49361  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 89         |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000355   |
| times/epoch_rollout_model      | 471        |
| times/evaluation_metrics       | 0.000483   |
| times/evaluation_paths         | 5          |
| times/timestep_after_hook      | 0.00351    |
| times/timestep_before_hook     | 0.01       |
| times/train                    | 55.2       |
| timestep                       | 1000       |
| timesteps_total                | 90000      |
| train-steps                    | 90000      |
| training/Q/q1_loss             | 69.09698   |
| training/sac_pi/alpha          | 0.14623016 |
| training/sac_pi/alpha_loss     | -0.6602599 |
| training/sac_pi/logp_pi        | 4.34117    |
| training/sac_pi/pi_entropy     | 3.753119   |
| training/sac_pi/pi_global_norm | 1.2608441  |
| training/sac_pi/policy_loss    | -187.5659  |
| training/sac_pi/std            | 0.5501282  |
| training/sac_pi/valid_num      | 4951.0     |
| training/sac_Q/q1              | 180.03786  |
| training/sac_Q/q2              | 180.1705   |
| training/sac_Q/q2_loss         | 68.496704  |
| training/sac_Q/q_global_norm   | 222.55702  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.14627607   |
| epoch                          | 90           |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4420.9375    |
| evaluation/return-max          | 4640.0015    |
| evaluation/return-min          | 4275.9243    |
| evaluation/return-std          | 99.51788     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.83         |
| model/origin_ret               | 84.9         |
| model/penalty_ret              | 84.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45264        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4420.9375    |
| perf/NormalizedReturn          | 0.963        |
| Q-avg                          | 170.09927    |
| Q-std                          | 92.387634    |
| Q_loss                         | 79.54224     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 90           |
| times/epoch_after_hook         | 2.12e-06     |
| times/epoch_before_hook        | 0.000108     |
| times/epoch_rollout_model      | 470          |
| times/evaluation_metrics       | 0.000532     |
| times/evaluation_paths         | 30.2         |
| times/timestep_after_hook      | 0.0036       |
| times/timestep_before_hook     | 0.00781      |
| times/train                    | 55.6         |
| timestep                       | 1000         |
| timesteps_total                | 91000        |
| train-steps                    | 91000        |
| training/Q/q1_loss             | 92.679825    |
| training/sac_pi/alpha          | 0.14626405   |
| training/sac_pi/alpha_loss     | -0.069978684 |
| training/sac_pi/logp_pi        | 5.346944     |
| training/sac_pi/pi_entropy     | 3.633168     |
| training/sac_pi/pi_global_norm | 1.3366421    |
| training/sac_pi/policy_loss    | -173.15369   |
| training/sac_pi/std            | 0.54761237   |
| training/sac_pi/valid_num      | 4876.0       |
| training/sac_Q/q1              | 161.4548     |
| training/sac_Q/q2              | 159.95041    |
| training/sac_Q/q2_loss         | 92.81891     |
| training/sac_Q/q_global_norm   | 257.82394    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.144105    |
| epoch                          | 91          |
| evaluation/episode-length-avg  | 541         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 123         |
| evaluation/episode-length-std  | 418         |
| evaluation/return-average      | 2610.8108   |
| evaluation/return-max          | 5217.455    |
| evaluation/return-min          | 291.2028    |
| evaluation/return-std          | 2336.842    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.81        |
| model/origin_ret               | 83.5        |
| model/penalty_ret              | 82.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45537       |
| perf/AverageLength             | 541         |
| perf/AverageReturn             | 2610.8108   |
| perf/NormalizedReturn          | 0.568       |
| Q-avg                          | 171.6246    |
| Q-std                          | 84.82348    |
| Q_loss                         | 88.98288    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 91          |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000103    |
| times/epoch_rollout_model      | 475         |
| times/evaluation_metrics       | 0.000521    |
| times/evaluation_paths         | 16.4        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 56.1        |
| timestep                       | 1000        |
| timesteps_total                | 92000       |
| train-steps                    | 92000       |
| training/Q/q1_loss             | 101.303505  |
| training/sac_pi/alpha          | 0.14405847  |
| training/sac_pi/alpha_loss     | -0.04063251 |
| training/sac_pi/logp_pi        | 4.21329     |
| training/sac_pi/pi_entropy     | 3.688528    |
| training/sac_pi/pi_global_norm | 1.2087066   |
| training/sac_pi/policy_loss    | -176.47163  |
| training/sac_pi/std            | 0.5267153   |
| training/sac_pi/valid_num      | 4983.0      |
| training/sac_Q/q1              | 169.94197   |
| training/sac_Q/q2              | 170.22202   |
| training/sac_Q/q2_loss         | 100.23571   |
| training/sac_Q/q_global_norm   | 276.2168    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14507605 |
| epoch                          | 92         |
| evaluation/episode-length-avg  | 337        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 167        |
| evaluation/episode-length-std  | 331        |
| evaluation/return-average      | 1443.6338  |
| evaluation/return-max          | 5413.9746  |
| evaluation/return-min          | 425.13458  |
| evaluation/return-std          | 1979.4766  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.87       |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45492      |
| perf/AverageLength             | 337        |
| perf/AverageReturn             | 1443.6338  |
| perf/NormalizedReturn          | 0.314      |
| Q-avg                          | 170.62491  |
| Q-std                          | 97.590675  |
| Q_loss                         | 106.96356  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 92         |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 474        |
| times/evaluation_metrics       | 0.000488   |
| times/evaluation_paths         | 10.4       |
| times/timestep_after_hook      | 0.00354    |
| times/timestep_before_hook     | 0.00781    |
| times/train                    | 55.5       |
| timestep                       | 1000       |
| timesteps_total                | 93000      |
| train-steps                    | 93000      |
| training/Q/q1_loss             | 104.08163  |
| training/sac_pi/alpha          | 0.14507298 |
| training/sac_pi/alpha_loss     | 0.591704   |
| training/sac_pi/logp_pi        | 4.658386   |
| training/sac_pi/pi_entropy     | 3.6930244  |
| training/sac_pi/pi_global_norm | 1.0429356  |
| training/sac_pi/policy_loss    | -183.76564 |
| training/sac_pi/std            | 0.5253299  |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 175.99785  |
| training/sac_Q/q2              | 176.09082  |
| training/sac_Q/q2_loss         | 103.793015 |
| training/sac_Q/q_global_norm   | 229.5154   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15010075  |
| epoch                          | 93          |
| evaluation/episode-length-avg  | 585         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 167         |
| evaluation/episode-length-std  | 415         |
| evaluation/return-average      | 2434.7595   |
| evaluation/return-max          | 4517.4814   |
| evaluation/return-min          | 451.8344    |
| evaluation/return-std          | 1964.3444   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.78        |
| model/origin_ret               | 83.6        |
| model/penalty_ret              | 83.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45241       |
| perf/AverageLength             | 585         |
| perf/AverageReturn             | 2434.7595   |
| perf/NormalizedReturn          | 0.53        |
| Q-avg                          | 167.62251   |
| Q-std                          | 89.14762    |
| Q_loss                         | 85.45851    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 93          |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000273    |
| times/epoch_rollout_model      | 473         |
| times/evaluation_metrics       | 0.000558    |
| times/evaluation_paths         | 17.8        |
| times/timestep_after_hook      | 0.00355     |
| times/timestep_before_hook     | 0.00781     |
| times/train                    | 55.7        |
| timestep                       | 1000        |
| timesteps_total                | 94000       |
| train-steps                    | 94000       |
| training/Q/q1_loss             | 93.362595   |
| training/sac_pi/alpha          | 0.15012892  |
| training/sac_pi/alpha_loss     | -0.29795942 |
| training/sac_pi/logp_pi        | 4.0507536   |
| training/sac_pi/pi_entropy     | 3.7389596   |
| training/sac_pi/pi_global_norm | 1.242236    |
| training/sac_pi/policy_loss    | -175.56645  |
| training/sac_pi/std            | 0.5260393   |
| training/sac_pi/valid_num      | 4941.0      |
| training/sac_Q/q1              | 167.22852   |
| training/sac_Q/q2              | 166.98592   |
| training/sac_Q/q2_loss         | 93.00583    |
| training/sac_Q/q_global_norm   | 311.21875   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14733033 |
| epoch                          | 94         |
| evaluation/episode-length-avg  | 451        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 210        |
| evaluation/episode-length-std  | 359        |
| evaluation/return-average      | 1917.4398  |
| evaluation/return-max          | 4714.96    |
| evaluation/return-min          | 697.8654   |
| evaluation/return-std          | 1819.9878  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.73       |
| model/origin_ret               | 83.2       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45154      |
| perf/AverageLength             | 451        |
| perf/AverageReturn             | 1917.4398  |
| perf/NormalizedReturn          | 0.417      |
| Q-avg                          | 171.49341  |
| Q-std                          | 85.59546   |
| Q_loss                         | 95.93416   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 94         |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000109   |
| times/epoch_rollout_model      | 472        |
| times/evaluation_metrics       | 0.000463   |
| times/evaluation_paths         | 13.6       |
| times/timestep_after_hook      | 0.00351    |
| times/timestep_before_hook     | 0.0077     |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 95000      |
| train-steps                    | 95000      |
| training/Q/q1_loss             | 97.308784  |
| training/sac_pi/alpha          | 0.14732169 |
| training/sac_pi/alpha_loss     | 0.3421883  |
| training/sac_pi/logp_pi        | 5.3994718  |
| training/sac_pi/pi_entropy     | 3.7611403  |
| training/sac_pi/pi_global_norm | 1.3298104  |
| training/sac_pi/policy_loss    | -175.63121 |
| training/sac_pi/std            | 0.55642486 |
| training/sac_pi/valid_num      | 4907.0     |
| training/sac_Q/q1              | 163.57162  |
| training/sac_Q/q2              | 163.35725  |
| training/sac_Q/q2_loss         | 96.810745  |
| training/sac_Q/q_global_norm   | 216.26787  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15004747 |
| epoch                          | 95         |
| evaluation/episode-length-avg  | 155        |
| evaluation/episode-length-max  | 171        |
| evaluation/episode-length-min  | 138        |
| evaluation/episode-length-std  | 13.1       |
| evaluation/return-average      | 414.64136  |
| evaluation/return-max          | 473.88516  |
| evaluation/return-min          | 350.81897  |
| evaluation/return-std          | 48.368298  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 82.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45315      |
| perf/AverageLength             | 155        |
| perf/AverageReturn             | 414.64136  |
| perf/NormalizedReturn          | 0.09       |
| Q-avg                          | 167.22177  |
| Q-std                          | 100.11986  |
| Q_loss                         | 101.24994  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 95         |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000107   |
| times/epoch_rollout_model      | 472        |
| times/evaluation_metrics       | 0.000478   |
| times/evaluation_paths         | 4.76       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00778    |
| times/train                    | 55.5       |
| timestep                       | 1000       |
| timesteps_total                | 96000      |
| train-steps                    | 96000      |
| training/Q/q1_loss             | 109.7267   |
| training/sac_pi/alpha          | 0.15004028 |
| training/sac_pi/alpha_loss     | 0.20229448 |
| training/sac_pi/logp_pi        | 5.5471344  |
| training/sac_pi/pi_entropy     | 3.8149333  |
| training/sac_pi/pi_global_norm | 1.7634125  |
| training/sac_pi/policy_loss    | -177.34036 |
| training/sac_pi/std            | 0.5585848  |
| training/sac_pi/valid_num      | 4877.0     |
| training/sac_Q/q1              | 165.91618  |
| training/sac_Q/q2              | 165.91179  |
| training/sac_Q/q2_loss         | 110.36593  |
| training/sac_Q/q_global_norm   | 262.31882  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14749666 |
| epoch                          | 96         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4928.199   |
| evaluation/return-max          | 4941.8955  |
| evaluation/return-min          | 4897.9253  |
| evaluation/return-std          | 12.786393  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.85       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45308      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4928.199   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 165.87312  |
| Q-std                          | 91.95055   |
| Q_loss                         | 107.600136 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 96         |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 6.86e-05   |
| times/epoch_rollout_model      | 471        |
| times/evaluation_metrics       | 0.000563   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00346    |
| times/timestep_before_hook     | 0.0077     |
| times/train                    | 55.4       |
| timestep                       | 1000       |
| timesteps_total                | 97000      |
| train-steps                    | 97000      |
| training/Q/q1_loss             | 97.20806   |
| training/sac_pi/alpha          | 0.1474915  |
| training/sac_pi/alpha_loss     | 0.1792054  |
| training/sac_pi/logp_pi        | 5.35105    |
| training/sac_pi/pi_entropy     | 3.6470304  |
| training/sac_pi/pi_global_norm | 1.1961266  |
| training/sac_pi/policy_loss    | -174.1684  |
| training/sac_pi/std            | 0.5458386  |
| training/sac_pi/valid_num      | 4871.0     |
| training/sac_Q/q1              | 162.43828  |
| training/sac_Q/q2              | 161.60466  |
| training/sac_Q/q2_loss         | 97.07307   |
| training/sac_Q/q_global_norm   | 351.3723   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1437952  |
| epoch                          | 97         |
| evaluation/episode-length-avg  | 141        |
| evaluation/episode-length-max  | 145        |
| evaluation/episode-length-min  | 135        |
| evaluation/episode-length-std  | 2.93       |
| evaluation/return-average      | 376.87402  |
| evaluation/return-max          | 398.77643  |
| evaluation/return-min          | 344.61548  |
| evaluation/return-std          | 16.559519  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.83       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 83.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45294      |
| perf/AverageLength             | 141        |
| perf/AverageReturn             | 376.87402  |
| perf/NormalizedReturn          | 0.0817     |
| Q-avg                          | 170.03491  |
| Q-std                          | 96.48371   |
| Q_loss                         | 93.44143   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 97         |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000274   |
| times/epoch_rollout_model      | 471        |
| times/evaluation_metrics       | 0.0006     |
| times/evaluation_paths         | 4.4        |
| times/timestep_after_hook      | 0.0035     |
| times/timestep_before_hook     | 0.0078     |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 98000      |
| train-steps                    | 98000      |
| training/Q/q1_loss             | 84.094635  |
| training/sac_pi/alpha          | 0.14379764 |
| training/sac_pi/alpha_loss     | -0.1849705 |
| training/sac_pi/logp_pi        | 4.4109154  |
| training/sac_pi/pi_entropy     | 3.797116   |
| training/sac_pi/pi_global_norm | 1.3596404  |
| training/sac_pi/policy_loss    | -180.59557 |
| training/sac_pi/std            | 0.53474253 |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 172.37784  |
| training/sac_Q/q2              | 173.41714  |
| training/sac_Q/q2_loss         | 83.90525   |
| training/sac_Q/q_global_norm   | 281.73294  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15172148 |
| epoch                          | 98         |
| evaluation/episode-length-avg  | 382        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 108        |
| evaluation/episode-length-std  | 405        |
| evaluation/return-average      | 1676.1116  |
| evaluation/return-max          | 5060.2715  |
| evaluation/return-min          | 231.257    |
| evaluation/return-std          | 2160.3838  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 83.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45405      |
| perf/AverageLength             | 382        |
| perf/AverageReturn             | 1676.1116  |
| perf/NormalizedReturn          | 0.365      |
| Q-avg                          | 169.40073  |
| Q-std                          | 96.805405  |
| Q_loss                         | 101.66969  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 98         |
| times/epoch_after_hook         | 3.86e-06   |
| times/epoch_before_hook        | 0.000116   |
| times/epoch_rollout_model      | 471        |
| times/evaluation_metrics       | 0.000597   |
| times/evaluation_paths         | 11.8       |
| times/timestep_after_hook      | 0.0035     |
| times/timestep_before_hook     | 0.00783    |
| times/train                    | 55.5       |
| timestep                       | 1000       |
| timesteps_total                | 99000      |
| train-steps                    | 99000      |
| training/Q/q1_loss             | 105.692116 |
| training/sac_pi/alpha          | 0.15171416 |
| training/sac_pi/alpha_loss     | 0.18279892 |
| training/sac_pi/logp_pi        | 4.70317    |
| training/sac_pi/pi_entropy     | 3.7312465  |
| training/sac_pi/pi_global_norm | 1.028905   |
| training/sac_pi/policy_loss    | -182.76111 |
| training/sac_pi/std            | 0.53860855 |
| training/sac_pi/valid_num      | 4945.0     |
| training/sac_Q/q1              | 173.1375   |
| training/sac_Q/q2              | 175.02173  |
| training/sac_Q/q2_loss         | 106.087364 |
| training/sac_Q/q_global_norm   | 258.71835  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14555612 |
| epoch                          | 99         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4626.1406  |
| evaluation/return-max          | 4654.3496  |
| evaluation/return-min          | 4585.824   |
| evaluation/return-std          | 20.963852  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.87       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 83.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45402      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4626.1406  |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 159.7457   |
| Q-std                          | 98.09027   |
| Q_loss                         | 106.04175  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 99         |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000117   |
| times/epoch_rollout_model      | 472        |
| times/evaluation_metrics       | 0.000576   |
| times/evaluation_paths         | 30.6       |
| times/timestep_after_hook      | 0.00351    |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 55.4       |
| timestep                       | 1000       |
| timesteps_total                | 100000     |
| train-steps                    | 100000     |
| training/Q/q1_loss             | 92.461395  |
| training/sac_pi/alpha          | 0.14552364 |
| training/sac_pi/alpha_loss     | 0.13200122 |
| training/sac_pi/logp_pi        | 4.8530235  |
| training/sac_pi/pi_entropy     | 3.8750927  |
| training/sac_pi/pi_global_norm | 1.1259744  |
| training/sac_pi/policy_loss    | -179.80498 |
| training/sac_pi/std            | 0.56163925 |
| training/sac_pi/valid_num      | 4906.0     |
| training/sac_Q/q1              | 168.28697  |
| training/sac_Q/q2              | 168.80762  |
| training/sac_Q/q2_loss         | 92.87853   |
| training/sac_Q/q_global_norm   | 202.92667  |
--------------------------------------------------------------------------------
[WARN] 100 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.14680788  |
| epoch                          | 100         |
| evaluation/episode-length-avg  | 390         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 176         |
| evaluation/episode-length-std  | 305         |
| evaluation/return-average      | 1526.6255   |
| evaluation/return-max          | 4671.585    |
| evaluation/return-min          | 493.8562    |
| evaluation/return-std          | 1561.282    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.81        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45387       |
| perf/AverageLength             | 390         |
| perf/AverageReturn             | 1526.6255   |
| perf/NormalizedReturn          | 0.332       |
| Q-avg                          | 168.0856    |
| Q-std                          | 94.142555   |
| Q_loss                         | 90.43108    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 100         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000105    |
| times/epoch_rollout_model      | 473         |
| times/evaluation_metrics       | 0.000643    |
| times/evaluation_paths         | 11.8        |
| times/timestep_after_hook      | 0.00353     |
| times/timestep_before_hook     | 0.0079      |
| times/train                    | 55.4        |
| timestep                       | 1000        |
| timesteps_total                | 101000      |
| train-steps                    | 101000      |
| training/Q/q1_loss             | 88.27619    |
| training/sac_pi/alpha          | 0.14679365  |
| training/sac_pi/alpha_loss     | 0.053850792 |
| training/sac_pi/logp_pi        | 4.310418    |
| training/sac_pi/pi_entropy     | 3.6618829   |
| training/sac_pi/pi_global_norm | 1.1724379   |
| training/sac_pi/policy_loss    | -179.06436  |
| training/sac_pi/std            | 0.5270245   |
| training/sac_pi/valid_num      | 4944.0      |
| training/sac_Q/q1              | 172.21196   |
| training/sac_Q/q2              | 172.66075   |
| training/sac_Q/q2_loss         | 89.093834   |
| training/sac_Q/q_global_norm   | 245.45561   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14359131 |
| epoch                          | 101        |
| evaluation/episode-length-avg  | 822        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 165        |
| evaluation/episode-length-std  | 290        |
| evaluation/return-average      | 3836.3054  |
| evaluation/return-max          | 4783.3516  |
| evaluation/return-min          | 478.5801   |
| evaluation/return-std          | 1487.7124  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.87       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45366      |
| perf/AverageLength             | 822        |
| perf/AverageReturn             | 3836.3054  |
| perf/NormalizedReturn          | 0.835      |
| Q-avg                          | 156.91515  |
| Q-std                          | 98.38431   |
| Q_loss                         | 93.21024   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 101        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000331   |
| times/epoch_rollout_model      | 470        |
| times/evaluation_metrics       | 0.000568   |
| times/evaluation_paths         | 24.7       |
| times/timestep_after_hook      | 0.00338    |
| times/timestep_before_hook     | 0.00788    |
| times/train                    | 55.5       |
| timestep                       | 1000       |
| timesteps_total                | 102000     |
| train-steps                    | 102000     |
| training/Q/q1_loss             | 97.34447   |
| training/sac_pi/alpha          | 0.14359097 |
| training/sac_pi/alpha_loss     | -0.3406106 |
| training/sac_pi/logp_pi        | 3.9077315  |
| training/sac_pi/pi_entropy     | 3.5887458  |
| training/sac_pi/pi_global_norm | 1.4373926  |
| training/sac_pi/policy_loss    | -169.14719 |
| training/sac_pi/std            | 0.5080794  |
| training/sac_pi/valid_num      | 5001.0     |
| training/sac_Q/q1              | 163.30807  |
| training/sac_Q/q2              | 163.90068  |
| training/sac_Q/q2_loss         | 98.05578   |
| training/sac_Q/q_global_norm   | 277.14362  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1460548  |
| epoch                          | 102        |
| evaluation/episode-length-avg  | 135        |
| evaluation/episode-length-max  | 135        |
| evaluation/episode-length-min  | 134        |
| evaluation/episode-length-std  | 0.3        |
| evaluation/return-average      | 411.44183  |
| evaluation/return-max          | 414.1608   |
| evaluation/return-min          | 408.7819   |
| evaluation/return-std          | 1.5156257  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.73       |
| model/origin_ret               | 81.1       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45482      |
| perf/AverageLength             | 135        |
| perf/AverageReturn             | 411.44183  |
| perf/NormalizedReturn          | 0.0893     |
| Q-avg                          | 164.87642  |
| Q-std                          | 95.004326  |
| Q_loss                         | 83.88451   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 102        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 472        |
| times/evaluation_metrics       | 0.000576   |
| times/evaluation_paths         | 4.04       |
| times/timestep_after_hook      | 0.00344    |
| times/timestep_before_hook     | 0.00783    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 103000     |
| train-steps                    | 103000     |
| training/Q/q1_loss             | 78.17523   |
| training/sac_pi/alpha          | 0.14602166 |
| training/sac_pi/alpha_loss     | 0.27776638 |
| training/sac_pi/logp_pi        | 5.0159416  |
| training/sac_pi/pi_entropy     | 3.8627598  |
| training/sac_pi/pi_global_norm | 1.0773562  |
| training/sac_pi/policy_loss    | -181.34596 |
| training/sac_pi/std            | 0.55824393 |
| training/sac_pi/valid_num      | 4886.0     |
| training/sac_Q/q1              | 169.98007  |
| training/sac_Q/q2              | 170.77127  |
| training/sac_Q/q2_loss         | 77.958534  |
| training/sac_Q/q_global_norm   | 207.17982  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1457696  |
| epoch                          | 103        |
| evaluation/episode-length-avg  | 912        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 122        |
| evaluation/episode-length-std  | 263        |
| evaluation/return-average      | 4098.5596  |
| evaluation/return-max          | 4552.368   |
| evaluation/return-min          | 368.7798   |
| evaluation/return-std          | 1243.3917  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 82.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45241      |
| perf/AverageLength             | 912        |
| perf/AverageReturn             | 4098.5596  |
| perf/NormalizedReturn          | 0.892      |
| Q-avg                          | 176.73479  |
| Q-std                          | 91.134186  |
| Q_loss                         | 73.461044  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 103        |
| times/epoch_after_hook         | 2.04e-06   |
| times/epoch_before_hook        | 6.32e-05   |
| times/epoch_rollout_model      | 470        |
| times/evaluation_metrics       | 0.000559   |
| times/evaluation_paths         | 27.5       |
| times/timestep_after_hook      | 0.00342    |
| times/timestep_before_hook     | 0.00776    |
| times/train                    | 55.3       |
| timestep                       | 1000       |
| timesteps_total                | 104000     |
| train-steps                    | 104000     |
| training/Q/q1_loss             | 85.9609    |
| training/sac_pi/alpha          | 0.14575157 |
| training/sac_pi/alpha_loss     | 0.26824483 |
| training/sac_pi/logp_pi        | 5.5178757  |
| training/sac_pi/pi_entropy     | 3.8567276  |
| training/sac_pi/pi_global_norm | 1.1551968  |
| training/sac_pi/policy_loss    | -173.54233 |
| training/sac_pi/std            | 0.57675683 |
| training/sac_pi/valid_num      | 4875.0     |
| training/sac_Q/q1              | 161.07938  |
| training/sac_Q/q2              | 161.20927  |
| training/sac_Q/q2_loss         | 86.28842   |
| training/sac_Q/q_global_norm   | 233.03322  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15041515  |
| epoch                          | 104         |
| evaluation/episode-length-avg  | 655         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 133         |
| evaluation/episode-length-std  | 422         |
| evaluation/return-average      | 3069.8672   |
| evaluation/return-max          | 4881.086    |
| evaluation/return-min          | 355.55426   |
| evaluation/return-std          | 2185.8416   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.82        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 83.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45140       |
| perf/AverageLength             | 655         |
| perf/AverageReturn             | 3069.8672   |
| perf/NormalizedReturn          | 0.668       |
| Q-avg                          | 169.7261    |
| Q-std                          | 84.758995   |
| Q_loss                         | 98.68751    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 104         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000109    |
| times/epoch_rollout_model      | 472         |
| times/evaluation_metrics       | 0.000543    |
| times/evaluation_paths         | 19.9        |
| times/timestep_after_hook      | 0.00346     |
| times/timestep_before_hook     | 0.00791     |
| times/train                    | 55.4        |
| timestep                       | 1000        |
| timesteps_total                | 105000      |
| train-steps                    | 105000      |
| training/Q/q1_loss             | 100.89224   |
| training/sac_pi/alpha          | 0.15044032  |
| training/sac_pi/alpha_loss     | -0.09233056 |
| training/sac_pi/logp_pi        | 4.812226    |
| training/sac_pi/pi_entropy     | 3.6371255   |
| training/sac_pi/pi_global_norm | 1.7113562   |
| training/sac_pi/policy_loss    | -175.98004  |
| training/sac_pi/std            | 0.52329826  |
| training/sac_pi/valid_num      | 4924.0      |
| training/sac_Q/q1              | 165.29848   |
| training/sac_Q/q2              | 165.66844   |
| training/sac_Q/q2_loss         | 101.12723   |
| training/sac_Q/q_global_norm   | 262.52866   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15300459   |
| epoch                          | 105          |
| evaluation/episode-length-avg  | 137          |
| evaluation/episode-length-max  | 140          |
| evaluation/episode-length-min  | 133          |
| evaluation/episode-length-std  | 2.15         |
| evaluation/return-average      | 420.45587    |
| evaluation/return-max          | 442.91687    |
| evaluation/return-min          | 400.07178    |
| evaluation/return-std          | 12.665867    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.93         |
| model/origin_ret               | 85.4         |
| model/penalty_ret              | 83.7         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45409        |
| perf/AverageLength             | 137          |
| perf/AverageReturn             | 420.45587    |
| perf/NormalizedReturn          | 0.0912       |
| Q-avg                          | 154.72989    |
| Q-std                          | 100.748276   |
| Q_loss                         | 95.9929      |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 105          |
| times/epoch_after_hook         | 1.71e-06     |
| times/epoch_before_hook        | 0.000333     |
| times/epoch_rollout_model      | 471          |
| times/evaluation_metrics       | 0.000641     |
| times/evaluation_paths         | 4.18         |
| times/timestep_after_hook      | 0.00346      |
| times/timestep_before_hook     | 0.00793      |
| times/train                    | 55.6         |
| timestep                       | 1000         |
| timesteps_total                | 106000       |
| train-steps                    | 106000       |
| training/Q/q1_loss             | 94.32539     |
| training/sac_pi/alpha          | 0.15303195   |
| training/sac_pi/alpha_loss     | -0.022924405 |
| training/sac_pi/logp_pi        | 4.7964506    |
| training/sac_pi/pi_entropy     | 3.8514075    |
| training/sac_pi/pi_global_norm | 1.188534     |
| training/sac_pi/policy_loss    | -174.98611   |
| training/sac_pi/std            | 0.56182194   |
| training/sac_pi/valid_num      | 4939.0       |
| training/sac_Q/q1              | 163.53366    |
| training/sac_Q/q2              | 164.1865     |
| training/sac_Q/q2_loss         | 94.56932     |
| training/sac_Q/q_global_norm   | 208.67844    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15304253 |
| epoch                          | 106        |
| evaluation/episode-length-avg  | 779        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 124        |
| evaluation/episode-length-std  | 299        |
| evaluation/return-average      | 3653.9282  |
| evaluation/return-max          | 4936.379   |
| evaluation/return-min          | 305.44373  |
| evaluation/return-std          | 1566.3762  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 83.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45437      |
| perf/AverageLength             | 779        |
| perf/AverageReturn             | 3653.9282  |
| perf/NormalizedReturn          | 0.796      |
| Q-avg                          | 182.60315  |
| Q-std                          | 76.01051   |
| Q_loss                         | 95.83569   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 106        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000108   |
| times/epoch_rollout_model      | 471        |
| times/evaluation_metrics       | 0.000633   |
| times/evaluation_paths         | 23.9       |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.00777    |
| times/train                    | 55.5       |
| timestep                       | 1000       |
| timesteps_total                | 107000     |
| train-steps                    | 107000     |
| training/Q/q1_loss             | 74.68177   |
| training/sac_pi/alpha          | 0.15300108 |
| training/sac_pi/alpha_loss     | 0.39681426 |
| training/sac_pi/logp_pi        | 5.0431314  |
| training/sac_pi/pi_entropy     | 3.58966    |
| training/sac_pi/pi_global_norm | 1.9758313  |
| training/sac_pi/policy_loss    | -188.15254 |
| training/sac_pi/std            | 0.5364458  |
| training/sac_pi/valid_num      | 4944.0     |
| training/sac_Q/q1              | 180.45047  |
| training/sac_Q/q2              | 179.43098  |
| training/sac_Q/q2_loss         | 75.79879   |
| training/sac_Q/q_global_norm   | 299.68622  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14850369 |
| epoch                          | 107        |
| evaluation/episode-length-avg  | 890        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 337        |
| evaluation/episode-length-std  | 226        |
| evaluation/return-average      | 4382.94    |
| evaluation/return-max          | 5031.19    |
| evaluation/return-min          | 1387.1234  |
| evaluation/return-std          | 1223.5297  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.82       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 82.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45303      |
| perf/AverageLength             | 890        |
| perf/AverageReturn             | 4382.94    |
| perf/NormalizedReturn          | 0.954      |
| Q-avg                          | 173.56558  |
| Q-std                          | 84.485886  |
| Q_loss                         | 94.39607   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 107        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000218   |
| times/epoch_rollout_model      | 471        |
| times/evaluation_metrics       | 0.000536   |
| times/evaluation_paths         | 27.2       |
| times/timestep_after_hook      | 0.00356    |
| times/timestep_before_hook     | 0.00791    |
| times/train                    | 55.3       |
| timestep                       | 1000       |
| timesteps_total                | 108000     |
| train-steps                    | 108000     |
| training/Q/q1_loss             | 109.14513  |
| training/sac_pi/alpha          | 0.14855208 |
| training/sac_pi/alpha_loss     | -0.5187517 |
| training/sac_pi/logp_pi        | 4.4170604  |
| training/sac_pi/pi_entropy     | 3.8100693  |
| training/sac_pi/pi_global_norm | 1.5126429  |
| training/sac_pi/policy_loss    | -170.67957 |
| training/sac_pi/std            | 0.54574436 |
| training/sac_pi/valid_num      | 4932.0     |
| training/sac_Q/q1              | 161.96487  |
| training/sac_Q/q2              | 162.04268  |
| training/sac_Q/q2_loss         | 109.07953  |
| training/sac_Q/q_global_norm   | 255.32278  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15589128  |
| epoch                          | 108         |
| evaluation/episode-length-avg  | 868         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 155         |
| evaluation/episode-length-std  | 276         |
| evaluation/return-average      | 4178.177    |
| evaluation/return-max          | 4890.758    |
| evaluation/return-min          | 486.11646   |
| evaluation/return-std          | 1437.2535   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.7         |
| model/origin_ret               | 81.5        |
| model/penalty_ret              | 83.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45332       |
| perf/AverageLength             | 868         |
| perf/AverageReturn             | 4178.177    |
| perf/NormalizedReturn          | 0.91        |
| Q-avg                          | 165.35265   |
| Q-std                          | 85.63479    |
| Q_loss                         | 99.41319    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 108         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000109    |
| times/epoch_rollout_model      | 473         |
| times/evaluation_metrics       | 0.000644    |
| times/evaluation_paths         | 26.6        |
| times/timestep_after_hook      | 0.00355     |
| times/timestep_before_hook     | 0.0078      |
| times/train                    | 55.4        |
| timestep                       | 1000        |
| timesteps_total                | 109000      |
| train-steps                    | 109000      |
| training/Q/q1_loss             | 90.590195   |
| training/sac_pi/alpha          | 0.15591452  |
| training/sac_pi/alpha_loss     | 0.034812756 |
| training/sac_pi/logp_pi        | 4.220648    |
| training/sac_pi/pi_entropy     | 3.6297164   |
| training/sac_pi/pi_global_norm | 1.1643109   |
| training/sac_pi/policy_loss    | -173.2161   |
| training/sac_pi/std            | 0.5046054   |
| training/sac_pi/valid_num      | 4965.0      |
| training/sac_Q/q1              | 167.26416   |
| training/sac_Q/q2              | 167.37971   |
| training/sac_Q/q2_loss         | 90.252014   |
| training/sac_Q/q_global_norm   | 295.538     |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15945114 |
| epoch                          | 109        |
| evaluation/episode-length-avg  | 938        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 783        |
| evaluation/episode-length-std  | 73.2       |
| evaluation/return-average      | 4255.6436  |
| evaluation/return-max          | 4658.7573  |
| evaluation/return-min          | 3478.502   |
| evaluation/return-std          | 362.1246   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.85       |
| model/origin_ret               | 83.8       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45528      |
| perf/AverageLength             | 938        |
| perf/AverageReturn             | 4255.6436  |
| perf/NormalizedReturn          | 0.927      |
| Q-avg                          | 162.31749  |
| Q-std                          | 101.76677  |
| Q_loss                         | 103.002266 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 109        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000286   |
| times/epoch_rollout_model      | 472        |
| times/evaluation_metrics       | 0.000573   |
| times/evaluation_paths         | 28.4       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00785    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 110000     |
| train-steps                    | 110000     |
| training/Q/q1_loss             | 86.645645  |
| training/sac_pi/alpha          | 0.15944983 |
| training/sac_pi/alpha_loss     | -0.0716658 |
| training/sac_pi/logp_pi        | 5.128048   |
| training/sac_pi/pi_entropy     | 3.90076    |
| training/sac_pi/pi_global_norm | 1.1159288  |
| training/sac_pi/policy_loss    | -168.98128 |
| training/sac_pi/std            | 0.5711114  |
| training/sac_pi/valid_num      | 4846.0     |
| training/sac_Q/q1              | 155.7178   |
| training/sac_Q/q2              | 157.191    |
| training/sac_Q/q2_loss         | 86.93057   |
| training/sac_Q/q_global_norm   | 204.61728  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1488146   |
| epoch                          | 110         |
| evaluation/episode-length-avg  | 484         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 132         |
| evaluation/episode-length-std  | 422         |
| evaluation/return-average      | 2043.0276   |
| evaluation/return-max          | 4609.2236   |
| evaluation/return-min          | 373.93994   |
| evaluation/return-std          | 2014.0355   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.81        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 83.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45133       |
| perf/AverageLength             | 484         |
| perf/AverageReturn             | 2043.0276   |
| perf/NormalizedReturn          | 0.445       |
| Q-avg                          | 172.12038   |
| Q-std                          | 94.66479    |
| Q_loss                         | 102.12685   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 110         |
| times/epoch_after_hook         | 2.03e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 473         |
| times/evaluation_metrics       | 0.000535    |
| times/evaluation_paths         | 14.9        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00792     |
| times/train                    | 55.7        |
| timestep                       | 1000        |
| timesteps_total                | 111000      |
| train-steps                    | 111000      |
| training/Q/q1_loss             | 75.709785   |
| training/sac_pi/alpha          | 0.14885461  |
| training/sac_pi/alpha_loss     | -0.35671607 |
| training/sac_pi/logp_pi        | 3.9662902   |
| training/sac_pi/pi_entropy     | 3.5441856   |
| training/sac_pi/pi_global_norm | 1.1184245   |
| training/sac_pi/policy_loss    | -173.95238  |
| training/sac_pi/std            | 0.50028205  |
| training/sac_pi/valid_num      | 4947.0      |
| training/sac_Q/q1              | 166.57079   |
| training/sac_Q/q2              | 167.38403   |
| training/sac_Q/q2_loss         | 76.52995    |
| training/sac_Q/q_global_norm   | 297.30417   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14739521  |
| epoch                          | 111         |
| evaluation/episode-length-avg  | 660         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 147         |
| evaluation/episode-length-std  | 417         |
| evaluation/return-average      | 3038.4102   |
| evaluation/return-max          | 4824.706    |
| evaluation/return-min          | 504.6338    |
| evaluation/return-std          | 2061.518    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.83        |
| model/origin_ret               | 83.6        |
| model/penalty_ret              | 83.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45529       |
| perf/AverageLength             | 660         |
| perf/AverageReturn             | 3038.4102   |
| perf/NormalizedReturn          | 0.662       |
| Q-avg                          | 168.82942   |
| Q-std                          | 78.90279    |
| Q_loss                         | 78.69956    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 111         |
| times/epoch_after_hook         | 2.95e-06    |
| times/epoch_before_hook        | 0.000101    |
| times/epoch_rollout_model      | 472         |
| times/evaluation_metrics       | 0.000592    |
| times/evaluation_paths         | 19.9        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00793     |
| times/train                    | 55.5        |
| timestep                       | 1000        |
| timesteps_total                | 112000      |
| train-steps                    | 112000      |
| training/Q/q1_loss             | 102.51462   |
| training/sac_pi/alpha          | 0.14740784  |
| training/sac_pi/alpha_loss     | -0.43855768 |
| training/sac_pi/logp_pi        | 4.7410727   |
| training/sac_pi/pi_entropy     | 3.6762536   |
| training/sac_pi/pi_global_norm | 1.2989298   |
| training/sac_pi/policy_loss    | -166.14038  |
| training/sac_pi/std            | 0.54045236  |
| training/sac_pi/valid_num      | 4882.0      |
| training/sac_Q/q1              | 156.00139   |
| training/sac_Q/q2              | 155.81804   |
| training/sac_Q/q2_loss         | 102.539955  |
| training/sac_Q/q_global_norm   | 253.68134   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1538515    |
| epoch                          | 112          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4813.886     |
| evaluation/return-max          | 4896.7275    |
| evaluation/return-min          | 4684.2993    |
| evaluation/return-std          | 61.993885    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.8          |
| model/origin_ret               | 84.1         |
| model/penalty_ret              | 84.1         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45405        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4813.886     |
| perf/NormalizedReturn          | 1.05         |
| Q-avg                          | 161.11874    |
| Q-std                          | 101.42143    |
| Q_loss                         | 114.34777    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 112          |
| times/epoch_after_hook         | 1.95e-06     |
| times/epoch_before_hook        | 0.000103     |
| times/epoch_rollout_model      | 475          |
| times/evaluation_metrics       | 0.000608     |
| times/evaluation_paths         | 30.6         |
| times/timestep_after_hook      | 0.00353      |
| times/timestep_before_hook     | 0.00786      |
| times/train                    | 55.5         |
| timestep                       | 1000         |
| timesteps_total                | 113000       |
| train-steps                    | 113000       |
| training/Q/q1_loss             | 93.66838     |
| training/sac_pi/alpha          | 0.15388      |
| training/sac_pi/alpha_loss     | -0.101508714 |
| training/sac_pi/logp_pi        | 5.577718     |
| training/sac_pi/pi_entropy     | 3.761664     |
| training/sac_pi/pi_global_norm | 1.3457832    |
| training/sac_pi/policy_loss    | -180.16237   |
| training/sac_pi/std            | 0.5658299    |
| training/sac_pi/valid_num      | 4862.0       |
| training/sac_Q/q1              | 166.23862    |
| training/sac_Q/q2              | 167.37589    |
| training/sac_Q/q2_loss         | 93.871735    |
| training/sac_Q/q_global_norm   | 253.48894    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.14722559   |
| epoch                          | 113          |
| evaluation/episode-length-avg  | 417          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 132          |
| evaluation/episode-length-std  | 384          |
| evaluation/return-average      | 1868.8215    |
| evaluation/return-max          | 4968.2812    |
| evaluation/return-min          | 380.33374    |
| evaluation/return-std          | 2035.6239    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.83         |
| model/origin_ret               | 84.1         |
| model/penalty_ret              | 83.1         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45338        |
| perf/AverageLength             | 417          |
| perf/AverageReturn             | 1868.8215    |
| perf/NormalizedReturn          | 0.407        |
| Q-avg                          | 171.77022    |
| Q-std                          | 96.01519     |
| Q_loss                         | 97.09899     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 113          |
| times/epoch_after_hook         | 1.82e-06     |
| times/epoch_before_hook        | 0.000348     |
| times/epoch_rollout_model      | 473          |
| times/evaluation_metrics       | 0.000687     |
| times/evaluation_paths         | 12.7         |
| times/timestep_after_hook      | 0.00348      |
| times/timestep_before_hook     | 0.00788      |
| times/train                    | 55.5         |
| timestep                       | 1000         |
| timesteps_total                | 114000       |
| train-steps                    | 114000       |
| training/Q/q1_loss             | 96.858284    |
| training/sac_pi/alpha          | 0.14721498   |
| training/sac_pi/alpha_loss     | -0.124364436 |
| training/sac_pi/logp_pi        | 4.193354     |
| training/sac_pi/pi_entropy     | 3.8432403    |
| training/sac_pi/pi_global_norm | 1.5700452    |
| training/sac_pi/policy_loss    | -178.56932   |
| training/sac_pi/std            | 0.53159076   |
| training/sac_pi/valid_num      | 4898.0       |
| training/sac_Q/q1              | 169.04276    |
| training/sac_Q/q2              | 168.30925    |
| training/sac_Q/q2_loss         | 97.15658     |
| training/sac_Q/q_global_norm   | 393.02182    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14897098 |
| epoch                          | 114        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4401.6094  |
| evaluation/return-max          | 4507.5996  |
| evaluation/return-min          | 4275.33    |
| evaluation/return-std          | 68.18556   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 82.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45222      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4401.6094  |
| perf/NormalizedReturn          | 0.958      |
| Q-avg                          | 174.62822  |
| Q-std                          | 94.39293   |
| Q_loss                         | 90.496216  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 114        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000105   |
| times/epoch_rollout_model      | 473        |
| times/evaluation_metrics       | 0.000595   |
| times/evaluation_paths         | 30.6       |
| times/timestep_after_hook      | 0.0035     |
| times/timestep_before_hook     | 0.00767    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 115000     |
| train-steps                    | 115000     |
| training/Q/q1_loss             | 107.222534 |
| training/sac_pi/alpha          | 0.14897643 |
| training/sac_pi/alpha_loss     | 0.08463778 |
| training/sac_pi/logp_pi        | 4.87197    |
| training/sac_pi/pi_entropy     | 3.655861   |
| training/sac_pi/pi_global_norm | 1.3422836  |
| training/sac_pi/policy_loss    | -173.05006 |
| training/sac_pi/std            | 0.53831226 |
| training/sac_pi/valid_num      | 4920.0     |
| training/sac_Q/q1              | 163.1134   |
| training/sac_Q/q2              | 162.60745  |
| training/sac_Q/q2_loss         | 107.15766  |
| training/sac_Q/q_global_norm   | 192.9537   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15640822 |
| epoch                          | 115        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4689.335   |
| evaluation/return-max          | 4724.943   |
| evaluation/return-min          | 4665.6387  |
| evaluation/return-std          | 18.49225   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.78       |
| model/origin_ret               | 82.7       |
| model/penalty_ret              | 82.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45417      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4689.335   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 166.49573  |
| Q-std                          | 102.88173  |
| Q_loss                         | 88.23462   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 115        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 473        |
| times/evaluation_metrics       | 0.000527   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00353    |
| times/timestep_before_hook     | 0.00787    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 116000     |
| train-steps                    | 116000     |
| training/Q/q1_loss             | 115.917755 |
| training/sac_pi/alpha          | 0.156382   |
| training/sac_pi/alpha_loss     | 0.5515604  |
| training/sac_pi/logp_pi        | 4.876353   |
| training/sac_pi/pi_entropy     | 3.7829041  |
| training/sac_pi/pi_global_norm | 1.2535616  |
| training/sac_pi/policy_loss    | -179.43448 |
| training/sac_pi/std            | 0.53612506 |
| training/sac_pi/valid_num      | 4903.0     |
| training/sac_Q/q1              | 168.93974  |
| training/sac_Q/q2              | 169.89963  |
| training/sac_Q/q2_loss         | 116.34346  |
| training/sac_Q/q_global_norm   | 277.50845  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15383576  |
| epoch                          | 116         |
| evaluation/episode-length-avg  | 215         |
| evaluation/episode-length-max  | 294         |
| evaluation/episode-length-min  | 202         |
| evaluation/episode-length-std  | 26.5        |
| evaluation/return-average      | 733.7808    |
| evaluation/return-max          | 1120.9589   |
| evaluation/return-min          | 665.34045   |
| evaluation/return-std          | 129.684     |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 86.9        |
| model/penalty_ret              | 83.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 44992       |
| perf/AverageLength             | 215         |
| perf/AverageReturn             | 733.7808    |
| perf/NormalizedReturn          | 0.159       |
| Q-avg                          | 168.19852   |
| Q-std                          | 100.344086  |
| Q_loss                         | 93.342      |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 116         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000111    |
| times/epoch_rollout_model      | 474         |
| times/evaluation_metrics       | 0.000471    |
| times/evaluation_paths         | 6.46        |
| times/timestep_after_hook      | 0.00356     |
| times/timestep_before_hook     | 0.00791     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 117000      |
| train-steps                    | 117000      |
| training/Q/q1_loss             | 95.41107    |
| training/sac_pi/alpha          | 0.15382904  |
| training/sac_pi/alpha_loss     | -0.43710425 |
| training/sac_pi/logp_pi        | 5.193963    |
| training/sac_pi/pi_entropy     | 3.8622317   |
| training/sac_pi/pi_global_norm | 1.6264584   |
| training/sac_pi/policy_loss    | -181.93129  |
| training/sac_pi/std            | 0.5817649   |
| training/sac_pi/valid_num      | 4863.0      |
| training/sac_Q/q1              | 167.34627   |
| training/sac_Q/q2              | 167.87094   |
| training/sac_Q/q2_loss         | 95.62089    |
| training/sac_Q/q_global_norm   | 212.21283   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15239112 |
| epoch                          | 117        |
| evaluation/episode-length-avg  | 493        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 143        |
| evaluation/episode-length-std  | 414        |
| evaluation/return-average      | 2269.5073  |
| evaluation/return-max          | 5017.4863  |
| evaluation/return-min          | 386.16898  |
| evaluation/return-std          | 2234.605   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.72       |
| model/origin_ret               | 83.2       |
| model/penalty_ret              | 83.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 44700      |
| perf/AverageLength             | 493        |
| perf/AverageReturn             | 2269.5073  |
| perf/NormalizedReturn          | 0.494      |
| Q-avg                          | 165.265    |
| Q-std                          | 100.671486 |
| Q_loss                         | 94.11071   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 117        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.00027    |
| times/epoch_rollout_model      | 471        |
| times/evaluation_metrics       | 0.000596   |
| times/evaluation_paths         | 14.9       |
| times/timestep_after_hook      | 0.00354    |
| times/timestep_before_hook     | 0.00783    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 118000     |
| train-steps                    | 118000     |
| training/Q/q1_loss             | 81.387146  |
| training/sac_pi/alpha          | 0.15240574 |
| training/sac_pi/alpha_loss     | 0.08983746 |
| training/sac_pi/logp_pi        | 4.782157   |
| training/sac_pi/pi_entropy     | 3.6847427  |
| training/sac_pi/pi_global_norm | 1.7126516  |
| training/sac_pi/policy_loss    | -182.81857 |
| training/sac_pi/std            | 0.532523   |
| training/sac_pi/valid_num      | 4915.0     |
| training/sac_Q/q1              | 171.07031  |
| training/sac_Q/q2              | 171.48479  |
| training/sac_Q/q2_loss         | 81.70043   |
| training/sac_Q/q_global_norm   | 208.01315  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15819131  |
| epoch                          | 118         |
| evaluation/episode-length-avg  | 314         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 142         |
| evaluation/episode-length-std  | 343         |
| evaluation/return-average      | 1364.809    |
| evaluation/return-max          | 5201.983    |
| evaluation/return-min          | 404.5227    |
| evaluation/return-std          | 1912.1128   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.77        |
| model/origin_ret               | 83.8        |
| model/penalty_ret              | 84.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45122       |
| perf/AverageLength             | 314         |
| perf/AverageReturn             | 1364.809    |
| perf/NormalizedReturn          | 0.297       |
| Q-avg                          | 173.53674   |
| Q-std                          | 84.57221    |
| Q_loss                         | 102.54696   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 118         |
| times/epoch_after_hook         | 1.66e-06    |
| times/epoch_before_hook        | 0.000104    |
| times/epoch_rollout_model      | 471         |
| times/evaluation_metrics       | 0.000603    |
| times/evaluation_paths         | 9.63        |
| times/timestep_after_hook      | 0.00348     |
| times/timestep_before_hook     | 0.00786     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 119000      |
| train-steps                    | 119000      |
| training/Q/q1_loss             | 102.03405   |
| training/sac_pi/alpha          | 0.15820006  |
| training/sac_pi/alpha_loss     | 0.072587654 |
| training/sac_pi/logp_pi        | 4.6093283   |
| training/sac_pi/pi_entropy     | 3.7701252   |
| training/sac_pi/pi_global_norm | 1.2584863   |
| training/sac_pi/policy_loss    | -179.28568  |
| training/sac_pi/std            | 0.54183465  |
| training/sac_pi/valid_num      | 4932.0      |
| training/sac_Q/q1              | 171.27084   |
| training/sac_Q/q2              | 171.20781   |
| training/sac_Q/q2_loss         | 102.212814  |
| training/sac_Q/q_global_norm   | 250.46034   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15876062 |
| epoch                          | 119        |
| evaluation/episode-length-avg  | 661        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 148        |
| evaluation/episode-length-std  | 415        |
| evaluation/return-average      | 2965.8538  |
| evaluation/return-max          | 4739.8594  |
| evaluation/return-min          | 377.69025  |
| evaluation/return-std          | 2096.8594  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 82.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45464      |
| perf/AverageLength             | 661        |
| perf/AverageReturn             | 2965.8538  |
| perf/NormalizedReturn          | 0.646      |
| Q-avg                          | 165.21353  |
| Q-std                          | 97.529274  |
| Q_loss                         | 104.63349  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 119        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000107   |
| times/epoch_rollout_model      | 473        |
| times/evaluation_metrics       | 0.000584   |
| times/evaluation_paths         | 19.9       |
| times/timestep_after_hook      | 0.00347    |
| times/timestep_before_hook     | 0.00794    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 120000     |
| train-steps                    | 120000     |
| training/Q/q1_loss             | 94.86423   |
| training/sac_pi/alpha          | 0.15880969 |
| training/sac_pi/alpha_loss     | -0.2934051 |
| training/sac_pi/logp_pi        | 4.523696   |
| training/sac_pi/pi_entropy     | 3.7056305  |
| training/sac_pi/pi_global_norm | 1.2274953  |
| training/sac_pi/policy_loss    | -179.98128 |
| training/sac_pi/std            | 0.52505314 |
| training/sac_pi/valid_num      | 4896.0     |
| training/sac_Q/q1              | 168.665    |
| training/sac_Q/q2              | 170.31064  |
| training/sac_Q/q2_loss         | 94.73111   |
| training/sac_Q/q_global_norm   | 267.01324  |
--------------------------------------------------------------------------------
[WARN] 120 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.15618978 |
| epoch                          | 120        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5226.147   |
| evaluation/return-max          | 5343.3105  |
| evaluation/return-min          | 5068.7695  |
| evaluation/return-std          | 93.78972   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.86       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 82.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45542      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5226.147   |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 151.23889  |
| Q-std                          | 99.90332   |
| Q_loss                         | 124.14064  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 120        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 472        |
| times/evaluation_metrics       | 0.000517   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.0035     |
| times/timestep_before_hook     | 0.0078     |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 121000     |
| train-steps                    | 121000     |
| training/Q/q1_loss             | 98.839     |
| training/sac_pi/alpha          | 0.15614088 |
| training/sac_pi/alpha_loss     | 0.6135637  |
| training/sac_pi/logp_pi        | 4.133224   |
| training/sac_pi/pi_entropy     | 3.479711   |
| training/sac_pi/pi_global_norm | 1.5449414  |
| training/sac_pi/policy_loss    | -180.2167  |
| training/sac_pi/std            | 0.47274208 |
| training/sac_pi/valid_num      | 5027.0     |
| training/sac_Q/q1              | 176.43152  |
| training/sac_Q/q2              | 176.48477  |
| training/sac_Q/q2_loss         | 98.59893   |
| training/sac_Q/q_global_norm   | 269.48322  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16174766  |
| epoch                          | 121         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4733.0107   |
| evaluation/return-max          | 4761.2656   |
| evaluation/return-min          | 4711.1997   |
| evaluation/return-std          | 15.046262   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 83.8        |
| model/penalty_ret              | 82.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45568       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4733.0107   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 171.55862   |
| Q-std                          | 94.25753    |
| Q_loss                         | 105.24134   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 121         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000323    |
| times/epoch_rollout_model      | 474         |
| times/evaluation_metrics       | 0.000622    |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00348     |
| times/timestep_before_hook     | 0.0079      |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 122000      |
| train-steps                    | 122000      |
| training/Q/q1_loss             | 93.72901    |
| training/sac_pi/alpha          | 0.16177803  |
| training/sac_pi/alpha_loss     | -0.26427513 |
| training/sac_pi/logp_pi        | 4.191478    |
| training/sac_pi/pi_entropy     | 3.667768    |
| training/sac_pi/pi_global_norm | 1.400266    |
| training/sac_pi/policy_loss    | -183.81914  |
| training/sac_pi/std            | 0.50910604  |
| training/sac_pi/valid_num      | 4941.0      |
| training/sac_Q/q1              | 175.40524   |
| training/sac_Q/q2              | 175.98772   |
| training/sac_Q/q2_loss         | 94.50681    |
| training/sac_Q/q_global_norm   | 255.81874   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16065465  |
| epoch                          | 122         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4539.707    |
| evaluation/return-max          | 4574.191    |
| evaluation/return-min          | 4516.7314   |
| evaluation/return-std          | 22.510078   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.8         |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 83.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45498       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4539.707    |
| perf/NormalizedReturn          | 0.989       |
| Q-avg                          | 160.29683   |
| Q-std                          | 110.12652   |
| Q_loss                         | 83.51637    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 122         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000105    |
| times/epoch_rollout_model      | 474         |
| times/evaluation_metrics       | 0.000576    |
| times/evaluation_paths         | 30.1        |
| times/timestep_after_hook      | 0.00351     |
| times/timestep_before_hook     | 0.00783     |
| times/train                    | 55.5        |
| timestep                       | 1000        |
| timesteps_total                | 123000      |
| train-steps                    | 123000      |
| training/Q/q1_loss             | 123.86541   |
| training/sac_pi/alpha          | 0.16069767  |
| training/sac_pi/alpha_loss     | -0.11713288 |
| training/sac_pi/logp_pi        | 6.0548406   |
| training/sac_pi/pi_entropy     | 3.684816    |
| training/sac_pi/pi_global_norm | 1.172282    |
| training/sac_pi/policy_loss    | -176.74324  |
| training/sac_pi/std            | 0.58337086  |
| training/sac_pi/valid_num      | 4861.0      |
| training/sac_Q/q1              | 162.63916   |
| training/sac_Q/q2              | 164.96997   |
| training/sac_Q/q2_loss         | 123.78407   |
| training/sac_Q/q_global_norm   | 291.3858    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16144611 |
| epoch                          | 123        |
| evaluation/episode-length-avg  | 996        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 964        |
| evaluation/episode-length-std  | 10.8       |
| evaluation/return-average      | 4747.743   |
| evaluation/return-max          | 4816.4893  |
| evaluation/return-min          | 4586.3413  |
| evaluation/return-std          | 58.9935    |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.87       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 83.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45464      |
| perf/AverageLength             | 996        |
| perf/AverageReturn             | 4747.743   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 171.72429  |
| Q-std                          | 98.656136  |
| Q_loss                         | 89.537315  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 123        |
| times/epoch_after_hook         | 3.54e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 473        |
| times/evaluation_metrics       | 0.000598   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00788    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 124000     |
| train-steps                    | 124000     |
| training/Q/q1_loss             | 91.01062   |
| training/sac_pi/alpha          | 0.16138312 |
| training/sac_pi/alpha_loss     | 0.63890266 |
| training/sac_pi/logp_pi        | 4.5566516  |
| training/sac_pi/pi_entropy     | 3.7371202  |
| training/sac_pi/pi_global_norm | 1.1729192  |
| training/sac_pi/policy_loss    | -178.47237 |
| training/sac_pi/std            | 0.512968   |
| training/sac_pi/valid_num      | 4995.0     |
| training/sac_Q/q1              | 172.35568  |
| training/sac_Q/q2              | 172.87936  |
| training/sac_Q/q2_loss         | 90.980995  |
| training/sac_Q/q_global_norm   | 305.4944   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1533672   |
| epoch                          | 124         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4840.204    |
| evaluation/return-max          | 4871.1924   |
| evaluation/return-min          | 4819.809    |
| evaluation/return-std          | 14.7091055  |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.82        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 83.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45155       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4840.204    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 177.13045   |
| Q-std                          | 82.933945   |
| Q_loss                         | 80.90254    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 124         |
| times/epoch_after_hook         | 1.98e-06    |
| times/epoch_before_hook        | 0.000104    |
| times/epoch_rollout_model      | 476         |
| times/evaluation_metrics       | 0.000552    |
| times/evaluation_paths         | 30          |
| times/timestep_after_hook      | 0.00351     |
| times/timestep_before_hook     | 0.00784     |
| times/train                    | 55.4        |
| timestep                       | 1000        |
| timesteps_total                | 125000      |
| train-steps                    | 125000      |
| training/Q/q1_loss             | 83.9576     |
| training/sac_pi/alpha          | 0.15337808  |
| training/sac_pi/alpha_loss     | -0.32057217 |
| training/sac_pi/logp_pi        | 4.126383    |
| training/sac_pi/pi_entropy     | 3.6574683   |
| training/sac_pi/pi_global_norm | 1.4514483   |
| training/sac_pi/policy_loss    | -185.98149  |
| training/sac_pi/std            | 0.5145049   |
| training/sac_pi/valid_num      | 4972.0      |
| training/sac_Q/q1              | 178.14377   |
| training/sac_Q/q2              | 179.76834   |
| training/sac_Q/q2_loss         | 83.358025   |
| training/sac_Q/q_global_norm   | 193.51523   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15524808 |
| epoch                          | 125        |
| evaluation/episode-length-avg  | 934        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 407        |
| evaluation/episode-length-std  | 177        |
| evaluation/return-average      | 4365.7744  |
| evaluation/return-max          | 4818.9453  |
| evaluation/return-min          | 1594.9584  |
| evaluation/return-std          | 944.11945  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.87       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45524      |
| perf/AverageLength             | 934        |
| perf/AverageReturn             | 4365.7744  |
| perf/NormalizedReturn          | 0.951      |
| Q-avg                          | 180.2298   |
| Q-std                          | 87.358765  |
| Q_loss                         | 98.19853   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 125        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000279   |
| times/epoch_rollout_model      | 472        |
| times/evaluation_metrics       | 0.000525   |
| times/evaluation_paths         | 28.1       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 126000     |
| train-steps                    | 126000     |
| training/Q/q1_loss             | 73.15871   |
| training/sac_pi/alpha          | 0.15521604 |
| training/sac_pi/alpha_loss     | 0.3152737  |
| training/sac_pi/logp_pi        | 5.6593437  |
| training/sac_pi/pi_entropy     | 3.8983219  |
| training/sac_pi/pi_global_norm | 1.3250816  |
| training/sac_pi/policy_loss    | -183.81062 |
| training/sac_pi/std            | 0.60012525 |
| training/sac_pi/valid_num      | 4850.0     |
| training/sac_Q/q1              | 169.79745  |
| training/sac_Q/q2              | 170.29216  |
| training/sac_Q/q2_loss         | 73.37542   |
| training/sac_Q/q_global_norm   | 227.02141  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15198182 |
| epoch                          | 126        |
| evaluation/episode-length-avg  | 484        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 144        |
| evaluation/episode-length-std  | 276        |
| evaluation/return-average      | 2077.9321  |
| evaluation/return-max          | 4836.4897  |
| evaluation/return-min          | 368.74896  |
| evaluation/return-std          | 1457.3282  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 82.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45382      |
| perf/AverageLength             | 484        |
| perf/AverageReturn             | 2077.9321  |
| perf/NormalizedReturn          | 0.452      |
| Q-avg                          | 172.56738  |
| Q-std                          | 97.30679   |
| Q_loss                         | 90.363495  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 126        |
| times/epoch_after_hook         | 2.12e-06   |
| times/epoch_before_hook        | 0.000118   |
| times/epoch_rollout_model      | 472        |
| times/evaluation_metrics       | 0.000529   |
| times/evaluation_paths         | 14.9       |
| times/timestep_after_hook      | 0.00341    |
| times/timestep_before_hook     | 0.00792    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 127000     |
| train-steps                    | 127000     |
| training/Q/q1_loss             | 103.51151  |
| training/sac_pi/alpha          | 0.15197612 |
| training/sac_pi/alpha_loss     | 0.1753882  |
| training/sac_pi/logp_pi        | 4.7822595  |
| training/sac_pi/pi_entropy     | 3.806209   |
| training/sac_pi/pi_global_norm | 1.922225   |
| training/sac_pi/policy_loss    | -181.55748 |
| training/sac_pi/std            | 0.5558935  |
| training/sac_pi/valid_num      | 4940.0     |
| training/sac_Q/q1              | 171.41345  |
| training/sac_Q/q2              | 172.3752   |
| training/sac_Q/q2_loss         | 103.418    |
| training/sac_Q/q_global_norm   | 212.05054  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15064488  |
| epoch                          | 127         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4933.8467   |
| evaluation/return-max          | 4959.1494   |
| evaluation/return-min          | 4905.292    |
| evaluation/return-std          | 16.171452   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.78        |
| model/origin_ret               | 82.6        |
| model/penalty_ret              | 82.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45700       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4933.8467   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 173.8158    |
| Q-std                          | 103.159706  |
| Q_loss                         | 87.66167    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 127         |
| times/epoch_after_hook         | 2.33e-06    |
| times/epoch_before_hook        | 0.000184    |
| times/epoch_rollout_model      | 474         |
| times/evaluation_metrics       | 0.000566    |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.00346     |
| times/timestep_before_hook     | 0.00791     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 128000      |
| train-steps                    | 128000      |
| training/Q/q1_loss             | 104.92616   |
| training/sac_pi/alpha          | 0.15063351  |
| training/sac_pi/alpha_loss     | -0.21812363 |
| training/sac_pi/logp_pi        | 4.2228127   |
| training/sac_pi/pi_entropy     | 3.5729117   |
| training/sac_pi/pi_global_norm | 1.2811518   |
| training/sac_pi/policy_loss    | -185.0254   |
| training/sac_pi/std            | 0.5026662   |
| training/sac_pi/valid_num      | 4974.0      |
| training/sac_Q/q1              | 177.1789    |
| training/sac_Q/q2              | 177.87494   |
| training/sac_Q/q2_loss         | 104.7332    |
| training/sac_Q/q_global_norm   | 308.8804    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15487576  |
| epoch                          | 128         |
| evaluation/episode-length-avg  | 689         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 218         |
| evaluation/episode-length-std  | 381         |
| evaluation/return-average      | 3198.5767   |
| evaluation/return-max          | 4859.651    |
| evaluation/return-min          | 721.50854   |
| evaluation/return-std          | 2003.6886   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 82.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45518       |
| perf/AverageLength             | 689         |
| perf/AverageReturn             | 3198.5767   |
| perf/NormalizedReturn          | 0.696       |
| Q-avg                          | 164.28049   |
| Q-std                          | 104.128944  |
| Q_loss                         | 93.58619    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 128         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000104    |
| times/epoch_rollout_model      | 473         |
| times/evaluation_metrics       | 0.000494    |
| times/evaluation_paths         | 20.8        |
| times/timestep_after_hook      | 0.0035      |
| times/timestep_before_hook     | 0.00784     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 129000      |
| train-steps                    | 129000      |
| training/Q/q1_loss             | 91.59636    |
| training/sac_pi/alpha          | 0.15489338  |
| training/sac_pi/alpha_loss     | -0.18531744 |
| training/sac_pi/logp_pi        | 4.635457    |
| training/sac_pi/pi_entropy     | 3.6799774   |
| training/sac_pi/pi_global_norm | 1.4790404   |
| training/sac_pi/policy_loss    | -187.97942  |
| training/sac_pi/std            | 0.52477556  |
| training/sac_pi/valid_num      | 4933.0      |
| training/sac_Q/q1              | 177.26575   |
| training/sac_Q/q2              | 178.1779    |
| training/sac_Q/q2_loss         | 91.63624    |
| training/sac_Q/q_global_norm   | 240.902     |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14846522  |
| epoch                          | 129         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4716.991    |
| evaluation/return-max          | 4734.4844   |
| evaluation/return-min          | 4696.875    |
| evaluation/return-std          | 10.193678   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 83          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45643       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4716.991    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 173.4454    |
| Q-std                          | 91.338844   |
| Q_loss                         | 81.47862    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 129         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000281    |
| times/epoch_rollout_model      | 472         |
| times/evaluation_metrics       | 0.000557    |
| times/evaluation_paths         | 30.6        |
| times/timestep_after_hook      | 0.00348     |
| times/timestep_before_hook     | 0.00784     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 130000      |
| train-steps                    | 130000      |
| training/Q/q1_loss             | 101.43301   |
| training/sac_pi/alpha          | 0.14848077  |
| training/sac_pi/alpha_loss     | -0.14362463 |
| training/sac_pi/logp_pi        | 4.123867    |
| training/sac_pi/pi_entropy     | 3.3599534   |
| training/sac_pi/pi_global_norm | 1.3916215   |
| training/sac_pi/policy_loss    | -182.10576  |
| training/sac_pi/std            | 0.4735365   |
| training/sac_pi/valid_num      | 4987.0      |
| training/sac_Q/q1              | 175.6392    |
| training/sac_Q/q2              | 176.11061   |
| training/sac_Q/q2_loss         | 102.35412   |
| training/sac_Q/q_global_norm   | 265.49588   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15956472  |
| epoch                          | 130         |
| evaluation/episode-length-avg  | 909         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 540         |
| evaluation/episode-length-std  | 183         |
| evaluation/return-average      | 4082.434    |
| evaluation/return-max          | 4759.6963   |
| evaluation/return-min          | 2166.978    |
| evaluation/return-std          | 951.6606    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 83          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45618       |
| perf/AverageLength             | 909         |
| perf/AverageReturn             | 4082.434    |
| perf/NormalizedReturn          | 0.889       |
| Q-avg                          | 165.42468   |
| Q-std                          | 105.76601   |
| Q_loss                         | 91.59206    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 130         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000106    |
| times/epoch_rollout_model      | 471         |
| times/evaluation_metrics       | 0.000524    |
| times/evaluation_paths         | 28.3        |
| times/timestep_after_hook      | 0.00347     |
| times/timestep_before_hook     | 0.00782     |
| times/train                    | 55.3        |
| timestep                       | 1000        |
| timesteps_total                | 131000      |
| train-steps                    | 131000      |
| training/Q/q1_loss             | 93.99337    |
| training/sac_pi/alpha          | 0.15962858  |
| training/sac_pi/alpha_loss     | -0.16114354 |
| training/sac_pi/logp_pi        | 4.652528    |
| training/sac_pi/pi_entropy     | 3.8913498   |
| training/sac_pi/pi_global_norm | 1.2289602   |
| training/sac_pi/policy_loss    | -168.31548  |
| training/sac_pi/std            | 0.54407287  |
| training/sac_pi/valid_num      | 4881.0      |
| training/sac_Q/q1              | 158.21579   |
| training/sac_Q/q2              | 158.8775    |
| training/sac_Q/q2_loss         | 94.348015   |
| training/sac_Q/q_global_norm   | 232.55408   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16065685 |
| epoch                          | 131        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4509.8486  |
| evaluation/return-max          | 4559.7188  |
| evaluation/return-min          | 4455.252   |
| evaluation/return-std          | 37.26038   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.84       |
| model/origin_ret               | 83.8       |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45571      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4509.8486  |
| perf/NormalizedReturn          | 0.982      |
| Q-avg                          | 172.5273   |
| Q-std                          | 102.443054 |
| Q_loss                         | 85.64755   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 131        |
| times/epoch_after_hook         | 2.03e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 473        |
| times/evaluation_metrics       | 0.00059    |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00346    |
| times/timestep_before_hook     | 0.00773    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 132000     |
| train-steps                    | 132000     |
| training/Q/q1_loss             | 93.63534   |
| training/sac_pi/alpha          | 0.16060503 |
| training/sac_pi/alpha_loss     | 0.39940602 |
| training/sac_pi/logp_pi        | 4.6201415  |
| training/sac_pi/pi_entropy     | 3.6749947  |
| training/sac_pi/pi_global_norm | 1.556098   |
| training/sac_pi/policy_loss    | -186.1874  |
| training/sac_pi/std            | 0.5031871  |
| training/sac_pi/valid_num      | 4981.0     |
| training/sac_Q/q1              | 179.76883  |
| training/sac_Q/q2              | 178.83963  |
| training/sac_Q/q2_loss         | 93.537056  |
| training/sac_Q/q_global_norm   | 221.76567  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15258704 |
| epoch                          | 132        |
| evaluation/episode-length-avg  | 125        |
| evaluation/episode-length-max  | 129        |
| evaluation/episode-length-min  | 122        |
| evaluation/episode-length-std  | 1.95       |
| evaluation/return-average      | 367.2438   |
| evaluation/return-max          | 398.74377  |
| evaluation/return-min          | 344.81116  |
| evaluation/return-std          | 16.633827  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 83.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45222      |
| perf/AverageLength             | 125        |
| perf/AverageReturn             | 367.2438   |
| perf/NormalizedReturn          | 0.0796     |
| Q-avg                          | 167.34671  |
| Q-std                          | 107.78802  |
| Q_loss                         | 92.60031   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 132        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000107   |
| times/epoch_rollout_model      | 475        |
| times/evaluation_metrics       | 0.000612   |
| times/evaluation_paths         | 3.86       |
| times/timestep_after_hook      | 0.00341    |
| times/timestep_before_hook     | 0.0077     |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 133000     |
| train-steps                    | 133000     |
| training/Q/q1_loss             | 109.106735 |
| training/sac_pi/alpha          | 0.15257761 |
| training/sac_pi/alpha_loss     | 0.09804733 |
| training/sac_pi/logp_pi        | 5.7434072  |
| training/sac_pi/pi_entropy     | 3.5311477  |
| training/sac_pi/pi_global_norm | 1.6897298  |
| training/sac_pi/policy_loss    | -185.96779 |
| training/sac_pi/std            | 0.5528259  |
| training/sac_pi/valid_num      | 4918.0     |
| training/sac_Q/q1              | 172.83281  |
| training/sac_Q/q2              | 174.35439  |
| training/sac_Q/q2_loss         | 109.134834 |
| training/sac_Q/q_global_norm   | 293.61832  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14944981 |
| epoch                          | 133        |
| evaluation/episode-length-avg  | 482        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 134        |
| evaluation/episode-length-std  | 358        |
| evaluation/return-average      | 2221.2998  |
| evaluation/return-max          | 4923.453   |
| evaluation/return-min          | 442.288    |
| evaluation/return-std          | 1849.4739  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.81       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 83.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45251      |
| perf/AverageLength             | 482        |
| perf/AverageReturn             | 2221.2998  |
| perf/NormalizedReturn          | 0.484      |
| Q-avg                          | 181.0964   |
| Q-std                          | 89.04819   |
| Q_loss                         | 93.209335  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 133        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000278   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000529   |
| times/evaluation_paths         | 14.9       |
| times/timestep_after_hook      | 0.0035     |
| times/timestep_before_hook     | 0.00784    |
| times/train                    | 55.3       |
| timestep                       | 1000       |
| timesteps_total                | 134000     |
| train-steps                    | 134000     |
| training/Q/q1_loss             | 103.07139  |
| training/sac_pi/alpha          | 0.14940974 |
| training/sac_pi/alpha_loss     | 0.29671425 |
| training/sac_pi/logp_pi        | 4.7778735  |
| training/sac_pi/pi_entropy     | 3.5365233  |
| training/sac_pi/pi_global_norm | 1.363961   |
| training/sac_pi/policy_loss    | -186.0199  |
| training/sac_pi/std            | 0.5178539  |
| training/sac_pi/valid_num      | 4880.0     |
| training/sac_Q/q1              | 174.42769  |
| training/sac_Q/q2              | 174.67154  |
| training/sac_Q/q2_loss         | 102.56593  |
| training/sac_Q/q_global_norm   | 364.3372   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15849683  |
| epoch                          | 134         |
| evaluation/episode-length-avg  | 827         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 135         |
| evaluation/episode-length-std  | 345         |
| evaluation/return-average      | 4191.0376   |
| evaluation/return-max          | 5167.9326   |
| evaluation/return-min          | 405.4143    |
| evaluation/return-std          | 1890.0682   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.83        |
| model/origin_ret               | 83.1        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45518       |
| perf/AverageLength             | 827         |
| perf/AverageReturn             | 4191.0376   |
| perf/NormalizedReturn          | 0.913       |
| Q-avg                          | 170.52255   |
| Q-std                          | 100.560234  |
| Q_loss                         | 78.70463    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 134         |
| times/epoch_after_hook         | 2.05e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 474         |
| times/evaluation_metrics       | 0.00058     |
| times/evaluation_paths         | 25.3        |
| times/timestep_after_hook      | 0.00346     |
| times/timestep_before_hook     | 0.00796     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 135000      |
| train-steps                    | 135000      |
| training/Q/q1_loss             | 89.189285   |
| training/sac_pi/alpha          | 0.15850277  |
| training/sac_pi/alpha_loss     | -0.07232755 |
| training/sac_pi/logp_pi        | 4.2158656   |
| training/sac_pi/pi_entropy     | 3.6362038   |
| training/sac_pi/pi_global_norm | 1.3133829   |
| training/sac_pi/policy_loss    | -184.69351  |
| training/sac_pi/std            | 0.50905144  |
| training/sac_pi/valid_num      | 4971.0      |
| training/sac_Q/q1              | 177.06686   |
| training/sac_Q/q2              | 177.604     |
| training/sac_Q/q2_loss         | 88.91998    |
| training/sac_Q/q_global_norm   | 226.58893   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15800543 |
| epoch                          | 135        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4621.5884  |
| evaluation/return-max          | 4722.9795  |
| evaluation/return-min          | 4409.0146  |
| evaluation/return-std          | 87.181786  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.84       |
| model/origin_ret               | 83.4       |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45557      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4621.5884  |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 175.5822   |
| Q-std                          | 97.58216   |
| Q_loss                         | 75.4888    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 135        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 472        |
| times/evaluation_metrics       | 0.000529   |
| times/evaluation_paths         | 30.9       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00788    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 136000     |
| train-steps                    | 136000     |
| training/Q/q1_loss             | 100.54097  |
| training/sac_pi/alpha          | 0.15802412 |
| training/sac_pi/alpha_loss     | 0.06620902 |
| training/sac_pi/logp_pi        | 4.3980455  |
| training/sac_pi/pi_entropy     | 3.9004903  |
| training/sac_pi/pi_global_norm | 1.2346779  |
| training/sac_pi/policy_loss    | -182.31313 |
| training/sac_pi/std            | 0.5555068  |
| training/sac_pi/valid_num      | 4921.0     |
| training/sac_Q/q1              | 172.69022  |
| training/sac_Q/q2              | 172.7075   |
| training/sac_Q/q2_loss         | 100.03282  |
| training/sac_Q/q_global_norm   | 337.8431   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15634346 |
| epoch                          | 136        |
| evaluation/episode-length-avg  | 379        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 111        |
| evaluation/episode-length-std  | 407        |
| evaluation/return-average      | 1716.1726  |
| evaluation/return-max          | 5143.2256  |
| evaluation/return-min          | 247.94476  |
| evaluation/return-std          | 2233.2585  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.87       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45666      |
| perf/AverageLength             | 379        |
| perf/AverageReturn             | 1716.1726  |
| perf/NormalizedReturn          | 0.373      |
| Q-avg                          | 178.18661  |
| Q-std                          | 102.11918  |
| Q_loss                         | 92.92342   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 136        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000161   |
| times/epoch_rollout_model      | 475        |
| times/evaluation_metrics       | 0.000483   |
| times/evaluation_paths         | 11.6       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00794    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 137000     |
| train-steps                    | 137000     |
| training/Q/q1_loss             | 90.26257   |
| training/sac_pi/alpha          | 0.15631483 |
| training/sac_pi/alpha_loss     | 0.36563563 |
| training/sac_pi/logp_pi        | 3.9483116  |
| training/sac_pi/pi_entropy     | 3.634152   |
| training/sac_pi/pi_global_norm | 1.5133374  |
| training/sac_pi/policy_loss    | -182.75385 |
| training/sac_pi/std            | 0.49111038 |
| training/sac_pi/valid_num      | 4990.0     |
| training/sac_Q/q1              | 177.83878  |
| training/sac_Q/q2              | 178.45187  |
| training/sac_Q/q2_loss         | 89.82708   |
| training/sac_Q/q_global_norm   | 267.09415  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1596345   |
| epoch                          | 137         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4038.257    |
| evaluation/return-max          | 4202.107    |
| evaluation/return-min          | 3918.4814   |
| evaluation/return-std          | 87.81938    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 82.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45604       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4038.257    |
| perf/NormalizedReturn          | 0.879       |
| Q-avg                          | 162.4328    |
| Q-std                          | 112.54346   |
| Q_loss                         | 95.422585   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 137         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000277    |
| times/epoch_rollout_model      | 472         |
| times/evaluation_metrics       | 0.000533    |
| times/evaluation_paths         | 30.3        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00787     |
| times/train                    | 56.2        |
| timestep                       | 1000        |
| timesteps_total                | 138000      |
| train-steps                    | 138000      |
| training/Q/q1_loss             | 100.370445  |
| training/sac_pi/alpha          | 0.15963864  |
| training/sac_pi/alpha_loss     | -0.23130214 |
| training/sac_pi/logp_pi        | 5.1289454   |
| training/sac_pi/pi_entropy     | 4.0104957   |
| training/sac_pi/pi_global_norm | 1.2382199   |
| training/sac_pi/policy_loss    | -178.41785  |
| training/sac_pi/std            | 0.61279833  |
| training/sac_pi/valid_num      | 4901.0      |
| training/sac_Q/q1              | 165.62924   |
| training/sac_Q/q2              | 167.08951   |
| training/sac_Q/q2_loss         | 101.12882   |
| training/sac_Q/q_global_norm   | 230.34177   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15386206 |
| epoch                          | 138        |
| evaluation/episode-length-avg  | 823        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 350        |
| evaluation/episode-length-std  | 272        |
| evaluation/return-average      | 3819.2058  |
| evaluation/return-max          | 4787.92    |
| evaluation/return-min          | 1438.2849  |
| evaluation/return-std          | 1369.5372  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.79       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 83.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45218      |
| perf/AverageLength             | 823        |
| perf/AverageReturn             | 3819.2058  |
| perf/NormalizedReturn          | 0.832      |
| Q-avg                          | 174.26517  |
| Q-std                          | 92.9345    |
| Q_loss                         | 97.651924  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 138        |
| times/epoch_after_hook         | 2.05e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.00056    |
| times/evaluation_paths         | 25.2       |
| times/timestep_after_hook      | 0.00352    |
| times/timestep_before_hook     | 0.00785    |
| times/train                    | 55.2       |
| timestep                       | 1000       |
| timesteps_total                | 139000     |
| train-steps                    | 139000     |
| training/Q/q1_loss             | 85.12417   |
| training/sac_pi/alpha          | 0.15383306 |
| training/sac_pi/alpha_loss     | 0.2851892  |
| training/sac_pi/logp_pi        | 4.357802   |
| training/sac_pi/pi_entropy     | 3.5491028  |
| training/sac_pi/pi_global_norm | 1.6760795  |
| training/sac_pi/policy_loss    | -184.17955 |
| training/sac_pi/std            | 0.5077684  |
| training/sac_pi/valid_num      | 4961.0     |
| training/sac_Q/q1              | 175.91125  |
| training/sac_Q/q2              | 176.52989  |
| training/sac_Q/q2_loss         | 85.56554   |
| training/sac_Q/q_global_norm   | 176.30112  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15338583  |
| epoch                          | 139         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4915.2217   |
| evaluation/return-max          | 4964.4907   |
| evaluation/return-min          | 4894.3867   |
| evaluation/return-std          | 21.314056   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.8         |
| model/origin_ret               | 83.5        |
| model/penalty_ret              | 83.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45336       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4915.2217   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 178.29944   |
| Q-std                          | 98.001526   |
| Q_loss                         | 96.6811     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 139         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 472         |
| times/evaluation_metrics       | 0.000553    |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.00352     |
| times/timestep_before_hook     | 0.00792     |
| times/train                    | 56.1        |
| timestep                       | 1000        |
| timesteps_total                | 140000      |
| train-steps                    | 140000      |
| training/Q/q1_loss             | 106.413216  |
| training/sac_pi/alpha          | 0.15341356  |
| training/sac_pi/alpha_loss     | -0.24994712 |
| training/sac_pi/logp_pi        | 4.950072    |
| training/sac_pi/pi_entropy     | 3.6899147   |
| training/sac_pi/pi_global_norm | 1.2840548   |
| training/sac_pi/policy_loss    | -184.79762  |
| training/sac_pi/std            | 0.5526255   |
| training/sac_pi/valid_num      | 4841.0      |
| training/sac_Q/q1              | 170.60498   |
| training/sac_Q/q2              | 172.4626    |
| training/sac_Q/q2_loss         | 107.17241   |
| training/sac_Q/q_global_norm   | 228.79468   |
---------------------------------------------------------------------------------
[WARN] 140 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.15329845 |
| epoch                          | 140        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4958.9927  |
| evaluation/return-max          | 4998.435   |
| evaluation/return-min          | 4924.6553  |
| evaluation/return-std          | 23.18164   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 83.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45430      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4958.9927  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 168.64296  |
| Q-std                          | 107.775055 |
| Q_loss                         | 102.21476  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 140        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000561   |
| times/evaluation_paths         | 31.7       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00785    |
| times/train                    | 56.1       |
| timestep                       | 1000       |
| timesteps_total                | 141000     |
| train-steps                    | 141000     |
| training/Q/q1_loss             | 89.80148   |
| training/sac_pi/alpha          | 0.15327951 |
| training/sac_pi/alpha_loss     | 0.13635187 |
| training/sac_pi/logp_pi        | 4.388614   |
| training/sac_pi/pi_entropy     | 3.4948082  |
| training/sac_pi/pi_global_norm | 1.2722505  |
| training/sac_pi/policy_loss    | -185.47592 |
| training/sac_pi/std            | 0.5107502  |
| training/sac_pi/valid_num      | 4972.0     |
| training/sac_Q/q1              | 176.23987  |
| training/sac_Q/q2              | 177.70071  |
| training/sac_Q/q2_loss         | 90.294426  |
| training/sac_Q/q_global_norm   | 367.00912  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1568385  |
| epoch                          | 141        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4652.571   |
| evaluation/return-max          | 4697.291   |
| evaluation/return-min          | 4620.339   |
| evaluation/return-std          | 29.747278  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.82       |
| model/origin_ret               | 82.8       |
| model/penalty_ret              | 83         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45576      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4652.571   |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 167.27145  |
| Q-std                          | 117.82994  |
| Q_loss                         | 85.71211   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 141        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000329   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000562   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 56.1       |
| timestep                       | 1000       |
| timesteps_total                | 142000     |
| train-steps                    | 142000     |
| training/Q/q1_loss             | 95.78321   |
| training/sac_pi/alpha          | 0.15685448 |
| training/sac_pi/alpha_loss     | 0.18163398 |
| training/sac_pi/logp_pi        | 4.3283634  |
| training/sac_pi/pi_entropy     | 3.447328   |
| training/sac_pi/pi_global_norm | 1.51341    |
| training/sac_pi/policy_loss    | -181.00284 |
| training/sac_pi/std            | 0.49282953 |
| training/sac_pi/valid_num      | 4986.0     |
| training/sac_Q/q1              | 174.6315   |
| training/sac_Q/q2              | 174.77524  |
| training/sac_Q/q2_loss         | 95.61344   |
| training/sac_Q/q_global_norm   | 283.32068  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15623593  |
| epoch                          | 142         |
| evaluation/episode-length-avg  | 305         |
| evaluation/episode-length-max  | 432         |
| evaluation/episode-length-min  | 250         |
| evaluation/episode-length-std  | 64.4        |
| evaluation/return-average      | 1252.0242   |
| evaluation/return-max          | 1923.3986   |
| evaluation/return-min          | 957.8799    |
| evaluation/return-std          | 334.9873    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45561       |
| perf/AverageLength             | 305         |
| perf/AverageReturn             | 1252.0242   |
| perf/NormalizedReturn          | 0.272       |
| Q-avg                          | 173.87527   |
| Q-std                          | 99.34723    |
| Q_loss                         | 88.5256     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 142         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000115    |
| times/epoch_rollout_model      | 474         |
| times/evaluation_metrics       | 0.000472    |
| times/evaluation_paths         | 9.3         |
| times/timestep_after_hook      | 0.00348     |
| times/timestep_before_hook     | 0.00792     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 143000      |
| train-steps                    | 143000      |
| training/Q/q1_loss             | 93.812004   |
| training/sac_pi/alpha          | 0.15626997  |
| training/sac_pi/alpha_loss     | -0.16422774 |
| training/sac_pi/logp_pi        | 5.811118    |
| training/sac_pi/pi_entropy     | 3.733667    |
| training/sac_pi/pi_global_norm | 1.7464235   |
| training/sac_pi/policy_loss    | -173.58589  |
| training/sac_pi/std            | 0.58124834  |
| training/sac_pi/valid_num      | 4852.0      |
| training/sac_Q/q1              | 155.37637   |
| training/sac_Q/q2              | 158.19357   |
| training/sac_Q/q2_loss         | 93.96759    |
| training/sac_Q/q_global_norm   | 197.16872   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15680858  |
| epoch                          | 143         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4587.2427   |
| evaluation/return-max          | 4606.74     |
| evaluation/return-min          | 4537.3447   |
| evaluation/return-std          | 24.031118   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 82.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45436       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4587.2427   |
| perf/NormalizedReturn          | 0.999       |
| Q-avg                          | 178.16458   |
| Q-std                          | 102.57979   |
| Q_loss                         | 101.563385  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 143         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000101    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000574    |
| times/evaluation_paths         | 30.4        |
| times/timestep_after_hook      | 0.00381     |
| times/timestep_before_hook     | 0.00832     |
| times/train                    | 57.5        |
| timestep                       | 1000        |
| timesteps_total                | 144000      |
| train-steps                    | 144000      |
| training/Q/q1_loss             | 92.88038    |
| training/sac_pi/alpha          | 0.15680489  |
| training/sac_pi/alpha_loss     | -0.04179863 |
| training/sac_pi/logp_pi        | 4.8875494   |
| training/sac_pi/pi_entropy     | 3.574017    |
| training/sac_pi/pi_global_norm | 1.6523998   |
| training/sac_pi/policy_loss    | -182.67644  |
| training/sac_pi/std            | 0.5245058   |
| training/sac_pi/valid_num      | 4953.0      |
| training/sac_Q/q1              | 170.2834    |
| training/sac_Q/q2              | 173.07475   |
| training/sac_Q/q2_loss         | 92.68958    |
| training/sac_Q/q_global_norm   | 197.80814   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15285851 |
| epoch                          | 144        |
| evaluation/episode-length-avg  | 914        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 142        |
| evaluation/episode-length-std  | 257        |
| evaluation/return-average      | 4042.5188  |
| evaluation/return-max          | 4468.8896  |
| evaluation/return-min          | 404.61884  |
| evaluation/return-std          | 1212.7117  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 83         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45548      |
| perf/AverageLength             | 914        |
| perf/AverageReturn             | 4042.5188  |
| perf/NormalizedReturn          | 0.88       |
| Q-avg                          | 170.1594   |
| Q-std                          | 116.75949  |
| Q_loss                         | 98.15082   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 144        |
| times/epoch_after_hook         | 1.97e-06   |
| times/epoch_before_hook        | 0.000103   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000568   |
| times/evaluation_paths         | 27.7       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00799    |
| times/train                    | 56.8       |
| timestep                       | 1000       |
| timesteps_total                | 145000     |
| train-steps                    | 145000     |
| training/Q/q1_loss             | 79.91877   |
| training/sac_pi/alpha          | 0.15286054 |
| training/sac_pi/alpha_loss     | -0.3511415 |
| training/sac_pi/logp_pi        | 4.182254   |
| training/sac_pi/pi_entropy     | 3.4634366  |
| training/sac_pi/pi_global_norm | 1.288946   |
| training/sac_pi/policy_loss    | -177.56232 |
| training/sac_pi/std            | 0.5027868  |
| training/sac_pi/valid_num      | 4971.0     |
| training/sac_Q/q1              | 167.75131  |
| training/sac_Q/q2              | 168.77982  |
| training/sac_Q/q2_loss         | 79.58216   |
| training/sac_Q/q_global_norm   | 249.4087   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14649808  |
| epoch                          | 145         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4966.298    |
| evaluation/return-max          | 5004.641    |
| evaluation/return-min          | 4920.412    |
| evaluation/return-std          | 27.944942   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 83.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45491       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4966.298    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 173.96997   |
| Q-std                          | 106.39028   |
| Q_loss                         | 103.97875   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 145         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000273    |
| times/epoch_rollout_model      | 474         |
| times/evaluation_metrics       | 0.000568    |
| times/evaluation_paths         | 31.5        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 58          |
| timestep                       | 1000        |
| timesteps_total                | 146000      |
| train-steps                    | 146000      |
| training/Q/q1_loss             | 98.59081    |
| training/sac_pi/alpha          | 0.14648972  |
| training/sac_pi/alpha_loss     | -0.09389101 |
| training/sac_pi/logp_pi        | 4.171986    |
| training/sac_pi/pi_entropy     | 3.4173203   |
| training/sac_pi/pi_global_norm | 1.4115788   |
| training/sac_pi/policy_loss    | -182.40926  |
| training/sac_pi/std            | 0.48504278  |
| training/sac_pi/valid_num      | 4995.0      |
| training/sac_Q/q1              | 175.01823   |
| training/sac_Q/q2              | 175.47781   |
| training/sac_Q/q2_loss         | 98.69729    |
| training/sac_Q/q_global_norm   | 271.4818    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14668262 |
| epoch                          | 146        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4920.9443  |
| evaluation/return-max          | 4973.143   |
| evaluation/return-min          | 4832.383   |
| evaluation/return-std          | 43.74029   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.81       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45375      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4920.9443  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 172.5821   |
| Q-std                          | 100.116844 |
| Q_loss                         | 89.3207    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 146        |
| times/epoch_after_hook         | 2.04e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 475        |
| times/evaluation_metrics       | 0.000512   |
| times/evaluation_paths         | 31.1       |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 57.4       |
| timestep                       | 1000       |
| timesteps_total                | 147000     |
| train-steps                    | 147000     |
| training/Q/q1_loss             | 96.014786  |
| training/sac_pi/alpha          | 0.14668937 |
| training/sac_pi/alpha_loss     | 0.17364134 |
| training/sac_pi/logp_pi        | 5.267209   |
| training/sac_pi/pi_entropy     | 3.4993591  |
| training/sac_pi/pi_global_norm | 1.5035468  |
| training/sac_pi/policy_loss    | -174.93105 |
| training/sac_pi/std            | 0.52699953 |
| training/sac_pi/valid_num      | 4867.0     |
| training/sac_Q/q1              | 158.21005  |
| training/sac_Q/q2              | 161.07053  |
| training/sac_Q/q2_loss         | 95.567085  |
| training/sac_Q/q_global_norm   | 238.08176  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15400653  |
| epoch                          | 147         |
| evaluation/episode-length-avg  | 783         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 536         |
| evaluation/episode-length-std  | 154         |
| evaluation/return-average      | 3785.4883   |
| evaluation/return-max          | 4951.513    |
| evaluation/return-min          | 2455.9565   |
| evaluation/return-std          | 826.2083    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.86        |
| model/origin_ret               | 82.8        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45773       |
| perf/AverageLength             | 783         |
| perf/AverageReturn             | 3785.4883   |
| perf/NormalizedReturn          | 0.824       |
| Q-avg                          | 182.27707   |
| Q-std                          | 94.10664    |
| Q_loss                         | 91.860374   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 147         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000647    |
| times/evaluation_paths         | 25.3        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 57          |
| timestep                       | 1000        |
| timesteps_total                | 148000      |
| train-steps                    | 148000      |
| training/Q/q1_loss             | 83.928604   |
| training/sac_pi/alpha          | 0.15399148  |
| training/sac_pi/alpha_loss     | -0.28398728 |
| training/sac_pi/logp_pi        | 4.40831     |
| training/sac_pi/pi_entropy     | 3.5838542   |
| training/sac_pi/pi_global_norm | 1.1479484   |
| training/sac_pi/policy_loss    | -192.12128  |
| training/sac_pi/std            | 0.51679957  |
| training/sac_pi/valid_num      | 4974.0      |
| training/sac_Q/q1              | 181.07993   |
| training/sac_Q/q2              | 182.73601   |
| training/sac_Q/q2_loss         | 83.082115   |
| training/sac_Q/q_global_norm   | 237.88953   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15083075   |
| epoch                          | 148          |
| evaluation/episode-length-avg  | 153          |
| evaluation/episode-length-max  | 157          |
| evaluation/episode-length-min  | 151          |
| evaluation/episode-length-std  | 2.21         |
| evaluation/return-average      | 494.82758    |
| evaluation/return-max          | 515.4711     |
| evaluation/return-min          | 480.1128     |
| evaluation/return-std          | 11.843521    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.93         |
| model/origin_ret               | 86.1         |
| model/penalty_ret              | 83.5         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45416        |
| perf/AverageLength             | 153          |
| perf/AverageReturn             | 494.82758    |
| perf/NormalizedReturn          | 0.107        |
| Q-avg                          | 174.1301     |
| Q-std                          | 105.7768     |
| Q_loss                         | 101.5285     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 148          |
| times/epoch_after_hook         | 1.68e-06     |
| times/epoch_before_hook        | 0.000137     |
| times/epoch_rollout_model      | 474          |
| times/evaluation_metrics       | 0.000434     |
| times/evaluation_paths         | 4.65         |
| times/timestep_after_hook      | 0.00383      |
| times/timestep_before_hook     | 0.00817      |
| times/train                    | 56.9         |
| timestep                       | 1000         |
| timesteps_total                | 149000       |
| train-steps                    | 149000       |
| training/Q/q1_loss             | 92.22666     |
| training/sac_pi/alpha          | 0.15086251   |
| training/sac_pi/alpha_loss     | 0.0064670066 |
| training/sac_pi/logp_pi        | 4.444367     |
| training/sac_pi/pi_entropy     | 3.6516304    |
| training/sac_pi/pi_global_norm | 1.3790807    |
| training/sac_pi/policy_loss    | -183.15407   |
| training/sac_pi/std            | 0.5188192    |
| training/sac_pi/valid_num      | 4965.0       |
| training/sac_Q/q1              | 175.47363    |
| training/sac_Q/q2              | 175.6105     |
| training/sac_Q/q2_loss         | 91.88761     |
| training/sac_Q/q_global_norm   | 218.05185    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15909176 |
| epoch                          | 149        |
| evaluation/episode-length-avg  | 571        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 136        |
| evaluation/episode-length-std  | 429        |
| evaluation/return-average      | 2872.2947  |
| evaluation/return-max          | 5325.292   |
| evaluation/return-min          | 444.9701   |
| evaluation/return-std          | 2410.952   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.8        |
| model/origin_ret               | 82.6       |
| model/penalty_ret              | 82.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45618      |
| perf/AverageLength             | 571        |
| perf/AverageReturn             | 2872.2947  |
| perf/NormalizedReturn          | 0.625      |
| Q-avg                          | 177.73785  |
| Q-std                          | 102.997055 |
| Q_loss                         | 94.2973    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 149        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000368   |
| times/epoch_rollout_model      | 474        |
| times/evaluation_metrics       | 0.000585   |
| times/evaluation_paths         | 18.2       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00846    |
| times/train                    | 58         |
| timestep                       | 1000       |
| timesteps_total                | 150000     |
| train-steps                    | 150000     |
| training/Q/q1_loss             | 90.907036  |
| training/sac_pi/alpha          | 0.15907803 |
| training/sac_pi/alpha_loss     | 0.2929844  |
| training/sac_pi/logp_pi        | 4.272381   |
| training/sac_pi/pi_entropy     | 3.6416023  |
| training/sac_pi/pi_global_norm | 1.3925884  |
| training/sac_pi/policy_loss    | -189.43724 |
| training/sac_pi/std            | 0.5039341  |
| training/sac_pi/valid_num      | 4991.0     |
| training/sac_Q/q1              | 182.5792   |
| training/sac_Q/q2              | 183.55219  |
| training/sac_Q/q2_loss         | 90.953995  |
| training/sac_Q/q_global_norm   | 254.35986  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16044037  |
| epoch                          | 150         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4824.552    |
| evaluation/return-max          | 4903.1006   |
| evaluation/return-min          | 4775.4272   |
| evaluation/return-std          | 38.83552    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45556       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4824.552    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 173.1537    |
| Q-std                          | 101.68461   |
| Q_loss                         | 113.73358   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 150         |
| times/epoch_after_hook         | 2.08e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 473         |
| times/evaluation_metrics       | 0.000624    |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.00386     |
| times/timestep_before_hook     | 0.00822     |
| times/train                    | 56.6        |
| timestep                       | 1000        |
| timesteps_total                | 151000      |
| train-steps                    | 151000      |
| training/Q/q1_loss             | 108.64401   |
| training/sac_pi/alpha          | 0.1605017   |
| training/sac_pi/alpha_loss     | -0.47325236 |
| training/sac_pi/logp_pi        | 5.065937    |
| training/sac_pi/pi_entropy     | 3.5595193   |
| training/sac_pi/pi_global_norm | 1.8407323   |
| training/sac_pi/policy_loss    | -188.95929  |
| training/sac_pi/std            | 0.53490484  |
| training/sac_pi/valid_num      | 4884.0      |
| training/sac_Q/q1              | 175.309     |
| training/sac_Q/q2              | 175.77184   |
| training/sac_Q/q2_loss         | 107.74641   |
| training/sac_Q/q_global_norm   | 229.84944   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16546394 |
| epoch                          | 151        |
| evaluation/episode-length-avg  | 702        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 342        |
| evaluation/episode-length-std  | 297        |
| evaluation/return-average      | 2972.6707  |
| evaluation/return-max          | 4433.613   |
| evaluation/return-min          | 1249.9775  |
| evaluation/return-std          | 1435.6914  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.85       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 82.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45298      |
| perf/AverageLength             | 702        |
| perf/AverageReturn             | 2972.6707  |
| perf/NormalizedReturn          | 0.647      |
| Q-avg                          | 173.70325  |
| Q-std                          | 102.97924  |
| Q_loss                         | 102.51945  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 151        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000506   |
| times/evaluation_paths         | 22.3       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 57.5       |
| timestep                       | 1000       |
| timesteps_total                | 152000     |
| train-steps                    | 152000     |
| training/Q/q1_loss             | 95.41026   |
| training/sac_pi/alpha          | 0.16542032 |
| training/sac_pi/alpha_loss     | 0.41346473 |
| training/sac_pi/logp_pi        | 4.206488   |
| training/sac_pi/pi_entropy     | 3.6227221  |
| training/sac_pi/pi_global_norm | 1.584738   |
| training/sac_pi/policy_loss    | -185.43332 |
| training/sac_pi/std            | 0.4935941  |
| training/sac_pi/valid_num      | 5032.0     |
| training/sac_Q/q1              | 180.88004  |
| training/sac_Q/q2              | 181.4155   |
| training/sac_Q/q2_loss         | 94.84747   |
| training/sac_Q/q_global_norm   | 282.43985  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15593067 |
| epoch                          | 152        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4677.0796  |
| evaluation/return-max          | 4736.7993  |
| evaluation/return-min          | 4635.3594  |
| evaluation/return-std          | 33.159943  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.86       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45268      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4677.0796  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 167.52994  |
| Q-std                          | 112.20746  |
| Q_loss                         | 87.93482   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 152        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 475        |
| times/evaluation_metrics       | 0.000549   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00801    |
| times/train                    | 56.2       |
| timestep                       | 1000       |
| timesteps_total                | 153000     |
| train-steps                    | 153000     |
| training/Q/q1_loss             | 99.499504  |
| training/sac_pi/alpha          | 0.15592206 |
| training/sac_pi/alpha_loss     | -0.4561575 |
| training/sac_pi/logp_pi        | 4.8072433  |
| training/sac_pi/pi_entropy     | 3.4353898  |
| training/sac_pi/pi_global_norm | 1.2576346  |
| training/sac_pi/policy_loss    | -184.47134 |
| training/sac_pi/std            | 0.5054193  |
| training/sac_pi/valid_num      | 4894.0     |
| training/sac_Q/q1              | 170.64673  |
| training/sac_Q/q2              | 171.32162  |
| training/sac_Q/q2_loss         | 99.68828   |
| training/sac_Q/q_global_norm   | 222.11159  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1561592  |
| epoch                          | 153        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4431.534   |
| evaluation/return-max          | 4486.2734  |
| evaluation/return-min          | 4314.5967  |
| evaluation/return-std          | 45.715435  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.81       |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45403      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4431.534   |
| perf/NormalizedReturn          | 0.965      |
| Q-avg                          | 175.42468  |
| Q-std                          | 106.74679  |
| Q_loss                         | 103.56338  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 153        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000283   |
| times/epoch_rollout_model      | 474        |
| times/evaluation_metrics       | 0.000558   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00356    |
| times/timestep_before_hook     | 0.008      |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 154000     |
| train-steps                    | 154000     |
| training/Q/q1_loss             | 99.28355   |
| training/sac_pi/alpha          | 0.1561609  |
| training/sac_pi/alpha_loss     | 0.39056525 |
| training/sac_pi/logp_pi        | 4.723702   |
| training/sac_pi/pi_entropy     | 3.6352425  |
| training/sac_pi/pi_global_norm | 1.5418415  |
| training/sac_pi/policy_loss    | -188.57437 |
| training/sac_pi/std            | 0.5091837  |
| training/sac_pi/valid_num      | 4976.0     |
| training/sac_Q/q1              | 180.09766  |
| training/sac_Q/q2              | 180.53394  |
| training/sac_Q/q2_loss         | 99.49139   |
| training/sac_Q/q_global_norm   | 215.14662  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1519837   |
| epoch                          | 154         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4786.392    |
| evaluation/return-max          | 4846.967    |
| evaluation/return-min          | 4604.963    |
| evaluation/return-std          | 71.25532    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 83          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45470       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4786.392    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 177.85432   |
| Q-std                          | 112.87994   |
| Q_loss                         | 95.90394    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 154         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 474         |
| times/evaluation_metrics       | 0.000653    |
| times/evaluation_paths         | 31.2        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00796     |
| times/train                    | 56.2        |
| timestep                       | 1000        |
| timesteps_total                | 155000      |
| train-steps                    | 155000      |
| training/Q/q1_loss             | 96.806366   |
| training/sac_pi/alpha          | 0.15201317  |
| training/sac_pi/alpha_loss     | 0.110807836 |
| training/sac_pi/logp_pi        | 4.5986624   |
| training/sac_pi/pi_entropy     | 3.4801967   |
| training/sac_pi/pi_global_norm | 1.5001689   |
| training/sac_pi/policy_loss    | -184.47504  |
| training/sac_pi/std            | 0.5062663   |
| training/sac_pi/valid_num      | 4954.0      |
| training/sac_Q/q1              | 175.0539    |
| training/sac_Q/q2              | 175.76154   |
| training/sac_Q/q2_loss         | 97.10822    |
| training/sac_Q/q_global_norm   | 286.97934   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16362712 |
| epoch                          | 155        |
| evaluation/episode-length-avg  | 915        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 147        |
| evaluation/episode-length-std  | 256        |
| evaluation/return-average      | 4223.61    |
| evaluation/return-max          | 4691.7607  |
| evaluation/return-min          | 378.13324  |
| evaluation/return-std          | 1282.0469  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.74       |
| model/origin_ret               | 82         |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45410      |
| perf/AverageLength             | 915        |
| perf/AverageReturn             | 4223.61    |
| perf/NormalizedReturn          | 0.92       |
| Q-avg                          | 186.69772  |
| Q-std                          | 84.40314   |
| Q_loss                         | 85.69176   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 155        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000617   |
| times/evaluation_paths         | 27.9       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 56.6       |
| timestep                       | 1000       |
| timesteps_total                | 156000     |
| train-steps                    | 156000     |
| training/Q/q1_loss             | 93.94716   |
| training/sac_pi/alpha          | 0.16358456 |
| training/sac_pi/alpha_loss     | 0.3211829  |
| training/sac_pi/logp_pi        | 5.120818   |
| training/sac_pi/pi_entropy     | 3.8145058  |
| training/sac_pi/pi_global_norm | 1.4003859  |
| training/sac_pi/policy_loss    | -191.97008 |
| training/sac_pi/std            | 0.54582506 |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 180.56369  |
| training/sac_Q/q2              | 181.45232  |
| training/sac_Q/q2_loss         | 93.80901   |
| training/sac_Q/q_global_norm   | 190.4466   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15777452 |
| epoch                          | 156        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4877.183   |
| evaluation/return-max          | 4908.119   |
| evaluation/return-min          | 4827.1816  |
| evaluation/return-std          | 27.706339  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 83.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45327      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4877.183   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 167.09966  |
| Q-std                          | 119.58986  |
| Q_loss                         | 89.61504   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 156        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 475        |
| times/evaluation_metrics       | 0.000585   |
| times/evaluation_paths         | 30.1       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.0079     |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 157000     |
| train-steps                    | 157000     |
| training/Q/q1_loss             | 83.50944   |
| training/sac_pi/alpha          | 0.1577861  |
| training/sac_pi/alpha_loss     | 0.08952684 |
| training/sac_pi/logp_pi        | 4.426451   |
| training/sac_pi/pi_entropy     | 3.4914832  |
| training/sac_pi/pi_global_norm | 1.2612789  |
| training/sac_pi/policy_loss    | -187.15181 |
| training/sac_pi/std            | 0.49659094 |
| training/sac_pi/valid_num      | 4962.0     |
| training/sac_Q/q1              | 177.86835  |
| training/sac_Q/q2              | 177.73975  |
| training/sac_Q/q2_loss         | 83.37213   |
| training/sac_Q/q_global_norm   | 202.09535  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15158173 |
| epoch                          | 157        |
| evaluation/episode-length-avg  | 895        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 351        |
| evaluation/episode-length-std  | 205        |
| evaluation/return-average      | 4044.14    |
| evaluation/return-max          | 4703.6885  |
| evaluation/return-min          | 1233.1647  |
| evaluation/return-std          | 1068.2498  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45365      |
| perf/AverageLength             | 895        |
| perf/AverageReturn             | 4044.14    |
| perf/NormalizedReturn          | 0.881      |
| Q-avg                          | 173.81827  |
| Q-std                          | 102.8991   |
| Q_loss                         | 94.67255   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 157        |
| times/epoch_after_hook         | 2.08e-06   |
| times/epoch_before_hook        | 0.000279   |
| times/epoch_rollout_model      | 473        |
| times/evaluation_metrics       | 0.000663   |
| times/evaluation_paths         | 27.8       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 56.4       |
| timestep                       | 1000       |
| timesteps_total                | 158000     |
| train-steps                    | 158000     |
| training/Q/q1_loss             | 95.63138   |
| training/sac_pi/alpha          | 0.15158294 |
| training/sac_pi/alpha_loss     | 0.13929059 |
| training/sac_pi/logp_pi        | 4.4206495  |
| training/sac_pi/pi_entropy     | 3.6136215  |
| training/sac_pi/pi_global_norm | 1.5832326  |
| training/sac_pi/policy_loss    | -184.73134 |
| training/sac_pi/std            | 0.5258792  |
| training/sac_pi/valid_num      | 4939.0     |
| training/sac_Q/q1              | 176.27249  |
| training/sac_Q/q2              | 176.21469  |
| training/sac_Q/q2_loss         | 95.37469   |
| training/sac_Q/q_global_norm   | 279.74295  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15842825 |
| epoch                          | 158        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4815.5474  |
| evaluation/return-max          | 4843.299   |
| evaluation/return-min          | 4796.2246  |
| evaluation/return-std          | 15.75164   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.85       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45590      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4815.5474  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 171.14394  |
| Q-std                          | 136.5766   |
| Q_loss                         | 113.02296  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 158        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 474        |
| times/evaluation_metrics       | 0.000588   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 57.1       |
| timestep                       | 1000       |
| timesteps_total                | 159000     |
| train-steps                    | 159000     |
| training/Q/q1_loss             | 108.63879  |
| training/sac_pi/alpha          | 0.158393   |
| training/sac_pi/alpha_loss     | 0.18006949 |
| training/sac_pi/logp_pi        | 4.2944994  |
| training/sac_pi/pi_entropy     | 3.6369255  |
| training/sac_pi/pi_global_norm | 1.4698685  |
| training/sac_pi/policy_loss    | -184.39365 |
| training/sac_pi/std            | 0.5068143  |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 175.43135  |
| training/sac_Q/q2              | 175.32628  |
| training/sac_Q/q2_loss         | 107.35628  |
| training/sac_Q/q_global_norm   | 335.2539   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1562806   |
| epoch                          | 159         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4796.433    |
| evaluation/return-max          | 4854.022    |
| evaluation/return-min          | 4757.751    |
| evaluation/return-std          | 24.777927   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 82.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45706       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4796.433    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 168.93347   |
| Q-std                          | 122.13969   |
| Q_loss                         | 101.69491   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 159         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000108    |
| times/epoch_rollout_model      | 473         |
| times/evaluation_metrics       | 0.000506    |
| times/evaluation_paths         | 30.4        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 56.4        |
| timestep                       | 1000        |
| timesteps_total                | 160000      |
| train-steps                    | 160000      |
| training/Q/q1_loss             | 108.5221    |
| training/sac_pi/alpha          | 0.1562865   |
| training/sac_pi/alpha_loss     | 0.068753324 |
| training/sac_pi/logp_pi        | 5.0320015   |
| training/sac_pi/pi_entropy     | 3.5771713   |
| training/sac_pi/pi_global_norm | 1.6403157   |
| training/sac_pi/policy_loss    | -188.49654  |
| training/sac_pi/std            | 0.53955853  |
| training/sac_pi/valid_num      | 4915.0      |
| training/sac_Q/q1              | 178.11824   |
| training/sac_Q/q2              | 176.72476   |
| training/sac_Q/q2_loss         | 108.73606   |
| training/sac_Q/q_global_norm   | 242.60533   |
---------------------------------------------------------------------------------
[WARN] 160 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.1564191   |
| epoch                          | 160         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4754.0796   |
| evaluation/return-max          | 4777.169    |
| evaluation/return-min          | 4713.4033   |
| evaluation/return-std          | 19.46432    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.79        |
| model/origin_ret               | 83.1        |
| model/penalty_ret              | 82.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45393       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4754.0796   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 175.12773   |
| Q-std                          | 111.20371   |
| Q_loss                         | 96.01832    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 160         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 475         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 29.9        |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.00801     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 161000      |
| train-steps                    | 161000      |
| training/Q/q1_loss             | 81.99825    |
| training/sac_pi/alpha          | 0.15642162  |
| training/sac_pi/alpha_loss     | -0.04946233 |
| training/sac_pi/logp_pi        | 4.0892243   |
| training/sac_pi/pi_entropy     | 3.4461327   |
| training/sac_pi/pi_global_norm | 1.299109    |
| training/sac_pi/policy_loss    | -193.35239  |
| training/sac_pi/std            | 0.48772123  |
| training/sac_pi/valid_num      | 4958.0      |
| training/sac_Q/q1              | 184.76245   |
| training/sac_Q/q2              | 185.44913   |
| training/sac_Q/q2_loss         | 81.504326   |
| training/sac_Q/q_global_norm   | 326.7599    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15894781 |
| epoch                          | 161        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4653.292   |
| evaluation/return-max          | 4714.875   |
| evaluation/return-min          | 4583.8125  |
| evaluation/return-std          | 35.15602   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45715      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4653.292   |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 178.80846  |
| Q-std                          | 92.40636   |
| Q_loss                         | 107.486084 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 161        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.00028    |
| times/epoch_rollout_model      | 474        |
| times/evaluation_metrics       | 0.000532   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 57.4       |
| timestep                       | 1000       |
| timesteps_total                | 162000     |
| train-steps                    | 162000     |
| training/Q/q1_loss             | 94.10754   |
| training/sac_pi/alpha          | 0.15895845 |
| training/sac_pi/alpha_loss     | -0.4098051 |
| training/sac_pi/logp_pi        | 4.4708114  |
| training/sac_pi/pi_entropy     | 3.699019   |
| training/sac_pi/pi_global_norm | 1.2675115  |
| training/sac_pi/policy_loss    | -187.35732 |
| training/sac_pi/std            | 0.54374045 |
| training/sac_pi/valid_num      | 4920.0     |
| training/sac_Q/q1              | 174.73528  |
| training/sac_Q/q2              | 175.12187  |
| training/sac_Q/q2_loss         | 93.63517   |
| training/sac_Q/q_global_norm   | 174.50584  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16232292  |
| epoch                          | 162         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4627.6997   |
| evaluation/return-max          | 4705.526    |
| evaluation/return-min          | 4537.7637   |
| evaluation/return-std          | 47.287006   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.82        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 83.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45236       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4627.6997   |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 170.78549   |
| Q-std                          | 119.16483   |
| Q_loss                         | 84.43928    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 162         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000102    |
| times/epoch_rollout_model      | 471         |
| times/evaluation_metrics       | 0.000576    |
| times/evaluation_paths         | 31.4        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00779     |
| times/train                    | 55.4        |
| timestep                       | 1000        |
| timesteps_total                | 163000      |
| train-steps                    | 163000      |
| training/Q/q1_loss             | 112.834335  |
| training/sac_pi/alpha          | 0.16229543  |
| training/sac_pi/alpha_loss     | 0.005151488 |
| training/sac_pi/logp_pi        | 4.472222    |
| training/sac_pi/pi_entropy     | 3.8593793   |
| training/sac_pi/pi_global_norm | 1.2652416   |
| training/sac_pi/policy_loss    | -186.9726   |
| training/sac_pi/std            | 0.538192    |
| training/sac_pi/valid_num      | 4851.0      |
| training/sac_Q/q1              | 175.01053   |
| training/sac_Q/q2              | 174.07526   |
| training/sac_Q/q2_loss         | 113.46298   |
| training/sac_Q/q_global_norm   | 361.5141    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15986656 |
| epoch                          | 163        |
| evaluation/episode-length-avg  | 926        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 573        |
| evaluation/episode-length-std  | 150        |
| evaluation/return-average      | 4179.2876  |
| evaluation/return-max          | 4628.363   |
| evaluation/return-min          | 2414.4905  |
| evaluation/return-std          | 743.1264   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 82.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45466      |
| perf/AverageLength             | 926        |
| perf/AverageReturn             | 4179.2876  |
| perf/NormalizedReturn          | 0.91       |
| Q-avg                          | 174.50583  |
| Q-std                          | 104.230225 |
| Q_loss                         | 102.86125  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 163        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 473        |
| times/evaluation_metrics       | 0.000558   |
| times/evaluation_paths         | 28         |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 56.3       |
| timestep                       | 1000       |
| timesteps_total                | 164000     |
| train-steps                    | 164000     |
| training/Q/q1_loss             | 115.37928  |
| training/sac_pi/alpha          | 0.15985416 |
| training/sac_pi/alpha_loss     | 0.09804941 |
| training/sac_pi/logp_pi        | 4.701393   |
| training/sac_pi/pi_entropy     | 3.7402618  |
| training/sac_pi/pi_global_norm | 1.506242   |
| training/sac_pi/policy_loss    | -179.01225 |
| training/sac_pi/std            | 0.53315467 |
| training/sac_pi/valid_num      | 4917.0     |
| training/sac_Q/q1              | 169.46696  |
| training/sac_Q/q2              | 168.61612  |
| training/sac_Q/q2_loss         | 114.85306  |
| training/sac_Q/q_global_norm   | 311.01187  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16224273 |
| epoch                          | 164        |
| evaluation/episode-length-avg  | 904        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 500        |
| evaluation/episode-length-std  | 167        |
| evaluation/return-average      | 3988.1047  |
| evaluation/return-max          | 4558.361   |
| evaluation/return-min          | 1988.736   |
| evaluation/return-std          | 814.5104   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.85       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45422      |
| perf/AverageLength             | 904        |
| perf/AverageReturn             | 3988.1047  |
| perf/NormalizedReturn          | 0.868      |
| Q-avg                          | 183.8365   |
| Q-std                          | 78.17031   |
| Q_loss                         | 79.940285  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 164        |
| times/epoch_after_hook         | 2.18e-06   |
| times/epoch_before_hook        | 0.000108   |
| times/epoch_rollout_model      | 473        |
| times/evaluation_metrics       | 0.000643   |
| times/evaluation_paths         | 27.8       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 57.2       |
| timestep                       | 1000       |
| timesteps_total                | 165000     |
| train-steps                    | 165000     |
| training/Q/q1_loss             | 117.89896  |
| training/sac_pi/alpha          | 0.16221498 |
| training/sac_pi/alpha_loss     | 0.32926777 |
| training/sac_pi/logp_pi        | 4.649642   |
| training/sac_pi/pi_entropy     | 3.5966804  |
| training/sac_pi/pi_global_norm | 1.5221496  |
| training/sac_pi/policy_loss    | -183.94113 |
| training/sac_pi/std            | 0.51186365 |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 172.71046  |
| training/sac_Q/q2              | 173.20833  |
| training/sac_Q/q2_loss         | 117.59429  |
| training/sac_Q/q_global_norm   | 242.9934   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15654737 |
| epoch                          | 165        |
| evaluation/episode-length-avg  | 407        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 148        |
| evaluation/episode-length-std  | 388        |
| evaluation/return-average      | 1798.1975  |
| evaluation/return-max          | 4889.6025  |
| evaluation/return-min          | 465.32288  |
| evaluation/return-std          | 2003.0222  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.84       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 82.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45446      |
| perf/AverageLength             | 407        |
| perf/AverageReturn             | 1798.1975  |
| perf/NormalizedReturn          | 0.391      |
| Q-avg                          | 176.11948  |
| Q-std                          | 101.456566 |
| Q_loss                         | 112.819595 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 165        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000278   |
| times/epoch_rollout_model      | 473        |
| times/evaluation_metrics       | 0.000476   |
| times/evaluation_paths         | 12.2       |
| times/timestep_after_hook      | 0.00375    |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 166000     |
| train-steps                    | 166000     |
| training/Q/q1_loss             | 98.08902   |
| training/sac_pi/alpha          | 0.15653889 |
| training/sac_pi/alpha_loss     | -0.1460054 |
| training/sac_pi/logp_pi        | 4.7005105  |
| training/sac_pi/pi_entropy     | 3.5115657  |
| training/sac_pi/pi_global_norm | 1.408538   |
| training/sac_pi/policy_loss    | -183.44067 |
| training/sac_pi/std            | 0.50913346 |
| training/sac_pi/valid_num      | 4912.0     |
| training/sac_Q/q1              | 172.39078  |
| training/sac_Q/q2              | 172.61986  |
| training/sac_Q/q2_loss         | 97.27542   |
| training/sac_Q/q_global_norm   | 283.80502  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15738347 |
| epoch                          | 166        |
| evaluation/episode-length-avg  | 855        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 267        |
| evaluation/episode-length-std  | 290        |
| evaluation/return-average      | 3772.9956  |
| evaluation/return-max          | 4550.1514  |
| evaluation/return-min          | 839.31146  |
| evaluation/return-std          | 1455.9656  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 82.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45477      |
| perf/AverageLength             | 855        |
| perf/AverageReturn             | 3772.9956  |
| perf/NormalizedReturn          | 0.822      |
| Q-avg                          | 159.0135   |
| Q-std                          | 128.55083  |
| Q_loss                         | 119.315186 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 166        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000102   |
| times/epoch_rollout_model      | 474        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 26.4       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00786    |
| times/train                    | 55.5       |
| timestep                       | 1000       |
| timesteps_total                | 167000     |
| train-steps                    | 167000     |
| training/Q/q1_loss             | 93.44106   |
| training/sac_pi/alpha          | 0.15738855 |
| training/sac_pi/alpha_loss     | 0.14623463 |
| training/sac_pi/logp_pi        | 4.8386526  |
| training/sac_pi/pi_entropy     | 3.519621   |
| training/sac_pi/pi_global_norm | 1.2071322  |
| training/sac_pi/policy_loss    | -187.22299 |
| training/sac_pi/std            | 0.5211155  |
| training/sac_pi/valid_num      | 4951.0     |
| training/sac_Q/q1              | 175.94246  |
| training/sac_Q/q2              | 177.22395  |
| training/sac_Q/q2_loss         | 93.075905  |
| training/sac_Q/q_global_norm   | 178.97882  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.158636    |
| epoch                          | 167         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5134.449    |
| evaluation/return-max          | 5186.8516   |
| evaluation/return-min          | 5097.0103   |
| evaluation/return-std          | 27.073975   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.86        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45707       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5134.449    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 172.58528   |
| Q-std                          | 111.61682   |
| Q_loss                         | 104.66915   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 167         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 473         |
| times/evaluation_metrics       | 0.000568    |
| times/evaluation_paths         | 31.3        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 57.7        |
| timestep                       | 1000        |
| timesteps_total                | 168000      |
| train-steps                    | 168000      |
| training/Q/q1_loss             | 89.30892    |
| training/sac_pi/alpha          | 0.15863355  |
| training/sac_pi/alpha_loss     | -0.15914056 |
| training/sac_pi/logp_pi        | 4.075273    |
| training/sac_pi/pi_entropy     | 3.5580018   |
| training/sac_pi/pi_global_norm | 1.88757     |
| training/sac_pi/policy_loss    | -190.68117  |
| training/sac_pi/std            | 0.51245296  |
| training/sac_pi/valid_num      | 4925.0      |
| training/sac_Q/q1              | 180.97897   |
| training/sac_Q/q2              | 181.54587   |
| training/sac_Q/q2_loss         | 89.83896    |
| training/sac_Q/q_global_norm   | 214.42638   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15840544   |
| epoch                          | 168          |
| evaluation/episode-length-avg  | 849          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 238          |
| evaluation/episode-length-std  | 303          |
| evaluation/return-average      | 4000.3047    |
| evaluation/return-max          | 4815.8574    |
| evaluation/return-min          | 776.1655     |
| evaluation/return-std          | 1596.7706    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.93         |
| model/origin_ret               | 84           |
| model/penalty_ret              | 82.1         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45840        |
| perf/AverageLength             | 849          |
| perf/AverageReturn             | 4000.3047    |
| perf/NormalizedReturn          | 0.871        |
| Q-avg                          | 178.24992    |
| Q-std                          | 87.97531     |
| Q_loss                         | 101.52403    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 168          |
| times/epoch_after_hook         | 1.79e-06     |
| times/epoch_before_hook        | 0.00012      |
| times/epoch_rollout_model      | 477          |
| times/evaluation_metrics       | 0.000565     |
| times/evaluation_paths         | 26.5         |
| times/timestep_after_hook      | 0.00391      |
| times/timestep_before_hook     | 0.00819      |
| times/train                    | 57.3         |
| timestep                       | 1000         |
| timesteps_total                | 169000       |
| train-steps                    | 169000       |
| training/Q/q1_loss             | 104.66682    |
| training/sac_pi/alpha          | 0.15843803   |
| training/sac_pi/alpha_loss     | 0.0019105386 |
| training/sac_pi/logp_pi        | 4.7896986    |
| training/sac_pi/pi_entropy     | 3.5722802    |
| training/sac_pi/pi_global_norm | 1.5527225    |
| training/sac_pi/policy_loss    | -186.83484   |
| training/sac_pi/std            | 0.5194601    |
| training/sac_pi/valid_num      | 4946.0       |
| training/sac_Q/q1              | 175.01184    |
| training/sac_Q/q2              | 175.66246    |
| training/sac_Q/q2_loss         | 104.84472    |
| training/sac_Q/q_global_norm   | 215.6928     |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16004263  |
| epoch                          | 169         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4488.585    |
| evaluation/return-max          | 4602.1113   |
| evaluation/return-min          | 4446.45     |
| evaluation/return-std          | 50.76789    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 82.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45630       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4488.585    |
| perf/NormalizedReturn          | 0.977       |
| Q-avg                          | 168.7806    |
| Q-std                          | 115.752975  |
| Q_loss                         | 90.75161    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 169         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000286    |
| times/epoch_rollout_model      | 476         |
| times/evaluation_metrics       | 0.000687    |
| times/evaluation_paths         | 31.7        |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.00833     |
| times/train                    | 57.9        |
| timestep                       | 1000        |
| timesteps_total                | 170000      |
| train-steps                    | 170000      |
| training/Q/q1_loss             | 85.396706   |
| training/sac_pi/alpha          | 0.16004686  |
| training/sac_pi/alpha_loss     | -0.14080434 |
| training/sac_pi/logp_pi        | 3.6875396   |
| training/sac_pi/pi_entropy     | 3.6736138   |
| training/sac_pi/pi_global_norm | 1.312452    |
| training/sac_pi/policy_loss    | -187.86313  |
| training/sac_pi/std            | 0.49455678  |
| training/sac_pi/valid_num      | 5007.0      |
| training/sac_Q/q1              | 182.53262   |
| training/sac_Q/q2              | 183.03555   |
| training/sac_Q/q2_loss         | 85.95192    |
| training/sac_Q/q_global_norm   | 230.85144   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1636177  |
| epoch                          | 170        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5062.374   |
| evaluation/return-max          | 5080.88    |
| evaluation/return-min          | 5036.8545  |
| evaluation/return-std          | 15.327373  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.81       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 83.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45278      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5062.374   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 175.10535  |
| Q-std                          | 87.06432   |
| Q_loss                         | 113.14864  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 170        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000544   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00354    |
| times/timestep_before_hook     | 0.00802    |
| times/train                    | 55.4       |
| timestep                       | 1000       |
| timesteps_total                | 171000     |
| train-steps                    | 171000     |
| training/Q/q1_loss             | 80.623314  |
| training/sac_pi/alpha          | 0.16364072 |
| training/sac_pi/alpha_loss     | 0.11998779 |
| training/sac_pi/logp_pi        | 5.2577963  |
| training/sac_pi/pi_entropy     | 3.833897   |
| training/sac_pi/pi_global_norm | 1.3223885  |
| training/sac_pi/policy_loss    | -191.14175 |
| training/sac_pi/std            | 0.56909275 |
| training/sac_pi/valid_num      | 4849.0     |
| training/sac_Q/q1              | 174.52376  |
| training/sac_Q/q2              | 175.0156   |
| training/sac_Q/q2_loss         | 80.43208   |
| training/sac_Q/q_global_norm   | 281.71985  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15862827  |
| epoch                          | 171         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4540.1963   |
| evaluation/return-max          | 4579.664    |
| evaluation/return-min          | 4507.7705   |
| evaluation/return-std          | 21.581453   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 83.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45510       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4540.1963   |
| perf/NormalizedReturn          | 0.989       |
| Q-avg                          | 186.96986   |
| Q-std                          | 101.425514  |
| Q_loss                         | 101.21014   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 171         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000585    |
| times/evaluation_paths         | 30.3        |
| times/timestep_after_hook      | 0.00378     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 56.6        |
| timestep                       | 1000        |
| timesteps_total                | 172000      |
| train-steps                    | 172000      |
| training/Q/q1_loss             | 99.89252    |
| training/sac_pi/alpha          | 0.15863124  |
| training/sac_pi/alpha_loss     | -0.20616278 |
| training/sac_pi/logp_pi        | 3.9253907   |
| training/sac_pi/pi_entropy     | 3.6740906   |
| training/sac_pi/pi_global_norm | 1.4841238   |
| training/sac_pi/policy_loss    | -181.6226   |
| training/sac_pi/std            | 0.5021598   |
| training/sac_pi/valid_num      | 4987.0      |
| training/sac_Q/q1              | 175.06734   |
| training/sac_Q/q2              | 175.6254    |
| training/sac_Q/q2_loss         | 99.854774   |
| training/sac_Q/q_global_norm   | 184.667     |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15238589 |
| epoch                          | 172        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4782.728   |
| evaluation/return-max          | 4854.6514  |
| evaluation/return-min          | 4729.31    |
| evaluation/return-std          | 44.372448  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.85       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 82.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45470      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4782.728   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 165.62613  |
| Q-std                          | 123.09139  |
| Q_loss                         | 95.21107   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 172        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000107   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000591   |
| times/evaluation_paths         | 31.7       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 58         |
| timestep                       | 1000       |
| timesteps_total                | 173000     |
| train-steps                    | 173000     |
| training/Q/q1_loss             | 100.41545  |
| training/sac_pi/alpha          | 0.15235844 |
| training/sac_pi/alpha_loss     | 0.2870002  |
| training/sac_pi/logp_pi        | 4.3458986  |
| training/sac_pi/pi_entropy     | 3.6185124  |
| training/sac_pi/pi_global_norm | 1.613171   |
| training/sac_pi/policy_loss    | -181.59917 |
| training/sac_pi/std            | 0.5028173  |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 173.76468  |
| training/sac_Q/q2              | 173.68259  |
| training/sac_Q/q2_loss         | 100.505974 |
| training/sac_Q/q_global_norm   | 276.8634   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15261549 |
| epoch                          | 173        |
| evaluation/episode-length-avg  | 829        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 143        |
| evaluation/episode-length-std  | 342        |
| evaluation/return-average      | 3923.7375  |
| evaluation/return-max          | 4853.3315  |
| evaluation/return-min          | 438.6904   |
| evaluation/return-std          | 1739.7042  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.87       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45441      |
| perf/AverageLength             | 829        |
| perf/AverageReturn             | 3923.7375  |
| perf/NormalizedReturn          | 0.854      |
| Q-avg                          | 173.47993  |
| Q-std                          | 113.540726 |
| Q_loss                         | 87.42004   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 173        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000278   |
| times/epoch_rollout_model      | 473        |
| times/evaluation_metrics       | 0.000543   |
| times/evaluation_paths         | 26.1       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 174000     |
| train-steps                    | 174000     |
| training/Q/q1_loss             | 90.59375   |
| training/sac_pi/alpha          | 0.15257117 |
| training/sac_pi/alpha_loss     | 0.2981027  |
| training/sac_pi/logp_pi        | 4.1802225  |
| training/sac_pi/pi_entropy     | 3.6314247  |
| training/sac_pi/pi_global_norm | 1.4465795  |
| training/sac_pi/policy_loss    | -176.86006 |
| training/sac_pi/std            | 0.4998679  |
| training/sac_pi/valid_num      | 4972.0     |
| training/sac_Q/q1              | 169.11148  |
| training/sac_Q/q2              | 169.99101  |
| training/sac_Q/q2_loss         | 90.08874   |
| training/sac_Q/q_global_norm   | 242.4181   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.156439   |
| epoch                          | 174        |
| evaluation/episode-length-avg  | 642        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 219        |
| evaluation/episode-length-std  | 232        |
| evaluation/return-average      | 2834.9023  |
| evaluation/return-max          | 4737.0737  |
| evaluation/return-min          | 704.3071   |
| evaluation/return-std          | 1193.8282  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45431      |
| perf/AverageLength             | 642        |
| perf/AverageReturn             | 2834.9023  |
| perf/NormalizedReturn          | 0.617      |
| Q-avg                          | 169.88718  |
| Q-std                          | 122.61627  |
| Q_loss                         | 104.10764  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 174        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000168   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000643   |
| times/evaluation_paths         | 20.4       |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 58         |
| timestep                       | 1000       |
| timesteps_total                | 175000     |
| train-steps                    | 175000     |
| training/Q/q1_loss             | 102.27103  |
| training/sac_pi/alpha          | 0.15645052 |
| training/sac_pi/alpha_loss     | 0.18701445 |
| training/sac_pi/logp_pi        | 4.9262023  |
| training/sac_pi/pi_entropy     | 3.5845604  |
| training/sac_pi/pi_global_norm | 1.3670952  |
| training/sac_pi/policy_loss    | -182.9766  |
| training/sac_pi/std            | 0.52450716 |
| training/sac_pi/valid_num      | 4938.0     |
| training/sac_Q/q1              | 170.69626  |
| training/sac_Q/q2              | 169.58316  |
| training/sac_Q/q2_loss         | 102.28006  |
| training/sac_Q/q_global_norm   | 299.14893  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15500078  |
| epoch                          | 175         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4861.094    |
| evaluation/return-max          | 4901.8574   |
| evaluation/return-min          | 4799.4346   |
| evaluation/return-std          | 29.007668   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45811       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4861.094    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 181.68875   |
| Q-std                          | 92.0654     |
| Q_loss                         | 86.808846   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 175         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 476         |
| times/evaluation_metrics       | 0.0006      |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.00832     |
| times/train                    | 57.8        |
| timestep                       | 1000        |
| timesteps_total                | 176000      |
| train-steps                    | 176000      |
| training/Q/q1_loss             | 93.37221    |
| training/sac_pi/alpha          | 0.15500079  |
| training/sac_pi/alpha_loss     | -0.45987263 |
| training/sac_pi/logp_pi        | 4.209706    |
| training/sac_pi/pi_entropy     | 3.5827427   |
| training/sac_pi/pi_global_norm | 1.7798327   |
| training/sac_pi/policy_loss    | -178.40778  |
| training/sac_pi/std            | 0.5110534   |
| training/sac_pi/valid_num      | 4976.0      |
| training/sac_Q/q1              | 168.5906    |
| training/sac_Q/q2              | 168.15132   |
| training/sac_Q/q2_loss         | 93.682785   |
| training/sac_Q/q_global_norm   | 250.38084   |
---------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.15350169    |
| epoch                          | 176           |
| evaluation/episode-length-avg  | 411           |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 152           |
| evaluation/episode-length-std  | 386           |
| evaluation/return-average      | 1618.4452     |
| evaluation/return-max          | 4524.0244     |
| evaluation/return-min          | 368.23535     |
| evaluation/return-std          | 1882.0886     |
| model/max_penalty              | 7.34          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 2.87          |
| model/origin_ret               | 84.7          |
| model/penalty_ret              | 82.6          |
| model/val_loss                 | 0.35430613    |
| model/valid_num                | 45547         |
| perf/AverageLength             | 411           |
| perf/AverageReturn             | 1618.4452     |
| perf/NormalizedReturn          | 0.352         |
| Q-avg                          | 172.3286      |
| Q-std                          | 118.733955    |
| Q_loss                         | 81.095795     |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 176           |
| times/epoch_after_hook         | 1.91e-06      |
| times/epoch_before_hook        | 0.000128      |
| times/epoch_rollout_model      | 476           |
| times/evaluation_metrics       | 0.000487      |
| times/evaluation_paths         | 12.6          |
| times/timestep_after_hook      | 0.00375       |
| times/timestep_before_hook     | 0.00812       |
| times/train                    | 56.2          |
| timestep                       | 1000          |
| timesteps_total                | 177000        |
| train-steps                    | 177000        |
| training/Q/q1_loss             | 89.81926      |
| training/sac_pi/alpha          | 0.15351237    |
| training/sac_pi/alpha_loss     | -0.0001619888 |
| training/sac_pi/logp_pi        | 5.227355      |
| training/sac_pi/pi_entropy     | 3.576908      |
| training/sac_pi/pi_global_norm | 1.3722088     |
| training/sac_pi/policy_loss    | -180.60149    |
| training/sac_pi/std            | 0.5252533     |
| training/sac_pi/valid_num      | 4957.0        |
| training/sac_Q/q1              | 165.20901     |
| training/sac_Q/q2              | 165.61443     |
| training/sac_Q/q2_loss         | 90.27954      |
| training/sac_Q/q_global_norm   | 321.0107      |
-----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15402064  |
| epoch                          | 177         |
| evaluation/episode-length-avg  | 142         |
| evaluation/episode-length-max  | 142         |
| evaluation/episode-length-min  | 141         |
| evaluation/episode-length-std  | 0.4         |
| evaluation/return-average      | 380.44928   |
| evaluation/return-max          | 389.36194   |
| evaluation/return-min          | 374.1189    |
| evaluation/return-std          | 4.2973356   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.87        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 83.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45390       |
| perf/AverageLength             | 142         |
| perf/AverageReturn             | 380.44928   |
| perf/NormalizedReturn          | 0.0825      |
| Q-avg                          | 172.3634    |
| Q-std                          | 120.58359   |
| Q_loss                         | 87.912544   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 177         |
| times/epoch_after_hook         | 2e-06       |
| times/epoch_before_hook        | 0.000272    |
| times/epoch_rollout_model      | 475         |
| times/evaluation_metrics       | 0.000546    |
| times/evaluation_paths         | 4.61        |
| times/timestep_after_hook      | 0.00397     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 57.5        |
| timestep                       | 1000        |
| timesteps_total                | 178000      |
| train-steps                    | 178000      |
| training/Q/q1_loss             | 98.80192    |
| training/sac_pi/alpha          | 0.15399216  |
| training/sac_pi/alpha_loss     | -0.29538205 |
| training/sac_pi/logp_pi        | 4.6025825   |
| training/sac_pi/pi_entropy     | 3.847527    |
| training/sac_pi/pi_global_norm | 1.4263896   |
| training/sac_pi/policy_loss    | -192.0722   |
| training/sac_pi/std            | 0.5623035   |
| training/sac_pi/valid_num      | 4930.0      |
| training/sac_Q/q1              | 180.43436   |
| training/sac_Q/q2              | 181.44418   |
| training/sac_Q/q2_loss         | 98.69741    |
| training/sac_Q/q_global_norm   | 172.93605   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15915193  |
| epoch                          | 178         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4588.384    |
| evaluation/return-max          | 4663.582    |
| evaluation/return-min          | 4512.4287   |
| evaluation/return-std          | 51.14903    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.84        |
| model/origin_ret               | 83.2        |
| model/penalty_ret              | 82.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45531       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4588.384    |
| perf/NormalizedReturn          | 0.999       |
| Q-avg                          | 172.12112   |
| Q-std                          | 110.48712   |
| Q_loss                         | 72.32319    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 178         |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 8.86e-05    |
| times/epoch_rollout_model      | 476         |
| times/evaluation_metrics       | 0.000545    |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00387     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 56.7        |
| timestep                       | 1000        |
| timesteps_total                | 179000      |
| train-steps                    | 179000      |
| training/Q/q1_loss             | 92.32877    |
| training/sac_pi/alpha          | 0.15916656  |
| training/sac_pi/alpha_loss     | 0.018361283 |
| training/sac_pi/logp_pi        | 4.6494646   |
| training/sac_pi/pi_entropy     | 3.8064322   |
| training/sac_pi/pi_global_norm | 1.5623797   |
| training/sac_pi/policy_loss    | -181.91907  |
| training/sac_pi/std            | 0.55461746  |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 171.37814   |
| training/sac_Q/q2              | 170.85468   |
| training/sac_Q/q2_loss         | 92.30151    |
| training/sac_Q/q_global_norm   | 245.02994   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1586267  |
| epoch                          | 179        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4554.211   |
| evaluation/return-max          | 4586.4155  |
| evaluation/return-min          | 4515.22    |
| evaluation/return-std          | 20.566195  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45546      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4554.211   |
| perf/NormalizedReturn          | 0.992      |
| Q-avg                          | 180.56465  |
| Q-std                          | 99.08106   |
| Q_loss                         | 90.258736  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 179        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000102   |
| times/epoch_rollout_model      | 474        |
| times/evaluation_metrics       | 0.000561   |
| times/evaluation_paths         | 31.2       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 56.9       |
| timestep                       | 1000       |
| timesteps_total                | 180000     |
| train-steps                    | 180000     |
| training/Q/q1_loss             | 100.971756 |
| training/sac_pi/alpha          | 0.15863255 |
| training/sac_pi/alpha_loss     | -0.4515327 |
| training/sac_pi/logp_pi        | 4.720887   |
| training/sac_pi/pi_entropy     | 3.8138294  |
| training/sac_pi/pi_global_norm | 1.3632692  |
| training/sac_pi/policy_loss    | -186.07307 |
| training/sac_pi/std            | 0.556407   |
| training/sac_pi/valid_num      | 4877.0     |
| training/sac_Q/q1              | 173.3627   |
| training/sac_Q/q2              | 173.50516  |
| training/sac_Q/q2_loss         | 100.05171  |
| training/sac_Q/q_global_norm   | 318.45816  |
--------------------------------------------------------------------------------
[WARN] 180 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.15949705  |
| epoch                          | 180         |
| evaluation/episode-length-avg  | 250         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 142         |
| evaluation/episode-length-std  | 255         |
| evaluation/return-average      | 893.58484   |
| evaluation/return-max          | 4813.5977   |
| evaluation/return-min          | 349.31537   |
| evaluation/return-std          | 1327.8256   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.87        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 82.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45516       |
| perf/AverageLength             | 250         |
| perf/AverageReturn             | 893.58484   |
| perf/NormalizedReturn          | 0.194       |
| Q-avg                          | 186.68993   |
| Q-std                          | 90.98036    |
| Q_loss                         | 102.59773   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 180         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.00012     |
| times/epoch_rollout_model      | 476         |
| times/evaluation_metrics       | 0.000446    |
| times/evaluation_paths         | 7.71        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 181000      |
| train-steps                    | 181000      |
| training/Q/q1_loss             | 95.218376   |
| training/sac_pi/alpha          | 0.1594824   |
| training/sac_pi/alpha_loss     | 0.068362065 |
| training/sac_pi/logp_pi        | 5.052375    |
| training/sac_pi/pi_entropy     | 3.7824943   |
| training/sac_pi/pi_global_norm | 1.9690493   |
| training/sac_pi/policy_loss    | -189.5781   |
| training/sac_pi/std            | 0.5596705   |
| training/sac_pi/valid_num      | 4903.0      |
| training/sac_Q/q1              | 178.0907    |
| training/sac_Q/q2              | 177.2363    |
| training/sac_Q/q2_loss         | 94.96062    |
| training/sac_Q/q_global_norm   | 304.3427    |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15505795   |
| epoch                          | 181          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4722.669     |
| evaluation/return-max          | 4744.4053    |
| evaluation/return-min          | 4683.874     |
| evaluation/return-std          | 17.070387    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.91         |
| model/origin_ret               | 84.8         |
| model/penalty_ret              | 82.4         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45539        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4722.669     |
| perf/NormalizedReturn          | 1.03         |
| Q-avg                          | 178.37521    |
| Q-std                          | 107.0944     |
| Q_loss                         | 114.72961    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 181          |
| times/epoch_after_hook         | 1.86e-06     |
| times/epoch_before_hook        | 0.000273     |
| times/epoch_rollout_model      | 475          |
| times/evaluation_metrics       | 0.000534     |
| times/evaluation_paths         | 31.8         |
| times/timestep_after_hook      | 0.00383      |
| times/timestep_before_hook     | 0.00797      |
| times/train                    | 56.3         |
| timestep                       | 1000         |
| timesteps_total                | 182000       |
| train-steps                    | 182000       |
| training/Q/q1_loss             | 86.5286      |
| training/sac_pi/alpha          | 0.1550617    |
| training/sac_pi/alpha_loss     | -0.117997654 |
| training/sac_pi/logp_pi        | 5.1382647    |
| training/sac_pi/pi_entropy     | 3.7196674    |
| training/sac_pi/pi_global_norm | 1.3432577    |
| training/sac_pi/policy_loss    | -186.08408   |
| training/sac_pi/std            | 0.5576111    |
| training/sac_pi/valid_num      | 4927.0       |
| training/sac_Q/q1              | 173.1644     |
| training/sac_Q/q2              | 172.14767    |
| training/sac_Q/q2_loss         | 86.30023     |
| training/sac_Q/q_global_norm   | 229.65327    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15364793  |
| epoch                          | 182         |
| evaluation/episode-length-avg  | 916         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 162         |
| evaluation/episode-length-std  | 251         |
| evaluation/return-average      | 4462.198    |
| evaluation/return-max          | 4988.7754   |
| evaluation/return-min          | 378.2306    |
| evaluation/return-std          | 1361.7197   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 83          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45719       |
| perf/AverageLength             | 916         |
| perf/AverageReturn             | 4462.198    |
| perf/NormalizedReturn          | 0.972       |
| Q-avg                          | 181.2524    |
| Q-std                          | 87.96751    |
| Q_loss                         | 97.75654    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 182         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000106    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000508    |
| times/evaluation_paths         | 27.9        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00802     |
| times/train                    | 55.7        |
| timestep                       | 1000        |
| timesteps_total                | 183000      |
| train-steps                    | 183000      |
| training/Q/q1_loss             | 93.4565     |
| training/sac_pi/alpha          | 0.1536649   |
| training/sac_pi/alpha_loss     | -0.18300186 |
| training/sac_pi/logp_pi        | 5.0941534   |
| training/sac_pi/pi_entropy     | 3.6642659   |
| training/sac_pi/pi_global_norm | 1.2884274   |
| training/sac_pi/policy_loss    | -192.2306   |
| training/sac_pi/std            | 0.5585002   |
| training/sac_pi/valid_num      | 4868.0      |
| training/sac_Q/q1              | 175.16875   |
| training/sac_Q/q2              | 175.89058   |
| training/sac_Q/q2_loss         | 93.0578     |
| training/sac_Q/q_global_norm   | 341.0163    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15936059 |
| epoch                          | 183        |
| evaluation/episode-length-avg  | 951        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 507        |
| evaluation/episode-length-std  | 148        |
| evaluation/return-average      | 4255.5454  |
| evaluation/return-max          | 4642.453   |
| evaluation/return-min          | 1936.0178  |
| evaluation/return-std          | 776.62964  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 82.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45585      |
| perf/AverageLength             | 951        |
| perf/AverageReturn             | 4255.5454  |
| perf/NormalizedReturn          | 0.927      |
| Q-avg                          | 173.55762  |
| Q-std                          | 94.55114   |
| Q_loss                         | 96.11728   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 183        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000111   |
| times/epoch_rollout_model      | 473        |
| times/evaluation_metrics       | 0.000587   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 57.6       |
| timestep                       | 1000       |
| timesteps_total                | 184000     |
| train-steps                    | 184000     |
| training/Q/q1_loss             | 103.76356  |
| training/sac_pi/alpha          | 0.15940507 |
| training/sac_pi/alpha_loss     | -0.4845583 |
| training/sac_pi/logp_pi        | 4.490777   |
| training/sac_pi/pi_entropy     | 3.6124566  |
| training/sac_pi/pi_global_norm | 1.2199957  |
| training/sac_pi/policy_loss    | -187.0467  |
| training/sac_pi/std            | 0.5388704  |
| training/sac_pi/valid_num      | 4920.0     |
| training/sac_Q/q1              | 173.70398  |
| training/sac_Q/q2              | 174.32866  |
| training/sac_Q/q2_loss         | 103.78413  |
| training/sac_Q/q_global_norm   | 231.70953  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1553223   |
| epoch                          | 184         |
| evaluation/episode-length-avg  | 565         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 319         |
| evaluation/episode-length-std  | 256         |
| evaluation/return-average      | 2117.6882   |
| evaluation/return-max          | 4327.886    |
| evaluation/return-min          | 959.7412    |
| evaluation/return-std          | 1285.8931   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.89        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 82.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45635       |
| perf/AverageLength             | 565         |
| perf/AverageReturn             | 2117.6882   |
| perf/NormalizedReturn          | 0.461       |
| Q-avg                          | 169.11508   |
| Q-std                          | 104.60623   |
| Q_loss                         | 116.77703   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 184         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000624    |
| times/evaluation_paths         | 17.8        |
| times/timestep_after_hook      | 0.004       |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 58.8        |
| timestep                       | 1000        |
| timesteps_total                | 185000      |
| train-steps                    | 185000      |
| training/Q/q1_loss             | 107.69973   |
| training/sac_pi/alpha          | 0.1552847   |
| training/sac_pi/alpha_loss     | 0.025594978 |
| training/sac_pi/logp_pi        | 4.1780806   |
| training/sac_pi/pi_entropy     | 3.676796    |
| training/sac_pi/pi_global_norm | 1.2593173   |
| training/sac_pi/policy_loss    | -188.61105  |
| training/sac_pi/std            | 0.5207329   |
| training/sac_pi/valid_num      | 4920.0      |
| training/sac_Q/q1              | 178.55466   |
| training/sac_Q/q2              | 177.87923   |
| training/sac_Q/q2_loss         | 107.062065  |
| training/sac_Q/q_global_norm   | 231.14166   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15665549  |
| epoch                          | 185         |
| evaluation/episode-length-avg  | 822         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 251         |
| evaluation/episode-length-std  | 291         |
| evaluation/return-average      | 3619.4448   |
| evaluation/return-max          | 4670.586    |
| evaluation/return-min          | 806.79565   |
| evaluation/return-std          | 1469.0969   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 83.3        |
| model/penalty_ret              | 82.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45595       |
| perf/AverageLength             | 822         |
| perf/AverageReturn             | 3619.4448   |
| perf/NormalizedReturn          | 0.788       |
| Q-avg                          | 186.33328   |
| Q-std                          | 86.41287    |
| Q_loss                         | 95.948364   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 185         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000274    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000527    |
| times/evaluation_paths         | 26.2        |
| times/timestep_after_hook      | 0.00382     |
| times/timestep_before_hook     | 0.00782     |
| times/train                    | 57.3        |
| timestep                       | 1000        |
| timesteps_total                | 186000      |
| train-steps                    | 186000      |
| training/Q/q1_loss             | 109.197334  |
| training/sac_pi/alpha          | 0.1566639   |
| training/sac_pi/alpha_loss     | -0.35003272 |
| training/sac_pi/logp_pi        | 4.762097    |
| training/sac_pi/pi_entropy     | 3.6339993   |
| training/sac_pi/pi_global_norm | 1.3954917   |
| training/sac_pi/policy_loss    | -190.45903  |
| training/sac_pi/std            | 0.5402245   |
| training/sac_pi/valid_num      | 4882.0      |
| training/sac_Q/q1              | 179.36586   |
| training/sac_Q/q2              | 179.6939    |
| training/sac_Q/q2_loss         | 109.88299   |
| training/sac_Q/q_global_norm   | 268.6029    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15765123 |
| epoch                          | 186        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4418.793   |
| evaluation/return-max          | 4526.082   |
| evaluation/return-min          | 4336.5864  |
| evaluation/return-std          | 68.1529    |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.83       |
| model/origin_ret               | 83.5       |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45497      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4418.793   |
| perf/NormalizedReturn          | 0.962      |
| Q-avg                          | 178.60066  |
| Q-std                          | 105.80647  |
| Q_loss                         | 100.35734  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 186        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000562   |
| times/evaluation_paths         | 31.4       |
| times/timestep_after_hook      | 0.00398    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 58.4       |
| timestep                       | 1000       |
| timesteps_total                | 187000     |
| train-steps                    | 187000     |
| training/Q/q1_loss             | 101.599724 |
| training/sac_pi/alpha          | 0.15766783 |
| training/sac_pi/alpha_loss     | 0.31073433 |
| training/sac_pi/logp_pi        | 4.4242187  |
| training/sac_pi/pi_entropy     | 3.6515498  |
| training/sac_pi/pi_global_norm | 1.2881426  |
| training/sac_pi/policy_loss    | -192.96883 |
| training/sac_pi/std            | 0.5245199  |
| training/sac_pi/valid_num      | 4927.0     |
| training/sac_Q/q1              | 181.52145  |
| training/sac_Q/q2              | 180.53897  |
| training/sac_Q/q2_loss         | 101.93207  |
| training/sac_Q/q_global_norm   | 271.2373   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15955949 |
| epoch                          | 187        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4892.6367  |
| evaluation/return-max          | 4913.833   |
| evaluation/return-min          | 4872.451   |
| evaluation/return-std          | 12.945675  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45518      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4892.6367  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 183.97282  |
| Q-std                          | 105.725494 |
| Q_loss                         | 92.209984  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 187        |
| times/epoch_after_hook         | 1.97e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000628   |
| times/evaluation_paths         | 32.5       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 57.5       |
| timestep                       | 1000       |
| timesteps_total                | 188000     |
| train-steps                    | 188000     |
| training/Q/q1_loss             | 90.99654   |
| training/sac_pi/alpha          | 0.15957685 |
| training/sac_pi/alpha_loss     | 0.14991798 |
| training/sac_pi/logp_pi        | 4.440816   |
| training/sac_pi/pi_entropy     | 3.6794314  |
| training/sac_pi/pi_global_norm | 1.5110123  |
| training/sac_pi/policy_loss    | -186.49385 |
| training/sac_pi/std            | 0.53009915 |
| training/sac_pi/valid_num      | 4981.0     |
| training/sac_Q/q1              | 176.83939  |
| training/sac_Q/q2              | 177.37033  |
| training/sac_Q/q2_loss         | 91.36985   |
| training/sac_Q/q_global_norm   | 193.5613   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.156709    |
| epoch                          | 188         |
| evaluation/episode-length-avg  | 174         |
| evaluation/episode-length-max  | 496         |
| evaluation/episode-length-min  | 138         |
| evaluation/episode-length-std  | 107         |
| evaluation/return-average      | 614.37585   |
| evaluation/return-max          | 2104.2588   |
| evaluation/return-min          | 443.5338    |
| evaluation/return-std          | 496.63602   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45645       |
| perf/AverageLength             | 174         |
| perf/AverageReturn             | 614.37585   |
| perf/NormalizedReturn          | 0.133       |
| Q-avg                          | 180.83401   |
| Q-std                          | 115.50432   |
| Q_loss                         | 79.6568     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 188         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000604    |
| times/evaluation_paths         | 5.69        |
| times/timestep_after_hook      | 0.004       |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 57.5        |
| timestep                       | 1000        |
| timesteps_total                | 189000      |
| train-steps                    | 189000      |
| training/Q/q1_loss             | 96.82904    |
| training/sac_pi/alpha          | 0.156717    |
| training/sac_pi/alpha_loss     | -0.17182806 |
| training/sac_pi/logp_pi        | 4.3996677   |
| training/sac_pi/pi_entropy     | 3.7484202   |
| training/sac_pi/pi_global_norm | 1.2974015   |
| training/sac_pi/policy_loss    | -180.35356  |
| training/sac_pi/std            | 0.5300342   |
| training/sac_pi/valid_num      | 4965.0      |
| training/sac_Q/q1              | 172.4943    |
| training/sac_Q/q2              | 172.65823   |
| training/sac_Q/q2_loss         | 96.47934    |
| training/sac_Q/q_global_norm   | 229.43327   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15493035 |
| epoch                          | 189        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4466.624   |
| evaluation/return-max          | 4675.662   |
| evaluation/return-min          | 4304.3135  |
| evaluation/return-std          | 105.304855 |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 83.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45347      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4466.624   |
| perf/NormalizedReturn          | 0.973      |
| Q-avg                          | 185.07384  |
| Q-std                          | 102.51259  |
| Q_loss                         | 80.18823   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 189        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000308   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000617   |
| times/evaluation_paths         | 32.7       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00804    |
| times/train                    | 57.5       |
| timestep                       | 1000       |
| timesteps_total                | 190000     |
| train-steps                    | 190000     |
| training/Q/q1_loss             | 93.43494   |
| training/sac_pi/alpha          | 0.15491593 |
| training/sac_pi/alpha_loss     | 0.25858352 |
| training/sac_pi/logp_pi        | 4.722415   |
| training/sac_pi/pi_entropy     | 3.720417   |
| training/sac_pi/pi_global_norm | 1.368641   |
| training/sac_pi/policy_loss    | -184.58206 |
| training/sac_pi/std            | 0.54334617 |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 177.05547  |
| training/sac_Q/q2              | 176.14397  |
| training/sac_Q/q2_loss         | 93.756645  |
| training/sac_Q/q_global_norm   | 213.98436  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15505098  |
| epoch                          | 190         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4448.735    |
| evaluation/return-max          | 4611.045    |
| evaluation/return-min          | 4217.5664   |
| evaluation/return-std          | 121.57722   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 82.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45615       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4448.735    |
| perf/NormalizedReturn          | 0.969       |
| Q-avg                          | 179.49765   |
| Q-std                          | 104.84769   |
| Q_loss                         | 111.79035   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 190         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000597    |
| times/evaluation_paths         | 31.8        |
| times/timestep_after_hook      | 0.00407     |
| times/timestep_before_hook     | 0.00834     |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 191000      |
| train-steps                    | 191000      |
| training/Q/q1_loss             | 97.040695   |
| training/sac_pi/alpha          | 0.15504873  |
| training/sac_pi/alpha_loss     | -0.22207873 |
| training/sac_pi/logp_pi        | 3.9874344   |
| training/sac_pi/pi_entropy     | 3.6709328   |
| training/sac_pi/pi_global_norm | 1.2932482   |
| training/sac_pi/policy_loss    | -190.03496  |
| training/sac_pi/std            | 0.5278785   |
| training/sac_pi/valid_num      | 4982.0      |
| training/sac_Q/q1              | 183.52048   |
| training/sac_Q/q2              | 182.63335   |
| training/sac_Q/q2_loss         | 97.38431    |
| training/sac_Q/q_global_norm   | 305.29315   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15941328 |
| epoch                          | 191        |
| evaluation/episode-length-avg  | 561        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 119        |
| evaluation/episode-length-std  | 439        |
| evaluation/return-average      | 2471.3938  |
| evaluation/return-max          | 4713.368   |
| evaluation/return-min          | 244.62222  |
| evaluation/return-std          | 2221.366   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45812      |
| perf/AverageLength             | 561        |
| perf/AverageReturn             | 2471.3938  |
| perf/NormalizedReturn          | 0.538      |
| Q-avg                          | 185.60652  |
| Q-std                          | 108.25136  |
| Q_loss                         | 88.31746   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 191        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000567   |
| times/evaluation_paths         | 17.2       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00793    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 192000     |
| train-steps                    | 192000     |
| training/Q/q1_loss             | 84.31803   |
| training/sac_pi/alpha          | 0.15939084 |
| training/sac_pi/alpha_loss     | 0.3579229  |
| training/sac_pi/logp_pi        | 3.7597814  |
| training/sac_pi/pi_entropy     | 3.5973518  |
| training/sac_pi/pi_global_norm | 1.3818703  |
| training/sac_pi/policy_loss    | -191.5441  |
| training/sac_pi/std            | 0.4850613  |
| training/sac_pi/valid_num      | 4960.0     |
| training/sac_Q/q1              | 184.68535  |
| training/sac_Q/q2              | 184.9547   |
| training/sac_Q/q2_loss         | 85.33362   |
| training/sac_Q/q_global_norm   | 236.63823  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15554175 |
| epoch                          | 192        |
| evaluation/episode-length-avg  | 567        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 133        |
| evaluation/episode-length-std  | 433        |
| evaluation/return-average      | 2509.082   |
| evaluation/return-max          | 4727.2627  |
| evaluation/return-min          | 338.99213  |
| evaluation/return-std          | 2165.7927  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45626      |
| perf/AverageLength             | 567        |
| perf/AverageReturn             | 2509.082   |
| perf/NormalizedReturn          | 0.546      |
| Q-avg                          | 175.67819  |
| Q-std                          | 123.80251  |
| Q_loss                         | 94.472404  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 192        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000541   |
| times/evaluation_paths         | 17.4       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00806    |
| times/train                    | 56.7       |
| timestep                       | 1000       |
| timesteps_total                | 193000     |
| train-steps                    | 193000     |
| training/Q/q1_loss             | 78.385895  |
| training/sac_pi/alpha          | 0.1555437  |
| training/sac_pi/alpha_loss     | 0.3262292  |
| training/sac_pi/logp_pi        | 4.6869965  |
| training/sac_pi/pi_entropy     | 3.4637318  |
| training/sac_pi/pi_global_norm | 1.3432244  |
| training/sac_pi/policy_loss    | -196.13155 |
| training/sac_pi/std            | 0.5117048  |
| training/sac_pi/valid_num      | 4967.0     |
| training/sac_Q/q1              | 186.80234  |
| training/sac_Q/q2              | 185.76358  |
| training/sac_Q/q2_loss         | 77.91098   |
| training/sac_Q/q_global_norm   | 197.30115  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15438773   |
| epoch                          | 193          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4725.2124    |
| evaluation/return-max          | 4760.057     |
| evaluation/return-min          | 4686.4907    |
| evaluation/return-std          | 23.197998    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.91         |
| model/origin_ret               | 84.7         |
| model/penalty_ret              | 82.9         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45701        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4725.2124    |
| perf/NormalizedReturn          | 1.03         |
| Q-avg                          | 189.43884    |
| Q-std                          | 103.11607    |
| Q_loss                         | 119.63003    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 193          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.000279     |
| times/epoch_rollout_model      | 474          |
| times/evaluation_metrics       | 0.000624     |
| times/evaluation_paths         | 30.5         |
| times/timestep_after_hook      | 0.00375      |
| times/timestep_before_hook     | 0.00799      |
| times/train                    | 56           |
| timestep                       | 1000         |
| timesteps_total                | 194000       |
| train-steps                    | 194000       |
| training/Q/q1_loss             | 83.80074     |
| training/sac_pi/alpha          | 0.15440615   |
| training/sac_pi/alpha_loss     | -0.026721371 |
| training/sac_pi/logp_pi        | 4.5244136    |
| training/sac_pi/pi_entropy     | 3.4742637    |
| training/sac_pi/pi_global_norm | 1.5607456    |
| training/sac_pi/policy_loss    | -197.51135   |
| training/sac_pi/std            | 0.50576407   |
| training/sac_pi/valid_num      | 4943.0       |
| training/sac_Q/q1              | 188.66823    |
| training/sac_Q/q2              | 187.05624    |
| training/sac_Q/q2_loss         | 82.69844     |
| training/sac_Q/q_global_norm   | 213.97466    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15901119  |
| epoch                          | 194         |
| evaluation/episode-length-avg  | 795         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 138         |
| evaluation/episode-length-std  | 330         |
| evaluation/return-average      | 3642.5376   |
| evaluation/return-max          | 4724.7886   |
| evaluation/return-min          | 346.28445   |
| evaluation/return-std          | 1681.0244   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 82.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45686       |
| perf/AverageLength             | 795         |
| perf/AverageReturn             | 3642.5376   |
| perf/NormalizedReturn          | 0.793       |
| Q-avg                          | 175.47073   |
| Q-std                          | 118.13888   |
| Q_loss                         | 113.9229    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 194         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000108    |
| times/epoch_rollout_model      | 474         |
| times/evaluation_metrics       | 0.000631    |
| times/evaluation_paths         | 24.3        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00788     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 195000      |
| train-steps                    | 195000      |
| training/Q/q1_loss             | 109.37209   |
| training/sac_pi/alpha          | 0.15900746  |
| training/sac_pi/alpha_loss     | -0.18522328 |
| training/sac_pi/logp_pi        | 4.5703516   |
| training/sac_pi/pi_entropy     | 3.8125725   |
| training/sac_pi/pi_global_norm | 1.3926755   |
| training/sac_pi/policy_loss    | -188.37271  |
| training/sac_pi/std            | 0.5639332   |
| training/sac_pi/valid_num      | 4970.0      |
| training/sac_Q/q1              | 176.30899   |
| training/sac_Q/q2              | 177.58182   |
| training/sac_Q/q2_loss         | 109.02208   |
| training/sac_Q/q_global_norm   | 383.7677    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16050588 |
| epoch                          | 195        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4817.8413  |
| evaluation/return-max          | 4870.266   |
| evaluation/return-min          | 4714.8037  |
| evaluation/return-std          | 51.835056  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.79       |
| model/origin_ret               | 82.5       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45646      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4817.8413  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 181.73174  |
| Q-std                          | 127.38034  |
| Q_loss                         | 96.38855   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 195        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000107   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000672   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00795    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 196000     |
| train-steps                    | 196000     |
| training/Q/q1_loss             | 90.30946   |
| training/sac_pi/alpha          | 0.16053125 |
| training/sac_pi/alpha_loss     | -0.2504319 |
| training/sac_pi/logp_pi        | 4.8295503  |
| training/sac_pi/pi_entropy     | 3.8335373  |
| training/sac_pi/pi_global_norm | 1.5359055  |
| training/sac_pi/policy_loss    | -187.7037  |
| training/sac_pi/std            | 0.56904984 |
| training/sac_pi/valid_num      | 4935.0     |
| training/sac_Q/q1              | 176.48206  |
| training/sac_Q/q2              | 175.49097  |
| training/sac_Q/q2_loss         | 90.0129    |
| training/sac_Q/q_global_norm   | 251.02223  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1630125  |
| epoch                          | 196        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4416.6133  |
| evaluation/return-max          | 4522.4043  |
| evaluation/return-min          | 4322.915   |
| evaluation/return-std          | 64.295906  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 83.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45551      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4416.6133  |
| perf/NormalizedReturn          | 0.962      |
| Q-avg                          | 178.4331   |
| Q-std                          | 101.32028  |
| Q_loss                         | 113.48461  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 196        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 473        |
| times/evaluation_metrics       | 0.000563   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 56.3       |
| timestep                       | 1000       |
| timesteps_total                | 197000     |
| train-steps                    | 197000     |
| training/Q/q1_loss             | 101.32863  |
| training/sac_pi/alpha          | 0.16298568 |
| training/sac_pi/alpha_loss     | 0.61067164 |
| training/sac_pi/logp_pi        | 4.392438   |
| training/sac_pi/pi_entropy     | 3.6852322  |
| training/sac_pi/pi_global_norm | 1.4727992  |
| training/sac_pi/policy_loss    | -183.54642 |
| training/sac_pi/std            | 0.5142063  |
| training/sac_pi/valid_num      | 4953.0     |
| training/sac_Q/q1              | 174.58255  |
| training/sac_Q/q2              | 173.19499  |
| training/sac_Q/q2_loss         | 100.93092  |
| training/sac_Q/q_global_norm   | 217.54227  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1582582  |
| epoch                          | 197        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4986.534   |
| evaluation/return-max          | 5021.3174  |
| evaluation/return-min          | 4939.6543  |
| evaluation/return-std          | 24.764683  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45493      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4986.534   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 172.93259  |
| Q-std                          | 117.96783  |
| Q_loss                         | 113.09271  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 197        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000313   |
| times/epoch_rollout_model      | 473        |
| times/evaluation_metrics       | 0.00059    |
| times/evaluation_paths         | 29.9       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00797    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 198000     |
| train-steps                    | 198000     |
| training/Q/q1_loss             | 82.98155   |
| training/sac_pi/alpha          | 0.1582945  |
| training/sac_pi/alpha_loss     | -0.225701  |
| training/sac_pi/logp_pi        | 3.7670693  |
| training/sac_pi/pi_entropy     | 3.7688842  |
| training/sac_pi/pi_global_norm | 1.3240056  |
| training/sac_pi/policy_loss    | -185.99374 |
| training/sac_pi/std            | 0.50911295 |
| training/sac_pi/valid_num      | 5007.0     |
| training/sac_Q/q1              | 179.86258  |
| training/sac_Q/q2              | 179.55428  |
| training/sac_Q/q2_loss         | 81.9086    |
| training/sac_Q/q_global_norm   | 214.64404  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16077335 |
| epoch                          | 198        |
| evaluation/episode-length-avg  | 544        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 311        |
| evaluation/episode-length-std  | 298        |
| evaluation/return-average      | 2238.683   |
| evaluation/return-max          | 4692.6543  |
| evaluation/return-min          | 1028.4331  |
| evaluation/return-std          | 1573.0852  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 83.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45479      |
| perf/AverageLength             | 544        |
| perf/AverageReturn             | 2238.683   |
| perf/NormalizedReturn          | 0.487      |
| Q-avg                          | 177.0147   |
| Q-std                          | 111.64674  |
| Q_loss                         | 97.08557   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 198        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000109   |
| times/epoch_rollout_model      | 474        |
| times/evaluation_metrics       | 0.000672   |
| times/evaluation_paths         | 16.4       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00788    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 199000     |
| train-steps                    | 199000     |
| training/Q/q1_loss             | 87.14932   |
| training/sac_pi/alpha          | 0.16075449 |
| training/sac_pi/alpha_loss     | 0.33905238 |
| training/sac_pi/logp_pi        | 4.5043907  |
| training/sac_pi/pi_entropy     | 3.6870198  |
| training/sac_pi/pi_global_norm | 1.5197723  |
| training/sac_pi/policy_loss    | -197.97896 |
| training/sac_pi/std            | 0.51666576 |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 186.8085   |
| training/sac_Q/q2              | 186.7952   |
| training/sac_Q/q2_loss         | 87.03775   |
| training/sac_Q/q_global_norm   | 261.31158  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15755375 |
| epoch                          | 199        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4555.3477  |
| evaluation/return-max          | 4632.8184  |
| evaluation/return-min          | 4447.284   |
| evaluation/return-std          | 61.744247  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.84       |
| model/origin_ret               | 83.1       |
| model/penalty_ret              | 82.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45605      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4555.3477  |
| perf/NormalizedReturn          | 0.992      |
| Q-avg                          | 177.6008   |
| Q-std                          | 105.34913  |
| Q_loss                         | 119.70906  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 199        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000108   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000635   |
| times/evaluation_paths         | 30.1       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00797    |
| times/train                    | 56.1       |
| timestep                       | 1000       |
| timesteps_total                | 200000     |
| train-steps                    | 200000     |
| training/Q/q1_loss             | 104.98626  |
| training/sac_pi/alpha          | 0.15757446 |
| training/sac_pi/alpha_loss     | -0.1320393 |
| training/sac_pi/logp_pi        | 5.3592477  |
| training/sac_pi/pi_entropy     | 3.7468371  |
| training/sac_pi/pi_global_norm | 1.4890606  |
| training/sac_pi/policy_loss    | -187.89275 |
| training/sac_pi/std            | 0.57007307 |
| training/sac_pi/valid_num      | 4884.0     |
| training/sac_Q/q1              | 169.88467  |
| training/sac_Q/q2              | 168.92953  |
| training/sac_Q/q2_loss         | 105.1446   |
| training/sac_Q/q_global_norm   | 367.06396  |
--------------------------------------------------------------------------------
[WARN] 200 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.1558627    |
| epoch                          | 200          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4461.3115    |
| evaluation/return-max          | 4503.275     |
| evaluation/return-min          | 4403.6562    |
| evaluation/return-std          | 33.89964     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.88         |
| model/origin_ret               | 84.2         |
| model/penalty_ret              | 83.4         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45595        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4461.3115    |
| perf/NormalizedReturn          | 0.971        |
| Q-avg                          | 183.57858    |
| Q-std                          | 114.76248    |
| Q_loss                         | 89.28141     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 200          |
| times/epoch_after_hook         | 1.83e-06     |
| times/epoch_before_hook        | 0.000107     |
| times/epoch_rollout_model      | 474          |
| times/evaluation_metrics       | 0.000526     |
| times/evaluation_paths         | 30.2         |
| times/timestep_after_hook      | 0.00361      |
| times/timestep_before_hook     | 0.00795      |
| times/train                    | 55.8         |
| timestep                       | 1000         |
| timesteps_total                | 201000       |
| train-steps                    | 201000       |
| training/Q/q1_loss             | 78.009254    |
| training/sac_pi/alpha          | 0.155847     |
| training/sac_pi/alpha_loss     | -0.056514032 |
| training/sac_pi/logp_pi        | 3.6932693    |
| training/sac_pi/pi_entropy     | 3.6861107    |
| training/sac_pi/pi_global_norm | 1.4979655    |
| training/sac_pi/policy_loss    | -191.07906   |
| training/sac_pi/std            | 0.49806646   |
| training/sac_pi/valid_num      | 4952.0       |
| training/sac_Q/q1              | 183.76837    |
| training/sac_Q/q2              | 183.37328    |
| training/sac_Q/q2_loss         | 78.14686     |
| training/sac_Q/q_global_norm   | 186.74014    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15867284  |
| epoch                          | 201         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4636.2725   |
| evaluation/return-max          | 4649.2007   |
| evaluation/return-min          | 4612.591    |
| evaluation/return-std          | 10.572036   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.85        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 82.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45654       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4636.2725   |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 177.05214   |
| Q-std                          | 100.15432   |
| Q_loss                         | 93.57025    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 201         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000278    |
| times/epoch_rollout_model      | 475         |
| times/evaluation_metrics       | 0.000537    |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.0044      |
| times/timestep_before_hook     | 0.00794     |
| times/train                    | 56.2        |
| timestep                       | 1000        |
| timesteps_total                | 202000      |
| train-steps                    | 202000      |
| training/Q/q1_loss             | 91.331345   |
| training/sac_pi/alpha          | 0.15869312  |
| training/sac_pi/alpha_loss     | -0.15230305 |
| training/sac_pi/logp_pi        | 4.5589504   |
| training/sac_pi/pi_entropy     | 3.5328114   |
| training/sac_pi/pi_global_norm | 1.4329625   |
| training/sac_pi/policy_loss    | -192.04059  |
| training/sac_pi/std            | 0.51842195  |
| training/sac_pi/valid_num      | 4979.0      |
| training/sac_Q/q1              | 182.62434   |
| training/sac_Q/q2              | 179.94196   |
| training/sac_Q/q2_loss         | 93.09337    |
| training/sac_Q/q_global_norm   | 280.45914   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15838853 |
| epoch                          | 202        |
| evaluation/episode-length-avg  | 493        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 154        |
| evaluation/episode-length-std  | 414        |
| evaluation/return-average      | 2174.4373  |
| evaluation/return-max          | 4882.043   |
| evaluation/return-min          | 379.949    |
| evaluation/return-std          | 2187.2432  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.84       |
| model/origin_ret               | 83.2       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45668      |
| perf/AverageLength             | 493        |
| perf/AverageReturn             | 2174.4373  |
| perf/NormalizedReturn          | 0.473      |
| Q-avg                          | 179.01639  |
| Q-std                          | 109.632675 |
| Q_loss                         | 105.44994  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 202        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.00024    |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000609   |
| times/evaluation_paths         | 15.3       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00787    |
| times/train                    | 56.2       |
| timestep                       | 1000       |
| timesteps_total                | 203000     |
| train-steps                    | 203000     |
| training/Q/q1_loss             | 86.67551   |
| training/sac_pi/alpha          | 0.15836579 |
| training/sac_pi/alpha_loss     | 0.1038419  |
| training/sac_pi/logp_pi        | 4.338318   |
| training/sac_pi/pi_entropy     | 3.7247825  |
| training/sac_pi/pi_global_norm | 1.3553448  |
| training/sac_pi/policy_loss    | -190.9359  |
| training/sac_pi/std            | 0.5186422  |
| training/sac_pi/valid_num      | 4970.0     |
| training/sac_Q/q1              | 181.31406  |
| training/sac_Q/q2              | 179.90096  |
| training/sac_Q/q2_loss         | 86.66598   |
| training/sac_Q/q_global_norm   | 266.6134   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15643276  |
| epoch                          | 203         |
| evaluation/episode-length-avg  | 831         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 155         |
| evaluation/episode-length-std  | 337         |
| evaluation/return-average      | 3810.0066   |
| evaluation/return-max          | 4707.578    |
| evaluation/return-min          | 392.8188    |
| evaluation/return-std          | 1706.99     |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45555       |
| perf/AverageLength             | 831         |
| perf/AverageReturn             | 3810.0066   |
| perf/NormalizedReturn          | 0.83        |
| Q-avg                          | 172.16452   |
| Q-std                          | 138.66423   |
| Q_loss                         | 106.768105  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 203         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000104    |
| times/epoch_rollout_model      | 476         |
| times/evaluation_metrics       | 0.000612    |
| times/evaluation_paths         | 25.5        |
| times/timestep_after_hook      | 0.0038      |
| times/timestep_before_hook     | 0.00797     |
| times/train                    | 56.2        |
| timestep                       | 1000        |
| timesteps_total                | 204000      |
| train-steps                    | 204000      |
| training/Q/q1_loss             | 89.63059    |
| training/sac_pi/alpha          | 0.15644605  |
| training/sac_pi/alpha_loss     | -0.16022015 |
| training/sac_pi/logp_pi        | 4.6137543   |
| training/sac_pi/pi_entropy     | 3.6471772   |
| training/sac_pi/pi_global_norm | 1.5888493   |
| training/sac_pi/policy_loss    | -190.53296  |
| training/sac_pi/std            | 0.54192144  |
| training/sac_pi/valid_num      | 4940.0      |
| training/sac_Q/q1              | 179.05017   |
| training/sac_Q/q2              | 179.22787   |
| training/sac_Q/q2_loss         | 90.00483    |
| training/sac_Q/q_global_norm   | 196.98192   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16225849 |
| epoch                          | 204        |
| evaluation/episode-length-avg  | 879        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 321        |
| evaluation/episode-length-std  | 219        |
| evaluation/return-average      | 4088.4512  |
| evaluation/return-max          | 4793.584   |
| evaluation/return-min          | 1117.3472  |
| evaluation/return-std          | 1155.6958  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45688      |
| perf/AverageLength             | 879        |
| perf/AverageReturn             | 4088.4512  |
| perf/NormalizedReturn          | 0.89       |
| Q-avg                          | 182.28726  |
| Q-std                          | 111.42994  |
| Q_loss                         | 94.7025    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 204        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000477   |
| times/evaluation_paths         | 26.9       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 205000     |
| train-steps                    | 205000     |
| training/Q/q1_loss             | 104.06353  |
| training/sac_pi/alpha          | 0.1622574  |
| training/sac_pi/alpha_loss     | 0.05668759 |
| training/sac_pi/logp_pi        | 5.350165   |
| training/sac_pi/pi_entropy     | 3.6107717  |
| training/sac_pi/pi_global_norm | 1.7873617  |
| training/sac_pi/policy_loss    | -188.36171 |
| training/sac_pi/std            | 0.5334734  |
| training/sac_pi/valid_num      | 4921.0     |
| training/sac_Q/q1              | 175.92221  |
| training/sac_Q/q2              | 174.85541  |
| training/sac_Q/q2_loss         | 104.58174  |
| training/sac_Q/q_global_norm   | 220.02773  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15562008  |
| epoch                          | 205         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4808.69     |
| evaluation/return-max          | 4828.26     |
| evaluation/return-min          | 4777.4385   |
| evaluation/return-std          | 15.722305   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.86        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 82.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45537       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4808.69     |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 173.04202   |
| Q-std                          | 126.95494   |
| Q_loss                         | 107.55865   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 205         |
| times/epoch_after_hook         | 3.27e-06    |
| times/epoch_before_hook        | 0.000278    |
| times/epoch_rollout_model      | 473         |
| times/evaluation_metrics       | 0.000523    |
| times/evaluation_paths         | 30.2        |
| times/timestep_after_hook      | 0.0035      |
| times/timestep_before_hook     | 0.00794     |
| times/train                    | 55.7        |
| timestep                       | 1000        |
| timesteps_total                | 206000      |
| train-steps                    | 206000      |
| training/Q/q1_loss             | 119.85289   |
| training/sac_pi/alpha          | 0.15562327  |
| training/sac_pi/alpha_loss     | -0.04217585 |
| training/sac_pi/logp_pi        | 5.4794474   |
| training/sac_pi/pi_entropy     | 3.6747925   |
| training/sac_pi/pi_global_norm | 1.4117932   |
| training/sac_pi/policy_loss    | -191.90321  |
| training/sac_pi/std            | 0.57047546  |
| training/sac_pi/valid_num      | 4902.0      |
| training/sac_Q/q1              | 174.98425   |
| training/sac_Q/q2              | 175.93475   |
| training/sac_Q/q2_loss         | 120.24554   |
| training/sac_Q/q_global_norm   | 250.05424   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16119058  |
| epoch                          | 206         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4906.2515   |
| evaluation/return-max          | 4969.5093   |
| evaluation/return-min          | 4853.1704   |
| evaluation/return-std          | 38.352398   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.89        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 83.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45435       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4906.2515   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 193.14774   |
| Q-std                          | 102.17147   |
| Q_loss                         | 87.91055    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 206         |
| times/epoch_after_hook         | 1.99e-06    |
| times/epoch_before_hook        | 0.000116    |
| times/epoch_rollout_model      | 475         |
| times/evaluation_metrics       | 0.000527    |
| times/evaluation_paths         | 30.2        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00778     |
| times/train                    | 55.5        |
| timestep                       | 1000        |
| timesteps_total                | 207000      |
| train-steps                    | 207000      |
| training/Q/q1_loss             | 102.15399   |
| training/sac_pi/alpha          | 0.16121078  |
| training/sac_pi/alpha_loss     | 0.035817288 |
| training/sac_pi/logp_pi        | 5.2741227   |
| training/sac_pi/pi_entropy     | 3.7333329   |
| training/sac_pi/pi_global_norm | 1.7631507   |
| training/sac_pi/policy_loss    | -189.19858  |
| training/sac_pi/std            | 0.5584995   |
| training/sac_pi/valid_num      | 4922.0      |
| training/sac_Q/q1              | 178.2287    |
| training/sac_Q/q2              | 177.64671   |
| training/sac_Q/q2_loss         | 102.749756  |
| training/sac_Q/q_global_norm   | 343.8304    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1561813   |
| epoch                          | 207         |
| evaluation/episode-length-avg  | 313         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 136         |
| evaluation/episode-length-std  | 344         |
| evaluation/return-average      | 1293.6069   |
| evaluation/return-max          | 4943.2847   |
| evaluation/return-min          | 364.82416   |
| evaluation/return-std          | 1822.2891   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.89        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 83          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45662       |
| perf/AverageLength             | 313         |
| perf/AverageReturn             | 1293.6069   |
| perf/NormalizedReturn          | 0.281       |
| Q-avg                          | 184.37497   |
| Q-std                          | 114.04191   |
| Q_loss                         | 97.42781    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 207         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 472         |
| times/evaluation_metrics       | 0.000575    |
| times/evaluation_paths         | 9.35        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00798     |
| times/train                    | 55.5        |
| timestep                       | 1000        |
| timesteps_total                | 208000      |
| train-steps                    | 208000      |
| training/Q/q1_loss             | 92.1743     |
| training/sac_pi/alpha          | 0.15616056  |
| training/sac_pi/alpha_loss     | -0.07129658 |
| training/sac_pi/logp_pi        | 4.921326    |
| training/sac_pi/pi_entropy     | 3.6701763   |
| training/sac_pi/pi_global_norm | 1.3539436   |
| training/sac_pi/policy_loss    | -184.70096  |
| training/sac_pi/std            | 0.5472919   |
| training/sac_pi/valid_num      | 4930.0      |
| training/sac_Q/q1              | 171.17082   |
| training/sac_Q/q2              | 170.8182    |
| training/sac_Q/q2_loss         | 91.97314    |
| training/sac_Q/q_global_norm   | 411.42862   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15799733  |
| epoch                          | 208         |
| evaluation/episode-length-avg  | 762         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 146         |
| evaluation/episode-length-std  | 367         |
| evaluation/return-average      | 3564.0151   |
| evaluation/return-max          | 4819.971    |
| evaluation/return-min          | 460.16113   |
| evaluation/return-std          | 1874.6079   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 82.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45607       |
| perf/AverageLength             | 762         |
| perf/AverageReturn             | 3564.0151   |
| perf/NormalizedReturn          | 0.776       |
| Q-avg                          | 160.36296   |
| Q-std                          | 135.95418   |
| Q_loss                         | 110.420944  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 208         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000109    |
| times/epoch_rollout_model      | 473         |
| times/evaluation_metrics       | 0.000532    |
| times/evaluation_paths         | 23.2        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00784     |
| times/train                    | 55.3        |
| timestep                       | 1000        |
| timesteps_total                | 209000      |
| train-steps                    | 209000      |
| training/Q/q1_loss             | 99.17634    |
| training/sac_pi/alpha          | 0.15802138  |
| training/sac_pi/alpha_loss     | 0.016713252 |
| training/sac_pi/logp_pi        | 4.422685    |
| training/sac_pi/pi_entropy     | 3.4696865   |
| training/sac_pi/pi_global_norm | 1.4636503   |
| training/sac_pi/policy_loss    | -186.43773  |
| training/sac_pi/std            | 0.50336266  |
| training/sac_pi/valid_num      | 4982.0      |
| training/sac_Q/q1              | 178.42996   |
| training/sac_Q/q2              | 178.61263   |
| training/sac_Q/q2_loss         | 99.38628    |
| training/sac_Q/q_global_norm   | 194.01747   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16828777 |
| epoch                          | 209        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4725.6426  |
| evaluation/return-max          | 4755.875   |
| evaluation/return-min          | 4683.232   |
| evaluation/return-std          | 22.180956  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.77       |
| model/origin_ret               | 82.1       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45515      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4725.6426  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 174.81783  |
| Q-std                          | 107.25312  |
| Q_loss                         | 107.996544 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 209        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.00028    |
| times/epoch_rollout_model      | 474        |
| times/evaluation_metrics       | 0.000604   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00355    |
| times/timestep_before_hook     | 0.00798    |
| times/train                    | 55.2       |
| timestep                       | 1000       |
| timesteps_total                | 210000     |
| train-steps                    | 210000     |
| training/Q/q1_loss             | 95.623634  |
| training/sac_pi/alpha          | 0.16830125 |
| training/sac_pi/alpha_loss     | 0.11826881 |
| training/sac_pi/logp_pi        | 4.4331093  |
| training/sac_pi/pi_entropy     | 3.8112588  |
| training/sac_pi/pi_global_norm | 1.3856902  |
| training/sac_pi/policy_loss    | -180.24178 |
| training/sac_pi/std            | 0.53855205 |
| training/sac_pi/valid_num      | 4955.0     |
| training/sac_Q/q1              | 170.79662  |
| training/sac_Q/q2              | 171.61948  |
| training/sac_Q/q2_loss         | 95.944145  |
| training/sac_Q/q_global_norm   | 219.1448   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16633567  |
| epoch                          | 210         |
| evaluation/episode-length-avg  | 732         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 107         |
| evaluation/episode-length-std  | 409         |
| evaluation/return-average      | 3448.3445   |
| evaluation/return-max          | 4895.742    |
| evaluation/return-min          | 189.12978   |
| evaluation/return-std          | 2133.3784   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45612       |
| perf/AverageLength             | 732         |
| perf/AverageReturn             | 3448.3445   |
| perf/NormalizedReturn          | 0.751       |
| Q-avg                          | 183.16074   |
| Q-std                          | 104.33906   |
| Q_loss                         | 95.32681    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 210         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 476         |
| times/evaluation_metrics       | 0.000481    |
| times/evaluation_paths         | 22.4        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 55.9        |
| timestep                       | 1000        |
| timesteps_total                | 211000      |
| train-steps                    | 211000      |
| training/Q/q1_loss             | 89.5738     |
| training/sac_pi/alpha          | 0.16634706  |
| training/sac_pi/alpha_loss     | -0.15059204 |
| training/sac_pi/logp_pi        | 4.3022423   |
| training/sac_pi/pi_entropy     | 3.8198013   |
| training/sac_pi/pi_global_norm | 1.4073694   |
| training/sac_pi/policy_loss    | -188.03694  |
| training/sac_pi/std            | 0.53963774  |
| training/sac_pi/valid_num      | 4927.0      |
| training/sac_Q/q1              | 176.50015   |
| training/sac_Q/q2              | 176.7267    |
| training/sac_Q/q2_loss         | 90.43256    |
| training/sac_Q/q_global_norm   | 214.9567    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15880795  |
| epoch                          | 211         |
| evaluation/episode-length-avg  | 783         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 480         |
| evaluation/episode-length-std  | 201         |
| evaluation/return-average      | 3340.979    |
| evaluation/return-max          | 4549.302    |
| evaluation/return-min          | 1814.6097   |
| evaluation/return-std          | 996.36804   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 82.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45524       |
| perf/AverageLength             | 783         |
| perf/AverageReturn             | 3340.979    |
| perf/NormalizedReturn          | 0.727       |
| Q-avg                          | 180.05276   |
| Q-std                          | 103.20048   |
| Q_loss                         | 86.80643    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 211         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000105    |
| times/epoch_rollout_model      | 471         |
| times/evaluation_metrics       | 0.000522    |
| times/evaluation_paths         | 23.8        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00794     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 212000      |
| train-steps                    | 212000      |
| training/Q/q1_loss             | 105.870636  |
| training/sac_pi/alpha          | 0.15876642  |
| training/sac_pi/alpha_loss     | -0.05458597 |
| training/sac_pi/logp_pi        | 4.874611    |
| training/sac_pi/pi_entropy     | 3.6840508   |
| training/sac_pi/pi_global_norm | 1.3828074   |
| training/sac_pi/policy_loss    | -195.00673  |
| training/sac_pi/std            | 0.55703634  |
| training/sac_pi/valid_num      | 4888.0      |
| training/sac_Q/q1              | 179.37363   |
| training/sac_Q/q2              | 179.43546   |
| training/sac_Q/q2_loss         | 105.516136  |
| training/sac_Q/q_global_norm   | 231.26845   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15296803   |
| epoch                          | 212          |
| evaluation/episode-length-avg  | 660          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 147          |
| evaluation/episode-length-std  | 416          |
| evaluation/return-average      | 3265.2349    |
| evaluation/return-max          | 5175.394     |
| evaluation/return-min          | 450.46497    |
| evaluation/return-std          | 2288.6614    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.84         |
| model/origin_ret               | 83.4         |
| model/penalty_ret              | 82.1         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45542        |
| perf/AverageLength             | 660          |
| perf/AverageReturn             | 3265.2349    |
| perf/NormalizedReturn          | 0.711        |
| Q-avg                          | 184.95029    |
| Q-std                          | 108.389725   |
| Q_loss                         | 107.46396    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 212          |
| times/epoch_after_hook         | 1.8e-06      |
| times/epoch_before_hook        | 0.000102     |
| times/epoch_rollout_model      | 471          |
| times/evaluation_metrics       | 0.000491     |
| times/evaluation_paths         | 20.4         |
| times/timestep_after_hook      | 0.00367      |
| times/timestep_before_hook     | 0.00797      |
| times/train                    | 55.7         |
| timestep                       | 1000         |
| timesteps_total                | 213000       |
| train-steps                    | 213000       |
| training/Q/q1_loss             | 67.18873     |
| training/sac_pi/alpha          | 0.1529549    |
| training/sac_pi/alpha_loss     | -0.008617888 |
| training/sac_pi/logp_pi        | 4.4136457    |
| training/sac_pi/pi_entropy     | 3.5044816    |
| training/sac_pi/pi_global_norm | 1.4126288    |
| training/sac_pi/policy_loss    | -195.54056   |
| training/sac_pi/std            | 0.52257866   |
| training/sac_pi/valid_num      | 4952.0       |
| training/sac_Q/q1              | 185.95886    |
| training/sac_Q/q2              | 185.33487    |
| training/sac_Q/q2_loss         | 66.34209     |
| training/sac_Q/q_global_norm   | 208.74055    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15275186  |
| epoch                          | 213         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4969.849    |
| evaluation/return-max          | 5004.4453   |
| evaluation/return-min          | 4932.5537   |
| evaluation/return-std          | 21.685276   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.89        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 83.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45644       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4969.849    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 179.68536   |
| Q-std                          | 136.86101   |
| Q_loss                         | 98.213      |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 213         |
| times/epoch_after_hook         | 1.93e-06    |
| times/epoch_before_hook        | 0.000326    |
| times/epoch_rollout_model      | 469         |
| times/evaluation_metrics       | 0.000578    |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.008       |
| times/train                    | 55.9        |
| timestep                       | 1000        |
| timesteps_total                | 214000      |
| train-steps                    | 214000      |
| training/Q/q1_loss             | 72.71494    |
| training/sac_pi/alpha          | 0.15275384  |
| training/sac_pi/alpha_loss     | 0.037291817 |
| training/sac_pi/logp_pi        | 4.21374     |
| training/sac_pi/pi_entropy     | 3.6706269   |
| training/sac_pi/pi_global_norm | 1.4454162   |
| training/sac_pi/policy_loss    | -203.14201  |
| training/sac_pi/std            | 0.5228979   |
| training/sac_pi/valid_num      | 4917.0      |
| training/sac_Q/q1              | 190.6198    |
| training/sac_Q/q2              | 190.48105   |
| training/sac_Q/q2_loss         | 72.47439    |
| training/sac_Q/q_global_norm   | 295.72897   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15511316   |
| epoch                          | 214          |
| evaluation/episode-length-avg  | 742          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 138          |
| evaluation/episode-length-std  | 395          |
| evaluation/return-average      | 3468.9617    |
| evaluation/return-max          | 4865.664     |
| evaluation/return-min          | 314.79385    |
| evaluation/return-std          | 2063.5447    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.83         |
| model/origin_ret               | 84.4         |
| model/penalty_ret              | 82.6         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45247        |
| perf/AverageLength             | 742          |
| perf/AverageReturn             | 3468.9617    |
| perf/NormalizedReturn          | 0.755        |
| Q-avg                          | 186.587      |
| Q-std                          | 125.603546   |
| Q_loss                         | 87.19076     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 214          |
| times/epoch_after_hook         | 1.87e-06     |
| times/epoch_before_hook        | 0.00013      |
| times/epoch_rollout_model      | 469          |
| times/evaluation_metrics       | 0.000566     |
| times/evaluation_paths         | 22.8         |
| times/timestep_after_hook      | 0.00364      |
| times/timestep_before_hook     | 0.00805      |
| times/train                    | 56.1         |
| timestep                       | 1000         |
| timesteps_total                | 215000       |
| train-steps                    | 215000       |
| training/Q/q1_loss             | 98.00983     |
| training/sac_pi/alpha          | 0.15510711   |
| training/sac_pi/alpha_loss     | -0.015490331 |
| training/sac_pi/logp_pi        | 4.507418     |
| training/sac_pi/pi_entropy     | 3.6547897    |
| training/sac_pi/pi_global_norm | 1.2994219    |
| training/sac_pi/policy_loss    | -191.39444   |
| training/sac_pi/std            | 0.5432701    |
| training/sac_pi/valid_num      | 4951.0       |
| training/sac_Q/q1              | 180.88492    |
| training/sac_Q/q2              | 181.14226    |
| training/sac_Q/q2_loss         | 98.35518     |
| training/sac_Q/q_global_norm   | 353.15732    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16075382   |
| epoch                          | 215          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4729.089     |
| evaluation/return-max          | 4758.586     |
| evaluation/return-min          | 4704.671     |
| evaluation/return-std          | 17.63322     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.9          |
| model/origin_ret               | 84.5         |
| model/penalty_ret              | 81.9         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45620        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4729.089     |
| perf/NormalizedReturn          | 1.03         |
| Q-avg                          | 186.63464    |
| Q-std                          | 114.69376    |
| Q_loss                         | 86.53908     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 215          |
| times/epoch_after_hook         | 1.99e-06     |
| times/epoch_before_hook        | 0.000108     |
| times/epoch_rollout_model      | 471          |
| times/evaluation_metrics       | 0.000527     |
| times/evaluation_paths         | 30.2         |
| times/timestep_after_hook      | 0.0036       |
| times/timestep_before_hook     | 0.00797      |
| times/train                    | 55           |
| timestep                       | 1000         |
| timesteps_total                | 216000       |
| train-steps                    | 216000       |
| training/Q/q1_loss             | 95.85029     |
| training/sac_pi/alpha          | 0.1607547    |
| training/sac_pi/alpha_loss     | 0.0027206356 |
| training/sac_pi/logp_pi        | 4.2281613    |
| training/sac_pi/pi_entropy     | 3.7079353    |
| training/sac_pi/pi_global_norm | 1.4450976    |
| training/sac_pi/policy_loss    | -193.57518   |
| training/sac_pi/std            | 0.5241167    |
| training/sac_pi/valid_num      | 4967.0       |
| training/sac_Q/q1              | 184.16122    |
| training/sac_Q/q2              | 183.52724    |
| training/sac_Q/q2_loss         | 96.45469     |
| training/sac_Q/q_global_norm   | 197.43666    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16189726  |
| epoch                          | 216         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4857.045    |
| evaluation/return-max          | 4881.379    |
| evaluation/return-min          | 4840.182    |
| evaluation/return-std          | 13.299109   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.86        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 83.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45427       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4857.045    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 187.41393   |
| Q-std                          | 111.17205   |
| Q_loss                         | 97.771065   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 216         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 473         |
| times/evaluation_metrics       | 0.000552    |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00787     |
| times/train                    | 55.5        |
| timestep                       | 1000        |
| timesteps_total                | 217000      |
| train-steps                    | 217000      |
| training/Q/q1_loss             | 93.57558    |
| training/sac_pi/alpha          | 0.16187711  |
| training/sac_pi/alpha_loss     | 0.047543827 |
| training/sac_pi/logp_pi        | 4.0389075   |
| training/sac_pi/pi_entropy     | 3.5642543   |
| training/sac_pi/pi_global_norm | 1.5094023   |
| training/sac_pi/policy_loss    | -196.84544  |
| training/sac_pi/std            | 0.49405417  |
| training/sac_pi/valid_num      | 4945.0      |
| training/sac_Q/q1              | 187.00005   |
| training/sac_Q/q2              | 186.65718   |
| training/sac_Q/q2_loss         | 92.11749    |
| training/sac_Q/q_global_norm   | 228.87485   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16145495  |
| epoch                          | 217         |
| evaluation/episode-length-avg  | 990         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 896         |
| evaluation/episode-length-std  | 31.2        |
| evaluation/return-average      | 4275.904    |
| evaluation/return-max          | 4471.0005   |
| evaluation/return-min          | 3911.5881   |
| evaluation/return-std          | 171.05022   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45547       |
| perf/AverageLength             | 990         |
| perf/AverageReturn             | 4275.904    |
| perf/NormalizedReturn          | 0.931       |
| Q-avg                          | 182.58768   |
| Q-std                          | 112.26317   |
| Q_loss                         | 97.67302    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 217         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000332    |
| times/epoch_rollout_model      | 469         |
| times/evaluation_metrics       | 0.000616    |
| times/evaluation_paths         | 30.1        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00793     |
| times/train                    | 55.4        |
| timestep                       | 1000        |
| timesteps_total                | 218000      |
| train-steps                    | 218000      |
| training/Q/q1_loss             | 86.075386   |
| training/sac_pi/alpha          | 0.16146398  |
| training/sac_pi/alpha_loss     | -0.14569972 |
| training/sac_pi/logp_pi        | 4.3746405   |
| training/sac_pi/pi_entropy     | 3.4690495   |
| training/sac_pi/pi_global_norm | 1.4359822   |
| training/sac_pi/policy_loss    | -192.97977  |
| training/sac_pi/std            | 0.4912409   |
| training/sac_pi/valid_num      | 4930.0      |
| training/sac_Q/q1              | 183.02007   |
| training/sac_Q/q2              | 183.4808    |
| training/sac_Q/q2_loss         | 86.51535    |
| training/sac_Q/q_global_norm   | 234.43599   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15764381 |
| epoch                          | 218        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4640.692   |
| evaluation/return-max          | 4670.61    |
| evaluation/return-min          | 4569.7837  |
| evaluation/return-std          | 27.618042  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.8        |
| model/origin_ret               | 82.9       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45430      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4640.692   |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 176.19589  |
| Q-std                          | 105.54575  |
| Q_loss                         | 109.690384 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 218        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 471        |
| times/evaluation_metrics       | 0.000523   |
| times/evaluation_paths         | 30.4       |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.0079     |
| times/train                    | 55.5       |
| timestep                       | 1000       |
| timesteps_total                | 219000     |
| train-steps                    | 219000     |
| training/Q/q1_loss             | 112.51337  |
| training/sac_pi/alpha          | 0.15764147 |
| training/sac_pi/alpha_loss     | 0.16280536 |
| training/sac_pi/logp_pi        | 4.1423063  |
| training/sac_pi/pi_entropy     | 3.5235932  |
| training/sac_pi/pi_global_norm | 1.562378   |
| training/sac_pi/policy_loss    | -194.73828 |
| training/sac_pi/std            | 0.5154127  |
| training/sac_pi/valid_num      | 4953.0     |
| training/sac_Q/q1              | 185.27737  |
| training/sac_Q/q2              | 185.37537  |
| training/sac_Q/q2_loss         | 112.954254 |
| training/sac_Q/q_global_norm   | 272.55447  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15986636  |
| epoch                          | 219         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4938.2334   |
| evaluation/return-max          | 4983.3203   |
| evaluation/return-min          | 4858.247    |
| evaluation/return-std          | 42.132652   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.89        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 82.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45760       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4938.2334   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 191.46693   |
| Q-std                          | 108.13646   |
| Q_loss                         | 113.6628    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 219         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000105    |
| times/epoch_rollout_model      | 470         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 30.2        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00782     |
| times/train                    | 55.3        |
| timestep                       | 1000        |
| timesteps_total                | 220000      |
| train-steps                    | 220000      |
| training/Q/q1_loss             | 97.76371    |
| training/sac_pi/alpha          | 0.15989543  |
| training/sac_pi/alpha_loss     | -0.06523557 |
| training/sac_pi/logp_pi        | 3.6258824   |
| training/sac_pi/pi_entropy     | 3.7651558   |
| training/sac_pi/pi_global_norm | 1.5828974   |
| training/sac_pi/policy_loss    | -183.0243   |
| training/sac_pi/std            | 0.50964683  |
| training/sac_pi/valid_num      | 4978.0      |
| training/sac_Q/q1              | 175.8925    |
| training/sac_Q/q2              | 175.29526   |
| training/sac_Q/q2_loss         | 98.1965     |
| training/sac_Q/q_global_norm   | 200.26297   |
---------------------------------------------------------------------------------
[WARN] 220 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.16069154   |
| epoch                          | 220          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4662.292     |
| evaluation/return-max          | 4702.7837    |
| evaluation/return-min          | 4618.248     |
| evaluation/return-std          | 23.227633    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.86         |
| model/origin_ret               | 84.1         |
| model/penalty_ret              | 82.7         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45581        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4662.292     |
| perf/NormalizedReturn          | 1.02         |
| Q-avg                          | 181.32187    |
| Q-std                          | 133.4793     |
| Q_loss                         | 96.704254    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 220          |
| times/epoch_after_hook         | 1.8e-06      |
| times/epoch_before_hook        | 0.000119     |
| times/epoch_rollout_model      | 469          |
| times/evaluation_metrics       | 0.000492     |
| times/evaluation_paths         | 30.3         |
| times/timestep_after_hook      | 0.00361      |
| times/timestep_before_hook     | 0.00786      |
| times/train                    | 55.6         |
| timestep                       | 1000         |
| timesteps_total                | 221000       |
| train-steps                    | 221000       |
| training/Q/q1_loss             | 107.45328    |
| training/sac_pi/alpha          | 0.1606979    |
| training/sac_pi/alpha_loss     | -0.061263252 |
| training/sac_pi/logp_pi        | 5.092415     |
| training/sac_pi/pi_entropy     | 3.7254448    |
| training/sac_pi/pi_global_norm | 1.5439894    |
| training/sac_pi/policy_loss    | -192.10239   |
| training/sac_pi/std            | 0.5653871    |
| training/sac_pi/valid_num      | 4907.0       |
| training/sac_Q/q1              | 177.98318    |
| training/sac_Q/q2              | 179.452      |
| training/sac_Q/q2_loss         | 107.059814   |
| training/sac_Q/q_global_norm   | 213.95642    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15966564  |
| epoch                          | 221         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4830.913    |
| evaluation/return-max          | 4870.791    |
| evaluation/return-min          | 4789.1367   |
| evaluation/return-std          | 20.044907   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 83.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45415       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4830.913    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 171.1295    |
| Q-std                          | 137.43106   |
| Q_loss                         | 103.66103   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 221         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000286    |
| times/epoch_rollout_model      | 471         |
| times/evaluation_metrics       | 0.000722    |
| times/evaluation_paths         | 30.6        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00793     |
| times/train                    | 55.4        |
| timestep                       | 1000        |
| timesteps_total                | 222000      |
| train-steps                    | 222000      |
| training/Q/q1_loss             | 110.570465  |
| training/sac_pi/alpha          | 0.15969822  |
| training/sac_pi/alpha_loss     | -0.36177748 |
| training/sac_pi/logp_pi        | 5.3553643   |
| training/sac_pi/pi_entropy     | 3.8879313   |
| training/sac_pi/pi_global_norm | 1.3749976   |
| training/sac_pi/policy_loss    | -186.6381   |
| training/sac_pi/std            | 0.6014436   |
| training/sac_pi/valid_num      | 4834.0      |
| training/sac_Q/q1              | 164.7428    |
| training/sac_Q/q2              | 163.96841   |
| training/sac_Q/q2_loss         | 110.70018   |
| training/sac_Q/q_global_norm   | 331.2794    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16183375  |
| epoch                          | 222         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4669.718    |
| evaluation/return-max          | 4711.674    |
| evaluation/return-min          | 4625.2627   |
| evaluation/return-std          | 23.782581   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 82.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45488       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4669.718    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 192.9779    |
| Q-std                          | 102.81897   |
| Q_loss                         | 93.69598    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 222         |
| times/epoch_after_hook         | 2.21e-06    |
| times/epoch_before_hook        | 0.000116    |
| times/epoch_rollout_model      | 472         |
| times/evaluation_metrics       | 0.000632    |
| times/evaluation_paths         | 30.1        |
| times/timestep_after_hook      | 0.00353     |
| times/timestep_before_hook     | 0.00783     |
| times/train                    | 55.5        |
| timestep                       | 1000        |
| timesteps_total                | 223000      |
| train-steps                    | 223000      |
| training/Q/q1_loss             | 97.12787    |
| training/sac_pi/alpha          | 0.16180831  |
| training/sac_pi/alpha_loss     | 0.072082944 |
| training/sac_pi/logp_pi        | 4.5484266   |
| training/sac_pi/pi_entropy     | 3.8193517   |
| training/sac_pi/pi_global_norm | 1.2129455   |
| training/sac_pi/policy_loss    | -189.73335  |
| training/sac_pi/std            | 0.5530618   |
| training/sac_pi/valid_num      | 4922.0      |
| training/sac_Q/q1              | 177.96376   |
| training/sac_Q/q2              | 177.00522   |
| training/sac_Q/q2_loss         | 97.809425   |
| training/sac_Q/q_global_norm   | 251.73914   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16340281   |
| epoch                          | 223          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4763.921     |
| evaluation/return-max          | 4818.692     |
| evaluation/return-min          | 4726.352     |
| evaluation/return-std          | 25.129608    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3            |
| model/origin_ret               | 86.2         |
| model/penalty_ret              | 82.5         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45396        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4763.921     |
| perf/NormalizedReturn          | 1.04         |
| Q-avg                          | 164.85828    |
| Q-std                          | 146.44913    |
| Q_loss                         | 102.1117     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 223          |
| times/epoch_after_hook         | 1.68e-06     |
| times/epoch_before_hook        | 0.000121     |
| times/epoch_rollout_model      | 469          |
| times/evaluation_metrics       | 0.000553     |
| times/evaluation_paths         | 29.8         |
| times/timestep_after_hook      | 0.00372      |
| times/timestep_before_hook     | 0.00792      |
| times/train                    | 54.5         |
| timestep                       | 1000         |
| timesteps_total                | 224000       |
| train-steps                    | 224000       |
| training/Q/q1_loss             | 81.78189     |
| training/sac_pi/alpha          | 0.16344592   |
| training/sac_pi/alpha_loss     | -0.094774924 |
| training/sac_pi/logp_pi        | 4.4382052    |
| training/sac_pi/pi_entropy     | 3.5662518    |
| training/sac_pi/pi_global_norm | 1.575451     |
| training/sac_pi/policy_loss    | -191.5889    |
| training/sac_pi/std            | 0.5074622    |
| training/sac_pi/valid_num      | 4942.0       |
| training/sac_Q/q1              | 180.91257    |
| training/sac_Q/q2              | 179.76602    |
| training/sac_Q/q2_loss         | 80.85077     |
| training/sac_Q/q_global_norm   | 175.22913    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16161554  |
| epoch                          | 224         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4622.84     |
| evaluation/return-max          | 4658.7764   |
| evaluation/return-min          | 4573.287    |
| evaluation/return-std          | 26.209906   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.82        |
| model/origin_ret               | 83.6        |
| model/penalty_ret              | 83          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45454       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4622.84     |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 184.03365   |
| Q-std                          | 112.63761   |
| Q_loss                         | 109.38842   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 224         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000105    |
| times/epoch_rollout_model      | 470         |
| times/evaluation_metrics       | 0.000629    |
| times/evaluation_paths         | 30.4        |
| times/timestep_after_hook      | 0.00353     |
| times/timestep_before_hook     | 0.00803     |
| times/train                    | 55.4        |
| timestep                       | 1000        |
| timesteps_total                | 225000      |
| train-steps                    | 225000      |
| training/Q/q1_loss             | 96.407974   |
| training/sac_pi/alpha          | 0.16161416  |
| training/sac_pi/alpha_loss     | -0.07992948 |
| training/sac_pi/logp_pi        | 4.5200553   |
| training/sac_pi/pi_entropy     | 3.674974    |
| training/sac_pi/pi_global_norm | 1.5715262   |
| training/sac_pi/policy_loss    | -192.7778   |
| training/sac_pi/std            | 0.5421369   |
| training/sac_pi/valid_num      | 4947.0      |
| training/sac_Q/q1              | 179.6431    |
| training/sac_Q/q2              | 179.98232   |
| training/sac_Q/q2_loss         | 95.63622    |
| training/sac_Q/q_global_norm   | 288.38272   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16122961  |
| epoch                          | 225         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4699.0923   |
| evaluation/return-max          | 4761.8154   |
| evaluation/return-min          | 4606.766    |
| evaluation/return-std          | 45.885246   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.77        |
| model/origin_ret               | 82.5        |
| model/penalty_ret              | 82.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45325       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4699.0923   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 175.13687   |
| Q-std                          | 151.4342    |
| Q_loss                         | 95.88663    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 225         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000278    |
| times/epoch_rollout_model      | 469         |
| times/evaluation_metrics       | 0.000514    |
| times/evaluation_paths         | 30.1        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00794     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 226000      |
| train-steps                    | 226000      |
| training/Q/q1_loss             | 95.05054    |
| training/sac_pi/alpha          | 0.16125445  |
| training/sac_pi/alpha_loss     | -0.24320373 |
| training/sac_pi/logp_pi        | 4.702728    |
| training/sac_pi/pi_entropy     | 3.5581505   |
| training/sac_pi/pi_global_norm | 1.3268877   |
| training/sac_pi/policy_loss    | -187.35551  |
| training/sac_pi/std            | 0.5179778   |
| training/sac_pi/valid_num      | 4933.0      |
| training/sac_Q/q1              | 176.68379   |
| training/sac_Q/q2              | 175.71555   |
| training/sac_Q/q2_loss         | 95.22675    |
| training/sac_Q/q_global_norm   | 262.17746   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16043015   |
| epoch                          | 226          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4879.5283    |
| evaluation/return-max          | 4910.2603    |
| evaluation/return-min          | 4822.5693    |
| evaluation/return-std          | 29.489101    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.91         |
| model/origin_ret               | 84.4         |
| model/penalty_ret              | 81.9         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45582        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4879.5283    |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 180.79977    |
| Q-std                          | 112.037865   |
| Q_loss                         | 112.78131    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 226          |
| times/epoch_after_hook         | 1.88e-06     |
| times/epoch_before_hook        | 0.000109     |
| times/epoch_rollout_model      | 470          |
| times/evaluation_metrics       | 0.000536     |
| times/evaluation_paths         | 30.3         |
| times/timestep_after_hook      | 0.00361      |
| times/timestep_before_hook     | 0.00802      |
| times/train                    | 55.7         |
| timestep                       | 1000         |
| timesteps_total                | 227000       |
| train-steps                    | 227000       |
| training/Q/q1_loss             | 105.73524    |
| training/sac_pi/alpha          | 0.16042177   |
| training/sac_pi/alpha_loss     | 0.0031369638 |
| training/sac_pi/logp_pi        | 4.7061043    |
| training/sac_pi/pi_entropy     | 3.5144284    |
| training/sac_pi/pi_global_norm | 1.6903136    |
| training/sac_pi/policy_loss    | -200.25255   |
| training/sac_pi/std            | 0.52138895   |
| training/sac_pi/valid_num      | 4967.0       |
| training/sac_Q/q1              | 189.84981    |
| training/sac_Q/q2              | 187.92       |
| training/sac_Q/q2_loss         | 106.10378    |
| training/sac_Q/q_global_norm   | 187.79063    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16419211 |
| epoch                          | 227        |
| evaluation/episode-length-avg  | 378        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 91         |
| evaluation/episode-length-std  | 304        |
| evaluation/return-average      | 1469.6321  |
| evaluation/return-max          | 4650.6626  |
| evaluation/return-min          | 181.86684  |
| evaluation/return-std          | 1459.4521  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.86       |
| model/origin_ret               | 83.3       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45441      |
| perf/AverageLength             | 378        |
| perf/AverageReturn             | 1469.6321  |
| perf/NormalizedReturn          | 0.32       |
| Q-avg                          | 163.23256  |
| Q-std                          | 163.02034  |
| Q_loss                         | 116.82682  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 227        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 469        |
| times/evaluation_metrics       | 0.000475   |
| times/evaluation_paths         | 11.5       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00798    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 228000     |
| train-steps                    | 228000     |
| training/Q/q1_loss             | 94.154884  |
| training/sac_pi/alpha          | 0.16417776 |
| training/sac_pi/alpha_loss     | 0.20943347 |
| training/sac_pi/logp_pi        | 4.249457   |
| training/sac_pi/pi_entropy     | 3.472438   |
| training/sac_pi/pi_global_norm | 1.7317847  |
| training/sac_pi/policy_loss    | -201.63702 |
| training/sac_pi/std            | 0.49457633 |
| training/sac_pi/valid_num      | 4996.0     |
| training/sac_Q/q1              | 195.65662  |
| training/sac_Q/q2              | 193.6583   |
| training/sac_Q/q2_loss         | 94.566895  |
| training/sac_Q/q_global_norm   | 159.14864  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16909534   |
| epoch                          | 228          |
| evaluation/episode-length-avg  | 409          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 150          |
| evaluation/episode-length-std  | 387          |
| evaluation/return-average      | 1728.0277    |
| evaluation/return-max          | 4729.047     |
| evaluation/return-min          | 432.08124    |
| evaluation/return-std          | 1948.0525    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.88         |
| model/origin_ret               | 83.8         |
| model/penalty_ret              | 82.1         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45499        |
| perf/AverageLength             | 409          |
| perf/AverageReturn             | 1728.0277    |
| perf/NormalizedReturn          | 0.376        |
| Q-avg                          | 191.00975    |
| Q-std                          | 107.18227    |
| Q_loss                         | 75.502754    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 228          |
| times/epoch_after_hook         | 1.83e-06     |
| times/epoch_before_hook        | 0.000106     |
| times/epoch_rollout_model      | 474          |
| times/evaluation_metrics       | 0.000485     |
| times/evaluation_paths         | 12.9         |
| times/timestep_after_hook      | 0.0039       |
| times/timestep_before_hook     | 0.00816      |
| times/train                    | 57.8         |
| timestep                       | 1000         |
| timesteps_total                | 229000       |
| train-steps                    | 229000       |
| training/Q/q1_loss             | 82.24368     |
| training/sac_pi/alpha          | 0.16913973   |
| training/sac_pi/alpha_loss     | -0.121657744 |
| training/sac_pi/logp_pi        | 4.427064     |
| training/sac_pi/pi_entropy     | 3.8834481    |
| training/sac_pi/pi_global_norm | 1.4376917    |
| training/sac_pi/policy_loss    | -194.55486   |
| training/sac_pi/std            | 0.56863153   |
| training/sac_pi/valid_num      | 4910.0       |
| training/sac_Q/q1              | 180.18759    |
| training/sac_Q/q2              | 179.55545    |
| training/sac_Q/q2_loss         | 82.66474     |
| training/sac_Q/q_global_norm   | 207.94879    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16505122 |
| epoch                          | 229        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4742.275   |
| evaluation/return-max          | 4778.794   |
| evaluation/return-min          | 4712.92    |
| evaluation/return-std          | 17.348513  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 82.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45508      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4742.275   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 174.08841  |
| Q-std                          | 117.16875  |
| Q_loss                         | 106.64337  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 229        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000273   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000562   |
| times/evaluation_paths         | 31.9       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 57.9       |
| timestep                       | 1000       |
| timesteps_total                | 230000     |
| train-steps                    | 230000     |
| training/Q/q1_loss             | 102.43735  |
| training/sac_pi/alpha          | 0.1650248  |
| training/sac_pi/alpha_loss     | 0.1553447  |
| training/sac_pi/logp_pi        | 5.033906   |
| training/sac_pi/pi_entropy     | 3.6600296  |
| training/sac_pi/pi_global_norm | 1.6425526  |
| training/sac_pi/policy_loss    | -197.75397 |
| training/sac_pi/std            | 0.54749006 |
| training/sac_pi/valid_num      | 4893.0     |
| training/sac_Q/q1              | 182.73734  |
| training/sac_Q/q2              | 182.15067  |
| training/sac_Q/q2_loss         | 101.9432   |
| training/sac_Q/q_global_norm   | 186.37611  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16042162 |
| epoch                          | 230        |
| evaluation/episode-length-avg  | 830        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 148        |
| evaluation/episode-length-std  | 341        |
| evaluation/return-average      | 3921.4695  |
| evaluation/return-max          | 4944.669   |
| evaluation/return-min          | 396.60843  |
| evaluation/return-std          | 1761.126   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 82.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45458      |
| perf/AverageLength             | 830        |
| perf/AverageReturn             | 3921.4695  |
| perf/NormalizedReturn          | 0.854      |
| Q-avg                          | 175.82144  |
| Q-std                          | 124.996735 |
| Q_loss                         | 97.28172   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 230        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000108   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000625   |
| times/evaluation_paths         | 26.8       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 57.9       |
| timestep                       | 1000       |
| timesteps_total                | 231000     |
| train-steps                    | 231000     |
| training/Q/q1_loss             | 113.33101  |
| training/sac_pi/alpha          | 0.16041869 |
| training/sac_pi/alpha_loss     | 0.04354785 |
| training/sac_pi/logp_pi        | 5.170985   |
| training/sac_pi/pi_entropy     | 3.4944396  |
| training/sac_pi/pi_global_norm | 1.7298081  |
| training/sac_pi/policy_loss    | -190.82104 |
| training/sac_pi/std            | 0.52848303 |
| training/sac_pi/valid_num      | 4913.0     |
| training/sac_Q/q1              | 174.7081   |
| training/sac_Q/q2              | 174.21992  |
| training/sac_Q/q2_loss         | 113.17662  |
| training/sac_Q/q_global_norm   | 246.76093  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15961479  |
| epoch                          | 231         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4577.7275   |
| evaluation/return-max          | 4629.9604   |
| evaluation/return-min          | 4532.394    |
| evaluation/return-std          | 27.08509    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.83        |
| model/origin_ret               | 83          |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45610       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4577.7275   |
| perf/NormalizedReturn          | 0.997       |
| Q-avg                          | 181.9403    |
| Q-std                          | 104.860146  |
| Q_loss                         | 87.04852    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 231         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000668    |
| times/evaluation_paths         | 31.8        |
| times/timestep_after_hook      | 0.00386     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 58.3        |
| timestep                       | 1000        |
| timesteps_total                | 232000      |
| train-steps                    | 232000      |
| training/Q/q1_loss             | 103.64659   |
| training/sac_pi/alpha          | 0.15961926  |
| training/sac_pi/alpha_loss     | -0.02730269 |
| training/sac_pi/logp_pi        | 4.764344    |
| training/sac_pi/pi_entropy     | 3.5883682   |
| training/sac_pi/pi_global_norm | 1.3939047   |
| training/sac_pi/policy_loss    | -188.13045  |
| training/sac_pi/std            | 0.5379699   |
| training/sac_pi/valid_num      | 4947.0      |
| training/sac_Q/q1              | 177.24704   |
| training/sac_Q/q2              | 176.09167   |
| training/sac_Q/q2_loss         | 103.26473   |
| training/sac_Q/q_global_norm   | 226.79295   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16176207 |
| epoch                          | 232        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4881.961   |
| evaluation/return-max          | 4908.0376  |
| evaluation/return-min          | 4834.304   |
| evaluation/return-std          | 18.790054  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 82.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45606      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4881.961   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 178.48538  |
| Q-std                          | 126.41796  |
| Q_loss                         | 103.39755  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 232        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000619   |
| times/evaluation_paths         | 32.2       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 57.8       |
| timestep                       | 1000       |
| timesteps_total                | 233000     |
| train-steps                    | 233000     |
| training/Q/q1_loss             | 96.06337   |
| training/sac_pi/alpha          | 0.16174223 |
| training/sac_pi/alpha_loss     | 0.29096586 |
| training/sac_pi/logp_pi        | 4.3411064  |
| training/sac_pi/pi_entropy     | 3.741122   |
| training/sac_pi/pi_global_norm | 1.3876218  |
| training/sac_pi/policy_loss    | -192.34392 |
| training/sac_pi/std            | 0.5226206  |
| training/sac_pi/valid_num      | 5000.0     |
| training/sac_Q/q1              | 183.32458  |
| training/sac_Q/q2              | 182.79892  |
| training/sac_Q/q2_loss         | 96.469826  |
| training/sac_Q/q_global_norm   | 199.12486  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16709182  |
| epoch                          | 233         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4665.859    |
| evaluation/return-max          | 4688.5605   |
| evaluation/return-min          | 4640.407    |
| evaluation/return-std          | 14.231516   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.86        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 83.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45487       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4665.859    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 179.23521   |
| Q-std                          | 126.46237   |
| Q_loss                         | 89.60189    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 233         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000282    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000687    |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.00382     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 57.8        |
| timestep                       | 1000        |
| timesteps_total                | 234000      |
| train-steps                    | 234000      |
| training/Q/q1_loss             | 91.28152    |
| training/sac_pi/alpha          | 0.16709481  |
| training/sac_pi/alpha_loss     | 0.014341273 |
| training/sac_pi/logp_pi        | 4.2542086   |
| training/sac_pi/pi_entropy     | 3.8995204   |
| training/sac_pi/pi_global_norm | 1.8150766   |
| training/sac_pi/policy_loss    | -190.1179   |
| training/sac_pi/std            | 0.5709803   |
| training/sac_pi/valid_num      | 4912.0      |
| training/sac_Q/q1              | 176.91458   |
| training/sac_Q/q2              | 176.531     |
| training/sac_Q/q2_loss         | 93.37774    |
| training/sac_Q/q_global_norm   | 248.66742   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16086902  |
| epoch                          | 234         |
| evaluation/episode-length-avg  | 514         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 137         |
| evaluation/episode-length-std  | 404         |
| evaluation/return-average      | 2290.898    |
| evaluation/return-max          | 4977.9473   |
| evaluation/return-min          | 327.4013    |
| evaluation/return-std          | 2141.9524   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.85        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 82.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45537       |
| perf/AverageLength             | 514         |
| perf/AverageReturn             | 2290.898    |
| perf/NormalizedReturn          | 0.499       |
| Q-avg                          | 177.5308    |
| Q-std                          | 123.907265  |
| Q_loss                         | 88.23497    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 234         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.00024     |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000653    |
| times/evaluation_paths         | 16.4        |
| times/timestep_after_hook      | 0.00382     |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 57.6        |
| timestep                       | 1000        |
| timesteps_total                | 235000      |
| train-steps                    | 235000      |
| training/Q/q1_loss             | 93.66681    |
| training/sac_pi/alpha          | 0.16087927  |
| training/sac_pi/alpha_loss     | -0.19552806 |
| training/sac_pi/logp_pi        | 4.148057    |
| training/sac_pi/pi_entropy     | 3.6067245   |
| training/sac_pi/pi_global_norm | 1.2826042   |
| training/sac_pi/policy_loss    | -197.2256   |
| training/sac_pi/std            | 0.51615274  |
| training/sac_pi/valid_num      | 4992.0      |
| training/sac_Q/q1              | 190.28825   |
| training/sac_Q/q2              | 189.53596   |
| training/sac_Q/q2_loss         | 93.165344   |
| training/sac_Q/q_global_norm   | 291.04605   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16438955 |
| epoch                          | 235        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4557.374   |
| evaluation/return-max          | 4622.63    |
| evaluation/return-min          | 4524.235   |
| evaluation/return-std          | 25.427702  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.85       |
| model/origin_ret               | 83.4       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45488      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4557.374   |
| perf/NormalizedReturn          | 0.992      |
| Q-avg                          | 177.2161   |
| Q-std                          | 129.41428  |
| Q_loss                         | 110.7838   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 235        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000109   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000543   |
| times/evaluation_paths         | 32.1       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 58         |
| timestep                       | 1000       |
| timesteps_total                | 236000     |
| train-steps                    | 236000     |
| training/Q/q1_loss             | 110.755844 |
| training/sac_pi/alpha          | 0.16438597 |
| training/sac_pi/alpha_loss     | 0.09871581 |
| training/sac_pi/logp_pi        | 4.8054695  |
| training/sac_pi/pi_entropy     | 3.8013809  |
| training/sac_pi/pi_global_norm | 1.794614   |
| training/sac_pi/policy_loss    | -190.83392 |
| training/sac_pi/std            | 0.5628021  |
| training/sac_pi/valid_num      | 4921.0     |
| training/sac_Q/q1              | 177.37381  |
| training/sac_Q/q2              | 175.22388  |
| training/sac_Q/q2_loss         | 110.9645   |
| training/sac_Q/q_global_norm   | 320.73715  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16232656   |
| epoch                          | 236          |
| evaluation/episode-length-avg  | 648          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 251          |
| evaluation/episode-length-std  | 353          |
| evaluation/return-average      | 2887.719     |
| evaluation/return-max          | 4761.6436    |
| evaluation/return-min          | 863.6029     |
| evaluation/return-std          | 1850.7272    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.91         |
| model/origin_ret               | 84.7         |
| model/penalty_ret              | 81.7         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45654        |
| perf/AverageLength             | 648          |
| perf/AverageReturn             | 2887.719     |
| perf/NormalizedReturn          | 0.629        |
| Q-avg                          | 169.56596    |
| Q-std                          | 131.48701    |
| Q_loss                         | 110.38046    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 236          |
| times/epoch_after_hook         | 1.71e-06     |
| times/epoch_before_hook        | 0.000149     |
| times/epoch_rollout_model      | 479          |
| times/evaluation_metrics       | 0.000531     |
| times/evaluation_paths         | 20.7         |
| times/timestep_after_hook      | 0.00383      |
| times/timestep_before_hook     | 0.00827      |
| times/train                    | 58.2         |
| timestep                       | 1000         |
| timesteps_total                | 237000       |
| train-steps                    | 237000       |
| training/Q/q1_loss             | 102.022484   |
| training/sac_pi/alpha          | 0.16236134   |
| training/sac_pi/alpha_loss     | -0.045835827 |
| training/sac_pi/logp_pi        | 4.40197      |
| training/sac_pi/pi_entropy     | 3.6616611    |
| training/sac_pi/pi_global_norm | 1.3727208    |
| training/sac_pi/policy_loss    | -190.34225   |
| training/sac_pi/std            | 0.5287042    |
| training/sac_pi/valid_num      | 4962.0       |
| training/sac_Q/q1              | 181.6082     |
| training/sac_Q/q2              | 179.3523     |
| training/sac_Q/q2_loss         | 101.660385   |
| training/sac_Q/q_global_norm   | 222.5521     |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1647283   |
| epoch                          | 237         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4827.561    |
| evaluation/return-max          | 4850.1567   |
| evaluation/return-min          | 4803.3125   |
| evaluation/return-std          | 13.800364   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.75        |
| model/origin_ret               | 81.2        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45521       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4827.561    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 184.3794    |
| Q-std                          | 97.00584    |
| Q_loss                         | 88.33509    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 237         |
| times/epoch_after_hook         | 2.4e-06     |
| times/epoch_before_hook        | 0.000331    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000616    |
| times/evaluation_paths         | 31.8        |
| times/timestep_after_hook      | 0.0038      |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 58          |
| timestep                       | 1000        |
| timesteps_total                | 238000      |
| train-steps                    | 238000      |
| training/Q/q1_loss             | 97.68582    |
| training/sac_pi/alpha          | 0.1647211   |
| training/sac_pi/alpha_loss     | -0.12285262 |
| training/sac_pi/logp_pi        | 4.5272408   |
| training/sac_pi/pi_entropy     | 3.6405952   |
| training/sac_pi/pi_global_norm | 1.5197616   |
| training/sac_pi/policy_loss    | -191.67542  |
| training/sac_pi/std            | 0.5467351   |
| training/sac_pi/valid_num      | 4955.0      |
| training/sac_Q/q1              | 181.30887   |
| training/sac_Q/q2              | 179.63052   |
| training/sac_Q/q2_loss         | 98.035774   |
| training/sac_Q/q_global_norm   | 358.92242   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16608155   |
| epoch                          | 238          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4763.884     |
| evaluation/return-max          | 4808.068     |
| evaluation/return-min          | 4724.6294    |
| evaluation/return-std          | 23.190619    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.83         |
| model/origin_ret               | 83.3         |
| model/penalty_ret              | 81.7         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45459        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4763.884     |
| perf/NormalizedReturn          | 1.04         |
| Q-avg                          | 189.719      |
| Q-std                          | 129.34889    |
| Q_loss                         | 84.228294    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 238          |
| times/epoch_after_hook         | 1.82e-06     |
| times/epoch_before_hook        | 0.000127     |
| times/epoch_rollout_model      | 472          |
| times/evaluation_metrics       | 0.000538     |
| times/evaluation_paths         | 32.1         |
| times/timestep_after_hook      | 0.00384      |
| times/timestep_before_hook     | 0.00831      |
| times/train                    | 57.9         |
| timestep                       | 1000         |
| timesteps_total                | 239000       |
| train-steps                    | 239000       |
| training/Q/q1_loss             | 95.02333     |
| training/sac_pi/alpha          | 0.16607471   |
| training/sac_pi/alpha_loss     | -0.040553633 |
| training/sac_pi/logp_pi        | 4.418023     |
| training/sac_pi/pi_entropy     | 3.8167388    |
| training/sac_pi/pi_global_norm | 1.8337228    |
| training/sac_pi/policy_loss    | -193.91855   |
| training/sac_pi/std            | 0.54711115   |
| training/sac_pi/valid_num      | 4943.0       |
| training/sac_Q/q1              | 180.16634    |
| training/sac_Q/q2              | 182.83101    |
| training/sac_Q/q2_loss         | 94.53236     |
| training/sac_Q/q_global_norm   | 177.55899    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1650774  |
| epoch                          | 239        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4952.9736  |
| evaluation/return-max          | 4986.04    |
| evaluation/return-min          | 4928.67    |
| evaluation/return-std          | 16.750305  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 82.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45381      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4952.9736  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 179.17056  |
| Q-std                          | 133.08337  |
| Q_loss                         | 86.89382   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 239        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000116   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000591   |
| times/evaluation_paths         | 32.1       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00853    |
| times/train                    | 57.8       |
| timestep                       | 1000       |
| timesteps_total                | 240000     |
| train-steps                    | 240000     |
| training/Q/q1_loss             | 104.82403  |
| training/sac_pi/alpha          | 0.16511975 |
| training/sac_pi/alpha_loss     | 0.2343019  |
| training/sac_pi/logp_pi        | 4.5578294  |
| training/sac_pi/pi_entropy     | 3.6669304  |
| training/sac_pi/pi_global_norm | 1.6266849  |
| training/sac_pi/policy_loss    | -186.0228  |
| training/sac_pi/std            | 0.52478606 |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 175.12195  |
| training/sac_Q/q2              | 175.47426  |
| training/sac_Q/q2_loss         | 105.10531  |
| training/sac_Q/q_global_norm   | 250.95692  |
--------------------------------------------------------------------------------
[WARN] 240 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16986035 |
| epoch                          | 240        |
| evaluation/episode-length-avg  | 758        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 149        |
| evaluation/episode-length-std  | 299        |
| evaluation/return-average      | 3427.81    |
| evaluation/return-max          | 4865.5566  |
| evaluation/return-min          | 466.32086  |
| evaluation/return-std          | 1491.071   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.84       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 83.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45557      |
| perf/AverageLength             | 758        |
| perf/AverageReturn             | 3427.81    |
| perf/NormalizedReturn          | 0.746      |
| Q-avg                          | 184.57407  |
| Q-std                          | 134.44714  |
| Q_loss                         | 107.79118  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 240        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000578   |
| times/evaluation_paths         | 24.8       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 57.8       |
| timestep                       | 1000       |
| timesteps_total                | 241000     |
| train-steps                    | 241000     |
| training/Q/q1_loss             | 118.35289  |
| training/sac_pi/alpha          | 0.16982155 |
| training/sac_pi/alpha_loss     | 0.07017906 |
| training/sac_pi/logp_pi        | 4.781016   |
| training/sac_pi/pi_entropy     | 3.753057   |
| training/sac_pi/pi_global_norm | 1.6328403  |
| training/sac_pi/policy_loss    | -190.17705 |
| training/sac_pi/std            | 0.5598738  |
| training/sac_pi/valid_num      | 4918.0     |
| training/sac_Q/q1              | 178.33954  |
| training/sac_Q/q2              | 178.08504  |
| training/sac_Q/q2_loss         | 118.35308  |
| training/sac_Q/q_global_norm   | 292.768    |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16733776  |
| epoch                          | 241         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4746.271    |
| evaluation/return-max          | 4786.756    |
| evaluation/return-min          | 4704.39     |
| evaluation/return-std          | 21.783762   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 82.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45734       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4746.271    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 192.28342   |
| Q-std                          | 108.765465  |
| Q_loss                         | 91.30086    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 241         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000285    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000588    |
| times/evaluation_paths         | 32.1        |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00871     |
| times/train                    | 57.8        |
| timestep                       | 1000        |
| timesteps_total                | 242000      |
| train-steps                    | 242000      |
| training/Q/q1_loss             | 88.06255    |
| training/sac_pi/alpha          | 0.16733234  |
| training/sac_pi/alpha_loss     | 0.068402275 |
| training/sac_pi/logp_pi        | 4.48202     |
| training/sac_pi/pi_entropy     | 3.7630544   |
| training/sac_pi/pi_global_norm | 1.571833    |
| training/sac_pi/policy_loss    | -192.05919  |
| training/sac_pi/std            | 0.53466356  |
| training/sac_pi/valid_num      | 4886.0      |
| training/sac_Q/q1              | 179.8121    |
| training/sac_Q/q2              | 179.5314    |
| training/sac_Q/q2_loss         | 88.75777    |
| training/sac_Q/q_global_norm   | 212.16064   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16814117   |
| epoch                          | 242          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4298.464     |
| evaluation/return-max          | 4364.4844    |
| evaluation/return-min          | 4263.528     |
| evaluation/return-std          | 32.587097    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.91         |
| model/origin_ret               | 84.8         |
| model/penalty_ret              | 82.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45532        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4298.464     |
| perf/NormalizedReturn          | 0.936        |
| Q-avg                          | 170.99615    |
| Q-std                          | 117.90544    |
| Q_loss                         | 121.44778    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 242          |
| times/epoch_after_hook         | 2.2e-06      |
| times/epoch_before_hook        | 0.000132     |
| times/epoch_rollout_model      | 479          |
| times/evaluation_metrics       | 0.000569     |
| times/evaluation_paths         | 32.2         |
| times/timestep_after_hook      | 0.00395      |
| times/timestep_before_hook     | 0.00844      |
| times/train                    | 58           |
| timestep                       | 1000         |
| timesteps_total                | 243000       |
| train-steps                    | 243000       |
| training/Q/q1_loss             | 100.09631    |
| training/sac_pi/alpha          | 0.16810405   |
| training/sac_pi/alpha_loss     | -0.083577275 |
| training/sac_pi/logp_pi        | 4.367276     |
| training/sac_pi/pi_entropy     | 3.674871     |
| training/sac_pi/pi_global_norm | 1.2824485    |
| training/sac_pi/policy_loss    | -195.9461    |
| training/sac_pi/std            | 0.5322862    |
| training/sac_pi/valid_num      | 4927.0       |
| training/sac_Q/q1              | 183.45593    |
| training/sac_Q/q2              | 184.38495    |
| training/sac_Q/q2_loss         | 98.8906      |
| training/sac_Q/q_global_norm   | 208.60332    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16383994 |
| epoch                          | 243        |
| evaluation/episode-length-avg  | 833        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 161        |
| evaluation/episode-length-std  | 335        |
| evaluation/return-average      | 3731.1648  |
| evaluation/return-max          | 4750.488   |
| evaluation/return-min          | 430.02588  |
| evaluation/return-std          | 1654.4438  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45597      |
| perf/AverageLength             | 833        |
| perf/AverageReturn             | 3731.1648  |
| perf/NormalizedReturn          | 0.812      |
| Q-avg                          | 178.48392  |
| Q-std                          | 142.3132   |
| Q_loss                         | 106.87573  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 243        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.00011    |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000633   |
| times/evaluation_paths         | 26.5       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 58         |
| timestep                       | 1000       |
| timesteps_total                | 244000     |
| train-steps                    | 244000     |
| training/Q/q1_loss             | 91.70623   |
| training/sac_pi/alpha          | 0.16385022 |
| training/sac_pi/alpha_loss     | 0.24111378 |
| training/sac_pi/logp_pi        | 4.25815    |
| training/sac_pi/pi_entropy     | 3.803402   |
| training/sac_pi/pi_global_norm | 1.471639   |
| training/sac_pi/policy_loss    | -194.34349 |
| training/sac_pi/std            | 0.5309418  |
| training/sac_pi/valid_num      | 4935.0     |
| training/sac_Q/q1              | 185.30377  |
| training/sac_Q/q2              | 185.35747  |
| training/sac_Q/q2_loss         | 91.798775  |
| training/sac_Q/q_global_norm   | 240.56573  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1670983    |
| epoch                          | 244          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4979.544     |
| evaluation/return-max          | 5050.3413    |
| evaluation/return-min          | 4933.4644    |
| evaluation/return-std          | 30.664524    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.81         |
| model/origin_ret               | 81.6         |
| model/penalty_ret              | 81.6         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45572        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4979.544     |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 188.32957    |
| Q-std                          | 115.90781    |
| Q_loss                         | 105.221855   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 244          |
| times/epoch_after_hook         | 1.91e-06     |
| times/epoch_before_hook        | 0.000115     |
| times/epoch_rollout_model      | 479          |
| times/evaluation_metrics       | 0.00057      |
| times/evaluation_paths         | 31.9         |
| times/timestep_after_hook      | 0.00386      |
| times/timestep_before_hook     | 0.00823      |
| times/train                    | 58.1         |
| timestep                       | 1000         |
| timesteps_total                | 245000       |
| train-steps                    | 245000       |
| training/Q/q1_loss             | 106.261604   |
| training/sac_pi/alpha          | 0.16710621   |
| training/sac_pi/alpha_loss     | -0.031562693 |
| training/sac_pi/logp_pi        | 4.8823853    |
| training/sac_pi/pi_entropy     | 3.5621433    |
| training/sac_pi/pi_global_norm | 1.2684876    |
| training/sac_pi/policy_loss    | -197.1453    |
| training/sac_pi/std            | 0.52563137   |
| training/sac_pi/valid_num      | 4928.0       |
| training/sac_Q/q1              | 182.40839    |
| training/sac_Q/q2              | 180.91089    |
| training/sac_Q/q2_loss         | 106.06911    |
| training/sac_Q/q_global_norm   | 225.63095    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16598862 |
| epoch                          | 245        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4695.799   |
| evaluation/return-max          | 4743.9873  |
| evaluation/return-min          | 4661.3833  |
| evaluation/return-std          | 23.15247   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 83         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45446      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4695.799   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 187.72617  |
| Q-std                          | 123.115204 |
| Q_loss                         | 76.08545   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 245        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000317   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000624   |
| times/evaluation_paths         | 31.6       |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 58.3       |
| timestep                       | 1000       |
| timesteps_total                | 246000     |
| train-steps                    | 246000     |
| training/Q/q1_loss             | 108.03201  |
| training/sac_pi/alpha          | 0.1660161  |
| training/sac_pi/alpha_loss     | 0.21155109 |
| training/sac_pi/logp_pi        | 4.749303   |
| training/sac_pi/pi_entropy     | 3.5890326  |
| training/sac_pi/pi_global_norm | 1.4849851  |
| training/sac_pi/policy_loss    | -187.39948 |
| training/sac_pi/std            | 0.5261013  |
| training/sac_pi/valid_num      | 4900.0     |
| training/sac_Q/q1              | 173.11143  |
| training/sac_Q/q2              | 172.80759  |
| training/sac_Q/q2_loss         | 107.05468  |
| training/sac_Q/q_global_norm   | 239.43304  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16509016   |
| epoch                          | 246          |
| evaluation/episode-length-avg  | 748          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 146          |
| evaluation/episode-length-std  | 385          |
| evaluation/return-average      | 3537.72      |
| evaluation/return-max          | 4927.5186    |
| evaluation/return-min          | 377.28317    |
| evaluation/return-std          | 2038.2783    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.8          |
| model/origin_ret               | 82.8         |
| model/penalty_ret              | 82           |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45432        |
| perf/AverageLength             | 748          |
| perf/AverageReturn             | 3537.72      |
| perf/NormalizedReturn          | 0.77         |
| Q-avg                          | 184.384      |
| Q-std                          | 110.38039    |
| Q_loss                         | 113.36364    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 246          |
| times/epoch_after_hook         | 2.07e-06     |
| times/epoch_before_hook        | 0.000129     |
| times/epoch_rollout_model      | 480          |
| times/evaluation_metrics       | 0.000703     |
| times/evaluation_paths         | 23.7         |
| times/timestep_after_hook      | 0.00392      |
| times/timestep_before_hook     | 0.00826      |
| times/train                    | 57.5         |
| timestep                       | 1000         |
| timesteps_total                | 247000       |
| train-steps                    | 247000       |
| training/Q/q1_loss             | 81.98637     |
| training/sac_pi/alpha          | 0.16508031   |
| training/sac_pi/alpha_loss     | -0.028947739 |
| training/sac_pi/logp_pi        | 3.9897504    |
| training/sac_pi/pi_entropy     | 3.666774     |
| training/sac_pi/pi_global_norm | 2.372988     |
| training/sac_pi/policy_loss    | -198.03223   |
| training/sac_pi/std            | 0.51804      |
| training/sac_pi/valid_num      | 4965.0       |
| training/sac_Q/q1              | 187.67253    |
| training/sac_Q/q2              | 188.02164    |
| training/sac_Q/q2_loss         | 81.63274     |
| training/sac_Q/q_global_norm   | 280.95026    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16385256 |
| epoch                          | 247        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4753.262   |
| evaluation/return-max          | 4769.4033  |
| evaluation/return-min          | 4727.8633  |
| evaluation/return-std          | 11.521594  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45723      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4753.262   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 179.08997  |
| Q-std                          | 120.343636 |
| Q_loss                         | 105.80822  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 247        |
| times/epoch_after_hook         | 2.12e-06   |
| times/epoch_before_hook        | 0.000142   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.00069    |
| times/evaluation_paths         | 32.1       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 57.9       |
| timestep                       | 1000       |
| timesteps_total                | 248000     |
| train-steps                    | 248000     |
| training/Q/q1_loss             | 93.46233   |
| training/sac_pi/alpha          | 0.1638503  |
| training/sac_pi/alpha_loss     | 0.3734364  |
| training/sac_pi/logp_pi        | 4.2058363  |
| training/sac_pi/pi_entropy     | 3.7053485  |
| training/sac_pi/pi_global_norm | 1.4606627  |
| training/sac_pi/policy_loss    | -194.28723 |
| training/sac_pi/std            | 0.51682925 |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 185.33151  |
| training/sac_Q/q2              | 184.86087  |
| training/sac_Q/q2_loss         | 94.08164   |
| training/sac_Q/q_global_norm   | 222.60352  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16987044  |
| epoch                          | 248         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4721.449    |
| evaluation/return-max          | 4787.3364   |
| evaluation/return-min          | 4668.5293   |
| evaluation/return-std          | 37.611813   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.85        |
| model/origin_ret               | 83.4        |
| model/penalty_ret              | 82.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45709       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4721.449    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 191.98056   |
| Q-std                          | 114.19988   |
| Q_loss                         | 120.55935   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 248         |
| times/epoch_after_hook         | 2.04e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000598    |
| times/evaluation_paths         | 32.2        |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 57.7        |
| timestep                       | 1000        |
| timesteps_total                | 249000      |
| train-steps                    | 249000      |
| training/Q/q1_loss             | 96.1422     |
| training/sac_pi/alpha          | 0.16984738  |
| training/sac_pi/alpha_loss     | -0.05068184 |
| training/sac_pi/logp_pi        | 3.5219872   |
| training/sac_pi/pi_entropy     | 3.6571853   |
| training/sac_pi/pi_global_norm | 1.4581786   |
| training/sac_pi/policy_loss    | -204.11528  |
| training/sac_pi/std            | 0.48893002  |
| training/sac_pi/valid_num      | 5002.0      |
| training/sac_Q/q1              | 198.50325   |
| training/sac_Q/q2              | 197.09633   |
| training/sac_Q/q2_loss         | 97.28651    |
| training/sac_Q/q_global_norm   | 360.8172    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16519703  |
| epoch                          | 249         |
| evaluation/episode-length-avg  | 167         |
| evaluation/episode-length-max  | 491         |
| evaluation/episode-length-min  | 128         |
| evaluation/episode-length-std  | 108         |
| evaluation/return-average      | 465.8557    |
| evaluation/return-max          | 1931.1249   |
| evaluation/return-min          | 294.90332   |
| evaluation/return-std          | 488.44565   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 83.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45497       |
| perf/AverageLength             | 167         |
| perf/AverageReturn             | 465.8557    |
| perf/NormalizedReturn          | 0.101       |
| Q-avg                          | 191.28134   |
| Q-std                          | 90.65132    |
| Q_loss                         | 76.168594   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 249         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000303    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000618    |
| times/evaluation_paths         | 5.35        |
| times/timestep_after_hook      | 0.00383     |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 57.9        |
| timestep                       | 1000        |
| timesteps_total                | 250000      |
| train-steps                    | 250000      |
| training/Q/q1_loss             | 122.26936   |
| training/sac_pi/alpha          | 0.16517861  |
| training/sac_pi/alpha_loss     | 0.040671784 |
| training/sac_pi/logp_pi        | 4.506301    |
| training/sac_pi/pi_entropy     | 3.6647315   |
| training/sac_pi/pi_global_norm | 1.4383935   |
| training/sac_pi/policy_loss    | -193.06958  |
| training/sac_pi/std            | 0.5350422   |
| training/sac_pi/valid_num      | 4919.0      |
| training/sac_Q/q1              | 180.08963   |
| training/sac_Q/q2              | 180.03593   |
| training/sac_Q/q2_loss         | 121.76123   |
| training/sac_Q/q_global_norm   | 255.04657   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16891903 |
| epoch                          | 250        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4488.1636  |
| evaluation/return-max          | 4567.3237  |
| evaluation/return-min          | 4393.5337  |
| evaluation/return-std          | 54.828262  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.86       |
| model/origin_ret               | 83.1       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45895      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4488.1636  |
| perf/NormalizedReturn          | 0.977      |
| Q-avg                          | 188.2388   |
| Q-std                          | 127.46333  |
| Q_loss                         | 92.910774  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 250        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.000141   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000652   |
| times/evaluation_paths         | 31.9       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 58         |
| timestep                       | 1000       |
| timesteps_total                | 251000     |
| train-steps                    | 251000     |
| training/Q/q1_loss             | 110.01714  |
| training/sac_pi/alpha          | 0.16893141 |
| training/sac_pi/alpha_loss     | -0.2164032 |
| training/sac_pi/logp_pi        | 4.3233285  |
| training/sac_pi/pi_entropy     | 3.5320745  |
| training/sac_pi/pi_global_norm | 1.7693554  |
| training/sac_pi/policy_loss    | -194.01651 |
| training/sac_pi/std            | 0.52076346 |
| training/sac_pi/valid_num      | 4988.0     |
| training/sac_Q/q1              | 182.83337  |
| training/sac_Q/q2              | 182.1034   |
| training/sac_Q/q2_loss         | 110.29198  |
| training/sac_Q/q_global_norm   | 236.638    |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16849722  |
| epoch                          | 251         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4998.9834   |
| evaluation/return-max          | 5017.121    |
| evaluation/return-min          | 4973.342    |
| evaluation/return-std          | 15.034779   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.85        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 82.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45401       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4998.9834   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 182.93716   |
| Q-std                          | 103.61878   |
| Q_loss                         | 99.508865   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 251         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000104    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.00055     |
| times/evaluation_paths         | 32.1        |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 57.8        |
| timestep                       | 1000        |
| timesteps_total                | 252000      |
| train-steps                    | 252000      |
| training/Q/q1_loss             | 101.85394   |
| training/sac_pi/alpha          | 0.16852988  |
| training/sac_pi/alpha_loss     | -0.15754473 |
| training/sac_pi/logp_pi        | 4.248458    |
| training/sac_pi/pi_entropy     | 3.7173564   |
| training/sac_pi/pi_global_norm | 1.5107985   |
| training/sac_pi/policy_loss    | -195.17215  |
| training/sac_pi/std            | 0.52747154  |
| training/sac_pi/valid_num      | 4921.0      |
| training/sac_Q/q1              | 182.73479   |
| training/sac_Q/q2              | 179.95503   |
| training/sac_Q/q2_loss         | 101.62372   |
| training/sac_Q/q_global_norm   | 269.5695    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16497374  |
| epoch                          | 252         |
| evaluation/episode-length-avg  | 859         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 292         |
| evaluation/episode-length-std  | 283         |
| evaluation/return-average      | 3964.0464   |
| evaluation/return-max          | 4820.224    |
| evaluation/return-min          | 995.0645    |
| evaluation/return-std          | 1485.4387   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 83.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45486       |
| perf/AverageLength             | 859         |
| perf/AverageReturn             | 3964.0464   |
| perf/NormalizedReturn          | 0.863       |
| Q-avg                          | 179.19977   |
| Q-std                          | 137.34288   |
| Q_loss                         | 104.11454   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 252         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000105    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000656    |
| times/evaluation_paths         | 27.6        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 57.6        |
| timestep                       | 1000        |
| timesteps_total                | 253000      |
| train-steps                    | 253000      |
| training/Q/q1_loss             | 92.80884    |
| training/sac_pi/alpha          | 0.16498977  |
| training/sac_pi/alpha_loss     | -0.32274544 |
| training/sac_pi/logp_pi        | 4.1218734   |
| training/sac_pi/pi_entropy     | 3.5923798   |
| training/sac_pi/pi_global_norm | 1.3899759   |
| training/sac_pi/policy_loss    | -205.03636  |
| training/sac_pi/std            | 0.5140628   |
| training/sac_pi/valid_num      | 4983.0      |
| training/sac_Q/q1              | 193.27177   |
| training/sac_Q/q2              | 193.49448   |
| training/sac_Q/q2_loss         | 93.44224    |
| training/sac_Q/q_global_norm   | 201.37968   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16692035 |
| epoch                          | 253        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4550.4575  |
| evaluation/return-max          | 4628.0483  |
| evaluation/return-min          | 4386.6465  |
| evaluation/return-std          | 68.983604  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45634      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4550.4575  |
| perf/NormalizedReturn          | 0.991      |
| Q-avg                          | 184.32051  |
| Q-std                          | 128.5852   |
| Q_loss                         | 102.42749  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 253        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000276   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000594   |
| times/evaluation_paths         | 32         |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 57.6       |
| timestep                       | 1000       |
| timesteps_total                | 254000     |
| train-steps                    | 254000     |
| training/Q/q1_loss             | 81.602615  |
| training/sac_pi/alpha          | 0.16690718 |
| training/sac_pi/alpha_loss     | 0.23598269 |
| training/sac_pi/logp_pi        | 4.0674906  |
| training/sac_pi/pi_entropy     | 3.489923   |
| training/sac_pi/pi_global_norm | 1.7699857  |
| training/sac_pi/policy_loss    | -205.47409 |
| training/sac_pi/std            | 0.49296674 |
| training/sac_pi/valid_num      | 5047.0     |
| training/sac_Q/q1              | 199.2457   |
| training/sac_Q/q2              | 198.8898   |
| training/sac_Q/q2_loss         | 82.80787   |
| training/sac_Q/q_global_norm   | 193.5075   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16656864 |
| epoch                          | 254        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4839.031   |
| evaluation/return-max          | 4910.5117  |
| evaluation/return-min          | 4782.983   |
| evaluation/return-std          | 36.93081   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.85       |
| model/origin_ret               | 83.5       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45615      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4839.031   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 184.45326  |
| Q-std                          | 112.16017  |
| Q_loss                         | 94.38593   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 254        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000578   |
| times/evaluation_paths         | 32.7       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 58         |
| timestep                       | 1000       |
| timesteps_total                | 255000     |
| train-steps                    | 255000     |
| training/Q/q1_loss             | 100.400444 |
| training/sac_pi/alpha          | 0.16656473 |
| training/sac_pi/alpha_loss     | 0.1007747  |
| training/sac_pi/logp_pi        | 4.8714027  |
| training/sac_pi/pi_entropy     | 3.449836   |
| training/sac_pi/pi_global_norm | 1.4220263  |
| training/sac_pi/policy_loss    | -195.13684 |
| training/sac_pi/std            | 0.5162744  |
| training/sac_pi/valid_num      | 4951.0     |
| training/sac_Q/q1              | 182.95145  |
| training/sac_Q/q2              | 181.54318  |
| training/sac_Q/q2_loss         | 100.97289  |
| training/sac_Q/q_global_norm   | 201.02965  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16083951  |
| epoch                          | 255         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5021.0303   |
| evaluation/return-max          | 5057.7017   |
| evaluation/return-min          | 4990.217    |
| evaluation/return-std          | 20.946728   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 82.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45518       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5021.0303   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 187.04408   |
| Q-std                          | 120.29146   |
| Q_loss                         | 108.42958   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 255         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000617    |
| times/evaluation_paths         | 32.4        |
| times/timestep_after_hook      | 0.00381     |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 57.6        |
| timestep                       | 1000        |
| timesteps_total                | 256000      |
| train-steps                    | 256000      |
| training/Q/q1_loss             | 100.56226   |
| training/sac_pi/alpha          | 0.16086546  |
| training/sac_pi/alpha_loss     | -0.32669196 |
| training/sac_pi/logp_pi        | 4.2580175   |
| training/sac_pi/pi_entropy     | 3.593654    |
| training/sac_pi/pi_global_norm | 1.9066291   |
| training/sac_pi/policy_loss    | -201.83247  |
| training/sac_pi/std            | 0.5322284   |
| training/sac_pi/valid_num      | 4952.0      |
| training/sac_Q/q1              | 189.38033   |
| training/sac_Q/q2              | 187.8771    |
| training/sac_Q/q2_loss         | 99.74098    |
| training/sac_Q/q_global_norm   | 252.65158   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16486199 |
| epoch                          | 256        |
| evaluation/episode-length-avg  | 837        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 183        |
| evaluation/episode-length-std  | 327        |
| evaluation/return-average      | 3756.229   |
| evaluation/return-max          | 4713.749   |
| evaluation/return-min          | 521.8722   |
| evaluation/return-std          | 1618.9991  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45590      |
| perf/AverageLength             | 837        |
| perf/AverageReturn             | 3756.229   |
| perf/NormalizedReturn          | 0.818      |
| Q-avg                          | 189.48189  |
| Q-std                          | 116.41505  |
| Q_loss                         | 103.2879   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 256        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000664   |
| times/evaluation_paths         | 27.2       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 58         |
| timestep                       | 1000       |
| timesteps_total                | 257000     |
| train-steps                    | 257000     |
| training/Q/q1_loss             | 93.219955  |
| training/sac_pi/alpha          | 0.16487932 |
| training/sac_pi/alpha_loss     | -0.5082487 |
| training/sac_pi/logp_pi        | 4.4197397  |
| training/sac_pi/pi_entropy     | 3.6856346  |
| training/sac_pi/pi_global_norm | 1.3975009  |
| training/sac_pi/policy_loss    | -195.90634 |
| training/sac_pi/std            | 0.55620396 |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 181.82927  |
| training/sac_Q/q2              | 180.78513  |
| training/sac_Q/q2_loss         | 93.35638   |
| training/sac_Q/q_global_norm   | 238.672    |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16765313 |
| epoch                          | 257        |
| evaluation/episode-length-avg  | 332        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 162        |
| evaluation/episode-length-std  | 334        |
| evaluation/return-average      | 1298.1475  |
| evaluation/return-max          | 4733.668   |
| evaluation/return-min          | 431.2928   |
| evaluation/return-std          | 1716.5939  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 82.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45513      |
| perf/AverageLength             | 332        |
| perf/AverageReturn             | 1298.1475  |
| perf/NormalizedReturn          | 0.282      |
| Q-avg                          | 185.57788  |
| Q-std                          | 119.322044 |
| Q_loss                         | 95.157715  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 257        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000275   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000636   |
| times/evaluation_paths         | 10.7       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00809    |
| times/train                    | 57.8       |
| timestep                       | 1000       |
| timesteps_total                | 258000     |
| train-steps                    | 258000     |
| training/Q/q1_loss             | 99.02622   |
| training/sac_pi/alpha          | 0.16764043 |
| training/sac_pi/alpha_loss     | -0.1816419 |
| training/sac_pi/logp_pi        | 4.8035126  |
| training/sac_pi/pi_entropy     | 3.6094048  |
| training/sac_pi/pi_global_norm | 1.4911387  |
| training/sac_pi/policy_loss    | -194.13316 |
| training/sac_pi/std            | 0.54083496 |
| training/sac_pi/valid_num      | 4929.0     |
| training/sac_Q/q1              | 180.81203  |
| training/sac_Q/q2              | 179.0185   |
| training/sac_Q/q2_loss         | 98.696526  |
| training/sac_Q/q_global_norm   | 222.5264   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16576098 |
| epoch                          | 258        |
| evaluation/episode-length-avg  | 508        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 130        |
| evaluation/episode-length-std  | 393        |
| evaluation/return-average      | 2157.3389  |
| evaluation/return-max          | 4592.605   |
| evaluation/return-min          | 345.8322   |
| evaluation/return-std          | 1904.6669  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45602      |
| perf/AverageLength             | 508        |
| perf/AverageReturn             | 2157.3389  |
| perf/NormalizedReturn          | 0.47       |
| Q-avg                          | 186.5949   |
| Q-std                          | 111.4494   |
| Q_loss                         | 106.81165  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 258        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000116   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000508   |
| times/evaluation_paths         | 16.3       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 58         |
| timestep                       | 1000       |
| timesteps_total                | 259000     |
| train-steps                    | 259000     |
| training/Q/q1_loss             | 103.78742  |
| training/sac_pi/alpha          | 0.1657108  |
| training/sac_pi/alpha_loss     | 0.6391743  |
| training/sac_pi/logp_pi        | 4.156756   |
| training/sac_pi/pi_entropy     | 3.4468055  |
| training/sac_pi/pi_global_norm | 1.5604875  |
| training/sac_pi/policy_loss    | -204.36485 |
| training/sac_pi/std            | 0.48487118 |
| training/sac_pi/valid_num      | 4974.0     |
| training/sac_Q/q1              | 195.78325  |
| training/sac_Q/q2              | 195.455    |
| training/sac_Q/q2_loss         | 104.48951  |
| training/sac_Q/q_global_norm   | 300.6544   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16477722  |
| epoch                          | 259         |
| evaluation/episode-length-avg  | 828         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 138         |
| evaluation/episode-length-std  | 343         |
| evaluation/return-average      | 3840.4172   |
| evaluation/return-max          | 4795.6924   |
| evaluation/return-min          | 347.2688    |
| evaluation/return-std          | 1741.6578   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 82.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45770       |
| perf/AverageLength             | 828         |
| perf/AverageReturn             | 3840.4172   |
| perf/NormalizedReturn          | 0.836       |
| Q-avg                          | 180.1135    |
| Q-std                          | 128.872     |
| Q_loss                         | 113.08311   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 259         |
| times/epoch_after_hook         | 2.01e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000711    |
| times/evaluation_paths         | 26.6        |
| times/timestep_after_hook      | 0.00381     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 57.5        |
| timestep                       | 1000        |
| timesteps_total                | 260000      |
| train-steps                    | 260000      |
| training/Q/q1_loss             | 111.79188   |
| training/sac_pi/alpha          | 0.16474928  |
| training/sac_pi/alpha_loss     | -0.06915718 |
| training/sac_pi/logp_pi        | 4.9511104   |
| training/sac_pi/pi_entropy     | 3.7204807   |
| training/sac_pi/pi_global_norm | 1.6332005   |
| training/sac_pi/policy_loss    | -199.08801  |
| training/sac_pi/std            | 0.542874    |
| training/sac_pi/valid_num      | 4907.0      |
| training/sac_Q/q1              | 186.46175   |
| training/sac_Q/q2              | 184.76898   |
| training/sac_Q/q2_loss         | 111.423096  |
| training/sac_Q/q_global_norm   | 237.77682   |
---------------------------------------------------------------------------------
[WARN] 260 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16662273 |
| epoch                          | 260        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4757.8286  |
| evaluation/return-max          | 4796.406   |
| evaluation/return-min          | 4674.2305  |
| evaluation/return-std          | 34.217052  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45646      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4757.8286  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 182.61734  |
| Q-std                          | 120.4217   |
| Q_loss                         | 95.04307   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 260        |
| times/epoch_after_hook         | 3.28e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000617   |
| times/evaluation_paths         | 32         |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 57.8       |
| timestep                       | 1000       |
| timesteps_total                | 261000     |
| train-steps                    | 261000     |
| training/Q/q1_loss             | 99.03735   |
| training/sac_pi/alpha          | 0.1665877  |
| training/sac_pi/alpha_loss     | 0.4565156  |
| training/sac_pi/logp_pi        | 4.517646   |
| training/sac_pi/pi_entropy     | 3.6148033  |
| training/sac_pi/pi_global_norm | 1.4804924  |
| training/sac_pi/policy_loss    | -194.94077 |
| training/sac_pi/std            | 0.5099143  |
| training/sac_pi/valid_num      | 5008.0     |
| training/sac_Q/q1              | 186.97661  |
| training/sac_Q/q2              | 186.56328  |
| training/sac_Q/q2_loss         | 98.76945   |
| training/sac_Q/q_global_norm   | 211.70659  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1632191  |
| epoch                          | 261        |
| evaluation/episode-length-avg  | 778        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 166        |
| evaluation/episode-length-std  | 347        |
| evaluation/return-average      | 3487.918   |
| evaluation/return-max          | 4694.749   |
| evaluation/return-min          | 507.06992  |
| evaluation/return-std          | 1701.0464  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45412      |
| perf/AverageLength             | 778        |
| perf/AverageReturn             | 3487.918   |
| perf/NormalizedReturn          | 0.759      |
| Q-avg                          | 178.53218  |
| Q-std                          | 104.56444  |
| Q_loss                         | 110.55169  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 261        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000275   |
| times/epoch_rollout_model      | 475        |
| times/evaluation_metrics       | 0.000588   |
| times/evaluation_paths         | 24.9       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00804    |
| times/train                    | 57.6       |
| timestep                       | 1000       |
| timesteps_total                | 262000     |
| train-steps                    | 262000     |
| training/Q/q1_loss             | 105.44905  |
| training/sac_pi/alpha          | 0.16320506 |
| training/sac_pi/alpha_loss     | 0.32016295 |
| training/sac_pi/logp_pi        | 5.713683   |
| training/sac_pi/pi_entropy     | 3.6398976  |
| training/sac_pi/pi_global_norm | 1.478657   |
| training/sac_pi/policy_loss    | -197.0104  |
| training/sac_pi/std            | 0.57943505 |
| training/sac_pi/valid_num      | 4878.0     |
| training/sac_Q/q1              | 175.98929  |
| training/sac_Q/q2              | 174.25215  |
| training/sac_Q/q2_loss         | 105.54773  |
| training/sac_Q/q_global_norm   | 271.41852  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16968994 |
| epoch                          | 262        |
| evaluation/episode-length-avg  | 913        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 132        |
| evaluation/episode-length-std  | 260        |
| evaluation/return-average      | 4015.6125  |
| evaluation/return-max          | 4499.6562  |
| evaluation/return-min          | 310.0768   |
| evaluation/return-std          | 1236.8849  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.86       |
| model/origin_ret               | 83.5       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45497      |
| perf/AverageLength             | 913        |
| perf/AverageReturn             | 4015.6125  |
| perf/NormalizedReturn          | 0.874      |
| Q-avg                          | 183.33693  |
| Q-std                          | 119.23599  |
| Q_loss                         | 104.08661  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 262        |
| times/epoch_after_hook         | 2.02e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000577   |
| times/evaluation_paths         | 29.6       |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 57.9       |
| timestep                       | 1000       |
| timesteps_total                | 263000     |
| train-steps                    | 263000     |
| training/Q/q1_loss             | 101.03134  |
| training/sac_pi/alpha          | 0.16963671 |
| training/sac_pi/alpha_loss     | 0.35132626 |
| training/sac_pi/logp_pi        | 5.188466   |
| training/sac_pi/pi_entropy     | 3.559475   |
| training/sac_pi/pi_global_norm | 1.4784933  |
| training/sac_pi/policy_loss    | -190.20084 |
| training/sac_pi/std            | 0.5421888  |
| training/sac_pi/valid_num      | 4895.0     |
| training/sac_Q/q1              | 176.54971  |
| training/sac_Q/q2              | 175.43361  |
| training/sac_Q/q2_loss         | 101.71435  |
| training/sac_Q/q_global_norm   | 340.07315  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16608101  |
| epoch                          | 263         |
| evaluation/episode-length-avg  | 996         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 959         |
| evaluation/episode-length-std  | 12.3        |
| evaluation/return-average      | 4763.38     |
| evaluation/return-max          | 4836.8555   |
| evaluation/return-min          | 4489.0396   |
| evaluation/return-std          | 94.50117    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45497       |
| perf/AverageLength             | 996         |
| perf/AverageReturn             | 4763.38     |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 182.87454   |
| Q-std                          | 136.64984   |
| Q_loss                         | 88.12425    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 263         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000545    |
| times/evaluation_paths         | 32.2        |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 58          |
| timestep                       | 1000        |
| timesteps_total                | 264000      |
| train-steps                    | 264000      |
| training/Q/q1_loss             | 106.911705  |
| training/sac_pi/alpha          | 0.16609524  |
| training/sac_pi/alpha_loss     | 0.033281624 |
| training/sac_pi/logp_pi        | 4.105314    |
| training/sac_pi/pi_entropy     | 3.4470286   |
| training/sac_pi/pi_global_norm | 2.013889    |
| training/sac_pi/policy_loss    | -198.03316  |
| training/sac_pi/std            | 0.48967546  |
| training/sac_pi/valid_num      | 4962.0      |
| training/sac_Q/q1              | 190.3486    |
| training/sac_Q/q2              | 190.24265   |
| training/sac_Q/q2_loss         | 106.6161    |
| training/sac_Q/q_global_norm   | 217.14078   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16262475 |
| epoch                          | 264        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4615.693   |
| evaluation/return-max          | 4653.3555  |
| evaluation/return-min          | 4574.9277  |
| evaluation/return-std          | 20.499765  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.85       |
| model/origin_ret               | 83         |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45624      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4615.693   |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 180.5688   |
| Q-std                          | 128.28171  |
| Q_loss                         | 100.78511  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 264        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.00011    |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.00067    |
| times/evaluation_paths         | 32.1       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 57.7       |
| timestep                       | 1000       |
| timesteps_total                | 265000     |
| train-steps                    | 265000     |
| training/Q/q1_loss             | 87.83498   |
| training/sac_pi/alpha          | 0.16259573 |
| training/sac_pi/alpha_loss     | 0.27322614 |
| training/sac_pi/logp_pi        | 4.248748   |
| training/sac_pi/pi_entropy     | 3.589685   |
| training/sac_pi/pi_global_norm | 1.7477413  |
| training/sac_pi/policy_loss    | -195.26425 |
| training/sac_pi/std            | 0.5053525  |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 184.24841  |
| training/sac_Q/q2              | 183.3603   |
| training/sac_Q/q2_loss         | 88.01073   |
| training/sac_Q/q_global_norm   | 229.6014   |
--------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.16328765    |
| epoch                          | 265           |
| evaluation/episode-length-avg  | 1e+03         |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 1000          |
| evaluation/episode-length-std  | 0             |
| evaluation/return-average      | 4893.294      |
| evaluation/return-max          | 4970.282      |
| evaluation/return-min          | 4831.8823     |
| evaluation/return-std          | 42.976604     |
| model/max_penalty              | 7.34          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 2.91          |
| model/origin_ret               | 85.2          |
| model/penalty_ret              | 82.3          |
| model/val_loss                 | 0.35430613    |
| model/valid_num                | 45448         |
| perf/AverageLength             | 1e+03         |
| perf/AverageReturn             | 4893.294      |
| perf/NormalizedReturn          | 1.07          |
| Q-avg                          | 179.69766     |
| Q-std                          | 154.20241     |
| Q_loss                         | 98.22523      |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 265           |
| times/epoch_after_hook         | 1.87e-06      |
| times/epoch_before_hook        | 0.000325      |
| times/epoch_rollout_model      | 483           |
| times/evaluation_metrics       | 0.000525      |
| times/evaluation_paths         | 30.3          |
| times/timestep_after_hook      | 0.00384       |
| times/timestep_before_hook     | 0.00827       |
| times/train                    | 57.8          |
| timestep                       | 1000          |
| timesteps_total                | 266000        |
| train-steps                    | 266000        |
| training/Q/q1_loss             | 109.624695    |
| training/sac_pi/alpha          | 0.16327852    |
| training/sac_pi/alpha_loss     | -0.0076328465 |
| training/sac_pi/logp_pi        | 5.025075      |
| training/sac_pi/pi_entropy     | 3.7294514     |
| training/sac_pi/pi_global_norm | 1.8446267     |
| training/sac_pi/policy_loss    | -193.16016    |
| training/sac_pi/std            | 0.5658029     |
| training/sac_pi/valid_num      | 4922.0        |
| training/sac_Q/q1              | 177.05386     |
| training/sac_Q/q2              | 175.15727     |
| training/sac_Q/q2_loss         | 108.50002     |
| training/sac_Q/q_global_norm   | 256.8729      |
-----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17056528   |
| epoch                          | 266          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4710.3955    |
| evaluation/return-max          | 4731.8223    |
| evaluation/return-min          | 4685.392     |
| evaluation/return-std          | 12.354583    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.92         |
| model/origin_ret               | 84.4         |
| model/penalty_ret              | 82.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45677        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4710.3955    |
| perf/NormalizedReturn          | 1.03         |
| Q-avg                          | 185.054      |
| Q-std                          | 102.69672    |
| Q_loss                         | 81.08634     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 266          |
| times/epoch_after_hook         | 1.65e-06     |
| times/epoch_before_hook        | 0.000102     |
| times/epoch_rollout_model      | 468          |
| times/evaluation_metrics       | 0.000577     |
| times/evaluation_paths         | 30.1         |
| times/timestep_after_hook      | 0.00361      |
| times/timestep_before_hook     | 0.00795      |
| times/train                    | 55.4         |
| timestep                       | 1000         |
| timesteps_total                | 267000       |
| train-steps                    | 267000       |
| training/Q/q1_loss             | 79.28986     |
| training/sac_pi/alpha          | 0.17058378   |
| training/sac_pi/alpha_loss     | -0.100757666 |
| training/sac_pi/logp_pi        | 3.9195805    |
| training/sac_pi/pi_entropy     | 3.6947823    |
| training/sac_pi/pi_global_norm | 1.4335244    |
| training/sac_pi/policy_loss    | -198.36957   |
| training/sac_pi/std            | 0.51071495   |
| training/sac_pi/valid_num      | 5000.0       |
| training/sac_Q/q1              | 188.9302     |
| training/sac_Q/q2              | 189.7074     |
| training/sac_Q/q2_loss         | 80.19962     |
| training/sac_Q/q_global_norm   | 245.46611    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16348557 |
| epoch                          | 267        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4772.8394  |
| evaluation/return-max          | 4826.5186  |
| evaluation/return-min          | 4726.6924  |
| evaluation/return-std          | 32.851044  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.79       |
| model/origin_ret               | 82.8       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45355      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4772.8394  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 183.96397  |
| Q-std                          | 118.30672  |
| Q_loss                         | 86.78194   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 267        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000109   |
| times/epoch_rollout_model      | 470        |
| times/evaluation_metrics       | 0.000534   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00795    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 268000     |
| train-steps                    | 268000     |
| training/Q/q1_loss             | 106.585686 |
| training/sac_pi/alpha          | 0.16348018 |
| training/sac_pi/alpha_loss     | -0.2201747 |
| training/sac_pi/logp_pi        | 4.3227262  |
| training/sac_pi/pi_entropy     | 3.7249062  |
| training/sac_pi/pi_global_norm | 1.689474   |
| training/sac_pi/policy_loss    | -192.52956 |
| training/sac_pi/std            | 0.53686845 |
| training/sac_pi/valid_num      | 4944.0     |
| training/sac_Q/q1              | 179.36665  |
| training/sac_Q/q2              | 178.41988  |
| training/sac_Q/q2_loss         | 105.97089  |
| training/sac_Q/q_global_norm   | 258.17587  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17259158 |
| epoch                          | 268        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4365.455   |
| evaluation/return-max          | 4415.0625  |
| evaluation/return-min          | 4304.74    |
| evaluation/return-std          | 34.567192  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.84       |
| model/origin_ret               | 83         |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45599      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4365.455   |
| perf/NormalizedReturn          | 0.951      |
| Q-avg                          | 187.00854  |
| Q-std                          | 108.788956 |
| Q_loss                         | 106.16816  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 268        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 468        |
| times/evaluation_metrics       | 0.000586   |
| times/evaluation_paths         | 29.9       |
| times/timestep_after_hook      | 0.00355    |
| times/timestep_before_hook     | 0.00798    |
| times/train                    | 55.4       |
| timestep                       | 1000       |
| timesteps_total                | 269000     |
| train-steps                    | 269000     |
| training/Q/q1_loss             | 115.49593  |
| training/sac_pi/alpha          | 0.17256871 |
| training/sac_pi/alpha_loss     | 0.3933891  |
| training/sac_pi/logp_pi        | 4.44672    |
| training/sac_pi/pi_entropy     | 3.7637436  |
| training/sac_pi/pi_global_norm | 1.5977279  |
| training/sac_pi/policy_loss    | -188.14886 |
| training/sac_pi/std            | 0.5190479  |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 177.79266  |
| training/sac_Q/q2              | 176.9082   |
| training/sac_Q/q2_loss         | 116.30957  |
| training/sac_Q/q_global_norm   | 243.36128  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17016937 |
| epoch                          | 269        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4358.2236  |
| evaluation/return-max          | 4423.3716  |
| evaluation/return-min          | 4292.351   |
| evaluation/return-std          | 38.713688  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45697      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4358.2236  |
| perf/NormalizedReturn          | 0.949      |
| Q-avg                          | 184.72217  |
| Q-std                          | 113.69981  |
| Q_loss                         | 87.326294  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 269        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000274   |
| times/epoch_rollout_model      | 469        |
| times/evaluation_metrics       | 0.000559   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00785    |
| times/train                    | 55.4       |
| timestep                       | 1000       |
| timesteps_total                | 270000     |
| train-steps                    | 270000     |
| training/Q/q1_loss             | 101.32325  |
| training/sac_pi/alpha          | 0.17016263 |
| training/sac_pi/alpha_loss     | 0.18575919 |
| training/sac_pi/logp_pi        | 4.942586   |
| training/sac_pi/pi_entropy     | 3.6440082  |
| training/sac_pi/pi_global_norm | 1.3150505  |
| training/sac_pi/policy_loss    | -194.6614  |
| training/sac_pi/std            | 0.53638685 |
| training/sac_pi/valid_num      | 4910.0     |
| training/sac_Q/q1              | 179.52304  |
| training/sac_Q/q2              | 178.59833  |
| training/sac_Q/q2_loss         | 101.876236 |
| training/sac_Q/q_global_norm   | 241.4838   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17286456 |
| epoch                          | 270        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4662.028   |
| evaluation/return-max          | 4721.413   |
| evaluation/return-min          | 4584.047   |
| evaluation/return-std          | 51.10443   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45686      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4662.028   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 178.24727  |
| Q-std                          | 120.8642   |
| Q_loss                         | 85.90536   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 270        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000186   |
| times/epoch_rollout_model      | 470        |
| times/evaluation_metrics       | 0.000628   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00352    |
| times/timestep_before_hook     | 0.00779    |
| times/train                    | 55.2       |
| timestep                       | 1000       |
| timesteps_total                | 271000     |
| train-steps                    | 271000     |
| training/Q/q1_loss             | 76.50677   |
| training/sac_pi/alpha          | 0.17285585 |
| training/sac_pi/alpha_loss     | 0.04115773 |
| training/sac_pi/logp_pi        | 3.7206597  |
| training/sac_pi/pi_entropy     | 3.5892212  |
| training/sac_pi/pi_global_norm | 1.3459185  |
| training/sac_pi/policy_loss    | -196.67209 |
| training/sac_pi/std            | 0.48637626 |
| training/sac_pi/valid_num      | 4994.0     |
| training/sac_Q/q1              | 190.2093   |
| training/sac_Q/q2              | 189.12778  |
| training/sac_Q/q2_loss         | 76.17382   |
| training/sac_Q/q_global_norm   | 215.55771  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16194779  |
| epoch                          | 271         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4841.0986   |
| evaluation/return-max          | 4887.954    |
| evaluation/return-min          | 4814.645    |
| evaluation/return-std          | 21.272509   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45702       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4841.0986   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 186.36812   |
| Q-std                          | 131.3464    |
| Q_loss                         | 105.42265   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 271         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000104    |
| times/epoch_rollout_model      | 469         |
| times/evaluation_metrics       | 0.000558    |
| times/evaluation_paths         | 30.2        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00795     |
| times/train                    | 55.5        |
| timestep                       | 1000        |
| timesteps_total                | 272000      |
| train-steps                    | 272000      |
| training/Q/q1_loss             | 92.64816    |
| training/sac_pi/alpha          | 0.16193274  |
| training/sac_pi/alpha_loss     | -0.16119103 |
| training/sac_pi/logp_pi        | 4.58508     |
| training/sac_pi/pi_entropy     | 3.5862243   |
| training/sac_pi/pi_global_norm | 1.656829    |
| training/sac_pi/policy_loss    | -199.31433  |
| training/sac_pi/std            | 0.5315229   |
| training/sac_pi/valid_num      | 4917.0      |
| training/sac_Q/q1              | 182.48074   |
| training/sac_Q/q2              | 183.60883   |
| training/sac_Q/q2_loss         | 92.507965   |
| training/sac_Q/q_global_norm   | 241.84297   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16486439 |
| epoch                          | 272        |
| evaluation/episode-length-avg  | 155        |
| evaluation/episode-length-max  | 163        |
| evaluation/episode-length-min  | 149        |
| evaluation/episode-length-std  | 5.51       |
| evaluation/return-average      | 442.0875   |
| evaluation/return-max          | 463.45877  |
| evaluation/return-min          | 422.54584  |
| evaluation/return-std          | 14.965202  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45657      |
| perf/AverageLength             | 155        |
| perf/AverageReturn             | 442.0875   |
| perf/NormalizedReturn          | 0.0959     |
| Q-avg                          | 173.0241   |
| Q-std                          | 148.95738  |
| Q_loss                         | 100.34404  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 272        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000105   |
| times/epoch_rollout_model      | 469        |
| times/evaluation_metrics       | 0.00054    |
| times/evaluation_paths         | 4.67       |
| times/timestep_after_hook      | 0.00353    |
| times/timestep_before_hook     | 0.00789    |
| times/train                    | 55.4       |
| timestep                       | 1000       |
| timesteps_total                | 273000     |
| train-steps                    | 273000     |
| training/Q/q1_loss             | 125.940834 |
| training/sac_pi/alpha          | 0.16490027 |
| training/sac_pi/alpha_loss     | -0.4436557 |
| training/sac_pi/logp_pi        | 4.12182    |
| training/sac_pi/pi_entropy     | 3.6123886  |
| training/sac_pi/pi_global_norm | 1.5374366  |
| training/sac_pi/policy_loss    | -194.80731 |
| training/sac_pi/std            | 0.51336277 |
| training/sac_pi/valid_num      | 4946.0     |
| training/sac_Q/q1              | 183.2313   |
| training/sac_Q/q2              | 183.66248  |
| training/sac_Q/q2_loss         | 126.62384  |
| training/sac_Q/q_global_norm   | 232.99127  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16181089 |
| epoch                          | 273        |
| evaluation/episode-length-avg  | 656        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 137        |
| evaluation/episode-length-std  | 422        |
| evaluation/return-average      | 3010.396   |
| evaluation/return-max          | 4819.3926  |
| evaluation/return-min          | 330.8557   |
| evaluation/return-std          | 2183.4092  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 82.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45672      |
| perf/AverageLength             | 656        |
| perf/AverageReturn             | 3010.396   |
| perf/NormalizedReturn          | 0.655      |
| Q-avg                          | 184.32329  |
| Q-std                          | 166.95609  |
| Q_loss                         | 90.64131   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 273        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000281   |
| times/epoch_rollout_model      | 468        |
| times/evaluation_metrics       | 0.000531   |
| times/evaluation_paths         | 19.8       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00778    |
| times/train                    | 55.4       |
| timestep                       | 1000       |
| timesteps_total                | 274000     |
| train-steps                    | 274000     |
| training/Q/q1_loss             | 85.28978   |
| training/sac_pi/alpha          | 0.16183904 |
| training/sac_pi/alpha_loss     | -0.4529826 |
| training/sac_pi/logp_pi        | 3.603862   |
| training/sac_pi/pi_entropy     | 3.4222527  |
| training/sac_pi/pi_global_norm | 2.0290194  |
| training/sac_pi/policy_loss    | -205.2032  |
| training/sac_pi/std            | 0.47744375 |
| training/sac_pi/valid_num      | 5013.0     |
| training/sac_Q/q1              | 198.21219  |
| training/sac_Q/q2              | 196.79129  |
| training/sac_Q/q2_loss         | 85.49157   |
| training/sac_Q/q_global_norm   | 202.07678  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16597505 |
| epoch                          | 274        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4942.7056  |
| evaluation/return-max          | 4976.0244  |
| evaluation/return-min          | 4878.0425  |
| evaluation/return-std          | 27.381285  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 82.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45710      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4942.7056  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 178.97293  |
| Q-std                          | 119.836845 |
| Q_loss                         | 95.24164   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 274        |
| times/epoch_after_hook         | 1.99e-06   |
| times/epoch_before_hook        | 0.000102   |
| times/epoch_rollout_model      | 468        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00356    |
| times/timestep_before_hook     | 0.00779    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 275000     |
| train-steps                    | 275000     |
| training/Q/q1_loss             | 102.448746 |
| training/sac_pi/alpha          | 0.16593713 |
| training/sac_pi/alpha_loss     | 0.4555884  |
| training/sac_pi/logp_pi        | 4.0623984  |
| training/sac_pi/pi_entropy     | 3.5318344  |
| training/sac_pi/pi_global_norm | 1.4346602  |
| training/sac_pi/policy_loss    | -193.76091 |
| training/sac_pi/std            | 0.47983965 |
| training/sac_pi/valid_num      | 5007.0     |
| training/sac_Q/q1              | 187.91187  |
| training/sac_Q/q2              | 188.05486  |
| training/sac_Q/q2_loss         | 102.396034 |
| training/sac_Q/q_global_norm   | 247.89502  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16292347  |
| epoch                          | 275         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5028.6836   |
| evaluation/return-max          | 5055.3306   |
| evaluation/return-min          | 5006.727    |
| evaluation/return-std          | 14.022649   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.89        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 82.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45470       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5028.6836   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 206.7104    |
| Q-std                          | 103.322075  |
| Q_loss                         | 81.3713     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 275         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000102    |
| times/epoch_rollout_model      | 469         |
| times/evaluation_metrics       | 0.000548    |
| times/evaluation_paths         | 30          |
| times/timestep_after_hook      | 0.00346     |
| times/timestep_before_hook     | 0.00776     |
| times/train                    | 55.4        |
| timestep                       | 1000        |
| timesteps_total                | 276000      |
| train-steps                    | 276000      |
| training/Q/q1_loss             | 83.35562    |
| training/sac_pi/alpha          | 0.16295852  |
| training/sac_pi/alpha_loss     | -0.16598925 |
| training/sac_pi/logp_pi        | 4.4236684   |
| training/sac_pi/pi_entropy     | 3.6160183   |
| training/sac_pi/pi_global_norm | 1.3170677   |
| training/sac_pi/policy_loss    | -198.15703  |
| training/sac_pi/std            | 0.5214176   |
| training/sac_pi/valid_num      | 4979.0      |
| training/sac_Q/q1              | 187.71494   |
| training/sac_Q/q2              | 185.43408   |
| training/sac_Q/q2_loss         | 83.08906    |
| training/sac_Q/q_global_norm   | 205.08345   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16920774 |
| epoch                          | 276        |
| evaluation/episode-length-avg  | 305        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 125        |
| evaluation/episode-length-std  | 348        |
| evaluation/return-average      | 1277.3317  |
| evaluation/return-max          | 4882.534   |
| evaluation/return-min          | 355.7881   |
| evaluation/return-std          | 1798.4592  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 83.5       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45608      |
| perf/AverageLength             | 305        |
| perf/AverageReturn             | 1277.3317  |
| perf/NormalizedReturn          | 0.278      |
| Q-avg                          | 168.71307  |
| Q-std                          | 142.13612  |
| Q_loss                         | 117.12611  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 276        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 470        |
| times/evaluation_metrics       | 0.000613   |
| times/evaluation_paths         | 9.43       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00775    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 277000     |
| train-steps                    | 277000     |
| training/Q/q1_loss             | 89.65988   |
| training/sac_pi/alpha          | 0.16916656 |
| training/sac_pi/alpha_loss     | 0.1823312  |
| training/sac_pi/logp_pi        | 4.0789433  |
| training/sac_pi/pi_entropy     | 3.6034093  |
| training/sac_pi/pi_global_norm | 1.6043236  |
| training/sac_pi/policy_loss    | -198.10712 |
| training/sac_pi/std            | 0.50813675 |
| training/sac_pi/valid_num      | 5020.0     |
| training/sac_Q/q1              | 187.74379  |
| training/sac_Q/q2              | 186.50757  |
| training/sac_Q/q2_loss         | 90.79111   |
| training/sac_Q/q_global_norm   | 279.15683  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16543259  |
| epoch                          | 277         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4895.6157   |
| evaluation/return-max          | 4927.4287   |
| evaluation/return-min          | 4871.5127   |
| evaluation/return-std          | 18.335133   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 83.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45735       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4895.6157   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 194.23819   |
| Q-std                          | 114.193245  |
| Q_loss                         | 93.46668    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 277         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000311    |
| times/epoch_rollout_model      | 469         |
| times/evaluation_metrics       | 0.000567    |
| times/evaluation_paths         | 29.8        |
| times/timestep_after_hook      | 0.00352     |
| times/timestep_before_hook     | 0.00781     |
| times/train                    | 55.3        |
| timestep                       | 1000        |
| timesteps_total                | 278000      |
| train-steps                    | 278000      |
| training/Q/q1_loss             | 111.399086  |
| training/sac_pi/alpha          | 0.16542917  |
| training/sac_pi/alpha_loss     | -0.06029571 |
| training/sac_pi/logp_pi        | 4.576031    |
| training/sac_pi/pi_entropy     | 3.6854072   |
| training/sac_pi/pi_global_norm | 1.3962718   |
| training/sac_pi/policy_loss    | -198.16731  |
| training/sac_pi/std            | 0.5308697   |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 185.10721   |
| training/sac_Q/q2              | 184.56735   |
| training/sac_Q/q2_loss         | 112.08088   |
| training/sac_Q/q_global_norm   | 243.59343   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16609031  |
| epoch                          | 278         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4732.191    |
| evaluation/return-max          | 4805.1206   |
| evaluation/return-min          | 4674.572    |
| evaluation/return-std          | 36.64377    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.87        |
| model/origin_ret               | 83.8        |
| model/penalty_ret              | 82.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45567       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4732.191    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 170.8497    |
| Q-std                          | 136.34346   |
| Q_loss                         | 113.825035  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 278         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000108    |
| times/epoch_rollout_model      | 470         |
| times/evaluation_metrics       | 0.00059     |
| times/evaluation_paths         | 30.2        |
| times/timestep_after_hook      | 0.00354     |
| times/timestep_before_hook     | 0.00786     |
| times/train                    | 55.7        |
| timestep                       | 1000        |
| timesteps_total                | 279000      |
| train-steps                    | 279000      |
| training/Q/q1_loss             | 117.209045  |
| training/sac_pi/alpha          | 0.16616611  |
| training/sac_pi/alpha_loss     | -0.47588617 |
| training/sac_pi/logp_pi        | 4.3655314   |
| training/sac_pi/pi_entropy     | 3.6887329   |
| training/sac_pi/pi_global_norm | 1.9929218   |
| training/sac_pi/policy_loss    | -189.08566  |
| training/sac_pi/std            | 0.53166944  |
| training/sac_pi/valid_num      | 4941.0      |
| training/sac_Q/q1              | 174.57187   |
| training/sac_Q/q2              | 173.89394   |
| training/sac_Q/q2_loss         | 117.36912   |
| training/sac_Q/q_global_norm   | 214.12248   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17234953  |
| epoch                          | 279         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4680.763    |
| evaluation/return-max          | 4726.398    |
| evaluation/return-min          | 4641.8926   |
| evaluation/return-std          | 24.780613   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.85        |
| model/origin_ret               | 82.6        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45701       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4680.763    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 183.82608   |
| Q-std                          | 116.99905   |
| Q_loss                         | 75.92068    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 279         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000106    |
| times/epoch_rollout_model      | 471         |
| times/evaluation_metrics       | 0.000601    |
| times/evaluation_paths         | 30          |
| times/timestep_after_hook      | 0.00355     |
| times/timestep_before_hook     | 0.00772     |
| times/train                    | 54.8        |
| timestep                       | 1000        |
| timesteps_total                | 280000      |
| train-steps                    | 280000      |
| training/Q/q1_loss             | 115.61999   |
| training/sac_pi/alpha          | 0.17234278  |
| training/sac_pi/alpha_loss     | -0.15778792 |
| training/sac_pi/logp_pi        | 4.720886    |
| training/sac_pi/pi_entropy     | 3.8439972   |
| training/sac_pi/pi_global_norm | 1.6483322   |
| training/sac_pi/policy_loss    | -193.49953  |
| training/sac_pi/std            | 0.55164236  |
| training/sac_pi/valid_num      | 4951.0      |
| training/sac_Q/q1              | 180.90384   |
| training/sac_Q/q2              | 178.00583   |
| training/sac_Q/q2_loss         | 115.58481   |
| training/sac_Q/q_global_norm   | 280.53876   |
---------------------------------------------------------------------------------
[WARN] 280 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16879982 |
| epoch                          | 280        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4930.028   |
| evaluation/return-max          | 4977.922   |
| evaluation/return-min          | 4883.112   |
| evaluation/return-std          | 27.324692  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45681      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4930.028   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 197.47592  |
| Q-std                          | 89.15685   |
| Q_loss                         | 96.3993    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 280        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000102   |
| times/epoch_rollout_model      | 468        |
| times/evaluation_metrics       | 0.000597   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00351    |
| times/timestep_before_hook     | 0.00779    |
| times/train                    | 54.7       |
| timestep                       | 1000       |
| timesteps_total                | 281000     |
| train-steps                    | 281000     |
| training/Q/q1_loss             | 118.6084   |
| training/sac_pi/alpha          | 0.16881017 |
| training/sac_pi/alpha_loss     | 0.08021595 |
| training/sac_pi/logp_pi        | 4.576196   |
| training/sac_pi/pi_entropy     | 3.8694656  |
| training/sac_pi/pi_global_norm | 1.633193   |
| training/sac_pi/policy_loss    | -192.06253 |
| training/sac_pi/std            | 0.5593003  |
| training/sac_pi/valid_num      | 4980.0     |
| training/sac_Q/q1              | 177.56796  |
| training/sac_Q/q2              | 175.11243  |
| training/sac_Q/q2_loss         | 120.03898  |
| training/sac_Q/q_global_norm   | 247.938    |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16628842 |
| epoch                          | 281        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4580.6294  |
| evaluation/return-max          | 4656.6445  |
| evaluation/return-min          | 4529.8325  |
| evaluation/return-std          | 35.528664  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45528      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4580.6294  |
| perf/NormalizedReturn          | 0.997      |
| Q-avg                          | 194.31792  |
| Q-std                          | 124.83015  |
| Q_loss                         | 86.404976  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 281        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.00029    |
| times/epoch_rollout_model      | 472        |
| times/evaluation_metrics       | 0.00052    |
| times/evaluation_paths         | 29.9       |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.00774    |
| times/train                    | 55.3       |
| timestep                       | 1000       |
| timesteps_total                | 282000     |
| train-steps                    | 282000     |
| training/Q/q1_loss             | 87.1       |
| training/sac_pi/alpha          | 0.16633211 |
| training/sac_pi/alpha_loss     | -0.2799458 |
| training/sac_pi/logp_pi        | 4.343183   |
| training/sac_pi/pi_entropy     | 3.4554062  |
| training/sac_pi/pi_global_norm | 1.4628141  |
| training/sac_pi/policy_loss    | -198.6083  |
| training/sac_pi/std            | 0.50832856 |
| training/sac_pi/valid_num      | 4979.0     |
| training/sac_Q/q1              | 186.41669  |
| training/sac_Q/q2              | 183.8167   |
| training/sac_Q/q2_loss         | 86.7563    |
| training/sac_Q/q_global_norm   | 288.3881   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17699763  |
| epoch                          | 282         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4208.2974   |
| evaluation/return-max          | 4319.52     |
| evaluation/return-min          | 4122.743    |
| evaluation/return-std          | 50.981483   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 82.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45627       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4208.2974   |
| perf/NormalizedReturn          | 0.916       |
| Q-avg                          | 185.79701   |
| Q-std                          | 119.999954  |
| Q_loss                         | 98.87725    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 282         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000109    |
| times/epoch_rollout_model      | 468         |
| times/evaluation_metrics       | 0.000543    |
| times/evaluation_paths         | 30.1        |
| times/timestep_after_hook      | 0.00349     |
| times/timestep_before_hook     | 0.00775     |
| times/train                    | 55.1        |
| timestep                       | 1000        |
| timesteps_total                | 283000      |
| train-steps                    | 283000      |
| training/Q/q1_loss             | 109.824814  |
| training/sac_pi/alpha          | 0.17700015  |
| training/sac_pi/alpha_loss     | 0.012472031 |
| training/sac_pi/logp_pi        | 5.025862    |
| training/sac_pi/pi_entropy     | 3.759365    |
| training/sac_pi/pi_global_norm | 1.5650803   |
| training/sac_pi/policy_loss    | -196.04257  |
| training/sac_pi/std            | 0.55721074  |
| training/sac_pi/valid_num      | 4842.0      |
| training/sac_Q/q1              | 177.57114   |
| training/sac_Q/q2              | 175.38403   |
| training/sac_Q/q2_loss         | 109.79448   |
| training/sac_Q/q_global_norm   | 203.04039   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17117387 |
| epoch                          | 283        |
| evaluation/episode-length-avg  | 914        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 135        |
| evaluation/episode-length-std  | 260        |
| evaluation/return-average      | 4514.889   |
| evaluation/return-max          | 5045.537   |
| evaluation/return-min          | 334.3061   |
| evaluation/return-std          | 1395.3517  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45581      |
| perf/AverageLength             | 914        |
| perf/AverageReturn             | 4514.889   |
| perf/NormalizedReturn          | 0.983      |
| Q-avg                          | 179.76486  |
| Q-std                          | 158.19951  |
| Q_loss                         | 115.44869  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 283        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 470        |
| times/evaluation_metrics       | 0.000526   |
| times/evaluation_paths         | 27.6       |
| times/timestep_after_hook      | 0.00356    |
| times/timestep_before_hook     | 0.00777    |
| times/train                    | 55.2       |
| timestep                       | 1000       |
| timesteps_total                | 284000     |
| train-steps                    | 284000     |
| training/Q/q1_loss             | 113.11412  |
| training/sac_pi/alpha          | 0.171174   |
| training/sac_pi/alpha_loss     | 0.14866725 |
| training/sac_pi/logp_pi        | 4.4176025  |
| training/sac_pi/pi_entropy     | 3.4754434  |
| training/sac_pi/pi_global_norm | 1.66353    |
| training/sac_pi/policy_loss    | -200.11636 |
| training/sac_pi/std            | 0.50344056 |
| training/sac_pi/valid_num      | 4980.0     |
| training/sac_Q/q1              | 187.92331  |
| training/sac_Q/q2              | 186.63583  |
| training/sac_Q/q2_loss         | 112.87327  |
| training/sac_Q/q_global_norm   | 205.6418   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17742488 |
| epoch                          | 284        |
| evaluation/episode-length-avg  | 846        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 221        |
| evaluation/episode-length-std  | 309        |
| evaluation/return-average      | 3918.1968  |
| evaluation/return-max          | 4770.409   |
| evaluation/return-min          | 647.187    |
| evaluation/return-std          | 1625.2831  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.86       |
| model/origin_ret               | 83.2       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45676      |
| perf/AverageLength             | 846        |
| perf/AverageReturn             | 3918.1968  |
| perf/NormalizedReturn          | 0.853      |
| Q-avg                          | 185.77109  |
| Q-std                          | 130.07358  |
| Q_loss                         | 97.96935   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 284        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 472        |
| times/evaluation_metrics       | 0.000522   |
| times/evaluation_paths         | 25.5       |
| times/timestep_after_hook      | 0.00356    |
| times/timestep_before_hook     | 0.00774    |
| times/train                    | 55.3       |
| timestep                       | 1000       |
| timesteps_total                | 285000     |
| train-steps                    | 285000     |
| training/Q/q1_loss             | 97.86154   |
| training/sac_pi/alpha          | 0.17740573 |
| training/sac_pi/alpha_loss     | 0.3419945  |
| training/sac_pi/logp_pi        | 4.674306   |
| training/sac_pi/pi_entropy     | 3.5593028  |
| training/sac_pi/pi_global_norm | 1.6147832  |
| training/sac_pi/policy_loss    | -199.43073 |
| training/sac_pi/std            | 0.51522785 |
| training/sac_pi/valid_num      | 4971.0     |
| training/sac_Q/q1              | 186.65227  |
| training/sac_Q/q2              | 186.84012  |
| training/sac_Q/q2_loss         | 97.539795  |
| training/sac_Q/q_global_norm   | 217.50226  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16942099 |
| epoch                          | 285        |
| evaluation/episode-length-avg  | 842        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 211        |
| evaluation/episode-length-std  | 315        |
| evaluation/return-average      | 3993.104   |
| evaluation/return-max          | 4865.83    |
| evaluation/return-min          | 636.7888   |
| evaluation/return-std          | 1672.9392  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45505      |
| perf/AverageLength             | 842        |
| perf/AverageReturn             | 3993.104   |
| perf/NormalizedReturn          | 0.869      |
| Q-avg                          | 181.21597  |
| Q-std                          | 138.81595  |
| Q_loss                         | 95.536964  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 285        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000278   |
| times/epoch_rollout_model      | 468        |
| times/evaluation_metrics       | 0.000531   |
| times/evaluation_paths         | 25.4       |
| times/timestep_after_hook      | 0.00349    |
| times/timestep_before_hook     | 0.00781    |
| times/train                    | 55.1       |
| timestep                       | 1000       |
| timesteps_total                | 286000     |
| train-steps                    | 286000     |
| training/Q/q1_loss             | 90.70278   |
| training/sac_pi/alpha          | 0.16940783 |
| training/sac_pi/alpha_loss     | 0.06982021 |
| training/sac_pi/logp_pi        | 4.717096   |
| training/sac_pi/pi_entropy     | 3.6846435  |
| training/sac_pi/pi_global_norm | 1.4239956  |
| training/sac_pi/policy_loss    | -198.6332  |
| training/sac_pi/std            | 0.54018646 |
| training/sac_pi/valid_num      | 4932.0     |
| training/sac_Q/q1              | 181.89133  |
| training/sac_Q/q2              | 182.36487  |
| training/sac_Q/q2_loss         | 90.210434  |
| training/sac_Q/q_global_norm   | 289.19165  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16341338  |
| epoch                          | 286         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4826.3237   |
| evaluation/return-max          | 4935.9316   |
| evaluation/return-min          | 4689.7305   |
| evaluation/return-std          | 72.9548     |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 86.9        |
| model/penalty_ret              | 83.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45435       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4826.3237   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 174.14851   |
| Q-std                          | 148.71027   |
| Q_loss                         | 87.26095    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 286         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000108    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000539    |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00805     |
| times/train                    | 55.3        |
| timestep                       | 1000        |
| timesteps_total                | 287000      |
| train-steps                    | 287000      |
| training/Q/q1_loss             | 94.54776    |
| training/sac_pi/alpha          | 0.16340543  |
| training/sac_pi/alpha_loss     | -0.30020648 |
| training/sac_pi/logp_pi        | 4.338605    |
| training/sac_pi/pi_entropy     | 3.8111672   |
| training/sac_pi/pi_global_norm | 1.5259781   |
| training/sac_pi/policy_loss    | -189.77936  |
| training/sac_pi/std            | 0.5641223   |
| training/sac_pi/valid_num      | 4954.0      |
| training/sac_Q/q1              | 178.52995   |
| training/sac_Q/q2              | 176.55289   |
| training/sac_Q/q2_loss         | 94.61762    |
| training/sac_Q/q_global_norm   | 202.06642   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16739662  |
| epoch                          | 287         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4706.937    |
| evaluation/return-max          | 4764.9824   |
| evaluation/return-min          | 4657.849    |
| evaluation/return-std          | 32.892914   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.84        |
| model/origin_ret               | 82.8        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45517       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4706.937    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 187.2439    |
| Q-std                          | 116.386826  |
| Q_loss                         | 93.65684    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 287         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 474         |
| times/evaluation_metrics       | 0.00068     |
| times/evaluation_paths         | 30.3        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00802     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 288000      |
| train-steps                    | 288000      |
| training/Q/q1_loss             | 100.0398    |
| training/sac_pi/alpha          | 0.167423    |
| training/sac_pi/alpha_loss     | -0.07539459 |
| training/sac_pi/logp_pi        | 4.8087645   |
| training/sac_pi/pi_entropy     | 3.7181728   |
| training/sac_pi/pi_global_norm | 1.5971116   |
| training/sac_pi/policy_loss    | -198.74098  |
| training/sac_pi/std            | 0.5555561   |
| training/sac_pi/valid_num      | 4913.0      |
| training/sac_Q/q1              | 182.83145   |
| training/sac_Q/q2              | 180.21024   |
| training/sac_Q/q2_loss         | 99.720695   |
| training/sac_Q/q_global_norm   | 384.75156   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16930063 |
| epoch                          | 288        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4398.3477  |
| evaluation/return-max          | 4464.3203  |
| evaluation/return-min          | 4347.9844  |
| evaluation/return-std          | 41.494114  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 83.8       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45651      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4398.3477  |
| perf/NormalizedReturn          | 0.958      |
| Q-avg                          | 176.59152  |
| Q-std                          | 157.5904   |
| Q_loss                         | 71.10514   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 288        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 471        |
| times/evaluation_metrics       | 0.000529   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00787    |
| times/train                    | 54.9       |
| timestep                       | 1000       |
| timesteps_total                | 289000     |
| train-steps                    | 289000     |
| training/Q/q1_loss             | 96.059654  |
| training/sac_pi/alpha          | 0.16928189 |
| training/sac_pi/alpha_loss     | 0.02855997 |
| training/sac_pi/logp_pi        | 4.2898264  |
| training/sac_pi/pi_entropy     | 3.6019177  |
| training/sac_pi/pi_global_norm | 1.6439251  |
| training/sac_pi/policy_loss    | -195.70381 |
| training/sac_pi/std            | 0.5176957  |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 184.0712   |
| training/sac_Q/q2              | 183.42537  |
| training/sac_Q/q2_loss         | 97.5174    |
| training/sac_Q/q_global_norm   | 235.94366  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.161997   |
| epoch                          | 289        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4582.1953  |
| evaluation/return-max          | 4646.1357  |
| evaluation/return-min          | 4524.7393  |
| evaluation/return-std          | 36.538548  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45574      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4582.1953  |
| perf/NormalizedReturn          | 0.998      |
| Q-avg                          | 180.91284  |
| Q-std                          | 126.97442  |
| Q_loss                         | 113.1059   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 289        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000285   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000519   |
| times/evaluation_paths         | 30.4       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 56.4       |
| timestep                       | 1000       |
| timesteps_total                | 290000     |
| train-steps                    | 290000     |
| training/Q/q1_loss             | 110.91202  |
| training/sac_pi/alpha          | 0.1619569  |
| training/sac_pi/alpha_loss     | 0.84695274 |
| training/sac_pi/logp_pi        | 5.1428084  |
| training/sac_pi/pi_entropy     | 3.5650833  |
| training/sac_pi/pi_global_norm | 1.4477948  |
| training/sac_pi/policy_loss    | -192.65367 |
| training/sac_pi/std            | 0.52319586 |
| training/sac_pi/valid_num      | 4955.0     |
| training/sac_Q/q1              | 182.6045   |
| training/sac_Q/q2              | 182.48213  |
| training/sac_Q/q2_loss         | 111.100426 |
| training/sac_Q/q_global_norm   | 252.39368  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1622467   |
| epoch                          | 290         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4569.047    |
| evaluation/return-max          | 4624.6533   |
| evaluation/return-min          | 4414.056    |
| evaluation/return-std          | 57.476723   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.82        |
| model/origin_ret               | 83.6        |
| model/penalty_ret              | 82.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45561       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4569.047    |
| perf/NormalizedReturn          | 0.995       |
| Q-avg                          | 176.00504   |
| Q-std                          | 166.39452   |
| Q_loss                         | 96.87213    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 290         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 30.1        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00796     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 291000      |
| train-steps                    | 291000      |
| training/Q/q1_loss             | 85.09118    |
| training/sac_pi/alpha          | 0.16227132  |
| training/sac_pi/alpha_loss     | -0.68029827 |
| training/sac_pi/logp_pi        | 5.0051317   |
| training/sac_pi/pi_entropy     | 3.6209671   |
| training/sac_pi/pi_global_norm | 1.4795892   |
| training/sac_pi/policy_loss    | -200.0942   |
| training/sac_pi/std            | 0.56704026  |
| training/sac_pi/valid_num      | 4853.0      |
| training/sac_Q/q1              | 180.79675   |
| training/sac_Q/q2              | 178.48636   |
| training/sac_Q/q2_loss         | 85.03607    |
| training/sac_Q/q_global_norm   | 190.71748   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16991644   |
| epoch                          | 291          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4858.2725    |
| evaluation/return-max          | 4913.6846    |
| evaluation/return-min          | 4803.868     |
| evaluation/return-std          | 30.15764     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.88         |
| model/origin_ret               | 83.4         |
| model/penalty_ret              | 81.5         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45610        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4858.2725    |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 180.66281    |
| Q-std                          | 108.50293    |
| Q_loss                         | 92.31902     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 291          |
| times/epoch_after_hook         | 2e-06        |
| times/epoch_before_hook        | 0.000106     |
| times/epoch_rollout_model      | 476          |
| times/evaluation_metrics       | 0.000552     |
| times/evaluation_paths         | 31           |
| times/timestep_after_hook      | 0.00371      |
| times/timestep_before_hook     | 0.00804      |
| times/train                    | 55.8         |
| timestep                       | 1000         |
| timesteps_total                | 292000       |
| train-steps                    | 292000       |
| training/Q/q1_loss             | 85.89541     |
| training/sac_pi/alpha          | 0.16991527   |
| training/sac_pi/alpha_loss     | -0.052947022 |
| training/sac_pi/logp_pi        | 3.6959558    |
| training/sac_pi/pi_entropy     | 3.6623936    |
| training/sac_pi/pi_global_norm | 1.6048415    |
| training/sac_pi/policy_loss    | -195.54602   |
| training/sac_pi/std            | 0.49602732   |
| training/sac_pi/valid_num      | 5032.0       |
| training/sac_Q/q1              | 191.53496    |
| training/sac_Q/q2              | 189.7648     |
| training/sac_Q/q2_loss         | 86.43364     |
| training/sac_Q/q_global_norm   | 464.39218    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16375326 |
| epoch                          | 292        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5018.6396  |
| evaluation/return-max          | 5063.539   |
| evaluation/return-min          | 4986.2173  |
| evaluation/return-std          | 25.280733  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45507      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5018.6396  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 191.30736  |
| Q-std                          | 118.0764   |
| Q_loss                         | 89.77231   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 292        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000559   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00792    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 293000     |
| train-steps                    | 293000     |
| training/Q/q1_loss             | 105.99642  |
| training/sac_pi/alpha          | 0.1637665  |
| training/sac_pi/alpha_loss     | 0.10807215 |
| training/sac_pi/logp_pi        | 3.8766913  |
| training/sac_pi/pi_entropy     | 3.5767522  |
| training/sac_pi/pi_global_norm | 1.6111547  |
| training/sac_pi/policy_loss    | -203.30252 |
| training/sac_pi/std            | 0.500581   |
| training/sac_pi/valid_num      | 5012.0     |
| training/sac_Q/q1              | 197.01128  |
| training/sac_Q/q2              | 194.66739  |
| training/sac_Q/q2_loss         | 106.43467  |
| training/sac_Q/q_global_norm   | 305.11038  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16128485  |
| epoch                          | 293         |
| evaluation/episode-length-avg  | 410         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 149         |
| evaluation/episode-length-std  | 386         |
| evaluation/return-average      | 1821.7805   |
| evaluation/return-max          | 4925.555    |
| evaluation/return-min          | 481.5796    |
| evaluation/return-std          | 2017.9575   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45525       |
| perf/AverageLength             | 410         |
| perf/AverageReturn             | 1821.7805   |
| perf/NormalizedReturn          | 0.396       |
| Q-avg                          | 182.24492   |
| Q-std                          | 138.58942   |
| Q_loss                         | 94.66479    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 293         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000275    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000488    |
| times/evaluation_paths         | 12.6        |
| times/timestep_after_hook      | 0.00351     |
| times/timestep_before_hook     | 0.00783     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 294000      |
| train-steps                    | 294000      |
| training/Q/q1_loss             | 72.482994   |
| training/sac_pi/alpha          | 0.16129616  |
| training/sac_pi/alpha_loss     | -0.07144377 |
| training/sac_pi/logp_pi        | 3.9439225   |
| training/sac_pi/pi_entropy     | 3.5136642   |
| training/sac_pi/pi_global_norm | 1.6454352   |
| training/sac_pi/policy_loss    | -204.75223  |
| training/sac_pi/std            | 0.5011761   |
| training/sac_pi/valid_num      | 4979.0      |
| training/sac_Q/q1              | 193.89551   |
| training/sac_Q/q2              | 193.62764   |
| training/sac_Q/q2_loss         | 72.72172    |
| training/sac_Q/q_global_norm   | 209.67723   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16822432 |
| epoch                          | 294        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4669.6343  |
| evaluation/return-max          | 4855.222   |
| evaluation/return-min          | 4528.007   |
| evaluation/return-std          | 96.482475  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.87       |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45533      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4669.6343  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 188.09526  |
| Q-std                          | 136.85675  |
| Q_loss                         | 79.73911   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 294        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000543   |
| times/evaluation_paths         | 31.2       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00789    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 295000     |
| train-steps                    | 295000     |
| training/Q/q1_loss             | 97.655266  |
| training/sac_pi/alpha          | 0.1682058  |
| training/sac_pi/alpha_loss     | 0.15975732 |
| training/sac_pi/logp_pi        | 4.8493295  |
| training/sac_pi/pi_entropy     | 3.806202   |
| training/sac_pi/pi_global_norm | 1.4486015  |
| training/sac_pi/policy_loss    | -189.47633 |
| training/sac_pi/std            | 0.55724925 |
| training/sac_pi/valid_num      | 4866.0     |
| training/sac_Q/q1              | 173.3115   |
| training/sac_Q/q2              | 171.80681  |
| training/sac_Q/q2_loss         | 98.05273   |
| training/sac_Q/q_global_norm   | 276.70694  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16609077  |
| epoch                          | 295         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4570.77     |
| evaluation/return-max          | 4698.375    |
| evaluation/return-min          | 4393.7207   |
| evaluation/return-std          | 83.71344    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45622       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4570.77     |
| perf/NormalizedReturn          | 0.995       |
| Q-avg                          | 189.29808   |
| Q-std                          | 152.54362   |
| Q_loss                         | 82.9393     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 295         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.00012     |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000594    |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00787     |
| times/train                    | 56.1        |
| timestep                       | 1000        |
| timesteps_total                | 296000      |
| train-steps                    | 296000      |
| training/Q/q1_loss             | 102.237785  |
| training/sac_pi/alpha          | 0.16610186  |
| training/sac_pi/alpha_loss     | -0.34276313 |
| training/sac_pi/logp_pi        | 5.356951    |
| training/sac_pi/pi_entropy     | 3.8866036   |
| training/sac_pi/pi_global_norm | 1.5071763   |
| training/sac_pi/policy_loss    | -199.90445  |
| training/sac_pi/std            | 0.60480815  |
| training/sac_pi/valid_num      | 4857.0      |
| training/sac_Q/q1              | 179.54202   |
| training/sac_Q/q2              | 175.46417   |
| training/sac_Q/q2_loss         | 101.56441   |
| training/sac_Q/q_global_norm   | 348.91      |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16835676  |
| epoch                          | 296         |
| evaluation/episode-length-avg  | 924         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 245         |
| evaluation/episode-length-std  | 226         |
| evaluation/return-average      | 4645.968    |
| evaluation/return-max          | 5091.299    |
| evaluation/return-min          | 828.6994    |
| evaluation/return-std          | 1272.5712   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 83.6        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45745       |
| perf/AverageLength             | 924         |
| perf/AverageReturn             | 4645.968    |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 167.30695   |
| Q-std                          | 170.24355   |
| Q_loss                         | 115.08415   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 296         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000115    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000525    |
| times/evaluation_paths         | 28.4        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.008       |
| times/train                    | 56.2        |
| timestep                       | 1000        |
| timesteps_total                | 297000      |
| train-steps                    | 297000      |
| training/Q/q1_loss             | 98.476875   |
| training/sac_pi/alpha          | 0.1683555   |
| training/sac_pi/alpha_loss     | -0.06841857 |
| training/sac_pi/logp_pi        | 4.314128    |
| training/sac_pi/pi_entropy     | 3.5806491   |
| training/sac_pi/pi_global_norm | 1.870322    |
| training/sac_pi/policy_loss    | -194.96266  |
| training/sac_pi/std            | 0.5200454   |
| training/sac_pi/valid_num      | 5012.0      |
| training/sac_Q/q1              | 184.11292   |
| training/sac_Q/q2              | 182.07797   |
| training/sac_Q/q2_loss         | 98.04988    |
| training/sac_Q/q_global_norm   | 290.4663    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16708481  |
| epoch                          | 297         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4942.8853   |
| evaluation/return-max          | 4988.8887   |
| evaluation/return-min          | 4888.4517   |
| evaluation/return-std          | 30.153435   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 82.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45621       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4942.8853   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 175.99619   |
| Q-std                          | 154.53911   |
| Q_loss                         | 102.69939   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 297         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000334    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000628    |
| times/evaluation_paths         | 30.5        |
| times/timestep_after_hook      | 0.00376     |
| times/timestep_before_hook     | 0.00792     |
| times/train                    | 56.5        |
| timestep                       | 1000        |
| timesteps_total                | 298000      |
| train-steps                    | 298000      |
| training/Q/q1_loss             | 107.695206  |
| training/sac_pi/alpha          | 0.167087    |
| training/sac_pi/alpha_loss     | -0.24645723 |
| training/sac_pi/logp_pi        | 3.7427323   |
| training/sac_pi/pi_entropy     | 3.6330254   |
| training/sac_pi/pi_global_norm | 1.5183166   |
| training/sac_pi/policy_loss    | -202.41905  |
| training/sac_pi/std            | 0.49695224  |
| training/sac_pi/valid_num      | 4972.0      |
| training/sac_Q/q1              | 195.31706   |
| training/sac_Q/q2              | 195.16223   |
| training/sac_Q/q2_loss         | 107.326706  |
| training/sac_Q/q_global_norm   | 278.65378   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16836265 |
| epoch                          | 298        |
| evaluation/episode-length-avg  | 393        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 125        |
| evaluation/episode-length-std  | 398        |
| evaluation/return-average      | 1605.2494  |
| evaluation/return-max          | 4741.7783  |
| evaluation/return-min          | 257.76538  |
| evaluation/return-std          | 2021.944   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 82.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45548      |
| perf/AverageLength             | 393        |
| perf/AverageReturn             | 1605.2494  |
| perf/NormalizedReturn          | 0.349      |
| Q-avg                          | 187.76033  |
| Q-std                          | 158.00975  |
| Q_loss                         | 76.599686  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 298        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000113   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000564   |
| times/evaluation_paths         | 12.2       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 56.2       |
| timestep                       | 1000       |
| timesteps_total                | 299000     |
| train-steps                    | 299000     |
| training/Q/q1_loss             | 99.57174   |
| training/sac_pi/alpha          | 0.16834134 |
| training/sac_pi/alpha_loss     | 0.09040468 |
| training/sac_pi/logp_pi        | 4.596751   |
| training/sac_pi/pi_entropy     | 3.5011601  |
| training/sac_pi/pi_global_norm | 2.3351805  |
| training/sac_pi/policy_loss    | -196.74023 |
| training/sac_pi/std            | 0.50769234 |
| training/sac_pi/valid_num      | 4918.0     |
| training/sac_Q/q1              | 183.87094  |
| training/sac_Q/q2              | 182.35127  |
| training/sac_Q/q2_loss         | 100.71654  |
| training/sac_Q/q_global_norm   | 260.19287  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.163343     |
| epoch                          | 299          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4616.984     |
| evaluation/return-max          | 4650.9414    |
| evaluation/return-min          | 4568.6504    |
| evaluation/return-std          | 25.535568    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.87         |
| model/origin_ret               | 84.6         |
| model/penalty_ret              | 82           |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45450        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4616.984     |
| perf/NormalizedReturn          | 1.01         |
| Q-avg                          | 177.67194    |
| Q-std                          | 165.69109    |
| Q_loss                         | 88.32209     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 299          |
| times/epoch_after_hook         | 1.69e-06     |
| times/epoch_before_hook        | 0.00011      |
| times/epoch_rollout_model      | 491          |
| times/evaluation_metrics       | 0.000627     |
| times/evaluation_paths         | 30.6         |
| times/timestep_after_hook      | 0.00375      |
| times/timestep_before_hook     | 0.00792      |
| times/train                    | 56.4         |
| timestep                       | 1000         |
| timesteps_total                | 300000       |
| train-steps                    | 300000       |
| training/Q/q1_loss             | 89.45155     |
| training/sac_pi/alpha          | 0.16333929   |
| training/sac_pi/alpha_loss     | -0.017601723 |
| training/sac_pi/logp_pi        | 4.897353     |
| training/sac_pi/pi_entropy     | 3.5841103    |
| training/sac_pi/pi_global_norm | 1.6402932    |
| training/sac_pi/policy_loss    | -205.89986   |
| training/sac_pi/std            | 0.5447239    |
| training/sac_pi/valid_num      | 4902.0       |
| training/sac_Q/q1              | 190.9721     |
| training/sac_Q/q2              | 189.03403    |
| training/sac_Q/q2_loss         | 88.95198     |
| training/sac_Q/q_global_norm   | 228.45047    |
----------------------------------------------------------------------------------
[WARN] 300 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16273087  |
| epoch                          | 300         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4790.507    |
| evaluation/return-max          | 4834.535    |
| evaluation/return-min          | 4731.921    |
| evaluation/return-std          | 29.634354   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.87        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45410       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4790.507    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 181.17606   |
| Q-std                          | 134.49748   |
| Q_loss                         | 107.835434  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 300         |
| times/epoch_after_hook         | 2.09e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000528    |
| times/evaluation_paths         | 30.6        |
| times/timestep_after_hook      | 0.0035      |
| times/timestep_before_hook     | 0.00778     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 301000      |
| train-steps                    | 301000      |
| training/Q/q1_loss             | 105.9827    |
| training/sac_pi/alpha          | 0.16271761  |
| training/sac_pi/alpha_loss     | 0.011687887 |
| training/sac_pi/logp_pi        | 4.6843843   |
| training/sac_pi/pi_entropy     | 3.4901543   |
| training/sac_pi/pi_global_norm | 1.6588082   |
| training/sac_pi/policy_loss    | -203.4427   |
| training/sac_pi/std            | 0.52317125  |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 189.38904   |
| training/sac_Q/q2              | 189.60576   |
| training/sac_Q/q2_loss         | 106.18922   |
| training/sac_Q/q_global_norm   | 373.8358    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16980746 |
| epoch                          | 301        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4822.572   |
| evaluation/return-max          | 5020.9307  |
| evaluation/return-min          | 4739.8555  |
| evaluation/return-std          | 76.06677   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.81       |
| model/origin_ret               | 82.8       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45502      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4822.572   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 174.14868  |
| Q-std                          | 170.2153   |
| Q_loss                         | 92.491684  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 301        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000282   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.00066    |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00793    |
| times/train                    | 56.1       |
| timestep                       | 1000       |
| timesteps_total                | 302000     |
| train-steps                    | 302000     |
| training/Q/q1_loss             | 99.19986   |
| training/sac_pi/alpha          | 0.16981529 |
| training/sac_pi/alpha_loss     | 0.20876929 |
| training/sac_pi/logp_pi        | 4.018724   |
| training/sac_pi/pi_entropy     | 3.516182   |
| training/sac_pi/pi_global_norm | 1.5975802  |
| training/sac_pi/policy_loss    | -202.05396 |
| training/sac_pi/std            | 0.48116082 |
| training/sac_pi/valid_num      | 4995.0     |
| training/sac_Q/q1              | 195.12456  |
| training/sac_Q/q2              | 194.08743  |
| training/sac_Q/q2_loss         | 98.9405    |
| training/sac_Q/q_global_norm   | 192.23021  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16488944 |
| epoch                          | 302        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4932.95    |
| evaluation/return-max          | 4967.995   |
| evaluation/return-min          | 4885.0957  |
| evaluation/return-std          | 27.505886  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45753      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4932.95    |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 183.90132  |
| Q-std                          | 128.99081  |
| Q_loss                         | 103.38078  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 302        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000526   |
| times/evaluation_paths         | 30.6       |
| times/timestep_after_hook      | 0.00349    |
| times/timestep_before_hook     | 0.00776    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 303000     |
| train-steps                    | 303000     |
| training/Q/q1_loss             | 96.01718   |
| training/sac_pi/alpha          | 0.1648858  |
| training/sac_pi/alpha_loss     | 0.13754062 |
| training/sac_pi/logp_pi        | 4.64124    |
| training/sac_pi/pi_entropy     | 3.486456   |
| training/sac_pi/pi_global_norm | 1.5576044  |
| training/sac_pi/policy_loss    | -199.74237 |
| training/sac_pi/std            | 0.5061644  |
| training/sac_pi/valid_num      | 4996.0     |
| training/sac_Q/q1              | 190.77177  |
| training/sac_Q/q2              | 189.36426  |
| training/sac_Q/q2_loss         | 95.83953   |
| training/sac_Q/q_global_norm   | 228.70984  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16749386  |
| epoch                          | 303         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4816.342    |
| evaluation/return-max          | 4874.0957   |
| evaluation/return-min          | 4711.8647   |
| evaluation/return-std          | 43.89375    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45803       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4816.342    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 176.28174   |
| Q-std                          | 162.85324   |
| Q_loss                         | 105.76165   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 303         |
| times/epoch_after_hook         | 2.23e-06    |
| times/epoch_before_hook        | 8e-05       |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000589    |
| times/evaluation_paths         | 30.4        |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.008       |
| times/train                    | 56.1        |
| timestep                       | 1000        |
| timesteps_total                | 304000      |
| train-steps                    | 304000      |
| training/Q/q1_loss             | 92.280556   |
| training/sac_pi/alpha          | 0.16749482  |
| training/sac_pi/alpha_loss     | -0.06633811 |
| training/sac_pi/logp_pi        | 4.9124346   |
| training/sac_pi/pi_entropy     | 3.6194642   |
| training/sac_pi/pi_global_norm | 1.3769444   |
| training/sac_pi/policy_loss    | -197.9516   |
| training/sac_pi/std            | 0.5391836   |
| training/sac_pi/valid_num      | 4939.0      |
| training/sac_Q/q1              | 183.56384   |
| training/sac_Q/q2              | 183.39641   |
| training/sac_Q/q2_loss         | 91.275      |
| training/sac_Q/q_global_norm   | 248.90207   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16472253 |
| epoch                          | 304        |
| evaluation/episode-length-avg  | 960        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 605        |
| evaluation/episode-length-std  | 118        |
| evaluation/return-average      | 4212.4053  |
| evaluation/return-max          | 4618.9897  |
| evaluation/return-min          | 2292.988   |
| evaluation/return-std          | 645.9386   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45668      |
| perf/AverageLength             | 960        |
| perf/AverageReturn             | 4212.4053  |
| perf/NormalizedReturn          | 0.917      |
| Q-avg                          | 184.41081  |
| Q-std                          | 148.7979   |
| Q_loss                         | 93.68442   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 304        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000561   |
| times/evaluation_paths         | 29.1       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00796    |
| times/train                    | 56.1       |
| timestep                       | 1000       |
| timesteps_total                | 305000     |
| train-steps                    | 305000     |
| training/Q/q1_loss             | 110.80771  |
| training/sac_pi/alpha          | 0.16470022 |
| training/sac_pi/alpha_loss     | 0.37140387 |
| training/sac_pi/logp_pi        | 4.059951   |
| training/sac_pi/pi_entropy     | 3.4755561  |
| training/sac_pi/pi_global_norm | 1.5810755  |
| training/sac_pi/policy_loss    | -196.86511 |
| training/sac_pi/std            | 0.48518804 |
| training/sac_pi/valid_num      | 5032.0     |
| training/sac_Q/q1              | 192.2568   |
| training/sac_Q/q2              | 190.79614  |
| training/sac_Q/q2_loss         | 111.92518  |
| training/sac_Q/q_global_norm   | 219.23686  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16454652   |
| epoch                          | 305          |
| evaluation/episode-length-avg  | 749          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 341          |
| evaluation/episode-length-std  | 309          |
| evaluation/return-average      | 3491.3843    |
| evaluation/return-max          | 4855.9463    |
| evaluation/return-min          | 1320.4705    |
| evaluation/return-std          | 1644.3619    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.89         |
| model/origin_ret               | 84.1         |
| model/penalty_ret              | 82.1         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45588        |
| perf/AverageLength             | 749          |
| perf/AverageReturn             | 3491.3843    |
| perf/NormalizedReturn          | 0.76         |
| Q-avg                          | 190.74478    |
| Q-std                          | 115.80564    |
| Q_loss                         | 119.01815    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 305          |
| times/epoch_after_hook         | 1.74e-06     |
| times/epoch_before_hook        | 0.000292     |
| times/epoch_rollout_model      | 488          |
| times/evaluation_metrics       | 0.000516     |
| times/evaluation_paths         | 23.2         |
| times/timestep_after_hook      | 0.00381      |
| times/timestep_before_hook     | 0.00794      |
| times/train                    | 56.6         |
| timestep                       | 1000         |
| timesteps_total                | 306000       |
| train-steps                    | 306000       |
| training/Q/q1_loss             | 102.367455   |
| training/sac_pi/alpha          | 0.16453615   |
| training/sac_pi/alpha_loss     | -0.023577282 |
| training/sac_pi/logp_pi        | 3.825231     |
| training/sac_pi/pi_entropy     | 3.4176395    |
| training/sac_pi/pi_global_norm | 1.6122396    |
| training/sac_pi/policy_loss    | -202.92583   |
| training/sac_pi/std            | 0.4828766    |
| training/sac_pi/valid_num      | 4971.0       |
| training/sac_Q/q1              | 193.70421    |
| training/sac_Q/q2              | 194.07124    |
| training/sac_Q/q2_loss         | 102.67056    |
| training/sac_Q/q_global_norm   | 303.70828    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16678672  |
| epoch                          | 306         |
| evaluation/episode-length-avg  | 925         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 253         |
| evaluation/episode-length-std  | 224         |
| evaluation/return-average      | 4166.21     |
| evaluation/return-max          | 4696.004    |
| evaluation/return-min          | 823.62823   |
| evaluation/return-std          | 1117.5096   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 82.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45676       |
| perf/AverageLength             | 925         |
| perf/AverageReturn             | 4166.21     |
| perf/NormalizedReturn          | 0.907       |
| Q-avg                          | 178.1136    |
| Q-std                          | 160.23555   |
| Q_loss                         | 83.15583    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 306         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000117    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000528    |
| times/evaluation_paths         | 28.3        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00792     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 307000      |
| train-steps                    | 307000      |
| training/Q/q1_loss             | 85.573746   |
| training/sac_pi/alpha          | 0.16681042  |
| training/sac_pi/alpha_loss     | -0.13846369 |
| training/sac_pi/logp_pi        | 4.1825156   |
| training/sac_pi/pi_entropy     | 3.478066    |
| training/sac_pi/pi_global_norm | 1.3799129   |
| training/sac_pi/policy_loss    | -194.54431  |
| training/sac_pi/std            | 0.49350244  |
| training/sac_pi/valid_num      | 4959.0      |
| training/sac_Q/q1              | 183.19727   |
| training/sac_Q/q2              | 182.9354    |
| training/sac_Q/q2_loss         | 85.66048    |
| training/sac_Q/q_global_norm   | 170.10295   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16632098 |
| epoch                          | 307        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4968.0825  |
| evaluation/return-max          | 5055.6274  |
| evaluation/return-min          | 4860.077   |
| evaluation/return-std          | 60.05912   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45634      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4968.0825  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 183.25717  |
| Q-std                          | 165.83601  |
| Q_loss                         | 92.85177   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 307        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.00067    |
| times/evaluation_paths         | 33.1       |
| times/timestep_after_hook      | 0.00406    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 59.7       |
| timestep                       | 1000       |
| timesteps_total                | 308000     |
| train-steps                    | 308000     |
| training/Q/q1_loss             | 90.037     |
| training/sac_pi/alpha          | 0.16632633 |
| training/sac_pi/alpha_loss     | 0.09663841 |
| training/sac_pi/logp_pi        | 4.572082   |
| training/sac_pi/pi_entropy     | 3.4593246  |
| training/sac_pi/pi_global_norm | 1.4833938  |
| training/sac_pi/policy_loss    | -205.48062 |
| training/sac_pi/std            | 0.5071585  |
| training/sac_pi/valid_num      | 4979.0     |
| training/sac_Q/q1              | 195.40207  |
| training/sac_Q/q2              | 192.59875  |
| training/sac_Q/q2_loss         | 89.87023   |
| training/sac_Q/q_global_norm   | 214.21672  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1660952  |
| epoch                          | 308        |
| evaluation/episode-length-avg  | 934        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 341        |
| evaluation/episode-length-std  | 198        |
| evaluation/return-average      | 4230.2603  |
| evaluation/return-max          | 4587.709   |
| evaluation/return-min          | 1293.7706  |
| evaluation/return-std          | 978.9264   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45687      |
| perf/AverageLength             | 934        |
| perf/AverageReturn             | 4230.2603  |
| perf/NormalizedReturn          | 0.921      |
| Q-avg                          | 190.23782  |
| Q-std                          | 125.74368  |
| Q_loss                         | 81.417206  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 308        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.00054    |
| times/evaluation_paths         | 31.2       |
| times/timestep_after_hook      | 0.00412    |
| times/timestep_before_hook     | 0.00852    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 309000     |
| train-steps                    | 309000     |
| training/Q/q1_loss             | 129.86494  |
| training/sac_pi/alpha          | 0.16604666 |
| training/sac_pi/alpha_loss     | 0.4975205  |
| training/sac_pi/logp_pi        | 5.2194576  |
| training/sac_pi/pi_entropy     | 3.3606071  |
| training/sac_pi/pi_global_norm | 1.389846   |
| training/sac_pi/policy_loss    | -193.55093 |
| training/sac_pi/std            | 0.5003774  |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 180.63733  |
| training/sac_Q/q2              | 179.92064  |
| training/sac_Q/q2_loss         | 131.07524  |
| training/sac_Q/q_global_norm   | 217.87506  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16245455 |
| epoch                          | 309        |
| evaluation/episode-length-avg  | 159        |
| evaluation/episode-length-max  | 168        |
| evaluation/episode-length-min  | 148        |
| evaluation/episode-length-std  | 6.36       |
| evaluation/return-average      | 470.19208  |
| evaluation/return-max          | 497.42236  |
| evaluation/return-min          | 429.74658  |
| evaluation/return-std          | 21.154581  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45593      |
| perf/AverageLength             | 159        |
| perf/AverageReturn             | 470.19208  |
| perf/NormalizedReturn          | 0.102      |
| Q-avg                          | 179.6464   |
| Q-std                          | 143.54027  |
| Q_loss                         | 103.24299  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 309        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000304   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000438   |
| times/evaluation_paths         | 5.18       |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 310000     |
| train-steps                    | 310000     |
| training/Q/q1_loss             | 98.00363   |
| training/sac_pi/alpha          | 0.16245477 |
| training/sac_pi/alpha_loss     | 0.13144238 |
| training/sac_pi/logp_pi        | 4.8163085  |
| training/sac_pi/pi_entropy     | 3.636825   |
| training/sac_pi/pi_global_norm | 1.2807696  |
| training/sac_pi/policy_loss    | -191.65315 |
| training/sac_pi/std            | 0.53240407 |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 177.95944  |
| training/sac_Q/q2              | 175.64236  |
| training/sac_Q/q2_loss         | 97.31259   |
| training/sac_Q/q_global_norm   | 244.69073  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16402511 |
| epoch                          | 310        |
| evaluation/episode-length-avg  | 659        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 145        |
| evaluation/episode-length-std  | 417        |
| evaluation/return-average      | 2914.9753  |
| evaluation/return-max          | 4620.083   |
| evaluation/return-min          | 391.7907   |
| evaluation/return-std          | 2048.2993  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45683      |
| perf/AverageLength             | 659        |
| perf/AverageReturn             | 2914.9753  |
| perf/NormalizedReturn          | 0.635      |
| Q-avg                          | 188.50674  |
| Q-std                          | 143.29893  |
| Q_loss                         | 89.181335  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 310        |
| times/epoch_after_hook         | 3.84e-06   |
| times/epoch_before_hook        | 0.000224   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000562   |
| times/evaluation_paths         | 22.4       |
| times/timestep_after_hook      | 0.00408    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 311000     |
| train-steps                    | 311000     |
| training/Q/q1_loss             | 101.97638  |
| training/sac_pi/alpha          | 0.16396978 |
| training/sac_pi/alpha_loss     | 0.74320495 |
| training/sac_pi/logp_pi        | 5.692299   |
| training/sac_pi/pi_entropy     | 3.6668916  |
| training/sac_pi/pi_global_norm | 1.751179   |
| training/sac_pi/policy_loss    | -195.07472 |
| training/sac_pi/std            | 0.56919366 |
| training/sac_pi/valid_num      | 4894.0     |
| training/sac_Q/q1              | 176.22998  |
| training/sac_Q/q2              | 172.02475  |
| training/sac_Q/q2_loss         | 101.0205   |
| training/sac_Q/q_global_norm   | 255.26904  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16230622  |
| epoch                          | 311         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4959.714    |
| evaluation/return-max          | 5112.433    |
| evaluation/return-min          | 4806.7246   |
| evaluation/return-std          | 97.27971    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 82.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45513       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4959.714    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 195.8731    |
| Q-std                          | 98.668724   |
| Q_loss                         | 93.23723    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 311         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000113    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000539    |
| times/evaluation_paths         | 33.1        |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 59.7        |
| timestep                       | 1000        |
| timesteps_total                | 312000      |
| train-steps                    | 312000      |
| training/Q/q1_loss             | 81.73912    |
| training/sac_pi/alpha          | 0.16231582  |
| training/sac_pi/alpha_loss     | -0.16154173 |
| training/sac_pi/logp_pi        | 4.739773    |
| training/sac_pi/pi_entropy     | 3.4166806   |
| training/sac_pi/pi_global_norm | 1.8633785   |
| training/sac_pi/policy_loss    | -206.43082  |
| training/sac_pi/std            | 0.52221876  |
| training/sac_pi/valid_num      | 4913.0      |
| training/sac_Q/q1              | 186.21468   |
| training/sac_Q/q2              | 185.57234   |
| training/sac_Q/q2_loss         | 81.55596    |
| training/sac_Q/q_global_norm   | 209.74368   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16631767 |
| epoch                          | 312        |
| evaluation/episode-length-avg  | 895        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 474        |
| evaluation/episode-length-std  | 210        |
| evaluation/return-average      | 4522.9404  |
| evaluation/return-max          | 5227.8896  |
| evaluation/return-min          | 2096.7795  |
| evaluation/return-std          | 1192.7513  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45703      |
| perf/AverageLength             | 895        |
| perf/AverageReturn             | 4522.9404  |
| perf/NormalizedReturn          | 0.985      |
| Q-avg                          | 178.67094  |
| Q-std                          | 149.23962  |
| Q_loss                         | 102.58722  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 312        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000528   |
| times/evaluation_paths         | 29.5       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00861    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 313000     |
| train-steps                    | 313000     |
| training/Q/q1_loss             | 94.9327    |
| training/sac_pi/alpha          | 0.16632698 |
| training/sac_pi/alpha_loss     | 0.07678706 |
| training/sac_pi/logp_pi        | 4.8046675  |
| training/sac_pi/pi_entropy     | 3.611383   |
| training/sac_pi/pi_global_norm | 1.6245427  |
| training/sac_pi/policy_loss    | -198.77011 |
| training/sac_pi/std            | 0.5343706  |
| training/sac_pi/valid_num      | 4936.0     |
| training/sac_Q/q1              | 184.02206  |
| training/sac_Q/q2              | 183.18988  |
| training/sac_Q/q2_loss         | 95.78442   |
| training/sac_Q/q_global_norm   | 216.38928  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16751635   |
| epoch                          | 313          |
| evaluation/episode-length-avg  | 833          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 164          |
| evaluation/episode-length-std  | 334          |
| evaluation/return-average      | 3824.4192    |
| evaluation/return-max          | 4696.8726    |
| evaluation/return-min          | 444.9709     |
| evaluation/return-std          | 1689.2291    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.94         |
| model/origin_ret               | 84.7         |
| model/penalty_ret              | 81.7         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45646        |
| perf/AverageLength             | 833          |
| perf/AverageReturn             | 3824.4192    |
| perf/NormalizedReturn          | 0.833        |
| Q-avg                          | 183.80476    |
| Q-std                          | 143.8569     |
| Q_loss                         | 108.27635    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 313          |
| times/epoch_after_hook         | 1.88e-06     |
| times/epoch_before_hook        | 0.000333     |
| times/epoch_rollout_model      | 485          |
| times/evaluation_metrics       | 0.000548     |
| times/evaluation_paths         | 27           |
| times/timestep_after_hook      | 0.00383      |
| times/timestep_before_hook     | 0.00854      |
| times/train                    | 58.6         |
| timestep                       | 1000         |
| timesteps_total                | 314000       |
| train-steps                    | 314000       |
| training/Q/q1_loss             | 105.36171    |
| training/sac_pi/alpha          | 0.16749157   |
| training/sac_pi/alpha_loss     | -0.030437943 |
| training/sac_pi/logp_pi        | 4.488268     |
| training/sac_pi/pi_entropy     | 3.521991     |
| training/sac_pi/pi_global_norm | 1.8064799    |
| training/sac_pi/policy_loss    | -198.71333   |
| training/sac_pi/std            | 0.51040524   |
| training/sac_pi/valid_num      | 4958.0       |
| training/sac_Q/q1              | 185.60881    |
| training/sac_Q/q2              | 184.52013    |
| training/sac_Q/q2_loss         | 106.183945   |
| training/sac_Q/q_global_norm   | 238.59576    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16687408  |
| epoch                          | 314         |
| evaluation/episode-length-avg  | 825         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 111         |
| evaluation/episode-length-std  | 351         |
| evaluation/return-average      | 3841.5474   |
| evaluation/return-max          | 4760.5156   |
| evaluation/return-min          | 255.34055   |
| evaluation/return-std          | 1770.2362   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45582       |
| perf/AverageLength             | 825         |
| perf/AverageReturn             | 3841.5474   |
| perf/NormalizedReturn          | 0.836       |
| Q-avg                          | 196.99927   |
| Q-std                          | 98.27913    |
| Q_loss                         | 86.42138    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 314         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000599    |
| times/evaluation_paths         | 27.5        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00801     |
| times/train                    | 59.1        |
| timestep                       | 1000        |
| timesteps_total                | 315000      |
| train-steps                    | 315000      |
| training/Q/q1_loss             | 118.22887   |
| training/sac_pi/alpha          | 0.16688694  |
| training/sac_pi/alpha_loss     | -0.07093381 |
| training/sac_pi/logp_pi        | 4.279654    |
| training/sac_pi/pi_entropy     | 3.5066707   |
| training/sac_pi/pi_global_norm | 1.4640471   |
| training/sac_pi/policy_loss    | -196.19228  |
| training/sac_pi/std            | 0.49949327  |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 187.63718   |
| training/sac_Q/q2              | 185.16008   |
| training/sac_Q/q2_loss         | 118.608215  |
| training/sac_Q/q_global_norm   | 277.62384   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16947585 |
| epoch                          | 315        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4760.7734  |
| evaluation/return-max          | 4822.532   |
| evaluation/return-min          | 4697.907   |
| evaluation/return-std          | 37.809055  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45614      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4760.7734  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 181.0125   |
| Q-std                          | 122.13809  |
| Q_loss                         | 108.96533  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 315        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000549   |
| times/evaluation_paths         | 32.7       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 59         |
| timestep                       | 1000       |
| timesteps_total                | 316000     |
| train-steps                    | 316000     |
| training/Q/q1_loss             | 88.07755   |
| training/sac_pi/alpha          | 0.16942778 |
| training/sac_pi/alpha_loss     | 0.20144796 |
| training/sac_pi/logp_pi        | 5.1867743  |
| training/sac_pi/pi_entropy     | 3.6107037  |
| training/sac_pi/pi_global_norm | 1.6528597  |
| training/sac_pi/policy_loss    | -198.98051 |
| training/sac_pi/std            | 0.5432919  |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 188.48724  |
| training/sac_Q/q2              | 184.5148   |
| training/sac_Q/q2_loss         | 87.152565  |
| training/sac_Q/q_global_norm   | 187.02705  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16376354  |
| epoch                          | 316         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4569.6377   |
| evaluation/return-max          | 4580.3604   |
| evaluation/return-min          | 4542.0127   |
| evaluation/return-std          | 11.373436   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45667       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4569.6377   |
| perf/NormalizedReturn          | 0.995       |
| Q-avg                          | 177.33574   |
| Q-std                          | 139.70045   |
| Q_loss                         | 98.02002    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 316         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000108    |
| times/epoch_rollout_model      | 509         |
| times/evaluation_metrics       | 0.000592    |
| times/evaluation_paths         | 32.7        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.0084      |
| times/train                    | 59.3        |
| timestep                       | 1000        |
| timesteps_total                | 317000      |
| train-steps                    | 317000      |
| training/Q/q1_loss             | 93.22552    |
| training/sac_pi/alpha          | 0.1637916   |
| training/sac_pi/alpha_loss     | -0.40287948 |
| training/sac_pi/logp_pi        | 4.3229475   |
| training/sac_pi/pi_entropy     | 3.5892766   |
| training/sac_pi/pi_global_norm | 1.2453365   |
| training/sac_pi/policy_loss    | -191.6147   |
| training/sac_pi/std            | 0.5240249   |
| training/sac_pi/valid_num      | 4939.0      |
| training/sac_Q/q1              | 179.68913   |
| training/sac_Q/q2              | 177.23055   |
| training/sac_Q/q2_loss         | 92.75288    |
| training/sac_Q/q_global_norm   | 278.10788   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16329421 |
| epoch                          | 317        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5011.5264  |
| evaluation/return-max          | 5034.3223  |
| evaluation/return-min          | 4990.7515  |
| evaluation/return-std          | 15.103219  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 82.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45576      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5011.5264  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 175.06467  |
| Q-std                          | 153.57018  |
| Q_loss                         | 121.22309  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 317        |
| times/epoch_after_hook         | 1.97e-06   |
| times/epoch_before_hook        | 0.000328   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000706   |
| times/evaluation_paths         | 33.8       |
| times/timestep_after_hook      | 0.00408    |
| times/timestep_before_hook     | 0.00872    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 318000     |
| train-steps                    | 318000     |
| training/Q/q1_loss             | 101.40765  |
| training/sac_pi/alpha          | 0.16329342 |
| training/sac_pi/alpha_loss     | -0.0792969 |
| training/sac_pi/logp_pi        | 4.2821093  |
| training/sac_pi/pi_entropy     | 3.6715744  |
| training/sac_pi/pi_global_norm | 1.5136005  |
| training/sac_pi/policy_loss    | -194.84666 |
| training/sac_pi/std            | 0.51353085 |
| training/sac_pi/valid_num      | 4913.0     |
| training/sac_Q/q1              | 182.34467  |
| training/sac_Q/q2              | 180.53386  |
| training/sac_Q/q2_loss         | 101.96348  |
| training/sac_Q/q_global_norm   | 322.18518  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15943703   |
| epoch                          | 318          |
| evaluation/episode-length-avg  | 403          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 144          |
| evaluation/episode-length-std  | 391          |
| evaluation/return-average      | 1667.2158    |
| evaluation/return-max          | 4802.5723    |
| evaluation/return-min          | 321.73676    |
| evaluation/return-std          | 2043.0343    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.9          |
| model/origin_ret               | 84.8         |
| model/penalty_ret              | 82.7         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45695        |
| perf/AverageLength             | 403          |
| perf/AverageReturn             | 1667.2158    |
| perf/NormalizedReturn          | 0.363        |
| Q-avg                          | 186.8615     |
| Q-std                          | 149.05959    |
| Q_loss                         | 99.02466     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 318          |
| times/epoch_after_hook         | 1.75e-06     |
| times/epoch_before_hook        | 0.000136     |
| times/epoch_rollout_model      | 489          |
| times/evaluation_metrics       | 0.000538     |
| times/evaluation_paths         | 13.6         |
| times/timestep_after_hook      | 0.00413      |
| times/timestep_before_hook     | 0.00838      |
| times/train                    | 60.3         |
| timestep                       | 1000         |
| timesteps_total                | 319000       |
| train-steps                    | 319000       |
| training/Q/q1_loss             | 95.420555    |
| training/sac_pi/alpha          | 0.15941817   |
| training/sac_pi/alpha_loss     | -0.089356124 |
| training/sac_pi/logp_pi        | 4.4855576    |
| training/sac_pi/pi_entropy     | 3.4785552    |
| training/sac_pi/pi_global_norm | 1.4374758    |
| training/sac_pi/policy_loss    | -202.5268    |
| training/sac_pi/std            | 0.5058437    |
| training/sac_pi/valid_num      | 4950.0       |
| training/sac_Q/q1              | 190.35417    |
| training/sac_Q/q2              | 186.66118    |
| training/sac_Q/q2_loss         | 94.688576    |
| training/sac_Q/q_global_norm   | 245.46877    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16104828 |
| epoch                          | 319        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4527.587   |
| evaluation/return-max          | 4568.9146  |
| evaluation/return-min          | 4450.6997  |
| evaluation/return-std          | 38.054024  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45664      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4527.587   |
| perf/NormalizedReturn          | 0.986      |
| Q-avg                          | 183.40347  |
| Q-std                          | 153.1547   |
| Q_loss                         | 92.31772   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 319        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000577   |
| times/evaluation_paths         | 32.3       |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 58.1       |
| timestep                       | 1000       |
| timesteps_total                | 320000     |
| train-steps                    | 320000     |
| training/Q/q1_loss             | 114.52442  |
| training/sac_pi/alpha          | 0.16100565 |
| training/sac_pi/alpha_loss     | 0.41659334 |
| training/sac_pi/logp_pi        | 5.290118   |
| training/sac_pi/pi_entropy     | 3.5889995  |
| training/sac_pi/pi_global_norm | 1.4437599  |
| training/sac_pi/policy_loss    | -197.24823 |
| training/sac_pi/std            | 0.53708994 |
| training/sac_pi/valid_num      | 4881.0     |
| training/sac_Q/q1              | 181.581    |
| training/sac_Q/q2              | 180.25717  |
| training/sac_Q/q2_loss         | 115.79147  |
| training/sac_Q/q_global_norm   | 276.7452   |
--------------------------------------------------------------------------------
[WARN] 320 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.1641656    |
| epoch                          | 320          |
| evaluation/episode-length-avg  | 302          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 123          |
| evaluation/episode-length-std  | 349          |
| evaluation/return-average      | 1217.2872    |
| evaluation/return-max          | 4823.7236    |
| evaluation/return-min          | 304.16336    |
| evaluation/return-std          | 1802.3622    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.94         |
| model/origin_ret               | 84.5         |
| model/penalty_ret              | 82.2         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45707        |
| perf/AverageLength             | 302          |
| perf/AverageReturn             | 1217.2872    |
| perf/NormalizedReturn          | 0.265        |
| Q-avg                          | 187.39598    |
| Q-std                          | 142.64874    |
| Q_loss                         | 96.672325    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 320          |
| times/epoch_after_hook         | 1.78e-06     |
| times/epoch_before_hook        | 0.000151     |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.000477     |
| times/evaluation_paths         | 10.3         |
| times/timestep_after_hook      | 0.00388      |
| times/timestep_before_hook     | 0.00825      |
| times/train                    | 59.7         |
| timestep                       | 1000         |
| timesteps_total                | 321000       |
| train-steps                    | 321000       |
| training/Q/q1_loss             | 99.348015    |
| training/sac_pi/alpha          | 0.16413762   |
| training/sac_pi/alpha_loss     | -0.025657475 |
| training/sac_pi/logp_pi        | 4.3912177    |
| training/sac_pi/pi_entropy     | 3.5722573    |
| training/sac_pi/pi_global_norm | 1.8340191    |
| training/sac_pi/policy_loss    | -194.72469   |
| training/sac_pi/std            | 0.5073376    |
| training/sac_pi/valid_num      | 4950.0       |
| training/sac_Q/q1              | 183.13396    |
| training/sac_Q/q2              | 181.22676    |
| training/sac_Q/q2_loss         | 99.72094     |
| training/sac_Q/q_global_norm   | 249.14159    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16496773 |
| epoch                          | 321        |
| evaluation/episode-length-avg  | 127        |
| evaluation/episode-length-max  | 132        |
| evaluation/episode-length-min  | 123        |
| evaluation/episode-length-std  | 2.49       |
| evaluation/return-average      | 295.27246  |
| evaluation/return-max          | 316.22046  |
| evaluation/return-min          | 275.85568  |
| evaluation/return-std          | 10.521591  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45687      |
| perf/AverageLength             | 127        |
| perf/AverageReturn             | 295.27246  |
| perf/NormalizedReturn          | 0.064      |
| Q-avg                          | 169.74629  |
| Q-std                          | 170.3513   |
| Q_loss                         | 106.67924  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 321        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000312   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000671   |
| times/evaluation_paths         | 4.18       |
| times/timestep_after_hook      | 0.00403    |
| times/timestep_before_hook     | 0.0086     |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 322000     |
| train-steps                    | 322000     |
| training/Q/q1_loss             | 103.77263  |
| training/sac_pi/alpha          | 0.16497765 |
| training/sac_pi/alpha_loss     | 0.14330584 |
| training/sac_pi/logp_pi        | 4.485894   |
| training/sac_pi/pi_entropy     | 3.6613297  |
| training/sac_pi/pi_global_norm | 1.8553541  |
| training/sac_pi/policy_loss    | -188.45004 |
| training/sac_pi/std            | 0.5207046  |
| training/sac_pi/valid_num      | 4987.0     |
| training/sac_Q/q1              | 177.79536  |
| training/sac_Q/q2              | 174.83655  |
| training/sac_Q/q2_loss         | 103.851166 |
| training/sac_Q/q_global_norm   | 189.19257  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17350957 |
| epoch                          | 322        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4827.6523  |
| evaluation/return-max          | 4912.58    |
| evaluation/return-min          | 4784.286   |
| evaluation/return-std          | 35.278824  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.85       |
| model/origin_ret               | 82.6       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45759      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4827.6523  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 190.04427  |
| Q-std                          | 132.09477  |
| Q_loss                         | 90.86306   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 322        |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.000107   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000602   |
| times/evaluation_paths         | 33.2       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00853    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 323000     |
| train-steps                    | 323000     |
| training/Q/q1_loss             | 108.561386 |
| training/sac_pi/alpha          | 0.17346278 |
| training/sac_pi/alpha_loss     | 0.3292913  |
| training/sac_pi/logp_pi        | 4.4491725  |
| training/sac_pi/pi_entropy     | 3.570911   |
| training/sac_pi/pi_global_norm | 1.6297343  |
| training/sac_pi/policy_loss    | -200.48944 |
| training/sac_pi/std            | 0.509901   |
| training/sac_pi/valid_num      | 4984.0     |
| training/sac_Q/q1              | 190.90845  |
| training/sac_Q/q2              | 189.5207   |
| training/sac_Q/q2_loss         | 108.74729  |
| training/sac_Q/q_global_norm   | 221.75038  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16511466  |
| epoch                          | 323         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4817.367    |
| evaluation/return-max          | 4870.643    |
| evaluation/return-min          | 4549.5127   |
| evaluation/return-std          | 90.55916    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.87        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45396       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4817.367    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 181.00894   |
| Q-std                          | 137.15123   |
| Q_loss                         | 99.544266   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 323         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000538    |
| times/evaluation_paths         | 32.3        |
| times/timestep_after_hook      | 0.00417     |
| times/timestep_before_hook     | 0.00915     |
| times/train                    | 59.5        |
| timestep                       | 1000        |
| timesteps_total                | 324000      |
| train-steps                    | 324000      |
| training/Q/q1_loss             | 95.09099    |
| training/sac_pi/alpha          | 0.16514836  |
| training/sac_pi/alpha_loss     | -0.26988444 |
| training/sac_pi/logp_pi        | 4.107576    |
| training/sac_pi/pi_entropy     | 3.4229913   |
| training/sac_pi/pi_global_norm | 1.5151585   |
| training/sac_pi/policy_loss    | -190.17374  |
| training/sac_pi/std            | 0.48464653  |
| training/sac_pi/valid_num      | 4982.0      |
| training/sac_Q/q1              | 182.02016   |
| training/sac_Q/q2              | 179.04045   |
| training/sac_Q/q2_loss         | 94.80994    |
| training/sac_Q/q_global_norm   | 219.10417   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16515954  |
| epoch                          | 324         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4878.858    |
| evaluation/return-max          | 4924.0327   |
| evaluation/return-min          | 4817.3203   |
| evaluation/return-std          | 30.223309   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.86        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45559       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4878.858    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 179.08157   |
| Q-std                          | 152.6111    |
| Q_loss                         | 106.67164   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 324         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000609    |
| times/evaluation_paths         | 34          |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00839     |
| times/train                    | 59.5        |
| timestep                       | 1000        |
| timesteps_total                | 325000      |
| train-steps                    | 325000      |
| training/Q/q1_loss             | 83.864624   |
| training/sac_pi/alpha          | 0.16519791  |
| training/sac_pi/alpha_loss     | -0.23725742 |
| training/sac_pi/logp_pi        | 4.188821    |
| training/sac_pi/pi_entropy     | 3.5017135   |
| training/sac_pi/pi_global_norm | 1.6127796   |
| training/sac_pi/policy_loss    | -205.95267  |
| training/sac_pi/std            | 0.50211984  |
| training/sac_pi/valid_num      | 4972.0      |
| training/sac_Q/q1              | 196.51018   |
| training/sac_Q/q2              | 194.30472   |
| training/sac_Q/q2_loss         | 83.044075   |
| training/sac_Q/q_global_norm   | 221.74255   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16660209  |
| epoch                          | 325         |
| evaluation/episode-length-avg  | 917         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 173         |
| evaluation/episode-length-std  | 248         |
| evaluation/return-average      | 4495.148    |
| evaluation/return-max          | 4953.62     |
| evaluation/return-min          | 520.2677    |
| evaluation/return-std          | 1324.9912   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.87        |
| model/origin_ret               | 83.5        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45653       |
| perf/AverageLength             | 917         |
| perf/AverageReturn             | 4495.148    |
| perf/NormalizedReturn          | 0.979       |
| Q-avg                          | 183.71056   |
| Q-std                          | 132.17996   |
| Q_loss                         | 91.161766   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 325         |
| times/epoch_after_hook         | 3.52e-06    |
| times/epoch_before_hook        | 0.00028     |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000683    |
| times/evaluation_paths         | 29.6        |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 57.4        |
| timestep                       | 1000        |
| timesteps_total                | 326000      |
| train-steps                    | 326000      |
| training/Q/q1_loss             | 124.639656  |
| training/sac_pi/alpha          | 0.16658114  |
| training/sac_pi/alpha_loss     | -0.03466908 |
| training/sac_pi/logp_pi        | 4.698027    |
| training/sac_pi/pi_entropy     | 3.606123    |
| training/sac_pi/pi_global_norm | 1.636289    |
| training/sac_pi/policy_loss    | -194.30157  |
| training/sac_pi/std            | 0.52096975  |
| training/sac_pi/valid_num      | 4920.0      |
| training/sac_Q/q1              | 178.65149   |
| training/sac_Q/q2              | 175.20663   |
| training/sac_Q/q2_loss         | 124.48262   |
| training/sac_Q/q_global_norm   | 272.82547   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16855104  |
| epoch                          | 326         |
| evaluation/episode-length-avg  | 148         |
| evaluation/episode-length-max  | 149         |
| evaluation/episode-length-min  | 146         |
| evaluation/episode-length-std  | 0.98        |
| evaluation/return-average      | 441.61786   |
| evaluation/return-max          | 452.43494   |
| evaluation/return-min          | 428.42078   |
| evaluation/return-std          | 8.255064    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 82.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45544       |
| perf/AverageLength             | 148         |
| perf/AverageReturn             | 441.61786   |
| perf/NormalizedReturn          | 0.0958      |
| Q-avg                          | 185.67075   |
| Q-std                          | 158.14091   |
| Q_loss                         | 88.6294     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 326         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.000165    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000753    |
| times/evaluation_paths         | 5.06        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 59.5        |
| timestep                       | 1000        |
| timesteps_total                | 327000      |
| train-steps                    | 327000      |
| training/Q/q1_loss             | 109.774414  |
| training/sac_pi/alpha          | 0.16854994  |
| training/sac_pi/alpha_loss     | 0.032169405 |
| training/sac_pi/logp_pi        | 5.148954    |
| training/sac_pi/pi_entropy     | 3.7086632   |
| training/sac_pi/pi_global_norm | 1.3799628   |
| training/sac_pi/policy_loss    | -193.24098  |
| training/sac_pi/std            | 0.57015365  |
| training/sac_pi/valid_num      | 4949.0      |
| training/sac_Q/q1              | 176.72162   |
| training/sac_Q/q2              | 174.01517   |
| training/sac_Q/q2_loss         | 109.07618   |
| training/sac_Q/q_global_norm   | 224.19066   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16071597 |
| epoch                          | 327        |
| evaluation/episode-length-avg  | 156        |
| evaluation/episode-length-max  | 165        |
| evaluation/episode-length-min  | 147        |
| evaluation/episode-length-std  | 6.93       |
| evaluation/return-average      | 491.42432  |
| evaluation/return-max          | 531.33093  |
| evaluation/return-min          | 448.16187  |
| evaluation/return-std          | 28.847374  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45666      |
| perf/AverageLength             | 156        |
| perf/AverageReturn             | 491.42432  |
| perf/NormalizedReturn          | 0.107      |
| Q-avg                          | 180.58292  |
| Q-std                          | 114.2339   |
| Q_loss                         | 104.907684 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 327        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000553   |
| times/evaluation_paths         | 5.06       |
| times/timestep_after_hook      | 0.00419    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 328000     |
| train-steps                    | 328000     |
| training/Q/q1_loss             | 94.08757   |
| training/sac_pi/alpha          | 0.16069388 |
| training/sac_pi/alpha_loss     | 0.2746398  |
| training/sac_pi/logp_pi        | 4.6378164  |
| training/sac_pi/pi_entropy     | 3.4458184  |
| training/sac_pi/pi_global_norm | 3.2183294  |
| training/sac_pi/policy_loss    | -199.22061 |
| training/sac_pi/std            | 0.5074459  |
| training/sac_pi/valid_num      | 4958.0     |
| training/sac_Q/q1              | 186.56168  |
| training/sac_Q/q2              | 184.05069  |
| training/sac_Q/q2_loss         | 95.12917   |
| training/sac_Q/q_global_norm   | 302.63992  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1620845   |
| epoch                          | 328         |
| evaluation/episode-length-avg  | 147         |
| evaluation/episode-length-max  | 149         |
| evaluation/episode-length-min  | 146         |
| evaluation/episode-length-std  | 0.781       |
| evaluation/return-average      | 316.95233   |
| evaluation/return-max          | 321.9737    |
| evaluation/return-min          | 310.85962   |
| evaluation/return-std          | 3.9743092   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45713       |
| perf/AverageLength             | 147         |
| perf/AverageReturn             | 316.95233   |
| perf/NormalizedReturn          | 0.0687      |
| Q-avg                          | 187.56113   |
| Q-std                          | 136.12386   |
| Q_loss                         | 94.26405    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 328         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000113    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000445    |
| times/evaluation_paths         | 4.9         |
| times/timestep_after_hook      | 0.004       |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 59.4        |
| timestep                       | 1000        |
| timesteps_total                | 329000      |
| train-steps                    | 329000      |
| training/Q/q1_loss             | 120.800896  |
| training/sac_pi/alpha          | 0.1620565   |
| training/sac_pi/alpha_loss     | 0.036727574 |
| training/sac_pi/logp_pi        | 4.566935    |
| training/sac_pi/pi_entropy     | 3.4319973   |
| training/sac_pi/pi_global_norm | 1.7487646   |
| training/sac_pi/policy_loss    | -200.36281  |
| training/sac_pi/std            | 0.50166565  |
| training/sac_pi/valid_num      | 4939.0      |
| training/sac_Q/q1              | 187.40584   |
| training/sac_Q/q2              | 187.1766    |
| training/sac_Q/q2_loss         | 120.43912   |
| training/sac_Q/q_global_norm   | 223.70671   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16203281 |
| epoch                          | 329        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4383.608   |
| evaluation/return-max          | 4421.9297  |
| evaluation/return-min          | 4363.6133  |
| evaluation/return-std          | 19.316267  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45612      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4383.608   |
| perf/NormalizedReturn          | 0.955      |
| Q-avg                          | 191.4303   |
| Q-std                          | 118.37389  |
| Q_loss                         | 75.39244   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 329        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000299   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000619   |
| times/evaluation_paths         | 33.5       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 59         |
| timestep                       | 1000       |
| timesteps_total                | 330000     |
| train-steps                    | 330000     |
| training/Q/q1_loss             | 100.43796  |
| training/sac_pi/alpha          | 0.16203445 |
| training/sac_pi/alpha_loss     | 0.11453629 |
| training/sac_pi/logp_pi        | 4.408006   |
| training/sac_pi/pi_entropy     | 3.4091153  |
| training/sac_pi/pi_global_norm | 1.5503736  |
| training/sac_pi/policy_loss    | -203.543   |
| training/sac_pi/std            | 0.50807023 |
| training/sac_pi/valid_num      | 4991.0     |
| training/sac_Q/q1              | 193.07053  |
| training/sac_Q/q2              | 191.25146  |
| training/sac_Q/q2_loss         | 99.71312   |
| training/sac_Q/q_global_norm   | 231.57268  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16747819  |
| epoch                          | 330         |
| evaluation/episode-length-avg  | 916         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 155         |
| evaluation/episode-length-std  | 254         |
| evaluation/return-average      | 4418.5356   |
| evaluation/return-max          | 4906.582    |
| evaluation/return-min          | 422.8301    |
| evaluation/return-std          | 1332.4078   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.87        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45575       |
| perf/AverageLength             | 916         |
| perf/AverageReturn             | 4418.5356   |
| perf/NormalizedReturn          | 0.962       |
| Q-avg                          | 181.72989   |
| Q-std                          | 160.63521   |
| Q_loss                         | 89.404724   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 330         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000595    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.00822     |
| times/train                    | 59.2        |
| timestep                       | 1000        |
| timesteps_total                | 331000      |
| train-steps                    | 331000      |
| training/Q/q1_loss             | 114.69415   |
| training/sac_pi/alpha          | 0.16748133  |
| training/sac_pi/alpha_loss     | -0.32410923 |
| training/sac_pi/logp_pi        | 4.304183    |
| training/sac_pi/pi_entropy     | 3.5531273   |
| training/sac_pi/pi_global_norm | 1.7334636   |
| training/sac_pi/policy_loss    | -193.67581  |
| training/sac_pi/std            | 0.5092048   |
| training/sac_pi/valid_num      | 4944.0      |
| training/sac_Q/q1              | 182.6907    |
| training/sac_Q/q2              | 180.96823   |
| training/sac_Q/q2_loss         | 116.09589   |
| training/sac_Q/q_global_norm   | 247.62955   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.165547   |
| epoch                          | 331        |
| evaluation/episode-length-avg  | 739        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 129        |
| evaluation/episode-length-std  | 398        |
| evaluation/return-average      | 3381.5474  |
| evaluation/return-max          | 4763.226   |
| evaluation/return-min          | 302.1775   |
| evaluation/return-std          | 2015.9105  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45787      |
| perf/AverageLength             | 739        |
| perf/AverageReturn             | 3381.5474  |
| perf/NormalizedReturn          | 0.736      |
| Q-avg                          | 177.02078  |
| Q-std                          | 149.21353  |
| Q_loss                         | 98.842514  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 331        |
| times/epoch_after_hook         | 2.09e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000548   |
| times/evaluation_paths         | 22.9       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 56.3       |
| timestep                       | 1000       |
| timesteps_total                | 332000     |
| train-steps                    | 332000     |
| training/Q/q1_loss             | 81.39172   |
| training/sac_pi/alpha          | 0.1654998  |
| training/sac_pi/alpha_loss     | 0.424213   |
| training/sac_pi/logp_pi        | 5.305583   |
| training/sac_pi/pi_entropy     | 3.586069   |
| training/sac_pi/pi_global_norm | 2.0460355  |
| training/sac_pi/policy_loss    | -196.55057 |
| training/sac_pi/std            | 0.55247796 |
| training/sac_pi/valid_num      | 4904.0     |
| training/sac_Q/q1              | 175.59117  |
| training/sac_Q/q2              | 169.46097  |
| training/sac_Q/q2_loss         | 81.50456   |
| training/sac_Q/q_global_norm   | 316.06696  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15979142 |
| epoch                          | 332        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4995.6514  |
| evaluation/return-max          | 5021.163   |
| evaluation/return-min          | 4961.3784  |
| evaluation/return-std          | 18.987253  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45664      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4995.6514  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 190.99263  |
| Q-std                          | 111.33212  |
| Q_loss                         | 97.890434  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 332        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000103   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000553   |
| times/evaluation_paths         | 33.5       |
| times/timestep_after_hook      | 0.00417    |
| times/timestep_before_hook     | 0.00844    |
| times/train                    | 59.4       |
| timestep                       | 1000       |
| timesteps_total                | 333000     |
| train-steps                    | 333000     |
| training/Q/q1_loss             | 112.62324  |
| training/sac_pi/alpha          | 0.15977672 |
| training/sac_pi/alpha_loss     | 0.11176645 |
| training/sac_pi/logp_pi        | 4.7796636  |
| training/sac_pi/pi_entropy     | 3.6620045  |
| training/sac_pi/pi_global_norm | 1.2955618  |
| training/sac_pi/policy_loss    | -198.17445 |
| training/sac_pi/std            | 0.5348616  |
| training/sac_pi/valid_num      | 4924.0     |
| training/sac_Q/q1              | 184.05704  |
| training/sac_Q/q2              | 179.8906   |
| training/sac_Q/q2_loss         | 111.74051  |
| training/sac_Q/q_global_norm   | 233.35555  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16464731   |
| epoch                          | 333          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4796.1494    |
| evaluation/return-max          | 4884.5337    |
| evaluation/return-min          | 4620.0264    |
| evaluation/return-std          | 77.464554    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.92         |
| model/origin_ret               | 84.6         |
| model/penalty_ret              | 82.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45545        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4796.1494    |
| perf/NormalizedReturn          | 1.04         |
| Q-avg                          | 172.04341    |
| Q-std                          | 175.46455    |
| Q_loss                         | 102.80603    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 333          |
| times/epoch_after_hook         | 1.68e-06     |
| times/epoch_before_hook        | 0.000278     |
| times/epoch_rollout_model      | 489          |
| times/evaluation_metrics       | 0.000659     |
| times/evaluation_paths         | 33.5         |
| times/timestep_after_hook      | 0.00409      |
| times/timestep_before_hook     | 0.00845      |
| times/train                    | 59.7         |
| timestep                       | 1000         |
| timesteps_total                | 334000       |
| train-steps                    | 334000       |
| training/Q/q1_loss             | 83.10578     |
| training/sac_pi/alpha          | 0.16466796   |
| training/sac_pi/alpha_loss     | -0.015373479 |
| training/sac_pi/logp_pi        | 3.800324     |
| training/sac_pi/pi_entropy     | 3.4352622    |
| training/sac_pi/pi_global_norm | 1.4879686    |
| training/sac_pi/policy_loss    | -196.22934   |
| training/sac_pi/std            | 0.48076618   |
| training/sac_pi/valid_num      | 5028.0       |
| training/sac_Q/q1              | 190.18555    |
| training/sac_Q/q2              | 189.20607    |
| training/sac_Q/q2_loss         | 83.42448     |
| training/sac_Q/q_global_norm   | 216.91478    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16778482  |
| epoch                          | 334         |
| evaluation/episode-length-avg  | 358         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 140         |
| evaluation/episode-length-std  | 348         |
| evaluation/return-average      | 1372.6511   |
| evaluation/return-max          | 4393.3228   |
| evaluation/return-min          | 362.8668    |
| evaluation/return-std          | 1613.2974   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45651       |
| perf/AverageLength             | 358         |
| perf/AverageReturn             | 1372.6511   |
| perf/NormalizedReturn          | 0.299       |
| Q-avg                          | 187.31471   |
| Q-std                          | 143.17822   |
| Q_loss                         | 107.304184  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 334         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.00049     |
| times/evaluation_paths         | 11.9        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 60.2        |
| timestep                       | 1000        |
| timesteps_total                | 335000      |
| train-steps                    | 335000      |
| training/Q/q1_loss             | 96.92382    |
| training/sac_pi/alpha          | 0.16775571  |
| training/sac_pi/alpha_loss     | -0.22247852 |
| training/sac_pi/logp_pi        | 4.0383997   |
| training/sac_pi/pi_entropy     | 3.6509595   |
| training/sac_pi/pi_global_norm | 1.6148685   |
| training/sac_pi/policy_loss    | -195.1924   |
| training/sac_pi/std            | 0.50481784  |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 186.4613    |
| training/sac_Q/q2              | 183.97372   |
| training/sac_Q/q2_loss         | 96.54437    |
| training/sac_Q/q_global_norm   | 186.54211   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16145149  |
| epoch                          | 335         |
| evaluation/episode-length-avg  | 917         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 166         |
| evaluation/episode-length-std  | 250         |
| evaluation/return-average      | 4722.118    |
| evaluation/return-max          | 5277.371    |
| evaluation/return-min          | 558.6875    |
| evaluation/return-std          | 1389.297    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45736       |
| perf/AverageLength             | 917         |
| perf/AverageReturn             | 4722.118    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 191.88748   |
| Q-std                          | 99.57542    |
| Q_loss                         | 95.65176    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 335         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000141    |
| times/epoch_rollout_model      | 507         |
| times/evaluation_metrics       | 0.000605    |
| times/evaluation_paths         | 30.6        |
| times/timestep_after_hook      | 0.00439     |
| times/timestep_before_hook     | 0.00855     |
| times/train                    | 60.1        |
| timestep                       | 1000        |
| timesteps_total                | 336000      |
| train-steps                    | 336000      |
| training/Q/q1_loss             | 94.451836   |
| training/sac_pi/alpha          | 0.16148125  |
| training/sac_pi/alpha_loss     | -0.34989303 |
| training/sac_pi/logp_pi        | 4.557607    |
| training/sac_pi/pi_entropy     | 3.6879349   |
| training/sac_pi/pi_global_norm | 1.4842188   |
| training/sac_pi/policy_loss    | -197.46451  |
| training/sac_pi/std            | 0.5463451   |
| training/sac_pi/valid_num      | 4950.0      |
| training/sac_Q/q1              | 180.589     |
| training/sac_Q/q2              | 177.34416   |
| training/sac_Q/q2_loss         | 93.753204   |
| training/sac_Q/q_global_norm   | 267.02518   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1666979    |
| epoch                          | 336          |
| evaluation/episode-length-avg  | 998          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 981          |
| evaluation/episode-length-std  | 5.7          |
| evaluation/return-average      | 4555.3877    |
| evaluation/return-max          | 4713.745     |
| evaluation/return-min          | 4441.392     |
| evaluation/return-std          | 69.29448     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.89         |
| model/origin_ret               | 83.7         |
| model/penalty_ret              | 81.9         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45655        |
| perf/AverageLength             | 998          |
| perf/AverageReturn             | 4555.3877    |
| perf/NormalizedReturn          | 0.992        |
| Q-avg                          | 185.92064    |
| Q-std                          | 151.18709    |
| Q_loss                         | 96.50117     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 336          |
| times/epoch_after_hook         | 1.81e-06     |
| times/epoch_before_hook        | 0.000122     |
| times/epoch_rollout_model      | 504          |
| times/evaluation_metrics       | 0.000545     |
| times/evaluation_paths         | 35.2         |
| times/timestep_after_hook      | 0.00432      |
| times/timestep_before_hook     | 0.00864      |
| times/train                    | 62.6         |
| timestep                       | 1000         |
| timesteps_total                | 337000       |
| train-steps                    | 337000       |
| training/Q/q1_loss             | 81.550285    |
| training/sac_pi/alpha          | 0.16668667   |
| training/sac_pi/alpha_loss     | -0.028532634 |
| training/sac_pi/logp_pi        | 3.9783273    |
| training/sac_pi/pi_entropy     | 3.4750724    |
| training/sac_pi/pi_global_norm | 1.4549714    |
| training/sac_pi/policy_loss    | -209.48586   |
| training/sac_pi/std            | 0.492596     |
| training/sac_pi/valid_num      | 5019.0       |
| training/sac_Q/q1              | 201.15399    |
| training/sac_Q/q2              | 199.8328     |
| training/sac_Q/q2_loss         | 81.45753     |
| training/sac_Q/q_global_norm   | 195.79927    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16452543 |
| epoch                          | 337        |
| evaluation/episode-length-avg  | 825        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 125        |
| evaluation/episode-length-std  | 349        |
| evaluation/return-average      | 3625.2056  |
| evaluation/return-max          | 4546.004   |
| evaluation/return-min          | 276.35287  |
| evaluation/return-std          | 1671.1765  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45723      |
| perf/AverageLength             | 825        |
| perf/AverageReturn             | 3625.2056  |
| perf/NormalizedReturn          | 0.789      |
| Q-avg                          | 196.74089  |
| Q-std                          | 127.28803  |
| Q_loss                         | 98.51745   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 337        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000279   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000606   |
| times/evaluation_paths         | 28         |
| times/timestep_after_hook      | 0.00422    |
| times/timestep_before_hook     | 0.00878    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 338000     |
| train-steps                    | 338000     |
| training/Q/q1_loss             | 83.63005   |
| training/sac_pi/alpha          | 0.16453086 |
| training/sac_pi/alpha_loss     | 0.24529831 |
| training/sac_pi/logp_pi        | 4.8386526  |
| training/sac_pi/pi_entropy     | 3.588466   |
| training/sac_pi/pi_global_norm | 2.0354176  |
| training/sac_pi/policy_loss    | -196.05084 |
| training/sac_pi/std            | 0.52717143 |
| training/sac_pi/valid_num      | 4915.0     |
| training/sac_Q/q1              | 182.407    |
| training/sac_Q/q2              | 178.05316  |
| training/sac_Q/q2_loss         | 83.77478   |
| training/sac_Q/q_global_norm   | 249.40323  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16734588  |
| epoch                          | 338         |
| evaluation/episode-length-avg  | 616         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 127         |
| evaluation/episode-length-std  | 410         |
| evaluation/return-average      | 2545.8984   |
| evaluation/return-max          | 4396.0215   |
| evaluation/return-min          | 294.0011    |
| evaluation/return-std          | 1889.7539   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45725       |
| perf/AverageLength             | 616         |
| perf/AverageReturn             | 2545.8984   |
| perf/NormalizedReturn          | 0.554       |
| Q-avg                          | 182.61145   |
| Q-std                          | 144.8237    |
| Q_loss                         | 113.43225   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 338         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000143    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000753    |
| times/evaluation_paths         | 19.3        |
| times/timestep_after_hook      | 0.00385     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 59.5        |
| timestep                       | 1000        |
| timesteps_total                | 339000      |
| train-steps                    | 339000      |
| training/Q/q1_loss             | 82.72147    |
| training/sac_pi/alpha          | 0.16735926  |
| training/sac_pi/alpha_loss     | -0.17336246 |
| training/sac_pi/logp_pi        | 4.953447    |
| training/sac_pi/pi_entropy     | 3.686151    |
| training/sac_pi/pi_global_norm | 1.6161847   |
| training/sac_pi/policy_loss    | -200.52502  |
| training/sac_pi/std            | 0.55302775  |
| training/sac_pi/valid_num      | 4916.0      |
| training/sac_Q/q1              | 183.95493   |
| training/sac_Q/q2              | 180.57047   |
| training/sac_Q/q2_loss         | 83.52308    |
| training/sac_Q/q_global_norm   | 185.86118   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1636764  |
| epoch                          | 339        |
| evaluation/episode-length-avg  | 833        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 163        |
| evaluation/episode-length-std  | 335        |
| evaluation/return-average      | 3958.231   |
| evaluation/return-max          | 4851.0244  |
| evaluation/return-min          | 527.594    |
| evaluation/return-std          | 1714.072   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45728      |
| perf/AverageLength             | 833        |
| perf/AverageReturn             | 3958.231   |
| perf/NormalizedReturn          | 0.862      |
| Q-avg                          | 185.09273  |
| Q-std                          | 138.04405  |
| Q_loss                         | 119.85072  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 339        |
| times/epoch_after_hook         | 3.4e-06    |
| times/epoch_before_hook        | 0.000154   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000525   |
| times/evaluation_paths         | 25.2       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 58.1       |
| timestep                       | 1000       |
| timesteps_total                | 340000     |
| train-steps                    | 340000     |
| training/Q/q1_loss             | 81.08855   |
| training/sac_pi/alpha          | 0.16366038 |
| training/sac_pi/alpha_loss     | 0.03080087 |
| training/sac_pi/logp_pi        | 4.2474146  |
| training/sac_pi/pi_entropy     | 3.6343567  |
| training/sac_pi/pi_global_norm | 1.676505   |
| training/sac_pi/policy_loss    | -202.99672 |
| training/sac_pi/std            | 0.5095863  |
| training/sac_pi/valid_num      | 4984.0     |
| training/sac_Q/q1              | 193.85422  |
| training/sac_Q/q2              | 190.81796  |
| training/sac_Q/q2_loss         | 80.94595   |
| training/sac_Q/q_global_norm   | 207.49213  |
--------------------------------------------------------------------------------
[WARN] 340 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.16450068   |
| epoch                          | 340          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5125.579     |
| evaluation/return-max          | 5272.968     |
| evaluation/return-min          | 4971.413     |
| evaluation/return-std          | 96.53231     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.96         |
| model/origin_ret               | 85.2         |
| model/penalty_ret              | 81.8         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45810        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5125.579     |
| perf/NormalizedReturn          | 1.12         |
| Q-avg                          | 205.53091    |
| Q-std                          | 105.59989    |
| Q_loss                         | 79.52556     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 340          |
| times/epoch_after_hook         | 2.02e-06     |
| times/epoch_before_hook        | 0.000146     |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.00062      |
| times/evaluation_paths         | 31.4         |
| times/timestep_after_hook      | 0.00378      |
| times/timestep_before_hook     | 0.00813      |
| times/train                    | 56.3         |
| timestep                       | 1000         |
| timesteps_total                | 341000       |
| train-steps                    | 341000       |
| training/Q/q1_loss             | 112.47643    |
| training/sac_pi/alpha          | 0.1644957    |
| training/sac_pi/alpha_loss     | -0.017568238 |
| training/sac_pi/logp_pi        | 5.8891187    |
| training/sac_pi/pi_entropy     | 3.6551514    |
| training/sac_pi/pi_global_norm | 1.4733846    |
| training/sac_pi/policy_loss    | -204.70967   |
| training/sac_pi/std            | 0.5590826    |
| training/sac_pi/valid_num      | 4871.0       |
| training/sac_Q/q1              | 182.40378    |
| training/sac_Q/q2              | 178.41023    |
| training/sac_Q/q2_loss         | 113.45118    |
| training/sac_Q/q_global_norm   | 200.3047     |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16584866   |
| epoch                          | 341          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4911.9775    |
| evaluation/return-max          | 4973.381     |
| evaluation/return-min          | 4865.582     |
| evaluation/return-std          | 31.484629    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.91         |
| model/origin_ret               | 83.4         |
| model/penalty_ret              | 81.6         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45557        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4911.9775    |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 185.49965    |
| Q-std                          | 177.74484    |
| Q_loss                         | 103.50331    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 341          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.000279     |
| times/epoch_rollout_model      | 473          |
| times/evaluation_metrics       | 0.000649     |
| times/evaluation_paths         | 30.3         |
| times/timestep_after_hook      | 0.00379      |
| times/timestep_before_hook     | 0.0081       |
| times/train                    | 56.6         |
| timestep                       | 1000         |
| timesteps_total                | 342000       |
| train-steps                    | 342000       |
| training/Q/q1_loss             | 102.29687    |
| training/sac_pi/alpha          | 0.165858     |
| training/sac_pi/alpha_loss     | -0.109481215 |
| training/sac_pi/logp_pi        | 4.9261103    |
| training/sac_pi/pi_entropy     | 3.7019792    |
| training/sac_pi/pi_global_norm | 1.7564338    |
| training/sac_pi/policy_loss    | -201.09465   |
| training/sac_pi/std            | 0.5572353    |
| training/sac_pi/valid_num      | 4917.0       |
| training/sac_Q/q1              | 185.69809    |
| training/sac_Q/q2              | 179.59644    |
| training/sac_Q/q2_loss         | 103.67625    |
| training/sac_Q/q_global_norm   | 184.5987     |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16826104  |
| epoch                          | 342         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4866.757    |
| evaluation/return-max          | 4935.2773   |
| evaluation/return-min          | 4815.088    |
| evaluation/return-std          | 33.503635   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 83.8        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45622       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4866.757    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 180.6843    |
| Q-std                          | 163.84134   |
| Q_loss                         | 84.68646    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 342         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000101    |
| times/epoch_rollout_model      | 468         |
| times/evaluation_metrics       | 0.000534    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00357     |
| times/timestep_before_hook     | 0.00787     |
| times/train                    | 55.2        |
| timestep                       | 1000        |
| timesteps_total                | 343000      |
| train-steps                    | 343000      |
| training/Q/q1_loss             | 91.65724    |
| training/sac_pi/alpha          | 0.16827619  |
| training/sac_pi/alpha_loss     | -0.25257525 |
| training/sac_pi/logp_pi        | 3.6083152   |
| training/sac_pi/pi_entropy     | 3.570108    |
| training/sac_pi/pi_global_norm | 1.5626634   |
| training/sac_pi/policy_loss    | -191.14632  |
| training/sac_pi/std            | 0.48299724  |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 183.85345   |
| training/sac_Q/q2              | 182.22191   |
| training/sac_Q/q2_loss         | 91.77772    |
| training/sac_Q/q_global_norm   | 251.75366   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16588297 |
| epoch                          | 343        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4976.796   |
| evaluation/return-max          | 5022.89    |
| evaluation/return-min          | 4901.877   |
| evaluation/return-std          | 33.660633  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45653      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4976.796   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 195.7918   |
| Q-std                          | 121.89216  |
| Q_loss                         | 112.448235 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 343        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000113   |
| times/epoch_rollout_model      | 468        |
| times/evaluation_metrics       | 0.000531   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.0079     |
| times/train                    | 54.3       |
| timestep                       | 1000       |
| timesteps_total                | 344000     |
| train-steps                    | 344000     |
| training/Q/q1_loss             | 103.24394  |
| training/sac_pi/alpha          | 0.1658895  |
| training/sac_pi/alpha_loss     | -0.5289488 |
| training/sac_pi/logp_pi        | 4.5488915  |
| training/sac_pi/pi_entropy     | 3.543134   |
| training/sac_pi/pi_global_norm | 1.9190776  |
| training/sac_pi/policy_loss    | -207.18564 |
| training/sac_pi/std            | 0.5259405  |
| training/sac_pi/valid_num      | 4939.0     |
| training/sac_Q/q1              | 191.0198   |
| training/sac_Q/q2              | 190.2544   |
| training/sac_Q/q2_loss         | 102.25853  |
| training/sac_Q/q_global_norm   | 205.22379  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17063685  |
| epoch                          | 344         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5120.316    |
| evaluation/return-max          | 5200.9404   |
| evaluation/return-min          | 5013.5137   |
| evaluation/return-std          | 51.38149    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45677       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5120.316    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 179.80876   |
| Q-std                          | 166.02344   |
| Q_loss                         | 111.31129   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 344         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 471         |
| times/evaluation_metrics       | 0.000538    |
| times/evaluation_paths         | 30.5        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00796     |
| times/train                    | 56.2        |
| timestep                       | 1000        |
| timesteps_total                | 345000      |
| train-steps                    | 345000      |
| training/Q/q1_loss             | 116.26459   |
| training/sac_pi/alpha          | 0.1706126   |
| training/sac_pi/alpha_loss     | 0.027672287 |
| training/sac_pi/logp_pi        | 4.5785475   |
| training/sac_pi/pi_entropy     | 3.5591805   |
| training/sac_pi/pi_global_norm | 1.5446757   |
| training/sac_pi/policy_loss    | -203.1027   |
| training/sac_pi/std            | 0.52259785  |
| training/sac_pi/valid_num      | 4944.0      |
| training/sac_Q/q1              | 189.94357   |
| training/sac_Q/q2              | 186.0492    |
| training/sac_Q/q2_loss         | 117.25421   |
| training/sac_Q/q_global_norm   | 208.34326   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16710715  |
| epoch                          | 345         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4755.0796   |
| evaluation/return-max          | 4845.7866   |
| evaluation/return-min          | 4672.0977   |
| evaluation/return-std          | 54.59588    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45632       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4755.0796   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 182.45613   |
| Q-std                          | 126.2216    |
| Q_loss                         | 106.49428   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 345         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000274    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000612    |
| times/evaluation_paths         | 29.9        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 54.7        |
| timestep                       | 1000        |
| timesteps_total                | 346000      |
| train-steps                    | 346000      |
| training/Q/q1_loss             | 96.55822    |
| training/sac_pi/alpha          | 0.1671106   |
| training/sac_pi/alpha_loss     | -0.10120177 |
| training/sac_pi/logp_pi        | 4.107816    |
| training/sac_pi/pi_entropy     | 3.4624443   |
| training/sac_pi/pi_global_norm | 1.9052062   |
| training/sac_pi/policy_loss    | -203.35306  |
| training/sac_pi/std            | 0.4895715   |
| training/sac_pi/valid_num      | 4973.0      |
| training/sac_Q/q1              | 194.44019   |
| training/sac_Q/q2              | 193.19193   |
| training/sac_Q/q2_loss         | 96.627014   |
| training/sac_Q/q_global_norm   | 273.61026   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16986802  |
| epoch                          | 346         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4806.939    |
| evaluation/return-max          | 4870.5654   |
| evaluation/return-min          | 4739.538    |
| evaluation/return-std          | 47.40698    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.89        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 82.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45523       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4806.939    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 182.51193   |
| Q-std                          | 153.61206   |
| Q_loss                         | 89.4825     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 346         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000577    |
| times/evaluation_paths         | 30          |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00794     |
| times/train                    | 55.1        |
| timestep                       | 1000        |
| timesteps_total                | 347000      |
| train-steps                    | 347000      |
| training/Q/q1_loss             | 106.1729    |
| training/sac_pi/alpha          | 0.16981414  |
| training/sac_pi/alpha_loss     | -0.03269805 |
| training/sac_pi/logp_pi        | 4.9268765   |
| training/sac_pi/pi_entropy     | 3.614038    |
| training/sac_pi/pi_global_norm | 1.5583183   |
| training/sac_pi/policy_loss    | -198.21094  |
| training/sac_pi/std            | 0.5388242   |
| training/sac_pi/valid_num      | 4957.0      |
| training/sac_Q/q1              | 182.73973   |
| training/sac_Q/q2              | 180.74576   |
| training/sac_Q/q2_loss         | 105.58897   |
| training/sac_Q/q_global_norm   | 203.6867    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17214891 |
| epoch                          | 347        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4820.0737  |
| evaluation/return-max          | 4887.7344  |
| evaluation/return-min          | 4718.2183  |
| evaluation/return-std          | 47.678818  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45634      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4820.0737  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 183.32431  |
| Q-std                          | 152.23135  |
| Q_loss                         | 105.791824 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 347        |
| times/epoch_after_hook         | 3.7e-06    |
| times/epoch_before_hook        | 0.000101   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000563   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00375    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 54.6       |
| timestep                       | 1000       |
| timesteps_total                | 348000     |
| train-steps                    | 348000     |
| training/Q/q1_loss             | 107.27448  |
| training/sac_pi/alpha          | 0.17217237 |
| training/sac_pi/alpha_loss     | -0.4225294 |
| training/sac_pi/logp_pi        | 4.4316893  |
| training/sac_pi/pi_entropy     | 3.5400627  |
| training/sac_pi/pi_global_norm | 1.599458   |
| training/sac_pi/policy_loss    | -198.66524 |
| training/sac_pi/std            | 0.5105249  |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 189.78072  |
| training/sac_Q/q2              | 188.51213  |
| training/sac_Q/q2_loss         | 107.59835  |
| training/sac_Q/q_global_norm   | 176.73988  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17193484 |
| epoch                          | 348        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4848.124   |
| evaluation/return-max          | 4857.487   |
| evaluation/return-min          | 4841.344   |
| evaluation/return-std          | 4.638283   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45883      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4848.124   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 192.28662  |
| Q-std                          | 120.550644 |
| Q_loss                         | 84.59116   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 348        |
| times/epoch_after_hook         | 2.01e-06   |
| times/epoch_before_hook        | 9.91e-05   |
| times/epoch_rollout_model      | 473        |
| times/evaluation_metrics       | 0.000652   |
| times/evaluation_paths         | 31.1       |
| times/timestep_after_hook      | 0.00344    |
| times/timestep_before_hook     | 0.0079     |
| times/train                    | 54.2       |
| timestep                       | 1000       |
| timesteps_total                | 349000     |
| train-steps                    | 349000     |
| training/Q/q1_loss             | 98.63961   |
| training/sac_pi/alpha          | 0.17192672 |
| training/sac_pi/alpha_loss     | 0.06220485 |
| training/sac_pi/logp_pi        | 4.662339   |
| training/sac_pi/pi_entropy     | 3.4485824  |
| training/sac_pi/pi_global_norm | 1.7492589  |
| training/sac_pi/policy_loss    | -198.94377 |
| training/sac_pi/std            | 0.50880075 |
| training/sac_pi/valid_num      | 4937.0     |
| training/sac_Q/q1              | 182.57657  |
| training/sac_Q/q2              | 180.33603  |
| training/sac_Q/q2_loss         | 97.43426   |
| training/sac_Q/q_global_norm   | 238.63452  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16326855 |
| epoch                          | 349        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4955.6357  |
| evaluation/return-max          | 5002.8267  |
| evaluation/return-min          | 4916.618   |
| evaluation/return-std          | 29.36691   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45648      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4955.6357  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 175.53018  |
| Q-std                          | 171.07558  |
| Q_loss                         | 110.44999  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 349        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.00031    |
| times/epoch_rollout_model      | 468        |
| times/evaluation_metrics       | 0.000639   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00353    |
| times/timestep_before_hook     | 0.00785    |
| times/train                    | 55.2       |
| timestep                       | 1000       |
| timesteps_total                | 350000     |
| train-steps                    | 350000     |
| training/Q/q1_loss             | 86.62037   |
| training/sac_pi/alpha          | 0.16324396 |
| training/sac_pi/alpha_loss     | 0.20495309 |
| training/sac_pi/logp_pi        | 4.095914   |
| training/sac_pi/pi_entropy     | 3.3856728  |
| training/sac_pi/pi_global_norm | 1.8673698  |
| training/sac_pi/policy_loss    | -204.46768 |
| training/sac_pi/std            | 0.4833271  |
| training/sac_pi/valid_num      | 4993.0     |
| training/sac_Q/q1              | 196.20471  |
| training/sac_Q/q2              | 194.01035  |
| training/sac_Q/q2_loss         | 87.43484   |
| training/sac_Q/q_global_norm   | 329.23392  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17191426 |
| epoch                          | 350        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4945.659   |
| evaluation/return-max          | 4997.0107  |
| evaluation/return-min          | 4890.6787  |
| evaluation/return-std          | 31.878973  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45780      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4945.659   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 182.92482  |
| Q-std                          | 140.80045  |
| Q_loss                         | 117.53594  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 350        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000101   |
| times/epoch_rollout_model      | 472        |
| times/evaluation_metrics       | 0.000608   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 55.2       |
| timestep                       | 1000       |
| timesteps_total                | 351000     |
| train-steps                    | 351000     |
| training/Q/q1_loss             | 101.448204 |
| training/sac_pi/alpha          | 0.17189653 |
| training/sac_pi/alpha_loss     | 0.16403928 |
| training/sac_pi/logp_pi        | 4.5558214  |
| training/sac_pi/pi_entropy     | 3.4348502  |
| training/sac_pi/pi_global_norm | 1.407931   |
| training/sac_pi/policy_loss    | -203.11755 |
| training/sac_pi/std            | 0.48964944 |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 190.0803   |
| training/sac_Q/q2              | 185.57324  |
| training/sac_Q/q2_loss         | 102.285286 |
| training/sac_Q/q_global_norm   | 220.80756  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17022006 |
| epoch                          | 351        |
| evaluation/episode-length-avg  | 890        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 395        |
| evaluation/episode-length-std  | 221        |
| evaluation/return-average      | 4119.9375  |
| evaluation/return-max          | 4753.006   |
| evaluation/return-min          | 1569.7239  |
| evaluation/return-std          | 1140.4844  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45585      |
| perf/AverageLength             | 890        |
| perf/AverageReturn             | 4119.9375  |
| perf/NormalizedReturn          | 0.897      |
| Q-avg                          | 184.27861  |
| Q-std                          | 141.35056  |
| Q_loss                         | 99.71028   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 351        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 474        |
| times/evaluation_metrics       | 0.000596   |
| times/evaluation_paths         | 27.3       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 55.2       |
| timestep                       | 1000       |
| timesteps_total                | 352000     |
| train-steps                    | 352000     |
| training/Q/q1_loss             | 115.242035 |
| training/sac_pi/alpha          | 0.1702219  |
| training/sac_pi/alpha_loss     | 0.1104017  |
| training/sac_pi/logp_pi        | 5.23786    |
| training/sac_pi/pi_entropy     | 3.6048188  |
| training/sac_pi/pi_global_norm | 2.144083   |
| training/sac_pi/policy_loss    | -199.87065 |
| training/sac_pi/std            | 0.552844   |
| training/sac_pi/valid_num      | 4866.0     |
| training/sac_Q/q1              | 181.00143  |
| training/sac_Q/q2              | 174.29501  |
| training/sac_Q/q2_loss         | 115.502045 |
| training/sac_Q/q_global_norm   | 295.52298  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16589499 |
| epoch                          | 352        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4998.6553  |
| evaluation/return-max          | 5128.792   |
| evaluation/return-min          | 4908.504   |
| evaluation/return-std          | 71.22586   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45769      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4998.6553  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 175.31284  |
| Q-std                          | 180.15147  |
| Q_loss                         | 123.112564 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 352        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000114   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000586   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.008      |
| times/train                    | 53.9       |
| timestep                       | 1000       |
| timesteps_total                | 353000     |
| train-steps                    | 353000     |
| training/Q/q1_loss             | 99.515175  |
| training/sac_pi/alpha          | 0.1659321  |
| training/sac_pi/alpha_loss     | -0.2015943 |
| training/sac_pi/logp_pi        | 4.371768   |
| training/sac_pi/pi_entropy     | 3.6261413  |
| training/sac_pi/pi_global_norm | 1.4223629  |
| training/sac_pi/policy_loss    | -201.85164 |
| training/sac_pi/std            | 0.53086025 |
| training/sac_pi/valid_num      | 4934.0     |
| training/sac_Q/q1              | 184.85701  |
| training/sac_Q/q2              | 182.11946  |
| training/sac_Q/q2_loss         | 98.69137   |
| training/sac_Q/q_global_norm   | 243.03242  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16746199  |
| epoch                          | 353         |
| evaluation/episode-length-avg  | 913         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 134         |
| evaluation/episode-length-std  | 260         |
| evaluation/return-average      | 4050.7954   |
| evaluation/return-max          | 4678.921    |
| evaluation/return-min          | 329.40283   |
| evaluation/return-std          | 1245.0459   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45596       |
| perf/AverageLength             | 913         |
| perf/AverageReturn             | 4050.7954   |
| perf/NormalizedReturn          | 0.882       |
| Q-avg                          | 190.57002   |
| Q-std                          | 146.6514    |
| Q_loss                         | 77.16375    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 353         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000329    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000523    |
| times/evaluation_paths         | 27.3        |
| times/timestep_after_hook      | 0.00355     |
| times/timestep_before_hook     | 0.00794     |
| times/train                    | 53.7        |
| timestep                       | 1000        |
| timesteps_total                | 354000      |
| train-steps                    | 354000      |
| training/Q/q1_loss             | 87.40989    |
| training/sac_pi/alpha          | 0.16744931  |
| training/sac_pi/alpha_loss     | 0.104147434 |
| training/sac_pi/logp_pi        | 3.794685    |
| training/sac_pi/pi_entropy     | 3.415385    |
| training/sac_pi/pi_global_norm | 1.6379668   |
| training/sac_pi/policy_loss    | -204.86642  |
| training/sac_pi/std            | 0.4774504   |
| training/sac_pi/valid_num      | 4969.0      |
| training/sac_Q/q1              | 196.95256   |
| training/sac_Q/q2              | 195.77647   |
| training/sac_Q/q2_loss         | 86.13765    |
| training/sac_Q/q_global_norm   | 212.59995   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16530415  |
| epoch                          | 354         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4991.296    |
| evaluation/return-max          | 5037.0303   |
| evaluation/return-min          | 4947.449    |
| evaluation/return-std          | 32.74917    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.87        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45534       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4991.296    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 194.26805   |
| Q-std                          | 99.562706   |
| Q_loss                         | 95.80365    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 354         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000154    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.00052     |
| times/evaluation_paths         | 30.2        |
| times/timestep_after_hook      | 0.00357     |
| times/timestep_before_hook     | 0.00787     |
| times/train                    | 54.3        |
| timestep                       | 1000        |
| timesteps_total                | 355000      |
| train-steps                    | 355000      |
| training/Q/q1_loss             | 109.84646   |
| training/sac_pi/alpha          | 0.16531806  |
| training/sac_pi/alpha_loss     | -0.28683388 |
| training/sac_pi/logp_pi        | 4.46519     |
| training/sac_pi/pi_entropy     | 3.5101535   |
| training/sac_pi/pi_global_norm | 1.4401693   |
| training/sac_pi/policy_loss    | -196.79356  |
| training/sac_pi/std            | 0.5065945   |
| training/sac_pi/valid_num      | 4875.0      |
| training/sac_Q/q1              | 185.31424   |
| training/sac_Q/q2              | 183.57556   |
| training/sac_Q/q2_loss         | 109.14452   |
| training/sac_Q/q_global_norm   | 228.03809   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16912387 |
| epoch                          | 355        |
| evaluation/episode-length-avg  | 939        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 390        |
| evaluation/episode-length-std  | 183        |
| evaluation/return-average      | 4326.1226  |
| evaluation/return-max          | 4752.1816  |
| evaluation/return-min          | 1441.8508  |
| evaluation/return-std          | 965.131    |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45558      |
| perf/AverageLength             | 939        |
| perf/AverageReturn             | 4326.1226  |
| perf/NormalizedReturn          | 0.942      |
| Q-avg                          | 186.6506   |
| Q-std                          | 163.20027  |
| Q_loss                         | 109.03958  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 355        |
| times/epoch_after_hook         | 2.16e-06   |
| times/epoch_before_hook        | 0.000184   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000516   |
| times/evaluation_paths         | 28.8       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00801    |
| times/train                    | 53.1       |
| timestep                       | 1000       |
| timesteps_total                | 356000     |
| train-steps                    | 356000     |
| training/Q/q1_loss             | 112.852646 |
| training/sac_pi/alpha          | 0.1691744  |
| training/sac_pi/alpha_loss     | 0.35127956 |
| training/sac_pi/logp_pi        | 5.4222126  |
| training/sac_pi/pi_entropy     | 3.6186378  |
| training/sac_pi/pi_global_norm | 1.8372948  |
| training/sac_pi/policy_loss    | -196.50769 |
| training/sac_pi/std            | 0.53009933 |
| training/sac_pi/valid_num      | 4876.0     |
| training/sac_Q/q1              | 179.81885  |
| training/sac_Q/q2              | 173.70528  |
| training/sac_Q/q2_loss         | 112.568756 |
| training/sac_Q/q_global_norm   | 236.93086  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17184119 |
| epoch                          | 356        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4736.3115  |
| evaluation/return-max          | 4839.6123  |
| evaluation/return-min          | 4667.6816  |
| evaluation/return-std          | 54.55915   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45744      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4736.3115  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 184.21219  |
| Q-std                          | 168.56625  |
| Q_loss                         | 107.520226 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 356        |
| times/epoch_after_hook         | 3.11e-06   |
| times/epoch_before_hook        | 7.64e-05   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.00058    |
| times/evaluation_paths         | 30.4       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00794    |
| times/train                    | 53.1       |
| timestep                       | 1000       |
| timesteps_total                | 357000     |
| train-steps                    | 357000     |
| training/Q/q1_loss             | 96.28563   |
| training/sac_pi/alpha          | 0.1718217  |
| training/sac_pi/alpha_loss     | 0.15162884 |
| training/sac_pi/logp_pi        | 5.010143   |
| training/sac_pi/pi_entropy     | 3.7583683  |
| training/sac_pi/pi_global_norm | 1.7139794  |
| training/sac_pi/policy_loss    | -196.18826 |
| training/sac_pi/std            | 0.5572393  |
| training/sac_pi/valid_num      | 4947.0     |
| training/sac_Q/q1              | 180.68384  |
| training/sac_Q/q2              | 178.0845   |
| training/sac_Q/q2_loss         | 97.27191   |
| training/sac_Q/q_global_norm   | 180.25829  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1672277   |
| epoch                          | 357         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5000.1626   |
| evaluation/return-max          | 5060.524    |
| evaluation/return-min          | 4936.9224   |
| evaluation/return-std          | 36.42928    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 82.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45636       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5000.1626   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 190.7512    |
| Q-std                          | 112.07477   |
| Q_loss                         | 104.69766   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 357         |
| times/epoch_after_hook         | 3.26e-06    |
| times/epoch_before_hook        | 0.000273    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000527    |
| times/evaluation_paths         | 29.6        |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00781     |
| times/train                    | 54.2        |
| timestep                       | 1000        |
| timesteps_total                | 358000      |
| train-steps                    | 358000      |
| training/Q/q1_loss             | 111.39326   |
| training/sac_pi/alpha          | 0.1672289   |
| training/sac_pi/alpha_loss     | 0.088133074 |
| training/sac_pi/logp_pi        | 4.609064    |
| training/sac_pi/pi_entropy     | 3.521717    |
| training/sac_pi/pi_global_norm | 1.5631022   |
| training/sac_pi/policy_loss    | -202.3245   |
| training/sac_pi/std            | 0.5184753   |
| training/sac_pi/valid_num      | 4970.0      |
| training/sac_Q/q1              | 190.05116   |
| training/sac_Q/q2              | 187.84282   |
| training/sac_Q/q2_loss         | 110.04918   |
| training/sac_Q/q_global_norm   | 303.67297   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1680021   |
| epoch                          | 358         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4897.1704   |
| evaluation/return-max          | 5013.3354   |
| evaluation/return-min          | 4785.459    |
| evaluation/return-std          | 76.7697     |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45821       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4897.1704   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 185.30887   |
| Q-std                          | 136.89458   |
| Q_loss                         | 80.772606   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 358         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000101    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000531    |
| times/evaluation_paths         | 29.8        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00796     |
| times/train                    | 55.4        |
| timestep                       | 1000        |
| timesteps_total                | 359000      |
| train-steps                    | 359000      |
| training/Q/q1_loss             | 95.25149    |
| training/sac_pi/alpha          | 0.16801174  |
| training/sac_pi/alpha_loss     | -0.11271392 |
| training/sac_pi/logp_pi        | 4.469893    |
| training/sac_pi/pi_entropy     | 3.7392802   |
| training/sac_pi/pi_global_norm | 1.7155874   |
| training/sac_pi/policy_loss    | -199.97746  |
| training/sac_pi/std            | 0.5376407   |
| training/sac_pi/valid_num      | 4956.0      |
| training/sac_Q/q1              | 185.99164   |
| training/sac_Q/q2              | 181.95377   |
| training/sac_Q/q2_loss         | 96.37369    |
| training/sac_Q/q_global_norm   | 291.06744   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16755776  |
| epoch                          | 359         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5021.3843   |
| evaluation/return-max          | 5062.017    |
| evaluation/return-min          | 4939.9473   |
| evaluation/return-std          | 40.62602    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 82.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45498       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5021.3843   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 163.01169   |
| Q-std                          | 219.65952   |
| Q_loss                         | 92.96915    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 359         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000101    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000543    |
| times/evaluation_paths         | 30.4        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00803     |
| times/train                    | 55.9        |
| timestep                       | 1000        |
| timesteps_total                | 360000      |
| train-steps                    | 360000      |
| training/Q/q1_loss             | 95.87305    |
| training/sac_pi/alpha          | 0.16759895  |
| training/sac_pi/alpha_loss     | -0.46338266 |
| training/sac_pi/logp_pi        | 4.0421977   |
| training/sac_pi/pi_entropy     | 3.4256597   |
| training/sac_pi/pi_global_norm | 1.6144272   |
| training/sac_pi/policy_loss    | -198.7779   |
| training/sac_pi/std            | 0.4964363   |
| training/sac_pi/valid_num      | 4957.0      |
| training/sac_Q/q1              | 185.17505   |
| training/sac_Q/q2              | 182.39005   |
| training/sac_Q/q2_loss         | 95.954285   |
| training/sac_Q/q_global_norm   | 239.56319   |
---------------------------------------------------------------------------------
[WARN] 360 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.16534533   |
| epoch                          | 360          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5005.5044    |
| evaluation/return-max          | 5158.5947    |
| evaluation/return-min          | 4806.8887    |
| evaluation/return-std          | 128.05162    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.95         |
| model/origin_ret               | 83.7         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45776        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5005.5044    |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 188.81331    |
| Q-std                          | 158.1417     |
| Q_loss                         | 110.84832    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 360          |
| times/epoch_after_hook         | 1.77e-06     |
| times/epoch_before_hook        | 0.000102     |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.000556     |
| times/evaluation_paths         | 30.1         |
| times/timestep_after_hook      | 0.00367      |
| times/timestep_before_hook     | 0.00794      |
| times/train                    | 54.8         |
| timestep                       | 1000         |
| timesteps_total                | 361000       |
| train-steps                    | 361000       |
| training/Q/q1_loss             | 89.42472     |
| training/sac_pi/alpha          | 0.1653828    |
| training/sac_pi/alpha_loss     | -0.108392194 |
| training/sac_pi/logp_pi        | 4.535347     |
| training/sac_pi/pi_entropy     | 3.5030792    |
| training/sac_pi/pi_global_norm | 1.8103317    |
| training/sac_pi/policy_loss    | -201.90587   |
| training/sac_pi/std            | 0.5208007    |
| training/sac_pi/valid_num      | 4949.0       |
| training/sac_Q/q1              | 185.32777    |
| training/sac_Q/q2              | 180.75198    |
| training/sac_Q/q2_loss         | 88.937515    |
| training/sac_Q/q_global_norm   | 212.28091    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17014691  |
| epoch                          | 361         |
| evaluation/episode-length-avg  | 966         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 656         |
| evaluation/episode-length-std  | 103         |
| evaluation/return-average      | 4489.3936   |
| evaluation/return-max          | 4796.9062   |
| evaluation/return-min          | 2789.9646   |
| evaluation/return-std          | 570.04034   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.84        |
| model/origin_ret               | 82.1        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45673       |
| perf/AverageLength             | 966         |
| perf/AverageReturn             | 4489.3936   |
| perf/NormalizedReturn          | 0.978       |
| Q-avg                          | 187.48984   |
| Q-std                          | 123.03414   |
| Q_loss                         | 100.78663   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 361         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000279    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000568    |
| times/evaluation_paths         | 29.3        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 54          |
| timestep                       | 1000        |
| timesteps_total                | 362000      |
| train-steps                    | 362000      |
| training/Q/q1_loss             | 89.872025   |
| training/sac_pi/alpha          | 0.17013179  |
| training/sac_pi/alpha_loss     | 0.014741452 |
| training/sac_pi/logp_pi        | 3.8262267   |
| training/sac_pi/pi_entropy     | 3.4434288   |
| training/sac_pi/pi_global_norm | 1.6663097   |
| training/sac_pi/policy_loss    | -203.57028  |
| training/sac_pi/std            | 0.47653168  |
| training/sac_pi/valid_num      | 5014.0      |
| training/sac_Q/q1              | 194.69263   |
| training/sac_Q/q2              | 191.91577   |
| training/sac_Q/q2_loss         | 90.3883     |
| training/sac_Q/q_global_norm   | 192.11597   |
---------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.16776407    |
| epoch                          | 362           |
| evaluation/episode-length-avg  | 773           |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 155           |
| evaluation/episode-length-std  | 353           |
| evaluation/return-average      | 3486.4048     |
| evaluation/return-max          | 4749.271      |
| evaluation/return-min          | 430.23334     |
| evaluation/return-std          | 1785.3435     |
| model/max_penalty              | 7.34          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 2.91          |
| model/origin_ret               | 84            |
| model/penalty_ret              | 81.3          |
| model/val_loss                 | 0.35430613    |
| model/valid_num                | 45618         |
| perf/AverageLength             | 773           |
| perf/AverageReturn             | 3486.4048     |
| perf/NormalizedReturn          | 0.759         |
| Q-avg                          | 175.61086     |
| Q-std                          | 181.53786     |
| Q_loss                         | 104.98051     |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 362           |
| times/epoch_after_hook         | 1.76e-06      |
| times/epoch_before_hook        | 0.000133      |
| times/epoch_rollout_model      | 481           |
| times/evaluation_metrics       | 0.000486      |
| times/evaluation_paths         | 23.9          |
| times/timestep_after_hook      | 0.00366       |
| times/timestep_before_hook     | 0.00795       |
| times/train                    | 55.5          |
| timestep                       | 1000          |
| timesteps_total                | 363000        |
| train-steps                    | 363000        |
| training/Q/q1_loss             | 86.56223      |
| training/sac_pi/alpha          | 0.16776368    |
| training/sac_pi/alpha_loss     | -0.0085628955 |
| training/sac_pi/logp_pi        | 4.9916563     |
| training/sac_pi/pi_entropy     | 3.3232408     |
| training/sac_pi/pi_global_norm | 1.6608951     |
| training/sac_pi/policy_loss    | -195.87712    |
| training/sac_pi/std            | 0.49906904    |
| training/sac_pi/valid_num      | 4963.0        |
| training/sac_Q/q1              | 181.49031     |
| training/sac_Q/q2              | 178.84631     |
| training/sac_Q/q2_loss         | 86.224594     |
| training/sac_Q/q_global_norm   | 252.13329     |
-----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16235526  |
| epoch                          | 363         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4908.982    |
| evaluation/return-max          | 4962.0625   |
| evaluation/return-min          | 4876.0127   |
| evaluation/return-std          | 23.970068   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45780       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4908.982    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 184.693     |
| Q-std                          | 158.77014   |
| Q_loss                         | 85.47514    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 363         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 9.34e-05    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000524    |
| times/evaluation_paths         | 30.3        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00781     |
| times/train                    | 55.5        |
| timestep                       | 1000        |
| timesteps_total                | 364000      |
| train-steps                    | 364000      |
| training/Q/q1_loss             | 84.7178     |
| training/sac_pi/alpha          | 0.16233604  |
| training/sac_pi/alpha_loss     | -0.13340941 |
| training/sac_pi/logp_pi        | 4.004827    |
| training/sac_pi/pi_entropy     | 3.3730018   |
| training/sac_pi/pi_global_norm | 1.5280372   |
| training/sac_pi/policy_loss    | -203.52715  |
| training/sac_pi/std            | 0.48085487  |
| training/sac_pi/valid_num      | 4985.0      |
| training/sac_Q/q1              | 193.44917   |
| training/sac_Q/q2              | 191.70078   |
| training/sac_Q/q2_loss         | 85.63883    |
| training/sac_Q/q_global_norm   | 239.72107   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16704303 |
| epoch                          | 364        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4770.873   |
| evaluation/return-max          | 4806.0884  |
| evaluation/return-min          | 4727.224   |
| evaluation/return-std          | 26.307377  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45755      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4770.873   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 187.55217  |
| Q-std                          | 170.66035  |
| Q_loss                         | 109.989586 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 364        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000102   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000631   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00802    |
| times/train                    | 55.5       |
| timestep                       | 1000       |
| timesteps_total                | 365000     |
| train-steps                    | 365000     |
| training/Q/q1_loss             | 92.80316   |
| training/sac_pi/alpha          | 0.16707334 |
| training/sac_pi/alpha_loss     | -0.3170772 |
| training/sac_pi/logp_pi        | 3.9539113  |
| training/sac_pi/pi_entropy     | 3.7351518  |
| training/sac_pi/pi_global_norm | 1.4693437  |
| training/sac_pi/policy_loss    | -199.31888 |
| training/sac_pi/std            | 0.52123123 |
| training/sac_pi/valid_num      | 4948.0     |
| training/sac_Q/q1              | 189.04489  |
| training/sac_Q/q2              | 187.253    |
| training/sac_Q/q2_loss         | 91.90196   |
| training/sac_Q/q_global_norm   | 229.25479  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1687619  |
| epoch                          | 365        |
| evaluation/episode-length-avg  | 653        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 131        |
| evaluation/episode-length-std  | 425        |
| evaluation/return-average      | 2976.8313  |
| evaluation/return-max          | 4759.093   |
| evaluation/return-min          | 336.74673  |
| evaluation/return-std          | 2146.9563  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45721      |
| perf/AverageLength             | 653        |
| perf/AverageReturn             | 2976.8313  |
| perf/NormalizedReturn          | 0.648      |
| Q-avg                          | 187.31412  |
| Q-std                          | 137.36623  |
| Q_loss                         | 104.16802  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 365        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000277   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000608   |
| times/evaluation_paths         | 19.8       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 366000     |
| train-steps                    | 366000     |
| training/Q/q1_loss             | 104.44425  |
| training/sac_pi/alpha          | 0.1687855  |
| training/sac_pi/alpha_loss     | 0.17516495 |
| training/sac_pi/logp_pi        | 4.1954703  |
| training/sac_pi/pi_entropy     | 3.5354302  |
| training/sac_pi/pi_global_norm | 1.4857191  |
| training/sac_pi/policy_loss    | -203.55028 |
| training/sac_pi/std            | 0.50259775 |
| training/sac_pi/valid_num      | 5017.0     |
| training/sac_Q/q1              | 194.18567  |
| training/sac_Q/q2              | 192.83032  |
| training/sac_Q/q2_loss         | 103.362305 |
| training/sac_Q/q_global_norm   | 184.19688  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1594615   |
| epoch                          | 366         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4953.0513   |
| evaluation/return-max          | 4995.9253   |
| evaluation/return-min          | 4909.925    |
| evaluation/return-std          | 28.904911   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 82.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45645       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4953.0513   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 182.57094   |
| Q-std                          | 172.8069    |
| Q_loss                         | 88.646835   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 366         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.00015     |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000587    |
| times/evaluation_paths         | 30.1        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00792     |
| times/train                    | 53.8        |
| timestep                       | 1000        |
| timesteps_total                | 367000      |
| train-steps                    | 367000      |
| training/Q/q1_loss             | 92.14725    |
| training/sac_pi/alpha          | 0.15947442  |
| training/sac_pi/alpha_loss     | -0.28299177 |
| training/sac_pi/logp_pi        | 4.408498    |
| training/sac_pi/pi_entropy     | 3.5671043   |
| training/sac_pi/pi_global_norm | 1.3491913   |
| training/sac_pi/policy_loss    | -199.18623  |
| training/sac_pi/std            | 0.51357025  |
| training/sac_pi/valid_num      | 4916.0      |
| training/sac_Q/q1              | 187.72566   |
| training/sac_Q/q2              | 185.7817    |
| training/sac_Q/q2_loss         | 92.62715    |
| training/sac_Q/q_global_norm   | 237.93666   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16202281 |
| epoch                          | 367        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4672.562   |
| evaluation/return-max          | 4765.754   |
| evaluation/return-min          | 4622.286   |
| evaluation/return-std          | 41.870197  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45723      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4672.562   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 184.53683  |
| Q-std                          | 162.61835  |
| Q_loss                         | 102.16481  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 367        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000102   |
| times/epoch_rollout_model      | 475        |
| times/evaluation_metrics       | 0.000615   |
| times/evaluation_paths         | 29.8       |
| times/timestep_after_hook      | 0.00356    |
| times/timestep_before_hook     | 0.00769    |
| times/train                    | 54.8       |
| timestep                       | 1000       |
| timesteps_total                | 368000     |
| train-steps                    | 368000     |
| training/Q/q1_loss             | 90.04093   |
| training/sac_pi/alpha          | 0.16198325 |
| training/sac_pi/alpha_loss     | 0.35688323 |
| training/sac_pi/logp_pi        | 3.969833   |
| training/sac_pi/pi_entropy     | 3.575972   |
| training/sac_pi/pi_global_norm | 1.5402317  |
| training/sac_pi/policy_loss    | -203.51619 |
| training/sac_pi/std            | 0.48477527 |
| training/sac_pi/valid_num      | 5013.0     |
| training/sac_Q/q1              | 198.3316   |
| training/sac_Q/q2              | 198.51329  |
| training/sac_Q/q2_loss         | 90.068245  |
| training/sac_Q/q_global_norm   | 206.52753  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16215345  |
| epoch                          | 368         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4814.376    |
| evaluation/return-max          | 4910.925    |
| evaluation/return-min          | 4723.9756   |
| evaluation/return-std          | 56.02693    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45810       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4814.376    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 180.89696   |
| Q-std                          | 157.56633   |
| Q_loss                         | 103.28103   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 368         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000103    |
| times/epoch_rollout_model      | 475         |
| times/evaluation_metrics       | 0.000578    |
| times/evaluation_paths         | 29.7        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00794     |
| times/train                    | 54.1        |
| timestep                       | 1000        |
| timesteps_total                | 369000      |
| train-steps                    | 369000      |
| training/Q/q1_loss             | 107.65887   |
| training/sac_pi/alpha          | 0.16216859  |
| training/sac_pi/alpha_loss     | 0.057225164 |
| training/sac_pi/logp_pi        | 5.218394    |
| training/sac_pi/pi_entropy     | 3.4795518   |
| training/sac_pi/pi_global_norm | 1.6378671   |
| training/sac_pi/policy_loss    | -200.98796  |
| training/sac_pi/std            | 0.53287345  |
| training/sac_pi/valid_num      | 4878.0      |
| training/sac_Q/q1              | 180.1538    |
| training/sac_Q/q2              | 178.4253    |
| training/sac_Q/q2_loss         | 108.1722    |
| training/sac_Q/q_global_norm   | 206.63826   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1646965   |
| epoch                          | 369         |
| evaluation/episode-length-avg  | 562         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 139         |
| evaluation/episode-length-std  | 276         |
| evaluation/return-average      | 2485.8755   |
| evaluation/return-max          | 4639.1396   |
| evaluation/return-min          | 422.68405   |
| evaluation/return-std          | 1359.0927   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 82.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45665       |
| perf/AverageLength             | 562         |
| perf/AverageReturn             | 2485.8755   |
| perf/NormalizedReturn          | 0.541       |
| Q-avg                          | 191.12283   |
| Q-std                          | 116.14609   |
| Q_loss                         | 91.591095   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 369         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000281    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000547    |
| times/evaluation_paths         | 17.2        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00803     |
| times/train                    | 55.4        |
| timestep                       | 1000        |
| timesteps_total                | 370000      |
| train-steps                    | 370000      |
| training/Q/q1_loss             | 99.52785    |
| training/sac_pi/alpha          | 0.16472489  |
| training/sac_pi/alpha_loss     | -0.34234887 |
| training/sac_pi/logp_pi        | 4.8077517   |
| training/sac_pi/pi_entropy     | 3.5338295   |
| training/sac_pi/pi_global_norm | 1.6152403   |
| training/sac_pi/policy_loss    | -205.40533  |
| training/sac_pi/std            | 0.5401812   |
| training/sac_pi/valid_num      | 4875.0      |
| training/sac_Q/q1              | 184.21202   |
| training/sac_Q/q2              | 180.55522   |
| training/sac_Q/q2_loss         | 100.760735  |
| training/sac_Q/q_global_norm   | 273.20557   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16278353 |
| epoch                          | 370        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4869.765   |
| evaluation/return-max          | 4903.2217  |
| evaluation/return-min          | 4794.3564  |
| evaluation/return-std          | 34.52539   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45693      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4869.765   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 179.93033  |
| Q-std                          | 160.00682  |
| Q_loss                         | 114.879166 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 370        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000157   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.008      |
| times/train                    | 55.3       |
| timestep                       | 1000       |
| timesteps_total                | 371000     |
| train-steps                    | 371000     |
| training/Q/q1_loss             | 101.88809  |
| training/sac_pi/alpha          | 0.1627715  |
| training/sac_pi/alpha_loss     | 0.240004   |
| training/sac_pi/logp_pi        | 4.6306124  |
| training/sac_pi/pi_entropy     | 3.3188267  |
| training/sac_pi/pi_global_norm | 1.647563   |
| training/sac_pi/policy_loss    | -204.68686 |
| training/sac_pi/std            | 0.49295264 |
| training/sac_pi/valid_num      | 4939.0     |
| training/sac_Q/q1              | 187.65811  |
| training/sac_Q/q2              | 184.94754  |
| training/sac_Q/q2_loss         | 100.72062  |
| training/sac_Q/q_global_norm   | 223.52715  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16673064 |
| epoch                          | 371        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4927.247   |
| evaluation/return-max          | 4945.7354  |
| evaluation/return-min          | 4907.802   |
| evaluation/return-std          | 12.221439  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45551      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4927.247   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 193.82608  |
| Q-std                          | 145.21594  |
| Q_loss                         | 85.209274  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 371        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000552   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00798    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 372000     |
| train-steps                    | 372000     |
| training/Q/q1_loss             | 90.53661   |
| training/sac_pi/alpha          | 0.16672578 |
| training/sac_pi/alpha_loss     | 0.08297394 |
| training/sac_pi/logp_pi        | 5.3414016  |
| training/sac_pi/pi_entropy     | 3.5745323  |
| training/sac_pi/pi_global_norm | 1.5995947  |
| training/sac_pi/policy_loss    | -192.40901 |
| training/sac_pi/std            | 0.5321182  |
| training/sac_pi/valid_num      | 4856.0     |
| training/sac_Q/q1              | 172.97551  |
| training/sac_Q/q2              | 169.40848  |
| training/sac_Q/q2_loss         | 90.65849   |
| training/sac_Q/q_global_norm   | 196.60828  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16444156  |
| epoch                          | 372         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5134.779    |
| evaluation/return-max          | 5165.656    |
| evaluation/return-min          | 5103.2773   |
| evaluation/return-std          | 18.502634   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 82.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45553       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5134.779    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 184.43103   |
| Q-std                          | 147.74362   |
| Q_loss                         | 113.80143   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 372         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000591    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00789     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 373000      |
| train-steps                    | 373000      |
| training/Q/q1_loss             | 134.36613   |
| training/sac_pi/alpha          | 0.16445148  |
| training/sac_pi/alpha_loss     | -0.23974514 |
| training/sac_pi/logp_pi        | 3.6201317   |
| training/sac_pi/pi_entropy     | 3.5668817   |
| training/sac_pi/pi_global_norm | 1.6033682   |
| training/sac_pi/policy_loss    | -191.52351  |
| training/sac_pi/std            | 0.48217604  |
| training/sac_pi/valid_num      | 4975.0      |
| training/sac_Q/q1              | 183.66759   |
| training/sac_Q/q2              | 183.00146   |
| training/sac_Q/q2_loss         | 134.37068   |
| training/sac_Q/q_global_norm   | 199.88403   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16852549 |
| epoch                          | 373        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4884.032   |
| evaluation/return-max          | 4935.3867  |
| evaluation/return-min          | 4832.335   |
| evaluation/return-std          | 32.08571   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45666      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4884.032   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 186.33823  |
| Q-std                          | 141.71338  |
| Q_loss                         | 103.92956  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 373        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000277   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000546   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00796    |
| times/train                    | 52.9       |
| timestep                       | 1000       |
| timesteps_total                | 374000     |
| train-steps                    | 374000     |
| training/Q/q1_loss             | 118.893456 |
| training/sac_pi/alpha          | 0.16853037 |
| training/sac_pi/alpha_loss     | 0.1014987  |
| training/sac_pi/logp_pi        | 4.618833   |
| training/sac_pi/pi_entropy     | 3.6622627  |
| training/sac_pi/pi_global_norm | 1.5472515  |
| training/sac_pi/policy_loss    | -194.79895 |
| training/sac_pi/std            | 0.538594   |
| training/sac_pi/valid_num      | 4911.0     |
| training/sac_Q/q1              | 177.023    |
| training/sac_Q/q2              | 173.80176  |
| training/sac_Q/q2_loss         | 118.49632  |
| training/sac_Q/q_global_norm   | 210.8121   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16764171   |
| epoch                          | 374          |
| evaluation/episode-length-avg  | 216          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 123          |
| evaluation/episode-length-std  | 261          |
| evaluation/return-average      | 793.0846     |
| evaluation/return-max          | 4908.299     |
| evaluation/return-min          | 315.00912    |
| evaluation/return-std          | 1371.892     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.87         |
| model/origin_ret               | 84.5         |
| model/penalty_ret              | 82.1         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45463        |
| perf/AverageLength             | 216          |
| perf/AverageReturn             | 793.0846     |
| perf/NormalizedReturn          | 0.172        |
| Q-avg                          | 182.07916    |
| Q-std                          | 169.63898    |
| Q_loss                         | 103.65059    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 374          |
| times/epoch_after_hook         | 1.77e-06     |
| times/epoch_before_hook        | 0.000111     |
| times/epoch_rollout_model      | 475          |
| times/evaluation_metrics       | 0.000482     |
| times/evaluation_paths         | 6.51         |
| times/timestep_after_hook      | 0.00361      |
| times/timestep_before_hook     | 0.0078       |
| times/train                    | 53.1         |
| timestep                       | 1000         |
| timesteps_total                | 375000       |
| train-steps                    | 375000       |
| training/Q/q1_loss             | 115.48048    |
| training/sac_pi/alpha          | 0.16764887   |
| training/sac_pi/alpha_loss     | -0.098054394 |
| training/sac_pi/logp_pi        | 4.812398     |
| training/sac_pi/pi_entropy     | 3.494121     |
| training/sac_pi/pi_global_norm | 1.3523009    |
| training/sac_pi/policy_loss    | -208.1591    |
| training/sac_pi/std            | 0.5305269    |
| training/sac_pi/valid_num      | 4939.0       |
| training/sac_Q/q1              | 188.98299    |
| training/sac_Q/q2              | 184.71387    |
| training/sac_Q/q2_loss         | 116.081795   |
| training/sac_Q/q_global_norm   | 290.21664    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16788426 |
| epoch                          | 375        |
| evaluation/episode-length-avg  | 829        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 145        |
| evaluation/episode-length-std  | 341        |
| evaluation/return-average      | 3824.4812  |
| evaluation/return-max          | 4714.4453  |
| evaluation/return-min          | 395.78784  |
| evaluation/return-std          | 1713.6262  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45635      |
| perf/AverageLength             | 829        |
| perf/AverageReturn             | 3824.4812  |
| perf/NormalizedReturn          | 0.833      |
| Q-avg                          | 172.8372   |
| Q-std                          | 184.60928  |
| Q_loss                         | 97.68165   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 375        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000103   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000596   |
| times/evaluation_paths         | 25.3       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00771    |
| times/train                    | 55.2       |
| timestep                       | 1000       |
| timesteps_total                | 376000     |
| train-steps                    | 376000     |
| training/Q/q1_loss             | 101.68237  |
| training/sac_pi/alpha          | 0.16790922 |
| training/sac_pi/alpha_loss     | -0.1576801 |
| training/sac_pi/logp_pi        | 5.491061   |
| training/sac_pi/pi_entropy     | 3.588472   |
| training/sac_pi/pi_global_norm | 1.3715887  |
| training/sac_pi/policy_loss    | -201.0642  |
| training/sac_pi/std            | 0.5639718  |
| training/sac_pi/valid_num      | 4888.0     |
| training/sac_Q/q1              | 179.24806  |
| training/sac_Q/q2              | 172.51114  |
| training/sac_Q/q2_loss         | 101.8087   |
| training/sac_Q/q_global_norm   | 195.72456  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16942666 |
| epoch                          | 376        |
| evaluation/episode-length-avg  | 570        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 134        |
| evaluation/episode-length-std  | 430        |
| evaluation/return-average      | 2504.8787  |
| evaluation/return-max          | 4768.371   |
| evaluation/return-min          | 322.67737  |
| evaluation/return-std          | 2155.276   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45656      |
| perf/AverageLength             | 570        |
| perf/AverageReturn             | 2504.8787  |
| perf/NormalizedReturn          | 0.545      |
| Q-avg                          | 178.9373   |
| Q-std                          | 192.95888  |
| Q_loss                         | 103.9485   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 376        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000101   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.00052    |
| times/evaluation_paths         | 17.5       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00797    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 377000     |
| train-steps                    | 377000     |
| training/Q/q1_loss             | 97.6076    |
| training/sac_pi/alpha          | 0.16938552 |
| training/sac_pi/alpha_loss     | 0.21104257 |
| training/sac_pi/logp_pi        | 4.532893   |
| training/sac_pi/pi_entropy     | 3.6518238  |
| training/sac_pi/pi_global_norm | 1.7105654  |
| training/sac_pi/policy_loss    | -194.70378 |
| training/sac_pi/std            | 0.5230144  |
| training/sac_pi/valid_num      | 4909.0     |
| training/sac_Q/q1              | 182.82376  |
| training/sac_Q/q2              | 182.09988  |
| training/sac_Q/q2_loss         | 97.219765  |
| training/sac_Q/q_global_norm   | 211.34615  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17087328  |
| epoch                          | 377         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4815.132    |
| evaluation/return-max          | 4867.449    |
| evaluation/return-min          | 4776.217    |
| evaluation/return-std          | 29.564838   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45738       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4815.132    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 190.55856   |
| Q-std                          | 147.2667    |
| Q_loss                         | 85.45559    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 377         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.00033     |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000589    |
| times/evaluation_paths         | 30.4        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00792     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 378000      |
| train-steps                    | 378000      |
| training/Q/q1_loss             | 106.27637   |
| training/sac_pi/alpha          | 0.17089741  |
| training/sac_pi/alpha_loss     | -0.10658186 |
| training/sac_pi/logp_pi        | 4.4484577   |
| training/sac_pi/pi_entropy     | 3.5020912   |
| training/sac_pi/pi_global_norm | 1.77654     |
| training/sac_pi/policy_loss    | -198.33887  |
| training/sac_pi/std            | 0.501817    |
| training/sac_pi/valid_num      | 4997.0      |
| training/sac_Q/q1              | 189.89767   |
| training/sac_Q/q2              | 187.28601   |
| training/sac_Q/q2_loss         | 105.558495  |
| training/sac_Q/q_global_norm   | 210.03983   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17124526  |
| epoch                          | 378         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4816.3413   |
| evaluation/return-max          | 4871.249    |
| evaluation/return-min          | 4777.828    |
| evaluation/return-std          | 28.138636   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45666       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4816.3413   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 190.33925   |
| Q-std                          | 123.00598   |
| Q_loss                         | 99.01218    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 378         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 504         |
| times/evaluation_metrics       | 0.000641    |
| times/evaluation_paths         | 30.3        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 379000      |
| train-steps                    | 379000      |
| training/Q/q1_loss             | 102.80195   |
| training/sac_pi/alpha          | 0.1712801   |
| training/sac_pi/alpha_loss     | -0.39336523 |
| training/sac_pi/logp_pi        | 4.526145    |
| training/sac_pi/pi_entropy     | 3.5450733   |
| training/sac_pi/pi_global_norm | 2.2455919   |
| training/sac_pi/policy_loss    | -206.8108   |
| training/sac_pi/std            | 0.5402471   |
| training/sac_pi/valid_num      | 4924.0      |
| training/sac_Q/q1              | 189.34416   |
| training/sac_Q/q2              | 181.28735   |
| training/sac_Q/q2_loss         | 103.01057   |
| training/sac_Q/q_global_norm   | 256.05377   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17225069  |
| epoch                          | 379         |
| evaluation/episode-length-avg  | 922         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 696         |
| evaluation/episode-length-std  | 111         |
| evaluation/return-average      | 4696.756    |
| evaluation/return-max          | 5209.386    |
| evaluation/return-min          | 3388.9294   |
| evaluation/return-std          | 649.67145   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.85        |
| model/origin_ret               | 82.5        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45641       |
| perf/AverageLength             | 922         |
| perf/AverageReturn             | 4696.756    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 172.49463   |
| Q-std                          | 205.63762   |
| Q_loss                         | 106.6978    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 379         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000108    |
| times/epoch_rollout_model      | 475         |
| times/evaluation_metrics       | 0.000559    |
| times/evaluation_paths         | 27.6        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00805     |
| times/train                    | 53.6        |
| timestep                       | 1000        |
| timesteps_total                | 380000      |
| train-steps                    | 380000      |
| training/Q/q1_loss             | 122.75676   |
| training/sac_pi/alpha          | 0.17222653  |
| training/sac_pi/alpha_loss     | 0.032878716 |
| training/sac_pi/logp_pi        | 5.4648266   |
| training/sac_pi/pi_entropy     | 3.6964653   |
| training/sac_pi/pi_global_norm | 1.3958882   |
| training/sac_pi/policy_loss    | -195.16298  |
| training/sac_pi/std            | 0.56390935  |
| training/sac_pi/valid_num      | 4893.0      |
| training/sac_Q/q1              | 173.33655   |
| training/sac_Q/q2              | 171.13327   |
| training/sac_Q/q2_loss         | 122.39803   |
| training/sac_Q/q_global_norm   | 223.98239   |
---------------------------------------------------------------------------------
[WARN] 380 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.1674234   |
| epoch                          | 380         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4976.0244   |
| evaluation/return-max          | 4998.008    |
| evaluation/return-min          | 4948.7925   |
| evaluation/return-std          | 14.746037   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45383       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4976.0244   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 181.19028   |
| Q-std                          | 164.44122   |
| Q_loss                         | 106.10035   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 380         |
| times/epoch_after_hook         | 1.59e-06    |
| times/epoch_before_hook        | 0.000102    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000548    |
| times/evaluation_paths         | 30.5        |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00794     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 381000      |
| train-steps                    | 381000      |
| training/Q/q1_loss             | 107.600845  |
| training/sac_pi/alpha          | 0.1674274   |
| training/sac_pi/alpha_loss     | -0.22576188 |
| training/sac_pi/logp_pi        | 6.599649    |
| training/sac_pi/pi_entropy     | 3.573548    |
| training/sac_pi/pi_global_norm | 1.762159    |
| training/sac_pi/policy_loss    | -201.20497  |
| training/sac_pi/std            | 0.5914484   |
| training/sac_pi/valid_num      | 4813.0      |
| training/sac_Q/q1              | 173.31502   |
| training/sac_Q/q2              | 169.89017   |
| training/sac_Q/q2_loss         | 107.16491   |
| training/sac_Q/q_global_norm   | 230.83961   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1659336   |
| epoch                          | 381         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4838.0737   |
| evaluation/return-max          | 4881.835    |
| evaluation/return-min          | 4762.491    |
| evaluation/return-std          | 36.142998   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45613       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4838.0737   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 180.7119    |
| Q-std                          | 136.14958   |
| Q_loss                         | 102.80603   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 381         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.00028     |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 30.5        |
| times/timestep_after_hook      | 0.00357     |
| times/timestep_before_hook     | 0.00791     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 382000      |
| train-steps                    | 382000      |
| training/Q/q1_loss             | 105.81869   |
| training/sac_pi/alpha          | 0.16594096  |
| training/sac_pi/alpha_loss     | -0.11132571 |
| training/sac_pi/logp_pi        | 6.069104    |
| training/sac_pi/pi_entropy     | 3.5800426   |
| training/sac_pi/pi_global_norm | 1.3777444   |
| training/sac_pi/policy_loss    | -196.69948  |
| training/sac_pi/std            | 0.57316375  |
| training/sac_pi/valid_num      | 4829.0      |
| training/sac_Q/q1              | 173.699     |
| training/sac_Q/q2              | 170.39761   |
| training/sac_Q/q2_loss         | 106.565475  |
| training/sac_Q/q_global_norm   | 184.1172    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16620773 |
| epoch                          | 382        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4608.4287  |
| evaluation/return-max          | 4702.9194  |
| evaluation/return-min          | 4501.8066  |
| evaluation/return-std          | 46.43704   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45551      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4608.4287  |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 178.77327  |
| Q-std                          | 184.11224  |
| Q_loss                         | 82.39237   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 382        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 8.29e-05   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000571   |
| times/evaluation_paths         | 30.1       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00774    |
| times/train                    | 55.4       |
| timestep                       | 1000       |
| timesteps_total                | 383000     |
| train-steps                    | 383000     |
| training/Q/q1_loss             | 100.21606  |
| training/sac_pi/alpha          | 0.16616598 |
| training/sac_pi/alpha_loss     | 0.64300394 |
| training/sac_pi/logp_pi        | 4.6834927  |
| training/sac_pi/pi_entropy     | 3.4013672  |
| training/sac_pi/pi_global_norm | 1.4863963  |
| training/sac_pi/policy_loss    | -202.77036 |
| training/sac_pi/std            | 0.49296415 |
| training/sac_pi/valid_num      | 4996.0     |
| training/sac_Q/q1              | 191.46709  |
| training/sac_Q/q2              | 190.6342   |
| training/sac_Q/q2_loss         | 100.27861  |
| training/sac_Q/q_global_norm   | 237.79504  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16871274  |
| epoch                          | 383         |
| evaluation/episode-length-avg  | 418         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 161         |
| evaluation/episode-length-std  | 381         |
| evaluation/return-average      | 1581.553    |
| evaluation/return-max          | 4513.351    |
| evaluation/return-min          | 355.78302   |
| evaluation/return-std          | 1841.5314   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45566       |
| perf/AverageLength             | 418         |
| perf/AverageReturn             | 1581.553    |
| perf/NormalizedReturn          | 0.344       |
| Q-avg                          | 178.67255   |
| Q-std                          | 182.25655   |
| Q_loss                         | 111.92112   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 383         |
| times/epoch_after_hook         | 3.3e-06     |
| times/epoch_before_hook        | 0.000107    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000575    |
| times/evaluation_paths         | 12.6        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00786     |
| times/train                    | 55.2        |
| timestep                       | 1000        |
| timesteps_total                | 384000      |
| train-steps                    | 384000      |
| training/Q/q1_loss             | 92.68548    |
| training/sac_pi/alpha          | 0.16872795  |
| training/sac_pi/alpha_loss     | -0.17784914 |
| training/sac_pi/logp_pi        | 4.927896    |
| training/sac_pi/pi_entropy     | 3.6316197   |
| training/sac_pi/pi_global_norm | 1.7428057   |
| training/sac_pi/policy_loss    | -197.58723  |
| training/sac_pi/std            | 0.5368993   |
| training/sac_pi/valid_num      | 4944.0      |
| training/sac_Q/q1              | 182.33282   |
| training/sac_Q/q2              | 179.67703   |
| training/sac_Q/q2_loss         | 92.589424   |
| training/sac_Q/q_global_norm   | 195.38991   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16457412   |
| epoch                          | 384          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4618.032     |
| evaluation/return-max          | 4721.258     |
| evaluation/return-min          | 4556.067     |
| evaluation/return-std          | 56.161705    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.89         |
| model/origin_ret               | 83.5         |
| model/penalty_ret              | 81.4         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45603        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4618.032     |
| perf/NormalizedReturn          | 1.01         |
| Q-avg                          | 189.99582    |
| Q-std                          | 135.69263    |
| Q_loss                         | 88.70846     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 384          |
| times/epoch_after_hook         | 1.86e-06     |
| times/epoch_before_hook        | 0.000102     |
| times/epoch_rollout_model      | 476          |
| times/evaluation_metrics       | 0.000575     |
| times/evaluation_paths         | 30.4         |
| times/timestep_after_hook      | 0.00366      |
| times/timestep_before_hook     | 0.00806      |
| times/train                    | 53.7         |
| timestep                       | 1000         |
| timesteps_total                | 385000       |
| train-steps                    | 385000       |
| training/Q/q1_loss             | 89.76004     |
| training/sac_pi/alpha          | 0.16459133   |
| training/sac_pi/alpha_loss     | -0.053500094 |
| training/sac_pi/logp_pi        | 4.5130935    |
| training/sac_pi/pi_entropy     | 3.5901723    |
| training/sac_pi/pi_global_norm | 1.6351043    |
| training/sac_pi/policy_loss    | -195.57936   |
| training/sac_pi/std            | 0.51980287   |
| training/sac_pi/valid_num      | 4896.0       |
| training/sac_Q/q1              | 177.30429    |
| training/sac_Q/q2              | 174.64015    |
| training/sac_Q/q2_loss         | 90.508224    |
| training/sac_Q/q_global_norm   | 306.70016    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17281216  |
| epoch                          | 385         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5038.3604   |
| evaluation/return-max          | 5065.206    |
| evaluation/return-min          | 5016.7466   |
| evaluation/return-std          | 14.962646   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.89        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45596       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5038.3604   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 182.92036   |
| Q-std                          | 173.533     |
| Q_loss                         | 112.35715   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 385         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000273    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 386000      |
| train-steps                    | 386000      |
| training/Q/q1_loss             | 81.41762    |
| training/sac_pi/alpha          | 0.1728126   |
| training/sac_pi/alpha_loss     | -0.30564564 |
| training/sac_pi/logp_pi        | 4.998665    |
| training/sac_pi/pi_entropy     | 3.6964364   |
| training/sac_pi/pi_global_norm | 1.5290858   |
| training/sac_pi/policy_loss    | -202.7222   |
| training/sac_pi/std            | 0.56016815  |
| training/sac_pi/valid_num      | 4913.0      |
| training/sac_Q/q1              | 180.6742    |
| training/sac_Q/q2              | 177.87184   |
| training/sac_Q/q2_loss         | 82.44455    |
| training/sac_Q/q_global_norm   | 168.15831   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17249572  |
| epoch                          | 386         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4792.1816   |
| evaluation/return-max          | 4816.3      |
| evaluation/return-min          | 4746.337    |
| evaluation/return-std          | 21.652534   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45554       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4792.1816   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 194.86076   |
| Q-std                          | 141.97284   |
| Q_loss                         | 114.47863   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 386         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 472         |
| times/evaluation_metrics       | 0.000545    |
| times/evaluation_paths         | 31.1        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 56.6        |
| timestep                       | 1000        |
| timesteps_total                | 387000      |
| train-steps                    | 387000      |
| training/Q/q1_loss             | 78.107285   |
| training/sac_pi/alpha          | 0.17249656  |
| training/sac_pi/alpha_loss     | -0.42653483 |
| training/sac_pi/logp_pi        | 4.7341185   |
| training/sac_pi/pi_entropy     | 3.6880596   |
| training/sac_pi/pi_global_norm | 1.664896    |
| training/sac_pi/policy_loss    | -195.6896   |
| training/sac_pi/std            | 0.5540988   |
| training/sac_pi/valid_num      | 4883.0      |
| training/sac_Q/q1              | 175.77744   |
| training/sac_Q/q2              | 176.73984   |
| training/sac_Q/q2_loss         | 78.00226    |
| training/sac_Q/q_global_norm   | 197.74832   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16695027 |
| epoch                          | 387        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4483.093   |
| evaluation/return-max          | 4544.593   |
| evaluation/return-min          | 4391.8184  |
| evaluation/return-std          | 38.776436  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 87         |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45519      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4483.093   |
| perf/NormalizedReturn          | 0.976      |
| Q-avg                          | 186.32089  |
| Q-std                          | 146.27925  |
| Q_loss                         | 105.886055 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 387        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000103   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000608   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00797    |
| times/train                    | 56.6       |
| timestep                       | 1000       |
| timesteps_total                | 388000     |
| train-steps                    | 388000     |
| training/Q/q1_loss             | 100.257774 |
| training/sac_pi/alpha          | 0.16692653 |
| training/sac_pi/alpha_loss     | 0.5854529  |
| training/sac_pi/logp_pi        | 4.8326683  |
| training/sac_pi/pi_entropy     | 3.66174    |
| training/sac_pi/pi_global_norm | 1.7588845  |
| training/sac_pi/policy_loss    | -202.20982 |
| training/sac_pi/std            | 0.5507246  |
| training/sac_pi/valid_num      | 4942.0     |
| training/sac_Q/q1              | 185.75708  |
| training/sac_Q/q2              | 183.75868  |
| training/sac_Q/q2_loss         | 99.85092   |
| training/sac_Q/q_global_norm   | 266.23373  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17037515  |
| epoch                          | 388         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4797.6436   |
| evaluation/return-max          | 4846.462    |
| evaluation/return-min          | 4709.6562   |
| evaluation/return-std          | 47.50328    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.87        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45514       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4797.6436   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 173.83403   |
| Q-std                          | 207.76785   |
| Q_loss                         | 104.60903   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 388         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000571    |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00809     |
| times/train                    | 56.5        |
| timestep                       | 1000        |
| timesteps_total                | 389000      |
| train-steps                    | 389000      |
| training/Q/q1_loss             | 100.005196  |
| training/sac_pi/alpha          | 0.17037068  |
| training/sac_pi/alpha_loss     | -0.15584698 |
| training/sac_pi/logp_pi        | 5.1429014   |
| training/sac_pi/pi_entropy     | 3.6310055   |
| training/sac_pi/pi_global_norm | 1.5384637   |
| training/sac_pi/policy_loss    | -198.58517  |
| training/sac_pi/std            | 0.55646425  |
| training/sac_pi/valid_num      | 4924.0      |
| training/sac_Q/q1              | 181.77641   |
| training/sac_Q/q2              | 178.02457   |
| training/sac_Q/q2_loss         | 100.08783   |
| training/sac_Q/q_global_norm   | 197.73      |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16777685  |
| epoch                          | 389         |
| evaluation/episode-length-avg  | 679         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 148         |
| evaluation/episode-length-std  | 396         |
| evaluation/return-average      | 3157.342    |
| evaluation/return-max          | 4883.452    |
| evaluation/return-min          | 415.19006   |
| evaluation/return-std          | 2073.5652   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45733       |
| perf/AverageLength             | 679         |
| perf/AverageReturn             | 3157.342    |
| perf/NormalizedReturn          | 0.687       |
| Q-avg                          | 177.65872   |
| Q-std                          | 169.40442   |
| Q_loss                         | 118.74561   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 389         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000282    |
| times/epoch_rollout_model      | 476         |
| times/evaluation_metrics       | 0.000481    |
| times/evaluation_paths         | 20.8        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00805     |
| times/train                    | 56.7        |
| timestep                       | 1000        |
| timesteps_total                | 390000      |
| train-steps                    | 390000      |
| training/Q/q1_loss             | 109.19401   |
| training/sac_pi/alpha          | 0.16779603  |
| training/sac_pi/alpha_loss     | 0.011437744 |
| training/sac_pi/logp_pi        | 4.2475204   |
| training/sac_pi/pi_entropy     | 3.5470397   |
| training/sac_pi/pi_global_norm | 1.5907521   |
| training/sac_pi/policy_loss    | -197.85686  |
| training/sac_pi/std            | 0.5046976   |
| training/sac_pi/valid_num      | 4976.0      |
| training/sac_Q/q1              | 187.21568   |
| training/sac_Q/q2              | 185.00705   |
| training/sac_Q/q2_loss         | 111.06259   |
| training/sac_Q/q_global_norm   | 306.36182   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16628551 |
| epoch                          | 390        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4938.7656  |
| evaluation/return-max          | 4950.4595  |
| evaluation/return-min          | 4915.6523  |
| evaluation/return-std          | 10.621096  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45873      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4938.7656  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 182.76009  |
| Q-std                          | 162.62373  |
| Q_loss                         | 96.469025  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 390        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.0001     |
| times/epoch_rollout_model      | 474        |
| times/evaluation_metrics       | 0.000546   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00381    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 55.2       |
| timestep                       | 1000       |
| timesteps_total                | 391000     |
| train-steps                    | 391000     |
| training/Q/q1_loss             | 111.07541  |
| training/sac_pi/alpha          | 0.16632478 |
| training/sac_pi/alpha_loss     | -0.6233233 |
| training/sac_pi/logp_pi        | 4.949575   |
| training/sac_pi/pi_entropy     | 3.5100098  |
| training/sac_pi/pi_global_norm | 1.7944331  |
| training/sac_pi/policy_loss    | -197.20084 |
| training/sac_pi/std            | 0.5328689  |
| training/sac_pi/valid_num      | 4880.0     |
| training/sac_Q/q1              | 176.8909   |
| training/sac_Q/q2              | 174.71619  |
| training/sac_Q/q2_loss         | 112.11766  |
| training/sac_Q/q_global_norm   | 170.0795   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16981697  |
| epoch                          | 391         |
| evaluation/episode-length-avg  | 744         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 145         |
| evaluation/episode-length-std  | 391         |
| evaluation/return-average      | 3467.489    |
| evaluation/return-max          | 4777.835    |
| evaluation/return-min          | 435.09186   |
| evaluation/return-std          | 1976.2151   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45677       |
| perf/AverageLength             | 744         |
| perf/AverageReturn             | 3467.489    |
| perf/NormalizedReturn          | 0.755       |
| Q-avg                          | 183.84631   |
| Q-std                          | 156.10732   |
| Q_loss                         | 100.38628   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 391         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000143    |
| times/epoch_rollout_model      | 475         |
| times/evaluation_metrics       | 0.000487    |
| times/evaluation_paths         | 23.4        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 56.1        |
| timestep                       | 1000        |
| timesteps_total                | 392000      |
| train-steps                    | 392000      |
| training/Q/q1_loss             | 101.96744   |
| training/sac_pi/alpha          | 0.16977774  |
| training/sac_pi/alpha_loss     | 0.031959813 |
| training/sac_pi/logp_pi        | 3.8040092   |
| training/sac_pi/pi_entropy     | 3.5922005   |
| training/sac_pi/pi_global_norm | 1.4675028   |
| training/sac_pi/policy_loss    | -194.09547  |
| training/sac_pi/std            | 0.49854884  |
| training/sac_pi/valid_num      | 5024.0      |
| training/sac_Q/q1              | 186.3409    |
| training/sac_Q/q2              | 186.00098   |
| training/sac_Q/q2_loss         | 103.600044  |
| training/sac_Q/q_global_norm   | 191.855     |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1707891  |
| epoch                          | 392        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4990.7275  |
| evaluation/return-max          | 5015.248   |
| evaluation/return-min          | 4932.1064  |
| evaluation/return-std          | 24.688942  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45701      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4990.7275  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 183.68556  |
| Q-std                          | 154.7294   |
| Q_loss                         | 92.405945  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 392        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 6.76e-05   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000601   |
| times/evaluation_paths         | 30.9       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00801    |
| times/train                    | 56.5       |
| timestep                       | 1000       |
| timesteps_total                | 393000     |
| train-steps                    | 393000     |
| training/Q/q1_loss             | 110.88275  |
| training/sac_pi/alpha          | 0.17083119 |
| training/sac_pi/alpha_loss     | -0.1675926 |
| training/sac_pi/logp_pi        | 5.270751   |
| training/sac_pi/pi_entropy     | 3.7004058  |
| training/sac_pi/pi_global_norm | 1.6008832  |
| training/sac_pi/policy_loss    | -204.24619 |
| training/sac_pi/std            | 0.5635947  |
| training/sac_pi/valid_num      | 4887.0     |
| training/sac_Q/q1              | 182.31851  |
| training/sac_Q/q2              | 176.50748  |
| training/sac_Q/q2_loss         | 109.4082   |
| training/sac_Q/q_global_norm   | 251.96349  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16426757   |
| epoch                          | 393          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5013.8057    |
| evaluation/return-max          | 5048.8887    |
| evaluation/return-min          | 4947.1123    |
| evaluation/return-std          | 30.79585     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.97         |
| model/origin_ret               | 85.1         |
| model/penalty_ret              | 82.1         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45621        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5013.8057    |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 185.75198    |
| Q-std                          | 146.00537    |
| Q_loss                         | 113.64994    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 393          |
| times/epoch_after_hook         | 3.45e-06     |
| times/epoch_before_hook        | 0.000286     |
| times/epoch_rollout_model      | 481          |
| times/evaluation_metrics       | 0.000553     |
| times/evaluation_paths         | 30.7         |
| times/timestep_after_hook      | 0.00365      |
| times/timestep_before_hook     | 0.00799      |
| times/train                    | 56.6         |
| timestep                       | 1000         |
| timesteps_total                | 394000       |
| train-steps                    | 394000       |
| training/Q/q1_loss             | 103.94535    |
| training/sac_pi/alpha          | 0.16426371   |
| training/sac_pi/alpha_loss     | -0.054472946 |
| training/sac_pi/logp_pi        | 4.297153     |
| training/sac_pi/pi_entropy     | 3.5706303    |
| training/sac_pi/pi_global_norm | 1.5751001    |
| training/sac_pi/policy_loss    | -202.12862   |
| training/sac_pi/std            | 0.5141743    |
| training/sac_pi/valid_num      | 4947.0       |
| training/sac_Q/q1              | 188.57315    |
| training/sac_Q/q2              | 186.32736    |
| training/sac_Q/q2_loss         | 102.82971    |
| training/sac_Q/q_global_norm   | 264.28192    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16800745 |
| epoch                          | 394        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4728.1333  |
| evaluation/return-max          | 4754.752   |
| evaluation/return-min          | 4709.363   |
| evaluation/return-std          | 13.895794  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45666      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4728.1333  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 192.60635  |
| Q-std                          | 134.27754  |
| Q_loss                         | 101.45357  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 394        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 475        |
| times/evaluation_metrics       | 0.000577   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 56.4       |
| timestep                       | 1000       |
| timesteps_total                | 395000     |
| train-steps                    | 395000     |
| training/Q/q1_loss             | 94.147804  |
| training/sac_pi/alpha          | 0.16803306 |
| training/sac_pi/alpha_loss     | 0.277286   |
| training/sac_pi/logp_pi        | 4.516065   |
| training/sac_pi/pi_entropy     | 3.4337165  |
| training/sac_pi/pi_global_norm | 1.5508931  |
| training/sac_pi/policy_loss    | -202.85234 |
| training/sac_pi/std            | 0.49874845 |
| training/sac_pi/valid_num      | 5013.0     |
| training/sac_Q/q1              | 193.73805  |
| training/sac_Q/q2              | 191.66934  |
| training/sac_Q/q2_loss         | 94.17036   |
| training/sac_Q/q_global_norm   | 209.78784  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16544703 |
| epoch                          | 395        |
| evaluation/episode-length-avg  | 473        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 120        |
| evaluation/episode-length-std  | 431        |
| evaluation/return-average      | 2150.1997  |
| evaluation/return-max          | 4998.87    |
| evaluation/return-min          | 265.52484  |
| evaluation/return-std          | 2298.7334  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45579      |
| perf/AverageLength             | 473        |
| perf/AverageReturn             | 2150.1997  |
| perf/NormalizedReturn          | 0.468      |
| Q-avg                          | 191.44217  |
| Q-std                          | 140.15018  |
| Q_loss                         | 87.76559   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 395        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000498   |
| times/evaluation_paths         | 14.8       |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.00809    |
| times/train                    | 56.7       |
| timestep                       | 1000       |
| timesteps_total                | 396000     |
| train-steps                    | 396000     |
| training/Q/q1_loss             | 122.714355 |
| training/sac_pi/alpha          | 0.16543719 |
| training/sac_pi/alpha_loss     | 0.5265386  |
| training/sac_pi/logp_pi        | 5.0238676  |
| training/sac_pi/pi_entropy     | 3.4930687  |
| training/sac_pi/pi_global_norm | 1.4516788  |
| training/sac_pi/policy_loss    | -202.07564 |
| training/sac_pi/std            | 0.50486153 |
| training/sac_pi/valid_num      | 4927.0     |
| training/sac_Q/q1              | 186.45149  |
| training/sac_Q/q2              | 184.548    |
| training/sac_Q/q2_loss         | 122.16907  |
| training/sac_Q/q_global_norm   | 256.3714   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16772571 |
| epoch                          | 396        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4826.8345  |
| evaluation/return-max          | 4940.1567  |
| evaluation/return-min          | 4676.95    |
| evaluation/return-std          | 61.763523  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 83.3       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45706      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4826.8345  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 189.26518  |
| Q-std                          | 148.49623  |
| Q_loss                         | 88.37467   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 396        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000102   |
| times/epoch_rollout_model      | 475        |
| times/evaluation_metrics       | 0.000535   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.0079     |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 397000     |
| train-steps                    | 397000     |
| training/Q/q1_loss             | 108.05644  |
| training/sac_pi/alpha          | 0.16772123 |
| training/sac_pi/alpha_loss     | 0.45556617 |
| training/sac_pi/logp_pi        | 4.438674   |
| training/sac_pi/pi_entropy     | 3.527806   |
| training/sac_pi/pi_global_norm | 1.9881411  |
| training/sac_pi/policy_loss    | -195.80595 |
| training/sac_pi/std            | 0.50127923 |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 186.2167   |
| training/sac_Q/q2              | 186.4281   |
| training/sac_Q/q2_loss         | 108.51671  |
| training/sac_Q/q_global_norm   | 260.89517  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16980775 |
| epoch                          | 397        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4664.133   |
| evaluation/return-max          | 4702.5117  |
| evaluation/return-min          | 4642.168   |
| evaluation/return-std          | 20.80159   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45735      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4664.133   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 191.19646  |
| Q-std                          | 176.1723   |
| Q_loss                         | 86.66231   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 397        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000276   |
| times/epoch_rollout_model      | 470        |
| times/evaluation_metrics       | 0.000528   |
| times/evaluation_paths         | 31.1       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 57.6       |
| timestep                       | 1000       |
| timesteps_total                | 398000     |
| train-steps                    | 398000     |
| training/Q/q1_loss             | 75.088585  |
| training/sac_pi/alpha          | 0.16978747 |
| training/sac_pi/alpha_loss     | 0.29595137 |
| training/sac_pi/logp_pi        | 4.245465   |
| training/sac_pi/pi_entropy     | 3.3859406  |
| training/sac_pi/pi_global_norm | 1.4730518  |
| training/sac_pi/policy_loss    | -204.45975 |
| training/sac_pi/std            | 0.4731395  |
| training/sac_pi/valid_num      | 4996.0     |
| training/sac_Q/q1              | 195.56425  |
| training/sac_Q/q2              | 195.09985  |
| training/sac_Q/q2_loss         | 75.29186   |
| training/sac_Q/q_global_norm   | 190.62962  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17267755  |
| epoch                          | 398         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4876.093    |
| evaluation/return-max          | 4917.826    |
| evaluation/return-min          | 4840.674    |
| evaluation/return-std          | 24.349203   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 82.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45510       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4876.093    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 182.94778   |
| Q-std                          | 157.87529   |
| Q_loss                         | 101.62756   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 398         |
| times/epoch_after_hook         | 2.01e-06    |
| times/epoch_before_hook        | 0.000136    |
| times/epoch_rollout_model      | 472         |
| times/evaluation_metrics       | 0.000524    |
| times/evaluation_paths         | 30.2        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00795     |
| times/train                    | 55.7        |
| timestep                       | 1000        |
| timesteps_total                | 399000      |
| train-steps                    | 399000      |
| training/Q/q1_loss             | 96.107925   |
| training/sac_pi/alpha          | 0.17265508  |
| training/sac_pi/alpha_loss     | -0.07778163 |
| training/sac_pi/logp_pi        | 5.5438166   |
| training/sac_pi/pi_entropy     | 3.7689736   |
| training/sac_pi/pi_global_norm | 1.6944066   |
| training/sac_pi/policy_loss    | -201.58699  |
| training/sac_pi/std            | 0.58726937  |
| training/sac_pi/valid_num      | 4871.0      |
| training/sac_Q/q1              | 178.72394   |
| training/sac_Q/q2              | 177.13893   |
| training/sac_Q/q2_loss         | 95.57144    |
| training/sac_Q/q_global_norm   | 219.3098    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16707243  |
| epoch                          | 399         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4967.3135   |
| evaluation/return-max          | 5022.633    |
| evaluation/return-min          | 4862.826    |
| evaluation/return-std          | 44.869633   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45700       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4967.3135   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 198.3792    |
| Q-std                          | 143.30466   |
| Q_loss                         | 79.62238    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 399         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000136    |
| times/epoch_rollout_model      | 473         |
| times/evaluation_metrics       | 0.000537    |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 56.5        |
| timestep                       | 1000        |
| timesteps_total                | 400000      |
| train-steps                    | 400000      |
| training/Q/q1_loss             | 117.5499    |
| training/sac_pi/alpha          | 0.1670983   |
| training/sac_pi/alpha_loss     | -0.25500694 |
| training/sac_pi/logp_pi        | 4.784275    |
| training/sac_pi/pi_entropy     | 3.5431695   |
| training/sac_pi/pi_global_norm | 1.4973452   |
| training/sac_pi/policy_loss    | -199.257    |
| training/sac_pi/std            | 0.5295163   |
| training/sac_pi/valid_num      | 4943.0      |
| training/sac_Q/q1              | 182.27473   |
| training/sac_Q/q2              | 178.03491   |
| training/sac_Q/q2_loss         | 118.66896   |
| training/sac_Q/q_global_norm   | 270.81662   |
---------------------------------------------------------------------------------
[WARN] 400 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16776411  |
| epoch                          | 400         |
| evaluation/episode-length-avg  | 190         |
| evaluation/episode-length-max  | 209         |
| evaluation/episode-length-min  | 183         |
| evaluation/episode-length-std  | 6.9         |
| evaluation/return-average      | 279.08447   |
| evaluation/return-max          | 306.40424   |
| evaluation/return-min          | 270.82858   |
| evaluation/return-std          | 9.706845    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45878       |
| perf/AverageLength             | 190         |
| perf/AverageReturn             | 279.08447   |
| perf/NormalizedReturn          | 0.0604      |
| Q-avg                          | 187.70244   |
| Q-std                          | 147.95409   |
| Q_loss                         | 124.55847   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 400         |
| times/epoch_after_hook         | 2.04e-06    |
| times/epoch_before_hook        | 0.0001      |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.00045     |
| times/evaluation_paths         | 5.87        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00794     |
| times/train                    | 56.5        |
| timestep                       | 1000        |
| timesteps_total                | 401000      |
| train-steps                    | 401000      |
| training/Q/q1_loss             | 88.774216   |
| training/sac_pi/alpha          | 0.16778256  |
| training/sac_pi/alpha_loss     | -0.13954821 |
| training/sac_pi/logp_pi        | 3.8505738   |
| training/sac_pi/pi_entropy     | 3.4520702   |
| training/sac_pi/pi_global_norm | 1.8381712   |
| training/sac_pi/policy_loss    | -205.94955  |
| training/sac_pi/std            | 0.48652962  |
| training/sac_pi/valid_num      | 4996.0      |
| training/sac_Q/q1              | 195.1801    |
| training/sac_Q/q2              | 194.40503   |
| training/sac_Q/q2_loss         | 88.364944   |
| training/sac_Q/q_global_norm   | 226.9817    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17152947  |
| epoch                          | 401         |
| evaluation/episode-length-avg  | 916         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 159         |
| evaluation/episode-length-std  | 252         |
| evaluation/return-average      | 4259.155    |
| evaluation/return-max          | 4712.381    |
| evaluation/return-min          | 433.362     |
| evaluation/return-std          | 1275.4218   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45720       |
| perf/AverageLength             | 916         |
| perf/AverageReturn             | 4259.155    |
| perf/NormalizedReturn          | 0.927       |
| Q-avg                          | 195.49295   |
| Q-std                          | 154.18816   |
| Q_loss                         | 88.11372    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 401         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000292    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.00055     |
| times/evaluation_paths         | 28.4        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 56.2        |
| timestep                       | 1000        |
| timesteps_total                | 402000      |
| train-steps                    | 402000      |
| training/Q/q1_loss             | 107.744     |
| training/sac_pi/alpha          | 0.171513    |
| training/sac_pi/alpha_loss     | 0.088587694 |
| training/sac_pi/logp_pi        | 4.213622    |
| training/sac_pi/pi_entropy     | 3.3961766   |
| training/sac_pi/pi_global_norm | 1.7673745   |
| training/sac_pi/policy_loss    | -198.66469  |
| training/sac_pi/std            | 0.48735628  |
| training/sac_pi/valid_num      | 4991.0      |
| training/sac_Q/q1              | 186.97768   |
| training/sac_Q/q2              | 183.99622   |
| training/sac_Q/q2_loss         | 108.77667   |
| training/sac_Q/q_global_norm   | 246.03851   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16698323  |
| epoch                          | 402         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5052.116    |
| evaluation/return-max          | 5073.594    |
| evaluation/return-min          | 5027.466    |
| evaluation/return-std          | 16.414345   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45699       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5052.116    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 177.40736   |
| Q-std                          | 168.46053   |
| Q_loss                         | 131.02432   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 402         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 56.2        |
| timestep                       | 1000        |
| timesteps_total                | 403000      |
| train-steps                    | 403000      |
| training/Q/q1_loss             | 92.517784   |
| training/sac_pi/alpha          | 0.16699344  |
| training/sac_pi/alpha_loss     | 0.017507758 |
| training/sac_pi/logp_pi        | 4.4884653   |
| training/sac_pi/pi_entropy     | 3.560077    |
| training/sac_pi/pi_global_norm | 1.696254    |
| training/sac_pi/policy_loss    | -201.28024  |
| training/sac_pi/std            | 0.5189715   |
| training/sac_pi/valid_num      | 4964.0      |
| training/sac_Q/q1              | 186.37534   |
| training/sac_Q/q2              | 185.06332   |
| training/sac_Q/q2_loss         | 93.228836   |
| training/sac_Q/q_global_norm   | 190.53516   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16754353 |
| epoch                          | 403        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4733.265   |
| evaluation/return-max          | 4772.446   |
| evaluation/return-min          | 4641.7256  |
| evaluation/return-std          | 36.919632  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 83.2       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45626      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4733.265   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 185.04207  |
| Q-std                          | 131.73427  |
| Q_loss                         | 108.08175  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 403        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000103   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000614   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 56.2       |
| timestep                       | 1000       |
| timesteps_total                | 404000     |
| train-steps                    | 404000     |
| training/Q/q1_loss             | 109.303925 |
| training/sac_pi/alpha          | 0.1675781  |
| training/sac_pi/alpha_loss     | 0.05107422 |
| training/sac_pi/logp_pi        | 4.27432    |
| training/sac_pi/pi_entropy     | 3.5363038  |
| training/sac_pi/pi_global_norm | 1.6397219  |
| training/sac_pi/policy_loss    | -205.52908 |
| training/sac_pi/std            | 0.5248549  |
| training/sac_pi/valid_num      | 4958.0     |
| training/sac_Q/q1              | 192.70692  |
| training/sac_Q/q2              | 190.56177  |
| training/sac_Q/q2_loss         | 109.56799  |
| training/sac_Q/q_global_norm   | 293.08405  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17287321   |
| epoch                          | 404          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4796.597     |
| evaluation/return-max          | 4868.7056    |
| evaluation/return-min          | 4721.5723    |
| evaluation/return-std          | 54.07991     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.87         |
| model/origin_ret               | 83.7         |
| model/penalty_ret              | 82.2         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45670        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4796.597     |
| perf/NormalizedReturn          | 1.04         |
| Q-avg                          | 197.83017    |
| Q-std                          | 122.44788    |
| Q_loss                         | 94.62555     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 404          |
| times/epoch_after_hook         | 1.76e-06     |
| times/epoch_before_hook        | 0.00012      |
| times/epoch_rollout_model      | 479          |
| times/evaluation_metrics       | 0.000588     |
| times/evaluation_paths         | 30.8         |
| times/timestep_after_hook      | 0.00378      |
| times/timestep_before_hook     | 0.00821      |
| times/train                    | 55.5         |
| timestep                       | 1000         |
| timesteps_total                | 405000       |
| train-steps                    | 405000       |
| training/Q/q1_loss             | 104.26031    |
| training/sac_pi/alpha          | 0.17283396   |
| training/sac_pi/alpha_loss     | 0.0035735925 |
| training/sac_pi/logp_pi        | 4.3105664    |
| training/sac_pi/pi_entropy     | 3.7115142    |
| training/sac_pi/pi_global_norm | 1.5216169    |
| training/sac_pi/policy_loss    | -192.00145   |
| training/sac_pi/std            | 0.5247459    |
| training/sac_pi/valid_num      | 4986.0       |
| training/sac_Q/q1              | 179.46194    |
| training/sac_Q/q2              | 175.37007    |
| training/sac_Q/q2_loss         | 104.63085    |
| training/sac_Q/q_global_norm   | 196.66328    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16802521 |
| epoch                          | 405        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5179.033   |
| evaluation/return-max          | 5204.423   |
| evaluation/return-min          | 5148.3213  |
| evaluation/return-std          | 17.540743  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45589      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5179.033   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 191.95062  |
| Q-std                          | 165.51656  |
| Q_loss                         | 105.81062  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 405        |
| times/epoch_after_hook         | 1.65e-06   |
| times/epoch_before_hook        | 0.000282   |
| times/epoch_rollout_model      | 474        |
| times/evaluation_metrics       | 0.000545   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00842    |
| times/train                    | 55.4       |
| timestep                       | 1000       |
| timesteps_total                | 406000     |
| train-steps                    | 406000     |
| training/Q/q1_loss             | 92.26611   |
| training/sac_pi/alpha          | 0.1680407  |
| training/sac_pi/alpha_loss     | -0.3828607 |
| training/sac_pi/logp_pi        | 4.9512987  |
| training/sac_pi/pi_entropy     | 3.3450685  |
| training/sac_pi/pi_global_norm | 1.5835657  |
| training/sac_pi/policy_loss    | -202.46378 |
| training/sac_pi/std            | 0.4957259  |
| training/sac_pi/valid_num      | 4868.0     |
| training/sac_Q/q1              | 180.3176   |
| training/sac_Q/q2              | 176.52847  |
| training/sac_Q/q2_loss         | 93.644104  |
| training/sac_Q/q_global_norm   | 224.27977  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17748524 |
| epoch                          | 406        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4938.5     |
| evaluation/return-max          | 4979.6353  |
| evaluation/return-min          | 4898.2954  |
| evaluation/return-std          | 25.220013  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 83         |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45803      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4938.5     |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 183.38931  |
| Q-std                          | 181.67322  |
| Q_loss                         | 121.16641  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 406        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000267   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.0006     |
| times/evaluation_paths         | 30.6       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 407000     |
| train-steps                    | 407000     |
| training/Q/q1_loss             | 116.00725  |
| training/sac_pi/alpha          | 0.17745477 |
| training/sac_pi/alpha_loss     | 0.10284314 |
| training/sac_pi/logp_pi        | 4.5463333  |
| training/sac_pi/pi_entropy     | 3.7312324  |
| training/sac_pi/pi_global_norm | 1.5882112  |
| training/sac_pi/policy_loss    | -197.26468 |
| training/sac_pi/std            | 0.53503364 |
| training/sac_pi/valid_num      | 4906.0     |
| training/sac_Q/q1              | 178.05542  |
| training/sac_Q/q2              | 176.24927  |
| training/sac_Q/q2_loss         | 116.19153  |
| training/sac_Q/q_global_norm   | 257.57803  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17205946 |
| epoch                          | 407        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4991.1064  |
| evaluation/return-max          | 5042.342   |
| evaluation/return-min          | 4941.9297  |
| evaluation/return-std          | 29.01038   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45756      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4991.1064  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 196.8227   |
| Q-std                          | 112.973335 |
| Q_loss                         | 103.32623  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 407        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000566   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 54.9       |
| timestep                       | 1000       |
| timesteps_total                | 408000     |
| train-steps                    | 408000     |
| training/Q/q1_loss             | 88.294174  |
| training/sac_pi/alpha          | 0.17206548 |
| training/sac_pi/alpha_loss     | 0.07069926 |
| training/sac_pi/logp_pi        | 4.353429   |
| training/sac_pi/pi_entropy     | 3.4735084  |
| training/sac_pi/pi_global_norm | 1.6592627  |
| training/sac_pi/policy_loss    | -205.5545  |
| training/sac_pi/std            | 0.5028494  |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 194.86652  |
| training/sac_Q/q2              | 193.92168  |
| training/sac_Q/q2_loss         | 88.46005   |
| training/sac_Q/q_global_norm   | 171.43916  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.172531   |
| epoch                          | 408        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4752.8936  |
| evaluation/return-max          | 4878.6426  |
| evaluation/return-min          | 4622.943   |
| evaluation/return-std          | 76.40403   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45710      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4752.8936  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 177.54929  |
| Q-std                          | 158.72328  |
| Q_loss                         | 102.66988  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 408        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.00058    |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 409000     |
| train-steps                    | 409000     |
| training/Q/q1_loss             | 112.10101  |
| training/sac_pi/alpha          | 0.17249887 |
| training/sac_pi/alpha_loss     | 0.43694478 |
| training/sac_pi/logp_pi        | 4.1277843  |
| training/sac_pi/pi_entropy     | 3.726268   |
| training/sac_pi/pi_global_norm | 1.5807928  |
| training/sac_pi/policy_loss    | -197.54813 |
| training/sac_pi/std            | 0.51629424 |
| training/sac_pi/valid_num      | 4976.0     |
| training/sac_Q/q1              | 186.87344  |
| training/sac_Q/q2              | 186.4804   |
| training/sac_Q/q2_loss         | 111.22003  |
| training/sac_Q/q_global_norm   | 247.31964  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16839361   |
| epoch                          | 409          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4935.7295    |
| evaluation/return-max          | 5015.716     |
| evaluation/return-min          | 4873.324     |
| evaluation/return-std          | 46.046223    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.96         |
| model/origin_ret               | 84.9         |
| model/penalty_ret              | 81.8         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45689        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4935.7295    |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 204.36145    |
| Q-std                          | 106.58668    |
| Q_loss                         | 85.43388     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 409          |
| times/epoch_after_hook         | 1.91e-06     |
| times/epoch_before_hook        | 0.000284     |
| times/epoch_rollout_model      | 473          |
| times/evaluation_metrics       | 0.000528     |
| times/evaluation_paths         | 30.6         |
| times/timestep_after_hook      | 0.00371      |
| times/timestep_before_hook     | 0.00809      |
| times/train                    | 56.1         |
| timestep                       | 1000         |
| timesteps_total                | 410000       |
| train-steps                    | 410000       |
| training/Q/q1_loss             | 97.57071     |
| training/sac_pi/alpha          | 0.16841438   |
| training/sac_pi/alpha_loss     | -0.072273575 |
| training/sac_pi/logp_pi        | 4.170419     |
| training/sac_pi/pi_entropy     | 3.5018623    |
| training/sac_pi/pi_global_norm | 1.7279972    |
| training/sac_pi/policy_loss    | -203.10094   |
| training/sac_pi/std            | 0.49905884   |
| training/sac_pi/valid_num      | 4960.0       |
| training/sac_Q/q1              | 192.25375    |
| training/sac_Q/q2              | 190.82915    |
| training/sac_Q/q2_loss         | 96.2168      |
| training/sac_Q/q_global_norm   | 249.31058    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1710254  |
| epoch                          | 410        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4952.788   |
| evaluation/return-max          | 4980.625   |
| evaluation/return-min          | 4928.3184  |
| evaluation/return-std          | 15.430968  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 82.8       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45653      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4952.788   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 181.42307  |
| Q-std                          | 157.5398   |
| Q_loss                         | 109.42576  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 410        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000102   |
| times/epoch_rollout_model      | 471        |
| times/evaluation_metrics       | 0.000555   |
| times/evaluation_paths         | 31.2       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 54.1       |
| timestep                       | 1000       |
| timesteps_total                | 411000     |
| train-steps                    | 411000     |
| training/Q/q1_loss             | 123.50423  |
| training/sac_pi/alpha          | 0.17101645 |
| training/sac_pi/alpha_loss     | 0.2975207  |
| training/sac_pi/logp_pi        | 4.639652   |
| training/sac_pi/pi_entropy     | 3.6412692  |
| training/sac_pi/pi_global_norm | 1.7282296  |
| training/sac_pi/policy_loss    | -201.63823 |
| training/sac_pi/std            | 0.5238388  |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 187.4736   |
| training/sac_Q/q2              | 184.43893  |
| training/sac_Q/q2_loss         | 124.34784  |
| training/sac_Q/q_global_norm   | 287.4417   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16533388 |
| epoch                          | 411        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4584.3003  |
| evaluation/return-max          | 4639.5254  |
| evaluation/return-min          | 4526.991   |
| evaluation/return-std          | 36.843414  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45537      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4584.3003  |
| perf/NormalizedReturn          | 0.998      |
| Q-avg                          | 188.7174   |
| Q-std                          | 139.75792  |
| Q_loss                         | 77.78603   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 411        |
| times/epoch_after_hook         | 2e-06      |
| times/epoch_before_hook        | 0.000145   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 412000     |
| train-steps                    | 412000     |
| training/Q/q1_loss             | 112.33579  |
| training/sac_pi/alpha          | 0.1653272  |
| training/sac_pi/alpha_loss     | 0.11457821 |
| training/sac_pi/logp_pi        | 3.7284737  |
| training/sac_pi/pi_entropy     | 3.5608635  |
| training/sac_pi/pi_global_norm | 1.7011509  |
| training/sac_pi/policy_loss    | -194.61952 |
| training/sac_pi/std            | 0.48101538 |
| training/sac_pi/valid_num      | 5025.0     |
| training/sac_Q/q1              | 189.38274  |
| training/sac_Q/q2              | 188.23628  |
| training/sac_Q/q2_loss         | 111.6489   |
| training/sac_Q/q_global_norm   | 284.44476  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17167874  |
| epoch                          | 412         |
| evaluation/episode-length-avg  | 972         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 721         |
| evaluation/episode-length-std  | 83.7        |
| evaluation/return-average      | 4627.709    |
| evaluation/return-max          | 4853.208    |
| evaluation/return-min          | 3273.4392   |
| evaluation/return-std          | 453.77625   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.84        |
| model/origin_ret               | 83.3        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45437       |
| perf/AverageLength             | 972         |
| perf/AverageReturn             | 4627.709    |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 185.79602   |
| Q-std                          | 151.69038   |
| Q_loss                         | 87.61128    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 412         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000628    |
| times/evaluation_paths         | 29.3        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 55          |
| timestep                       | 1000        |
| timesteps_total                | 413000      |
| train-steps                    | 413000      |
| training/Q/q1_loss             | 90.272705   |
| training/sac_pi/alpha          | 0.17166266  |
| training/sac_pi/alpha_loss     | -0.09953117 |
| training/sac_pi/logp_pi        | 4.5270257   |
| training/sac_pi/pi_entropy     | 3.7081559   |
| training/sac_pi/pi_global_norm | 1.4254669   |
| training/sac_pi/policy_loss    | -201.61372  |
| training/sac_pi/std            | 0.541582    |
| training/sac_pi/valid_num      | 4936.0      |
| training/sac_Q/q1              | 185.86775   |
| training/sac_Q/q2              | 184.2965    |
| training/sac_Q/q2_loss         | 89.984375   |
| training/sac_Q/q_global_norm   | 215.9459    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17319565 |
| epoch                          | 413        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4806.075   |
| evaluation/return-max          | 4865.611   |
| evaluation/return-min          | 4708.0723  |
| evaluation/return-std          | 50.850746  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45749      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4806.075   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 186.85478  |
| Q-std                          | 136.59705  |
| Q_loss                         | 103.08881  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 413        |
| times/epoch_after_hook         | 3.44e-06   |
| times/epoch_before_hook        | 0.000279   |
| times/epoch_rollout_model      | 475        |
| times/evaluation_metrics       | 0.000538   |
| times/evaluation_paths         | 30.4       |
| times/timestep_after_hook      | 0.00381    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 414000     |
| train-steps                    | 414000     |
| training/Q/q1_loss             | 126.75583  |
| training/sac_pi/alpha          | 0.17318325 |
| training/sac_pi/alpha_loss     | 0.13113071 |
| training/sac_pi/logp_pi        | 4.9379945  |
| training/sac_pi/pi_entropy     | 3.5852997  |
| training/sac_pi/pi_global_norm | 1.4396198  |
| training/sac_pi/policy_loss    | -203.56367 |
| training/sac_pi/std            | 0.52698517 |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 187.0069   |
| training/sac_Q/q2              | 183.52792  |
| training/sac_Q/q2_loss         | 126.44896  |
| training/sac_Q/q_global_norm   | 219.04921  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1701271  |
| epoch                          | 414        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4793.939   |
| evaluation/return-max          | 4845.754   |
| evaluation/return-min          | 4757.8203  |
| evaluation/return-std          | 28.85892   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45731      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4793.939   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 169.39018  |
| Q-std                          | 202.36522  |
| Q_loss                         | 99.17085   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 414        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000566   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 56.4       |
| timestep                       | 1000       |
| timesteps_total                | 415000     |
| train-steps                    | 415000     |
| training/Q/q1_loss             | 94.28899   |
| training/sac_pi/alpha          | 0.17007624 |
| training/sac_pi/alpha_loss     | 0.54227316 |
| training/sac_pi/logp_pi        | 5.3073936  |
| training/sac_pi/pi_entropy     | 3.6839592  |
| training/sac_pi/pi_global_norm | 1.8155421  |
| training/sac_pi/policy_loss    | -197.19446 |
| training/sac_pi/std            | 0.55836046 |
| training/sac_pi/valid_num      | 4935.0     |
| training/sac_Q/q1              | 179.90392  |
| training/sac_Q/q2              | 176.25934  |
| training/sac_Q/q2_loss         | 94.589615  |
| training/sac_Q/q_global_norm   | 206.6403   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16687517 |
| epoch                          | 415        |
| evaluation/episode-length-avg  | 158        |
| evaluation/episode-length-max  | 162        |
| evaluation/episode-length-min  | 152        |
| evaluation/episode-length-std  | 3.06       |
| evaluation/return-average      | 414.00836  |
| evaluation/return-max          | 421.61053  |
| evaluation/return-min          | 408.99585  |
| evaluation/return-std          | 4.201425   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45656      |
| perf/AverageLength             | 158        |
| perf/AverageReturn             | 414.00836  |
| perf/NormalizedReturn          | 0.0898     |
| Q-avg                          | 183.16228  |
| Q-std                          | 141.01414  |
| Q_loss                         | 85.09031   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 415        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 474        |
| times/evaluation_metrics       | 0.000577   |
| times/evaluation_paths         | 4.83       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 56         |
| timestep                       | 1000       |
| timesteps_total                | 416000     |
| train-steps                    | 416000     |
| training/Q/q1_loss             | 99.54964   |
| training/sac_pi/alpha          | 0.16689391 |
| training/sac_pi/alpha_loss     | -0.2639433 |
| training/sac_pi/logp_pi        | 4.4094     |
| training/sac_pi/pi_entropy     | 3.42388    |
| training/sac_pi/pi_global_norm | 1.5283836  |
| training/sac_pi/policy_loss    | -195.2174  |
| training/sac_pi/std            | 0.49711987 |
| training/sac_pi/valid_num      | 4963.0     |
| training/sac_Q/q1              | 183.96985  |
| training/sac_Q/q2              | 181.42513  |
| training/sac_Q/q2_loss         | 99.560326  |
| training/sac_Q/q_global_norm   | 318.16766  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16816047   |
| epoch                          | 416          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5124.932     |
| evaluation/return-max          | 5206.8887    |
| evaluation/return-min          | 5060.083     |
| evaluation/return-std          | 49.202652    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.92         |
| model/origin_ret               | 84.1         |
| model/penalty_ret              | 81.7         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45789        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5124.932     |
| perf/NormalizedReturn          | 1.12         |
| Q-avg                          | 192.90921    |
| Q-std                          | 172.34709    |
| Q_loss                         | 94.85604     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 416          |
| times/epoch_after_hook         | 1.78e-06     |
| times/epoch_before_hook        | 8.96e-05     |
| times/epoch_rollout_model      | 473          |
| times/evaluation_metrics       | 0.000604     |
| times/evaluation_paths         | 30.8         |
| times/timestep_after_hook      | 0.00383      |
| times/timestep_before_hook     | 0.00825      |
| times/train                    | 54.7         |
| timestep                       | 1000         |
| timesteps_total                | 417000       |
| train-steps                    | 417000       |
| training/Q/q1_loss             | 104.340935   |
| training/sac_pi/alpha          | 0.1681789    |
| training/sac_pi/alpha_loss     | -0.041454334 |
| training/sac_pi/logp_pi        | 4.216016     |
| training/sac_pi/pi_entropy     | 3.494444     |
| training/sac_pi/pi_global_norm | 1.4947983    |
| training/sac_pi/policy_loss    | -205.71616   |
| training/sac_pi/std            | 0.500502     |
| training/sac_pi/valid_num      | 4971.0       |
| training/sac_Q/q1              | 194.56123    |
| training/sac_Q/q2              | 192.67416    |
| training/sac_Q/q2_loss         | 104.094475   |
| training/sac_Q/q_global_norm   | 191.17905    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17018916 |
| epoch                          | 417        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4866.4937  |
| evaluation/return-max          | 4886.709   |
| evaluation/return-min          | 4835.4165  |
| evaluation/return-std          | 15.618887  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45634      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4866.4937  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 180.35202  |
| Q-std                          | 159.75996  |
| Q_loss                         | 113.20526  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 417        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000324   |
| times/epoch_rollout_model      | 475        |
| times/evaluation_metrics       | 0.000586   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 55         |
| timestep                       | 1000       |
| timesteps_total                | 418000     |
| train-steps                    | 418000     |
| training/Q/q1_loss             | 87.098915  |
| training/sac_pi/alpha          | 0.1701492  |
| training/sac_pi/alpha_loss     | 0.20083354 |
| training/sac_pi/logp_pi        | 4.6695766  |
| training/sac_pi/pi_entropy     | 3.5566182  |
| training/sac_pi/pi_global_norm | 1.6363378  |
| training/sac_pi/policy_loss    | -197.78305 |
| training/sac_pi/std            | 0.52120584 |
| training/sac_pi/valid_num      | 4934.0     |
| training/sac_Q/q1              | 182.35678  |
| training/sac_Q/q2              | 182.56738  |
| training/sac_Q/q2_loss         | 87.58309   |
| training/sac_Q/q_global_norm   | 183.50462  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16716571 |
| epoch                          | 418        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4761.5063  |
| evaluation/return-max          | 4798.525   |
| evaluation/return-min          | 4720.7617  |
| evaluation/return-std          | 23.538612  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45581      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4761.5063  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 170.26566  |
| Q-std                          | 159.04817  |
| Q_loss                         | 99.12928   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 418        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000547   |
| times/evaluation_paths         | 30.6       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 56         |
| timestep                       | 1000       |
| timesteps_total                | 419000     |
| train-steps                    | 419000     |
| training/Q/q1_loss             | 93.052795  |
| training/sac_pi/alpha          | 0.16711745 |
| training/sac_pi/alpha_loss     | 0.06435147 |
| training/sac_pi/logp_pi        | 4.7297816  |
| training/sac_pi/pi_entropy     | 3.6129906  |
| training/sac_pi/pi_global_norm | 1.8131856  |
| training/sac_pi/policy_loss    | -199.21445 |
| training/sac_pi/std            | 0.52592725 |
| training/sac_pi/valid_num      | 4919.0     |
| training/sac_Q/q1              | 182.33678  |
| training/sac_Q/q2              | 181.84956  |
| training/sac_Q/q2_loss         | 92.36966   |
| training/sac_Q/q_global_norm   | 238.57883  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16929594   |
| epoch                          | 419          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4972.0454    |
| evaluation/return-max          | 5037.205     |
| evaluation/return-min          | 4905.459     |
| evaluation/return-std          | 46.208256    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.93         |
| model/origin_ret               | 85.5         |
| model/penalty_ret              | 82.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45641        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4972.0454    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 184.78123    |
| Q-std                          | 156.9616     |
| Q_loss                         | 114.515465   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 419          |
| times/epoch_after_hook         | 1.86e-06     |
| times/epoch_before_hook        | 0.000128     |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.000536     |
| times/evaluation_paths         | 30.5         |
| times/timestep_after_hook      | 0.00364      |
| times/timestep_before_hook     | 0.00819      |
| times/train                    | 55.7         |
| timestep                       | 1000         |
| timesteps_total                | 420000       |
| train-steps                    | 420000       |
| training/Q/q1_loss             | 104.8944     |
| training/sac_pi/alpha          | 0.16926844   |
| training/sac_pi/alpha_loss     | 0.0012104074 |
| training/sac_pi/logp_pi        | 4.625035     |
| training/sac_pi/pi_entropy     | 3.5787785    |
| training/sac_pi/pi_global_norm | 1.675716     |
| training/sac_pi/policy_loss    | -206.51631   |
| training/sac_pi/std            | 0.52827245   |
| training/sac_pi/valid_num      | 4910.0       |
| training/sac_Q/q1              | 190.05331    |
| training/sac_Q/q2              | 187.85533    |
| training/sac_Q/q2_loss         | 104.738174   |
| training/sac_Q/q_global_norm   | 255.17963    |
----------------------------------------------------------------------------------
[WARN] 420 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.16701503   |
| epoch                          | 420          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4971.3647    |
| evaluation/return-max          | 5026.3975    |
| evaluation/return-min          | 4878.13      |
| evaluation/return-std          | 41.65293     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.92         |
| model/origin_ret               | 84.3         |
| model/penalty_ret              | 81.4         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45613        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4971.3647    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 185.00229    |
| Q-std                          | 186.21547    |
| Q_loss                         | 91.56011     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 420          |
| times/epoch_after_hook         | 2.12e-06     |
| times/epoch_before_hook        | 0.000133     |
| times/epoch_rollout_model      | 478          |
| times/evaluation_metrics       | 0.000624     |
| times/evaluation_paths         | 30.7         |
| times/timestep_after_hook      | 0.00364      |
| times/timestep_before_hook     | 0.00791      |
| times/train                    | 55.9         |
| timestep                       | 1000         |
| timesteps_total                | 421000       |
| train-steps                    | 421000       |
| training/Q/q1_loss             | 110.920166   |
| training/sac_pi/alpha          | 0.16701934   |
| training/sac_pi/alpha_loss     | -0.022734465 |
| training/sac_pi/logp_pi        | 5.252848     |
| training/sac_pi/pi_entropy     | 3.637773     |
| training/sac_pi/pi_global_norm | 1.6003069    |
| training/sac_pi/policy_loss    | -200.53453   |
| training/sac_pi/std            | 0.55211234   |
| training/sac_pi/valid_num      | 4889.0       |
| training/sac_Q/q1              | 179.39435    |
| training/sac_Q/q2              | 179.22696    |
| training/sac_Q/q2_loss         | 111.27378    |
| training/sac_Q/q_global_norm   | 329.20374    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17257825   |
| epoch                          | 421          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4774.531     |
| evaluation/return-max          | 4795.56      |
| evaluation/return-min          | 4756.545     |
| evaluation/return-std          | 9.807983     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.96         |
| model/origin_ret               | 83.7         |
| model/penalty_ret              | 81           |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45874        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4774.531     |
| perf/NormalizedReturn          | 1.04         |
| Q-avg                          | 175.88861    |
| Q-std                          | 168.90341    |
| Q_loss                         | 101.64557    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 421          |
| times/epoch_after_hook         | 1.83e-06     |
| times/epoch_before_hook        | 0.000345     |
| times/epoch_rollout_model      | 479          |
| times/evaluation_metrics       | 0.000515     |
| times/evaluation_paths         | 30.8         |
| times/timestep_after_hook      | 0.00392      |
| times/timestep_before_hook     | 0.00812      |
| times/train                    | 54.3         |
| timestep                       | 1000         |
| timesteps_total                | 422000       |
| train-steps                    | 422000       |
| training/Q/q1_loss             | 116.43995    |
| training/sac_pi/alpha          | 0.17257869   |
| training/sac_pi/alpha_loss     | -0.107385956 |
| training/sac_pi/logp_pi        | 4.300645     |
| training/sac_pi/pi_entropy     | 3.5910327    |
| training/sac_pi/pi_global_norm | 1.8994914    |
| training/sac_pi/policy_loss    | -200.09238   |
| training/sac_pi/std            | 0.5098152    |
| training/sac_pi/valid_num      | 4946.0       |
| training/sac_Q/q1              | 184.5314     |
| training/sac_Q/q2              | 183.03545    |
| training/sac_Q/q2_loss         | 115.75795    |
| training/sac_Q/q_global_norm   | 212.66982    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17008507 |
| epoch                          | 422        |
| evaluation/episode-length-avg  | 927        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 267        |
| evaluation/episode-length-std  | 220        |
| evaluation/return-average      | 4478.75    |
| evaluation/return-max          | 4968.129   |
| evaluation/return-min          | 990.2143   |
| evaluation/return-std          | 1164.1582  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45577      |
| perf/AverageLength             | 927        |
| perf/AverageReturn             | 4478.75    |
| perf/NormalizedReturn          | 0.975      |
| Q-avg                          | 192.40552  |
| Q-std                          | 139.647    |
| Q_loss                         | 99.217224  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 422        |
| times/epoch_after_hook         | 3.76e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 475        |
| times/evaluation_metrics       | 0.000566   |
| times/evaluation_paths         | 28.3       |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 55.4       |
| timestep                       | 1000       |
| timesteps_total                | 423000     |
| train-steps                    | 423000     |
| training/Q/q1_loss             | 92.50364   |
| training/sac_pi/alpha          | 0.1700913  |
| training/sac_pi/alpha_loss     | -0.0130101 |
| training/sac_pi/logp_pi        | 4.345402   |
| training/sac_pi/pi_entropy     | 3.639323   |
| training/sac_pi/pi_global_norm | 1.5845078  |
| training/sac_pi/policy_loss    | -195.49286 |
| training/sac_pi/std            | 0.525413   |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 181.85362  |
| training/sac_Q/q2              | 180.56387  |
| training/sac_Q/q2_loss         | 91.38944   |
| training/sac_Q/q_global_norm   | 229.95882  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16973986  |
| epoch                          | 423         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4885.3584   |
| evaluation/return-max          | 4943.287    |
| evaluation/return-min          | 4817.018    |
| evaluation/return-std          | 33.23163    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45716       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4885.3584   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 192.83237   |
| Q-std                          | 151.22977   |
| Q_loss                         | 100.911575  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 423         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.00011     |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000593    |
| times/evaluation_paths         | 30.3        |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 55          |
| timestep                       | 1000        |
| timesteps_total                | 424000      |
| train-steps                    | 424000      |
| training/Q/q1_loss             | 101.0027    |
| training/sac_pi/alpha          | 0.16973506  |
| training/sac_pi/alpha_loss     | -0.08361292 |
| training/sac_pi/logp_pi        | 4.3687863   |
| training/sac_pi/pi_entropy     | 3.6871483   |
| training/sac_pi/pi_global_norm | 1.4795293   |
| training/sac_pi/policy_loss    | -201.73988  |
| training/sac_pi/std            | 0.5296677   |
| training/sac_pi/valid_num      | 4917.0      |
| training/sac_Q/q1              | 183.19612   |
| training/sac_Q/q2              | 182.99341   |
| training/sac_Q/q2_loss         | 101.22564   |
| training/sac_Q/q_global_norm   | 342.6245    |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16629833   |
| epoch                          | 424          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5005.4497    |
| evaluation/return-max          | 5060.956     |
| evaluation/return-min          | 4945.2646    |
| evaluation/return-std          | 37.62882     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.92         |
| model/origin_ret               | 84.2         |
| model/penalty_ret              | 81.5         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45650        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5005.4497    |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 176.6176     |
| Q-std                          | 211.17087    |
| Q_loss                         | 114.22296    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 424          |
| times/epoch_after_hook         | 1.66e-06     |
| times/epoch_before_hook        | 0.000113     |
| times/epoch_rollout_model      | 478          |
| times/evaluation_metrics       | 0.000529     |
| times/evaluation_paths         | 30.5         |
| times/timestep_after_hook      | 0.0038       |
| times/timestep_before_hook     | 0.00812      |
| times/train                    | 55.5         |
| timestep                       | 1000         |
| timesteps_total                | 425000       |
| train-steps                    | 425000       |
| training/Q/q1_loss             | 102.432625   |
| training/sac_pi/alpha          | 0.16632336   |
| training/sac_pi/alpha_loss     | -0.122085385 |
| training/sac_pi/logp_pi        | 4.602041     |
| training/sac_pi/pi_entropy     | 3.3458397    |
| training/sac_pi/pi_global_norm | 1.7139237    |
| training/sac_pi/policy_loss    | -207.45705   |
| training/sac_pi/std            | 0.5086335    |
| training/sac_pi/valid_num      | 4957.0       |
| training/sac_Q/q1              | 194.44832    |
| training/sac_Q/q2              | 191.90459    |
| training/sac_Q/q2_loss         | 102.47966    |
| training/sac_Q/q_global_norm   | 304.07306    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17083612   |
| epoch                          | 425          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4899.575     |
| evaluation/return-max          | 5049.964     |
| evaluation/return-min          | 4766.251     |
| evaluation/return-std          | 78.61715     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.94         |
| model/origin_ret               | 84.9         |
| model/penalty_ret              | 81.7         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45535        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4899.575     |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 183.6416     |
| Q-std                          | 184.93794    |
| Q_loss                         | 89.54045     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 425          |
| times/epoch_after_hook         | 1.83e-06     |
| times/epoch_before_hook        | 0.000286     |
| times/epoch_rollout_model      | 478          |
| times/evaluation_metrics       | 0.000546     |
| times/evaluation_paths         | 30.9         |
| times/timestep_after_hook      | 0.00376      |
| times/timestep_before_hook     | 0.00812      |
| times/train                    | 55.7         |
| timestep                       | 1000         |
| timesteps_total                | 426000       |
| train-steps                    | 426000       |
| training/Q/q1_loss             | 94.79019     |
| training/sac_pi/alpha          | 0.17081712   |
| training/sac_pi/alpha_loss     | -0.031533472 |
| training/sac_pi/logp_pi        | 5.1521387    |
| training/sac_pi/pi_entropy     | 3.7150924    |
| training/sac_pi/pi_global_norm | 1.4863584    |
| training/sac_pi/policy_loss    | -196.39629   |
| training/sac_pi/std            | 0.55936396   |
| training/sac_pi/valid_num      | 4899.0       |
| training/sac_Q/q1              | 172.60312    |
| training/sac_Q/q2              | 172.87187    |
| training/sac_Q/q2_loss         | 95.42886     |
| training/sac_Q/q_global_norm   | 148.13322    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16545025 |
| epoch                          | 426        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4656.497   |
| evaluation/return-max          | 4737.214   |
| evaluation/return-min          | 4512.453   |
| evaluation/return-std          | 62.482018  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45475      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4656.497   |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 193.52179  |
| Q-std                          | 165.46468  |
| Q_loss                         | 80.245766  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 426        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000521   |
| times/evaluation_paths         | 30.9       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 427000     |
| train-steps                    | 427000     |
| training/Q/q1_loss             | 99.80398   |
| training/sac_pi/alpha          | 0.16541556 |
| training/sac_pi/alpha_loss     | 0.19365096 |
| training/sac_pi/logp_pi        | 4.318496   |
| training/sac_pi/pi_entropy     | 3.5826607  |
| training/sac_pi/pi_global_norm | 1.5447437  |
| training/sac_pi/policy_loss    | -194.67624 |
| training/sac_pi/std            | 0.5112582  |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 180.1126   |
| training/sac_Q/q2              | 179.62312  |
| training/sac_Q/q2_loss         | 100.374695 |
| training/sac_Q/q_global_norm   | 197.43439  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16792195 |
| epoch                          | 427        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4876.472   |
| evaluation/return-max          | 4951.2754  |
| evaluation/return-min          | 4795.7695  |
| evaluation/return-std          | 49.203156  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 82.9       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45628      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4876.472   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 186.60855  |
| Q-std                          | 146.13606  |
| Q_loss                         | 108.9653   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 427        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000532   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 54.6       |
| timestep                       | 1000       |
| timesteps_total                | 428000     |
| train-steps                    | 428000     |
| training/Q/q1_loss             | 106.87672  |
| training/sac_pi/alpha          | 0.16787218 |
| training/sac_pi/alpha_loss     | 0.17132412 |
| training/sac_pi/logp_pi        | 5.3571715  |
| training/sac_pi/pi_entropy     | 3.499869   |
| training/sac_pi/pi_global_norm | 1.6254733  |
| training/sac_pi/policy_loss    | -195.41818 |
| training/sac_pi/std            | 0.5388454  |
| training/sac_pi/valid_num      | 4915.0     |
| training/sac_Q/q1              | 174.99265  |
| training/sac_Q/q2              | 170.4523   |
| training/sac_Q/q2_loss         | 108.044136 |
| training/sac_Q/q_global_norm   | 335.0793   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1697022  |
| epoch                          | 428        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4769.126   |
| evaluation/return-max          | 4799.198   |
| evaluation/return-min          | 4728.055   |
| evaluation/return-std          | 22.704885  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45683      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4769.126   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 170.9568   |
| Q-std                          | 186.17955  |
| Q_loss                         | 87.990974  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 428        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000119   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000513   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 55.2       |
| timestep                       | 1000       |
| timesteps_total                | 429000     |
| train-steps                    | 429000     |
| training/Q/q1_loss             | 118.50383  |
| training/sac_pi/alpha          | 0.16964623 |
| training/sac_pi/alpha_loss     | 0.53264874 |
| training/sac_pi/logp_pi        | 5.710289   |
| training/sac_pi/pi_entropy     | 3.5301151  |
| training/sac_pi/pi_global_norm | 1.7806295  |
| training/sac_pi/policy_loss    | -202.47821 |
| training/sac_pi/std            | 0.54721004 |
| training/sac_pi/valid_num      | 4896.0     |
| training/sac_Q/q1              | 181.22493  |
| training/sac_Q/q2              | 177.0784   |
| training/sac_Q/q2_loss         | 119.2335   |
| training/sac_Q/q_global_norm   | 262.61462  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16630286 |
| epoch                          | 429        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4689.9136  |
| evaluation/return-max          | 4719.1665  |
| evaluation/return-min          | 4674.169   |
| evaluation/return-std          | 13.631955  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45662      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4689.9136  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 185.63078  |
| Q-std                          | 158.6977   |
| Q_loss                         | 120.27917  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 429        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000279   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000527   |
| times/evaluation_paths         | 30.6       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 56.2       |
| timestep                       | 1000       |
| timesteps_total                | 430000     |
| train-steps                    | 430000     |
| training/Q/q1_loss             | 104.638855 |
| training/sac_pi/alpha          | 0.1662706  |
| training/sac_pi/alpha_loss     | 0.15327643 |
| training/sac_pi/logp_pi        | 5.1297417  |
| training/sac_pi/pi_entropy     | 3.364327   |
| training/sac_pi/pi_global_norm | 1.7018654  |
| training/sac_pi/policy_loss    | -200.76009 |
| training/sac_pi/std            | 0.50053674 |
| training/sac_pi/valid_num      | 4909.0     |
| training/sac_Q/q1              | 181.9042   |
| training/sac_Q/q2              | 180.14645  |
| training/sac_Q/q2_loss         | 105.47538  |
| training/sac_Q/q_global_norm   | 309.60626  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16661999 |
| epoch                          | 430        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4861.4873  |
| evaluation/return-max          | 4898.2383  |
| evaluation/return-min          | 4842.3364  |
| evaluation/return-std          | 15.803815  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45750      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4861.4873  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 179.37515  |
| Q-std                          | 174.37582  |
| Q_loss                         | 85.97944   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 430        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000609   |
| times/evaluation_paths         | 30.9       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 56.4       |
| timestep                       | 1000       |
| timesteps_total                | 431000     |
| train-steps                    | 431000     |
| training/Q/q1_loss             | 107.52017  |
| training/sac_pi/alpha          | 0.1666703  |
| training/sac_pi/alpha_loss     | -0.0701949 |
| training/sac_pi/logp_pi        | 5.0028443  |
| training/sac_pi/pi_entropy     | 3.681033   |
| training/sac_pi/pi_global_norm | 1.5349715  |
| training/sac_pi/policy_loss    | -192.91096 |
| training/sac_pi/std            | 0.5451858  |
| training/sac_pi/valid_num      | 4898.0     |
| training/sac_Q/q1              | 172.57828  |
| training/sac_Q/q2              | 170.70062  |
| training/sac_Q/q2_loss         | 108.081345 |
| training/sac_Q/q_global_norm   | 209.9132   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1675283  |
| epoch                          | 431        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5072.6055  |
| evaluation/return-max          | 5142.2466  |
| evaluation/return-min          | 5013.9526  |
| evaluation/return-std          | 36.399143  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45702      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5072.6055  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 178.03616  |
| Q-std                          | 172.47464  |
| Q_loss                         | 121.46006  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 431        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000142   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000562   |
| times/evaluation_paths         | 30.6       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 432000     |
| train-steps                    | 432000     |
| training/Q/q1_loss             | 88.304054  |
| training/sac_pi/alpha          | 0.16753124 |
| training/sac_pi/alpha_loss     | 0.32415214 |
| training/sac_pi/logp_pi        | 4.6031375  |
| training/sac_pi/pi_entropy     | 3.6751778  |
| training/sac_pi/pi_global_norm | 1.6205883  |
| training/sac_pi/policy_loss    | -199.77826 |
| training/sac_pi/std            | 0.52425146 |
| training/sac_pi/valid_num      | 4922.0     |
| training/sac_Q/q1              | 183.19145  |
| training/sac_Q/q2              | 181.74376  |
| training/sac_Q/q2_loss         | 87.65435   |
| training/sac_Q/q_global_norm   | 192.64232  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16528878 |
| epoch                          | 432        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4295.114   |
| evaluation/return-max          | 4394.1104  |
| evaluation/return-min          | 4237.6704  |
| evaluation/return-std          | 49.576824  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45519      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4295.114   |
| perf/NormalizedReturn          | 0.935      |
| Q-avg                          | 182.93387  |
| Q-std                          | 163.75143  |
| Q_loss                         | 102.82607  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 432        |
| times/epoch_after_hook         | 1.97e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 474        |
| times/evaluation_metrics       | 0.000545   |
| times/evaluation_paths         | 30.9       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 54.8       |
| timestep                       | 1000       |
| timesteps_total                | 433000     |
| train-steps                    | 433000     |
| training/Q/q1_loss             | 100.72951  |
| training/sac_pi/alpha          | 0.16527845 |
| training/sac_pi/alpha_loss     | 0.38269565 |
| training/sac_pi/logp_pi        | 4.9592094  |
| training/sac_pi/pi_entropy     | 3.4242082  |
| training/sac_pi/pi_global_norm | 1.673033   |
| training/sac_pi/policy_loss    | -206.17685 |
| training/sac_pi/std            | 0.5012547  |
| training/sac_pi/valid_num      | 4937.0     |
| training/sac_Q/q1              | 190.10237  |
| training/sac_Q/q2              | 187.84134  |
| training/sac_Q/q2_loss         | 100.41283  |
| training/sac_Q/q_global_norm   | 205.56386  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17305943 |
| epoch                          | 433        |
| evaluation/episode-length-avg  | 958        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 734        |
| evaluation/episode-length-std  | 87.1       |
| evaluation/return-average      | 4518.0903  |
| evaluation/return-max          | 4799.447   |
| evaluation/return-min          | 3337.6292  |
| evaluation/return-std          | 454.45905  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45732      |
| perf/AverageLength             | 958        |
| perf/AverageReturn             | 4518.0903  |
| perf/NormalizedReturn          | 0.984      |
| Q-avg                          | 186.48952  |
| Q-std                          | 141.84085  |
| Q_loss                         | 83.469124  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 433        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000282   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000634   |
| times/evaluation_paths         | 29.5       |
| times/timestep_after_hook      | 0.00375    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 434000     |
| train-steps                    | 434000     |
| training/Q/q1_loss             | 106.46718  |
| training/sac_pi/alpha          | 0.17305961 |
| training/sac_pi/alpha_loss     | 0.13334252 |
| training/sac_pi/logp_pi        | 4.1175895  |
| training/sac_pi/pi_entropy     | 3.5250633  |
| training/sac_pi/pi_global_norm | 1.606022   |
| training/sac_pi/policy_loss    | -201.8981  |
| training/sac_pi/std            | 0.48418954 |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 191.4622   |
| training/sac_Q/q2              | 190.09976  |
| training/sac_Q/q2_loss         | 106.84177  |
| training/sac_Q/q_global_norm   | 213.91145  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17641711  |
| epoch                          | 434         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 1059.5176   |
| evaluation/return-max          | 1061.7559   |
| evaluation/return-min          | 1056.9764   |
| evaluation/return-std          | 1.4848148   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45440       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 1059.5176   |
| perf/NormalizedReturn          | 0.23        |
| Q-avg                          | 185.9944    |
| Q-std                          | 152.44104   |
| Q_loss                         | 85.77754    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 434         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000104    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000553    |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 56.1        |
| timestep                       | 1000        |
| timesteps_total                | 435000      |
| train-steps                    | 435000      |
| training/Q/q1_loss             | 92.10594    |
| training/sac_pi/alpha          | 0.17645712  |
| training/sac_pi/alpha_loss     | -0.12703416 |
| training/sac_pi/logp_pi        | 4.6876245   |
| training/sac_pi/pi_entropy     | 3.4482353   |
| training/sac_pi/pi_global_norm | 1.6034166   |
| training/sac_pi/policy_loss    | -200.78752  |
| training/sac_pi/std            | 0.50441384  |
| training/sac_pi/valid_num      | 4981.0      |
| training/sac_Q/q1              | 186.93582   |
| training/sac_Q/q2              | 185.32536   |
| training/sac_Q/q2_loss         | 93.57408    |
| training/sac_Q/q_global_norm   | 245.71484   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17358875  |
| epoch                          | 435         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4645.243    |
| evaluation/return-max          | 4726.116    |
| evaluation/return-min          | 4592.3604   |
| evaluation/return-std          | 33.45005    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45727       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4645.243    |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 173.08418   |
| Q-std                          | 197.93709   |
| Q_loss                         | 111.21306   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 435         |
| times/epoch_after_hook         | 2.05e-06    |
| times/epoch_before_hook        | 0.000113    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000567    |
| times/evaluation_paths         | 30.3        |
| times/timestep_after_hook      | 0.00381     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 55.9        |
| timestep                       | 1000        |
| timesteps_total                | 436000      |
| train-steps                    | 436000      |
| training/Q/q1_loss             | 120.33879   |
| training/sac_pi/alpha          | 0.1736276   |
| training/sac_pi/alpha_loss     | -0.25866604 |
| training/sac_pi/logp_pi        | 3.978559    |
| training/sac_pi/pi_entropy     | 3.338276    |
| training/sac_pi/pi_global_norm | 1.4379295   |
| training/sac_pi/policy_loss    | -205.0066   |
| training/sac_pi/std            | 0.47121003  |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 195.42441   |
| training/sac_Q/q2              | 193.73618   |
| training/sac_Q/q2_loss         | 120.722824  |
| training/sac_Q/q_global_norm   | 260.7072    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16824535 |
| epoch                          | 436        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4886.309   |
| evaluation/return-max          | 4948.7656  |
| evaluation/return-min          | 4832.4253  |
| evaluation/return-std          | 29.720222  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45794      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4886.309   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 183.29208  |
| Q-std                          | 169.91838  |
| Q_loss                         | 109.61944  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 436        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000521   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 54.6       |
| timestep                       | 1000       |
| timesteps_total                | 437000     |
| train-steps                    | 437000     |
| training/Q/q1_loss             | 118.4578   |
| training/sac_pi/alpha          | 0.16826881 |
| training/sac_pi/alpha_loss     | -0.0400945 |
| training/sac_pi/logp_pi        | 4.152393   |
| training/sac_pi/pi_entropy     | 3.4613678  |
| training/sac_pi/pi_global_norm | 1.6140137  |
| training/sac_pi/policy_loss    | -200.40462 |
| training/sac_pi/std            | 0.49540094 |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 188.57455  |
| training/sac_Q/q2              | 186.58253  |
| training/sac_Q/q2_loss         | 117.5638   |
| training/sac_Q/q_global_norm   | 231.49043  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17449363  |
| epoch                          | 437         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4909.5737   |
| evaluation/return-max          | 4940.585    |
| evaluation/return-min          | 4871.273    |
| evaluation/return-std          | 23.795465   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45955       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4909.5737   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 186.68425   |
| Q-std                          | 158.3211    |
| Q_loss                         | 98.97337    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 437         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000279    |
| times/epoch_rollout_model      | 475         |
| times/evaluation_metrics       | 0.000686    |
| times/evaluation_paths         | 31.9        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00798     |
| times/train                    | 55.2        |
| timestep                       | 1000        |
| timesteps_total                | 438000      |
| train-steps                    | 438000      |
| training/Q/q1_loss             | 101.12509   |
| training/sac_pi/alpha          | 0.17452046  |
| training/sac_pi/alpha_loss     | -0.03295988 |
| training/sac_pi/logp_pi        | 5.4486566   |
| training/sac_pi/pi_entropy     | 3.5826793   |
| training/sac_pi/pi_global_norm | 1.697919    |
| training/sac_pi/policy_loss    | -198.34637  |
| training/sac_pi/std            | 0.54583913  |
| training/sac_pi/valid_num      | 4922.0      |
| training/sac_Q/q1              | 175.30466   |
| training/sac_Q/q2              | 173.85669   |
| training/sac_Q/q2_loss         | 100.56439   |
| training/sac_Q/q_global_norm   | 215.21046   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17309174  |
| epoch                          | 438         |
| evaluation/episode-length-avg  | 729         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 360         |
| evaluation/episode-length-std  | 290         |
| evaluation/return-average      | 3229.954    |
| evaluation/return-max          | 4744.474    |
| evaluation/return-min          | 1397.5258   |
| evaluation/return-std          | 1457.0045   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45825       |
| perf/AverageLength             | 729         |
| perf/AverageReturn             | 3229.954    |
| perf/NormalizedReturn          | 0.703       |
| Q-avg                          | 180.0693    |
| Q-std                          | 176.92554   |
| Q_loss                         | 94.61928    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 438         |
| times/epoch_after_hook         | 2.03e-06    |
| times/epoch_before_hook        | 9.97e-05    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000546    |
| times/evaluation_paths         | 21.9        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00778     |
| times/train                    | 54.9        |
| timestep                       | 1000        |
| timesteps_total                | 439000      |
| train-steps                    | 439000      |
| training/Q/q1_loss             | 103.00424   |
| training/sac_pi/alpha          | 0.17311315  |
| training/sac_pi/alpha_loss     | -0.14425614 |
| training/sac_pi/logp_pi        | 4.188546    |
| training/sac_pi/pi_entropy     | 3.3989987   |
| training/sac_pi/pi_global_norm | 1.6788601   |
| training/sac_pi/policy_loss    | -202.78404  |
| training/sac_pi/std            | 0.48005518  |
| training/sac_pi/valid_num      | 4986.0      |
| training/sac_Q/q1              | 192.96196   |
| training/sac_Q/q2              | 190.0236    |
| training/sac_Q/q2_loss         | 101.75869   |
| training/sac_Q/q_global_norm   | 226.72177   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16900277  |
| epoch                          | 439         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4749.2163   |
| evaluation/return-max          | 4833.681    |
| evaluation/return-min          | 4706.957    |
| evaluation/return-std          | 38.53321    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.86        |
| model/origin_ret               | 82.4        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45684       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4749.2163   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 185.87729   |
| Q-std                          | 165.03265   |
| Q_loss                         | 110.42228   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 439         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000101    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000598    |
| times/evaluation_paths         | 30          |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00789     |
| times/train                    | 54.8        |
| timestep                       | 1000        |
| timesteps_total                | 440000      |
| train-steps                    | 440000      |
| training/Q/q1_loss             | 113.72518   |
| training/sac_pi/alpha          | 0.16896507  |
| training/sac_pi/alpha_loss     | 0.087636285 |
| training/sac_pi/logp_pi        | 4.50406     |
| training/sac_pi/pi_entropy     | 3.4079528   |
| training/sac_pi/pi_global_norm | 1.3017834   |
| training/sac_pi/policy_loss    | -207.06236  |
| training/sac_pi/std            | 0.51861966  |
| training/sac_pi/valid_num      | 4949.0      |
| training/sac_Q/q1              | 189.05734   |
| training/sac_Q/q2              | 185.76079   |
| training/sac_Q/q2_loss         | 113.32446   |
| training/sac_Q/q_global_norm   | 274.11124   |
---------------------------------------------------------------------------------
[WARN] 440 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.17014068 |
| epoch                          | 440        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4955.518   |
| evaluation/return-max          | 4984.654   |
| evaluation/return-min          | 4926.8457  |
| evaluation/return-std          | 19.66714   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45883      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4955.518   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 186.88573  |
| Q-std                          | 143.19305  |
| Q_loss                         | 110.405945 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 440        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000108   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000535   |
| times/evaluation_paths         | 31.3       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 55.5       |
| timestep                       | 1000       |
| timesteps_total                | 441000     |
| train-steps                    | 441000     |
| training/Q/q1_loss             | 83.52668   |
| training/sac_pi/alpha          | 0.17013097 |
| training/sac_pi/alpha_loss     | 0.0817146  |
| training/sac_pi/logp_pi        | 4.7267675  |
| training/sac_pi/pi_entropy     | 3.6197777  |
| training/sac_pi/pi_global_norm | 1.6513804  |
| training/sac_pi/policy_loss    | -198.84955 |
| training/sac_pi/std            | 0.5280706  |
| training/sac_pi/valid_num      | 4884.0     |
| training/sac_Q/q1              | 179.12196  |
| training/sac_Q/q2              | 178.61174  |
| training/sac_Q/q2_loss         | 82.69448   |
| training/sac_Q/q_global_norm   | 205.9147   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1629058  |
| epoch                          | 441        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5101.2603  |
| evaluation/return-max          | 5266.0557  |
| evaluation/return-min          | 4917.1055  |
| evaluation/return-std          | 98.741196  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45672      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5101.2603  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 181.98956  |
| Q-std                          | 191.19656  |
| Q_loss                         | 100.07449  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 441        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000276   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000631   |
| times/evaluation_paths         | 31.2       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00801    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 442000     |
| train-steps                    | 442000     |
| training/Q/q1_loss             | 103.01724  |
| training/sac_pi/alpha          | 0.16290784 |
| training/sac_pi/alpha_loss     | 0.14828488 |
| training/sac_pi/logp_pi        | 5.1989565  |
| training/sac_pi/pi_entropy     | 3.39002    |
| training/sac_pi/pi_global_norm | 1.8004441  |
| training/sac_pi/policy_loss    | -204.39763 |
| training/sac_pi/std            | 0.52956146 |
| training/sac_pi/valid_num      | 4911.0     |
| training/sac_Q/q1              | 183.27634  |
| training/sac_Q/q2              | 181.01624  |
| training/sac_Q/q2_loss         | 103.120476 |
| training/sac_Q/q_global_norm   | 217.22495  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16733024 |
| epoch                          | 442        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4991.5938  |
| evaluation/return-max          | 5041.119   |
| evaluation/return-min          | 4928.2344  |
| evaluation/return-std          | 35.49734   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45828      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4991.5938  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 187.59274  |
| Q-std                          | 153.10715  |
| Q_loss                         | 112.65061  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 442        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.00059    |
| times/evaluation_paths         | 30.9       |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 56         |
| timestep                       | 1000       |
| timesteps_total                | 443000     |
| train-steps                    | 443000     |
| training/Q/q1_loss             | 103.877556 |
| training/sac_pi/alpha          | 0.16731703 |
| training/sac_pi/alpha_loss     | 0.27089036 |
| training/sac_pi/logp_pi        | 4.1269484  |
| training/sac_pi/pi_entropy     | 3.451713   |
| training/sac_pi/pi_global_norm | 1.580032   |
| training/sac_pi/policy_loss    | -200.70412 |
| training/sac_pi/std            | 0.48990023 |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 190.61934  |
| training/sac_Q/q2              | 186.39363  |
| training/sac_Q/q2_loss         | 102.72381  |
| training/sac_Q/q_global_norm   | 210.30255  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16650167   |
| epoch                          | 443          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4814.986     |
| evaluation/return-max          | 4900.0347    |
| evaluation/return-min          | 4758.9277    |
| evaluation/return-std          | 40.482304    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.98         |
| model/origin_ret               | 84.8         |
| model/penalty_ret              | 81.4         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45850        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4814.986     |
| perf/NormalizedReturn          | 1.05         |
| Q-avg                          | 175.19865    |
| Q-std                          | 185.80107    |
| Q_loss                         | 88.78583     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 443          |
| times/epoch_after_hook         | 1.83e-06     |
| times/epoch_before_hook        | 0.000102     |
| times/epoch_rollout_model      | 480          |
| times/evaluation_metrics       | 0.000561     |
| times/evaluation_paths         | 31.5         |
| times/timestep_after_hook      | 0.00387      |
| times/timestep_before_hook     | 0.00811      |
| times/train                    | 55.3         |
| timestep                       | 1000         |
| timesteps_total                | 444000       |
| train-steps                    | 444000       |
| training/Q/q1_loss             | 82.14689     |
| training/sac_pi/alpha          | 0.16647384   |
| training/sac_pi/alpha_loss     | -0.036901653 |
| training/sac_pi/logp_pi        | 4.418485     |
| training/sac_pi/pi_entropy     | 3.364301     |
| training/sac_pi/pi_global_norm | 1.5475985    |
| training/sac_pi/policy_loss    | -210.8859    |
| training/sac_pi/std            | 0.4909459    |
| training/sac_pi/valid_num      | 4948.0       |
| training/sac_Q/q1              | 201.4501     |
| training/sac_Q/q2              | 199.28635    |
| training/sac_Q/q2_loss         | 82.134636    |
| training/sac_Q/q_global_norm   | 185.19333    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16235618  |
| epoch                          | 444         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4590.8525   |
| evaluation/return-max          | 4619.2314   |
| evaluation/return-min          | 4544.4395   |
| evaluation/return-std          | 22.415903   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45906       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4590.8525   |
| perf/NormalizedReturn          | 1           |
| Q-avg                          | 199.05528   |
| Q-std                          | 126.126274  |
| Q_loss                         | 88.28762    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 444         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000106    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000716    |
| times/evaluation_paths         | 30.5        |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 55.5        |
| timestep                       | 1000        |
| timesteps_total                | 445000      |
| train-steps                    | 445000      |
| training/Q/q1_loss             | 84.87251    |
| training/sac_pi/alpha          | 0.1623534   |
| training/sac_pi/alpha_loss     | -0.20431666 |
| training/sac_pi/logp_pi        | 4.222566    |
| training/sac_pi/pi_entropy     | 3.529985    |
| training/sac_pi/pi_global_norm | 1.5176148   |
| training/sac_pi/policy_loss    | -201.18472  |
| training/sac_pi/std            | 0.51638424  |
| training/sac_pi/valid_num      | 4913.0      |
| training/sac_Q/q1              | 186.04814   |
| training/sac_Q/q2              | 183.69986   |
| training/sac_Q/q2_loss         | 84.781586   |
| training/sac_Q/q_global_norm   | 151.90457   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16236454  |
| epoch                          | 445         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4798.7666   |
| evaluation/return-max          | 4833.2773   |
| evaluation/return-min          | 4756.107    |
| evaluation/return-std          | 27.101526   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.89        |
| model/origin_ret               | 83.5        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45573       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4798.7666   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 181.41216   |
| Q-std                          | 192.42969   |
| Q_loss                         | 110.17884   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 445         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000278    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000632    |
| times/evaluation_paths         | 31.4        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 55.3        |
| timestep                       | 1000        |
| timesteps_total                | 446000      |
| train-steps                    | 446000      |
| training/Q/q1_loss             | 90.64648    |
| training/sac_pi/alpha          | 0.1623644   |
| training/sac_pi/alpha_loss     | -0.08901779 |
| training/sac_pi/logp_pi        | 4.207648    |
| training/sac_pi/pi_entropy     | 3.505633    |
| training/sac_pi/pi_global_norm | 1.6246672   |
| training/sac_pi/policy_loss    | -198.79863  |
| training/sac_pi/std            | 0.5061862   |
| training/sac_pi/valid_num      | 4897.0      |
| training/sac_Q/q1              | 185.77982   |
| training/sac_Q/q2              | 183.47665   |
| training/sac_Q/q2_loss         | 91.61327    |
| training/sac_Q/q_global_norm   | 251.86285   |
---------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.17193478    |
| epoch                          | 446           |
| evaluation/episode-length-avg  | 1e+03         |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 1000          |
| evaluation/episode-length-std  | 0             |
| evaluation/return-average      | 4695.664      |
| evaluation/return-max          | 4715.257      |
| evaluation/return-min          | 4672.626      |
| evaluation/return-std          | 12.050556     |
| model/max_penalty              | 7.34          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 2.98          |
| model/origin_ret               | 84.5          |
| model/penalty_ret              | 81.6          |
| model/val_loss                 | 0.35430613    |
| model/valid_num                | 45840         |
| perf/AverageLength             | 1e+03         |
| perf/AverageReturn             | 4695.664      |
| perf/NormalizedReturn          | 1.02          |
| Q-avg                          | 185.61552     |
| Q-std                          | 178.03433     |
| Q_loss                         | 92.62329      |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 446           |
| times/epoch_after_hook         | 1.78e-06      |
| times/epoch_before_hook        | 0.000108      |
| times/epoch_rollout_model      | 487           |
| times/evaluation_metrics       | 0.00061       |
| times/evaluation_paths         | 31.3          |
| times/timestep_after_hook      | 0.00397       |
| times/timestep_before_hook     | 0.00828       |
| times/train                    | 57.2          |
| timestep                       | 1000          |
| timesteps_total                | 447000        |
| train-steps                    | 447000        |
| training/Q/q1_loss             | 101.58395     |
| training/sac_pi/alpha          | 0.17193206    |
| training/sac_pi/alpha_loss     | -0.0032067318 |
| training/sac_pi/logp_pi        | 4.618042      |
| training/sac_pi/pi_entropy     | 3.4855309     |
| training/sac_pi/pi_global_norm | 1.471432      |
| training/sac_pi/policy_loss    | -210.2697     |
| training/sac_pi/std            | 0.51256526    |
| training/sac_pi/valid_num      | 4988.0        |
| training/sac_Q/q1              | 195.86137     |
| training/sac_Q/q2              | 193.17609     |
| training/sac_Q/q2_loss         | 102.54547     |
| training/sac_Q/q_global_norm   | 200.37785     |
-----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16548432 |
| epoch                          | 447        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4688.413   |
| evaluation/return-max          | 4745.671   |
| evaluation/return-min          | 4603.77    |
| evaluation/return-std          | 35.14115   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45753      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4688.413   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 192.79225  |
| Q-std                          | 148.45499  |
| Q_loss                         | 98.19373   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 447        |
| times/epoch_after_hook         | 3.39e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000652   |
| times/evaluation_paths         | 32.3       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 56.1       |
| timestep                       | 1000       |
| timesteps_total                | 448000     |
| train-steps                    | 448000     |
| training/Q/q1_loss             | 117.29725  |
| training/sac_pi/alpha          | 0.16550589 |
| training/sac_pi/alpha_loss     | 0.43658584 |
| training/sac_pi/logp_pi        | 4.9664445  |
| training/sac_pi/pi_entropy     | 3.4575944  |
| training/sac_pi/pi_global_norm | 1.5623251  |
| training/sac_pi/policy_loss    | -203.57858 |
| training/sac_pi/std            | 0.52159274 |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 184.4262   |
| training/sac_Q/q2              | 183.0912   |
| training/sac_Q/q2_loss         | 117.29503  |
| training/sac_Q/q_global_norm   | 240.30458  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16690268  |
| epoch                          | 448         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4803.642    |
| evaluation/return-max          | 4834.7393   |
| evaluation/return-min          | 4773.999    |
| evaluation/return-std          | 18.753363   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45746       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4803.642    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 189.3008    |
| Q-std                          | 155.58365   |
| Q_loss                         | 84.65871    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 448         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000544    |
| times/evaluation_paths         | 31.4        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 54.5        |
| timestep                       | 1000        |
| timesteps_total                | 449000      |
| train-steps                    | 449000      |
| training/Q/q1_loss             | 93.1931     |
| training/sac_pi/alpha          | 0.16693392  |
| training/sac_pi/alpha_loss     | -0.18806714 |
| training/sac_pi/logp_pi        | 4.654451    |
| training/sac_pi/pi_entropy     | 3.6446946   |
| training/sac_pi/pi_global_norm | 1.7795306   |
| training/sac_pi/policy_loss    | -209.59595  |
| training/sac_pi/std            | 0.554116    |
| training/sac_pi/valid_num      | 4890.0      |
| training/sac_Q/q1              | 188.8275    |
| training/sac_Q/q2              | 184.98969   |
| training/sac_Q/q2_loss         | 93.46348    |
| training/sac_Q/q_global_norm   | 186.19385   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17380446  |
| epoch                          | 449         |
| evaluation/episode-length-avg  | 476         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 126         |
| evaluation/episode-length-std  | 428         |
| evaluation/return-average      | 2077.7344   |
| evaluation/return-max          | 4783.8877   |
| evaluation/return-min          | 295.55212   |
| evaluation/return-std          | 2177.515    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 82.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45671       |
| perf/AverageLength             | 476         |
| perf/AverageReturn             | 2077.7344   |
| perf/NormalizedReturn          | 0.452       |
| Q-avg                          | 181.16382   |
| Q-std                          | 180.84143   |
| Q_loss                         | 94.38858    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 449         |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 0.00028     |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000532    |
| times/evaluation_paths         | 14.7        |
| times/timestep_after_hook      | 0.00354     |
| times/timestep_before_hook     | 0.00786     |
| times/train                    | 55.1        |
| timestep                       | 1000        |
| timesteps_total                | 450000      |
| train-steps                    | 450000      |
| training/Q/q1_loss             | 75.50815    |
| training/sac_pi/alpha          | 0.17381774  |
| training/sac_pi/alpha_loss     | -0.26681402 |
| training/sac_pi/logp_pi        | 3.167211    |
| training/sac_pi/pi_entropy     | 3.4475617   |
| training/sac_pi/pi_global_norm | 2.1072288   |
| training/sac_pi/policy_loss    | -210.6645   |
| training/sac_pi/std            | 0.45702156  |
| training/sac_pi/valid_num      | 5075.0      |
| training/sac_Q/q1              | 208.34126   |
| training/sac_Q/q2              | 208.66147   |
| training/sac_Q/q2_loss         | 75.18519    |
| training/sac_Q/q_global_norm   | 262.86978   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17394038 |
| epoch                          | 450        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4894.7856  |
| evaluation/return-max          | 4927.7544  |
| evaluation/return-min          | 4865.426   |
| evaluation/return-std          | 20.88131   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45770      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4894.7856  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 195.69963  |
| Q-std                          | 131.81319  |
| Q_loss                         | 108.658455 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 450        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000619   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 56.9       |
| timestep                       | 1000       |
| timesteps_total                | 451000     |
| train-steps                    | 451000     |
| training/Q/q1_loss             | 111.232666 |
| training/sac_pi/alpha          | 0.17390533 |
| training/sac_pi/alpha_loss     | 0.42744112 |
| training/sac_pi/logp_pi        | 4.85558    |
| training/sac_pi/pi_entropy     | 3.6823792  |
| training/sac_pi/pi_global_norm | 1.3899989  |
| training/sac_pi/policy_loss    | -195.54366 |
| training/sac_pi/std            | 0.5329838  |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 181.72794  |
| training/sac_Q/q2              | 178.99747  |
| training/sac_Q/q2_loss         | 110.7074   |
| training/sac_Q/q_global_norm   | 278.98215  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.169466   |
| epoch                          | 451        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4721.179   |
| evaluation/return-max          | 4810.9053  |
| evaluation/return-min          | 4654.5537  |
| evaluation/return-std          | 45.79356   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45889      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4721.179   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 167.20764  |
| Q-std                          | 191.44276  |
| Q_loss                         | 111.960594 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 451        |
| times/epoch_after_hook         | 2.31e-06   |
| times/epoch_before_hook        | 9.93e-05   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000623   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00341    |
| times/timestep_before_hook     | 0.00771    |
| times/train                    | 53.7       |
| timestep                       | 1000       |
| timesteps_total                | 452000     |
| train-steps                    | 452000     |
| training/Q/q1_loss             | 100.77901  |
| training/sac_pi/alpha          | 0.16944402 |
| training/sac_pi/alpha_loss     | 0.3367879  |
| training/sac_pi/logp_pi        | 4.910128   |
| training/sac_pi/pi_entropy     | 3.3269088  |
| training/sac_pi/pi_global_norm | 1.3856037  |
| training/sac_pi/policy_loss    | -198.72606 |
| training/sac_pi/std            | 0.4949312  |
| training/sac_pi/valid_num      | 4937.0     |
| training/sac_Q/q1              | 184.78012  |
| training/sac_Q/q2              | 180.8356   |
| training/sac_Q/q2_loss         | 99.58192   |
| training/sac_Q/q_global_norm   | 196.29027  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16610478 |
| epoch                          | 452        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5115.0176  |
| evaluation/return-max          | 5159.56    |
| evaluation/return-min          | 5075.9355  |
| evaluation/return-std          | 25.103674  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45647      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5115.0176  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 191.48264  |
| Q-std                          | 153.40198  |
| Q_loss                         | 120.53979  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 452        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000119   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000623   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00789    |
| times/train                    | 54.1       |
| timestep                       | 1000       |
| timesteps_total                | 453000     |
| train-steps                    | 453000     |
| training/Q/q1_loss             | 88.48827   |
| training/sac_pi/alpha          | 0.16609421 |
| training/sac_pi/alpha_loss     | 0.10273069 |
| training/sac_pi/logp_pi        | 5.051266   |
| training/sac_pi/pi_entropy     | 3.5209973  |
| training/sac_pi/pi_global_norm | 1.9872625  |
| training/sac_pi/policy_loss    | -209.62537 |
| training/sac_pi/std            | 0.5432939  |
| training/sac_pi/valid_num      | 4875.0     |
| training/sac_Q/q1              | 188.82303  |
| training/sac_Q/q2              | 182.05367  |
| training/sac_Q/q2_loss         | 89.045845  |
| training/sac_Q/q_global_norm   | 222.78506  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16739744   |
| epoch                          | 453          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4787.0264    |
| evaluation/return-max          | 4845.1465    |
| evaluation/return-min          | 4684.966     |
| evaluation/return-std          | 42.72535     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.97         |
| model/origin_ret               | 85.3         |
| model/penalty_ret              | 82.4         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45679        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4787.0264    |
| perf/NormalizedReturn          | 1.04         |
| Q-avg                          | 180.20015    |
| Q-std                          | 173.14056    |
| Q_loss                         | 92.193504    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 453          |
| times/epoch_after_hook         | 1.79e-06     |
| times/epoch_before_hook        | 0.000274     |
| times/epoch_rollout_model      | 493          |
| times/evaluation_metrics       | 0.000535     |
| times/evaluation_paths         | 29.9         |
| times/timestep_after_hook      | 0.00355      |
| times/timestep_before_hook     | 0.00807      |
| times/train                    | 54.4         |
| timestep                       | 1000         |
| timesteps_total                | 454000       |
| train-steps                    | 454000       |
| training/Q/q1_loss             | 117.141205   |
| training/sac_pi/alpha          | 0.16740003   |
| training/sac_pi/alpha_loss     | -0.078322135 |
| training/sac_pi/logp_pi        | 4.126018     |
| training/sac_pi/pi_entropy     | 3.4991841    |
| training/sac_pi/pi_global_norm | 1.7341864    |
| training/sac_pi/policy_loss    | -205.59256   |
| training/sac_pi/std            | 0.50362945   |
| training/sac_pi/valid_num      | 4990.0       |
| training/sac_Q/q1              | 194.64766    |
| training/sac_Q/q2              | 191.80972    |
| training/sac_Q/q2_loss         | 116.268425   |
| training/sac_Q/q_global_norm   | 265.51526    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16837737  |
| epoch                          | 454         |
| evaluation/episode-length-avg  | 832         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 157         |
| evaluation/episode-length-std  | 337         |
| evaluation/return-average      | 4239.9165   |
| evaluation/return-max          | 5258.885    |
| evaluation/return-min          | 538.10986   |
| evaluation/return-std          | 1849.412    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 83.6        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45632       |
| perf/AverageLength             | 832         |
| perf/AverageReturn             | 4239.9165   |
| perf/NormalizedReturn          | 0.923       |
| Q-avg                          | 180.90448   |
| Q-std                          | 172.16064   |
| Q_loss                         | 127.30157   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 454         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000488    |
| times/evaluation_paths         | 25.5        |
| times/timestep_after_hook      | 0.00357     |
| times/timestep_before_hook     | 0.00806     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 455000      |
| train-steps                    | 455000      |
| training/Q/q1_loss             | 110.020424  |
| training/sac_pi/alpha          | 0.16843702  |
| training/sac_pi/alpha_loss     | -0.16157588 |
| training/sac_pi/logp_pi        | 4.9179487   |
| training/sac_pi/pi_entropy     | 3.4527214   |
| training/sac_pi/pi_global_norm | 1.8231971   |
| training/sac_pi/policy_loss    | -201.66617  |
| training/sac_pi/std            | 0.5152662   |
| training/sac_pi/valid_num      | 4936.0      |
| training/sac_Q/q1              | 185.81306   |
| training/sac_Q/q2              | 181.82434   |
| training/sac_Q/q2_loss         | 109.40654   |
| training/sac_Q/q_global_norm   | 218.49306   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16631548 |
| epoch                          | 455        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4909.771   |
| evaluation/return-max          | 5008.274   |
| evaluation/return-min          | 4831.5723  |
| evaluation/return-std          | 68.17203   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45803      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4909.771   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 185.74625  |
| Q-std                          | 188.64545  |
| Q_loss                         | 106.6358   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 455        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 9.1e-05    |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000603   |
| times/evaluation_paths         | 30.9       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00783    |
| times/train                    | 55.4       |
| timestep                       | 1000       |
| timesteps_total                | 456000     |
| train-steps                    | 456000     |
| training/Q/q1_loss             | 91.98236   |
| training/sac_pi/alpha          | 0.16634585 |
| training/sac_pi/alpha_loss     | -0.2701638 |
| training/sac_pi/logp_pi        | 4.0128574  |
| training/sac_pi/pi_entropy     | 3.3930314  |
| training/sac_pi/pi_global_norm | 1.8660725  |
| training/sac_pi/policy_loss    | -204.09975 |
| training/sac_pi/std            | 0.4899325  |
| training/sac_pi/valid_num      | 4995.0     |
| training/sac_Q/q1              | 192.31161  |
| training/sac_Q/q2              | 191.119    |
| training/sac_Q/q2_loss         | 91.69026   |
| training/sac_Q/q_global_norm   | 311.36053  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.171555    |
| epoch                          | 456         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4831.953    |
| evaluation/return-max          | 4897.223    |
| evaluation/return-min          | 4749.417    |
| evaluation/return-std          | 45.526814   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45694       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4831.953    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 179.07153   |
| Q-std                          | 199.58463   |
| Q_loss                         | 106.615036  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 456         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000136    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.00061     |
| times/evaluation_paths         | 30          |
| times/timestep_after_hook      | 0.00348     |
| times/timestep_before_hook     | 0.00781     |
| times/train                    | 54.9        |
| timestep                       | 1000        |
| timesteps_total                | 457000      |
| train-steps                    | 457000      |
| training/Q/q1_loss             | 99.02425    |
| training/sac_pi/alpha          | 0.17154662  |
| training/sac_pi/alpha_loss     | -0.24031493 |
| training/sac_pi/logp_pi        | 4.1192026   |
| training/sac_pi/pi_entropy     | 3.5500717   |
| training/sac_pi/pi_global_norm | 1.5162642   |
| training/sac_pi/policy_loss    | -205.46678  |
| training/sac_pi/std            | 0.51744956  |
| training/sac_pi/valid_num      | 4937.0      |
| training/sac_Q/q1              | 185.5879    |
| training/sac_Q/q2              | 184.56377   |
| training/sac_Q/q2_loss         | 99.841286   |
| training/sac_Q/q_global_norm   | 272.212     |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16914912  |
| epoch                          | 457         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4529.8267   |
| evaluation/return-max          | 4626.7676   |
| evaluation/return-min          | 4444.1455   |
| evaluation/return-std          | 57.70943    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45722       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4529.8267   |
| perf/NormalizedReturn          | 0.986       |
| Q-avg                          | 189.0697    |
| Q-std                          | 158.03835   |
| Q_loss                         | 104.08203   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 457         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000275    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000618    |
| times/evaluation_paths         | 30.6        |
| times/timestep_after_hook      | 0.00344     |
| times/timestep_before_hook     | 0.00788     |
| times/train                    | 55.2        |
| timestep                       | 1000        |
| timesteps_total                | 458000      |
| train-steps                    | 458000      |
| training/Q/q1_loss             | 92.63697    |
| training/sac_pi/alpha          | 0.1691553   |
| training/sac_pi/alpha_loss     | 0.015296637 |
| training/sac_pi/logp_pi        | 5.013953    |
| training/sac_pi/pi_entropy     | 3.344138    |
| training/sac_pi/pi_global_norm | 1.4662029   |
| training/sac_pi/policy_loss    | -206.21848  |
| training/sac_pi/std            | 0.5067948   |
| training/sac_pi/valid_num      | 4897.0      |
| training/sac_Q/q1              | 189.07512   |
| training/sac_Q/q2              | 187.903     |
| training/sac_Q/q2_loss         | 91.85121    |
| training/sac_Q/q_global_norm   | 171.81062   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16980477 |
| epoch                          | 458        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5029.3237  |
| evaluation/return-max          | 5081.856   |
| evaluation/return-min          | 4980.15    |
| evaluation/return-std          | 27.49319   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45757      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5029.3237  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 188.65598  |
| Q-std                          | 146.19646  |
| Q_loss                         | 91.29026   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 458        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000103   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000598   |
| times/evaluation_paths         | 30.6       |
| times/timestep_after_hook      | 0.00351    |
| times/timestep_before_hook     | 0.00767    |
| times/train                    | 54.1       |
| timestep                       | 1000       |
| timesteps_total                | 459000     |
| train-steps                    | 459000     |
| training/Q/q1_loss             | 90.99261   |
| training/sac_pi/alpha          | 0.1697804  |
| training/sac_pi/alpha_loss     | 0.1822861  |
| training/sac_pi/logp_pi        | 4.339077   |
| training/sac_pi/pi_entropy     | 3.328466   |
| training/sac_pi/pi_global_norm | 1.9186292  |
| training/sac_pi/policy_loss    | -214.24452 |
| training/sac_pi/std            | 0.48591292 |
| training/sac_pi/valid_num      | 5015.0     |
| training/sac_Q/q1              | 203.0383   |
| training/sac_Q/q2              | 202.00443  |
| training/sac_Q/q2_loss         | 90.89344   |
| training/sac_Q/q_global_norm   | 276.2628   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16450274 |
| epoch                          | 459        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4881.771   |
| evaluation/return-max          | 4934.1816  |
| evaluation/return-min          | 4798.165   |
| evaluation/return-std          | 39.254772  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45837      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4881.771   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 178.90286  |
| Q-std                          | 187.0249   |
| Q_loss                         | 81.16599   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 459        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000108   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000605   |
| times/evaluation_paths         | 30.1       |
| times/timestep_after_hook      | 0.00356    |
| times/timestep_before_hook     | 0.00776    |
| times/train                    | 55.2       |
| timestep                       | 1000       |
| timesteps_total                | 460000     |
| train-steps                    | 460000     |
| training/Q/q1_loss             | 129.94485  |
| training/sac_pi/alpha          | 0.16449386 |
| training/sac_pi/alpha_loss     | 0.12295508 |
| training/sac_pi/logp_pi        | 4.320426   |
| training/sac_pi/pi_entropy     | 3.552822   |
| training/sac_pi/pi_global_norm | 1.6758898  |
| training/sac_pi/policy_loss    | -200.92944 |
| training/sac_pi/std            | 0.5170094  |
| training/sac_pi/valid_num      | 4930.0     |
| training/sac_Q/q1              | 189.07312  |
| training/sac_Q/q2              | 188.55417  |
| training/sac_Q/q2_loss         | 129.24045  |
| training/sac_Q/q_global_norm   | 205.36438  |
--------------------------------------------------------------------------------
[WARN] 460 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16355035 |
| epoch                          | 460        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4497.6255  |
| evaluation/return-max          | 4594.361   |
| evaluation/return-min          | 4419.458   |
| evaluation/return-std          | 58.186047  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 83         |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45838      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4497.6255  |
| perf/NormalizedReturn          | 0.979      |
| Q-avg                          | 177.94797  |
| Q-std                          | 193.65561  |
| Q_loss                         | 90.008804  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 460        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000142   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000647   |
| times/evaluation_paths         | 30.6       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00795    |
| times/train                    | 53.2       |
| timestep                       | 1000       |
| timesteps_total                | 461000     |
| train-steps                    | 461000     |
| training/Q/q1_loss             | 108.49037  |
| training/sac_pi/alpha          | 0.16355707 |
| training/sac_pi/alpha_loss     | 0.16875267 |
| training/sac_pi/logp_pi        | 4.9239526  |
| training/sac_pi/pi_entropy     | 3.4932091  |
| training/sac_pi/pi_global_norm | 1.5748565  |
| training/sac_pi/policy_loss    | -195.11115 |
| training/sac_pi/std            | 0.52157    |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 181.09761  |
| training/sac_Q/q2              | 179.49626  |
| training/sac_Q/q2_loss         | 108.89859  |
| training/sac_Q/q_global_norm   | 299.8672   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16416997  |
| epoch                          | 461         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4960.4995   |
| evaluation/return-max          | 5029.6406   |
| evaluation/return-min          | 4900.682    |
| evaluation/return-std          | 43.157543   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45783       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4960.4995   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 190.70137   |
| Q-std                          | 154.11688   |
| Q_loss                         | 103.25364   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 461         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000281    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000593    |
| times/evaluation_paths         | 30.3        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00806     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 462000      |
| train-steps                    | 462000      |
| training/Q/q1_loss             | 107.59657   |
| training/sac_pi/alpha          | 0.16415286  |
| training/sac_pi/alpha_loss     | -0.47379225 |
| training/sac_pi/logp_pi        | 4.0651245   |
| training/sac_pi/pi_entropy     | 3.4267972   |
| training/sac_pi/pi_global_norm | 1.8408617   |
| training/sac_pi/policy_loss    | -203.77202  |
| training/sac_pi/std            | 0.50278085  |
| training/sac_pi/valid_num      | 4964.0      |
| training/sac_Q/q1              | 188.21585   |
| training/sac_Q/q2              | 187.0693    |
| training/sac_Q/q2_loss         | 107.81672   |
| training/sac_Q/q_global_norm   | 267.10324   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16208953  |
| epoch                          | 462         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4890.134    |
| evaluation/return-max          | 4951.5713   |
| evaluation/return-min          | 4842.955    |
| evaluation/return-std          | 33.075417   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45622       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4890.134    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 175.75684   |
| Q-std                          | 206.10286   |
| Q_loss                         | 91.02696    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 462         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000573    |
| times/evaluation_paths         | 29.5        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00822     |
| times/train                    | 54.9        |
| timestep                       | 1000        |
| timesteps_total                | 463000      |
| train-steps                    | 463000      |
| training/Q/q1_loss             | 97.68598    |
| training/sac_pi/alpha          | 0.16205506  |
| training/sac_pi/alpha_loss     | -0.13300563 |
| training/sac_pi/logp_pi        | 4.1882095   |
| training/sac_pi/pi_entropy     | 3.5530014   |
| training/sac_pi/pi_global_norm | 1.3660079   |
| training/sac_pi/policy_loss    | -194.26263  |
| training/sac_pi/std            | 0.5145538   |
| training/sac_pi/valid_num      | 4938.0      |
| training/sac_Q/q1              | 182.05377   |
| training/sac_Q/q2              | 178.54106   |
| training/sac_Q/q2_loss         | 96.74646    |
| training/sac_Q/q_global_norm   | 218.22878   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15997155 |
| epoch                          | 463        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4649.5513  |
| evaluation/return-max          | 4767.185   |
| evaluation/return-min          | 4545.6157  |
| evaluation/return-std          | 77.87935   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45665      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4649.5513  |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 192.57082  |
| Q-std                          | 151.33792  |
| Q_loss                         | 97.01023   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 463        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000156   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000557   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 55.1       |
| timestep                       | 1000       |
| timesteps_total                | 464000     |
| train-steps                    | 464000     |
| training/Q/q1_loss             | 103.6516   |
| training/sac_pi/alpha          | 0.16000837 |
| training/sac_pi/alpha_loss     | -0.1582435 |
| training/sac_pi/logp_pi        | 4.8408957  |
| training/sac_pi/pi_entropy     | 3.3675575  |
| training/sac_pi/pi_global_norm | 1.4643617  |
| training/sac_pi/policy_loss    | -201.25984 |
| training/sac_pi/std            | 0.50823027 |
| training/sac_pi/valid_num      | 4915.0     |
| training/sac_Q/q1              | 183.5759   |
| training/sac_Q/q2              | 182.97865  |
| training/sac_Q/q2_loss         | 103.64523  |
| training/sac_Q/q_global_norm   | 254.95543  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16629282  |
| epoch                          | 464         |
| evaluation/episode-length-avg  | 827         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 132         |
| evaluation/episode-length-std  | 346         |
| evaluation/return-average      | 3866.8047   |
| evaluation/return-max          | 4767.048    |
| evaluation/return-min          | 313.59763   |
| evaluation/return-std          | 1768.6093   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.89        |
| model/origin_ret               | 83.8        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45571       |
| perf/AverageLength             | 827         |
| perf/AverageReturn             | 3866.8047   |
| perf/NormalizedReturn          | 0.842       |
| Q-avg                          | 184.56126   |
| Q-std                          | 133.38152   |
| Q_loss                         | 104.864426  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 464         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000107    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000612    |
| times/evaluation_paths         | 25.4        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 54.4        |
| timestep                       | 1000        |
| timesteps_total                | 465000      |
| train-steps                    | 465000      |
| training/Q/q1_loss             | 102.21091   |
| training/sac_pi/alpha          | 0.16628152  |
| training/sac_pi/alpha_loss     | -0.01651211 |
| training/sac_pi/logp_pi        | 4.465875    |
| training/sac_pi/pi_entropy     | 3.4858658   |
| training/sac_pi/pi_global_norm | 1.6324244   |
| training/sac_pi/policy_loss    | -201.33662  |
| training/sac_pi/std            | 0.50778496  |
| training/sac_pi/valid_num      | 4984.0      |
| training/sac_Q/q1              | 190.89578   |
| training/sac_Q/q2              | 187.43024   |
| training/sac_Q/q2_loss         | 102.65685   |
| training/sac_Q/q_global_norm   | 251.96593   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16780262  |
| epoch                          | 465         |
| evaluation/episode-length-avg  | 388         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 112         |
| evaluation/episode-length-std  | 401         |
| evaluation/return-average      | 1626.066    |
| evaluation/return-max          | 4790.335    |
| evaluation/return-min          | 241.80661   |
| evaluation/return-std          | 2048.0178   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45770       |
| perf/AverageLength             | 388         |
| perf/AverageReturn             | 1626.066    |
| perf/NormalizedReturn          | 0.354       |
| Q-avg                          | 187.12332   |
| Q-std                          | 168.96391   |
| Q_loss                         | 90.17373    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 465         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000293    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000471    |
| times/evaluation_paths         | 11.8        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00801     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 466000      |
| train-steps                    | 466000      |
| training/Q/q1_loss             | 98.73013    |
| training/sac_pi/alpha          | 0.16779839  |
| training/sac_pi/alpha_loss     | -0.09163196 |
| training/sac_pi/logp_pi        | 5.3761396   |
| training/sac_pi/pi_entropy     | 3.6239216   |
| training/sac_pi/pi_global_norm | 1.6373765   |
| training/sac_pi/policy_loss    | -205.77545  |
| training/sac_pi/std            | 0.57055485  |
| training/sac_pi/valid_num      | 4911.0      |
| training/sac_Q/q1              | 181.76431   |
| training/sac_Q/q2              | 181.56198   |
| training/sac_Q/q2_loss         | 99.348335   |
| training/sac_Q/q_global_norm   | 198.62611   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16647558  |
| epoch                          | 466         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4466.568    |
| evaluation/return-max          | 4646.9795   |
| evaluation/return-min          | 4370.2217   |
| evaluation/return-std          | 70.29535    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 83.8        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45758       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4466.568    |
| perf/NormalizedReturn          | 0.973       |
| Q-avg                          | 165.99696   |
| Q-std                          | 214.20743   |
| Q_loss                         | 84.657295   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 466         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000113    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000528    |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 467000      |
| train-steps                    | 467000      |
| training/Q/q1_loss             | 125.78567   |
| training/sac_pi/alpha          | 0.16645375  |
| training/sac_pi/alpha_loss     | -0.24153647 |
| training/sac_pi/logp_pi        | 5.405299    |
| training/sac_pi/pi_entropy     | 3.6856809   |
| training/sac_pi/pi_global_norm | 1.8415294   |
| training/sac_pi/policy_loss    | -196.33826  |
| training/sac_pi/std            | 0.57669455  |
| training/sac_pi/valid_num      | 4871.0      |
| training/sac_Q/q1              | 169.66127   |
| training/sac_Q/q2              | 163.76872   |
| training/sac_Q/q2_loss         | 126.21768   |
| training/sac_Q/q_global_norm   | 271.94727   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17364293   |
| epoch                          | 467          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4994.2256    |
| evaluation/return-max          | 5020.1377    |
| evaluation/return-min          | 4938.286     |
| evaluation/return-std          | 23.470427    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.86         |
| model/origin_ret               | 82.7         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45727        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4994.2256    |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 190.3678     |
| Q-std                          | 152.69582    |
| Q_loss                         | 94.198746    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 467          |
| times/epoch_after_hook         | 1.9e-06      |
| times/epoch_before_hook        | 0.000104     |
| times/epoch_rollout_model      | 487          |
| times/evaluation_metrics       | 0.000591     |
| times/evaluation_paths         | 30.9         |
| times/timestep_after_hook      | 0.00382      |
| times/timestep_before_hook     | 0.00814      |
| times/train                    | 55.8         |
| timestep                       | 1000         |
| timesteps_total                | 468000       |
| train-steps                    | 468000       |
| training/Q/q1_loss             | 112.04243    |
| training/sac_pi/alpha          | 0.17366092   |
| training/sac_pi/alpha_loss     | -0.020454446 |
| training/sac_pi/logp_pi        | 4.824713     |
| training/sac_pi/pi_entropy     | 3.7842116    |
| training/sac_pi/pi_global_norm | 1.6027937    |
| training/sac_pi/policy_loss    | -196.35033   |
| training/sac_pi/std            | 0.5417764    |
| training/sac_pi/valid_num      | 4883.0       |
| training/sac_Q/q1              | 182.60895    |
| training/sac_Q/q2              | 178.52074    |
| training/sac_Q/q2_loss         | 112.83241    |
| training/sac_Q/q_global_norm   | 290.30414    |
----------------------------------------------------------------------------------
------------------------------------------------------------------------------------
| alpha                          | 0.16602795     |
| epoch                          | 468            |
| evaluation/episode-length-avg  | 1e+03          |
| evaluation/episode-length-max  | 1000           |
| evaluation/episode-length-min  | 1000           |
| evaluation/episode-length-std  | 0              |
| evaluation/return-average      | 5071.542       |
| evaluation/return-max          | 5116.6597      |
| evaluation/return-min          | 4994.837       |
| evaluation/return-std          | 32.10859       |
| model/max_penalty              | 7.34           |
| model/mean_rollout_length      | 20             |
| model/mean_rollout_reward      | 2.95           |
| model/origin_ret               | 85.4           |
| model/penalty_ret              | 82.2           |
| model/val_loss                 | 0.35430613     |
| model/valid_num                | 45618          |
| perf/AverageLength             | 1e+03          |
| perf/AverageReturn             | 5071.542       |
| perf/NormalizedReturn          | 1.1            |
| Q-avg                          | 189.40147      |
| Q-std                          | 156.55246      |
| Q_loss                         | 87.81967       |
| sampler/episodes               | 0              |
| sampler/last-path-return       | 0              |
| sampler/max-path-return        | -inf           |
| sampler/pool-size              | 1000000        |
| sampler/total-samples          | 0              |
| time-step                      | 468            |
| times/epoch_after_hook         | 1.95e-06       |
| times/epoch_before_hook        | 0.000128       |
| times/epoch_rollout_model      | 483            |
| times/evaluation_metrics       | 0.000572       |
| times/evaluation_paths         | 30.9           |
| times/timestep_after_hook      | 0.00374        |
| times/timestep_before_hook     | 0.0103         |
| times/train                    | 55.2           |
| timestep                       | 1000           |
| timesteps_total                | 469000         |
| train-steps                    | 469000         |
| training/Q/q1_loss             | 105.76176      |
| training/sac_pi/alpha          | 0.16605651     |
| training/sac_pi/alpha_loss     | -0.00054743706 |
| training/sac_pi/logp_pi        | 4.243821       |
| training/sac_pi/pi_entropy     | 3.442072       |
| training/sac_pi/pi_global_norm | 1.4008585      |
| training/sac_pi/policy_loss    | -210.06848     |
| training/sac_pi/std            | 0.5035558      |
| training/sac_pi/valid_num      | 4977.0         |
| training/sac_Q/q1              | 195.01901      |
| training/sac_Q/q2              | 192.15677      |
| training/sac_Q/q2_loss         | 106.258995     |
| training/sac_Q/q_global_norm   | 227.21434      |
------------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1689859    |
| epoch                          | 469          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4987.8296    |
| evaluation/return-max          | 5010.4365    |
| evaluation/return-min          | 4973.796     |
| evaluation/return-std          | 11.691676    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.95         |
| model/origin_ret               | 84.7         |
| model/penalty_ret              | 81.9         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45797        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4987.8296    |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 195.28036    |
| Q-std                          | 147.81259    |
| Q_loss                         | 71.4076      |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 469          |
| times/epoch_after_hook         | 1.8e-06      |
| times/epoch_before_hook        | 0.000333     |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.000654     |
| times/evaluation_paths         | 30.1         |
| times/timestep_after_hook      | 0.00383      |
| times/timestep_before_hook     | 0.00819      |
| times/train                    | 57           |
| timestep                       | 1000         |
| timesteps_total                | 470000       |
| train-steps                    | 470000       |
| training/Q/q1_loss             | 104.10911    |
| training/sac_pi/alpha          | 0.1689971    |
| training/sac_pi/alpha_loss     | -0.087326586 |
| training/sac_pi/logp_pi        | 4.0825996    |
| training/sac_pi/pi_entropy     | 3.5058784    |
| training/sac_pi/pi_global_norm | 1.4902402    |
| training/sac_pi/policy_loss    | -204.73245   |
| training/sac_pi/std            | 0.4952704    |
| training/sac_pi/valid_num      | 4966.0       |
| training/sac_Q/q1              | 193.60886    |
| training/sac_Q/q2              | 192.80013    |
| training/sac_Q/q2_loss         | 104.06507    |
| training/sac_Q/q_global_norm   | 231.29204    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17182523 |
| epoch                          | 470        |
| evaluation/episode-length-avg  | 732        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 106        |
| evaluation/episode-length-std  | 409        |
| evaluation/return-average      | 3350.5774  |
| evaluation/return-max          | 4778.586   |
| evaluation/return-min          | 220.77612  |
| evaluation/return-std          | 2044.722   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45673      |
| perf/AverageLength             | 732        |
| perf/AverageReturn             | 3350.5774  |
| perf/NormalizedReturn          | 0.73       |
| Q-avg                          | 198.07845  |
| Q-std                          | 102.081604 |
| Q_loss                         | 96.47096   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 470        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000554   |
| times/evaluation_paths         | 22.5       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00806    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 471000     |
| train-steps                    | 471000     |
| training/Q/q1_loss             | 97.58503   |
| training/sac_pi/alpha          | 0.17180449 |
| training/sac_pi/alpha_loss     | 0.27281284 |
| training/sac_pi/logp_pi        | 4.0429945  |
| training/sac_pi/pi_entropy     | 3.5190308  |
| training/sac_pi/pi_global_norm | 1.3599958  |
| training/sac_pi/policy_loss    | -204.17511 |
| training/sac_pi/std            | 0.4902434  |
| training/sac_pi/valid_num      | 4991.0     |
| training/sac_Q/q1              | 194.44247  |
| training/sac_Q/q2              | 193.79758  |
| training/sac_Q/q2_loss         | 96.21927   |
| training/sac_Q/q_global_norm   | 180.71259  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17170206 |
| epoch                          | 471        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4857.8633  |
| evaluation/return-max          | 4894.8755  |
| evaluation/return-min          | 4803.314   |
| evaluation/return-std          | 33.03349   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45842      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4857.8633  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 174.60222  |
| Q-std                          | 192.4513   |
| Q_loss                         | 86.883804  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 471        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000589   |
| times/evaluation_paths         | 31.5       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 56.7       |
| timestep                       | 1000       |
| timesteps_total                | 472000     |
| train-steps                    | 472000     |
| training/Q/q1_loss             | 74.371284  |
| training/sac_pi/alpha          | 0.17171109 |
| training/sac_pi/alpha_loss     | -0.3168836 |
| training/sac_pi/logp_pi        | 3.9651122  |
| training/sac_pi/pi_entropy     | 3.3865318  |
| training/sac_pi/pi_global_norm | 1.8552501  |
| training/sac_pi/policy_loss    | -205.64941 |
| training/sac_pi/std            | 0.4842364  |
| training/sac_pi/valid_num      | 4984.0     |
| training/sac_Q/q1              | 194.41489  |
| training/sac_Q/q2              | 194.84671  |
| training/sac_Q/q2_loss         | 73.94438   |
| training/sac_Q/q_global_norm   | 197.82631  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16372189  |
| epoch                          | 472         |
| evaluation/episode-length-avg  | 915         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 153         |
| evaluation/episode-length-std  | 254         |
| evaluation/return-average      | 4433.3096   |
| evaluation/return-max          | 4982.9146   |
| evaluation/return-min          | 376.9773    |
| evaluation/return-std          | 1353.5709   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45760       |
| perf/AverageLength             | 915         |
| perf/AverageReturn             | 4433.3096   |
| perf/NormalizedReturn          | 0.965       |
| Q-avg                          | 183.4988    |
| Q-std                          | 154.97505   |
| Q_loss                         | 116.810104  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 472         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000614    |
| times/evaluation_paths         | 27.4        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00801     |
| times/train                    | 54.5        |
| timestep                       | 1000        |
| timesteps_total                | 473000      |
| train-steps                    | 473000      |
| training/Q/q1_loss             | 87.110054   |
| training/sac_pi/alpha          | 0.16375582  |
| training/sac_pi/alpha_loss     | -0.30306536 |
| training/sac_pi/logp_pi        | 4.1634474   |
| training/sac_pi/pi_entropy     | 3.5657914   |
| training/sac_pi/pi_global_norm | 1.797695    |
| training/sac_pi/policy_loss    | -203.8883   |
| training/sac_pi/std            | 0.5198419   |
| training/sac_pi/valid_num      | 4963.0      |
| training/sac_Q/q1              | 192.23442   |
| training/sac_Q/q2              | 189.93796   |
| training/sac_Q/q2_loss         | 87.77283    |
| training/sac_Q/q_global_norm   | 206.16577   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1677175   |
| epoch                          | 473         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4823.196    |
| evaluation/return-max          | 4902.5576   |
| evaluation/return-min          | 4749.874    |
| evaluation/return-std          | 48.70532    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45895       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4823.196    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 187.9584    |
| Q-std                          | 142.13423   |
| Q_loss                         | 109.60476   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 473         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000279    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000519    |
| times/evaluation_paths         | 30.5        |
| times/timestep_after_hook      | 0.0038      |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 55.9        |
| timestep                       | 1000        |
| timesteps_total                | 474000      |
| train-steps                    | 474000      |
| training/Q/q1_loss             | 110.62371   |
| training/sac_pi/alpha          | 0.1677395   |
| training/sac_pi/alpha_loss     | -0.26060715 |
| training/sac_pi/logp_pi        | 4.554506    |
| training/sac_pi/pi_entropy     | 3.6889586   |
| training/sac_pi/pi_global_norm | 1.7635545   |
| training/sac_pi/policy_loss    | -202.50317  |
| training/sac_pi/std            | 0.550593    |
| training/sac_pi/valid_num      | 4945.0      |
| training/sac_Q/q1              | 183.96054   |
| training/sac_Q/q2              | 182.35866   |
| training/sac_Q/q2_loss         | 110.14084   |
| training/sac_Q/q_global_norm   | 257.51184   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17003383   |
| epoch                          | 474          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4728.9014    |
| evaluation/return-max          | 4753.152     |
| evaluation/return-min          | 4687.125     |
| evaluation/return-std          | 18.488026    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.95         |
| model/origin_ret               | 84.5         |
| model/penalty_ret              | 81.5         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45774        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4728.9014    |
| perf/NormalizedReturn          | 1.03         |
| Q-avg                          | 194.80016    |
| Q-std                          | 128.17078    |
| Q_loss                         | 96.329765    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 474          |
| times/epoch_after_hook         | 3.73e-06     |
| times/epoch_before_hook        | 0.00013      |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.000531     |
| times/evaluation_paths         | 30.6         |
| times/timestep_after_hook      | 0.00369      |
| times/timestep_before_hook     | 0.00787      |
| times/train                    | 54.3         |
| timestep                       | 1000         |
| timesteps_total                | 475000       |
| train-steps                    | 475000       |
| training/Q/q1_loss             | 105.36435    |
| training/sac_pi/alpha          | 0.1700443    |
| training/sac_pi/alpha_loss     | -0.019058594 |
| training/sac_pi/logp_pi        | 4.849942     |
| training/sac_pi/pi_entropy     | 3.5377076    |
| training/sac_pi/pi_global_norm | 2.2990124    |
| training/sac_pi/policy_loss    | -200.50044   |
| training/sac_pi/std            | 0.5282784    |
| training/sac_pi/valid_num      | 4939.0       |
| training/sac_Q/q1              | 185.69876    |
| training/sac_Q/q2              | 183.45476    |
| training/sac_Q/q2_loss         | 106.454796   |
| training/sac_Q/q_global_norm   | 216.69608    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16560875   |
| epoch                          | 475          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4767.5005    |
| evaluation/return-max          | 4816.967     |
| evaluation/return-min          | 4740.061     |
| evaluation/return-std          | 21.205173    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.92         |
| model/origin_ret               | 84.1         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45577        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4767.5005    |
| perf/NormalizedReturn          | 1.04         |
| Q-avg                          | 190.35564    |
| Q-std                          | 163.32806    |
| Q_loss                         | 92.371414    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 475          |
| times/epoch_after_hook         | 2.04e-06     |
| times/epoch_before_hook        | 9.98e-05     |
| times/epoch_rollout_model      | 487          |
| times/evaluation_metrics       | 0.000588     |
| times/evaluation_paths         | 30.4         |
| times/timestep_after_hook      | 0.00388      |
| times/timestep_before_hook     | 0.00825      |
| times/train                    | 55.6         |
| timestep                       | 1000         |
| timesteps_total                | 476000       |
| train-steps                    | 476000       |
| training/Q/q1_loss             | 100.280106   |
| training/sac_pi/alpha          | 0.16562758   |
| training/sac_pi/alpha_loss     | -0.011191709 |
| training/sac_pi/logp_pi        | 4.998483     |
| training/sac_pi/pi_entropy     | 3.2919812    |
| training/sac_pi/pi_global_norm | 1.9045123    |
| training/sac_pi/policy_loss    | -207.01395   |
| training/sac_pi/std            | 0.51139927   |
| training/sac_pi/valid_num      | 4954.0       |
| training/sac_Q/q1              | 190.37198    |
| training/sac_Q/q2              | 187.20865    |
| training/sac_Q/q2_loss         | 100.491486   |
| training/sac_Q/q_global_norm   | 284.25388    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17111526  |
| epoch                          | 476         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4944.39     |
| evaluation/return-max          | 4966.713    |
| evaluation/return-min          | 4915.595    |
| evaluation/return-std          | 15.44178    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.89        |
| model/origin_ret               | 82.6        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45756       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4944.39     |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 195.77377   |
| Q-std                          | 165.40341   |
| Q_loss                         | 99.18595    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 476         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000102    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000554    |
| times/evaluation_paths         | 30.5        |
| times/timestep_after_hook      | 0.00385     |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 55.5        |
| timestep                       | 1000        |
| timesteps_total                | 477000      |
| train-steps                    | 477000      |
| training/Q/q1_loss             | 94.236145   |
| training/sac_pi/alpha          | 0.17112738  |
| training/sac_pi/alpha_loss     | -0.15354048 |
| training/sac_pi/logp_pi        | 4.5453386   |
| training/sac_pi/pi_entropy     | 3.5850654   |
| training/sac_pi/pi_global_norm | 1.9320608   |
| training/sac_pi/policy_loss    | -201.78253  |
| training/sac_pi/std            | 0.52111274  |
| training/sac_pi/valid_num      | 4898.0      |
| training/sac_Q/q1              | 183.87051   |
| training/sac_Q/q2              | 183.21094   |
| training/sac_Q/q2_loss         | 93.96448    |
| training/sac_Q/q_global_norm   | 262.08984   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16943257 |
| epoch                          | 477        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4868.1416  |
| evaluation/return-max          | 4883.9985  |
| evaluation/return-min          | 4844.1035  |
| evaluation/return-std          | 10.361065  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45872      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4868.1416  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 182.0011   |
| Q-std                          | 195.39961  |
| Q_loss                         | 94.5367    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 477        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000288   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.00051    |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 55.3       |
| timestep                       | 1000       |
| timesteps_total                | 478000     |
| train-steps                    | 478000     |
| training/Q/q1_loss             | 113.03835  |
| training/sac_pi/alpha          | 0.16945331 |
| training/sac_pi/alpha_loss     | 0.20359641 |
| training/sac_pi/logp_pi        | 4.7772584  |
| training/sac_pi/pi_entropy     | 3.5569787  |
| training/sac_pi/pi_global_norm | 1.7082064  |
| training/sac_pi/policy_loss    | -203.83025 |
| training/sac_pi/std            | 0.5261845  |
| training/sac_pi/valid_num      | 4949.0     |
| training/sac_Q/q1              | 185.11162  |
| training/sac_Q/q2              | 182.67976  |
| training/sac_Q/q2_loss         | 113.52874  |
| training/sac_Q/q_global_norm   | 220.29889  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16976634  |
| epoch                          | 478         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4941.164    |
| evaluation/return-max          | 5030.452    |
| evaluation/return-min          | 4828.757    |
| evaluation/return-std          | 70.21917    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45549       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4941.164    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 197.1697    |
| Q-std                          | 118.413284  |
| Q_loss                         | 87.78586    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 478         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000104    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000542    |
| times/evaluation_paths         | 30.4        |
| times/timestep_after_hook      | 0.00595     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 56.5        |
| timestep                       | 1000        |
| timesteps_total                | 479000      |
| train-steps                    | 479000      |
| training/Q/q1_loss             | 86.9787     |
| training/sac_pi/alpha          | 0.16982749  |
| training/sac_pi/alpha_loss     | -0.06852288 |
| training/sac_pi/logp_pi        | 3.4728103   |
| training/sac_pi/pi_entropy     | 3.4342332   |
| training/sac_pi/pi_global_norm | 1.7312405   |
| training/sac_pi/policy_loss    | -202.00648  |
| training/sac_pi/std            | 0.4643763   |
| training/sac_pi/valid_num      | 5035.0      |
| training/sac_Q/q1              | 197.75313   |
| training/sac_Q/q2              | 197.65979   |
| training/sac_Q/q2_loss         | 87.3898     |
| training/sac_Q/q_global_norm   | 205.64355   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16907667  |
| epoch                          | 479         |
| evaluation/episode-length-avg  | 529         |
| evaluation/episode-length-max  | 897         |
| evaluation/episode-length-min  | 147         |
| evaluation/episode-length-std  | 260         |
| evaluation/return-average      | 2275.571    |
| evaluation/return-max          | 4371.2573   |
| evaluation/return-min          | 269.458     |
| evaluation/return-std          | 1391.4644   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 83.8        |
| model/penalty_ret              | 82.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45724       |
| perf/AverageLength             | 529         |
| perf/AverageReturn             | 2275.571    |
| perf/NormalizedReturn          | 0.495       |
| Q-avg                          | 174.83864   |
| Q-std                          | 234.83716   |
| Q_loss                         | 101.960815  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 479         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000109    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000482    |
| times/evaluation_paths         | 16.2        |
| times/timestep_after_hook      | 0.00376     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 55.7        |
| timestep                       | 1000        |
| timesteps_total                | 480000      |
| train-steps                    | 480000      |
| training/Q/q1_loss             | 96.46801    |
| training/sac_pi/alpha          | 0.16908054  |
| training/sac_pi/alpha_loss     | -0.14416957 |
| training/sac_pi/logp_pi        | 4.0723205   |
| training/sac_pi/pi_entropy     | 3.6086197   |
| training/sac_pi/pi_global_norm | 1.5113513   |
| training/sac_pi/policy_loss    | -209.06319  |
| training/sac_pi/std            | 0.51305044  |
| training/sac_pi/valid_num      | 5007.0      |
| training/sac_Q/q1              | 198.25345   |
| training/sac_Q/q2              | 195.23355   |
| training/sac_Q/q2_loss         | 97.6364     |
| training/sac_Q/q_global_norm   | 225.4734    |
---------------------------------------------------------------------------------
[WARN] 480 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.17069763 |
| epoch                          | 480        |
| evaluation/episode-length-avg  | 913        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 126        |
| evaluation/episode-length-std  | 262        |
| evaluation/return-average      | 4120.286   |
| evaluation/return-max          | 4584.922   |
| evaluation/return-min          | 285.84412  |
| evaluation/return-std          | 1278.4436  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45703      |
| perf/AverageLength             | 913        |
| perf/AverageReturn             | 4120.286   |
| perf/NormalizedReturn          | 0.897      |
| Q-avg                          | 186.19408  |
| Q-std                          | 157.40936  |
| Q_loss                         | 113.917244 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 480        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000102   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000551   |
| times/evaluation_paths         | 27.5       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00792    |
| times/train                    | 53.6       |
| timestep                       | 1000       |
| timesteps_total                | 481000     |
| train-steps                    | 481000     |
| training/Q/q1_loss             | 97.20998   |
| training/sac_pi/alpha          | 0.17064871 |
| training/sac_pi/alpha_loss     | 0.46999204 |
| training/sac_pi/logp_pi        | 5.3702283  |
| training/sac_pi/pi_entropy     | 3.6144753  |
| training/sac_pi/pi_global_norm | 1.7844043  |
| training/sac_pi/policy_loss    | -200.49211 |
| training/sac_pi/std            | 0.558066   |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 182.50308  |
| training/sac_Q/q2              | 178.87659  |
| training/sac_Q/q2_loss         | 97.398186  |
| training/sac_Q/q_global_norm   | 225.29007  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16674797 |
| epoch                          | 481        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4486.9585  |
| evaluation/return-max          | 4534.3965  |
| evaluation/return-min          | 4436.137   |
| evaluation/return-std          | 29.862112  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45682      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4486.9585  |
| perf/NormalizedReturn          | 0.977      |
| Q-avg                          | 186.2917   |
| Q-std                          | 159.10965  |
| Q_loss                         | 100.975525 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 481        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000279   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000577   |
| times/evaluation_paths         | 31.5       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 482000     |
| train-steps                    | 482000     |
| training/Q/q1_loss             | 99.77232   |
| training/sac_pi/alpha          | 0.16673219 |
| training/sac_pi/alpha_loss     | 0.42511937 |
| training/sac_pi/logp_pi        | 4.37271    |
| training/sac_pi/pi_entropy     | 3.4041762  |
| training/sac_pi/pi_global_norm | 1.3584247  |
| training/sac_pi/policy_loss    | -207.96191 |
| training/sac_pi/std            | 0.4857005  |
| training/sac_pi/valid_num      | 5012.0     |
| training/sac_Q/q1              | 195.91731  |
| training/sac_Q/q2              | 193.03575  |
| training/sac_Q/q2_loss         | 98.10519   |
| training/sac_Q/q_global_norm   | 241.43338  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16872296 |
| epoch                          | 482        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4910.077   |
| evaluation/return-max          | 4954.7427  |
| evaluation/return-min          | 4839.637   |
| evaluation/return-std          | 38.727505  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45933      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4910.077   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 186.95996  |
| Q-std                          | 160.20705  |
| Q_loss                         | 93.09841   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 482        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000115   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000808   |
| times/evaluation_paths         | 31.9       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 56.3       |
| timestep                       | 1000       |
| timesteps_total                | 483000     |
| train-steps                    | 483000     |
| training/Q/q1_loss             | 105.63726  |
| training/sac_pi/alpha          | 0.16870913 |
| training/sac_pi/alpha_loss     | 0.08703461 |
| training/sac_pi/logp_pi        | 4.283694   |
| training/sac_pi/pi_entropy     | 3.4589508  |
| training/sac_pi/pi_global_norm | 1.7630811  |
| training/sac_pi/policy_loss    | -213.8601  |
| training/sac_pi/std            | 0.48604017 |
| training/sac_pi/valid_num      | 4970.0     |
| training/sac_Q/q1              | 204.08784  |
| training/sac_Q/q2              | 199.86948  |
| training/sac_Q/q2_loss         | 104.80694  |
| training/sac_Q/q_global_norm   | 203.43791  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16650136   |
| epoch                          | 483          |
| evaluation/episode-length-avg  | 294          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 109          |
| evaluation/episode-length-std  | 353          |
| evaluation/return-average      | 1107.9778    |
| evaluation/return-max          | 4524.2046    |
| evaluation/return-min          | 238.43344    |
| evaluation/return-std          | 1685.944     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.97         |
| model/origin_ret               | 85.3         |
| model/penalty_ret              | 81.9         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45698        |
| perf/AverageLength             | 294          |
| perf/AverageReturn             | 1107.9778    |
| perf/NormalizedReturn          | 0.241        |
| Q-avg                          | 177.58463    |
| Q-std                          | 210.77243    |
| Q_loss                         | 83.017586    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 483          |
| times/epoch_after_hook         | 2.18e-06     |
| times/epoch_before_hook        | 0.000154     |
| times/epoch_rollout_model      | 536          |
| times/evaluation_metrics       | 0.00072      |
| times/evaluation_paths         | 9.28         |
| times/timestep_after_hook      | 0.00381      |
| times/timestep_before_hook     | 0.00819      |
| times/train                    | 56.3         |
| timestep                       | 1000         |
| timesteps_total                | 484000       |
| train-steps                    | 484000       |
| training/Q/q1_loss             | 86.94746     |
| training/sac_pi/alpha          | 0.16653189   |
| training/sac_pi/alpha_loss     | -0.034743782 |
| training/sac_pi/logp_pi        | 4.3789406    |
| training/sac_pi/pi_entropy     | 3.3099656    |
| training/sac_pi/pi_global_norm | 1.599173     |
| training/sac_pi/policy_loss    | -210.42682   |
| training/sac_pi/std            | 0.49068025   |
| training/sac_pi/valid_num      | 4948.0       |
| training/sac_Q/q1              | 198.19847    |
| training/sac_Q/q2              | 196.32419    |
| training/sac_Q/q2_loss         | 87.301994    |
| training/sac_Q/q_global_norm   | 285.01865    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17118025  |
| epoch                          | 484         |
| evaluation/episode-length-avg  | 751         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 165         |
| evaluation/episode-length-std  | 381         |
| evaluation/return-average      | 3218.7817   |
| evaluation/return-max          | 4501.7256   |
| evaluation/return-min          | 405.24133   |
| evaluation/return-std          | 1837.1226   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45840       |
| perf/AverageLength             | 751         |
| perf/AverageReturn             | 3218.7817   |
| perf/NormalizedReturn          | 0.701       |
| Q-avg                          | 176.78296   |
| Q-std                          | 207.75163   |
| Q_loss                         | 106.33797   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 484         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000195    |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000633    |
| times/evaluation_paths         | 23.4        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 56.1        |
| timestep                       | 1000        |
| timesteps_total                | 485000      |
| train-steps                    | 485000      |
| training/Q/q1_loss             | 105.62981   |
| training/sac_pi/alpha          | 0.17116909  |
| training/sac_pi/alpha_loss     | -0.17425452 |
| training/sac_pi/logp_pi        | 4.7074356   |
| training/sac_pi/pi_entropy     | 3.3608582   |
| training/sac_pi/pi_global_norm | 1.4454354   |
| training/sac_pi/policy_loss    | -208.66159  |
| training/sac_pi/std            | 0.49938813  |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 193.25468   |
| training/sac_Q/q2              | 189.65735   |
| training/sac_Q/q2_loss         | 104.89303   |
| training/sac_Q/q_global_norm   | 231.6905    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16751017 |
| epoch                          | 485        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4701.158   |
| evaluation/return-max          | 4794.5684  |
| evaluation/return-min          | 4638.759   |
| evaluation/return-std          | 44.778145  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45687      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4701.158   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 178.71317  |
| Q-std                          | 188.5741   |
| Q_loss                         | 90.46795   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 485        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000381   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000566   |
| times/evaluation_paths         | 31.3       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 56         |
| timestep                       | 1000       |
| timesteps_total                | 486000     |
| train-steps                    | 486000     |
| training/Q/q1_loss             | 101.90702  |
| training/sac_pi/alpha          | 0.16745111 |
| training/sac_pi/alpha_loss     | 0.7931681  |
| training/sac_pi/logp_pi        | 4.853017   |
| training/sac_pi/pi_entropy     | 3.4151683  |
| training/sac_pi/pi_global_norm | 2.271918   |
| training/sac_pi/policy_loss    | -206.87648 |
| training/sac_pi/std            | 0.5038932  |
| training/sac_pi/valid_num      | 4967.0     |
| training/sac_Q/q1              | 188.10489  |
| training/sac_Q/q2              | 188.63821  |
| training/sac_Q/q2_loss         | 102.01193  |
| training/sac_Q/q_global_norm   | 259.24597  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1639616  |
| epoch                          | 486        |
| evaluation/episode-length-avg  | 222        |
| evaluation/episode-length-max  | 224        |
| evaluation/episode-length-min  | 221        |
| evaluation/episode-length-std  | 0.943      |
| evaluation/return-average      | 657.8874   |
| evaluation/return-max          | 675.53845  |
| evaluation/return-min          | 644.59827  |
| evaluation/return-std          | 10.269179  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45491      |
| perf/AverageLength             | 222        |
| perf/AverageReturn             | 657.8874   |
| perf/NormalizedReturn          | 0.143      |
| Q-avg                          | 186.27829  |
| Q-std                          | 170.82083  |
| Q_loss                         | 110.12934  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 486        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.00015    |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000579   |
| times/evaluation_paths         | 6.87       |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 56.2       |
| timestep                       | 1000       |
| timesteps_total                | 487000     |
| train-steps                    | 487000     |
| training/Q/q1_loss             | 111.31699  |
| training/sac_pi/alpha          | 0.16398586 |
| training/sac_pi/alpha_loss     | 0.27875215 |
| training/sac_pi/logp_pi        | 5.3312883  |
| training/sac_pi/pi_entropy     | 3.4334404  |
| training/sac_pi/pi_global_norm | 1.8798289  |
| training/sac_pi/policy_loss    | -207.48337 |
| training/sac_pi/std            | 0.5419312  |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 187.42996  |
| training/sac_Q/q2              | 185.0746   |
| training/sac_Q/q2_loss         | 112.34912  |
| training/sac_Q/q_global_norm   | 181.28845  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16969416  |
| epoch                          | 487         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4649.247    |
| evaluation/return-max          | 4777.2466   |
| evaluation/return-min          | 4506.1924   |
| evaluation/return-std          | 81.958084   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45740       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4649.247    |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 189.80344   |
| Q-std                          | 144.38763   |
| Q_loss                         | 90.28395    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 487         |
| times/epoch_after_hook         | 2.18e-06    |
| times/epoch_before_hook        | 0.000102    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000836    |
| times/evaluation_paths         | 31.3        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 57.1        |
| timestep                       | 1000        |
| timesteps_total                | 488000      |
| train-steps                    | 488000      |
| training/Q/q1_loss             | 79.41282    |
| training/sac_pi/alpha          | 0.16971673  |
| training/sac_pi/alpha_loss     | -0.00590517 |
| training/sac_pi/logp_pi        | 4.7787504   |
| training/sac_pi/pi_entropy     | 3.3778427   |
| training/sac_pi/pi_global_norm | 2.499377    |
| training/sac_pi/policy_loss    | -212.92747  |
| training/sac_pi/std            | 0.50458485  |
| training/sac_pi/valid_num      | 4917.0      |
| training/sac_Q/q1              | 196.40129   |
| training/sac_Q/q2              | 194.8731    |
| training/sac_Q/q2_loss         | 78.72786    |
| training/sac_Q/q_global_norm   | 135.64053   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16981794 |
| epoch                          | 488        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4793.309   |
| evaluation/return-max          | 4922.922   |
| evaluation/return-min          | 4645.435   |
| evaluation/return-std          | 76.663216  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45741      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4793.309   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 197.67114  |
| Q-std                          | 120.42145  |
| Q_loss                         | 86.224754  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 488        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000566   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 56         |
| timestep                       | 1000       |
| timesteps_total                | 489000     |
| train-steps                    | 489000     |
| training/Q/q1_loss             | 93.9995    |
| training/sac_pi/alpha          | 0.16982056 |
| training/sac_pi/alpha_loss     | 0.06227611 |
| training/sac_pi/logp_pi        | 4.504978   |
| training/sac_pi/pi_entropy     | 3.4079757  |
| training/sac_pi/pi_global_norm | 1.425015   |
| training/sac_pi/policy_loss    | -203.6361  |
| training/sac_pi/std            | 0.4897094  |
| training/sac_pi/valid_num      | 4997.0     |
| training/sac_Q/q1              | 191.66623  |
| training/sac_Q/q2              | 190.009    |
| training/sac_Q/q2_loss         | 93.88306   |
| training/sac_Q/q_global_norm   | 180.91328  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16843316  |
| epoch                          | 489         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4900.262    |
| evaluation/return-max          | 5094.7427   |
| evaluation/return-min          | 4748.329    |
| evaluation/return-std          | 103.76038   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45693       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4900.262    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 181.6211    |
| Q-std                          | 189.24095   |
| Q_loss                         | 110.22822   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 489         |
| times/epoch_after_hook         | 1.95e-06    |
| times/epoch_before_hook        | 0.00028     |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000552    |
| times/evaluation_paths         | 31.1        |
| times/timestep_after_hook      | 0.00378     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 490000      |
| train-steps                    | 490000      |
| training/Q/q1_loss             | 117.82531   |
| training/sac_pi/alpha          | 0.16843858  |
| training/sac_pi/alpha_loss     | -0.52380645 |
| training/sac_pi/logp_pi        | 4.2389975   |
| training/sac_pi/pi_entropy     | 3.6052063   |
| training/sac_pi/pi_global_norm | 1.3655622   |
| training/sac_pi/policy_loss    | -194.34862  |
| training/sac_pi/std            | 0.5271464   |
| training/sac_pi/valid_num      | 4903.0      |
| training/sac_Q/q1              | 178.20206   |
| training/sac_Q/q2              | 178.90744   |
| training/sac_Q/q2_loss         | 118.678764  |
| training/sac_Q/q_global_norm   | 247.96034   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1642959  |
| epoch                          | 490        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4416.1104  |
| evaluation/return-max          | 4668.0806  |
| evaluation/return-min          | 4263.341   |
| evaluation/return-std          | 155.99683  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 83.4       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45771      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4416.1104  |
| perf/NormalizedReturn          | 0.962      |
| Q-avg                          | 192.86292  |
| Q-std                          | 144.72008  |
| Q_loss                         | 97.75714   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 490        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000519   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00809    |
| times/train                    | 56.5       |
| timestep                       | 1000       |
| timesteps_total                | 491000     |
| train-steps                    | 491000     |
| training/Q/q1_loss             | 84.97832   |
| training/sac_pi/alpha          | 0.16427453 |
| training/sac_pi/alpha_loss     | 0.08319758 |
| training/sac_pi/logp_pi        | 4.897826   |
| training/sac_pi/pi_entropy     | 3.3787112  |
| training/sac_pi/pi_global_norm | 1.7148042  |
| training/sac_pi/policy_loss    | -203.8021  |
| training/sac_pi/std            | 0.5054185  |
| training/sac_pi/valid_num      | 4940.0     |
| training/sac_Q/q1              | 187.58357  |
| training/sac_Q/q2              | 187.84671  |
| training/sac_Q/q2_loss         | 84.71523   |
| training/sac_Q/q_global_norm   | 152.29848  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16981539 |
| epoch                          | 491        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4768.685   |
| evaluation/return-max          | 4977.301   |
| evaluation/return-min          | 4597.477   |
| evaluation/return-std          | 96.34795   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.85       |
| model/origin_ret               | 83.1       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45669      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4768.685   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 196.59505  |
| Q-std                          | 149.12242  |
| Q_loss                         | 96.23685   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 491        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.000118   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000602   |
| times/evaluation_paths         | 31.3       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 56.2       |
| timestep                       | 1000       |
| timesteps_total                | 492000     |
| train-steps                    | 492000     |
| training/Q/q1_loss             | 96.90445   |
| training/sac_pi/alpha          | 0.1698171  |
| training/sac_pi/alpha_loss     | 0.1957912  |
| training/sac_pi/logp_pi        | 4.4618645  |
| training/sac_pi/pi_entropy     | 3.4704964  |
| training/sac_pi/pi_global_norm | 1.6523244  |
| training/sac_pi/policy_loss    | -211.34192 |
| training/sac_pi/std            | 0.50406927 |
| training/sac_pi/valid_num      | 4977.0     |
| training/sac_Q/q1              | 199.78769  |
| training/sac_Q/q2              | 201.13683  |
| training/sac_Q/q2_loss         | 96.166954  |
| training/sac_Q/q_global_norm   | 285.86667  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1700299  |
| epoch                          | 492        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5049.0405  |
| evaluation/return-max          | 5157.668   |
| evaluation/return-min          | 4948.535   |
| evaluation/return-std          | 61.740562  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45668      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5049.0405  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 192.21684  |
| Q-std                          | 138.10672  |
| Q_loss                         | 79.50203   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 492        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000114   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000623   |
| times/evaluation_paths         | 31.4       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 56.9       |
| timestep                       | 1000       |
| timesteps_total                | 493000     |
| train-steps                    | 493000     |
| training/Q/q1_loss             | 89.28826   |
| training/sac_pi/alpha          | 0.17000827 |
| training/sac_pi/alpha_loss     | 0.34119442 |
| training/sac_pi/logp_pi        | 3.981813   |
| training/sac_pi/pi_entropy     | 3.4551246  |
| training/sac_pi/pi_global_norm | 1.6418453  |
| training/sac_pi/policy_loss    | -206.8576  |
| training/sac_pi/std            | 0.47971055 |
| training/sac_pi/valid_num      | 5016.0     |
| training/sac_Q/q1              | 199.39456  |
| training/sac_Q/q2              | 197.86607  |
| training/sac_Q/q2_loss         | 88.71601   |
| training/sac_Q/q_global_norm   | 301.80402  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1742725   |
| epoch                          | 493         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4234.1396   |
| evaluation/return-max          | 4285.0723   |
| evaluation/return-min          | 4164.401    |
| evaluation/return-std          | 39.20805    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45730       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4234.1396   |
| perf/NormalizedReturn          | 0.922       |
| Q-avg                          | 182.09218   |
| Q-std                          | 173.47845   |
| Q_loss                         | 120.06001   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 493         |
| times/epoch_after_hook         | 3.61e-06    |
| times/epoch_before_hook        | 0.000334    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000593    |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 56.2        |
| timestep                       | 1000        |
| timesteps_total                | 494000      |
| train-steps                    | 494000      |
| training/Q/q1_loss             | 111.17351   |
| training/sac_pi/alpha          | 0.17428677  |
| training/sac_pi/alpha_loss     | -0.18684183 |
| training/sac_pi/logp_pi        | 4.4366407   |
| training/sac_pi/pi_entropy     | 3.4818177   |
| training/sac_pi/pi_global_norm | 1.6767333   |
| training/sac_pi/policy_loss    | -207.82658  |
| training/sac_pi/std            | 0.5139658   |
| training/sac_pi/valid_num      | 4953.0      |
| training/sac_Q/q1              | 188.46623   |
| training/sac_Q/q2              | 185.29678   |
| training/sac_Q/q2_loss         | 111.890686  |
| training/sac_Q/q_global_norm   | 266.01956   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17176823 |
| epoch                          | 494        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4989.7354  |
| evaluation/return-max          | 5022.815   |
| evaluation/return-min          | 4958.691   |
| evaluation/return-std          | 19.791248  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45654      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4989.7354  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 186.78604  |
| Q-std                          | 161.00227  |
| Q_loss                         | 88.662544  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 494        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000118   |
| times/epoch_rollout_model      | 505        |
| times/evaluation_metrics       | 0.000769   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 56.6       |
| timestep                       | 1000       |
| timesteps_total                | 495000     |
| train-steps                    | 495000     |
| training/Q/q1_loss             | 111.11851  |
| training/sac_pi/alpha          | 0.17176415 |
| training/sac_pi/alpha_loss     | 0.13973999 |
| training/sac_pi/logp_pi        | 4.8311834  |
| training/sac_pi/pi_entropy     | 3.603431   |
| training/sac_pi/pi_global_norm | 1.5697069  |
| training/sac_pi/policy_loss    | -204.46672 |
| training/sac_pi/std            | 0.5240124  |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 189.7714   |
| training/sac_Q/q2              | 186.33212  |
| training/sac_Q/q2_loss         | 111.0543   |
| training/sac_Q/q_global_norm   | 207.72186  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1670583  |
| epoch                          | 495        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4374.4775  |
| evaluation/return-max          | 4519.334   |
| evaluation/return-min          | 4302.5024  |
| evaluation/return-std          | 65.15638   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45727      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4374.4775  |
| perf/NormalizedReturn          | 0.953      |
| Q-avg                          | 192.31433  |
| Q-std                          | 134.07959  |
| Q_loss                         | 103.45978  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 495        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000105   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.00056    |
| times/evaluation_paths         | 31.1       |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 56.4       |
| timestep                       | 1000       |
| timesteps_total                | 496000     |
| train-steps                    | 496000     |
| training/Q/q1_loss             | 111.1812   |
| training/sac_pi/alpha          | 0.1670937  |
| training/sac_pi/alpha_loss     | 0.4078009  |
| training/sac_pi/logp_pi        | 4.455963   |
| training/sac_pi/pi_entropy     | 3.4083283  |
| training/sac_pi/pi_global_norm | 1.8109368  |
| training/sac_pi/policy_loss    | -199.42342 |
| training/sac_pi/std            | 0.4876876  |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 187.28902  |
| training/sac_Q/q2              | 187.43001  |
| training/sac_Q/q2_loss         | 111.226715 |
| training/sac_Q/q_global_norm   | 225.70866  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16685975 |
| epoch                          | 496        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4865.877   |
| evaluation/return-max          | 4908.451   |
| evaluation/return-min          | 4830.045   |
| evaluation/return-std          | 24.89146   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45800      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4865.877   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 188.87035  |
| Q-std                          | 129.79736  |
| Q_loss                         | 99.77503   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 496        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 511        |
| times/evaluation_metrics       | 0.000658   |
| times/evaluation_paths         | 31.4       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 56.8       |
| timestep                       | 1000       |
| timesteps_total                | 497000     |
| train-steps                    | 497000     |
| training/Q/q1_loss             | 122.376854 |
| training/sac_pi/alpha          | 0.16681479 |
| training/sac_pi/alpha_loss     | 0.22466108 |
| training/sac_pi/logp_pi        | 5.059543   |
| training/sac_pi/pi_entropy     | 3.6966584  |
| training/sac_pi/pi_global_norm | 1.7438807  |
| training/sac_pi/policy_loss    | -196.70659 |
| training/sac_pi/std            | 0.54671764 |
| training/sac_pi/valid_num      | 4885.0     |
| training/sac_Q/q1              | 175.92929  |
| training/sac_Q/q2              | 173.01071  |
| training/sac_Q/q2_loss         | 122.10965  |
| training/sac_Q/q_global_norm   | 206.2574   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16280448  |
| epoch                          | 497         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4817.899    |
| evaluation/return-max          | 4883.6025   |
| evaluation/return-min          | 4701.7627   |
| evaluation/return-std          | 60.9648     |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 82.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45701       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4817.899    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 183.84494   |
| Q-std                          | 192.33981   |
| Q_loss                         | 130.87747   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 497         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000282    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.00054     |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 56.1        |
| timestep                       | 1000        |
| timesteps_total                | 498000      |
| train-steps                    | 498000      |
| training/Q/q1_loss             | 74.31434    |
| training/sac_pi/alpha          | 0.16278318  |
| training/sac_pi/alpha_loss     | 0.018810347 |
| training/sac_pi/logp_pi        | 4.926337    |
| training/sac_pi/pi_entropy     | 3.3788502   |
| training/sac_pi/pi_global_norm | 1.7983115   |
| training/sac_pi/policy_loss    | -201.63626  |
| training/sac_pi/std            | 0.50731695  |
| training/sac_pi/valid_num      | 4915.0      |
| training/sac_Q/q1              | 181.50874   |
| training/sac_Q/q2              | 180.3016    |
| training/sac_Q/q2_loss         | 73.82652    |
| training/sac_Q/q_global_norm   | 186.51279   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16993152 |
| epoch                          | 498        |
| evaluation/episode-length-avg  | 153        |
| evaluation/episode-length-max  | 160        |
| evaluation/episode-length-min  | 150        |
| evaluation/episode-length-std  | 3.23       |
| evaluation/return-average      | 276.60263  |
| evaluation/return-max          | 293.31287  |
| evaluation/return-min          | 268.56305  |
| evaluation/return-std          | 7.279991   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.86       |
| model/origin_ret               | 82.3       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45759      |
| perf/AverageLength             | 153        |
| perf/AverageReturn             | 276.60263  |
| perf/NormalizedReturn          | 0.0599     |
| Q-avg                          | 180.50284  |
| Q-std                          | 170.66324  |
| Q_loss                         | 91.95231   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 498        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000473   |
| times/evaluation_paths         | 4.68       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 56.4       |
| timestep                       | 1000       |
| timesteps_total                | 499000     |
| train-steps                    | 499000     |
| training/Q/q1_loss             | 133.06056  |
| training/sac_pi/alpha          | 0.16991678 |
| training/sac_pi/alpha_loss     | 0.24910177 |
| training/sac_pi/logp_pi        | 6.1752057  |
| training/sac_pi/pi_entropy     | 3.6621754  |
| training/sac_pi/pi_global_norm | 1.4243232  |
| training/sac_pi/policy_loss    | -192.74448 |
| training/sac_pi/std            | 0.5812855  |
| training/sac_pi/valid_num      | 4856.0     |
| training/sac_Q/q1              | 161.50537  |
| training/sac_Q/q2              | 157.8217   |
| training/sac_Q/q2_loss         | 131.21503  |
| training/sac_Q/q_global_norm   | 262.77368  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17207535  |
| epoch                          | 499         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5138.53     |
| evaluation/return-max          | 5169.2197   |
| evaluation/return-min          | 5086.3955   |
| evaluation/return-std          | 24.944363   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45753       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5138.53     |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 186.55507   |
| Q-std                          | 167.51768   |
| Q_loss                         | 117.993286  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 499         |
| times/epoch_after_hook         | 1.99e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000619    |
| times/evaluation_paths         | 31.3        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 55.9        |
| timestep                       | 1000        |
| timesteps_total                | 500000      |
| train-steps                    | 500000      |
| training/Q/q1_loss             | 112.18977   |
| training/sac_pi/alpha          | 0.17207845  |
| training/sac_pi/alpha_loss     | -0.06564718 |
| training/sac_pi/logp_pi        | 4.6343513   |
| training/sac_pi/pi_entropy     | 3.3832428   |
| training/sac_pi/pi_global_norm | 1.5399619   |
| training/sac_pi/policy_loss    | -203.9954   |
| training/sac_pi/std            | 0.50059736  |
| training/sac_pi/valid_num      | 4920.0      |
| training/sac_Q/q1              | 186.46487   |
| training/sac_Q/q2              | 185.72836   |
| training/sac_Q/q2_loss         | 112.25619   |
| training/sac_Q/q_global_norm   | 269.36505   |
---------------------------------------------------------------------------------
[WARN] 500 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16920751  |
| epoch                          | 500         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5203.858    |
| evaluation/return-max          | 5263.833    |
| evaluation/return-min          | 5149.3506   |
| evaluation/return-std          | 30.629522   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45819       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5203.858    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 187.25638   |
| Q-std                          | 157.09332   |
| Q_loss                         | 111.69255   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 500         |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000111    |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000593    |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 55.9        |
| timestep                       | 1000        |
| timesteps_total                | 501000      |
| train-steps                    | 501000      |
| training/Q/q1_loss             | 87.73161    |
| training/sac_pi/alpha          | 0.16916457  |
| training/sac_pi/alpha_loss     | 0.012825253 |
| training/sac_pi/logp_pi        | 4.381423    |
| training/sac_pi/pi_entropy     | 3.3340843   |
| training/sac_pi/pi_global_norm | 1.595643    |
| training/sac_pi/policy_loss    | -203.0622   |
| training/sac_pi/std            | 0.48359457  |
| training/sac_pi/valid_num      | 4940.0      |
| training/sac_Q/q1              | 185.85524   |
| training/sac_Q/q2              | 185.27461   |
| training/sac_Q/q2_loss         | 87.95592    |
| training/sac_Q/q_global_norm   | 170.79283   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17239273 |
| epoch                          | 501        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4915.9863  |
| evaluation/return-max          | 4928.1455  |
| evaluation/return-min          | 4902.1914  |
| evaluation/return-std          | 7.5512595  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45805      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4915.9863  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 185.25793  |
| Q-std                          | 199.82967  |
| Q_loss                         | 88.51998   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 501        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000289   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000552   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 56.4       |
| timestep                       | 1000       |
| timesteps_total                | 502000     |
| train-steps                    | 502000     |
| training/Q/q1_loss             | 104.712906 |
| training/sac_pi/alpha          | 0.17241034 |
| training/sac_pi/alpha_loss     | 0.23398806 |
| training/sac_pi/logp_pi        | 5.3031282  |
| training/sac_pi/pi_entropy     | 3.640962   |
| training/sac_pi/pi_global_norm | 1.8975997  |
| training/sac_pi/policy_loss    | -203.18387 |
| training/sac_pi/std            | 0.54666114 |
| training/sac_pi/valid_num      | 4917.0     |
| training/sac_Q/q1              | 179.68433  |
| training/sac_Q/q2              | 177.14865  |
| training/sac_Q/q2_loss         | 104.40017  |
| training/sac_Q/q_global_norm   | 207.5327   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17198469  |
| epoch                          | 502         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4613.112    |
| evaluation/return-max          | 4733.98     |
| evaluation/return-min          | 4333.228    |
| evaluation/return-std          | 123.49415   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45704       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4613.112    |
| perf/NormalizedReturn          | 1           |
| Q-avg                          | 184.20195   |
| Q-std                          | 172.815     |
| Q_loss                         | 108.28957   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 502         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000556    |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00373     |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 56.2        |
| timestep                       | 1000        |
| timesteps_total                | 503000      |
| train-steps                    | 503000      |
| training/Q/q1_loss             | 112.33151   |
| training/sac_pi/alpha          | 0.17200801  |
| training/sac_pi/alpha_loss     | -0.35327563 |
| training/sac_pi/logp_pi        | 4.5496635   |
| training/sac_pi/pi_entropy     | 3.7472901   |
| training/sac_pi/pi_global_norm | 1.4996382   |
| training/sac_pi/policy_loss    | -199.89665  |
| training/sac_pi/std            | 0.54663044  |
| training/sac_pi/valid_num      | 4895.0      |
| training/sac_Q/q1              | 177.99773   |
| training/sac_Q/q2              | 172.66003   |
| training/sac_Q/q2_loss         | 112.52055   |
| training/sac_Q/q_global_norm   | 208.29745   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16627914 |
| epoch                          | 503        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4727.805   |
| evaluation/return-max          | 4802.6787  |
| evaluation/return-min          | 4690.286   |
| evaluation/return-std          | 31.207697  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45713      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4727.805   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 185.53738  |
| Q-std                          | 133.18326  |
| Q_loss                         | 107.8758   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 503        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000571   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00796    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 504000     |
| train-steps                    | 504000     |
| training/Q/q1_loss             | 138.86156  |
| training/sac_pi/alpha          | 0.16625091 |
| training/sac_pi/alpha_loss     | 0.1977861  |
| training/sac_pi/logp_pi        | 4.911092   |
| training/sac_pi/pi_entropy     | 3.7683282  |
| training/sac_pi/pi_global_norm | 1.4459916  |
| training/sac_pi/policy_loss    | -195.88058 |
| training/sac_pi/std            | 0.5567408  |
| training/sac_pi/valid_num      | 4900.0     |
| training/sac_Q/q1              | 176.3695   |
| training/sac_Q/q2              | 172.79353  |
| training/sac_Q/q2_loss         | 139.94371  |
| training/sac_Q/q_global_norm   | 305.43436  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17142943  |
| epoch                          | 504         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4676.4683   |
| evaluation/return-max          | 4734.0938   |
| evaluation/return-min          | 4566.0776   |
| evaluation/return-std          | 52.798023   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45626       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4676.4683   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 185.63943   |
| Q-std                          | 164.0919    |
| Q_loss                         | 101.830635  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 504         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000103    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000523    |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 505000      |
| train-steps                    | 505000      |
| training/Q/q1_loss             | 79.219      |
| training/sac_pi/alpha          | 0.17143317  |
| training/sac_pi/alpha_loss     | -0.13583547 |
| training/sac_pi/logp_pi        | 3.9239929   |
| training/sac_pi/pi_entropy     | 3.6293004   |
| training/sac_pi/pi_global_norm | 1.8968713   |
| training/sac_pi/policy_loss    | -200.45332  |
| training/sac_pi/std            | 0.5135582   |
| training/sac_pi/valid_num      | 4954.0      |
| training/sac_Q/q1              | 188.2579    |
| training/sac_Q/q2              | 186.24985   |
| training/sac_Q/q2_loss         | 79.081764   |
| training/sac_Q/q_global_norm   | 281.03543   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17367192  |
| epoch                          | 505         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4864.7686   |
| evaluation/return-max          | 4897.868    |
| evaluation/return-min          | 4813.615    |
| evaluation/return-std          | 25.066038   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45808       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4864.7686   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 174.28958   |
| Q-std                          | 222.17586   |
| Q_loss                         | 95.520226   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 505         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000282    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000538    |
| times/evaluation_paths         | 31.3        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00806     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 506000      |
| train-steps                    | 506000      |
| training/Q/q1_loss             | 97.2195     |
| training/sac_pi/alpha          | 0.1736959   |
| training/sac_pi/alpha_loss     | -0.41038394 |
| training/sac_pi/logp_pi        | 3.9672718   |
| training/sac_pi/pi_entropy     | 3.634111    |
| training/sac_pi/pi_global_norm | 1.5215178   |
| training/sac_pi/policy_loss    | -209.37485  |
| training/sac_pi/std            | 0.5155151   |
| training/sac_pi/valid_num      | 4953.0      |
| training/sac_Q/q1              | 192.77634   |
| training/sac_Q/q2              | 186.1672    |
| training/sac_Q/q2_loss         | 95.889206   |
| training/sac_Q/q_global_norm   | 199.98723   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16664018 |
| epoch                          | 506        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4895.056   |
| evaluation/return-max          | 4991.644   |
| evaluation/return-min          | 4697.133   |
| evaluation/return-std          | 83.02839   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45844      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4895.056   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 186.66429  |
| Q-std                          | 162.9438   |
| Q_loss                         | 110.78184  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 506        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000543   |
| times/evaluation_paths         | 30.9       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00804    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 507000     |
| train-steps                    | 507000     |
| training/Q/q1_loss             | 91.962395  |
| training/sac_pi/alpha          | 0.16665009 |
| training/sac_pi/alpha_loss     | 0.34930265 |
| training/sac_pi/logp_pi        | 4.545478   |
| training/sac_pi/pi_entropy     | 3.4811256  |
| training/sac_pi/pi_global_norm | 1.5463786  |
| training/sac_pi/policy_loss    | -201.62344 |
| training/sac_pi/std            | 0.5074419  |
| training/sac_pi/valid_num      | 4958.0     |
| training/sac_Q/q1              | 188.8989   |
| training/sac_Q/q2              | 188.04439  |
| training/sac_Q/q2_loss         | 90.30752   |
| training/sac_Q/q_global_norm   | 180.15999  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16695085 |
| epoch                          | 507        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4331.431   |
| evaluation/return-max          | 4750.8193  |
| evaluation/return-min          | 4224.132   |
| evaluation/return-std          | 152.49612  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45887      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4331.431   |
| perf/NormalizedReturn          | 0.943      |
| Q-avg                          | 172.99268  |
| Q-std                          | 189.04756  |
| Q_loss                         | 108.296776 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 507        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000146   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000576   |
| times/evaluation_paths         | 31.2       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 56.3       |
| timestep                       | 1000       |
| timesteps_total                | 508000     |
| train-steps                    | 508000     |
| training/Q/q1_loss             | 106.93602  |
| training/sac_pi/alpha          | 0.16697794 |
| training/sac_pi/alpha_loss     | 0.1238388  |
| training/sac_pi/logp_pi        | 5.0369363  |
| training/sac_pi/pi_entropy     | 3.508184   |
| training/sac_pi/pi_global_norm | 1.5399213  |
| training/sac_pi/policy_loss    | -208.13882 |
| training/sac_pi/std            | 0.53947216 |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 188.87625  |
| training/sac_Q/q2              | 184.99545  |
| training/sac_Q/q2_loss         | 106.669785 |
| training/sac_Q/q_global_norm   | 203.03331  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16503328  |
| epoch                          | 508         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4908.149    |
| evaluation/return-max          | 4949.0435   |
| evaluation/return-min          | 4859.0815   |
| evaluation/return-std          | 32.893627   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45741       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4908.149    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 176.43423   |
| Q-std                          | 167.83896   |
| Q_loss                         | 97.06511    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 508         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000556    |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00376     |
| times/timestep_before_hook     | 0.00802     |
| times/train                    | 56.1        |
| timestep                       | 1000        |
| timesteps_total                | 509000      |
| train-steps                    | 509000      |
| training/Q/q1_loss             | 75.62198    |
| training/sac_pi/alpha          | 0.16500106  |
| training/sac_pi/alpha_loss     | -0.15625447 |
| training/sac_pi/logp_pi        | 4.1671333   |
| training/sac_pi/pi_entropy     | 3.518891    |
| training/sac_pi/pi_global_norm | 1.5305406   |
| training/sac_pi/policy_loss    | -203.82431  |
| training/sac_pi/std            | 0.50983995  |
| training/sac_pi/valid_num      | 4982.0      |
| training/sac_Q/q1              | 191.55495   |
| training/sac_Q/q2              | 188.68001   |
| training/sac_Q/q2_loss         | 74.982346   |
| training/sac_Q/q_global_norm   | 156.88142   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1683641   |
| epoch                          | 509         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4901.591    |
| evaluation/return-max          | 4954.7246   |
| evaluation/return-min          | 4831.6543   |
| evaluation/return-std          | 41.15756    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45855       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4901.591    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 181.21118   |
| Q-std                          | 197.79279   |
| Q_loss                         | 98.70607    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 509         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000339    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000544    |
| times/evaluation_paths         | 31.1        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 56.1        |
| timestep                       | 1000        |
| timesteps_total                | 510000      |
| train-steps                    | 510000      |
| training/Q/q1_loss             | 83.68573    |
| training/sac_pi/alpha          | 0.16837007  |
| training/sac_pi/alpha_loss     | -0.16567221 |
| training/sac_pi/logp_pi        | 4.380346    |
| training/sac_pi/pi_entropy     | 3.6630616   |
| training/sac_pi/pi_global_norm | 1.4971337   |
| training/sac_pi/policy_loss    | -204.18808  |
| training/sac_pi/std            | 0.5284974   |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 191.9048    |
| training/sac_Q/q2              | 188.99117   |
| training/sac_Q/q2_loss         | 83.39053    |
| training/sac_Q/q_global_norm   | 175.39821   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17122354 |
| epoch                          | 510        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4779.1055  |
| evaluation/return-max          | 4830.78    |
| evaluation/return-min          | 4704.7905  |
| evaluation/return-std          | 38.210682  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45771      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4779.1055  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 184.90732  |
| Q-std                          | 165.19481  |
| Q_loss                         | 105.10901  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 510        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000103   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000659   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00798    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 511000     |
| train-steps                    | 511000     |
| training/Q/q1_loss             | 99.2317    |
| training/sac_pi/alpha          | 0.17121814 |
| training/sac_pi/alpha_loss     | -0.1301711 |
| training/sac_pi/logp_pi        | 3.9197922  |
| training/sac_pi/pi_entropy     | 3.4262958  |
| training/sac_pi/pi_global_norm | 1.7776687  |
| training/sac_pi/policy_loss    | -211.58362 |
| training/sac_pi/std            | 0.4896854  |
| training/sac_pi/valid_num      | 5023.0     |
| training/sac_Q/q1              | 199.1368   |
| training/sac_Q/q2              | 200.6653   |
| training/sac_Q/q2_loss         | 99.14712   |
| training/sac_Q/q_global_norm   | 299.5476   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16852793 |
| epoch                          | 511        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4543.803   |
| evaluation/return-max          | 4604.0156  |
| evaluation/return-min          | 4503.286   |
| evaluation/return-std          | 31.23729   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45746      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4543.803   |
| perf/NormalizedReturn          | 0.989      |
| Q-avg                          | 185.4351   |
| Q-std                          | 149.19218  |
| Q_loss                         | 114.75468  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 511        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000116   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.00058    |
| times/evaluation_paths         | 30.9       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 56.1       |
| timestep                       | 1000       |
| timesteps_total                | 512000     |
| train-steps                    | 512000     |
| training/Q/q1_loss             | 99.46016   |
| training/sac_pi/alpha          | 0.1685129  |
| training/sac_pi/alpha_loss     | 0.31577846 |
| training/sac_pi/logp_pi        | 4.348719   |
| training/sac_pi/pi_entropy     | 3.5929604  |
| training/sac_pi/pi_global_norm | 1.4609456  |
| training/sac_pi/policy_loss    | -201.6539  |
| training/sac_pi/std            | 0.5192452  |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 186.509    |
| training/sac_Q/q2              | 186.17517  |
| training/sac_Q/q2_loss         | 100.88222  |
| training/sac_Q/q_global_norm   | 231.83728  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17191204 |
| epoch                          | 512        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4844.0195  |
| evaluation/return-max          | 4935.1084  |
| evaluation/return-min          | 4800.0244  |
| evaluation/return-std          | 40.774326  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 83.2       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45627      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4844.0195  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 193.55164  |
| Q-std                          | 142.70496  |
| Q_loss                         | 92.58167   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 512        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000116   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000544   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 513000     |
| train-steps                    | 513000     |
| training/Q/q1_loss             | 104.937874 |
| training/sac_pi/alpha          | 0.1719041  |
| training/sac_pi/alpha_loss     | 0.22138254 |
| training/sac_pi/logp_pi        | 5.9544554  |
| training/sac_pi/pi_entropy     | 3.7606037  |
| training/sac_pi/pi_global_norm | 1.5868226  |
| training/sac_pi/policy_loss    | -203.56195 |
| training/sac_pi/std            | 0.60751176 |
| training/sac_pi/valid_num      | 4837.0     |
| training/sac_Q/q1              | 173.12479  |
| training/sac_Q/q2              | 168.3146   |
| training/sac_Q/q2_loss         | 104.192345 |
| training/sac_Q/q_global_norm   | 242.30832  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17261375 |
| epoch                          | 513        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4892.79    |
| evaluation/return-max          | 4934.0967  |
| evaluation/return-min          | 4790.8086  |
| evaluation/return-std          | 42.582447  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45666      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4892.79    |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 183.56862  |
| Q-std                          | 177.91003  |
| Q_loss                         | 106.936035 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 513        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000284   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000546   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00884    |
| times/train                    | 56         |
| timestep                       | 1000       |
| timesteps_total                | 514000     |
| train-steps                    | 514000     |
| training/Q/q1_loss             | 93.64882   |
| training/sac_pi/alpha          | 0.1726026  |
| training/sac_pi/alpha_loss     | 0.05916736 |
| training/sac_pi/logp_pi        | 5.411378   |
| training/sac_pi/pi_entropy     | 3.690548   |
| training/sac_pi/pi_global_norm | 1.8457799  |
| training/sac_pi/policy_loss    | -209.54376 |
| training/sac_pi/std            | 0.5782177  |
| training/sac_pi/valid_num      | 4902.0     |
| training/sac_Q/q1              | 181.90189  |
| training/sac_Q/q2              | 179.56163  |
| training/sac_Q/q2_loss         | 93.829025  |
| training/sac_Q/q_global_norm   | 186.62589  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16782151  |
| epoch                          | 514         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4951.3633   |
| evaluation/return-max          | 4995.6113   |
| evaluation/return-min          | 4898.0947   |
| evaluation/return-std          | 33.008938   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45895       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4951.3633   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 192.01717   |
| Q-std                          | 137.68163   |
| Q_loss                         | 103.82741   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 514         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.000103    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000554    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00382     |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 55.7        |
| timestep                       | 1000        |
| timesteps_total                | 515000      |
| train-steps                    | 515000      |
| training/Q/q1_loss             | 94.31855    |
| training/sac_pi/alpha          | 0.16780563  |
| training/sac_pi/alpha_loss     | -0.02592662 |
| training/sac_pi/logp_pi        | 5.0094175   |
| training/sac_pi/pi_entropy     | 3.4799924   |
| training/sac_pi/pi_global_norm | 1.3804753   |
| training/sac_pi/policy_loss    | -205.53522  |
| training/sac_pi/std            | 0.54066485  |
| training/sac_pi/valid_num      | 4941.0      |
| training/sac_Q/q1              | 185.80988   |
| training/sac_Q/q2              | 185.35628   |
| training/sac_Q/q2_loss         | 94.94104    |
| training/sac_Q/q_global_norm   | 211.91646   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16791959   |
| epoch                          | 515          |
| evaluation/episode-length-avg  | 914          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 138          |
| evaluation/episode-length-std  | 259          |
| evaluation/return-average      | 4218.843     |
| evaluation/return-max          | 4892.5713    |
| evaluation/return-min          | 364.99222    |
| evaluation/return-std          | 1302.9713    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.96         |
| model/origin_ret               | 85.1         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45842        |
| perf/AverageLength             | 914          |
| perf/AverageReturn             | 4218.843     |
| perf/NormalizedReturn          | 0.919        |
| Q-avg                          | 184.27129    |
| Q-std                          | 228.4597     |
| Q_loss                         | 89.72612     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 515          |
| times/epoch_after_hook         | 1.92e-06     |
| times/epoch_before_hook        | 0.000102     |
| times/epoch_rollout_model      | 482          |
| times/evaluation_metrics       | 0.000568     |
| times/evaluation_paths         | 28.3         |
| times/timestep_after_hook      | 0.00375      |
| times/timestep_before_hook     | 0.00809      |
| times/train                    | 56.2         |
| timestep                       | 1000         |
| timesteps_total                | 516000       |
| train-steps                    | 516000       |
| training/Q/q1_loss             | 78.100975    |
| training/sac_pi/alpha          | 0.16793014   |
| training/sac_pi/alpha_loss     | -0.118847445 |
| training/sac_pi/logp_pi        | 3.643048     |
| training/sac_pi/pi_entropy     | 3.383902     |
| training/sac_pi/pi_global_norm | 1.5850157    |
| training/sac_pi/policy_loss    | -213.3958    |
| training/sac_pi/std            | 0.48702827   |
| training/sac_pi/valid_num      | 5012.0       |
| training/sac_Q/q1              | 201.91338    |
| training/sac_Q/q2              | 202.34549    |
| training/sac_Q/q2_loss         | 78.28833     |
| training/sac_Q/q_global_norm   | 192.42378    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.160251   |
| epoch                          | 516        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4779.411   |
| evaluation/return-max          | 4845.6465  |
| evaluation/return-min          | 4749.1055  |
| evaluation/return-std          | 27.079939  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45840      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4779.411   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 201.04938  |
| Q-std                          | 146.00758  |
| Q_loss                         | 90.29724   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 516        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000603   |
| times/evaluation_paths         | 31.2       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 56.4       |
| timestep                       | 1000       |
| timesteps_total                | 517000     |
| train-steps                    | 517000     |
| training/Q/q1_loss             | 96.049706  |
| training/sac_pi/alpha          | 0.16024694 |
| training/sac_pi/alpha_loss     | 0.21148258 |
| training/sac_pi/logp_pi        | 4.6040697  |
| training/sac_pi/pi_entropy     | 3.4950516  |
| training/sac_pi/pi_global_norm | 2.0035107  |
| training/sac_pi/policy_loss    | -206.76707 |
| training/sac_pi/std            | 0.5247688  |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 192.30038  |
| training/sac_Q/q2              | 192.77975  |
| training/sac_Q/q2_loss         | 95.53703   |
| training/sac_Q/q_global_norm   | 186.19328  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16559438 |
| epoch                          | 517        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4563.47    |
| evaluation/return-max          | 4794.285   |
| evaluation/return-min          | 4493.8447  |
| evaluation/return-std          | 81.17399   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45820      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4563.47    |
| perf/NormalizedReturn          | 0.994      |
| Q-avg                          | 198.11711  |
| Q-std                          | 142.61693  |
| Q_loss                         | 82.38376   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 517        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000284   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000727   |
| times/evaluation_paths         | 31.3       |
| times/timestep_after_hook      | 0.00375    |
| times/timestep_before_hook     | 0.00794    |
| times/train                    | 56.3       |
| timestep                       | 1000       |
| timesteps_total                | 518000     |
| train-steps                    | 518000     |
| training/Q/q1_loss             | 94.2569    |
| training/sac_pi/alpha          | 0.16556229 |
| training/sac_pi/alpha_loss     | 0.33712915 |
| training/sac_pi/logp_pi        | 4.0798492  |
| training/sac_pi/pi_entropy     | 3.3694959  |
| training/sac_pi/pi_global_norm | 1.5992384  |
| training/sac_pi/policy_loss    | -209.038   |
| training/sac_pi/std            | 0.48352796 |
| training/sac_pi/valid_num      | 4999.0     |
| training/sac_Q/q1              | 198.957    |
| training/sac_Q/q2              | 196.46733  |
| training/sac_Q/q2_loss         | 94.13072   |
| training/sac_Q/q_global_norm   | 206.76982  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1665293  |
| epoch                          | 518        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4868.6934  |
| evaluation/return-max          | 4937.034   |
| evaluation/return-min          | 4789.545   |
| evaluation/return-std          | 42.64826   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45746      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4868.6934  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 179.2902   |
| Q-std                          | 142.03197  |
| Q_loss                         | 108.31387  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 518        |
| times/epoch_after_hook         | 3.78e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000611   |
| times/evaluation_paths         | 31.1       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 56.3       |
| timestep                       | 1000       |
| timesteps_total                | 519000     |
| train-steps                    | 519000     |
| training/Q/q1_loss             | 103.76683  |
| training/sac_pi/alpha          | 0.16649711 |
| training/sac_pi/alpha_loss     | 0.3211758  |
| training/sac_pi/logp_pi        | 5.100033   |
| training/sac_pi/pi_entropy     | 3.6462731  |
| training/sac_pi/pi_global_norm | 1.798652   |
| training/sac_pi/policy_loss    | -209.11292 |
| training/sac_pi/std            | 0.56395304 |
| training/sac_pi/valid_num      | 4932.0     |
| training/sac_Q/q1              | 186.771    |
| training/sac_Q/q2              | 183.38919  |
| training/sac_Q/q2_loss         | 102.05104  |
| training/sac_Q/q_global_norm   | 183.16565  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16663124  |
| epoch                          | 519         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4262.736    |
| evaluation/return-max          | 4278.0625   |
| evaluation/return-min          | 4251.0205   |
| evaluation/return-std          | 8.65952     |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45949       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4262.736    |
| perf/NormalizedReturn          | 0.928       |
| Q-avg                          | 184.94484   |
| Q-std                          | 190.69757   |
| Q_loss                         | 99.98041    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 519         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000526    |
| times/evaluation_paths         | 31.1        |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 56.2        |
| timestep                       | 1000        |
| timesteps_total                | 520000      |
| train-steps                    | 520000      |
| training/Q/q1_loss             | 100.18566   |
| training/sac_pi/alpha          | 0.16666982  |
| training/sac_pi/alpha_loss     | -0.27078152 |
| training/sac_pi/logp_pi        | 4.9915085   |
| training/sac_pi/pi_entropy     | 3.5681922   |
| training/sac_pi/pi_global_norm | 1.4418819   |
| training/sac_pi/policy_loss    | -204.33157  |
| training/sac_pi/std            | 0.5581388   |
| training/sac_pi/valid_num      | 4885.0      |
| training/sac_Q/q1              | 178.96512   |
| training/sac_Q/q2              | 176.18987   |
| training/sac_Q/q2_loss         | 99.86075    |
| training/sac_Q/q_global_norm   | 158.89575   |
---------------------------------------------------------------------------------
[WARN] 520 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.165182     |
| epoch                          | 520          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4825.0625    |
| evaluation/return-max          | 4907.499     |
| evaluation/return-min          | 4711.0635    |
| evaluation/return-std          | 58.995834    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.9          |
| model/origin_ret               | 84           |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45792        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4825.0625    |
| perf/NormalizedReturn          | 1.05         |
| Q-avg                          | 191.16779    |
| Q-std                          | 187.79665    |
| Q_loss                         | 98.10197     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 520          |
| times/epoch_after_hook         | 1.7e-06      |
| times/epoch_before_hook        | 0.000128     |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.000539     |
| times/evaluation_paths         | 31           |
| times/timestep_after_hook      | 0.00387      |
| times/timestep_before_hook     | 0.00813      |
| times/train                    | 56.2         |
| timestep                       | 1000         |
| timesteps_total                | 521000       |
| train-steps                    | 521000       |
| training/Q/q1_loss             | 108.98526    |
| training/sac_pi/alpha          | 0.16517843   |
| training/sac_pi/alpha_loss     | 0.0017465984 |
| training/sac_pi/logp_pi        | 4.5180883    |
| training/sac_pi/pi_entropy     | 3.5395794    |
| training/sac_pi/pi_global_norm | 1.8345987    |
| training/sac_pi/policy_loss    | -206.65643   |
| training/sac_pi/std            | 0.51585305   |
| training/sac_pi/valid_num      | 4924.0       |
| training/sac_Q/q1              | 192.05786    |
| training/sac_Q/q2              | 187.62733    |
| training/sac_Q/q2_loss         | 109.98231    |
| training/sac_Q/q_global_norm   | 297.03128    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17256033  |
| epoch                          | 521         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4778.817    |
| evaluation/return-max          | 4877.5356   |
| evaluation/return-min          | 4699.452    |
| evaluation/return-std          | 61.71176    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 83.5        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45876       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4778.817    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 184.24217   |
| Q-std                          | 165.92508   |
| Q_loss                         | 102.78697   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 521         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000333    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000528    |
| times/evaluation_paths         | 31.1        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00797     |
| times/train                    | 56.4        |
| timestep                       | 1000        |
| timesteps_total                | 522000      |
| train-steps                    | 522000      |
| training/Q/q1_loss             | 110.11288   |
| training/sac_pi/alpha          | 0.17258117  |
| training/sac_pi/alpha_loss     | -0.13820477 |
| training/sac_pi/logp_pi        | 4.4500427   |
| training/sac_pi/pi_entropy     | 3.5043054   |
| training/sac_pi/pi_global_norm | 1.6380757   |
| training/sac_pi/policy_loss    | -208.5208   |
| training/sac_pi/std            | 0.5173018   |
| training/sac_pi/valid_num      | 4970.0      |
| training/sac_Q/q1              | 192.39676   |
| training/sac_Q/q2              | 190.80945   |
| training/sac_Q/q2_loss         | 109.84559   |
| training/sac_Q/q_global_norm   | 382.91534   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16718222 |
| epoch                          | 522        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4810.877   |
| evaluation/return-max          | 4865.334   |
| evaluation/return-min          | 4732.082   |
| evaluation/return-std          | 43.321136  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45854      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4810.877   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 187.57431  |
| Q-std                          | 193.42374  |
| Q_loss                         | 114.09982  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 522        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000534   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 56.2       |
| timestep                       | 1000       |
| timesteps_total                | 523000     |
| train-steps                    | 523000     |
| training/Q/q1_loss             | 108.13381  |
| training/sac_pi/alpha          | 0.16715917 |
| training/sac_pi/alpha_loss     | 0.27362487 |
| training/sac_pi/logp_pi        | 5.0156755  |
| training/sac_pi/pi_entropy     | 3.4477417  |
| training/sac_pi/pi_global_norm | 1.5933743  |
| training/sac_pi/policy_loss    | -211.24638 |
| training/sac_pi/std            | 0.5268578  |
| training/sac_pi/valid_num      | 4910.0     |
| training/sac_Q/q1              | 186.801    |
| training/sac_Q/q2              | 187.59904  |
| training/sac_Q/q2_loss         | 108.30176  |
| training/sac_Q/q_global_norm   | 189.19826  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16857024   |
| epoch                          | 523          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4746.433     |
| evaluation/return-max          | 4835.9033    |
| evaluation/return-min          | 4666.9966    |
| evaluation/return-std          | 52.816708    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.92         |
| model/origin_ret               | 83.9         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45881        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4746.433     |
| perf/NormalizedReturn          | 1.03         |
| Q-avg                          | 191.47684    |
| Q-std                          | 150.53557    |
| Q_loss                         | 103.66083    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 523          |
| times/epoch_after_hook         | 1.74e-06     |
| times/epoch_before_hook        | 0.000146     |
| times/epoch_rollout_model      | 488          |
| times/evaluation_metrics       | 0.000563     |
| times/evaluation_paths         | 31           |
| times/timestep_after_hook      | 0.00378      |
| times/timestep_before_hook     | 0.00986      |
| times/train                    | 56           |
| timestep                       | 1000         |
| timesteps_total                | 524000       |
| train-steps                    | 524000       |
| training/Q/q1_loss             | 113.9837     |
| training/sac_pi/alpha          | 0.16859138   |
| training/sac_pi/alpha_loss     | -0.020715335 |
| training/sac_pi/logp_pi        | 4.5528336    |
| training/sac_pi/pi_entropy     | 3.7250953    |
| training/sac_pi/pi_global_norm | 1.5520254    |
| training/sac_pi/policy_loss    | -202.17235   |
| training/sac_pi/std            | 0.5413338    |
| training/sac_pi/valid_num      | 4933.0       |
| training/sac_Q/q1              | 185.36719    |
| training/sac_Q/q2              | 184.08641    |
| training/sac_Q/q2_loss         | 114.67306    |
| training/sac_Q/q_global_norm   | 192.41183    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16865131 |
| epoch                          | 524        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4857.2954  |
| evaluation/return-max          | 4897.5776  |
| evaluation/return-min          | 4791.701   |
| evaluation/return-std          | 30.875978  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45777      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4857.2954  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 193.61867  |
| Q-std                          | 135.8792   |
| Q_loss                         | 80.92459   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 524        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000113   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000541   |
| times/evaluation_paths         | 31.1       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 56.2       |
| timestep                       | 1000       |
| timesteps_total                | 525000     |
| train-steps                    | 525000     |
| training/Q/q1_loss             | 99.182846  |
| training/sac_pi/alpha          | 0.16866729 |
| training/sac_pi/alpha_loss     | 0.06846298 |
| training/sac_pi/logp_pi        | 3.9445279  |
| training/sac_pi/pi_entropy     | 3.4725862  |
| training/sac_pi/pi_global_norm | 1.5622375  |
| training/sac_pi/policy_loss    | -211.98027 |
| training/sac_pi/std            | 0.49546108 |
| training/sac_pi/valid_num      | 4929.0     |
| training/sac_Q/q1              | 195.22733  |
| training/sac_Q/q2              | 193.00761  |
| training/sac_Q/q2_loss         | 99.521515  |
| training/sac_Q/q_global_norm   | 201.61313  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16853796 |
| epoch                          | 525        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4752.93    |
| evaluation/return-max          | 4836.851   |
| evaluation/return-min          | 4571.735   |
| evaluation/return-std          | 79.875015  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45740      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4752.93    |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 173.1478   |
| Q-std                          | 221.13628  |
| Q_loss                         | 88.35314   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 525        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000289   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 31.3       |
| times/timestep_after_hook      | 0.00375    |
| times/timestep_before_hook     | 0.00798    |
| times/train                    | 56.3       |
| timestep                       | 1000       |
| timesteps_total                | 526000     |
| train-steps                    | 526000     |
| training/Q/q1_loss             | 98.56161   |
| training/sac_pi/alpha          | 0.16851784 |
| training/sac_pi/alpha_loss     | 0.2371511  |
| training/sac_pi/logp_pi        | 3.9336212  |
| training/sac_pi/pi_entropy     | 3.5384402  |
| training/sac_pi/pi_global_norm | 1.3721515  |
| training/sac_pi/policy_loss    | -199.85367 |
| training/sac_pi/std            | 0.4925095  |
| training/sac_pi/valid_num      | 4973.0     |
| training/sac_Q/q1              | 191.32114  |
| training/sac_Q/q2              | 190.13614  |
| training/sac_Q/q2_loss         | 99.26489   |
| training/sac_Q/q_global_norm   | 330.8753   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16999216 |
| epoch                          | 526        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4866.7964  |
| evaluation/return-max          | 4970.632   |
| evaluation/return-min          | 4728.41    |
| evaluation/return-std          | 76.034676  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45762      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4866.7964  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 184.06311  |
| Q-std                          | 196.71133  |
| Q_loss                         | 97.95363   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 526        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.00065    |
| times/evaluation_paths         | 31.2       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 56         |
| timestep                       | 1000       |
| timesteps_total                | 527000     |
| train-steps                    | 527000     |
| training/Q/q1_loss             | 78.00585   |
| training/sac_pi/alpha          | 0.16999641 |
| training/sac_pi/alpha_loss     | 0.1772489  |
| training/sac_pi/logp_pi        | 4.1418085  |
| training/sac_pi/pi_entropy     | 3.4750037  |
| training/sac_pi/pi_global_norm | 1.524599   |
| training/sac_pi/policy_loss    | -210.87402 |
| training/sac_pi/std            | 0.5026133  |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 196.0787   |
| training/sac_Q/q2              | 193.68582  |
| training/sac_Q/q2_loss         | 78.8163    |
| training/sac_Q/q_global_norm   | 168.63081  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17095043  |
| epoch                          | 527         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5161.0146   |
| evaluation/return-max          | 5196.7373   |
| evaluation/return-min          | 5121.1445   |
| evaluation/return-std          | 26.392435   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45759       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5161.0146   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 188.44897   |
| Q-std                          | 153.78102   |
| Q_loss                         | 114.25405   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 527         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000164    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.00052     |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 56.4        |
| timestep                       | 1000        |
| timesteps_total                | 528000      |
| train-steps                    | 528000      |
| training/Q/q1_loss             | 103.47396   |
| training/sac_pi/alpha          | 0.1709999   |
| training/sac_pi/alpha_loss     | -0.17988469 |
| training/sac_pi/logp_pi        | 3.8719094   |
| training/sac_pi/pi_entropy     | 3.5473714   |
| training/sac_pi/pi_global_norm | 1.4462018   |
| training/sac_pi/policy_loss    | -199.80707  |
| training/sac_pi/std            | 0.49406105  |
| training/sac_pi/valid_num      | 4974.0      |
| training/sac_Q/q1              | 188.73373   |
| training/sac_Q/q2              | 188.4887    |
| training/sac_Q/q2_loss         | 102.96077   |
| training/sac_Q/q_global_norm   | 229.79593   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17454982 |
| epoch                          | 528        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4372.7197  |
| evaluation/return-max          | 4430.647   |
| evaluation/return-min          | 4309.496   |
| evaluation/return-std          | 40.961403  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45847      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4372.7197  |
| perf/NormalizedReturn          | 0.952      |
| Q-avg                          | 181.68527  |
| Q-std                          | 202.2509   |
| Q_loss                         | 119.74327  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 528        |
| times/epoch_after_hook         | 3.67e-06   |
| times/epoch_before_hook        | 0.000115   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000629   |
| times/evaluation_paths         | 31.4       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 56.1       |
| timestep                       | 1000       |
| timesteps_total                | 529000     |
| train-steps                    | 529000     |
| training/Q/q1_loss             | 101.2994   |
| training/sac_pi/alpha          | 0.174548   |
| training/sac_pi/alpha_loss     | 0.06978639 |
| training/sac_pi/logp_pi        | 4.917581   |
| training/sac_pi/pi_entropy     | 3.5508976  |
| training/sac_pi/pi_global_norm | 1.3055642  |
| training/sac_pi/policy_loss    | -210.17244 |
| training/sac_pi/std            | 0.531831   |
| training/sac_pi/valid_num      | 4946.0     |
| training/sac_Q/q1              | 188.16466  |
| training/sac_Q/q2              | 189.74501  |
| training/sac_Q/q2_loss         | 100.06725  |
| training/sac_Q/q_global_norm   | 208.16664  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16610302 |
| epoch                          | 529        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4612.3604  |
| evaluation/return-max          | 4723.0815  |
| evaluation/return-min          | 4487.493   |
| evaluation/return-std          | 70.758156  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45818      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4612.3604  |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 192.25545  |
| Q-std                          | 169.9365   |
| Q_loss                         | 80.34163   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 529        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000277   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000545   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 530000     |
| train-steps                    | 530000     |
| training/Q/q1_loss             | 123.24191  |
| training/sac_pi/alpha          | 0.16608839 |
| training/sac_pi/alpha_loss     | 0.3293761  |
| training/sac_pi/logp_pi        | 5.0677595  |
| training/sac_pi/pi_entropy     | 3.5705216  |
| training/sac_pi/pi_global_norm | 1.6518493  |
| training/sac_pi/policy_loss    | -207.89989 |
| training/sac_pi/std            | 0.53545505 |
| training/sac_pi/valid_num      | 4877.0     |
| training/sac_Q/q1              | 189.65616  |
| training/sac_Q/q2              | 191.1268   |
| training/sac_Q/q2_loss         | 122.63405  |
| training/sac_Q/q_global_norm   | 548.33545  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1704571  |
| epoch                          | 530        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5313.1807  |
| evaluation/return-max          | 5395.6377  |
| evaluation/return-min          | 5210.7217  |
| evaluation/return-std          | 55.268696  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45913      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5313.1807  |
| perf/NormalizedReturn          | 1.16       |
| Q-avg                          | 178.9678   |
| Q-std                          | 202.74338  |
| Q_loss                         | 107.27917  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 530        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000139   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000566   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 531000     |
| train-steps                    | 531000     |
| training/Q/q1_loss             | 112.18977  |
| training/sac_pi/alpha          | 0.1704527  |
| training/sac_pi/alpha_loss     | 0.37278575 |
| training/sac_pi/logp_pi        | 4.8107266  |
| training/sac_pi/pi_entropy     | 3.4911366  |
| training/sac_pi/pi_global_norm | 1.738038   |
| training/sac_pi/policy_loss    | -205.45045 |
| training/sac_pi/std            | 0.5205249  |
| training/sac_pi/valid_num      | 4925.0     |
| training/sac_Q/q1              | 186.13617  |
| training/sac_Q/q2              | 185.67465  |
| training/sac_Q/q2_loss         | 111.711494 |
| training/sac_Q/q_global_norm   | 219.38004  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.169811    |
| epoch                          | 531         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5009.507    |
| evaluation/return-max          | 5049.215    |
| evaluation/return-min          | 4951.249    |
| evaluation/return-std          | 25.463951   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45982       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5009.507    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 185.2143    |
| Q-std                          | 144.80167   |
| Q_loss                         | 115.2563    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 531         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000142    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000556    |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 55.9        |
| timestep                       | 1000        |
| timesteps_total                | 532000      |
| train-steps                    | 532000      |
| training/Q/q1_loss             | 66.1948     |
| training/sac_pi/alpha          | 0.16981773  |
| training/sac_pi/alpha_loss     | -0.35979053 |
| training/sac_pi/logp_pi        | 4.319603    |
| training/sac_pi/pi_entropy     | 3.5225616   |
| training/sac_pi/pi_global_norm | 1.7552083   |
| training/sac_pi/policy_loss    | -208.50598  |
| training/sac_pi/std            | 0.53157496  |
| training/sac_pi/valid_num      | 4966.0      |
| training/sac_Q/q1              | 192.39624   |
| training/sac_Q/q2              | 190.21219   |
| training/sac_Q/q2_loss         | 65.02215    |
| training/sac_Q/q_global_norm   | 187.08914   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16846041 |
| epoch                          | 532        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4986.7544  |
| evaluation/return-max          | 5024.8457  |
| evaluation/return-min          | 4957.4087  |
| evaluation/return-std          | 18.994553  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45743      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4986.7544  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 192.19714  |
| Q-std                          | 162.88463  |
| Q_loss                         | 96.420044  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 532        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000109   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000524   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 533000     |
| train-steps                    | 533000     |
| training/Q/q1_loss             | 111.110825 |
| training/sac_pi/alpha          | 0.1684371  |
| training/sac_pi/alpha_loss     | 0.22201243 |
| training/sac_pi/logp_pi        | 4.2791557  |
| training/sac_pi/pi_entropy     | 3.591159   |
| training/sac_pi/pi_global_norm | 1.5024767  |
| training/sac_pi/policy_loss    | -195.42781 |
| training/sac_pi/std            | 0.5188419  |
| training/sac_pi/valid_num      | 4925.0     |
| training/sac_Q/q1              | 180.51813  |
| training/sac_Q/q2              | 179.2985   |
| training/sac_Q/q2_loss         | 110.90448  |
| training/sac_Q/q_global_norm   | 246.03693  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16827112  |
| epoch                          | 533         |
| evaluation/episode-length-avg  | 579         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 156         |
| evaluation/episode-length-std  | 421         |
| evaluation/return-average      | 2793.8354   |
| evaluation/return-max          | 5132.948    |
| evaluation/return-min          | 479.3634    |
| evaluation/return-std          | 2306.4685   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45800       |
| perf/AverageLength             | 579         |
| perf/AverageReturn             | 2793.8354   |
| perf/NormalizedReturn          | 0.608       |
| Q-avg                          | 192.40155   |
| Q-std                          | 149.56517   |
| Q_loss                         | 123.21273   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 533         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000296    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000497    |
| times/evaluation_paths         | 18.1        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 55.7        |
| timestep                       | 1000        |
| timesteps_total                | 534000      |
| train-steps                    | 534000      |
| training/Q/q1_loss             | 107.14764   |
| training/sac_pi/alpha          | 0.16827312  |
| training/sac_pi/alpha_loss     | -0.09387487 |
| training/sac_pi/logp_pi        | 4.7275743   |
| training/sac_pi/pi_entropy     | 3.5845344   |
| training/sac_pi/pi_global_norm | 1.5052674   |
| training/sac_pi/policy_loss    | -210.24098  |
| training/sac_pi/std            | 0.5498787   |
| training/sac_pi/valid_num      | 4947.0      |
| training/sac_Q/q1              | 189.94308   |
| training/sac_Q/q2              | 191.81523   |
| training/sac_Q/q2_loss         | 106.80707   |
| training/sac_Q/q_global_norm   | 240.29994   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16298275  |
| epoch                          | 534         |
| evaluation/episode-length-avg  | 914         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 139         |
| evaluation/episode-length-std  | 258         |
| evaluation/return-average      | 4227.7603   |
| evaluation/return-max          | 4741.9805   |
| evaluation/return-min          | 374.5732    |
| evaluation/return-std          | 1287.4375   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 83.6        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45721       |
| perf/AverageLength             | 914         |
| perf/AverageReturn             | 4227.7603   |
| perf/NormalizedReturn          | 0.921       |
| Q-avg                          | 185.01604   |
| Q-std                          | 171.6965    |
| Q_loss                         | 92.843735   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 534         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 5.64e-05    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000529    |
| times/evaluation_paths         | 28.5        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 55.7        |
| timestep                       | 1000        |
| timesteps_total                | 535000      |
| train-steps                    | 535000      |
| training/Q/q1_loss             | 91.34226    |
| training/sac_pi/alpha          | 0.16298674  |
| training/sac_pi/alpha_loss     | -0.15925494 |
| training/sac_pi/logp_pi        | 5.7179193   |
| training/sac_pi/pi_entropy     | 3.7028975   |
| training/sac_pi/pi_global_norm | 1.4606438   |
| training/sac_pi/policy_loss    | -200.93942  |
| training/sac_pi/std            | 0.6003421   |
| training/sac_pi/valid_num      | 4888.0      |
| training/sac_Q/q1              | 176.19063   |
| training/sac_Q/q2              | 174.15483   |
| training/sac_Q/q2_loss         | 89.79901    |
| training/sac_Q/q_global_norm   | 226.85083   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17020805 |
| epoch                          | 535        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4600.3315  |
| evaluation/return-max          | 4636.9893  |
| evaluation/return-min          | 4561.8857  |
| evaluation/return-std          | 23.36685   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 83.8       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45680      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4600.3315  |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 193.85359  |
| Q-std                          | 172.89836  |
| Q_loss                         | 91.893555  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 535        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000101   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000595   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 56         |
| timestep                       | 1000       |
| timesteps_total                | 536000     |
| train-steps                    | 536000     |
| training/Q/q1_loss             | 106.922226 |
| training/sac_pi/alpha          | 0.17019264 |
| training/sac_pi/alpha_loss     | 0.20852402 |
| training/sac_pi/logp_pi        | 5.050737   |
| training/sac_pi/pi_entropy     | 3.567325   |
| training/sac_pi/pi_global_norm | 1.4740242  |
| training/sac_pi/policy_loss    | -206.74977 |
| training/sac_pi/std            | 0.5422886  |
| training/sac_pi/valid_num      | 4906.0     |
| training/sac_Q/q1              | 189.20744  |
| training/sac_Q/q2              | 185.97939  |
| training/sac_Q/q2_loss         | 105.18196  |
| training/sac_Q/q_global_norm   | 222.65332  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16830395  |
| epoch                          | 536         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4908.492    |
| evaluation/return-max          | 4953.121    |
| evaluation/return-min          | 4875.501    |
| evaluation/return-std          | 23.17836    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45727       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4908.492    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 192.90475   |
| Q-std                          | 159.9364    |
| Q_loss                         | 117.15159   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 536         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000543    |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00827     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 537000      |
| train-steps                    | 537000      |
| training/Q/q1_loss             | 91.14612    |
| training/sac_pi/alpha          | 0.16829024  |
| training/sac_pi/alpha_loss     | -0.17299472 |
| training/sac_pi/logp_pi        | 4.129693    |
| training/sac_pi/pi_entropy     | 3.4712486   |
| training/sac_pi/pi_global_norm | 1.4641763   |
| training/sac_pi/policy_loss    | -206.5409   |
| training/sac_pi/std            | 0.5065969   |
| training/sac_pi/valid_num      | 5031.0      |
| training/sac_Q/q1              | 196.8593    |
| training/sac_Q/q2              | 195.69698   |
| training/sac_Q/q2_loss         | 92.089355   |
| training/sac_Q/q_global_norm   | 171.61452   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16951196  |
| epoch                          | 537         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4793.2686   |
| evaluation/return-max          | 4842.2363   |
| evaluation/return-min          | 4760.9116   |
| evaluation/return-std          | 25.540009   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45680       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4793.2686   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 183.57881   |
| Q-std                          | 195.38187   |
| Q_loss                         | 106.781624  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 537         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000281    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000592    |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 56.1        |
| timestep                       | 1000        |
| timesteps_total                | 538000      |
| train-steps                    | 538000      |
| training/Q/q1_loss             | 102.1916    |
| training/sac_pi/alpha          | 0.16948636  |
| training/sac_pi/alpha_loss     | -0.18756528 |
| training/sac_pi/logp_pi        | 4.2963104   |
| training/sac_pi/pi_entropy     | 3.607801    |
| training/sac_pi/pi_global_norm | 1.4026895   |
| training/sac_pi/policy_loss    | -206.31248  |
| training/sac_pi/std            | 0.5258155   |
| training/sac_pi/valid_num      | 4914.0      |
| training/sac_Q/q1              | 190.36482   |
| training/sac_Q/q2              | 190.93886   |
| training/sac_Q/q2_loss         | 101.50545   |
| training/sac_Q/q_global_norm   | 205.72978   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16548692 |
| epoch                          | 538        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4756.4653  |
| evaluation/return-max          | 4843.7305  |
| evaluation/return-min          | 4582.05    |
| evaluation/return-std          | 88.55163   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45656      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4756.4653  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 188.25586  |
| Q-std                          | 158.05157  |
| Q_loss                         | 101.38458  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 538        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000117   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00799    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 539000     |
| train-steps                    | 539000     |
| training/Q/q1_loss             | 100.79644  |
| training/sac_pi/alpha          | 0.16547884 |
| training/sac_pi/alpha_loss     | 0.3621948  |
| training/sac_pi/logp_pi        | 4.5545907  |
| training/sac_pi/pi_entropy     | 3.4518027  |
| training/sac_pi/pi_global_norm | 1.595372   |
| training/sac_pi/policy_loss    | -207.25594 |
| training/sac_pi/std            | 0.5121761  |
| training/sac_pi/valid_num      | 4974.0     |
| training/sac_Q/q1              | 191.0865   |
| training/sac_Q/q2              | 190.9814   |
| training/sac_Q/q2_loss         | 101.83012  |
| training/sac_Q/q_global_norm   | 283.23944  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1681134  |
| epoch                          | 539        |
| evaluation/episode-length-avg  | 115        |
| evaluation/episode-length-max  | 116        |
| evaluation/episode-length-min  | 114        |
| evaluation/episode-length-std  | 0.663      |
| evaluation/return-average      | 199.20279  |
| evaluation/return-max          | 202.07216  |
| evaluation/return-min          | 196.29108  |
| evaluation/return-std          | 1.9398917  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45869      |
| perf/AverageLength             | 115        |
| perf/AverageReturn             | 199.20279  |
| perf/NormalizedReturn          | 0.043      |
| Q-avg                          | 180.18428  |
| Q-std                          | 177.01018  |
| Q_loss                         | 109.3283   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 539        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000454   |
| times/evaluation_paths         | 3.59       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00806    |
| times/train                    | 56.2       |
| timestep                       | 1000       |
| timesteps_total                | 540000     |
| train-steps                    | 540000     |
| training/Q/q1_loss             | 112.116325 |
| training/sac_pi/alpha          | 0.16807626 |
| training/sac_pi/alpha_loss     | 0.34543675 |
| training/sac_pi/logp_pi        | 4.3743753  |
| training/sac_pi/pi_entropy     | 3.581887   |
| training/sac_pi/pi_global_norm | 1.5926265  |
| training/sac_pi/policy_loss    | -198.69702 |
| training/sac_pi/std            | 0.51417464 |
| training/sac_pi/valid_num      | 4979.0     |
| training/sac_Q/q1              | 188.14449  |
| training/sac_Q/q2              | 187.67569  |
| training/sac_Q/q2_loss         | 110.83952  |
| training/sac_Q/q_global_norm   | 164.4399   |
--------------------------------------------------------------------------------
[WARN] 540 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16310228  |
| epoch                          | 540         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4750.1245   |
| evaluation/return-max          | 4763.6406   |
| evaluation/return-min          | 4726.002    |
| evaluation/return-std          | 10.614836   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45797       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4750.1245   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 181.96266   |
| Q-std                          | 194.677     |
| Q_loss                         | 105.0415    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 540         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 8.56e-05    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000551    |
| times/evaluation_paths         | 31.1        |
| times/timestep_after_hook      | 0.00373     |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 541000      |
| train-steps                    | 541000      |
| training/Q/q1_loss             | 96.93639    |
| training/sac_pi/alpha          | 0.16307749  |
| training/sac_pi/alpha_loss     | -0.15423486 |
| training/sac_pi/logp_pi        | 4.67689     |
| training/sac_pi/pi_entropy     | 3.6232986   |
| training/sac_pi/pi_global_norm | 2.2684455   |
| training/sac_pi/policy_loss    | -212.71613  |
| training/sac_pi/std            | 0.5558485   |
| training/sac_pi/valid_num      | 4956.0      |
| training/sac_Q/q1              | 194.59898   |
| training/sac_Q/q2              | 193.72574   |
| training/sac_Q/q2_loss         | 97.82361    |
| training/sac_Q/q_global_norm   | 194.1634    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17058054  |
| epoch                          | 541         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4984.7334   |
| evaluation/return-max          | 5048.4004   |
| evaluation/return-min          | 4921.164    |
| evaluation/return-std          | 35.677223   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45647       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4984.7334   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 176.73515   |
| Q-std                          | 180.509     |
| Q_loss                         | 110.29958   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 541         |
| times/epoch_after_hook         | 2e-06       |
| times/epoch_before_hook        | 0.000327    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000547    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00373     |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 56.1        |
| timestep                       | 1000        |
| timesteps_total                | 542000      |
| train-steps                    | 542000      |
| training/Q/q1_loss             | 111.648766  |
| training/sac_pi/alpha          | 0.17058107  |
| training/sac_pi/alpha_loss     | -0.52952826 |
| training/sac_pi/logp_pi        | 5.241065    |
| training/sac_pi/pi_entropy     | 3.7379825   |
| training/sac_pi/pi_global_norm | 1.6515563   |
| training/sac_pi/policy_loss    | -199.00015  |
| training/sac_pi/std            | 0.58643055  |
| training/sac_pi/valid_num      | 4891.0      |
| training/sac_Q/q1              | 175.52753   |
| training/sac_Q/q2              | 178.42366   |
| training/sac_Q/q2_loss         | 112.69932   |
| training/sac_Q/q_global_norm   | 246.66518   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17062633  |
| epoch                          | 542         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4714.937    |
| evaluation/return-max          | 4742.867    |
| evaluation/return-min          | 4689.448    |
| evaluation/return-std          | 15.580336   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45583       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4714.937    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 175.488     |
| Q-std                          | 191.97545   |
| Q_loss                         | 116.357376  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 542         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000537    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00378     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 56.1        |
| timestep                       | 1000        |
| timesteps_total                | 543000      |
| train-steps                    | 543000      |
| training/Q/q1_loss             | 94.57343    |
| training/sac_pi/alpha          | 0.17061679  |
| training/sac_pi/alpha_loss     | -0.10659755 |
| training/sac_pi/logp_pi        | 4.422004    |
| training/sac_pi/pi_entropy     | 3.5874336   |
| training/sac_pi/pi_global_norm | 1.6427398   |
| training/sac_pi/policy_loss    | -204.97891  |
| training/sac_pi/std            | 0.51757723  |
| training/sac_pi/valid_num      | 4961.0      |
| training/sac_Q/q1              | 192.89626   |
| training/sac_Q/q2              | 194.0854    |
| training/sac_Q/q2_loss         | 94.83262    |
| training/sac_Q/q_global_norm   | 312.5588    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1682266   |
| epoch                          | 543         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4504.543    |
| evaluation/return-max          | 4621.1816   |
| evaluation/return-min          | 4411.993    |
| evaluation/return-std          | 67.92911    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45500       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4504.543    |
| perf/NormalizedReturn          | 0.981       |
| Q-avg                          | 189.01163   |
| Q-std                          | 167.45319   |
| Q_loss                         | 94.95411    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 543         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000546    |
| times/evaluation_paths         | 31.3        |
| times/timestep_after_hook      | 0.00373     |
| times/timestep_before_hook     | 0.00805     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 544000      |
| train-steps                    | 544000      |
| training/Q/q1_loss             | 83.12376    |
| training/sac_pi/alpha          | 0.16819377  |
| training/sac_pi/alpha_loss     | 0.030941887 |
| training/sac_pi/logp_pi        | 4.0791383   |
| training/sac_pi/pi_entropy     | 3.4174912   |
| training/sac_pi/pi_global_norm | 1.5619003   |
| training/sac_pi/policy_loss    | -209.15044  |
| training/sac_pi/std            | 0.48319486  |
| training/sac_pi/valid_num      | 4987.0      |
| training/sac_Q/q1              | 200.5411    |
| training/sac_Q/q2              | 200.61469   |
| training/sac_Q/q2_loss         | 84.202736   |
| training/sac_Q/q_global_norm   | 192.3558    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17070425 |
| epoch                          | 544        |
| evaluation/episode-length-avg  | 576        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 146        |
| evaluation/episode-length-std  | 424        |
| evaluation/return-average      | 2623.1677  |
| evaluation/return-max          | 4879.5547  |
| evaluation/return-min          | 475.30682  |
| evaluation/return-std          | 2129.0952  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.87       |
| model/origin_ret               | 83.4       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45683      |
| perf/AverageLength             | 576        |
| perf/AverageReturn             | 2623.1677  |
| perf/NormalizedReturn          | 0.571      |
| Q-avg                          | 178.4992   |
| Q-std                          | 199.68614  |
| Q_loss                         | 106.36087  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 544        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000105   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.0006     |
| times/evaluation_paths         | 17.7       |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.00795    |
| times/train                    | 56.2       |
| timestep                       | 1000       |
| timesteps_total                | 545000     |
| train-steps                    | 545000     |
| training/Q/q1_loss             | 106.028656 |
| training/sac_pi/alpha          | 0.17065404 |
| training/sac_pi/alpha_loss     | 0.54937106 |
| training/sac_pi/logp_pi        | 4.805299   |
| training/sac_pi/pi_entropy     | 3.699958   |
| training/sac_pi/pi_global_norm | 1.9705567  |
| training/sac_pi/policy_loss    | -199.97955 |
| training/sac_pi/std            | 0.54192644 |
| training/sac_pi/valid_num      | 4929.0     |
| training/sac_Q/q1              | 185.16287  |
| training/sac_Q/q2              | 182.78822  |
| training/sac_Q/q2_loss         | 106.37212  |
| training/sac_Q/q_global_norm   | 231.44987  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16456817  |
| epoch                          | 545         |
| evaluation/episode-length-avg  | 925         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 254         |
| evaluation/episode-length-std  | 224         |
| evaluation/return-average      | 4564.3374   |
| evaluation/return-max          | 5020.3877   |
| evaluation/return-min          | 931.4916    |
| evaluation/return-std          | 1211.4952   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 83.8        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45680       |
| perf/AverageLength             | 925         |
| perf/AverageReturn             | 4564.3374   |
| perf/NormalizedReturn          | 0.994       |
| Q-avg                          | 174.95837   |
| Q-std                          | 219.59334   |
| Q_loss                         | 82.62753    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 545         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000277    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000542    |
| times/evaluation_paths         | 28.3        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00798     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 546000      |
| train-steps                    | 546000      |
| training/Q/q1_loss             | 90.14798    |
| training/sac_pi/alpha          | 0.16460116  |
| training/sac_pi/alpha_loss     | -0.50234234 |
| training/sac_pi/logp_pi        | 4.806231    |
| training/sac_pi/pi_entropy     | 3.6124508   |
| training/sac_pi/pi_global_norm | 1.9745139   |
| training/sac_pi/policy_loss    | -203.62935  |
| training/sac_pi/std            | 0.56925964  |
| training/sac_pi/valid_num      | 4923.0      |
| training/sac_Q/q1              | 178.82553   |
| training/sac_Q/q2              | 178.43411   |
| training/sac_Q/q2_loss         | 90.66454    |
| training/sac_Q/q_global_norm   | 241.44585   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16563547 |
| epoch                          | 546        |
| evaluation/episode-length-avg  | 914        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 136        |
| evaluation/episode-length-std  | 259        |
| evaluation/return-average      | 4414.8506  |
| evaluation/return-max          | 4991.3135  |
| evaluation/return-min          | 358.59406  |
| evaluation/return-std          | 1355.4888  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45872      |
| perf/AverageLength             | 914        |
| perf/AverageReturn             | 4414.8506  |
| perf/NormalizedReturn          | 0.961      |
| Q-avg                          | 192.52156  |
| Q-std                          | 140.16621  |
| Q_loss                         | 91.12978   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 546        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.00053    |
| times/evaluation_paths         | 28.1       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00802    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 547000     |
| train-steps                    | 547000     |
| training/Q/q1_loss             | 104.74561  |
| training/sac_pi/alpha          | 0.16561009 |
| training/sac_pi/alpha_loss     | 0.22317253 |
| training/sac_pi/logp_pi        | 4.38899    |
| training/sac_pi/pi_entropy     | 3.3860295  |
| training/sac_pi/pi_global_norm | 1.5315212  |
| training/sac_pi/policy_loss    | -203.32573 |
| training/sac_pi/std            | 0.50133234 |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 190.38193  |
| training/sac_Q/q2              | 188.00932  |
| training/sac_Q/q2_loss         | 104.70554  |
| training/sac_Q/q_global_norm   | 247.90646  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17106809 |
| epoch                          | 547        |
| evaluation/episode-length-avg  | 839        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 185        |
| evaluation/episode-length-std  | 323        |
| evaluation/return-average      | 4080.3853  |
| evaluation/return-max          | 5033.899   |
| evaluation/return-min          | 652.8068   |
| evaluation/return-std          | 1697.4756  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45981      |
| perf/AverageLength             | 839        |
| perf/AverageReturn             | 4080.3853  |
| perf/NormalizedReturn          | 0.888      |
| Q-avg                          | 182.07219  |
| Q-std                          | 181.48856  |
| Q_loss                         | 94.44582   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 547        |
| times/epoch_after_hook         | 2e-06      |
| times/epoch_before_hook        | 0.000118   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000637   |
| times/evaluation_paths         | 25.8       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 548000     |
| train-steps                    | 548000     |
| training/Q/q1_loss             | 73.0455    |
| training/sac_pi/alpha          | 0.17105426 |
| training/sac_pi/alpha_loss     | 0.02265725 |
| training/sac_pi/logp_pi        | 4.2227945  |
| training/sac_pi/pi_entropy     | 3.4352028  |
| training/sac_pi/pi_global_norm | 1.6541636  |
| training/sac_pi/policy_loss    | -210.32767 |
| training/sac_pi/std            | 0.50245506 |
| training/sac_pi/valid_num      | 4988.0     |
| training/sac_Q/q1              | 197.22525  |
| training/sac_Q/q2              | 196.94742  |
| training/sac_Q/q2_loss         | 73.00525   |
| training/sac_Q/q_global_norm   | 236.24374  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16451594  |
| epoch                          | 548         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4992.167    |
| evaluation/return-max          | 5042.837    |
| evaluation/return-min          | 4939.6787   |
| evaluation/return-std          | 27.9697     |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45717       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4992.167    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 175.51509   |
| Q-std                          | 195.16995   |
| Q_loss                         | 117.51439   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 548         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000103    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000553    |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 549000      |
| train-steps                    | 549000      |
| training/Q/q1_loss             | 109.02364   |
| training/sac_pi/alpha          | 0.1645064   |
| training/sac_pi/alpha_loss     | 0.027413934 |
| training/sac_pi/logp_pi        | 4.6344366   |
| training/sac_pi/pi_entropy     | 3.3691242   |
| training/sac_pi/pi_global_norm | 1.7217013   |
| training/sac_pi/policy_loss    | -205.10756  |
| training/sac_pi/std            | 0.5080065   |
| training/sac_pi/valid_num      | 4977.0      |
| training/sac_Q/q1              | 191.03471   |
| training/sac_Q/q2              | 188.44188   |
| training/sac_Q/q2_loss         | 108.84903   |
| training/sac_Q/q_global_norm   | 185.77682   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16279064  |
| epoch                          | 549         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4358.5083   |
| evaluation/return-max          | 4411.4805   |
| evaluation/return-min          | 4316.306    |
| evaluation/return-std          | 31.748932   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45893       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4358.5083   |
| perf/NormalizedReturn          | 0.949       |
| Q-avg                          | 200.36697   |
| Q-std                          | 160.52725   |
| Q_loss                         | 94.38259    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 549         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000279    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000546    |
| times/evaluation_paths         | 31.1        |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 550000      |
| train-steps                    | 550000      |
| training/Q/q1_loss             | 94.54626    |
| training/sac_pi/alpha          | 0.16278853  |
| training/sac_pi/alpha_loss     | 0.111392125 |
| training/sac_pi/logp_pi        | 4.8701987   |
| training/sac_pi/pi_entropy     | 3.4138577   |
| training/sac_pi/pi_global_norm | 1.4355718   |
| training/sac_pi/policy_loss    | -213.10312  |
| training/sac_pi/std            | 0.52972114  |
| training/sac_pi/valid_num      | 4936.0      |
| training/sac_Q/q1              | 191.0408    |
| training/sac_Q/q2              | 189.47485   |
| training/sac_Q/q2_loss         | 94.73501    |
| training/sac_Q/q_global_norm   | 219.59283   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16248162 |
| epoch                          | 550        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4876.857   |
| evaluation/return-max          | 4938.1167  |
| evaluation/return-min          | 4791.7773  |
| evaluation/return-std          | 47.014973  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45774      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4876.857   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 189.83206  |
| Q-std                          | 169.96156  |
| Q_loss                         | 102.848076 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 550        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000102   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.00146    |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 551000     |
| train-steps                    | 551000     |
| training/Q/q1_loss             | 107.29576  |
| training/sac_pi/alpha          | 0.1624768  |
| training/sac_pi/alpha_loss     | 0.33519444 |
| training/sac_pi/logp_pi        | 4.729281   |
| training/sac_pi/pi_entropy     | 3.380375   |
| training/sac_pi/pi_global_norm | 1.4800586  |
| training/sac_pi/policy_loss    | -206.44969 |
| training/sac_pi/std            | 0.503854   |
| training/sac_pi/valid_num      | 4985.0     |
| training/sac_Q/q1              | 194.77342  |
| training/sac_Q/q2              | 191.58264  |
| training/sac_Q/q2_loss         | 107.735054 |
| training/sac_Q/q_global_norm   | 192.13719  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16687635 |
| epoch                          | 551        |
| evaluation/episode-length-avg  | 484        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 137        |
| evaluation/episode-length-std  | 422        |
| evaluation/return-average      | 2085.7297  |
| evaluation/return-max          | 4798.488   |
| evaluation/return-min          | 315.61758  |
| evaluation/return-std          | 2158.2285  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45922      |
| perf/AverageLength             | 484        |
| perf/AverageReturn             | 2085.7297  |
| perf/NormalizedReturn          | 0.454      |
| Q-avg                          | 184.96735  |
| Q-std                          | 181.11336  |
| Q_loss                         | 89.0468    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 551        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000486   |
| times/evaluation_paths         | 15         |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00795    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 552000     |
| train-steps                    | 552000     |
| training/Q/q1_loss             | 96.372765  |
| training/sac_pi/alpha          | 0.16689257 |
| training/sac_pi/alpha_loss     | 0.1447712  |
| training/sac_pi/logp_pi        | 4.45901    |
| training/sac_pi/pi_entropy     | 3.4895904  |
| training/sac_pi/pi_global_norm | 1.9671707  |
| training/sac_pi/policy_loss    | -205.43411 |
| training/sac_pi/std            | 0.50842786 |
| training/sac_pi/valid_num      | 4934.0     |
| training/sac_Q/q1              | 192.4019   |
| training/sac_Q/q2              | 190.61377  |
| training/sac_Q/q2_loss         | 97.04421   |
| training/sac_Q/q_global_norm   | 225.8544   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17378639 |
| epoch                          | 552        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5085.636   |
| evaluation/return-max          | 5154.926   |
| evaluation/return-min          | 4971.7236  |
| evaluation/return-std          | 60.510265  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45986      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5085.636   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 180.50522  |
| Q-std                          | 187.76286  |
| Q_loss                         | 92.98018   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 552        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000557   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.00809    |
| times/train                    | 56.1       |
| timestep                       | 1000       |
| timesteps_total                | 553000     |
| train-steps                    | 553000     |
| training/Q/q1_loss             | 102.37747  |
| training/sac_pi/alpha          | 0.17380212 |
| training/sac_pi/alpha_loss     | 0.17852707 |
| training/sac_pi/logp_pi        | 4.4984617  |
| training/sac_pi/pi_entropy     | 3.6480699  |
| training/sac_pi/pi_global_norm | 1.6855896  |
| training/sac_pi/policy_loss    | -209.74236 |
| training/sac_pi/std            | 0.53432095 |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 196.53667  |
| training/sac_Q/q2              | 195.13763  |
| training/sac_Q/q2_loss         | 103.31931  |
| training/sac_Q/q_global_norm   | 271.93054  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16831894  |
| epoch                          | 553         |
| evaluation/episode-length-avg  | 744         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 147         |
| evaluation/episode-length-std  | 391         |
| evaluation/return-average      | 3622.4941   |
| evaluation/return-max          | 5006.2734   |
| evaluation/return-min          | 513.64996   |
| evaluation/return-std          | 2032.8105   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45879       |
| perf/AverageLength             | 744         |
| perf/AverageReturn             | 3622.4941   |
| perf/NormalizedReturn          | 0.789       |
| Q-avg                          | 199.6872    |
| Q-std                          | 148.77472   |
| Q_loss                         | 100.729     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 553         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.00028     |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000492    |
| times/evaluation_paths         | 23          |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00791     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 554000      |
| train-steps                    | 554000      |
| training/Q/q1_loss             | 94.81025    |
| training/sac_pi/alpha          | 0.16827932  |
| training/sac_pi/alpha_loss     | -0.07812212 |
| training/sac_pi/logp_pi        | 4.2662735   |
| training/sac_pi/pi_entropy     | 3.578363    |
| training/sac_pi/pi_global_norm | 1.5275182   |
| training/sac_pi/policy_loss    | -203.60724  |
| training/sac_pi/std            | 0.51555     |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 191.15852   |
| training/sac_Q/q2              | 190.36865   |
| training/sac_Q/q2_loss         | 94.40839    |
| training/sac_Q/q_global_norm   | 205.68047   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17100444  |
| epoch                          | 554         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4986.632    |
| evaluation/return-max          | 5042.66     |
| evaluation/return-min          | 4914.919    |
| evaluation/return-std          | 38.57106    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45740       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4986.632    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 190.43428   |
| Q-std                          | 166.99962   |
| Q_loss                         | 115.78048   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 554         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000543    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00381     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 56.3        |
| timestep                       | 1000        |
| timesteps_total                | 555000      |
| train-steps                    | 555000      |
| training/Q/q1_loss             | 85.06941    |
| training/sac_pi/alpha          | 0.17102095  |
| training/sac_pi/alpha_loss     | 0.113267384 |
| training/sac_pi/logp_pi        | 4.3072996   |
| training/sac_pi/pi_entropy     | 3.4198842   |
| training/sac_pi/pi_global_norm | 1.4210931   |
| training/sac_pi/policy_loss    | -210.28911  |
| training/sac_pi/std            | 0.4955063   |
| training/sac_pi/valid_num      | 5027.0      |
| training/sac_Q/q1              | 198.09465   |
| training/sac_Q/q2              | 197.43399   |
| training/sac_Q/q2_loss         | 84.90428    |
| training/sac_Q/q_global_norm   | 200.67493   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16916513 |
| epoch                          | 555        |
| evaluation/episode-length-avg  | 990        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 903        |
| evaluation/episode-length-std  | 29.1       |
| evaluation/return-average      | 4622.4365  |
| evaluation/return-max          | 4888.882   |
| evaluation/return-min          | 4025.2954  |
| evaluation/return-std          | 238.48555  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45850      |
| perf/AverageLength             | 990        |
| perf/AverageReturn             | 4622.4365  |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 189.6302   |
| Q-std                          | 170.38295  |
| Q_loss                         | 99.56026   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 555        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000663   |
| times/evaluation_paths         | 30.6       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 556000     |
| train-steps                    | 556000     |
| training/Q/q1_loss             | 93.31722   |
| training/sac_pi/alpha          | 0.1691564  |
| training/sac_pi/alpha_loss     | 0.40320703 |
| training/sac_pi/logp_pi        | 4.671418   |
| training/sac_pi/pi_entropy     | 3.3765144  |
| training/sac_pi/pi_global_norm | 1.7452983  |
| training/sac_pi/policy_loss    | -208.13042 |
| training/sac_pi/std            | 0.4988963  |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 192.9003   |
| training/sac_Q/q2              | 190.38197  |
| training/sac_Q/q2_loss         | 92.50016   |
| training/sac_Q/q_global_norm   | 163.57181  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16530952   |
| epoch                          | 556          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4701.5947    |
| evaluation/return-max          | 4908.5376    |
| evaluation/return-min          | 4549.3384    |
| evaluation/return-std          | 98.9585      |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.01         |
| model/origin_ret               | 85           |
| model/penalty_ret              | 81.9         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45766        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4701.5947    |
| perf/NormalizedReturn          | 1.02         |
| Q-avg                          | 191.85916    |
| Q-std                          | 169.36888    |
| Q_loss                         | 89.14348     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 556          |
| times/epoch_after_hook         | 1.77e-06     |
| times/epoch_before_hook        | 0.000145     |
| times/epoch_rollout_model      | 490          |
| times/evaluation_metrics       | 0.0006       |
| times/evaluation_paths         | 30.8         |
| times/timestep_after_hook      | 0.0037       |
| times/timestep_before_hook     | 0.00819      |
| times/train                    | 55.7         |
| timestep                       | 1000         |
| timesteps_total                | 557000       |
| train-steps                    | 557000       |
| training/Q/q1_loss             | 95.42032     |
| training/sac_pi/alpha          | 0.1652616    |
| training/sac_pi/alpha_loss     | -0.037765242 |
| training/sac_pi/logp_pi        | 3.5146873    |
| training/sac_pi/pi_entropy     | 3.4346511    |
| training/sac_pi/pi_global_norm | 1.3063471    |
| training/sac_pi/policy_loss    | -205.11336   |
| training/sac_pi/std            | 0.47471383   |
| training/sac_pi/valid_num      | 5020.0       |
| training/sac_Q/q1              | 199.78915    |
| training/sac_Q/q2              | 199.67978    |
| training/sac_Q/q2_loss         | 96.14839     |
| training/sac_Q/q_global_norm   | 187.3044     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16625665 |
| epoch                          | 557        |
| evaluation/episode-length-avg  | 637        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 344        |
| evaluation/episode-length-std  | 260        |
| evaluation/return-average      | 2799.7642  |
| evaluation/return-max          | 4883.6284  |
| evaluation/return-min          | 1381.3348  |
| evaluation/return-std          | 1320.0796  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45625      |
| perf/AverageLength             | 637        |
| perf/AverageReturn             | 2799.7642  |
| perf/NormalizedReturn          | 0.61       |
| Q-avg                          | 186.01442  |
| Q-std                          | 173.9504   |
| Q_loss                         | 102.66501  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 557        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.0003     |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000489   |
| times/evaluation_paths         | 19.7       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00784    |
| times/train                    | 56         |
| timestep                       | 1000       |
| timesteps_total                | 558000     |
| train-steps                    | 558000     |
| training/Q/q1_loss             | 105.09204  |
| training/sac_pi/alpha          | 0.16624312 |
| training/sac_pi/alpha_loss     | 0.5493563  |
| training/sac_pi/logp_pi        | 5.2446127  |
| training/sac_pi/pi_entropy     | 3.4870696  |
| training/sac_pi/pi_global_norm | 1.598646   |
| training/sac_pi/policy_loss    | -206.81857 |
| training/sac_pi/std            | 0.5400639  |
| training/sac_pi/valid_num      | 4946.0     |
| training/sac_Q/q1              | 188.75717  |
| training/sac_Q/q2              | 188.44998  |
| training/sac_Q/q2_loss         | 105.61885  |
| training/sac_Q/q_global_norm   | 324.5582   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16528384 |
| epoch                          | 558        |
| evaluation/episode-length-avg  | 934        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 337        |
| evaluation/episode-length-std  | 199        |
| evaluation/return-average      | 4482.3154  |
| evaluation/return-max          | 4874.599   |
| evaluation/return-min          | 1359.9285  |
| evaluation/return-std          | 1041.841   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45798      |
| perf/AverageLength             | 934        |
| perf/AverageReturn             | 4482.3154  |
| perf/NormalizedReturn          | 0.976      |
| Q-avg                          | 197.30826  |
| Q-std                          | 133.8935   |
| Q_loss                         | 99.97503   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 558        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000544   |
| times/evaluation_paths         | 28.7       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00797    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 559000     |
| train-steps                    | 559000     |
| training/Q/q1_loss             | 107.69154  |
| training/sac_pi/alpha          | 0.16528635 |
| training/sac_pi/alpha_loss     | 0.10052247 |
| training/sac_pi/logp_pi        | 4.760215   |
| training/sac_pi/pi_entropy     | 3.3888042  |
| training/sac_pi/pi_global_norm | 1.7903574  |
| training/sac_pi/policy_loss    | -219.56514 |
| training/sac_pi/std            | 0.51977086 |
| training/sac_pi/valid_num      | 5005.0     |
| training/sac_Q/q1              | 202.10617  |
| training/sac_Q/q2              | 202.1099   |
| training/sac_Q/q2_loss         | 108.90734  |
| training/sac_Q/q_global_norm   | 280.89392  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1668073    |
| epoch                          | 559          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4757.508     |
| evaluation/return-max          | 4893.739     |
| evaluation/return-min          | 4668.958     |
| evaluation/return-std          | 77.30821     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.92         |
| model/origin_ret               | 84.4         |
| model/penalty_ret              | 81.7         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45764        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4757.508     |
| perf/NormalizedReturn          | 1.04         |
| Q-avg                          | 198.10771    |
| Q-std                          | 127.37943    |
| Q_loss                         | 110.08236    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 559          |
| times/epoch_after_hook         | 1.95e-06     |
| times/epoch_before_hook        | 0.000133     |
| times/epoch_rollout_model      | 478          |
| times/evaluation_metrics       | 0.000562     |
| times/evaluation_paths         | 30.9         |
| times/timestep_after_hook      | 0.00369      |
| times/timestep_before_hook     | 0.00813      |
| times/train                    | 56           |
| timestep                       | 1000         |
| timesteps_total                | 560000       |
| train-steps                    | 560000       |
| training/Q/q1_loss             | 83.7905      |
| training/sac_pi/alpha          | 0.16680256   |
| training/sac_pi/alpha_loss     | -0.067294225 |
| training/sac_pi/logp_pi        | 3.9182434    |
| training/sac_pi/pi_entropy     | 3.497908     |
| training/sac_pi/pi_global_norm | 1.5682626    |
| training/sac_pi/policy_loss    | -205.43901   |
| training/sac_pi/std            | 0.49141175   |
| training/sac_pi/valid_num      | 4968.0       |
| training/sac_Q/q1              | 194.64062    |
| training/sac_Q/q2              | 192.92317    |
| training/sac_Q/q2_loss         | 84.229836    |
| training/sac_Q/q_global_norm   | 282.52997    |
----------------------------------------------------------------------------------
[WARN] 560 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.1726439  |
| epoch                          | 560        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4882.4736  |
| evaluation/return-max          | 5075.754   |
| evaluation/return-min          | 4473.7163  |
| evaluation/return-std          | 167.97015  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 82.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45581      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4882.4736  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 184.47842  |
| Q-std                          | 216.61766  |
| Q_loss                         | 94.740654  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 560        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000552   |
| times/evaluation_paths         | 30.9       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 56         |
| timestep                       | 1000       |
| timesteps_total                | 561000     |
| train-steps                    | 561000     |
| training/Q/q1_loss             | 87.13679   |
| training/sac_pi/alpha          | 0.17264062 |
| training/sac_pi/alpha_loss     | 0.2585195  |
| training/sac_pi/logp_pi        | 4.0224347  |
| training/sac_pi/pi_entropy     | 3.4105103  |
| training/sac_pi/pi_global_norm | 1.7358798  |
| training/sac_pi/policy_loss    | -207.65211 |
| training/sac_pi/std            | 0.47600988 |
| training/sac_pi/valid_num      | 5025.0     |
| training/sac_Q/q1              | 199.69565  |
| training/sac_Q/q2              | 199.70027  |
| training/sac_Q/q2_loss         | 86.95796   |
| training/sac_Q/q_global_norm   | 182.92677  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16511692  |
| epoch                          | 561         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5007.5405   |
| evaluation/return-max          | 5060.2354   |
| evaluation/return-min          | 4954.88     |
| evaluation/return-std          | 35.434948   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45847       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5007.5405   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 188.1268    |
| Q-std                          | 162.9301    |
| Q_loss                         | 120.190186  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 561         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000276    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000531    |
| times/evaluation_paths         | 30.6        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.0101      |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 562000      |
| train-steps                    | 562000      |
| training/Q/q1_loss             | 103.314575  |
| training/sac_pi/alpha          | 0.16511805  |
| training/sac_pi/alpha_loss     | -0.19722041 |
| training/sac_pi/logp_pi        | 3.8610978   |
| training/sac_pi/pi_entropy     | 3.435332    |
| training/sac_pi/pi_global_norm | 1.6579331   |
| training/sac_pi/policy_loss    | -199.99734  |
| training/sac_pi/std            | 0.4871245   |
| training/sac_pi/valid_num      | 4986.0      |
| training/sac_Q/q1              | 189.40594   |
| training/sac_Q/q2              | 187.91086   |
| training/sac_Q/q2_loss         | 103.12319   |
| training/sac_Q/q_global_norm   | 256.32022   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1668058  |
| epoch                          | 562        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4990.637   |
| evaluation/return-max          | 5036.4194  |
| evaluation/return-min          | 4960.2446  |
| evaluation/return-std          | 21.65705   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45890      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4990.637   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 187.48087  |
| Q-std                          | 190.13866  |
| Q_loss                         | 97.04062   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 562        |
| times/epoch_after_hook         | 3.86e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000577   |
| times/evaluation_paths         | 30.6       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00792    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 563000     |
| train-steps                    | 563000     |
| training/Q/q1_loss             | 85.80465   |
| training/sac_pi/alpha          | 0.1667605  |
| training/sac_pi/alpha_loss     | 0.10657168 |
| training/sac_pi/logp_pi        | 4.969245   |
| training/sac_pi/pi_entropy     | 3.350697   |
| training/sac_pi/pi_global_norm | 1.5354979  |
| training/sac_pi/policy_loss    | -206.95207 |
| training/sac_pi/std            | 0.51167214 |
| training/sac_pi/valid_num      | 4880.0     |
| training/sac_Q/q1              | 187.22153  |
| training/sac_Q/q2              | 185.27812  |
| training/sac_Q/q2_loss         | 84.52098   |
| training/sac_Q/q_global_norm   | 253.15533  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17102532  |
| epoch                          | 563         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4547.9707   |
| evaluation/return-max          | 4871.413    |
| evaluation/return-min          | 4335.0396   |
| evaluation/return-std          | 199.62796   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45877       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4547.9707   |
| perf/NormalizedReturn          | 0.99        |
| Q-avg                          | 185.62404   |
| Q-std                          | 184.61021   |
| Q_loss                         | 102.005585  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 563         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.00011     |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000543    |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00799     |
| times/train                    | 55.7        |
| timestep                       | 1000        |
| timesteps_total                | 564000      |
| train-steps                    | 564000      |
| training/Q/q1_loss             | 109.23468   |
| training/sac_pi/alpha          | 0.17102261  |
| training/sac_pi/alpha_loss     | 0.037169226 |
| training/sac_pi/logp_pi        | 5.1956844   |
| training/sac_pi/pi_entropy     | 3.5118337   |
| training/sac_pi/pi_global_norm | 1.445846    |
| training/sac_pi/policy_loss    | -195.69518  |
| training/sac_pi/std            | 0.53502774  |
| training/sac_pi/valid_num      | 4913.0      |
| training/sac_Q/q1              | 175.82552   |
| training/sac_Q/q2              | 173.6868    |
| training/sac_Q/q2_loss         | 108.94535   |
| training/sac_Q/q_global_norm   | 223.26668   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16635111 |
| epoch                          | 564        |
| evaluation/episode-length-avg  | 410        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 151        |
| evaluation/episode-length-std  | 386        |
| evaluation/return-average      | 1660.3948  |
| evaluation/return-max          | 4516.6396  |
| evaluation/return-min          | 498.5568   |
| evaluation/return-std          | 1751.7047  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45713      |
| perf/AverageLength             | 410        |
| perf/AverageReturn             | 1660.3948  |
| perf/NormalizedReturn          | 0.361      |
| Q-avg                          | 178.12454  |
| Q-std                          | 211.76842  |
| Q_loss                         | 103.85911  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 564        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000144   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000623   |
| times/evaluation_paths         | 12.6       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00806    |
| times/train                    | 55.5       |
| timestep                       | 1000       |
| timesteps_total                | 565000     |
| train-steps                    | 565000     |
| training/Q/q1_loss             | 123.035904 |
| training/sac_pi/alpha          | 0.16635638 |
| training/sac_pi/alpha_loss     | -0.4523072 |
| training/sac_pi/logp_pi        | 4.021651   |
| training/sac_pi/pi_entropy     | 3.4612403  |
| training/sac_pi/pi_global_norm | 1.6549581  |
| training/sac_pi/policy_loss    | -209.21852 |
| training/sac_pi/std            | 0.5060792  |
| training/sac_pi/valid_num      | 4956.0     |
| training/sac_Q/q1              | 195.37598  |
| training/sac_Q/q2              | 195.14458  |
| training/sac_Q/q2_loss         | 122.04977  |
| training/sac_Q/q_global_norm   | 218.75946  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16425778 |
| epoch                          | 565        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4344.9526  |
| evaluation/return-max          | 4448.0977  |
| evaluation/return-min          | 4277.836   |
| evaluation/return-std          | 48.54211   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45862      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4344.9526  |
| perf/NormalizedReturn          | 0.946      |
| Q-avg                          | 190.09805  |
| Q-std                          | 161.65114  |
| Q_loss                         | 101.854355 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 565        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000299   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.00125    |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00797    |
| times/train                    | 56.1       |
| timestep                       | 1000       |
| timesteps_total                | 566000     |
| train-steps                    | 566000     |
| training/Q/q1_loss             | 104.065506 |
| training/sac_pi/alpha          | 0.16424094 |
| training/sac_pi/alpha_loss     | 0.2612941  |
| training/sac_pi/logp_pi        | 3.7569191  |
| training/sac_pi/pi_entropy     | 3.4593863  |
| training/sac_pi/pi_global_norm | 1.3987132  |
| training/sac_pi/policy_loss    | -205.37431 |
| training/sac_pi/std            | 0.47878557 |
| training/sac_pi/valid_num      | 4984.0     |
| training/sac_Q/q1              | 197.68706  |
| training/sac_Q/q2              | 197.27267  |
| training/sac_Q/q2_loss         | 104.760284 |
| training/sac_Q/q_global_norm   | 211.87694  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16515392  |
| epoch                          | 566         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4747.149    |
| evaluation/return-max          | 4879.9995   |
| evaluation/return-min          | 4526.0366   |
| evaluation/return-std          | 97.074455   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45980       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4747.149    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 190.15245   |
| Q-std                          | 170.14604   |
| Q_loss                         | 77.53466    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 566         |
| times/epoch_after_hook         | 2.23e-06    |
| times/epoch_before_hook        | 0.000101    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000514    |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00782     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 567000      |
| train-steps                    | 567000      |
| training/Q/q1_loss             | 100.25048   |
| training/sac_pi/alpha          | 0.16518079  |
| training/sac_pi/alpha_loss     | -0.22809164 |
| training/sac_pi/logp_pi        | 4.459876    |
| training/sac_pi/pi_entropy     | 3.4378822   |
| training/sac_pi/pi_global_norm | 1.5294791   |
| training/sac_pi/policy_loss    | -208.38914  |
| training/sac_pi/std            | 0.5055535   |
| training/sac_pi/valid_num      | 4947.0      |
| training/sac_Q/q1              | 192.035     |
| training/sac_Q/q2              | 190.82654   |
| training/sac_Q/q2_loss         | 100.55108   |
| training/sac_Q/q_global_norm   | 212.73787   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16858454  |
| epoch                          | 567         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4818.2173   |
| evaluation/return-max          | 4856.235    |
| evaluation/return-min          | 4759.8076   |
| evaluation/return-std          | 33.88848    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 82.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45711       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4818.2173   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 214.69043   |
| Q-std                          | 92.60401    |
| Q_loss                         | 69.46734    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 567         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000102    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000578    |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 55.9        |
| timestep                       | 1000        |
| timesteps_total                | 568000      |
| train-steps                    | 568000      |
| training/Q/q1_loss             | 114.322845  |
| training/sac_pi/alpha          | 0.16859812  |
| training/sac_pi/alpha_loss     | 0.053577337 |
| training/sac_pi/logp_pi        | 5.452645    |
| training/sac_pi/pi_entropy     | 3.6262448   |
| training/sac_pi/pi_global_norm | 1.5018886   |
| training/sac_pi/policy_loss    | -203.97403  |
| training/sac_pi/std            | 0.55758786  |
| training/sac_pi/valid_num      | 4889.0      |
| training/sac_Q/q1              | 179.95708   |
| training/sac_Q/q2              | 177.45804   |
| training/sac_Q/q2_loss         | 114.818596  |
| training/sac_Q/q_global_norm   | 191.60551   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16576481 |
| epoch                          | 568        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4238.2925  |
| evaluation/return-max          | 4295.8203  |
| evaluation/return-min          | 4146.669   |
| evaluation/return-std          | 41.732964  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45923      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4238.2925  |
| perf/NormalizedReturn          | 0.923      |
| Q-avg                          | 195.80734  |
| Q-std                          | 166.26097  |
| Q_loss                         | 83.91283   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 568        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.00055    |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00789    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 569000     |
| train-steps                    | 569000     |
| training/Q/q1_loss             | 124.18503  |
| training/sac_pi/alpha          | 0.1657234  |
| training/sac_pi/alpha_loss     | 0.27228096 |
| training/sac_pi/logp_pi        | 4.449473   |
| training/sac_pi/pi_entropy     | 3.455217   |
| training/sac_pi/pi_global_norm | 2.0187547  |
| training/sac_pi/policy_loss    | -199.93724 |
| training/sac_pi/std            | 0.51210284 |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 184.68341  |
| training/sac_Q/q2              | 185.00443  |
| training/sac_Q/q2_loss         | 123.452034 |
| training/sac_Q/q_global_norm   | 254.10262  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16892743 |
| epoch                          | 569        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4892.912   |
| evaluation/return-max          | 4961.1562  |
| evaluation/return-min          | 4826.428   |
| evaluation/return-std          | 40.390778  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45827      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4892.912   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 199.55643  |
| Q-std                          | 157.40472  |
| Q_loss                         | 82.76656   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 569        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000287   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00787    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 570000     |
| train-steps                    | 570000     |
| training/Q/q1_loss             | 98.796455  |
| training/sac_pi/alpha          | 0.16894068 |
| training/sac_pi/alpha_loss     | 0.14687052 |
| training/sac_pi/logp_pi        | 5.3478036  |
| training/sac_pi/pi_entropy     | 3.431546   |
| training/sac_pi/pi_global_norm | 1.7005364  |
| training/sac_pi/policy_loss    | -206.22916 |
| training/sac_pi/std            | 0.53429043 |
| training/sac_pi/valid_num      | 4958.0     |
| training/sac_Q/q1              | 186.74353  |
| training/sac_Q/q2              | 184.34006  |
| training/sac_Q/q2_loss         | 97.810776  |
| training/sac_Q/q_global_norm   | 217.51617  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1634529   |
| epoch                          | 570         |
| evaluation/episode-length-avg  | 944         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 445         |
| evaluation/episode-length-std  | 166         |
| evaluation/return-average      | 4378.676    |
| evaluation/return-max          | 4781.919    |
| evaluation/return-min          | 1789.8684   |
| evaluation/return-std          | 864.91376   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45664       |
| perf/AverageLength             | 944         |
| perf/AverageReturn             | 4378.676    |
| perf/NormalizedReturn          | 0.953       |
| Q-avg                          | 182.1053    |
| Q-std                          | 199.91371   |
| Q_loss                         | 109.82503   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 570         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000101    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000537    |
| times/evaluation_paths         | 29.1        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00784     |
| times/train                    | 55.9        |
| timestep                       | 1000        |
| timesteps_total                | 571000      |
| train-steps                    | 571000      |
| training/Q/q1_loss             | 92.093796   |
| training/sac_pi/alpha          | 0.16347334  |
| training/sac_pi/alpha_loss     | -0.21879518 |
| training/sac_pi/logp_pi        | 4.2272964   |
| training/sac_pi/pi_entropy     | 3.4347186   |
| training/sac_pi/pi_global_norm | 1.4181674   |
| training/sac_pi/policy_loss    | -211.71213  |
| training/sac_pi/std            | 0.5054712   |
| training/sac_pi/valid_num      | 4923.0      |
| training/sac_Q/q1              | 193.14018   |
| training/sac_Q/q2              | 190.43172   |
| training/sac_Q/q2_loss         | 93.042114   |
| training/sac_Q/q_global_norm   | 218.41058   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16717412 |
| epoch                          | 571        |
| evaluation/episode-length-avg  | 941        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 413        |
| evaluation/episode-length-std  | 176        |
| evaluation/return-average      | 4036.661   |
| evaluation/return-max          | 4509.946   |
| evaluation/return-min          | 1575.6013  |
| evaluation/return-std          | 832.92865  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.87       |
| model/origin_ret               | 82.6       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45873      |
| perf/AverageLength             | 941        |
| perf/AverageReturn             | 4036.661   |
| perf/NormalizedReturn          | 0.879      |
| Q-avg                          | 194.14194  |
| Q-std                          | 192.65097  |
| Q_loss                         | 84.71191   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 571        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000103   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000605   |
| times/evaluation_paths         | 28.9       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00802    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 572000     |
| train-steps                    | 572000     |
| training/Q/q1_loss             | 105.91317  |
| training/sac_pi/alpha          | 0.16716076 |
| training/sac_pi/alpha_loss     | 0.17809005 |
| training/sac_pi/logp_pi        | 4.260933   |
| training/sac_pi/pi_entropy     | 3.5095248  |
| training/sac_pi/pi_global_norm | 1.499193   |
| training/sac_pi/policy_loss    | -206.01695 |
| training/sac_pi/std            | 0.49776083 |
| training/sac_pi/valid_num      | 4974.0     |
| training/sac_Q/q1              | 194.71866  |
| training/sac_Q/q2              | 195.1073   |
| training/sac_Q/q2_loss         | 104.67659  |
| training/sac_Q/q_global_norm   | 189.71718  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17234975   |
| epoch                          | 572          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5060.929     |
| evaluation/return-max          | 5122.937     |
| evaluation/return-min          | 5027.56      |
| evaluation/return-std          | 30.272406    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.92         |
| model/origin_ret               | 84.5         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45754        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5060.929     |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 180.47264    |
| Q-std                          | 181.72842    |
| Q_loss                         | 125.534035   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 572          |
| times/epoch_after_hook         | 1.93e-06     |
| times/epoch_before_hook        | 0.000141     |
| times/epoch_rollout_model      | 481          |
| times/evaluation_metrics       | 0.000577     |
| times/evaluation_paths         | 31.2         |
| times/timestep_after_hook      | 0.00385      |
| times/timestep_before_hook     | 0.00816      |
| times/train                    | 56           |
| timestep                       | 1000         |
| timesteps_total                | 573000       |
| train-steps                    | 573000       |
| training/Q/q1_loss             | 98.000946    |
| training/sac_pi/alpha          | 0.1722976    |
| training/sac_pi/alpha_loss     | -0.048065513 |
| training/sac_pi/logp_pi        | 4.627435     |
| training/sac_pi/pi_entropy     | 3.7316833    |
| training/sac_pi/pi_global_norm | 1.4628847    |
| training/sac_pi/policy_loss    | -206.28926   |
| training/sac_pi/std            | 0.56078035   |
| training/sac_pi/valid_num      | 4955.0       |
| training/sac_Q/q1              | 189.43344    |
| training/sac_Q/q2              | 189.48874    |
| training/sac_Q/q2_loss         | 98.56362     |
| training/sac_Q/q_global_norm   | 259.66446    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17023705  |
| epoch                          | 573         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4882.86     |
| evaluation/return-max          | 4949.424    |
| evaluation/return-min          | 4838.9385   |
| evaluation/return-std          | 38.610474   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45708       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4882.86     |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 183.06586   |
| Q-std                          | 194.41922   |
| Q_loss                         | 98.6801     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 573         |
| times/epoch_after_hook         | 3.35e-06    |
| times/epoch_before_hook        | 0.000281    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000563    |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00795     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 574000      |
| train-steps                    | 574000      |
| training/Q/q1_loss             | 82.54027    |
| training/sac_pi/alpha          | 0.17026201  |
| training/sac_pi/alpha_loss     | -0.34272867 |
| training/sac_pi/logp_pi        | 4.0833387   |
| training/sac_pi/pi_entropy     | 3.3972268   |
| training/sac_pi/pi_global_norm | 1.5105524   |
| training/sac_pi/policy_loss    | -214.0051   |
| training/sac_pi/std            | 0.4924068   |
| training/sac_pi/valid_num      | 4930.0      |
| training/sac_Q/q1              | 199.47638   |
| training/sac_Q/q2              | 198.18948   |
| training/sac_Q/q2_loss         | 83.01084    |
| training/sac_Q/q_global_norm   | 177.39595   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16694842  |
| epoch                          | 574         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4795.151    |
| evaluation/return-max          | 4977.7026   |
| evaluation/return-min          | 4643.0728   |
| evaluation/return-std          | 103.47284   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46001       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4795.151    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 196.00589   |
| Q-std                          | 179.43912   |
| Q_loss                         | 98.90064    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 574         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000563    |
| times/evaluation_paths         | 29.9        |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 575000      |
| train-steps                    | 575000      |
| training/Q/q1_loss             | 94.94483    |
| training/sac_pi/alpha          | 0.1669749   |
| training/sac_pi/alpha_loss     | -0.25207055 |
| training/sac_pi/logp_pi        | 4.22967     |
| training/sac_pi/pi_entropy     | 3.2398543   |
| training/sac_pi/pi_global_norm | 1.8199866   |
| training/sac_pi/policy_loss    | -209.94695  |
| training/sac_pi/std            | 0.47478184  |
| training/sac_pi/valid_num      | 4959.0      |
| training/sac_Q/q1              | 197.84811   |
| training/sac_Q/q2              | 195.89995   |
| training/sac_Q/q2_loss         | 95.0084     |
| training/sac_Q/q_global_norm   | 154.57236   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17218615 |
| epoch                          | 575        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4719.547   |
| evaluation/return-max          | 4858.716   |
| evaluation/return-min          | 4579.7197  |
| evaluation/return-std          | 94.985916  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45843      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4719.547   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 184.3724   |
| Q-std                          | 183.61002  |
| Q_loss                         | 94.841545  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 575        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000107   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 56.7       |
| timestep                       | 1000       |
| timesteps_total                | 576000     |
| train-steps                    | 576000     |
| training/Q/q1_loss             | 95.038185  |
| training/sac_pi/alpha          | 0.17223482 |
| training/sac_pi/alpha_loss     | 0.18023005 |
| training/sac_pi/logp_pi        | 5.396452   |
| training/sac_pi/pi_entropy     | 3.4535935  |
| training/sac_pi/pi_global_norm | 1.530218   |
| training/sac_pi/policy_loss    | -198.05525 |
| training/sac_pi/std            | 0.5384791  |
| training/sac_pi/valid_num      | 4882.0     |
| training/sac_Q/q1              | 170.99637  |
| training/sac_Q/q2              | 172.98376  |
| training/sac_Q/q2_loss         | 95.387024  |
| training/sac_Q/q_global_norm   | 200.9647   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16819592   |
| epoch                          | 576          |
| evaluation/episode-length-avg  | 916          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 158          |
| evaluation/episode-length-std  | 253          |
| evaluation/return-average      | 4148.776     |
| evaluation/return-max          | 4583.4805    |
| evaluation/return-min          | 389.0018     |
| evaluation/return-std          | 1253.3193    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3            |
| model/origin_ret               | 84.9         |
| model/penalty_ret              | 81.1         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45794        |
| perf/AverageLength             | 916          |
| perf/AverageReturn             | 4148.776     |
| perf/NormalizedReturn          | 0.903        |
| Q-avg                          | 199.29155    |
| Q-std                          | 156.06044    |
| Q_loss                         | 100.49269    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 576          |
| times/epoch_after_hook         | 1.89e-06     |
| times/epoch_before_hook        | 0.000112     |
| times/epoch_rollout_model      | 479          |
| times/evaluation_metrics       | 0.000535     |
| times/evaluation_paths         | 28.1         |
| times/timestep_after_hook      | 0.00375      |
| times/timestep_before_hook     | 0.00826      |
| times/train                    | 56.7         |
| timestep                       | 1000         |
| timesteps_total                | 577000       |
| train-steps                    | 577000       |
| training/Q/q1_loss             | 104.00643    |
| training/sac_pi/alpha          | 0.16819859   |
| training/sac_pi/alpha_loss     | -0.066208184 |
| training/sac_pi/logp_pi        | 4.399517     |
| training/sac_pi/pi_entropy     | 3.437425     |
| training/sac_pi/pi_global_norm | 1.5262958    |
| training/sac_pi/policy_loss    | -203.85004   |
| training/sac_pi/std            | 0.5065095    |
| training/sac_pi/valid_num      | 4964.0       |
| training/sac_Q/q1              | 187.71817    |
| training/sac_Q/q2              | 188.26059    |
| training/sac_Q/q2_loss         | 103.681656   |
| training/sac_Q/q_global_norm   | 206.02892    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16914286  |
| epoch                          | 577         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5045.5615   |
| evaluation/return-max          | 5108.187    |
| evaluation/return-min          | 4915.972    |
| evaluation/return-std          | 67.38887    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45883       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5045.5615   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 187.03505   |
| Q-std                          | 178.78418   |
| Q_loss                         | 108.8852    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 577         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000344    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000554    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00381     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 56.7        |
| timestep                       | 1000        |
| timesteps_total                | 578000      |
| train-steps                    | 578000      |
| training/Q/q1_loss             | 97.34266    |
| training/sac_pi/alpha          | 0.16916406  |
| training/sac_pi/alpha_loss     | -0.14543153 |
| training/sac_pi/logp_pi        | 4.6160994   |
| training/sac_pi/pi_entropy     | 3.644593    |
| training/sac_pi/pi_global_norm | 1.4731764   |
| training/sac_pi/policy_loss    | -204.71733  |
| training/sac_pi/std            | 0.538477    |
| training/sac_pi/valid_num      | 4929.0      |
| training/sac_Q/q1              | 187.76001   |
| training/sac_Q/q2              | 184.93542   |
| training/sac_Q/q2_loss         | 98.56956    |
| training/sac_Q/q_global_norm   | 296.422     |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16995002 |
| epoch                          | 578        |
| evaluation/episode-length-avg  | 968        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 679        |
| evaluation/episode-length-std  | 96.3       |
| evaluation/return-average      | 4350.0483  |
| evaluation/return-max          | 4599.35    |
| evaluation/return-min          | 2961.9563  |
| evaluation/return-std          | 464.85632  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45767      |
| perf/AverageLength             | 968        |
| perf/AverageReturn             | 4350.0483  |
| perf/NormalizedReturn          | 0.947      |
| Q-avg                          | 177.13052  |
| Q-std                          | 215.75307  |
| Q_loss                         | 111.506165 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 578        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000111   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000526   |
| times/evaluation_paths         | 29.5       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 56.8       |
| timestep                       | 1000       |
| timesteps_total                | 579000     |
| train-steps                    | 579000     |
| training/Q/q1_loss             | 115.73995  |
| training/sac_pi/alpha          | 0.16992599 |
| training/sac_pi/alpha_loss     | 0.18792737 |
| training/sac_pi/logp_pi        | 5.312162   |
| training/sac_pi/pi_entropy     | 3.6526356  |
| training/sac_pi/pi_global_norm | 1.4902307  |
| training/sac_pi/policy_loss    | -202.56458 |
| training/sac_pi/std            | 0.55723286 |
| training/sac_pi/valid_num      | 4901.0     |
| training/sac_Q/q1              | 182.11502  |
| training/sac_Q/q2              | 179.41402  |
| training/sac_Q/q2_loss         | 115.919    |
| training/sac_Q/q_global_norm   | 299.93872  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16523491 |
| epoch                          | 579        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4992.722   |
| evaluation/return-max          | 5061.1997  |
| evaluation/return-min          | 4859.1133  |
| evaluation/return-std          | 65.266106  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45966      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4992.722   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 197.82101  |
| Q-std                          | 161.30933  |
| Q_loss                         | 86.51078   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 579        |
| times/epoch_after_hook         | 2.19e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 56.9       |
| timestep                       | 1000       |
| timesteps_total                | 580000     |
| train-steps                    | 580000     |
| training/Q/q1_loss             | 119.07378  |
| training/sac_pi/alpha          | 0.16525091 |
| training/sac_pi/alpha_loss     | -0.0135108 |
| training/sac_pi/logp_pi        | 4.328318   |
| training/sac_pi/pi_entropy     | 3.5481434  |
| training/sac_pi/pi_global_norm | 1.7070805  |
| training/sac_pi/policy_loss    | -203.80873 |
| training/sac_pi/std            | 0.51462024 |
| training/sac_pi/valid_num      | 4912.0     |
| training/sac_Q/q1              | 186.4186   |
| training/sac_Q/q2              | 183.49405  |
| training/sac_Q/q2_loss         | 118.779915 |
| training/sac_Q/q_global_norm   | 272.25598  |
--------------------------------------------------------------------------------
[WARN] 580 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16594149  |
| epoch                          | 580         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4990.6655   |
| evaluation/return-max          | 5031.583    |
| evaluation/return-min          | 4928.8926   |
| evaluation/return-std          | 27.06341    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45897       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4990.6655   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 181.96945   |
| Q-std                          | 197.76648   |
| Q_loss                         | 106.20492   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 580         |
| times/epoch_after_hook         | 2.08e-06    |
| times/epoch_before_hook        | 0.00011     |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000595    |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.00376     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 56.9        |
| timestep                       | 1000        |
| timesteps_total                | 581000      |
| train-steps                    | 581000      |
| training/Q/q1_loss             | 100.54077   |
| training/sac_pi/alpha          | 0.16596715  |
| training/sac_pi/alpha_loss     | -0.28879306 |
| training/sac_pi/logp_pi        | 4.837714    |
| training/sac_pi/pi_entropy     | 3.5775611   |
| training/sac_pi/pi_global_norm | 1.7140546   |
| training/sac_pi/policy_loss    | -206.10919  |
| training/sac_pi/std            | 0.55006284  |
| training/sac_pi/valid_num      | 4950.0      |
| training/sac_Q/q1              | 183.19815   |
| training/sac_Q/q2              | 182.80461   |
| training/sac_Q/q2_loss         | 100.57858   |
| training/sac_Q/q_global_norm   | 247.62082   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16704108 |
| epoch                          | 581        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4534.664   |
| evaluation/return-max          | 4640.9775  |
| evaluation/return-min          | 4443.8535  |
| evaluation/return-std          | 52.027885  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45911      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4534.664   |
| perf/NormalizedReturn          | 0.987      |
| Q-avg                          | 203.4907   |
| Q-std                          | 124.132515 |
| Q_loss                         | 85.968414  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 581        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000282   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000542   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 56.9       |
| timestep                       | 1000       |
| timesteps_total                | 582000     |
| train-steps                    | 582000     |
| training/Q/q1_loss             | 101.18669  |
| training/sac_pi/alpha          | 0.16701327 |
| training/sac_pi/alpha_loss     | 0.3582901  |
| training/sac_pi/logp_pi        | 4.9210296  |
| training/sac_pi/pi_entropy     | 3.5202096  |
| training/sac_pi/pi_global_norm | 1.4165466  |
| training/sac_pi/policy_loss    | -201.39847 |
| training/sac_pi/std            | 0.5202715  |
| training/sac_pi/valid_num      | 4945.0     |
| training/sac_Q/q1              | 181.93602  |
| training/sac_Q/q2              | 180.06194  |
| training/sac_Q/q2_loss         | 100.69205  |
| training/sac_Q/q_global_norm   | 186.6544   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16434602  |
| epoch                          | 582         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4800.6216   |
| evaluation/return-max          | 4866.548    |
| evaluation/return-min          | 4723.0225   |
| evaluation/return-std          | 50.05829    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45901       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4800.6216   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 192.02864   |
| Q-std                          | 219.80164   |
| Q_loss                         | 85.491425   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 582         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000107    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000542    |
| times/evaluation_paths         | 30.4        |
| times/timestep_after_hook      | 0.0038      |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 56.7        |
| timestep                       | 1000        |
| timesteps_total                | 583000      |
| train-steps                    | 583000      |
| training/Q/q1_loss             | 103.390816  |
| training/sac_pi/alpha          | 0.16432177  |
| training/sac_pi/alpha_loss     | -0.08320021 |
| training/sac_pi/logp_pi        | 4.5031505   |
| training/sac_pi/pi_entropy     | 3.3075118   |
| training/sac_pi/pi_global_norm | 1.5655743   |
| training/sac_pi/policy_loss    | -202.53542  |
| training/sac_pi/std            | 0.4812376   |
| training/sac_pi/valid_num      | 4924.0      |
| training/sac_Q/q1              | 185.66269   |
| training/sac_Q/q2              | 183.9782    |
| training/sac_Q/q2_loss         | 103.14996   |
| training/sac_Q/q_global_norm   | 240.52904   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16515829 |
| epoch                          | 583        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5077.37    |
| evaluation/return-max          | 5128.266   |
| evaluation/return-min          | 4884.99    |
| evaluation/return-std          | 65.78449   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45865      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5077.37    |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 195.75491  |
| Q-std                          | 127.064026 |
| Q_loss                         | 107.009636 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 583        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000114   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.00057    |
| times/evaluation_paths         | 30.4       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 57.3       |
| timestep                       | 1000       |
| timesteps_total                | 584000     |
| train-steps                    | 584000     |
| training/Q/q1_loss             | 85.938286  |
| training/sac_pi/alpha          | 0.16514055 |
| training/sac_pi/alpha_loss     | 0.21262223 |
| training/sac_pi/logp_pi        | 4.1878424  |
| training/sac_pi/pi_entropy     | 3.3493366  |
| training/sac_pi/pi_global_norm | 1.3689129  |
| training/sac_pi/policy_loss    | -213.48216 |
| training/sac_pi/std            | 0.48618796 |
| training/sac_pi/valid_num      | 4991.0     |
| training/sac_Q/q1              | 200.81741  |
| training/sac_Q/q2              | 198.50119  |
| training/sac_Q/q2_loss         | 85.96361   |
| training/sac_Q/q_global_norm   | 214.04187  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16749811 |
| epoch                          | 584        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4920.663   |
| evaluation/return-max          | 4951.908   |
| evaluation/return-min          | 4867.955   |
| evaluation/return-std          | 21.331997  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45796      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4920.663   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 186.20915  |
| Q-std                          | 138.65584  |
| Q_loss                         | 90.91465   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 584        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000108   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000539   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00797    |
| times/train                    | 56         |
| timestep                       | 1000       |
| timesteps_total                | 585000     |
| train-steps                    | 585000     |
| training/Q/q1_loss             | 87.60962   |
| training/sac_pi/alpha          | 0.16744806 |
| training/sac_pi/alpha_loss     | 0.14450662 |
| training/sac_pi/logp_pi        | 4.4765     |
| training/sac_pi/pi_entropy     | 3.7419262  |
| training/sac_pi/pi_global_norm | 1.5740511  |
| training/sac_pi/policy_loss    | -202.17757 |
| training/sac_pi/std            | 0.5340416  |
| training/sac_pi/valid_num      | 4905.0     |
| training/sac_Q/q1              | 184.60219  |
| training/sac_Q/q2              | 185.89278  |
| training/sac_Q/q2_loss         | 87.73235   |
| training/sac_Q/q_global_norm   | 192.97615  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16154984 |
| epoch                          | 585        |
| evaluation/episode-length-avg  | 833        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 165        |
| evaluation/episode-length-std  | 334        |
| evaluation/return-average      | 4134.1772  |
| evaluation/return-max          | 5121.0464  |
| evaluation/return-min          | 517.74445  |
| evaluation/return-std          | 1807.843   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45785      |
| perf/AverageLength             | 833        |
| perf/AverageReturn             | 4134.1772  |
| perf/NormalizedReturn          | 0.9        |
| Q-avg                          | 187.41826  |
| Q-std                          | 222.99596  |
| Q_loss                         | 125.94325  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 585        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000276   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000524   |
| times/evaluation_paths         | 25.9       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00791    |
| times/train                    | 56.1       |
| timestep                       | 1000       |
| timesteps_total                | 586000     |
| train-steps                    | 586000     |
| training/Q/q1_loss             | 104.12122  |
| training/sac_pi/alpha          | 0.16152528 |
| training/sac_pi/alpha_loss     | 0.20512637 |
| training/sac_pi/logp_pi        | 5.1749396  |
| training/sac_pi/pi_entropy     | 3.4141517  |
| training/sac_pi/pi_global_norm | 1.6452688  |
| training/sac_pi/policy_loss    | -200.98988 |
| training/sac_pi/std            | 0.5249611  |
| training/sac_pi/valid_num      | 4933.0     |
| training/sac_Q/q1              | 181.18713  |
| training/sac_Q/q2              | 181.23413  |
| training/sac_Q/q2_loss         | 104.21268  |
| training/sac_Q/q_global_norm   | 245.76453  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15784694 |
| epoch                          | 586        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4764.0425  |
| evaluation/return-max          | 4850.788   |
| evaluation/return-min          | 4644.9565  |
| evaluation/return-std          | 66.549385  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 83.8       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45644      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4764.0425  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 187.3171   |
| Q-std                          | 194.88214  |
| Q_loss                         | 105.94922  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 586        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000102   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000514   |
| times/evaluation_paths         | 31.3       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 55         |
| timestep                       | 1000       |
| timesteps_total                | 587000     |
| train-steps                    | 587000     |
| training/Q/q1_loss             | 77.58842   |
| training/sac_pi/alpha          | 0.15785575 |
| training/sac_pi/alpha_loss     | -0.193006  |
| training/sac_pi/logp_pi        | 5.1003256  |
| training/sac_pi/pi_entropy     | 3.4230149  |
| training/sac_pi/pi_global_norm | 1.4913234  |
| training/sac_pi/policy_loss    | -207.87488 |
| training/sac_pi/std            | 0.5344187  |
| training/sac_pi/valid_num      | 4915.0     |
| training/sac_Q/q1              | 185.8833   |
| training/sac_Q/q2              | 184.33823  |
| training/sac_Q/q2_loss         | 77.02019   |
| training/sac_Q/q_global_norm   | 200.92845  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16196097  |
| epoch                          | 587         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4864.814    |
| evaluation/return-max          | 4983.771    |
| evaluation/return-min          | 4794.8164   |
| evaluation/return-std          | 65.59763    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45759       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4864.814    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 177.90607   |
| Q-std                          | 217.48767   |
| Q_loss                         | 98.06912    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 587         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000104    |
| times/epoch_rollout_model      | 504         |
| times/evaluation_metrics       | 0.000527    |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 55          |
| timestep                       | 1000        |
| timesteps_total                | 588000      |
| train-steps                    | 588000      |
| training/Q/q1_loss             | 102.76371   |
| training/sac_pi/alpha          | 0.16199861  |
| training/sac_pi/alpha_loss     | -0.41746253 |
| training/sac_pi/logp_pi        | 4.2777605   |
| training/sac_pi/pi_entropy     | 3.5860457   |
| training/sac_pi/pi_global_norm | 1.4589097   |
| training/sac_pi/policy_loss    | -203.38487  |
| training/sac_pi/std            | 0.5223267   |
| training/sac_pi/valid_num      | 4887.0      |
| training/sac_Q/q1              | 179.27954   |
| training/sac_Q/q2              | 177.05237   |
| training/sac_Q/q2_loss         | 102.87651   |
| training/sac_Q/q_global_norm   | 219.36589   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1674212  |
| epoch                          | 588        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4914.428   |
| evaluation/return-max          | 4963.799   |
| evaluation/return-min          | 4843.366   |
| evaluation/return-std          | 34.39679   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45872      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4914.428   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 189.87503  |
| Q-std                          | 181.81258  |
| Q_loss                         | 86.24868   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 588        |
| times/epoch_after_hook         | 3.41e-06   |
| times/epoch_before_hook        | 0.00011    |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000577   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 54.5       |
| timestep                       | 1000       |
| timesteps_total                | 589000     |
| train-steps                    | 589000     |
| training/Q/q1_loss             | 101.41138  |
| training/sac_pi/alpha          | 0.16739261 |
| training/sac_pi/alpha_loss     | 0.17183246 |
| training/sac_pi/logp_pi        | 4.719278   |
| training/sac_pi/pi_entropy     | 3.6083865  |
| training/sac_pi/pi_global_norm | 1.425195   |
| training/sac_pi/policy_loss    | -202.9507  |
| training/sac_pi/std            | 0.53748524 |
| training/sac_pi/valid_num      | 4979.0     |
| training/sac_Q/q1              | 182.32166  |
| training/sac_Q/q2              | 180.1671   |
| training/sac_Q/q2_loss         | 101.13585  |
| training/sac_Q/q_global_norm   | 237.80887  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15673828  |
| epoch                          | 589         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5020.8374   |
| evaluation/return-max          | 5071.8696   |
| evaluation/return-min          | 4967.6245   |
| evaluation/return-std          | 32.316013   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45851       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5020.8374   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 197.26651   |
| Q-std                          | 146.7654    |
| Q_loss                         | 86.45324    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 589         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000335    |
| times/epoch_rollout_model      | 501         |
| times/evaluation_metrics       | 0.000525    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.0038      |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 54.2        |
| timestep                       | 1000        |
| timesteps_total                | 590000      |
| train-steps                    | 590000      |
| training/Q/q1_loss             | 96.68198    |
| training/sac_pi/alpha          | 0.15671115  |
| training/sac_pi/alpha_loss     | 0.111106195 |
| training/sac_pi/logp_pi        | 5.863611    |
| training/sac_pi/pi_entropy     | 3.113791    |
| training/sac_pi/pi_global_norm | 1.6324301   |
| training/sac_pi/policy_loss    | -204.30186  |
| training/sac_pi/std            | 0.5095542   |
| training/sac_pi/valid_num      | 4875.0      |
| training/sac_Q/q1              | 176.39856   |
| training/sac_Q/q2              | 175.76596   |
| training/sac_Q/q2_loss         | 97.24656    |
| training/sac_Q/q_global_norm   | 281.15884   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1670058  |
| epoch                          | 590        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5051.575   |
| evaluation/return-max          | 5114.6006  |
| evaluation/return-min          | 4943.5684  |
| evaluation/return-std          | 43.80271   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45926      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5051.575   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 194.83206  |
| Q-std                          | 160.15898  |
| Q_loss                         | 100.530495 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 590        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.00055    |
| times/evaluation_paths         | 31.4       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 591000     |
| train-steps                    | 591000     |
| training/Q/q1_loss             | 85.4695    |
| training/sac_pi/alpha          | 0.16700645 |
| training/sac_pi/alpha_loss     | 0.09434351 |
| training/sac_pi/logp_pi        | 4.3704453  |
| training/sac_pi/pi_entropy     | 3.4820075  |
| training/sac_pi/pi_global_norm | 1.6222496  |
| training/sac_pi/policy_loss    | -204.6993  |
| training/sac_pi/std            | 0.5041864  |
| training/sac_pi/valid_num      | 4971.0     |
| training/sac_Q/q1              | 192.9216   |
| training/sac_Q/q2              | 189.65816  |
| training/sac_Q/q2_loss         | 84.35951   |
| training/sac_Q/q_global_norm   | 266.4155   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16739959 |
| epoch                          | 591        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5129.9727  |
| evaluation/return-max          | 5189.198   |
| evaluation/return-min          | 5068.6797  |
| evaluation/return-std          | 34.182957  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45766      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5129.9727  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 199.51865  |
| Q-std                          | 160.23087  |
| Q_loss                         | 86.23827   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 591        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000534   |
| times/evaluation_paths         | 31.3       |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 55         |
| timestep                       | 1000       |
| timesteps_total                | 592000     |
| train-steps                    | 592000     |
| training/Q/q1_loss             | 108.62805  |
| training/sac_pi/alpha          | 0.16738386 |
| training/sac_pi/alpha_loss     | 0.09733777 |
| training/sac_pi/logp_pi        | 5.206979   |
| training/sac_pi/pi_entropy     | 3.6336265  |
| training/sac_pi/pi_global_norm | 1.4987999  |
| training/sac_pi/policy_loss    | -205.8032  |
| training/sac_pi/std            | 0.5540064  |
| training/sac_pi/valid_num      | 4900.0     |
| training/sac_Q/q1              | 182.70642  |
| training/sac_Q/q2              | 182.45349  |
| training/sac_Q/q2_loss         | 107.40063  |
| training/sac_Q/q_global_norm   | 291.64444  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16804807   |
| epoch                          | 592          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4824.587     |
| evaluation/return-max          | 4919.616     |
| evaluation/return-min          | 4668.9756    |
| evaluation/return-std          | 92.441216    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.98         |
| model/origin_ret               | 85.7         |
| model/penalty_ret              | 81.9         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45582        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4824.587     |
| perf/NormalizedReturn          | 1.05         |
| Q-avg                          | 180.8345     |
| Q-std                          | 202.73674    |
| Q_loss                         | 113.31867    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 592          |
| times/epoch_after_hook         | 1.84e-06     |
| times/epoch_before_hook        | 0.000134     |
| times/epoch_rollout_model      | 500          |
| times/evaluation_metrics       | 0.000564     |
| times/evaluation_paths         | 31.2         |
| times/timestep_after_hook      | 0.00375      |
| times/timestep_before_hook     | 0.00809      |
| times/train                    | 55.6         |
| timestep                       | 1000         |
| timesteps_total                | 593000       |
| train-steps                    | 593000       |
| training/Q/q1_loss             | 76.98988     |
| training/sac_pi/alpha          | 0.1680512    |
| training/sac_pi/alpha_loss     | -0.027480694 |
| training/sac_pi/logp_pi        | 4.234483     |
| training/sac_pi/pi_entropy     | 3.474118     |
| training/sac_pi/pi_global_norm | 2.0090373    |
| training/sac_pi/policy_loss    | -208.80914   |
| training/sac_pi/std            | 0.4949659    |
| training/sac_pi/valid_num      | 4955.0       |
| training/sac_Q/q1              | 194.07697    |
| training/sac_Q/q2              | 194.30415    |
| training/sac_Q/q2_loss         | 77.15265     |
| training/sac_Q/q_global_norm   | 170.61394    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16800903 |
| epoch                          | 593        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4850.7637  |
| evaluation/return-max          | 4898.629   |
| evaluation/return-min          | 4741.4507  |
| evaluation/return-std          | 46.10365   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45616      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4850.7637  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 190.2797   |
| Q-std                          | 166.59676  |
| Q_loss                         | 97.20679   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 593        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000334   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000532   |
| times/evaluation_paths         | 31.4       |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 54.6       |
| timestep                       | 1000       |
| timesteps_total                | 594000     |
| train-steps                    | 594000     |
| training/Q/q1_loss             | 102.58294  |
| training/sac_pi/alpha          | 0.16799453 |
| training/sac_pi/alpha_loss     | 0.18450087 |
| training/sac_pi/logp_pi        | 4.907743   |
| training/sac_pi/pi_entropy     | 3.445745   |
| training/sac_pi/pi_global_norm | 1.8336334  |
| training/sac_pi/policy_loss    | -202.02612 |
| training/sac_pi/std            | 0.5261777  |
| training/sac_pi/valid_num      | 4834.0     |
| training/sac_Q/q1              | 179.73032  |
| training/sac_Q/q2              | 183.72716  |
| training/sac_Q/q2_loss         | 102.59206  |
| training/sac_Q/q_global_norm   | 213.21277  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17011945 |
| epoch                          | 594        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4987.8223  |
| evaluation/return-max          | 5149.7354  |
| evaluation/return-min          | 4719.8164  |
| evaluation/return-std          | 147.32246  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45875      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4987.8223  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 183.12961  |
| Q-std                          | 173.57935  |
| Q_loss                         | 109.15269  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 594        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000525   |
| times/evaluation_paths         | 31.1       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 54.9       |
| timestep                       | 1000       |
| timesteps_total                | 595000     |
| train-steps                    | 595000     |
| training/Q/q1_loss             | 91.892586  |
| training/sac_pi/alpha          | 0.17013307 |
| training/sac_pi/alpha_loss     | -0.5769095 |
| training/sac_pi/logp_pi        | 4.740898   |
| training/sac_pi/pi_entropy     | 3.4698174  |
| training/sac_pi/pi_global_norm | 1.5039766  |
| training/sac_pi/policy_loss    | -205.26712 |
| training/sac_pi/std            | 0.5302481  |
| training/sac_pi/valid_num      | 4905.0     |
| training/sac_Q/q1              | 186.14029  |
| training/sac_Q/q2              | 184.32498  |
| training/sac_Q/q2_loss         | 91.4167    |
| training/sac_Q/q_global_norm   | 152.98315  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16846383 |
| epoch                          | 595        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4777.1924  |
| evaluation/return-max          | 4878.7324  |
| evaluation/return-min          | 4710.26    |
| evaluation/return-std          | 50.720142  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45842      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4777.1924  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 194.65984  |
| Q-std                          | 164.3641   |
| Q_loss                         | 102.21961  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 595        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000113   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.00052    |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.008      |
| times/train                    | 54.7       |
| timestep                       | 1000       |
| timesteps_total                | 596000     |
| train-steps                    | 596000     |
| training/Q/q1_loss             | 97.279724  |
| training/sac_pi/alpha          | 0.16844854 |
| training/sac_pi/alpha_loss     | -0.22268   |
| training/sac_pi/logp_pi        | 5.974375   |
| training/sac_pi/pi_entropy     | 3.4611428  |
| training/sac_pi/pi_global_norm | 1.5328563  |
| training/sac_pi/policy_loss    | -198.46146 |
| training/sac_pi/std            | 0.56204075 |
| training/sac_pi/valid_num      | 4842.0     |
| training/sac_Q/q1              | 170.9076   |
| training/sac_Q/q2              | 170.56808  |
| training/sac_Q/q2_loss         | 96.900154  |
| training/sac_Q/q_global_norm   | 203.17638  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16653253 |
| epoch                          | 596        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4926.7     |
| evaluation/return-max          | 4949.528   |
| evaluation/return-min          | 4869.756   |
| evaluation/return-std          | 23.924376  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45890      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4926.7     |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 178.93797  |
| Q-std                          | 201.04051  |
| Q_loss                         | 94.0616    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 596        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000565   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.008      |
| times/train                    | 53.9       |
| timestep                       | 1000       |
| timesteps_total                | 597000     |
| train-steps                    | 597000     |
| training/Q/q1_loss             | 106.81318  |
| training/sac_pi/alpha          | 0.16649912 |
| training/sac_pi/alpha_loss     | 0.18063405 |
| training/sac_pi/logp_pi        | 4.7097826  |
| training/sac_pi/pi_entropy     | 3.398957   |
| training/sac_pi/pi_global_norm | 1.3992984  |
| training/sac_pi/policy_loss    | -202.91147 |
| training/sac_pi/std            | 0.5010547  |
| training/sac_pi/valid_num      | 4959.0     |
| training/sac_Q/q1              | 189.85005  |
| training/sac_Q/q2              | 188.4834   |
| training/sac_Q/q2_loss         | 107.41577  |
| training/sac_Q/q_global_norm   | 246.00749  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16551705 |
| epoch                          | 597        |
| evaluation/episode-length-avg  | 137        |
| evaluation/episode-length-max  | 141        |
| evaluation/episode-length-min  | 135        |
| evaluation/episode-length-std  | 1.62       |
| evaluation/return-average      | 474.83643  |
| evaluation/return-max          | 488.91797  |
| evaluation/return-min          | 464.76862  |
| evaluation/return-std          | 6.1566052  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45832      |
| perf/AverageLength             | 137        |
| perf/AverageReturn             | 474.83643  |
| perf/NormalizedReturn          | 0.103      |
| Q-avg                          | 194.38246  |
| Q-std                          | 143.3173   |
| Q_loss                         | 100.893814 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 597        |
| times/epoch_after_hook         | 3.99e-06   |
| times/epoch_before_hook        | 0.000285   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000455   |
| times/evaluation_paths         | 4.16       |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00796    |
| times/train                    | 54.2       |
| timestep                       | 1000       |
| timesteps_total                | 598000     |
| train-steps                    | 598000     |
| training/Q/q1_loss             | 96.40885   |
| training/sac_pi/alpha          | 0.16552506 |
| training/sac_pi/alpha_loss     | 0.08290993 |
| training/sac_pi/logp_pi        | 6.08005    |
| training/sac_pi/pi_entropy     | 3.1118999  |
| training/sac_pi/pi_global_norm | 1.687789   |
| training/sac_pi/policy_loss    | -202.4792  |
| training/sac_pi/std            | 0.5051659  |
| training/sac_pi/valid_num      | 4894.0     |
| training/sac_Q/q1              | 176.97818  |
| training/sac_Q/q2              | 174.30626  |
| training/sac_Q/q2_loss         | 95.416695  |
| training/sac_Q/q_global_norm   | 223.86919  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16907603   |
| epoch                          | 598          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4935.11      |
| evaluation/return-max          | 4988.729     |
| evaluation/return-min          | 4833.199     |
| evaluation/return-std          | 53.155827    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.93         |
| model/origin_ret               | 83           |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45912        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4935.11      |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 199.91869    |
| Q-std                          | 124.39336    |
| Q_loss                         | 88.7137      |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 598          |
| times/epoch_after_hook         | 1.8e-06      |
| times/epoch_before_hook        | 6.11e-05     |
| times/epoch_rollout_model      | 494          |
| times/evaluation_metrics       | 0.000558     |
| times/evaluation_paths         | 31           |
| times/timestep_after_hook      | 0.00384      |
| times/timestep_before_hook     | 0.00802      |
| times/train                    | 55.3         |
| timestep                       | 1000         |
| timesteps_total                | 599000       |
| train-steps                    | 599000       |
| training/Q/q1_loss             | 101.3405     |
| training/sac_pi/alpha          | 0.16907421   |
| training/sac_pi/alpha_loss     | -0.052432045 |
| training/sac_pi/logp_pi        | 4.9454412    |
| training/sac_pi/pi_entropy     | 3.4841278    |
| training/sac_pi/pi_global_norm | 1.722796     |
| training/sac_pi/policy_loss    | -202.01408   |
| training/sac_pi/std            | 0.5248355    |
| training/sac_pi/valid_num      | 4932.0       |
| training/sac_Q/q1              | 182.16443    |
| training/sac_Q/q2              | 179.80795    |
| training/sac_Q/q2_loss         | 101.32471    |
| training/sac_Q/q_global_norm   | 187.42459    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16892353 |
| epoch                          | 599        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4619.517   |
| evaluation/return-max          | 4688.897   |
| evaluation/return-min          | 4571.288   |
| evaluation/return-std          | 35.69832   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45812      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4619.517   |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 181.22041  |
| Q-std                          | 179.79022  |
| Q_loss                         | 95.277275  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 599        |
| times/epoch_after_hook         | 1.99e-06   |
| times/epoch_before_hook        | 0.000186   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000712   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 56.5       |
| timestep                       | 1000       |
| timesteps_total                | 600000     |
| train-steps                    | 600000     |
| training/Q/q1_loss             | 111.07619  |
| training/sac_pi/alpha          | 0.16893382 |
| training/sac_pi/alpha_loss     | 0.1425676  |
| training/sac_pi/logp_pi        | 4.731035   |
| training/sac_pi/pi_entropy     | 3.6741226  |
| training/sac_pi/pi_global_norm | 1.6902179  |
| training/sac_pi/policy_loss    | -199.64333 |
| training/sac_pi/std            | 0.54557306 |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 176.51553  |
| training/sac_Q/q2              | 173.85196  |
| training/sac_Q/q2_loss         | 111.12514  |
| training/sac_Q/q_global_norm   | 218.36404  |
--------------------------------------------------------------------------------
[WARN] 600 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16852458 |
| epoch                          | 600        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4680.8     |
| evaluation/return-max          | 4753.908   |
| evaluation/return-min          | 4608.8545  |
| evaluation/return-std          | 44.760532  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45802      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4680.8     |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 184.19063  |
| Q-std                          | 168.4275   |
| Q_loss                         | 122.44762  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 600        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000549   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 54.4       |
| timestep                       | 1000       |
| timesteps_total                | 601000     |
| train-steps                    | 601000     |
| training/Q/q1_loss             | 104.43926  |
| training/sac_pi/alpha          | 0.1684914  |
| training/sac_pi/alpha_loss     | 0.22368859 |
| training/sac_pi/logp_pi        | 5.2752047  |
| training/sac_pi/pi_entropy     | 3.6178162  |
| training/sac_pi/pi_global_norm | 1.75416    |
| training/sac_pi/policy_loss    | -193.40125 |
| training/sac_pi/std            | 0.54380035 |
| training/sac_pi/valid_num      | 4865.0     |
| training/sac_Q/q1              | 166.45068  |
| training/sac_Q/q2              | 163.34622  |
| training/sac_Q/q2_loss         | 104.066246 |
| training/sac_Q/q_global_norm   | 231.3955   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16361542 |
| epoch                          | 601        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4885.6904  |
| evaluation/return-max          | 4939.316   |
| evaluation/return-min          | 4844.757   |
| evaluation/return-std          | 29.421503  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45761      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4885.6904  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 179.69919  |
| Q-std                          | 198.37396  |
| Q_loss                         | 111.21785  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 601        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000295   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000582   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 602000     |
| train-steps                    | 602000     |
| training/Q/q1_loss             | 125.71889  |
| training/sac_pi/alpha          | 0.16362984 |
| training/sac_pi/alpha_loss     | 0.39376104 |
| training/sac_pi/logp_pi        | 5.3182197  |
| training/sac_pi/pi_entropy     | 3.4736602  |
| training/sac_pi/pi_global_norm | 1.4893304  |
| training/sac_pi/policy_loss    | -195.56815 |
| training/sac_pi/std            | 0.5290763  |
| training/sac_pi/valid_num      | 4877.0     |
| training/sac_Q/q1              | 172.22173  |
| training/sac_Q/q2              | 170.67859  |
| training/sac_Q/q2_loss         | 126.02571  |
| training/sac_Q/q_global_norm   | 285.7563   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16507381  |
| epoch                          | 602         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4859.5366   |
| evaluation/return-max          | 4963.627    |
| evaluation/return-min          | 4789.3853   |
| evaluation/return-std          | 49.353764   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45766       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4859.5366   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 183.30733   |
| Q-std                          | 200.16824   |
| Q_loss                         | 97.441124   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 602         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000531    |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 56.1        |
| timestep                       | 1000        |
| timesteps_total                | 603000      |
| train-steps                    | 603000      |
| training/Q/q1_loss             | 107.794334  |
| training/sac_pi/alpha          | 0.16507421  |
| training/sac_pi/alpha_loss     | -0.09355715 |
| training/sac_pi/logp_pi        | 4.760467    |
| training/sac_pi/pi_entropy     | 3.4390616   |
| training/sac_pi/pi_global_norm | 1.4985311   |
| training/sac_pi/policy_loss    | -204.25356  |
| training/sac_pi/std            | 0.50870776  |
| training/sac_pi/valid_num      | 4893.0      |
| training/sac_Q/q1              | 182.87048   |
| training/sac_Q/q2              | 179.07254   |
| training/sac_Q/q2_loss         | 107.05798   |
| training/sac_Q/q_global_norm   | 200.85663   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16832851  |
| epoch                          | 603         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5126.048    |
| evaluation/return-max          | 5173.38     |
| evaluation/return-min          | 5001.419    |
| evaluation/return-std          | 54.55068    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 83.3        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45954       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5126.048    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 182.658     |
| Q-std                          | 227.09503   |
| Q_loss                         | 106.043755  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 603         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000105    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000533    |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00798     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 604000      |
| train-steps                    | 604000      |
| training/Q/q1_loss             | 100.424446  |
| training/sac_pi/alpha          | 0.16835874  |
| training/sac_pi/alpha_loss     | 0.012674839 |
| training/sac_pi/logp_pi        | 4.5215874   |
| training/sac_pi/pi_entropy     | 3.4996078   |
| training/sac_pi/pi_global_norm | 1.4923753   |
| training/sac_pi/policy_loss    | -202.60179  |
| training/sac_pi/std            | 0.5075726   |
| training/sac_pi/valid_num      | 4928.0      |
| training/sac_Q/q1              | 187.48573   |
| training/sac_Q/q2              | 183.166     |
| training/sac_Q/q2_loss         | 101.44439   |
| training/sac_Q/q_global_norm   | 211.15169   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16454068   |
| epoch                          | 604          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4821.3696    |
| evaluation/return-max          | 4856.4697    |
| evaluation/return-min          | 4794.595     |
| evaluation/return-std          | 15.346206    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.02         |
| model/origin_ret               | 85.2         |
| model/penalty_ret              | 81.4         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45877        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4821.3696    |
| perf/NormalizedReturn          | 1.05         |
| Q-avg                          | 192.65059    |
| Q-std                          | 154.6308     |
| Q_loss                         | 102.07397    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 604          |
| times/epoch_after_hook         | 1.86e-06     |
| times/epoch_before_hook        | 0.000103     |
| times/epoch_rollout_model      | 486          |
| times/evaluation_metrics       | 0.00055      |
| times/evaluation_paths         | 31.1         |
| times/timestep_after_hook      | 0.00379      |
| times/timestep_before_hook     | 0.0081       |
| times/train                    | 56.3         |
| timestep                       | 1000         |
| timesteps_total                | 605000       |
| train-steps                    | 605000       |
| training/Q/q1_loss             | 96.35648     |
| training/sac_pi/alpha          | 0.16451083   |
| training/sac_pi/alpha_loss     | -0.060850654 |
| training/sac_pi/logp_pi        | 3.572235     |
| training/sac_pi/pi_entropy     | 3.3922546    |
| training/sac_pi/pi_global_norm | 1.9286354    |
| training/sac_pi/policy_loss    | -205.72543   |
| training/sac_pi/std            | 0.467676     |
| training/sac_pi/valid_num      | 5024.0       |
| training/sac_Q/q1              | 198.49849    |
| training/sac_Q/q2              | 198.5662     |
| training/sac_Q/q2_loss         | 96.96861     |
| training/sac_Q/q_global_norm   | 225.82494    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16470394   |
| epoch                          | 605          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5114.293     |
| evaluation/return-max          | 5176.115     |
| evaluation/return-min          | 5072.664     |
| evaluation/return-std          | 32.42133     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.92         |
| model/origin_ret               | 84.1         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45800        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5114.293     |
| perf/NormalizedReturn          | 1.11         |
| Q-avg                          | 200.00302    |
| Q-std                          | 133.39372    |
| Q_loss                         | 80.82858     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 605          |
| times/epoch_after_hook         | 1.78e-06     |
| times/epoch_before_hook        | 0.000288     |
| times/epoch_rollout_model      | 486          |
| times/evaluation_metrics       | 0.000666     |
| times/evaluation_paths         | 30.7         |
| times/timestep_after_hook      | 0.00376      |
| times/timestep_before_hook     | 0.00809      |
| times/train                    | 56.4         |
| timestep                       | 1000         |
| timesteps_total                | 606000       |
| train-steps                    | 606000       |
| training/Q/q1_loss             | 84.89456     |
| training/sac_pi/alpha          | 0.1647266    |
| training/sac_pi/alpha_loss     | -0.006299506 |
| training/sac_pi/logp_pi        | 4.3827696    |
| training/sac_pi/pi_entropy     | 3.2038906    |
| training/sac_pi/pi_global_norm | 1.3580114    |
| training/sac_pi/policy_loss    | -212.23137   |
| training/sac_pi/std            | 0.48629287   |
| training/sac_pi/valid_num      | 5007.0       |
| training/sac_Q/q1              | 197.5077     |
| training/sac_Q/q2              | 193.34895    |
| training/sac_Q/q2_loss         | 85.383125    |
| training/sac_Q/q_global_norm   | 221.25311    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16514459 |
| epoch                          | 606        |
| evaluation/episode-length-avg  | 778        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 402        |
| evaluation/episode-length-std  | 260        |
| evaluation/return-average      | 3496.5793  |
| evaluation/return-max          | 4690.233   |
| evaluation/return-min          | 1568.6924  |
| evaluation/return-std          | 1339.5552  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46039      |
| perf/AverageLength             | 778        |
| perf/AverageReturn             | 3496.5793  |
| perf/NormalizedReturn          | 0.761      |
| Q-avg                          | 186.5835   |
| Q-std                          | 188.0105   |
| Q_loss                         | 99.21424   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 606        |
| times/epoch_after_hook         | 1.97e-06   |
| times/epoch_before_hook        | 0.000115   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000579   |
| times/evaluation_paths         | 24.3       |
| times/timestep_after_hook      | 0.00375    |
| times/timestep_before_hook     | 0.008      |
| times/train                    | 56.1       |
| timestep                       | 1000       |
| timesteps_total                | 607000     |
| train-steps                    | 607000     |
| training/Q/q1_loss             | 84.85276   |
| training/sac_pi/alpha          | 0.16511008 |
| training/sac_pi/alpha_loss     | 0.62045765 |
| training/sac_pi/logp_pi        | 5.4072027  |
| training/sac_pi/pi_entropy     | 3.4359794  |
| training/sac_pi/pi_global_norm | 1.6421261  |
| training/sac_pi/policy_loss    | -200.75618 |
| training/sac_pi/std            | 0.54517096 |
| training/sac_pi/valid_num      | 4850.0     |
| training/sac_Q/q1              | 180.49501  |
| training/sac_Q/q2              | 178.7432   |
| training/sac_Q/q2_loss         | 86.82055   |
| training/sac_Q/q_global_norm   | 182.26495  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16946098  |
| epoch                          | 607         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4878.377    |
| evaluation/return-max          | 4899.2334   |
| evaluation/return-min          | 4853.963    |
| evaluation/return-std          | 14.148329   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45747       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4878.377    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 188.81247   |
| Q-std                          | 193.81732   |
| Q_loss                         | 97.08698    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 607         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.00067     |
| times/evaluation_paths         | 30.4        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00771     |
| times/train                    | 55.9        |
| timestep                       | 1000        |
| timesteps_total                | 608000      |
| train-steps                    | 608000      |
| training/Q/q1_loss             | 98.70676    |
| training/sac_pi/alpha          | 0.16943356  |
| training/sac_pi/alpha_loss     | -0.08766606 |
| training/sac_pi/logp_pi        | 3.9760406   |
| training/sac_pi/pi_entropy     | 3.388948    |
| training/sac_pi/pi_global_norm | 1.4641219   |
| training/sac_pi/policy_loss    | -208.83998  |
| training/sac_pi/std            | 0.48124903  |
| training/sac_pi/valid_num      | 5033.0      |
| training/sac_Q/q1              | 200.77258   |
| training/sac_Q/q2              | 196.79056   |
| training/sac_Q/q2_loss         | 98.95079    |
| training/sac_Q/q_global_norm   | 229.10529   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16621152 |
| epoch                          | 608        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4855.2295  |
| evaluation/return-max          | 4885.4062  |
| evaluation/return-min          | 4804.6885  |
| evaluation/return-std          | 24.56267   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45712      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4855.2295  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 189.90523  |
| Q-std                          | 169.94849  |
| Q_loss                         | 96.35758   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 608        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000573   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.0078     |
| times/train                    | 56.1       |
| timestep                       | 1000       |
| timesteps_total                | 609000     |
| train-steps                    | 609000     |
| training/Q/q1_loss             | 91.0178    |
| training/sac_pi/alpha          | 0.16621925 |
| training/sac_pi/alpha_loss     | 0.21929714 |
| training/sac_pi/logp_pi        | 5.125318   |
| training/sac_pi/pi_entropy     | 3.3777452  |
| training/sac_pi/pi_global_norm | 1.6407503  |
| training/sac_pi/policy_loss    | -210.23563 |
| training/sac_pi/std            | 0.51731795 |
| training/sac_pi/valid_num      | 4895.0     |
| training/sac_Q/q1              | 189.57246  |
| training/sac_Q/q2              | 186.57166  |
| training/sac_Q/q2_loss         | 90.89457   |
| training/sac_Q/q_global_norm   | 194.39331  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16486037  |
| epoch                          | 609         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4592.6055   |
| evaluation/return-max          | 4683.8945   |
| evaluation/return-min          | 4485.8096   |
| evaluation/return-std          | 70.1968     |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45968       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4592.6055   |
| perf/NormalizedReturn          | 1           |
| Q-avg                          | 192.11174   |
| Q-std                          | 155.32208   |
| Q_loss                         | 121.0658    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 609         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000286    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000543    |
| times/evaluation_paths         | 31.4        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 57.2        |
| timestep                       | 1000        |
| timesteps_total                | 610000      |
| train-steps                    | 610000      |
| training/Q/q1_loss             | 96.746254   |
| training/sac_pi/alpha          | 0.16484965  |
| training/sac_pi/alpha_loss     | -0.09384289 |
| training/sac_pi/logp_pi        | 4.590693    |
| training/sac_pi/pi_entropy     | 3.2142386   |
| training/sac_pi/pi_global_norm | 1.7362977   |
| training/sac_pi/policy_loss    | -209.59706  |
| training/sac_pi/std            | 0.48386633  |
| training/sac_pi/valid_num      | 5007.0      |
| training/sac_Q/q1              | 196.26236   |
| training/sac_Q/q2              | 195.78262   |
| training/sac_Q/q2_loss         | 96.64125    |
| training/sac_Q/q_global_norm   | 171.94925   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16632481 |
| epoch                          | 610        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5010.795   |
| evaluation/return-max          | 5106.0684  |
| evaluation/return-min          | 4730.0586  |
| evaluation/return-std          | 127.542496 |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45878      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5010.795   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 180.8705   |
| Q-std                          | 224.68187  |
| Q_loss                         | 100.40096  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 610        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000661   |
| times/evaluation_paths         | 32.1       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00806    |
| times/train                    | 55.3       |
| timestep                       | 1000       |
| timesteps_total                | 611000     |
| train-steps                    | 611000     |
| training/Q/q1_loss             | 102.92619  |
| training/sac_pi/alpha          | 0.16632111 |
| training/sac_pi/alpha_loss     | 0.18429334 |
| training/sac_pi/logp_pi        | 4.8696837  |
| training/sac_pi/pi_entropy     | 3.440991   |
| training/sac_pi/pi_global_norm | 1.5604746  |
| training/sac_pi/policy_loss    | -206.40367 |
| training/sac_pi/std            | 0.51768845 |
| training/sac_pi/valid_num      | 4932.0     |
| training/sac_Q/q1              | 188.57915  |
| training/sac_Q/q2              | 186.8508   |
| training/sac_Q/q2_loss         | 100.74836  |
| training/sac_Q/q_global_norm   | 170.74461  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16642277 |
| epoch                          | 611        |
| evaluation/episode-length-avg  | 666        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 161        |
| evaluation/episode-length-std  | 409        |
| evaluation/return-average      | 3278.3784  |
| evaluation/return-max          | 5169.8604  |
| evaluation/return-min          | 476.20575  |
| evaluation/return-std          | 2275.805   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45875      |
| perf/AverageLength             | 666        |
| perf/AverageReturn             | 3278.3784  |
| perf/NormalizedReturn          | 0.714      |
| Q-avg                          | 183.24245  |
| Q-std                          | 179.39359  |
| Q_loss                         | 129.92218  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 611        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000141   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000491   |
| times/evaluation_paths         | 20.8       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00802    |
| times/train                    | 55.4       |
| timestep                       | 1000       |
| timesteps_total                | 612000     |
| train-steps                    | 612000     |
| training/Q/q1_loss             | 87.5365    |
| training/sac_pi/alpha          | 0.16643669 |
| training/sac_pi/alpha_loss     | 0.15542711 |
| training/sac_pi/logp_pi        | 3.899987   |
| training/sac_pi/pi_entropy     | 3.5206764  |
| training/sac_pi/pi_global_norm | 1.7467225  |
| training/sac_pi/policy_loss    | -210.63736 |
| training/sac_pi/std            | 0.4909611  |
| training/sac_pi/valid_num      | 4983.0     |
| training/sac_Q/q1              | 200.34557  |
| training/sac_Q/q2              | 199.45917  |
| training/sac_Q/q2_loss         | 86.86884   |
| training/sac_Q/q_global_norm   | 159.52917  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16523886 |
| epoch                          | 612        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4545.213   |
| evaluation/return-max          | 4693.21    |
| evaluation/return-min          | 4415.802   |
| evaluation/return-std          | 76.36359   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45820      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4545.213   |
| perf/NormalizedReturn          | 0.99       |
| Q-avg                          | 193.01738  |
| Q-std                          | 159.61852  |
| Q_loss                         | 86.888954  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 612        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000108   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000529   |
| times/evaluation_paths         | 32.3       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 57.9       |
| timestep                       | 1000       |
| timesteps_total                | 613000     |
| train-steps                    | 613000     |
| training/Q/q1_loss             | 96.06097   |
| training/sac_pi/alpha          | 0.16525027 |
| training/sac_pi/alpha_loss     | 0.06794049 |
| training/sac_pi/logp_pi        | 4.97381    |
| training/sac_pi/pi_entropy     | 3.351738   |
| training/sac_pi/pi_global_norm | 1.4928524  |
| training/sac_pi/policy_loss    | -203.52606 |
| training/sac_pi/std            | 0.5190626  |
| training/sac_pi/valid_num      | 4942.0     |
| training/sac_Q/q1              | 182.95512  |
| training/sac_Q/q2              | 179.86325  |
| training/sac_Q/q2_loss         | 95.95912   |
| training/sac_Q/q_global_norm   | 220.69485  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16978538 |
| epoch                          | 613        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5042.959   |
| evaluation/return-max          | 5075.0986  |
| evaluation/return-min          | 4999.633   |
| evaluation/return-std          | 21.252018  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45816      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5042.959   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 188.11765  |
| Q-std                          | 201.7448   |
| Q_loss                         | 119.4509   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 613        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000282   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000664   |
| times/evaluation_paths         | 31.7       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00793    |
| times/train                    | 56.8       |
| timestep                       | 1000       |
| timesteps_total                | 614000     |
| train-steps                    | 614000     |
| training/Q/q1_loss             | 89.97589   |
| training/sac_pi/alpha          | 0.16980477 |
| training/sac_pi/alpha_loss     | 0.02560057 |
| training/sac_pi/logp_pi        | 5.2191176  |
| training/sac_pi/pi_entropy     | 3.4703605  |
| training/sac_pi/pi_global_norm | 1.4696145  |
| training/sac_pi/policy_loss    | -207.35168 |
| training/sac_pi/std            | 0.5328039  |
| training/sac_pi/valid_num      | 4916.0     |
| training/sac_Q/q1              | 183.90567  |
| training/sac_Q/q2              | 179.82108  |
| training/sac_Q/q2_loss         | 90.457985  |
| training/sac_Q/q_global_norm   | 182.53416  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16868213  |
| epoch                          | 614         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4948.1475   |
| evaluation/return-max          | 5006.962    |
| evaluation/return-min          | 4869.628    |
| evaluation/return-std          | 42.339237   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45833       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4948.1475   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 163.66699   |
| Q-std                          | 264.2571    |
| Q_loss                         | 106.55304   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 614         |
| times/epoch_after_hook         | 2.94e-06    |
| times/epoch_before_hook        | 0.00015     |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000552    |
| times/evaluation_paths         | 31.4        |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 58.5        |
| timestep                       | 1000        |
| timesteps_total                | 615000      |
| train-steps                    | 615000      |
| training/Q/q1_loss             | 112.548706  |
| training/sac_pi/alpha          | 0.168742    |
| training/sac_pi/alpha_loss     | -0.23883809 |
| training/sac_pi/logp_pi        | 4.4624186   |
| training/sac_pi/pi_entropy     | 3.697429    |
| training/sac_pi/pi_global_norm | 1.6961901   |
| training/sac_pi/policy_loss    | -199.27629  |
| training/sac_pi/std            | 0.5409068   |
| training/sac_pi/valid_num      | 4953.0      |
| training/sac_Q/q1              | 184.1679    |
| training/sac_Q/q2              | 180.45854   |
| training/sac_Q/q2_loss         | 111.70543   |
| training/sac_Q/q_global_norm   | 267.4058    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16974345 |
| epoch                          | 615        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4896.9746  |
| evaluation/return-max          | 4962.8525  |
| evaluation/return-min          | 4786.1943  |
| evaluation/return-std          | 51.418335  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45824      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4896.9746  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 189.29355  |
| Q-std                          | 179.32841  |
| Q_loss                         | 103.526886 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 615        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000202   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.00056    |
| times/evaluation_paths         | 30.6       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 56.6       |
| timestep                       | 1000       |
| timesteps_total                | 616000     |
| train-steps                    | 616000     |
| training/Q/q1_loss             | 89.55087   |
| training/sac_pi/alpha          | 0.16976893 |
| training/sac_pi/alpha_loss     | 0.0761082  |
| training/sac_pi/logp_pi        | 4.1459565  |
| training/sac_pi/pi_entropy     | 3.4915779  |
| training/sac_pi/pi_global_norm | 1.4621993  |
| training/sac_pi/policy_loss    | -200.18156 |
| training/sac_pi/std            | 0.49547157 |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 186.70198  |
| training/sac_Q/q2              | 186.59232  |
| training/sac_Q/q2_loss         | 88.93949   |
| training/sac_Q/q_global_norm   | 263.8096   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1679948    |
| epoch                          | 616          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4757.9663    |
| evaluation/return-max          | 4855.406     |
| evaluation/return-min          | 4648.0986    |
| evaluation/return-std          | 69.18495     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.96         |
| model/origin_ret               | 84.6         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45815        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4757.9663    |
| perf/NormalizedReturn          | 1.04         |
| Q-avg                          | 192.59485    |
| Q-std                          | 137.96799    |
| Q_loss                         | 94.38046     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 616          |
| times/epoch_after_hook         | 1.79e-06     |
| times/epoch_before_hook        | 0.000107     |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.000727     |
| times/evaluation_paths         | 31.8         |
| times/timestep_after_hook      | 0.00377      |
| times/timestep_before_hook     | 0.00814      |
| times/train                    | 56.5         |
| timestep                       | 1000         |
| timesteps_total                | 617000       |
| train-steps                    | 617000       |
| training/Q/q1_loss             | 101.098656   |
| training/sac_pi/alpha          | 0.1680046    |
| training/sac_pi/alpha_loss     | -0.088120244 |
| training/sac_pi/logp_pi        | 3.7300582    |
| training/sac_pi/pi_entropy     | 3.3424416    |
| training/sac_pi/pi_global_norm | 1.36999      |
| training/sac_pi/policy_loss    | -204.06511   |
| training/sac_pi/std            | 0.47062328   |
| training/sac_pi/valid_num      | 4982.0       |
| training/sac_Q/q1              | 195.2426     |
| training/sac_Q/q2              | 196.53166    |
| training/sac_Q/q2_loss         | 100.289665   |
| training/sac_Q/q_global_norm   | 212.19502    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17278334  |
| epoch                          | 617         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4993.032    |
| evaluation/return-max          | 5004.94     |
| evaluation/return-min          | 4968.2026   |
| evaluation/return-std          | 11.170516   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45993       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4993.032    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 186.7532    |
| Q-std                          | 181.62766   |
| Q_loss                         | 96.512115   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 617         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000327    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000544    |
| times/evaluation_paths         | 31.6        |
| times/timestep_after_hook      | 0.00387     |
| times/timestep_before_hook     | 0.00838     |
| times/train                    | 57.9        |
| timestep                       | 1000        |
| timesteps_total                | 618000      |
| train-steps                    | 618000      |
| training/Q/q1_loss             | 82.70118    |
| training/sac_pi/alpha          | 0.1727641   |
| training/sac_pi/alpha_loss     | -0.09089101 |
| training/sac_pi/logp_pi        | 3.8735662   |
| training/sac_pi/pi_entropy     | 3.4884446   |
| training/sac_pi/pi_global_norm | 1.3290116   |
| training/sac_pi/policy_loss    | -204.29056  |
| training/sac_pi/std            | 0.4881302   |
| training/sac_pi/valid_num      | 4973.0      |
| training/sac_Q/q1              | 194.16853   |
| training/sac_Q/q2              | 191.70126   |
| training/sac_Q/q2_loss         | 82.32374    |
| training/sac_Q/q_global_norm   | 210.08829   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17085344  |
| epoch                          | 618         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4951.1655   |
| evaluation/return-max          | 4988.0244   |
| evaluation/return-min          | 4904.9976   |
| evaluation/return-std          | 25.320292   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45797       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4951.1655   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 191.87976   |
| Q-std                          | 185.13412   |
| Q_loss                         | 89.58894    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 618         |
| times/epoch_after_hook         | 2.04e-06    |
| times/epoch_before_hook        | 0.000104    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000637    |
| times/evaluation_paths         | 32.1        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00798     |
| times/train                    | 56.7        |
| timestep                       | 1000        |
| timesteps_total                | 619000      |
| train-steps                    | 619000      |
| training/Q/q1_loss             | 84.49093    |
| training/sac_pi/alpha          | 0.17084864  |
| training/sac_pi/alpha_loss     | -0.13557163 |
| training/sac_pi/logp_pi        | 4.6096334   |
| training/sac_pi/pi_entropy     | 3.5868602   |
| training/sac_pi/pi_global_norm | 1.6693563   |
| training/sac_pi/policy_loss    | -212.69907  |
| training/sac_pi/std            | 0.55201274  |
| training/sac_pi/valid_num      | 4866.0      |
| training/sac_Q/q1              | 195.60062   |
| training/sac_Q/q2              | 193.42722   |
| training/sac_Q/q2_loss         | 84.3747     |
| training/sac_Q/q_global_norm   | 189.5132    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17023109 |
| epoch                          | 619        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4968.1265  |
| evaluation/return-max          | 5029.915   |
| evaluation/return-min          | 4927.08    |
| evaluation/return-std          | 29.96046   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45826      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4968.1265  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 181.41985  |
| Q-std                          | 219.00766  |
| Q_loss                         | 100.40183  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 619        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.00014    |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000542   |
| times/evaluation_paths         | 32.1       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 58.8       |
| timestep                       | 1000       |
| timesteps_total                | 620000     |
| train-steps                    | 620000     |
| training/Q/q1_loss             | 108.72196  |
| training/sac_pi/alpha          | 0.17020865 |
| training/sac_pi/alpha_loss     | 0.21736556 |
| training/sac_pi/logp_pi        | 5.326103   |
| training/sac_pi/pi_entropy     | 3.589265   |
| training/sac_pi/pi_global_norm | 1.4761842  |
| training/sac_pi/policy_loss    | -200.82947 |
| training/sac_pi/std            | 0.5629027  |
| training/sac_pi/valid_num      | 4922.0     |
| training/sac_Q/q1              | 174.79503  |
| training/sac_Q/q2              | 171.02907  |
| training/sac_Q/q2_loss         | 108.60854  |
| training/sac_Q/q_global_norm   | 276.52277  |
--------------------------------------------------------------------------------
[WARN] 620 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16735443 |
| epoch                          | 620        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5090.343   |
| evaluation/return-max          | 5147.8564  |
| evaluation/return-min          | 5015.1475  |
| evaluation/return-std          | 42.624565  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45916      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5090.343   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 202.48715  |
| Q-std                          | 144.64568  |
| Q_loss                         | 101.15365  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 620        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000102   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000657   |
| times/evaluation_paths         | 32.8       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00799    |
| times/train                    | 56.4       |
| timestep                       | 1000       |
| timesteps_total                | 621000     |
| train-steps                    | 621000     |
| training/Q/q1_loss             | 93.61616   |
| training/sac_pi/alpha          | 0.16734739 |
| training/sac_pi/alpha_loss     | 0.23544338 |
| training/sac_pi/logp_pi        | 4.0100813  |
| training/sac_pi/pi_entropy     | 3.4316006  |
| training/sac_pi/pi_global_norm | 1.6947148  |
| training/sac_pi/policy_loss    | -203.1111  |
| training/sac_pi/std            | 0.47752407 |
| training/sac_pi/valid_num      | 4999.0     |
| training/sac_Q/q1              | 192.5268   |
| training/sac_Q/q2              | 192.11667  |
| training/sac_Q/q2_loss         | 94.4466    |
| training/sac_Q/q_global_norm   | 211.38676  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17039515  |
| epoch                          | 621         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4794.6455   |
| evaluation/return-max          | 4899.7764   |
| evaluation/return-min          | 4348.96     |
| evaluation/return-std          | 163.73938   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45785       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4794.6455   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 193.97708   |
| Q-std                          | 200.43408   |
| Q_loss                         | 111.908005  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 621         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000281    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000642    |
| times/evaluation_paths         | 31.9        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00791     |
| times/train                    | 56.6        |
| timestep                       | 1000        |
| timesteps_total                | 622000      |
| train-steps                    | 622000      |
| training/Q/q1_loss             | 92.24195    |
| training/sac_pi/alpha          | 0.17035735  |
| training/sac_pi/alpha_loss     | 0.061499704 |
| training/sac_pi/logp_pi        | 4.766106    |
| training/sac_pi/pi_entropy     | 3.5222065   |
| training/sac_pi/pi_global_norm | 1.4010196   |
| training/sac_pi/policy_loss    | -206.83134  |
| training/sac_pi/std            | 0.52813345  |
| training/sac_pi/valid_num      | 4945.0      |
| training/sac_Q/q1              | 187.68515   |
| training/sac_Q/q2              | 186.34636   |
| training/sac_Q/q2_loss         | 93.36868    |
| training/sac_Q/q_global_norm   | 150.96748   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16860245  |
| epoch                          | 622         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4395.581    |
| evaluation/return-max          | 4530.3105   |
| evaluation/return-min          | 4352.5986   |
| evaluation/return-std          | 46.477695   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45863       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4395.581    |
| perf/NormalizedReturn          | 0.957       |
| Q-avg                          | 186.10672   |
| Q-std                          | 176.02985   |
| Q_loss                         | 108.347565  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 622         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000542    |
| times/evaluation_paths         | 31.4        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 623000      |
| train-steps                    | 623000      |
| training/Q/q1_loss             | 94.84079    |
| training/sac_pi/alpha          | 0.16856758  |
| training/sac_pi/alpha_loss     | 0.014938081 |
| training/sac_pi/logp_pi        | 4.6063      |
| training/sac_pi/pi_entropy     | 3.6389403   |
| training/sac_pi/pi_global_norm | 1.4455131   |
| training/sac_pi/policy_loss    | -207.62218  |
| training/sac_pi/std            | 0.5417244   |
| training/sac_pi/valid_num      | 4965.0      |
| training/sac_Q/q1              | 189.95735   |
| training/sac_Q/q2              | 186.81003   |
| training/sac_Q/q2_loss         | 95.46852    |
| training/sac_Q/q_global_norm   | 264.1517    |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17553893   |
| epoch                          | 623          |
| evaluation/episode-length-avg  | 915          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 147          |
| evaluation/episode-length-std  | 256          |
| evaluation/return-average      | 4473.489     |
| evaluation/return-max          | 4947.5464    |
| evaluation/return-min          | 470.6323     |
| evaluation/return-std          | 1334.4287    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.91         |
| model/origin_ret               | 83.9         |
| model/penalty_ret              | 81.8         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45818        |
| perf/AverageLength             | 915          |
| perf/AverageReturn             | 4473.489     |
| perf/NormalizedReturn          | 0.974        |
| Q-avg                          | 180.26695    |
| Q-std                          | 188.22128    |
| Q_loss                         | 85.33885     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 623          |
| times/epoch_after_hook         | 1.87e-06     |
| times/epoch_before_hook        | 0.000131     |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.000558     |
| times/evaluation_paths         | 27.9         |
| times/timestep_after_hook      | 0.00366      |
| times/timestep_before_hook     | 0.00813      |
| times/train                    | 56.2         |
| timestep                       | 1000         |
| timesteps_total                | 624000       |
| train-steps                    | 624000       |
| training/Q/q1_loss             | 97.448425    |
| training/sac_pi/alpha          | 0.1755172    |
| training/sac_pi/alpha_loss     | -0.036121853 |
| training/sac_pi/logp_pi        | 4.658431     |
| training/sac_pi/pi_entropy     | 3.7133198    |
| training/sac_pi/pi_global_norm | 1.7795404    |
| training/sac_pi/policy_loss    | -200.3765    |
| training/sac_pi/std            | 0.55632156   |
| training/sac_pi/valid_num      | 4971.0       |
| training/sac_Q/q1              | 187.57935    |
| training/sac_Q/q2              | 183.03363    |
| training/sac_Q/q2_loss         | 97.56712     |
| training/sac_Q/q_global_norm   | 294.91077    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17215405 |
| epoch                          | 624        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4888.1357  |
| evaluation/return-max          | 4979.783   |
| evaluation/return-min          | 4800.1655  |
| evaluation/return-std          | 62.216103  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45686      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4888.1357  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 187.55916  |
| Q-std                          | 161.04367  |
| Q_loss                         | 103.968376 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 624        |
| times/epoch_after_hook         | 3.58e-06   |
| times/epoch_before_hook        | 0.000154   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000536   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00791    |
| times/train                    | 56.4       |
| timestep                       | 1000       |
| timesteps_total                | 625000     |
| train-steps                    | 625000     |
| training/Q/q1_loss             | 94.339195  |
| training/sac_pi/alpha          | 0.17211169 |
| training/sac_pi/alpha_loss     | 0.36130944 |
| training/sac_pi/logp_pi        | 4.1815233  |
| training/sac_pi/pi_entropy     | 3.4482849  |
| training/sac_pi/pi_global_norm | 1.4980565  |
| training/sac_pi/policy_loss    | -209.2045  |
| training/sac_pi/std            | 0.48838827 |
| training/sac_pi/valid_num      | 4994.0     |
| training/sac_Q/q1              | 197.05658  |
| training/sac_Q/q2              | 195.70346  |
| training/sac_Q/q2_loss         | 93.66921   |
| training/sac_Q/q_global_norm   | 241.16386  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17058527 |
| epoch                          | 625        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4933.9287  |
| evaluation/return-max          | 4983.867   |
| evaluation/return-min          | 4853.7905  |
| evaluation/return-std          | 36.441475  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45816      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4933.9287  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 184.74947  |
| Q-std                          | 170.01651  |
| Q_loss                         | 103.35459  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 625        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000281   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000529   |
| times/evaluation_paths         | 32.5       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00801    |
| times/train                    | 56.2       |
| timestep                       | 1000       |
| timesteps_total                | 626000     |
| train-steps                    | 626000     |
| training/Q/q1_loss             | 103.87219  |
| training/sac_pi/alpha          | 0.1705844  |
| training/sac_pi/alpha_loss     | 0.10575821 |
| training/sac_pi/logp_pi        | 5.577707   |
| training/sac_pi/pi_entropy     | 3.7234752  |
| training/sac_pi/pi_global_norm | 1.3652889  |
| training/sac_pi/policy_loss    | -198.54973 |
| training/sac_pi/std            | 0.58753914 |
| training/sac_pi/valid_num      | 4848.0     |
| training/sac_Q/q1              | 169.65742  |
| training/sac_Q/q2              | 166.60428  |
| training/sac_Q/q2_loss         | 103.86933  |
| training/sac_Q/q_global_norm   | 230.91951  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16789103  |
| epoch                          | 626         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4770.673    |
| evaluation/return-max          | 4803.464    |
| evaluation/return-min          | 4707.2363   |
| evaluation/return-std          | 28.839464   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45810       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4770.673    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 198.22751   |
| Q-std                          | 119.59198   |
| Q_loss                         | 116.132454  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 626         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000107    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000522    |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00796     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 627000      |
| train-steps                    | 627000      |
| training/Q/q1_loss             | 86.13248    |
| training/sac_pi/alpha          | 0.1678886   |
| training/sac_pi/alpha_loss     | -0.12511778 |
| training/sac_pi/logp_pi        | 3.6466897   |
| training/sac_pi/pi_entropy     | 3.3898826   |
| training/sac_pi/pi_global_norm | 1.7454804   |
| training/sac_pi/policy_loss    | -207.79326  |
| training/sac_pi/std            | 0.47206178  |
| training/sac_pi/valid_num      | 5000.0      |
| training/sac_Q/q1              | 201.0912    |
| training/sac_Q/q2              | 199.7653    |
| training/sac_Q/q2_loss         | 87.074936   |
| training/sac_Q/q_global_norm   | 204.99554   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17393456 |
| epoch                          | 627        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4285.901   |
| evaluation/return-max          | 4547.3257  |
| evaluation/return-min          | 4177.8516  |
| evaluation/return-std          | 104.48196  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45773      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4285.901   |
| perf/NormalizedReturn          | 0.933      |
| Q-avg                          | 194.25021  |
| Q-std                          | 172.40356  |
| Q_loss                         | 100.56419  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 627        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000541   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00784    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 628000     |
| train-steps                    | 628000     |
| training/Q/q1_loss             | 92.008896  |
| training/sac_pi/alpha          | 0.17395106 |
| training/sac_pi/alpha_loss     | 0.07782623 |
| training/sac_pi/logp_pi        | 4.2675743  |
| training/sac_pi/pi_entropy     | 3.4626737  |
| training/sac_pi/pi_global_norm | 1.7275946  |
| training/sac_pi/policy_loss    | -201.13031 |
| training/sac_pi/std            | 0.49652347 |
| training/sac_pi/valid_num      | 4934.0     |
| training/sac_Q/q1              | 184.93523  |
| training/sac_Q/q2              | 182.52647  |
| training/sac_Q/q2_loss         | 92.40926   |
| training/sac_Q/q_global_norm   | 189.21951  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17031212  |
| epoch                          | 628         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4842.4995   |
| evaluation/return-max          | 4935.6104   |
| evaluation/return-min          | 4754.9326   |
| evaluation/return-std          | 49.601856   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45945       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4842.4995   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 203.97044   |
| Q-std                          | 120.358246  |
| Q_loss                         | 88.93893    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 628         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000104    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000522    |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00791     |
| times/train                    | 55.9        |
| timestep                       | 1000        |
| timesteps_total                | 629000      |
| train-steps                    | 629000      |
| training/Q/q1_loss             | 87.090096   |
| training/sac_pi/alpha          | 0.1703346   |
| training/sac_pi/alpha_loss     | -0.13458645 |
| training/sac_pi/logp_pi        | 4.0233717   |
| training/sac_pi/pi_entropy     | 3.5540147   |
| training/sac_pi/pi_global_norm | 1.9974442   |
| training/sac_pi/policy_loss    | -205.05373  |
| training/sac_pi/std            | 0.50423914  |
| training/sac_pi/valid_num      | 4959.0      |
| training/sac_Q/q1              | 191.18279   |
| training/sac_Q/q2              | 187.4322    |
| training/sac_Q/q2_loss         | 87.45968    |
| training/sac_Q/q_global_norm   | 188.74547   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17064223  |
| epoch                          | 629         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4870.258    |
| evaluation/return-max          | 4887.8096   |
| evaluation/return-min          | 4827.0293   |
| evaluation/return-std          | 17.029202   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45922       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4870.258    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 192.60767   |
| Q-std                          | 151.19492   |
| Q_loss                         | 91.70363    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 629         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000368    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00803     |
| times/train                    | 56.6        |
| timestep                       | 1000        |
| timesteps_total                | 630000      |
| train-steps                    | 630000      |
| training/Q/q1_loss             | 95.299805   |
| training/sac_pi/alpha          | 0.17060955  |
| training/sac_pi/alpha_loss     | -0.15120666 |
| training/sac_pi/logp_pi        | 4.6010313   |
| training/sac_pi/pi_entropy     | 3.7705467   |
| training/sac_pi/pi_global_norm | 2.1831713   |
| training/sac_pi/policy_loss    | -201.37503  |
| training/sac_pi/std            | 0.5433129   |
| training/sac_pi/valid_num      | 4917.0      |
| training/sac_Q/q1              | 182.95343   |
| training/sac_Q/q2              | 182.30087   |
| training/sac_Q/q2_loss         | 95.39481    |
| training/sac_Q/q_global_norm   | 212.50255   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1725718  |
| epoch                          | 630        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4958.7617  |
| evaluation/return-max          | 5017.8584  |
| evaluation/return-min          | 4921.5557  |
| evaluation/return-std          | 29.65996   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45674      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4958.7617  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 185.02214  |
| Q-std                          | 163.2971   |
| Q_loss                         | 107.266594 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 630        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000526   |
| times/evaluation_paths         | 32.4       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 57.2       |
| timestep                       | 1000       |
| timesteps_total                | 631000     |
| train-steps                    | 631000     |
| training/Q/q1_loss             | 86.29321   |
| training/sac_pi/alpha          | 0.1725577  |
| training/sac_pi/alpha_loss     | 0.03760561 |
| training/sac_pi/logp_pi        | 4.034995   |
| training/sac_pi/pi_entropy     | 3.5800147  |
| training/sac_pi/pi_global_norm | 1.7410424  |
| training/sac_pi/policy_loss    | -205.99559 |
| training/sac_pi/std            | 0.5018054  |
| training/sac_pi/valid_num      | 5019.0     |
| training/sac_Q/q1              | 196.67747  |
| training/sac_Q/q2              | 196.95251  |
| training/sac_Q/q2_loss         | 85.869774  |
| training/sac_Q/q_global_norm   | 217.81432  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1680794  |
| epoch                          | 631        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5044.5146  |
| evaluation/return-max          | 5136.553   |
| evaluation/return-min          | 4957.378   |
| evaluation/return-std          | 61.238796  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45701      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5044.5146  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 197.19629  |
| Q-std                          | 164.48418  |
| Q_loss                         | 105.88211  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 631        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000102   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000578   |
| times/evaluation_paths         | 31.2       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00795    |
| times/train                    | 56         |
| timestep                       | 1000       |
| timesteps_total                | 632000     |
| train-steps                    | 632000     |
| training/Q/q1_loss             | 114.45086  |
| training/sac_pi/alpha          | 0.16810143 |
| training/sac_pi/alpha_loss     | -0.3243383 |
| training/sac_pi/logp_pi        | 4.65489    |
| training/sac_pi/pi_entropy     | 3.4025369  |
| training/sac_pi/pi_global_norm | 1.6142105  |
| training/sac_pi/policy_loss    | -210.74458 |
| training/sac_pi/std            | 0.5155164  |
| training/sac_pi/valid_num      | 4936.0     |
| training/sac_Q/q1              | 189.2582   |
| training/sac_Q/q2              | 187.00577  |
| training/sac_Q/q2_loss         | 114.81283  |
| training/sac_Q/q_global_norm   | 232.71909  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16863275 |
| epoch                          | 632        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4869.728   |
| evaluation/return-max          | 4892.003   |
| evaluation/return-min          | 4828.376   |
| evaluation/return-std          | 18.298197  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45666      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4869.728   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 176.42307  |
| Q-std                          | 188.16872  |
| Q_loss                         | 96.9932    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 632        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 9.9e-05    |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000634   |
| times/evaluation_paths         | 31.5       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00796    |
| times/train                    | 55.4       |
| timestep                       | 1000       |
| timesteps_total                | 633000     |
| train-steps                    | 633000     |
| training/Q/q1_loss             | 95.031876  |
| training/sac_pi/alpha          | 0.1686525  |
| training/sac_pi/alpha_loss     | 0.15740745 |
| training/sac_pi/logp_pi        | 4.878577   |
| training/sac_pi/pi_entropy     | 3.283863   |
| training/sac_pi/pi_global_norm | 1.6831719  |
| training/sac_pi/policy_loss    | -211.55896 |
| training/sac_pi/std            | 0.506768   |
| training/sac_pi/valid_num      | 4944.0     |
| training/sac_Q/q1              | 192.32024  |
| training/sac_Q/q2              | 192.5672   |
| training/sac_Q/q2_loss         | 95.54685   |
| training/sac_Q/q_global_norm   | 204.16423  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16631332  |
| epoch                          | 633         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4820.874    |
| evaluation/return-max          | 4849.6665   |
| evaluation/return-min          | 4791.9336   |
| evaluation/return-std          | 17.374422   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 83.6        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45771       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4820.874    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 189.20764   |
| Q-std                          | 179.51189   |
| Q_loss                         | 100.39805   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 633         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000332    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000559    |
| times/evaluation_paths         | 30.6        |
| times/timestep_after_hook      | 0.00355     |
| times/timestep_before_hook     | 0.00785     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 634000      |
| train-steps                    | 634000      |
| training/Q/q1_loss             | 90.27206    |
| training/sac_pi/alpha          | 0.16632834  |
| training/sac_pi/alpha_loss     | -0.03580816 |
| training/sac_pi/logp_pi        | 4.1730833   |
| training/sac_pi/pi_entropy     | 3.372663    |
| training/sac_pi/pi_global_norm | 1.5343701   |
| training/sac_pi/policy_loss    | -214.29024  |
| training/sac_pi/std            | 0.4907779   |
| training/sac_pi/valid_num      | 4993.0      |
| training/sac_Q/q1              | 202.59969   |
| training/sac_Q/q2              | 201.75005   |
| training/sac_Q/q2_loss         | 90.67471    |
| training/sac_Q/q_global_norm   | 190.21852   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16298985   |
| epoch                          | 634          |
| evaluation/episode-length-avg  | 323          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 151          |
| evaluation/episode-length-std  | 339          |
| evaluation/return-average      | 1416.1086    |
| evaluation/return-max          | 5208.0703    |
| evaluation/return-min          | 450.4103     |
| evaluation/return-std          | 1886.1069    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.96         |
| model/origin_ret               | 84.9         |
| model/penalty_ret              | 81.4         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45883        |
| perf/AverageLength             | 323          |
| perf/AverageReturn             | 1416.1086    |
| perf/NormalizedReturn          | 0.308        |
| Q-avg                          | 163.11905    |
| Q-std                          | 252.67552    |
| Q_loss                         | 114.47744    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 634          |
| times/epoch_after_hook         | 1.91e-06     |
| times/epoch_before_hook        | 0.000103     |
| times/epoch_rollout_model      | 481          |
| times/evaluation_metrics       | 0.000477     |
| times/evaluation_paths         | 9.96         |
| times/timestep_after_hook      | 0.00354      |
| times/timestep_before_hook     | 0.00781      |
| times/train                    | 55.6         |
| timestep                       | 1000         |
| timesteps_total                | 635000       |
| train-steps                    | 635000       |
| training/Q/q1_loss             | 82.793205    |
| training/sac_pi/alpha          | 0.1629943    |
| training/sac_pi/alpha_loss     | -0.039354768 |
| training/sac_pi/logp_pi        | 4.178324     |
| training/sac_pi/pi_entropy     | 3.2506256    |
| training/sac_pi/pi_global_norm | 1.4156939    |
| training/sac_pi/policy_loss    | -212.72345   |
| training/sac_pi/std            | 0.48719418   |
| training/sac_pi/valid_num      | 4967.0       |
| training/sac_Q/q1              | 197.43333    |
| training/sac_Q/q2              | 197.08957    |
| training/sac_Q/q2_loss         | 82.48627     |
| training/sac_Q/q_global_norm   | 154.90031    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16776517  |
| epoch                          | 635         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4850.2305   |
| evaluation/return-max          | 4884.3447   |
| evaluation/return-min          | 4804.2324   |
| evaluation/return-std          | 24.368746   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45896       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4850.2305   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 186.21063   |
| Q-std                          | 211.91142   |
| Q_loss                         | 93.308044   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 635         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000538    |
| times/evaluation_paths         | 30.1        |
| times/timestep_after_hook      | 0.00354     |
| times/timestep_before_hook     | 0.00777     |
| times/train                    | 56          |
| timestep                       | 1000        |
| timesteps_total                | 636000      |
| train-steps                    | 636000      |
| training/Q/q1_loss             | 117.50743   |
| training/sac_pi/alpha          | 0.16780671  |
| training/sac_pi/alpha_loss     | -0.35360652 |
| training/sac_pi/logp_pi        | 4.5254655   |
| training/sac_pi/pi_entropy     | 3.5058866   |
| training/sac_pi/pi_global_norm | 1.5530232   |
| training/sac_pi/policy_loss    | -207.17818  |
| training/sac_pi/std            | 0.52298814  |
| training/sac_pi/valid_num      | 4918.0      |
| training/sac_Q/q1              | 182.67545   |
| training/sac_Q/q2              | 177.06436   |
| training/sac_Q/q2_loss         | 116.127754  |
| training/sac_Q/q_global_norm   | 257.4383    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16490085 |
| epoch                          | 636        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5121.11    |
| evaluation/return-max          | 5180.7476  |
| evaluation/return-min          | 5070.4355  |
| evaluation/return-std          | 40.344826  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45775      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5121.11    |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 181.92447  |
| Q-std                          | 176.06627  |
| Q_loss                         | 118.36975  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 636        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.00011    |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000616   |
| times/evaluation_paths         | 31.4       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00789    |
| times/train                    | 56         |
| timestep                       | 1000       |
| timesteps_total                | 637000     |
| train-steps                    | 637000     |
| training/Q/q1_loss             | 81.37003   |
| training/sac_pi/alpha          | 0.1648734  |
| training/sac_pi/alpha_loss     | 0.09097863 |
| training/sac_pi/logp_pi        | 4.812894   |
| training/sac_pi/pi_entropy     | 3.2500267  |
| training/sac_pi/pi_global_norm | 1.6959617  |
| training/sac_pi/policy_loss    | -206.81694 |
| training/sac_pi/std            | 0.49009764 |
| training/sac_pi/valid_num      | 4942.0     |
| training/sac_Q/q1              | 192.54321  |
| training/sac_Q/q2              | 191.85825  |
| training/sac_Q/q2_loss         | 80.60671   |
| training/sac_Q/q_global_norm   | 236.31712  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16601     |
| epoch                          | 637         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4717.7744   |
| evaluation/return-max          | 4827.4385   |
| evaluation/return-min          | 4663.4805   |
| evaluation/return-std          | 43.566845   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45698       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4717.7744   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 182.80887   |
| Q-std                          | 165.24127   |
| Q_loss                         | 101.174416  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 637         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000318    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000528    |
| times/evaluation_paths         | 31.4        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00763     |
| times/train                    | 56.4        |
| timestep                       | 1000        |
| timesteps_total                | 638000      |
| train-steps                    | 638000      |
| training/Q/q1_loss             | 121.554855  |
| training/sac_pi/alpha          | 0.1660018   |
| training/sac_pi/alpha_loss     | 0.030412098 |
| training/sac_pi/logp_pi        | 4.8058867   |
| training/sac_pi/pi_entropy     | 3.3392227   |
| training/sac_pi/pi_global_norm | 1.7976243   |
| training/sac_pi/policy_loss    | -202.04417  |
| training/sac_pi/std            | 0.50842804  |
| training/sac_pi/valid_num      | 4929.0      |
| training/sac_Q/q1              | 184.74576   |
| training/sac_Q/q2              | 182.51312   |
| training/sac_Q/q2_loss         | 121.10548   |
| training/sac_Q/q_global_norm   | 201.56184   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16218646   |
| epoch                          | 638          |
| evaluation/episode-length-avg  | 830          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 152          |
| evaluation/episode-length-std  | 339          |
| evaluation/return-average      | 3894.1277    |
| evaluation/return-max          | 4807.551     |
| evaluation/return-min          | 439.54657    |
| evaluation/return-std          | 1727.266     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.86         |
| model/origin_ret               | 83.4         |
| model/penalty_ret              | 81.8         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45786        |
| perf/AverageLength             | 830          |
| perf/AverageReturn             | 3894.1277    |
| perf/NormalizedReturn          | 0.848        |
| Q-avg                          | 181.25618    |
| Q-std                          | 237.43349    |
| Q_loss                         | 104.8315     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 638          |
| times/epoch_after_hook         | 1.78e-06     |
| times/epoch_before_hook        | 0.000102     |
| times/epoch_rollout_model      | 481          |
| times/evaluation_metrics       | 0.000585     |
| times/evaluation_paths         | 27.2         |
| times/timestep_after_hook      | 0.0039       |
| times/timestep_before_hook     | 0.008        |
| times/train                    | 57.3         |
| timestep                       | 1000         |
| timesteps_total                | 639000       |
| train-steps                    | 639000       |
| training/Q/q1_loss             | 91.619385    |
| training/sac_pi/alpha          | 0.1622195    |
| training/sac_pi/alpha_loss     | -0.037886806 |
| training/sac_pi/logp_pi        | 4.581008     |
| training/sac_pi/pi_entropy     | 3.4741604    |
| training/sac_pi/pi_global_norm | 1.4806569    |
| training/sac_pi/policy_loss    | -206.24721   |
| training/sac_pi/std            | 0.5251183    |
| training/sac_pi/valid_num      | 4953.0       |
| training/sac_Q/q1              | 188.499      |
| training/sac_Q/q2              | 186.39798    |
| training/sac_Q/q2_loss         | 91.67699     |
| training/sac_Q/q_global_norm   | 237.53728    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1660711  |
| epoch                          | 639        |
| evaluation/episode-length-avg  | 133        |
| evaluation/episode-length-max  | 142        |
| evaluation/episode-length-min  | 124        |
| evaluation/episode-length-std  | 6.29       |
| evaluation/return-average      | 398.01413  |
| evaluation/return-max          | 427.42215  |
| evaluation/return-min          | 357.15057  |
| evaluation/return-std          | 24.126026  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45786      |
| perf/AverageLength             | 133        |
| perf/AverageReturn             | 398.01413  |
| perf/NormalizedReturn          | 0.0863     |
| Q-avg                          | 187.03004  |
| Q-std                          | 156.64822  |
| Q_loss                         | 86.85686   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 639        |
| times/epoch_after_hook         | 3.66e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000528   |
| times/evaluation_paths         | 4.07       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00785    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 640000     |
| train-steps                    | 640000     |
| training/Q/q1_loss             | 110.458374 |
| training/sac_pi/alpha          | 0.1660156  |
| training/sac_pi/alpha_loss     | 0.12759408 |
| training/sac_pi/logp_pi        | 5.516413   |
| training/sac_pi/pi_entropy     | 3.401099   |
| training/sac_pi/pi_global_norm | 1.547702   |
| training/sac_pi/policy_loss    | -205.40831 |
| training/sac_pi/std            | 0.5369437  |
| training/sac_pi/valid_num      | 4853.0     |
| training/sac_Q/q1              | 185.3016   |
| training/sac_Q/q2              | 181.55469  |
| training/sac_Q/q2_loss         | 110.533134 |
| training/sac_Q/q_global_norm   | 293.36682  |
--------------------------------------------------------------------------------
[WARN] 640 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16010544  |
| epoch                          | 640         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4580.5645   |
| evaluation/return-max          | 4620.5596   |
| evaluation/return-min          | 4535.2305   |
| evaluation/return-std          | 35.2878     |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45881       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4580.5645   |
| perf/NormalizedReturn          | 0.997       |
| Q-avg                          | 182.99545   |
| Q-std                          | 196.01486   |
| Q_loss                         | 95.33071    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 640         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 6.03e-05    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000603    |
| times/evaluation_paths         | 31.3        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00795     |
| times/train                    | 56.1        |
| timestep                       | 1000        |
| timesteps_total                | 641000      |
| train-steps                    | 641000      |
| training/Q/q1_loss             | 82.6261     |
| training/sac_pi/alpha          | 0.16015019  |
| training/sac_pi/alpha_loss     | -0.27252343 |
| training/sac_pi/logp_pi        | 4.4948635   |
| training/sac_pi/pi_entropy     | 3.5277996   |
| training/sac_pi/pi_global_norm | 1.7532321   |
| training/sac_pi/policy_loss    | -206.67735  |
| training/sac_pi/std            | 0.5342646   |
| training/sac_pi/valid_num      | 4961.0      |
| training/sac_Q/q1              | 192.0823    |
| training/sac_Q/q2              | 187.08391   |
| training/sac_Q/q2_loss         | 83.00597    |
| training/sac_Q/q_global_norm   | 232.48323   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16489007  |
| epoch                          | 641         |
| evaluation/episode-length-avg  | 209         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 120         |
| evaluation/episode-length-std  | 264         |
| evaluation/return-average      | 724.33636   |
| evaluation/return-max          | 4786.3633   |
| evaluation/return-min          | 267.75925   |
| evaluation/return-std          | 1354.0114   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45770       |
| perf/AverageLength             | 209         |
| perf/AverageReturn             | 724.33636   |
| perf/NormalizedReturn          | 0.157       |
| Q-avg                          | 201.15865   |
| Q-std                          | 131.2377    |
| Q_loss                         | 98.26002    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 641         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000287    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000469    |
| times/evaluation_paths         | 6.4         |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 57          |
| timestep                       | 1000        |
| timesteps_total                | 642000      |
| train-steps                    | 642000      |
| training/Q/q1_loss             | 107.430695  |
| training/sac_pi/alpha          | 0.16492286  |
| training/sac_pi/alpha_loss     | -0.34278202 |
| training/sac_pi/logp_pi        | 4.5907435   |
| training/sac_pi/pi_entropy     | 3.553658    |
| training/sac_pi/pi_global_norm | 1.8803837   |
| training/sac_pi/policy_loss    | -209.01665  |
| training/sac_pi/std            | 0.54744935  |
| training/sac_pi/valid_num      | 4886.0      |
| training/sac_Q/q1              | 190.23088   |
| training/sac_Q/q2              | 185.08327   |
| training/sac_Q/q2_loss         | 107.10433   |
| training/sac_Q/q_global_norm   | 224.71626   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16963147 |
| epoch                          | 642        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4759.1377  |
| evaluation/return-max          | 4791.806   |
| evaluation/return-min          | 4742.1943  |
| evaluation/return-std          | 15.411467  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45995      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4759.1377  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 198.71104  |
| Q-std                          | 125.69359  |
| Q_loss                         | 112.53005  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 642        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000101   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000546   |
| times/evaluation_paths         | 32.1       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00784    |
| times/train                    | 56.8       |
| timestep                       | 1000       |
| timesteps_total                | 643000     |
| train-steps                    | 643000     |
| training/Q/q1_loss             | 113.10727  |
| training/sac_pi/alpha          | 0.169617   |
| training/sac_pi/alpha_loss     | 0.13153166 |
| training/sac_pi/logp_pi        | 4.730542   |
| training/sac_pi/pi_entropy     | 3.6630177  |
| training/sac_pi/pi_global_norm | 1.6378742  |
| training/sac_pi/policy_loss    | -207.80617 |
| training/sac_pi/std            | 0.5590886  |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 190.63457  |
| training/sac_Q/q2              | 188.03363  |
| training/sac_Q/q2_loss         | 112.71154  |
| training/sac_Q/q_global_norm   | 257.45953  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16913381  |
| epoch                          | 643         |
| evaluation/episode-length-avg  | 131         |
| evaluation/episode-length-max  | 133         |
| evaluation/episode-length-min  | 129         |
| evaluation/episode-length-std  | 1.18        |
| evaluation/return-average      | 357.87027   |
| evaluation/return-max          | 364.67767   |
| evaluation/return-min          | 348.24518   |
| evaluation/return-std          | 4.6279984   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45809       |
| perf/AverageLength             | 131         |
| perf/AverageReturn             | 357.87027   |
| perf/NormalizedReturn          | 0.0776      |
| Q-avg                          | 187.79861   |
| Q-std                          | 179.20905   |
| Q_loss                         | 99.773346   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 643         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000108    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000443    |
| times/evaluation_paths         | 3.96        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00772     |
| times/train                    | 55.1        |
| timestep                       | 1000        |
| timesteps_total                | 644000      |
| train-steps                    | 644000      |
| training/Q/q1_loss             | 75.98844    |
| training/sac_pi/alpha          | 0.16916692  |
| training/sac_pi/alpha_loss     | 0.019612594 |
| training/sac_pi/logp_pi        | 4.060491    |
| training/sac_pi/pi_entropy     | 3.407119    |
| training/sac_pi/pi_global_norm | 1.7035038   |
| training/sac_pi/policy_loss    | -212.81123  |
| training/sac_pi/std            | 0.48516062  |
| training/sac_pi/valid_num      | 4926.0      |
| training/sac_Q/q1              | 200.38145   |
| training/sac_Q/q2              | 199.61218   |
| training/sac_Q/q2_loss         | 77.02435    |
| training/sac_Q/q_global_norm   | 202.67352   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16923906  |
| epoch                          | 644         |
| evaluation/episode-length-avg  | 914         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 145         |
| evaluation/episode-length-std  | 256         |
| evaluation/return-average      | 4409.2666   |
| evaluation/return-max          | 4938.241    |
| evaluation/return-min          | 391.7658    |
| evaluation/return-std          | 1339.8401   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45919       |
| perf/AverageLength             | 914         |
| perf/AverageReturn             | 4409.2666   |
| perf/NormalizedReturn          | 0.96        |
| Q-avg                          | 193.6915    |
| Q-std                          | 149.86913   |
| Q_loss                         | 82.02683    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 644         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 8.05e-05    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000542    |
| times/evaluation_paths         | 28.5        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 56.5        |
| timestep                       | 1000        |
| timesteps_total                | 645000      |
| train-steps                    | 645000      |
| training/Q/q1_loss             | 92.88192    |
| training/sac_pi/alpha          | 0.16929576  |
| training/sac_pi/alpha_loss     | -0.27014777 |
| training/sac_pi/logp_pi        | 4.3735085   |
| training/sac_pi/pi_entropy     | 3.6222458   |
| training/sac_pi/pi_global_norm | 1.4088398   |
| training/sac_pi/policy_loss    | -208.22884  |
| training/sac_pi/std            | 0.53015333  |
| training/sac_pi/valid_num      | 4954.0      |
| training/sac_Q/q1              | 190.48999   |
| training/sac_Q/q2              | 189.1707    |
| training/sac_Q/q2_loss         | 91.96344    |
| training/sac_Q/q_global_norm   | 164.50359   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17428882  |
| epoch                          | 645         |
| evaluation/episode-length-avg  | 881         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 398         |
| evaluation/episode-length-std  | 239         |
| evaluation/return-average      | 4101.261    |
| evaluation/return-max          | 4767.102    |
| evaluation/return-min          | 1604.905    |
| evaluation/return-std          | 1239.1627   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45848       |
| perf/AverageLength             | 881         |
| perf/AverageReturn             | 4101.261    |
| perf/NormalizedReturn          | 0.893       |
| Q-avg                          | 205.83833   |
| Q-std                          | 117.76024   |
| Q_loss                         | 103.69878   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 645         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000345    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000532    |
| times/evaluation_paths         | 27.6        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00797     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 646000      |
| train-steps                    | 646000      |
| training/Q/q1_loss             | 112.8212    |
| training/sac_pi/alpha          | 0.17431554  |
| training/sac_pi/alpha_loss     | 0.018606413 |
| training/sac_pi/logp_pi        | 5.3752885   |
| training/sac_pi/pi_entropy     | 3.5917695   |
| training/sac_pi/pi_global_norm | 1.7504163   |
| training/sac_pi/policy_loss    | -203.24043  |
| training/sac_pi/std            | 0.54708993  |
| training/sac_pi/valid_num      | 4857.0      |
| training/sac_Q/q1              | 172.71602   |
| training/sac_Q/q2              | 168.39783   |
| training/sac_Q/q2_loss         | 112.89277   |
| training/sac_Q/q_global_norm   | 226.49644   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16803801  |
| epoch                          | 646         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4868.371    |
| evaluation/return-max          | 4897.445    |
| evaluation/return-min          | 4839.2666   |
| evaluation/return-std          | 17.465319   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45785       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4868.371    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 194.28954   |
| Q-std                          | 170.33504   |
| Q_loss                         | 108.546906  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 646         |
| times/epoch_after_hook         | 2e-06       |
| times/epoch_before_hook        | 0.00012     |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000597    |
| times/evaluation_paths         | 31.4        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.0081      |
| times/train                    | 55.9        |
| timestep                       | 1000        |
| timesteps_total                | 647000      |
| train-steps                    | 647000      |
| training/Q/q1_loss             | 93.01608    |
| training/sac_pi/alpha          | 0.16803096  |
| training/sac_pi/alpha_loss     | -0.09858428 |
| training/sac_pi/logp_pi        | 4.3550725   |
| training/sac_pi/pi_entropy     | 3.306106    |
| training/sac_pi/pi_global_norm | 1.5806041   |
| training/sac_pi/policy_loss    | -210.16943  |
| training/sac_pi/std            | 0.49398243  |
| training/sac_pi/valid_num      | 4932.0      |
| training/sac_Q/q1              | 193.0096    |
| training/sac_Q/q2              | 191.56033   |
| training/sac_Q/q2_loss         | 94.541855   |
| training/sac_Q/q_global_norm   | 230.72491   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16804874  |
| epoch                          | 647         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5034.218    |
| evaluation/return-max          | 5112.466    |
| evaluation/return-min          | 4975.3716   |
| evaluation/return-std          | 41.478878   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45841       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5034.218    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 188.04483   |
| Q-std                          | 202.64435   |
| Q_loss                         | 96.8289     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 647         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000114    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000572    |
| times/evaluation_paths         | 31.3        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 57.4        |
| timestep                       | 1000        |
| timesteps_total                | 648000      |
| train-steps                    | 648000      |
| training/Q/q1_loss             | 127.223976  |
| training/sac_pi/alpha          | 0.16803008  |
| training/sac_pi/alpha_loss     | -0.04388562 |
| training/sac_pi/logp_pi        | 3.970672    |
| training/sac_pi/pi_entropy     | 3.553868    |
| training/sac_pi/pi_global_norm | 1.497835    |
| training/sac_pi/policy_loss    | -205.50217  |
| training/sac_pi/std            | 0.50646317  |
| training/sac_pi/valid_num      | 5005.0      |
| training/sac_Q/q1              | 195.53828   |
| training/sac_Q/q2              | 195.69661   |
| training/sac_Q/q2_loss         | 127.83307   |
| training/sac_Q/q_global_norm   | 212.78911   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17214987  |
| epoch                          | 648         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4774.13     |
| evaluation/return-max          | 4866.5366   |
| evaluation/return-min          | 4658.8066   |
| evaluation/return-std          | 66.266235   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45870       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4774.13     |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 181.41522   |
| Q-std                          | 197.82872   |
| Q_loss                         | 102.750496  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 648         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000552    |
| times/evaluation_paths         | 30.5        |
| times/timestep_after_hook      | 0.00373     |
| times/timestep_before_hook     | 0.00798     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 649000      |
| train-steps                    | 649000      |
| training/Q/q1_loss             | 102.577934  |
| training/sac_pi/alpha          | 0.17214349  |
| training/sac_pi/alpha_loss     | -0.14448555 |
| training/sac_pi/logp_pi        | 4.4947524   |
| training/sac_pi/pi_entropy     | 3.5400677   |
| training/sac_pi/pi_global_norm | 1.4635838   |
| training/sac_pi/policy_loss    | -211.76006  |
| training/sac_pi/std            | 0.51871794  |
| training/sac_pi/valid_num      | 4944.0      |
| training/sac_Q/q1              | 196.12029   |
| training/sac_Q/q2              | 193.90993   |
| training/sac_Q/q2_loss         | 102.20435   |
| training/sac_Q/q_global_norm   | 298.63303   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1683306   |
| epoch                          | 649         |
| evaluation/episode-length-avg  | 656         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 142         |
| evaluation/episode-length-std  | 417         |
| evaluation/return-average      | 3055.3083   |
| evaluation/return-max          | 5020.401    |
| evaluation/return-min          | 392.216     |
| evaluation/return-std          | 2167.1597   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45834       |
| perf/AverageLength             | 656         |
| perf/AverageReturn             | 3055.3083   |
| perf/NormalizedReturn          | 0.665       |
| Q-avg                          | 168.71126   |
| Q-std                          | 265.59558   |
| Q_loss                         | 129.10896   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 649         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.00029     |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000535    |
| times/evaluation_paths         | 19.7        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00791     |
| times/train                    | 55.4        |
| timestep                       | 1000        |
| timesteps_total                | 650000      |
| train-steps                    | 650000      |
| training/Q/q1_loss             | 100.85301   |
| training/sac_pi/alpha          | 0.1683156   |
| training/sac_pi/alpha_loss     | -0.09126488 |
| training/sac_pi/logp_pi        | 3.757321    |
| training/sac_pi/pi_entropy     | 3.433808    |
| training/sac_pi/pi_global_norm | 1.9963155   |
| training/sac_pi/policy_loss    | -209.04837  |
| training/sac_pi/std            | 0.48518565  |
| training/sac_pi/valid_num      | 5049.0      |
| training/sac_Q/q1              | 201.27376   |
| training/sac_Q/q2              | 201.84065   |
| training/sac_Q/q2_loss         | 100.28512   |
| training/sac_Q/q_global_norm   | 182.7864    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16910046 |
| epoch                          | 650        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4837.763   |
| evaluation/return-max          | 4863.285   |
| evaluation/return-min          | 4786.1934  |
| evaluation/return-std          | 21.887634  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 83.8       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45772      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4837.763   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 190.51619  |
| Q-std                          | 159.2236   |
| Q_loss                         | 127.91366  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 650        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.000107   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000632   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00793    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 651000     |
| train-steps                    | 651000     |
| training/Q/q1_loss             | 122.86511  |
| training/sac_pi/alpha          | 0.16911145 |
| training/sac_pi/alpha_loss     | 0.08182569 |
| training/sac_pi/logp_pi        | 5.655201   |
| training/sac_pi/pi_entropy     | 3.5827003  |
| training/sac_pi/pi_global_norm | 1.5654644  |
| training/sac_pi/policy_loss    | -197.29257 |
| training/sac_pi/std            | 0.5681183  |
| training/sac_pi/valid_num      | 4843.0     |
| training/sac_Q/q1              | 166.18149  |
| training/sac_Q/q2              | 163.90279  |
| training/sac_Q/q2_loss         | 123.25291  |
| training/sac_Q/q_global_norm   | 219.91965  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.166433    |
| epoch                          | 651         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4926.2866   |
| evaluation/return-max          | 4967.8354   |
| evaluation/return-min          | 4887.578    |
| evaluation/return-std          | 22.595057   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45873       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4926.2866   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 182.65762   |
| Q-std                          | 204.72372   |
| Q_loss                         | 121.17709   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 651         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.00052     |
| times/evaluation_paths         | 29.9        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00795     |
| times/train                    | 55.5        |
| timestep                       | 1000        |
| timesteps_total                | 652000      |
| train-steps                    | 652000      |
| training/Q/q1_loss             | 76.10331    |
| training/sac_pi/alpha          | 0.1664113   |
| training/sac_pi/alpha_loss     | 0.019520707 |
| training/sac_pi/logp_pi        | 5.538564    |
| training/sac_pi/pi_entropy     | 3.4712677   |
| training/sac_pi/pi_global_norm | 1.491974    |
| training/sac_pi/policy_loss    | -216.30127  |
| training/sac_pi/std            | 0.5390599   |
| training/sac_pi/valid_num      | 4828.0      |
| training/sac_Q/q1              | 190.2917    |
| training/sac_Q/q2              | 189.60123   |
| training/sac_Q/q2_loss         | 76.5766     |
| training/sac_Q/q_global_norm   | 166.53758   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17127067 |
| epoch                          | 652        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4948.9     |
| evaluation/return-max          | 4981.917   |
| evaluation/return-min          | 4894.4233  |
| evaluation/return-std          | 24.991999  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45857      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4948.9     |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 192.86629  |
| Q-std                          | 201.64731  |
| Q_loss                         | 90.892105  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 652        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000109   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000576   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00791    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 653000     |
| train-steps                    | 653000     |
| training/Q/q1_loss             | 88.15961   |
| training/sac_pi/alpha          | 0.17129207 |
| training/sac_pi/alpha_loss     | 0.09702611 |
| training/sac_pi/logp_pi        | 4.832639   |
| training/sac_pi/pi_entropy     | 3.4062905  |
| training/sac_pi/pi_global_norm | 1.7394553  |
| training/sac_pi/policy_loss    | -211.0368  |
| training/sac_pi/std            | 0.51206887 |
| training/sac_pi/valid_num      | 4993.0     |
| training/sac_Q/q1              | 192.0254   |
| training/sac_Q/q2              | 192.55424  |
| training/sac_Q/q2_loss         | 88.59412   |
| training/sac_Q/q_global_norm   | 223.92165  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17151073   |
| epoch                          | 653          |
| evaluation/episode-length-avg  | 131          |
| evaluation/episode-length-max  | 135          |
| evaluation/episode-length-min  | 128          |
| evaluation/episode-length-std  | 1.73         |
| evaluation/return-average      | 317.87836    |
| evaluation/return-max          | 333.78723    |
| evaluation/return-min          | 303.83728    |
| evaluation/return-std          | 7.689433     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.98         |
| model/origin_ret               | 85.9         |
| model/penalty_ret              | 82.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45855        |
| perf/AverageLength             | 131          |
| perf/AverageReturn             | 317.87836    |
| perf/NormalizedReturn          | 0.0689       |
| Q-avg                          | 191.23816    |
| Q-std                          | 182.95233    |
| Q_loss                         | 96.26061     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 653          |
| times/epoch_after_hook         | 1.9e-06      |
| times/epoch_before_hook        | 0.00028      |
| times/epoch_rollout_model      | 480          |
| times/evaluation_metrics       | 0.00044      |
| times/evaluation_paths         | 4.12         |
| times/timestep_after_hook      | 0.00372      |
| times/timestep_before_hook     | 0.00799      |
| times/train                    | 55.3         |
| timestep                       | 1000         |
| timesteps_total                | 654000       |
| train-steps                    | 654000       |
| training/Q/q1_loss             | 101.36061    |
| training/sac_pi/alpha          | 0.17149895   |
| training/sac_pi/alpha_loss     | -0.036614183 |
| training/sac_pi/logp_pi        | 4.5234895    |
| training/sac_pi/pi_entropy     | 3.6390877    |
| training/sac_pi/pi_global_norm | 1.74322      |
| training/sac_pi/policy_loss    | -203.16113   |
| training/sac_pi/std            | 0.528093     |
| training/sac_pi/valid_num      | 4950.0       |
| training/sac_Q/q1              | 185.11523    |
| training/sac_Q/q2              | 185.2745     |
| training/sac_Q/q2_loss         | 102.0464     |
| training/sac_Q/q_global_norm   | 241.25974    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17225984  |
| epoch                          | 654         |
| evaluation/episode-length-avg  | 491         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 147         |
| evaluation/episode-length-std  | 416         |
| evaluation/return-average      | 2286.1328   |
| evaluation/return-max          | 5115.176    |
| evaluation/return-min          | 421.5817    |
| evaluation/return-std          | 2262.3784   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 83.6        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45798       |
| perf/AverageLength             | 491         |
| perf/AverageReturn             | 2286.1328   |
| perf/NormalizedReturn          | 0.498       |
| Q-avg                          | 185.17308   |
| Q-std                          | 218.2291    |
| Q_loss                         | 96.66161    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 654         |
| times/epoch_after_hook         | 1.93e-06    |
| times/epoch_before_hook        | 6.08e-05    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000552    |
| times/evaluation_paths         | 15          |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00801     |
| times/train                    | 55.2        |
| timestep                       | 1000        |
| timesteps_total                | 655000      |
| train-steps                    | 655000      |
| training/Q/q1_loss             | 107.66456   |
| training/sac_pi/alpha          | 0.17228153  |
| training/sac_pi/alpha_loss     | 0.046388805 |
| training/sac_pi/logp_pi        | 5.377228    |
| training/sac_pi/pi_entropy     | 3.6781273   |
| training/sac_pi/pi_global_norm | 1.4746351   |
| training/sac_pi/policy_loss    | -201.39218  |
| training/sac_pi/std            | 0.56815976  |
| training/sac_pi/valid_num      | 4890.0      |
| training/sac_Q/q1              | 175.45392   |
| training/sac_Q/q2              | 170.54932   |
| training/sac_Q/q2_loss         | 107.82115   |
| training/sac_Q/q_global_norm   | 274.41873   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1698995   |
| epoch                          | 655         |
| evaluation/episode-length-avg  | 298         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 121         |
| evaluation/episode-length-std  | 351         |
| evaluation/return-average      | 1197.4934   |
| evaluation/return-max          | 4892.3086   |
| evaluation/return-min          | 269.86835   |
| evaluation/return-std          | 1839.8234   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45726       |
| perf/AverageLength             | 298         |
| perf/AverageReturn             | 1197.4934   |
| perf/NormalizedReturn          | 0.26        |
| Q-avg                          | 192.61166   |
| Q-std                          | 146.46252   |
| Q_loss                         | 117.26764   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 655         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000102    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000466    |
| times/evaluation_paths         | 8.9         |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00795     |
| times/train                    | 55.2        |
| timestep                       | 1000        |
| timesteps_total                | 656000      |
| train-steps                    | 656000      |
| training/Q/q1_loss             | 96.12437    |
| training/sac_pi/alpha          | 0.16985068  |
| training/sac_pi/alpha_loss     | -0.13480005 |
| training/sac_pi/logp_pi        | 4.2663183   |
| training/sac_pi/pi_entropy     | 3.4995155   |
| training/sac_pi/pi_global_norm | 1.6432203   |
| training/sac_pi/policy_loss    | -201.9696   |
| training/sac_pi/std            | 0.511088    |
| training/sac_pi/valid_num      | 4973.0      |
| training/sac_Q/q1              | 187.0118    |
| training/sac_Q/q2              | 187.89685   |
| training/sac_Q/q2_loss         | 95.907646   |
| training/sac_Q/q_global_norm   | 191.71086   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1599195   |
| epoch                          | 656         |
| evaluation/episode-length-avg  | 664         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 158         |
| evaluation/episode-length-std  | 412         |
| evaluation/return-average      | 3108.7998   |
| evaluation/return-max          | 4929.6543   |
| evaluation/return-min          | 463.41028   |
| evaluation/return-std          | 2156.2244   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45891       |
| perf/AverageLength             | 664         |
| perf/AverageReturn             | 3108.7998   |
| perf/NormalizedReturn          | 0.677       |
| Q-avg                          | 192.98022   |
| Q-std                          | 139.62196   |
| Q_loss                         | 91.9875     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 656         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000118    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000566    |
| times/evaluation_paths         | 20.2        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00789     |
| times/train                    | 55.2        |
| timestep                       | 1000        |
| timesteps_total                | 657000      |
| train-steps                    | 657000      |
| training/Q/q1_loss             | 132.74957   |
| training/sac_pi/alpha          | 0.15996078  |
| training/sac_pi/alpha_loss     | -0.21272342 |
| training/sac_pi/logp_pi        | 5.4195395   |
| training/sac_pi/pi_entropy     | 3.5362792   |
| training/sac_pi/pi_global_norm | 1.5242776   |
| training/sac_pi/policy_loss    | -204.85039  |
| training/sac_pi/std            | 0.5676729   |
| training/sac_pi/valid_num      | 4909.0      |
| training/sac_Q/q1              | 175.66707   |
| training/sac_Q/q2              | 171.55423   |
| training/sac_Q/q2_loss         | 133.06409   |
| training/sac_Q/q_global_norm   | 208.53305   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16878451   |
| epoch                          | 657          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4843.2246    |
| evaluation/return-max          | 4911.5283    |
| evaluation/return-min          | 4801.336     |
| evaluation/return-std          | 37.28309     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.98         |
| model/origin_ret               | 84.5         |
| model/penalty_ret              | 81.4         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45883        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4843.2246    |
| perf/NormalizedReturn          | 1.05         |
| Q-avg                          | 184.67252    |
| Q-std                          | 171.28026    |
| Q_loss                         | 105.47499    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 657          |
| times/epoch_after_hook         | 1.88e-06     |
| times/epoch_before_hook        | 0.000282     |
| times/epoch_rollout_model      | 480          |
| times/evaluation_metrics       | 0.000535     |
| times/evaluation_paths         | 30.1         |
| times/timestep_after_hook      | 0.00362      |
| times/timestep_before_hook     | 0.00777      |
| times/train                    | 55.1         |
| timestep                       | 1000         |
| timesteps_total                | 658000       |
| train-steps                    | 658000       |
| training/Q/q1_loss             | 97.00352     |
| training/sac_pi/alpha          | 0.16877523   |
| training/sac_pi/alpha_loss     | -0.119659334 |
| training/sac_pi/logp_pi        | 4.589103     |
| training/sac_pi/pi_entropy     | 3.5766525    |
| training/sac_pi/pi_global_norm | 1.7858106    |
| training/sac_pi/policy_loss    | -206.258     |
| training/sac_pi/std            | 0.5252181    |
| training/sac_pi/valid_num      | 4927.0       |
| training/sac_Q/q1              | 188.77759    |
| training/sac_Q/q2              | 186.82422    |
| training/sac_Q/q2_loss         | 97.08423     |
| training/sac_Q/q_global_norm   | 165.47522    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16645716 |
| epoch                          | 658        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4995.693   |
| evaluation/return-max          | 5041.6416  |
| evaluation/return-min          | 4880.295   |
| evaluation/return-std          | 49.84305   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45751      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4995.693   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 176.61134  |
| Q-std                          | 242.05031  |
| Q_loss                         | 103.59083  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 658        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.00055    |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00777    |
| times/train                    | 55         |
| timestep                       | 1000       |
| timesteps_total                | 659000     |
| train-steps                    | 659000     |
| training/Q/q1_loss             | 91.90682   |
| training/sac_pi/alpha          | 0.16644041 |
| training/sac_pi/alpha_loss     | 0.11415119 |
| training/sac_pi/logp_pi        | 4.2514696  |
| training/sac_pi/pi_entropy     | 3.636502   |
| training/sac_pi/pi_global_norm | 1.5139076  |
| training/sac_pi/policy_loss    | -202.66371 |
| training/sac_pi/std            | 0.52008903 |
| training/sac_pi/valid_num      | 4986.0     |
| training/sac_Q/q1              | 191.64941  |
| training/sac_Q/q2              | 191.23349  |
| training/sac_Q/q2_loss         | 91.90315   |
| training/sac_Q/q_global_norm   | 244.6516   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16489121  |
| epoch                          | 659         |
| evaluation/episode-length-avg  | 915         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 149         |
| evaluation/episode-length-std  | 255         |
| evaluation/return-average      | 4112.2627   |
| evaluation/return-max          | 4671.1157   |
| evaluation/return-min          | 470.55878   |
| evaluation/return-std          | 1215.193    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45935       |
| perf/AverageLength             | 915         |
| perf/AverageReturn             | 4112.2627   |
| perf/NormalizedReturn          | 0.895       |
| Q-avg                          | 204.12863   |
| Q-std                          | 141.61368   |
| Q_loss                         | 101.05976   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 659         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000108    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.00048     |
| times/evaluation_paths         | 27.7        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00793     |
| times/train                    | 55.5        |
| timestep                       | 1000        |
| timesteps_total                | 660000      |
| train-steps                    | 660000      |
| training/Q/q1_loss             | 99.49604    |
| training/sac_pi/alpha          | 0.16492169  |
| training/sac_pi/alpha_loss     | -0.22567819 |
| training/sac_pi/logp_pi        | 3.8607545   |
| training/sac_pi/pi_entropy     | 3.4858499   |
| training/sac_pi/pi_global_norm | 1.386802    |
| training/sac_pi/policy_loss    | -207.9323   |
| training/sac_pi/std            | 0.49558955  |
| training/sac_pi/valid_num      | 4995.0      |
| training/sac_Q/q1              | 199.2088    |
| training/sac_Q/q2              | 199.5427    |
| training/sac_Q/q2_loss         | 99.5897     |
| training/sac_Q/q_global_norm   | 186.46535   |
---------------------------------------------------------------------------------
[WARN] 660 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16700697 |
| epoch                          | 660        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4840.185   |
| evaluation/return-max          | 4904.5913  |
| evaluation/return-min          | 4724.536   |
| evaluation/return-std          | 48.94089   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46060      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4840.185   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 180.45256  |
| Q-std                          | 203.75854  |
| Q_loss                         | 86.03055   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 660        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000509   |
| times/evaluation_paths         | 30.4       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00797    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 661000     |
| train-steps                    | 661000     |
| training/Q/q1_loss             | 113.1596   |
| training/sac_pi/alpha          | 0.16702293 |
| training/sac_pi/alpha_loss     | 0.15769877 |
| training/sac_pi/logp_pi        | 4.7681656  |
| training/sac_pi/pi_entropy     | 3.5467706  |
| training/sac_pi/pi_global_norm | 1.7437738  |
| training/sac_pi/policy_loss    | -202.81549 |
| training/sac_pi/std            | 0.52533686 |
| training/sac_pi/valid_num      | 4977.0     |
| training/sac_Q/q1              | 187.03542  |
| training/sac_Q/q2              | 186.20496  |
| training/sac_Q/q2_loss         | 113.13534  |
| training/sac_Q/q_global_norm   | 286.02585  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17097418  |
| epoch                          | 661         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4922.0527   |
| evaluation/return-max          | 4938.8584   |
| evaluation/return-min          | 4905.1733   |
| evaluation/return-std          | 10.882353   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 83.8        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45940       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4922.0527   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 188.10399   |
| Q-std                          | 168.21094   |
| Q_loss                         | 112.57393   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 661         |
| times/epoch_after_hook         | 3.18e-06    |
| times/epoch_before_hook        | 0.000279    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000514    |
| times/evaluation_paths         | 30.3        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00803     |
| times/train                    | 55.5        |
| timestep                       | 1000        |
| timesteps_total                | 662000      |
| train-steps                    | 662000      |
| training/Q/q1_loss             | 91.90323    |
| training/sac_pi/alpha          | 0.17096688  |
| training/sac_pi/alpha_loss     | 0.054316547 |
| training/sac_pi/logp_pi        | 4.6993685   |
| training/sac_pi/pi_entropy     | 3.64071     |
| training/sac_pi/pi_global_norm | 1.5467839   |
| training/sac_pi/policy_loss    | -216.06303  |
| training/sac_pi/std            | 0.5495046   |
| training/sac_pi/valid_num      | 4866.0      |
| training/sac_Q/q1              | 191.50218   |
| training/sac_Q/q2              | 189.27567   |
| training/sac_Q/q2_loss         | 92.03084    |
| training/sac_Q/q_global_norm   | 215.15167   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16968058 |
| epoch                          | 662        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5209.6704  |
| evaluation/return-max          | 5253.946   |
| evaluation/return-min          | 5189.202   |
| evaluation/return-std          | 19.039284  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45789      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5209.6704  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 196.60622  |
| Q-std                          | 156.89694  |
| Q_loss                         | 126.59045  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 662        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000103   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000521   |
| times/evaluation_paths         | 30         |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.0079     |
| times/train                    | 55.2       |
| timestep                       | 1000       |
| timesteps_total                | 663000     |
| train-steps                    | 663000     |
| training/Q/q1_loss             | 111.518875 |
| training/sac_pi/alpha          | 0.16965619 |
| training/sac_pi/alpha_loss     | 0.14956492 |
| training/sac_pi/logp_pi        | 4.9497924  |
| training/sac_pi/pi_entropy     | 3.5802827  |
| training/sac_pi/pi_global_norm | 1.6157919  |
| training/sac_pi/policy_loss    | -206.1215  |
| training/sac_pi/std            | 0.5426355  |
| training/sac_pi/valid_num      | 4944.0     |
| training/sac_Q/q1              | 187.51212  |
| training/sac_Q/q2              | 185.07303  |
| training/sac_Q/q2_loss         | 111.501595 |
| training/sac_Q/q_global_norm   | 182.16934  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16642898 |
| epoch                          | 663        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5096.757   |
| evaluation/return-max          | 5146.1475  |
| evaluation/return-min          | 5067.092   |
| evaluation/return-std          | 22.984312  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45817      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5096.757   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 203.0066   |
| Q-std                          | 128.60025  |
| Q_loss                         | 95.31539   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 663        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.0001     |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000546   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00797    |
| times/train                    | 55.3       |
| timestep                       | 1000       |
| timesteps_total                | 664000     |
| train-steps                    | 664000     |
| training/Q/q1_loss             | 97.5288    |
| training/sac_pi/alpha          | 0.1664258  |
| training/sac_pi/alpha_loss     | -0.0862253 |
| training/sac_pi/logp_pi        | 4.5376663  |
| training/sac_pi/pi_entropy     | 3.5344512  |
| training/sac_pi/pi_global_norm | 1.5903488  |
| training/sac_pi/policy_loss    | -206.45839 |
| training/sac_pi/std            | 0.5277803  |
| training/sac_pi/valid_num      | 4947.0     |
| training/sac_Q/q1              | 187.47525  |
| training/sac_Q/q2              | 187.85266  |
| training/sac_Q/q2_loss         | 97.99961   |
| training/sac_Q/q_global_norm   | 206.64064  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16956562  |
| epoch                          | 664         |
| evaluation/episode-length-avg  | 917         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 166         |
| evaluation/episode-length-std  | 250         |
| evaluation/return-average      | 4284.58     |
| evaluation/return-max          | 4817.873    |
| evaluation/return-min          | 529.24585   |
| evaluation/return-std          | 1253.5918   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 82.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45658       |
| perf/AverageLength             | 917         |
| perf/AverageReturn             | 4284.58     |
| perf/NormalizedReturn          | 0.933       |
| Q-avg                          | 197.80118   |
| Q-std                          | 110.77401   |
| Q_loss                         | 90.49851    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 664         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000106    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000529    |
| times/evaluation_paths         | 28.4        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00796     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 665000      |
| train-steps                    | 665000      |
| training/Q/q1_loss             | 94.31973    |
| training/sac_pi/alpha          | 0.16956693  |
| training/sac_pi/alpha_loss     | -0.44951946 |
| training/sac_pi/logp_pi        | 3.895583    |
| training/sac_pi/pi_entropy     | 3.6338983   |
| training/sac_pi/pi_global_norm | 1.855218    |
| training/sac_pi/policy_loss    | -202.73355  |
| training/sac_pi/std            | 0.51052797  |
| training/sac_pi/valid_num      | 4941.0      |
| training/sac_Q/q1              | 193.04489   |
| training/sac_Q/q2              | 192.5391    |
| training/sac_Q/q2_loss         | 95.50131    |
| training/sac_Q/q_global_norm   | 255.95024   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1736059   |
| epoch                          | 665         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5297.6587   |
| evaluation/return-max          | 5329.6846   |
| evaluation/return-min          | 5273.7627   |
| evaluation/return-std          | 17.629549   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 83.8        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45741       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5297.6587   |
| perf/NormalizedReturn          | 1.15        |
| Q-avg                          | 200.63542   |
| Q-std                          | 118.03378   |
| Q_loss                         | 77.71233    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 665         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.00028     |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000532    |
| times/evaluation_paths         | 30.2        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00775     |
| times/train                    | 55.4        |
| timestep                       | 1000        |
| timesteps_total                | 666000      |
| train-steps                    | 666000      |
| training/Q/q1_loss             | 94.72853    |
| training/sac_pi/alpha          | 0.17358144  |
| training/sac_pi/alpha_loss     | -0.28400838 |
| training/sac_pi/logp_pi        | 5.277294    |
| training/sac_pi/pi_entropy     | 3.6475747   |
| training/sac_pi/pi_global_norm | 1.5295563   |
| training/sac_pi/policy_loss    | -202.2942   |
| training/sac_pi/std            | 0.5637226   |
| training/sac_pi/valid_num      | 4826.0      |
| training/sac_Q/q1              | 176.49844   |
| training/sac_Q/q2              | 177.32622   |
| training/sac_Q/q2_loss         | 94.89514    |
| training/sac_Q/q_global_norm   | 176.29903   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16618097  |
| epoch                          | 666         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5030.075    |
| evaluation/return-max          | 5079.129    |
| evaluation/return-min          | 4867.3247   |
| evaluation/return-std          | 57.768246   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45805       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5030.075    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 191.77489   |
| Q-std                          | 159.17189   |
| Q_loss                         | 103.78419   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 666         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000112    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.00055     |
| times/evaluation_paths         | 30          |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00795     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 667000      |
| train-steps                    | 667000      |
| training/Q/q1_loss             | 114.72495   |
| training/sac_pi/alpha          | 0.16622655  |
| training/sac_pi/alpha_loss     | 0.009333528 |
| training/sac_pi/logp_pi        | 4.369049    |
| training/sac_pi/pi_entropy     | 3.56585     |
| training/sac_pi/pi_global_norm | 1.4884859   |
| training/sac_pi/policy_loss    | -205.69386  |
| training/sac_pi/std            | 0.5255558   |
| training/sac_pi/valid_num      | 4970.0      |
| training/sac_Q/q1              | 193.62747   |
| training/sac_Q/q2              | 190.32195   |
| training/sac_Q/q2_loss         | 114.80654   |
| training/sac_Q/q_global_norm   | 279.29736   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17047495   |
| epoch                          | 667          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5084.2427    |
| evaluation/return-max          | 5121.4365    |
| evaluation/return-min          | 4944.856     |
| evaluation/return-std          | 48.49131     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.93         |
| model/origin_ret               | 84.3         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45945        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5084.2427    |
| perf/NormalizedReturn          | 1.11         |
| Q-avg                          | 193.68477    |
| Q-std                          | 164.72365    |
| Q_loss                         | 92.39014     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 667          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.000115     |
| times/epoch_rollout_model      | 481          |
| times/evaluation_metrics       | 0.000523     |
| times/evaluation_paths         | 30.3         |
| times/timestep_after_hook      | 0.00365      |
| times/timestep_before_hook     | 0.0079       |
| times/train                    | 55.1         |
| timestep                       | 1000         |
| timesteps_total                | 668000       |
| train-steps                    | 668000       |
| training/Q/q1_loss             | 111.67478    |
| training/sac_pi/alpha          | 0.17048025   |
| training/sac_pi/alpha_loss     | -0.068994455 |
| training/sac_pi/logp_pi        | 3.795716     |
| training/sac_pi/pi_entropy     | 3.5629563    |
| training/sac_pi/pi_global_norm | 1.6565509    |
| training/sac_pi/policy_loss    | -197.14458   |
| training/sac_pi/std            | 0.4924688    |
| training/sac_pi/valid_num      | 4992.0       |
| training/sac_Q/q1              | 189.77596    |
| training/sac_Q/q2              | 188.02603    |
| training/sac_Q/q2_loss         | 111.31523    |
| training/sac_Q/q_global_norm   | 284.00272    |
----------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.17109679    |
| epoch                          | 668           |
| evaluation/episode-length-avg  | 1e+03         |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 1000          |
| evaluation/episode-length-std  | 0             |
| evaluation/return-average      | 4992.089      |
| evaluation/return-max          | 5036.4883     |
| evaluation/return-min          | 4937.755      |
| evaluation/return-std          | 32.105198     |
| model/max_penalty              | 7.34          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 3.02          |
| model/origin_ret               | 86.3          |
| model/penalty_ret              | 82.5          |
| model/val_loss                 | 0.35430613    |
| model/valid_num                | 45740         |
| perf/AverageLength             | 1e+03         |
| perf/AverageReturn             | 4992.089      |
| perf/NormalizedReturn          | 1.09          |
| Q-avg                          | 185.45894     |
| Q-std                          | 175.03175     |
| Q_loss                         | 130.40965     |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 668           |
| times/epoch_after_hook         | 1.86e-06      |
| times/epoch_before_hook        | 0.000101      |
| times/epoch_rollout_model      | 481           |
| times/evaluation_metrics       | 0.000526      |
| times/evaluation_paths         | 30            |
| times/timestep_after_hook      | 0.00366       |
| times/timestep_before_hook     | 0.00766       |
| times/train                    | 55.4          |
| timestep                       | 1000          |
| timesteps_total                | 669000        |
| train-steps                    | 669000        |
| training/Q/q1_loss             | 95.75959      |
| training/sac_pi/alpha          | 0.17107725    |
| training/sac_pi/alpha_loss     | -0.0030844356 |
| training/sac_pi/logp_pi        | 4.474445      |
| training/sac_pi/pi_entropy     | 3.5852356     |
| training/sac_pi/pi_global_norm | 1.4969378     |
| training/sac_pi/policy_loss    | -214.65619    |
| training/sac_pi/std            | 0.51654446    |
| training/sac_pi/valid_num      | 4941.0        |
| training/sac_Q/q1              | 200.52432     |
| training/sac_Q/q2              | 198.15013     |
| training/sac_Q/q2_loss         | 95.34317      |
| training/sac_Q/q_global_norm   | 177.6878      |
-----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1680949   |
| epoch                          | 669         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5372.416    |
| evaluation/return-max          | 5404.7754   |
| evaluation/return-min          | 5322.6274   |
| evaluation/return-std          | 30.53939    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45733       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5372.416    |
| perf/NormalizedReturn          | 1.17        |
| Q-avg                          | 184.18066   |
| Q-std                          | 167.16751   |
| Q_loss                         | 100.03238   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 669         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000291    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000519    |
| times/evaluation_paths         | 30.1        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00786     |
| times/train                    | 55.4        |
| timestep                       | 1000        |
| timesteps_total                | 670000      |
| train-steps                    | 670000      |
| training/Q/q1_loss             | 104.61012   |
| training/sac_pi/alpha          | 0.16807508  |
| training/sac_pi/alpha_loss     | -0.19319049 |
| training/sac_pi/logp_pi        | 5.5593767   |
| training/sac_pi/pi_entropy     | 3.8469653   |
| training/sac_pi/pi_global_norm | 1.5670012   |
| training/sac_pi/policy_loss    | -204.68417  |
| training/sac_pi/std            | 0.60537237  |
| training/sac_pi/valid_num      | 4899.0      |
| training/sac_Q/q1              | 177.06558   |
| training/sac_Q/q2              | 176.01302   |
| training/sac_Q/q2_loss         | 104.88735   |
| training/sac_Q/q_global_norm   | 257.23972   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16938224  |
| epoch                          | 670         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4815.2383   |
| evaluation/return-max          | 4975.069    |
| evaluation/return-min          | 4719.799    |
| evaluation/return-std          | 87.997154   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45821       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4815.2383   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 179.32407   |
| Q-std                          | 170.16959   |
| Q_loss                         | 118.21696   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 670         |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 0.000108    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000532    |
| times/evaluation_paths         | 30.4        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00782     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 671000      |
| train-steps                    | 671000      |
| training/Q/q1_loss             | 88.18081    |
| training/sac_pi/alpha          | 0.16937777  |
| training/sac_pi/alpha_loss     | -0.21585584 |
| training/sac_pi/logp_pi        | 5.069181    |
| training/sac_pi/pi_entropy     | 3.8444474   |
| training/sac_pi/pi_global_norm | 1.7080973   |
| training/sac_pi/policy_loss    | -204.38118  |
| training/sac_pi/std            | 0.594832    |
| training/sac_pi/valid_num      | 4917.0      |
| training/sac_Q/q1              | 178.25009   |
| training/sac_Q/q2              | 176.11246   |
| training/sac_Q/q2_loss         | 88.791      |
| training/sac_Q/q_global_norm   | 141.08583   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17129342 |
| epoch                          | 671        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4924.428   |
| evaluation/return-max          | 4971.341   |
| evaluation/return-min          | 4882.7153  |
| evaluation/return-std          | 33.090084  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45690      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4924.428   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 185.30466  |
| Q-std                          | 216.29889  |
| Q_loss                         | 89.92104   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 671        |
| times/epoch_after_hook         | 3.52e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000534   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00783    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 672000     |
| train-steps                    | 672000     |
| training/Q/q1_loss             | 107.427246 |
| training/sac_pi/alpha          | 0.17129564 |
| training/sac_pi/alpha_loss     | 0.14460535 |
| training/sac_pi/logp_pi        | 4.8040733  |
| training/sac_pi/pi_entropy     | 3.4475274  |
| training/sac_pi/pi_global_norm | 1.7473668  |
| training/sac_pi/policy_loss    | -201.26674 |
| training/sac_pi/std            | 0.51952493 |
| training/sac_pi/valid_num      | 4937.0     |
| training/sac_Q/q1              | 182.94514  |
| training/sac_Q/q2              | 181.02324  |
| training/sac_Q/q2_loss         | 109.020256 |
| training/sac_Q/q_global_norm   | 220.4361   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16877307  |
| epoch                          | 672         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5059.4463   |
| evaluation/return-max          | 5106.0244   |
| evaluation/return-min          | 4989.3506   |
| evaluation/return-std          | 35.959217   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45788       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5059.4463   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 188.45999   |
| Q-std                          | 158.82515   |
| Q_loss                         | 82.59679    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 672         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.0001      |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000571    |
| times/evaluation_paths         | 31.2        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00797     |
| times/train                    | 55.4        |
| timestep                       | 1000        |
| timesteps_total                | 673000      |
| train-steps                    | 673000      |
| training/Q/q1_loss             | 88.18558    |
| training/sac_pi/alpha          | 0.16874607  |
| training/sac_pi/alpha_loss     | 0.026711509 |
| training/sac_pi/logp_pi        | 4.479637    |
| training/sac_pi/pi_entropy     | 3.6728897   |
| training/sac_pi/pi_global_norm | 1.479125    |
| training/sac_pi/policy_loss    | -207.1379   |
| training/sac_pi/std            | 0.54284275  |
| training/sac_pi/valid_num      | 4934.0      |
| training/sac_Q/q1              | 190.04756   |
| training/sac_Q/q2              | 188.23672   |
| training/sac_Q/q2_loss         | 88.32986    |
| training/sac_Q/q_global_norm   | 183.76985   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17011675  |
| epoch                          | 673         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5238.496    |
| evaluation/return-max          | 5289.733    |
| evaluation/return-min          | 5192.734    |
| evaluation/return-std          | 26.507826   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45847       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5238.496    |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 190.89987   |
| Q-std                          | 195.9714    |
| Q_loss                         | 90.728264   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 673         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000298    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000549    |
| times/evaluation_paths         | 30.3        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00795     |
| times/train                    | 55.3        |
| timestep                       | 1000        |
| timesteps_total                | 674000      |
| train-steps                    | 674000      |
| training/Q/q1_loss             | 109.79097   |
| training/sac_pi/alpha          | 0.1701292   |
| training/sac_pi/alpha_loss     | 0.073701024 |
| training/sac_pi/logp_pi        | 4.4092937   |
| training/sac_pi/pi_entropy     | 3.725554    |
| training/sac_pi/pi_global_norm | 1.5642678   |
| training/sac_pi/policy_loss    | -201.06596  |
| training/sac_pi/std            | 0.54683846  |
| training/sac_pi/valid_num      | 4906.0      |
| training/sac_Q/q1              | 184.65123   |
| training/sac_Q/q2              | 185.00479   |
| training/sac_Q/q2_loss         | 108.13489   |
| training/sac_Q/q_global_norm   | 199.80414   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16611482 |
| epoch                          | 674        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4965.739   |
| evaluation/return-max          | 5073.8076  |
| evaluation/return-min          | 4868.1875  |
| evaluation/return-std          | 60.471832  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45750      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4965.739   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 200.85233  |
| Q-std                          | 157.1637   |
| Q_loss                         | 85.24524   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 674        |
| times/epoch_after_hook         | 2.21e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000544   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00783    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 675000     |
| train-steps                    | 675000     |
| training/Q/q1_loss             | 112.27117  |
| training/sac_pi/alpha          | 0.16611944 |
| training/sac_pi/alpha_loss     | 0.21703646 |
| training/sac_pi/logp_pi        | 4.833973   |
| training/sac_pi/pi_entropy     | 3.4872208  |
| training/sac_pi/pi_global_norm | 1.4797958  |
| training/sac_pi/policy_loss    | -204.05824 |
| training/sac_pi/std            | 0.5322846  |
| training/sac_pi/valid_num      | 4960.0     |
| training/sac_Q/q1              | 183.93806  |
| training/sac_Q/q2              | 182.09866  |
| training/sac_Q/q2_loss         | 111.38645  |
| training/sac_Q/q_global_norm   | 198.14732  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17146751  |
| epoch                          | 675         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4931.2993   |
| evaluation/return-max          | 5035.2715   |
| evaluation/return-min          | 4845.7725   |
| evaluation/return-std          | 52.27923    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45792       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4931.2993   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 183.35483   |
| Q-std                          | 220.90517   |
| Q_loss                         | 102.04551   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 675         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000104    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000547    |
| times/evaluation_paths         | 30.4        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00798     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 676000      |
| train-steps                    | 676000      |
| training/Q/q1_loss             | 103.58883   |
| training/sac_pi/alpha          | 0.17145444  |
| training/sac_pi/alpha_loss     | 0.032675643 |
| training/sac_pi/logp_pi        | 4.548537    |
| training/sac_pi/pi_entropy     | 3.7752986   |
| training/sac_pi/pi_global_norm | 1.6447941   |
| training/sac_pi/policy_loss    | -200.86037  |
| training/sac_pi/std            | 0.5536633   |
| training/sac_pi/valid_num      | 4930.0      |
| training/sac_Q/q1              | 186.51607   |
| training/sac_Q/q2              | 180.9307    |
| training/sac_Q/q2_loss         | 103.27029   |
| training/sac_Q/q_global_norm   | 274.11847   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16982247 |
| epoch                          | 676        |
| evaluation/episode-length-avg  | 151        |
| evaluation/episode-length-max  | 153        |
| evaluation/episode-length-min  | 147        |
| evaluation/episode-length-std  | 1.85       |
| evaluation/return-average      | 452.19376  |
| evaluation/return-max          | 463.52008  |
| evaluation/return-min          | 438.5741   |
| evaluation/return-std          | 8.441186   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45790      |
| perf/AverageLength             | 151        |
| perf/AverageReturn             | 452.19376  |
| perf/NormalizedReturn          | 0.0981     |
| Q-avg                          | 195.45244  |
| Q-std                          | 177.14143  |
| Q_loss                         | 90.14981   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 676        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000586   |
| times/evaluation_paths         | 4.49       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00775    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 677000     |
| train-steps                    | 677000     |
| training/Q/q1_loss             | 114.75823  |
| training/sac_pi/alpha          | 0.16979635 |
| training/sac_pi/alpha_loss     | 0.3950122  |
| training/sac_pi/logp_pi        | 4.9485574  |
| training/sac_pi/pi_entropy     | 3.6714091  |
| training/sac_pi/pi_global_norm | 1.7007706  |
| training/sac_pi/policy_loss    | -198.3113  |
| training/sac_pi/std            | 0.54189754 |
| training/sac_pi/valid_num      | 4956.0     |
| training/sac_Q/q1              | 181.85197  |
| training/sac_Q/q2              | 180.67334  |
| training/sac_Q/q2_loss         | 115.27845  |
| training/sac_Q/q_global_norm   | 225.23232  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1691069  |
| epoch                          | 677        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4653.1016  |
| evaluation/return-max          | 4751.494   |
| evaluation/return-min          | 4572.1807  |
| evaluation/return-std          | 64.914795  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45839      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4653.1016  |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 177.93875  |
| Q-std                          | 252.56157  |
| Q_loss                         | 105.08084  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 677        |
| times/epoch_after_hook         | 2e-06      |
| times/epoch_before_hook        | 0.000273   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000594   |
| times/evaluation_paths         | 30.4       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00782    |
| times/train                    | 56.1       |
| timestep                       | 1000       |
| timesteps_total                | 678000     |
| train-steps                    | 678000     |
| training/Q/q1_loss             | 76.59688   |
| training/sac_pi/alpha          | 0.16905604 |
| training/sac_pi/alpha_loss     | 0.25780457 |
| training/sac_pi/logp_pi        | 4.239001   |
| training/sac_pi/pi_entropy     | 3.581395   |
| training/sac_pi/pi_global_norm | 1.6289979  |
| training/sac_pi/policy_loss    | -205.86627 |
| training/sac_pi/std            | 0.50634754 |
| training/sac_pi/valid_num      | 4936.0     |
| training/sac_Q/q1              | 193.89673  |
| training/sac_Q/q2              | 194.64432  |
| training/sac_Q/q2_loss         | 75.88893   |
| training/sac_Q/q_global_norm   | 231.71753  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16522858  |
| epoch                          | 678         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4848.465    |
| evaluation/return-max          | 4947.035    |
| evaluation/return-min          | 4703.2705   |
| evaluation/return-std          | 59.830563   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 82.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45872       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4848.465    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 187.78519   |
| Q-std                          | 190.18414   |
| Q_loss                         | 92.92565    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 678         |
| times/epoch_after_hook         | 2.07e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000517    |
| times/evaluation_paths         | 30.4        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00789     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 679000      |
| train-steps                    | 679000      |
| training/Q/q1_loss             | 84.56824    |
| training/sac_pi/alpha          | 0.16525358  |
| training/sac_pi/alpha_loss     | -0.37520963 |
| training/sac_pi/logp_pi        | 4.371899    |
| training/sac_pi/pi_entropy     | 3.5956085   |
| training/sac_pi/pi_global_norm | 1.5575947   |
| training/sac_pi/policy_loss    | -204.67885  |
| training/sac_pi/std            | 0.5462247   |
| training/sac_pi/valid_num      | 4954.0      |
| training/sac_Q/q1              | 184.35251   |
| training/sac_Q/q2              | 181.83652   |
| training/sac_Q/q2_loss         | 84.38727    |
| training/sac_Q/q_global_norm   | 214.25171   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16551834 |
| epoch                          | 679        |
| evaluation/episode-length-avg  | 961        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 610        |
| evaluation/episode-length-std  | 117        |
| evaluation/return-average      | 4937.223   |
| evaluation/return-max          | 5320.727   |
| evaluation/return-min          | 2944.5728  |
| evaluation/return-std          | 672.49524  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45887      |
| perf/AverageLength             | 961        |
| perf/AverageReturn             | 4937.223   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 189.67007  |
| Q-std                          | 144.24037  |
| Q_loss                         | 95.45226   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 679        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 9.96e-05   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000538   |
| times/evaluation_paths         | 29.8       |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.00796    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 680000     |
| train-steps                    | 680000     |
| training/Q/q1_loss             | 101.83979  |
| training/sac_pi/alpha          | 0.165489   |
| training/sac_pi/alpha_loss     | 0.20177251 |
| training/sac_pi/logp_pi        | 4.42323    |
| training/sac_pi/pi_entropy     | 3.4892259  |
| training/sac_pi/pi_global_norm | 1.765997   |
| training/sac_pi/policy_loss    | -205.87811 |
| training/sac_pi/std            | 0.50768036 |
| training/sac_pi/valid_num      | 4985.0     |
| training/sac_Q/q1              | 193.0445   |
| training/sac_Q/q2              | 192.56668  |
| training/sac_Q/q2_loss         | 102.21913  |
| training/sac_Q/q_global_norm   | 203.95486  |
--------------------------------------------------------------------------------
[WARN] 680 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16717502 |
| epoch                          | 680        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5171.201   |
| evaluation/return-max          | 5203.395   |
| evaluation/return-min          | 5117.2812  |
| evaluation/return-std          | 27.259851  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45754      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5171.201   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 175.16191  |
| Q-std                          | 191.48724  |
| Q_loss                         | 110.97117  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 680        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000185   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000548   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00789    |
| times/train                    | 55.5       |
| timestep                       | 1000       |
| timesteps_total                | 681000     |
| train-steps                    | 681000     |
| training/Q/q1_loss             | 107.591805 |
| training/sac_pi/alpha          | 0.16713223 |
| training/sac_pi/alpha_loss     | 0.14580387 |
| training/sac_pi/logp_pi        | 4.1904235  |
| training/sac_pi/pi_entropy     | 3.5536911  |
| training/sac_pi/pi_global_norm | 1.5684286  |
| training/sac_pi/policy_loss    | -200.70108 |
| training/sac_pi/std            | 0.4901086  |
| training/sac_pi/valid_num      | 4999.0     |
| training/sac_Q/q1              | 189.21817  |
| training/sac_Q/q2              | 186.81892  |
| training/sac_Q/q2_loss         | 105.974594 |
| training/sac_Q/q_global_norm   | 230.60881  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16461158   |
| epoch                          | 681          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4945.0986    |
| evaluation/return-max          | 5021.2324    |
| evaluation/return-min          | 4887.8643    |
| evaluation/return-std          | 36.171276    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.01         |
| model/origin_ret               | 86.3         |
| model/penalty_ret              | 81.8         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45710        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4945.0986    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 180.17209    |
| Q-std                          | 215.43875    |
| Q_loss                         | 98.11308     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 681          |
| times/epoch_after_hook         | 1.84e-06     |
| times/epoch_before_hook        | 0.000326     |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.000533     |
| times/evaluation_paths         | 30.3         |
| times/timestep_after_hook      | 0.00357      |
| times/timestep_before_hook     | 0.00793      |
| times/train                    | 55.7         |
| timestep                       | 1000         |
| timesteps_total                | 682000       |
| train-steps                    | 682000       |
| training/Q/q1_loss             | 92.03203     |
| training/sac_pi/alpha          | 0.1645994    |
| training/sac_pi/alpha_loss     | -0.026461223 |
| training/sac_pi/logp_pi        | 4.506225     |
| training/sac_pi/pi_entropy     | 3.435285     |
| training/sac_pi/pi_global_norm | 2.1670601    |
| training/sac_pi/policy_loss    | -205.22946   |
| training/sac_pi/std            | 0.53124243   |
| training/sac_pi/valid_num      | 4965.0       |
| training/sac_Q/q1              | 188.90475    |
| training/sac_Q/q2              | 181.39336    |
| training/sac_Q/q2_loss         | 91.4502      |
| training/sac_Q/q_global_norm   | 209.92955    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16598837 |
| epoch                          | 682        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4783.8076  |
| evaluation/return-max          | 4855.9097  |
| evaluation/return-min          | 4718.6006  |
| evaluation/return-std          | 40.303753  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45827      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4783.8076  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 189.41139  |
| Q-std                          | 199.16164  |
| Q_loss                         | 104.81525  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 682        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 30.4       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00787    |
| times/train                    | 55.5       |
| timestep                       | 1000       |
| timesteps_total                | 683000     |
| train-steps                    | 683000     |
| training/Q/q1_loss             | 98.60133   |
| training/sac_pi/alpha          | 0.16594422 |
| training/sac_pi/alpha_loss     | 0.14609528 |
| training/sac_pi/logp_pi        | 5.237184   |
| training/sac_pi/pi_entropy     | 3.4830856  |
| training/sac_pi/pi_global_norm | 2.3097312  |
| training/sac_pi/policy_loss    | -206.94484 |
| training/sac_pi/std            | 0.5417803  |
| training/sac_pi/valid_num      | 4910.0     |
| training/sac_Q/q1              | 184.64261  |
| training/sac_Q/q2              | 179.01077  |
| training/sac_Q/q2_loss         | 98.335045  |
| training/sac_Q/q_global_norm   | 209.1999   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1703039   |
| epoch                          | 683         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5088.7954   |
| evaluation/return-max          | 5154.3286   |
| evaluation/return-min          | 5027.504    |
| evaluation/return-std          | 38.00618    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 82.7        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45808       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5088.7954   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 195.65543   |
| Q-std                          | 181.83102   |
| Q_loss                         | 96.96047    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 683         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000109    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.00055     |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00355     |
| times/timestep_before_hook     | 0.00778     |
| times/train                    | 55.7        |
| timestep                       | 1000        |
| timesteps_total                | 684000      |
| train-steps                    | 684000      |
| training/Q/q1_loss             | 93.161224   |
| training/sac_pi/alpha          | 0.17030711  |
| training/sac_pi/alpha_loss     | -0.22495991 |
| training/sac_pi/logp_pi        | 4.6446137   |
| training/sac_pi/pi_entropy     | 3.6897812   |
| training/sac_pi/pi_global_norm | 1.335015    |
| training/sac_pi/policy_loss    | -208.8893   |
| training/sac_pi/std            | 0.56274605  |
| training/sac_pi/valid_num      | 4904.0      |
| training/sac_Q/q1              | 181.56209   |
| training/sac_Q/q2              | 176.51071   |
| training/sac_Q/q2_loss         | 93.27071    |
| training/sac_Q/q_global_norm   | 187.78198   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16566883 |
| epoch                          | 684        |
| evaluation/episode-length-avg  | 830        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 147        |
| evaluation/episode-length-std  | 340        |
| evaluation/return-average      | 4203.5957  |
| evaluation/return-max          | 5192.769   |
| evaluation/return-min          | 446.87827  |
| evaluation/return-std          | 1872.5126  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45845      |
| perf/AverageLength             | 830        |
| perf/AverageReturn             | 4203.5957  |
| perf/NormalizedReturn          | 0.915      |
| Q-avg                          | 188.58928  |
| Q-std                          | 161.5347   |
| Q_loss                         | 97.657005  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 684        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000101   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000523   |
| times/evaluation_paths         | 25.6       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00782    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 685000     |
| train-steps                    | 685000     |
| training/Q/q1_loss             | 100.634605 |
| training/sac_pi/alpha          | 0.16563676 |
| training/sac_pi/alpha_loss     | 0.27756426 |
| training/sac_pi/logp_pi        | 3.807045   |
| training/sac_pi/pi_entropy     | 3.4407666  |
| training/sac_pi/pi_global_norm | 1.5784048  |
| training/sac_pi/policy_loss    | -205.15407 |
| training/sac_pi/std            | 0.48048812 |
| training/sac_pi/valid_num      | 5002.0     |
| training/sac_Q/q1              | 195.98743  |
| training/sac_Q/q2              | 194.62358  |
| training/sac_Q/q2_loss         | 100.171684 |
| training/sac_Q/q_global_norm   | 262.68533  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16587679  |
| epoch                          | 685         |
| evaluation/episode-length-avg  | 944         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 442         |
| evaluation/episode-length-std  | 167         |
| evaluation/return-average      | 4513.9976   |
| evaluation/return-max          | 4871.379    |
| evaluation/return-min          | 1836.2952   |
| evaluation/return-std          | 894.5633    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45900       |
| perf/AverageLength             | 944         |
| perf/AverageReturn             | 4513.9976   |
| perf/NormalizedReturn          | 0.983       |
| Q-avg                          | 195.44974   |
| Q-std                          | 135.33827   |
| Q_loss                         | 95.18223    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 685         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000278    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000571    |
| times/evaluation_paths         | 29          |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00793     |
| times/train                    | 55.9        |
| timestep                       | 1000        |
| timesteps_total                | 686000      |
| train-steps                    | 686000      |
| training/Q/q1_loss             | 119.885025  |
| training/sac_pi/alpha          | 0.16588546  |
| training/sac_pi/alpha_loss     | -0.24324957 |
| training/sac_pi/logp_pi        | 4.155659    |
| training/sac_pi/pi_entropy     | 3.4843323   |
| training/sac_pi/pi_global_norm | 1.5563855   |
| training/sac_pi/policy_loss    | -207.57462  |
| training/sac_pi/std            | 0.5134617   |
| training/sac_pi/valid_num      | 4908.0      |
| training/sac_Q/q1              | 192.03757   |
| training/sac_Q/q2              | 187.87253   |
| training/sac_Q/q2_loss         | 119.7067    |
| training/sac_Q/q_global_norm   | 192.89265   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16802374  |
| epoch                          | 686         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4516.777    |
| evaluation/return-max          | 4743.131    |
| evaluation/return-min          | 4452.4824   |
| evaluation/return-std          | 81.31824    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45959       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4516.777    |
| perf/NormalizedReturn          | 0.984       |
| Q-avg                          | 180.52989   |
| Q-std                          | 185.19038   |
| Q_loss                         | 123.88999   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 686         |
| times/epoch_after_hook         | 3.77e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000538    |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00787     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 687000      |
| train-steps                    | 687000      |
| training/Q/q1_loss             | 101.718956  |
| training/sac_pi/alpha          | 0.16803545  |
| training/sac_pi/alpha_loss     | -0.20348497 |
| training/sac_pi/logp_pi        | 4.509225    |
| training/sac_pi/pi_entropy     | 3.79412     |
| training/sac_pi/pi_global_norm | 1.7307924   |
| training/sac_pi/policy_loss    | -195.2557   |
| training/sac_pi/std            | 0.56744796  |
| training/sac_pi/valid_num      | 4905.0      |
| training/sac_Q/q1              | 173.98967   |
| training/sac_Q/q2              | 173.2659    |
| training/sac_Q/q2_loss         | 99.78834    |
| training/sac_Q/q_global_norm   | 219.07278   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16498259 |
| epoch                          | 687        |
| evaluation/episode-length-avg  | 916        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 162        |
| evaluation/episode-length-std  | 251        |
| evaluation/return-average      | 4714.0327  |
| evaluation/return-max          | 5216.881   |
| evaluation/return-min          | 540.05164  |
| evaluation/return-std          | 1391.5377  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45877      |
| perf/AverageLength             | 916        |
| perf/AverageReturn             | 4714.0327  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 177.40204  |
| Q-std                          | 248.04918  |
| Q_loss                         | 77.4307    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 687        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000541   |
| times/evaluation_paths         | 27.7       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00795    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 688000     |
| train-steps                    | 688000     |
| training/Q/q1_loss             | 108.54355  |
| training/sac_pi/alpha          | 0.1649848  |
| training/sac_pi/alpha_loss     | 0.18739688 |
| training/sac_pi/logp_pi        | 4.6600013  |
| training/sac_pi/pi_entropy     | 3.4672108  |
| training/sac_pi/pi_global_norm | 2.0525825  |
| training/sac_pi/policy_loss    | -204.49965 |
| training/sac_pi/std            | 0.52612746 |
| training/sac_pi/valid_num      | 4977.0     |
| training/sac_Q/q1              | 189.09518  |
| training/sac_Q/q2              | 187.36845  |
| training/sac_Q/q2_loss         | 108.01546  |
| training/sac_Q/q_global_norm   | 232.28285  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16794895 |
| epoch                          | 688        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5030.247   |
| evaluation/return-max          | 5062.995   |
| evaluation/return-min          | 4985.075   |
| evaluation/return-std          | 25.200232  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45998      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5030.247   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 200.83916  |
| Q-std                          | 190.6296   |
| Q_loss                         | 93.885735  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 688        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000103   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000524   |
| times/evaluation_paths         | 30.4       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00794    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 689000     |
| train-steps                    | 689000     |
| training/Q/q1_loss             | 104.94167  |
| training/sac_pi/alpha          | 0.16793807 |
| training/sac_pi/alpha_loss     | 0.08162131 |
| training/sac_pi/logp_pi        | 3.6225371  |
| training/sac_pi/pi_entropy     | 3.3977942  |
| training/sac_pi/pi_global_norm | 1.5920024  |
| training/sac_pi/policy_loss    | -213.17308 |
| training/sac_pi/std            | 0.46666956 |
| training/sac_pi/valid_num      | 5043.0     |
| training/sac_Q/q1              | 207.61736  |
| training/sac_Q/q2              | 207.08545  |
| training/sac_Q/q2_loss         | 104.22043  |
| training/sac_Q/q_global_norm   | 171.21515  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16424713  |
| epoch                          | 689         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4730.8706   |
| evaluation/return-max          | 4783.7666   |
| evaluation/return-min          | 4678.677    |
| evaluation/return-std          | 31.689482   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 82.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45811       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4730.8706   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 193.48544   |
| Q-std                          | 145.67142   |
| Q_loss                         | 93.328865   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 689         |
| times/epoch_after_hook         | 1.99e-06    |
| times/epoch_before_hook        | 0.00028     |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000537    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00783     |
| times/train                    | 55.7        |
| timestep                       | 1000        |
| timesteps_total                | 690000      |
| train-steps                    | 690000      |
| training/Q/q1_loss             | 119.095276  |
| training/sac_pi/alpha          | 0.1642428   |
| training/sac_pi/alpha_loss     | -0.05769534 |
| training/sac_pi/logp_pi        | 4.3968954   |
| training/sac_pi/pi_entropy     | 3.4960093   |
| training/sac_pi/pi_global_norm | 1.5392414   |
| training/sac_pi/policy_loss    | -206.1329   |
| training/sac_pi/std            | 0.51393574  |
| training/sac_pi/valid_num      | 4922.0      |
| training/sac_Q/q1              | 192.20769   |
| training/sac_Q/q2              | 192.61813   |
| training/sac_Q/q2_loss         | 119.36088   |
| training/sac_Q/q_global_norm   | 254.3723    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16592827 |
| epoch                          | 690        |
| evaluation/episode-length-avg  | 125        |
| evaluation/episode-length-max  | 126        |
| evaluation/episode-length-min  | 123        |
| evaluation/episode-length-std  | 0.8        |
| evaluation/return-average      | 319.84872  |
| evaluation/return-max          | 326.17865  |
| evaluation/return-min          | 312.4472   |
| evaluation/return-std          | 4.365302   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45878      |
| perf/AverageLength             | 125        |
| perf/AverageReturn             | 319.84872  |
| perf/NormalizedReturn          | 0.0693     |
| Q-avg                          | 212.02487  |
| Q-std                          | 126.4587   |
| Q_loss                         | 67.656364  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 690        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000119   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000437   |
| times/evaluation_paths         | 3.84       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00775    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 691000     |
| train-steps                    | 691000     |
| training/Q/q1_loss             | 103.19025  |
| training/sac_pi/alpha          | 0.16594538 |
| training/sac_pi/alpha_loss     | -0.4104325 |
| training/sac_pi/logp_pi        | 4.094018   |
| training/sac_pi/pi_entropy     | 3.3391044  |
| training/sac_pi/pi_global_norm | 1.5609729  |
| training/sac_pi/policy_loss    | -210.38799 |
| training/sac_pi/std            | 0.49249884 |
| training/sac_pi/valid_num      | 4936.0     |
| training/sac_Q/q1              | 195.01138  |
| training/sac_Q/q2              | 196.76167  |
| training/sac_Q/q2_loss         | 104.14094  |
| training/sac_Q/q_global_norm   | 207.41408  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16858013  |
| epoch                          | 691         |
| evaluation/episode-length-avg  | 150         |
| evaluation/episode-length-max  | 152         |
| evaluation/episode-length-min  | 147         |
| evaluation/episode-length-std  | 1.37        |
| evaluation/return-average      | 470.57748   |
| evaluation/return-max          | 489.31998   |
| evaluation/return-min          | 451.38812   |
| evaluation/return-std          | 11.824369   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46018       |
| perf/AverageLength             | 150         |
| perf/AverageReturn             | 470.57748   |
| perf/NormalizedReturn          | 0.102       |
| Q-avg                          | 188.75659   |
| Q-std                          | 182.5094    |
| Q_loss                         | 80.44513    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 691         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 8.74e-05    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000478    |
| times/evaluation_paths         | 4.55        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00805     |
| times/train                    | 55.6        |
| timestep                       | 1000        |
| timesteps_total                | 692000      |
| train-steps                    | 692000      |
| training/Q/q1_loss             | 96.544815   |
| training/sac_pi/alpha          | 0.16855253  |
| training/sac_pi/alpha_loss     | 0.072366595 |
| training/sac_pi/logp_pi        | 4.321425    |
| training/sac_pi/pi_entropy     | 3.3575833   |
| training/sac_pi/pi_global_norm | 1.415909    |
| training/sac_pi/policy_loss    | -211.89569  |
| training/sac_pi/std            | 0.49926963  |
| training/sac_pi/valid_num      | 4972.0      |
| training/sac_Q/q1              | 195.79184   |
| training/sac_Q/q2              | 193.6816    |
| training/sac_Q/q2_loss         | 97.76469    |
| training/sac_Q/q_global_norm   | 185.08154   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16839978 |
| epoch                          | 692        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4828.5586  |
| evaluation/return-max          | 4853.1963  |
| evaluation/return-min          | 4798.3823  |
| evaluation/return-std          | 17.139523  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45910      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4828.5586  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 181.47107  |
| Q-std                          | 204.44269  |
| Q_loss                         | 91.63214   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 692        |
| times/epoch_after_hook         | 1.98e-06   |
| times/epoch_before_hook        | 9.99e-05   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000536   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00801    |
| times/train                    | 55.8       |
| timestep                       | 1000       |
| timesteps_total                | 693000     |
| train-steps                    | 693000     |
| training/Q/q1_loss             | 89.967865  |
| training/sac_pi/alpha          | 0.16834952 |
| training/sac_pi/alpha_loss     | 0.03490831 |
| training/sac_pi/logp_pi        | 4.215734   |
| training/sac_pi/pi_entropy     | 3.4001603  |
| training/sac_pi/pi_global_norm | 1.7600588  |
| training/sac_pi/policy_loss    | -211.10071 |
| training/sac_pi/std            | 0.5035102  |
| training/sac_pi/valid_num      | 5012.0     |
| training/sac_Q/q1              | 198.53146  |
| training/sac_Q/q2              | 198.40317  |
| training/sac_Q/q2_loss         | 89.68206   |
| training/sac_Q/q_global_norm   | 195.98488  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17146899 |
| epoch                          | 693        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4951.0757  |
| evaluation/return-max          | 5004.0713  |
| evaluation/return-min          | 4898.763   |
| evaluation/return-std          | 34.662724  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46037      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4951.0757  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 193.9856   |
| Q-std                          | 152.92355  |
| Q_loss                         | 91.544044  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 693        |
| times/epoch_after_hook         | 2.19e-06   |
| times/epoch_before_hook        | 0.000282   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000552   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00796    |
| times/train                    | 54.9       |
| timestep                       | 1000       |
| timesteps_total                | 694000     |
| train-steps                    | 694000     |
| training/Q/q1_loss             | 89.74608   |
| training/sac_pi/alpha          | 0.17144789 |
| training/sac_pi/alpha_loss     | 0.02105459 |
| training/sac_pi/logp_pi        | 4.6256247  |
| training/sac_pi/pi_entropy     | 3.432412   |
| training/sac_pi/pi_global_norm | 1.4113505  |
| training/sac_pi/policy_loss    | -207.81581 |
| training/sac_pi/std            | 0.51773983 |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 191.37975  |
| training/sac_Q/q2              | 189.88676  |
| training/sac_Q/q2_loss         | 91.23688   |
| training/sac_Q/q_global_norm   | 248.34721  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17129266   |
| epoch                          | 694          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 999          |
| evaluation/episode-length-std  | 0.3          |
| evaluation/return-average      | 4886.3037    |
| evaluation/return-max          | 5057.19      |
| evaluation/return-min          | 4741.4023    |
| evaluation/return-std          | 83.809364    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.96         |
| model/origin_ret               | 85.3         |
| model/penalty_ret              | 81.9         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45895        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4886.3037    |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 192.10126    |
| Q-std                          | 139.61804    |
| Q_loss                         | 103.32911    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 694          |
| times/epoch_after_hook         | 1.83e-06     |
| times/epoch_before_hook        | 0.000128     |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.000518     |
| times/evaluation_paths         | 30.2         |
| times/timestep_after_hook      | 0.00369      |
| times/timestep_before_hook     | 0.00783      |
| times/train                    | 55.2         |
| timestep                       | 1000         |
| timesteps_total                | 695000       |
| train-steps                    | 695000       |
| training/Q/q1_loss             | 99.465485    |
| training/sac_pi/alpha          | 0.17128856   |
| training/sac_pi/alpha_loss     | -0.022568328 |
| training/sac_pi/logp_pi        | 4.5261865    |
| training/sac_pi/pi_entropy     | 3.5928104    |
| training/sac_pi/pi_global_norm | 1.6650113    |
| training/sac_pi/policy_loss    | -204.43187   |
| training/sac_pi/std            | 0.5347697    |
| training/sac_pi/valid_num      | 4906.0       |
| training/sac_Q/q1              | 183.00687    |
| training/sac_Q/q2              | 181.3238     |
| training/sac_Q/q2_loss         | 99.74686     |
| training/sac_Q/q_global_norm   | 293.86148    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16385768  |
| epoch                          | 695         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4536.122    |
| evaluation/return-max          | 4633.743    |
| evaluation/return-min          | 4460.711    |
| evaluation/return-std          | 53.63973    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45974       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4536.122    |
| perf/NormalizedReturn          | 0.988       |
| Q-avg                          | 191.97449   |
| Q-std                          | 155.36508   |
| Q_loss                         | 88.99372    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 695         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 9.84e-05    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000517    |
| times/evaluation_paths         | 30.5        |
| times/timestep_after_hook      | 0.00355     |
| times/timestep_before_hook     | 0.00769     |
| times/train                    | 55.1        |
| timestep                       | 1000        |
| timesteps_total                | 696000      |
| train-steps                    | 696000      |
| training/Q/q1_loss             | 109.041855  |
| training/sac_pi/alpha          | 0.16385157  |
| training/sac_pi/alpha_loss     | 0.012594674 |
| training/sac_pi/logp_pi        | 4.5127873   |
| training/sac_pi/pi_entropy     | 3.6091793   |
| training/sac_pi/pi_global_norm | 1.5335662   |
| training/sac_pi/policy_loss    | -207.72795  |
| training/sac_pi/std            | 0.5227265   |
| training/sac_pi/valid_num      | 4934.0      |
| training/sac_Q/q1              | 188.84358   |
| training/sac_Q/q2              | 186.83066   |
| training/sac_Q/q2_loss         | 110.21063   |
| training/sac_Q/q_global_norm   | 209.9952    |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16890377   |
| epoch                          | 696          |
| evaluation/episode-length-avg  | 581          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 156          |
| evaluation/episode-length-std  | 419          |
| evaluation/return-average      | 2602.3635    |
| evaluation/return-max          | 4749.9707    |
| evaluation/return-min          | 452.84015    |
| evaluation/return-std          | 2127.1077    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.88         |
| model/origin_ret               | 83.2         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45846        |
| perf/AverageLength             | 581          |
| perf/AverageReturn             | 2602.3635    |
| perf/NormalizedReturn          | 0.567        |
| Q-avg                          | 191.16537    |
| Q-std                          | 165.26892    |
| Q_loss                         | 87.86832     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 696          |
| times/epoch_after_hook         | 3.29e-06     |
| times/epoch_before_hook        | 0.000115     |
| times/epoch_rollout_model      | 480          |
| times/evaluation_metrics       | 0.000546     |
| times/evaluation_paths         | 18           |
| times/timestep_after_hook      | 0.00352      |
| times/timestep_before_hook     | 0.00768      |
| times/train                    | 54.9         |
| timestep                       | 1000         |
| timesteps_total                | 697000       |
| train-steps                    | 697000       |
| training/Q/q1_loss             | 73.647995    |
| training/sac_pi/alpha          | 0.1689106    |
| training/sac_pi/alpha_loss     | -0.052063666 |
| training/sac_pi/logp_pi        | 3.8422947    |
| training/sac_pi/pi_entropy     | 3.6368752    |
| training/sac_pi/pi_global_norm | 1.5342374    |
| training/sac_pi/policy_loss    | -206.00882   |
| training/sac_pi/std            | 0.5021199    |
| training/sac_pi/valid_num      | 4985.0       |
| training/sac_Q/q1              | 197.18376    |
| training/sac_Q/q2              | 197.50601    |
| training/sac_Q/q2_loss         | 73.56275     |
| training/sac_Q/q_global_norm   | 164.92624    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16763534  |
| epoch                          | 697         |
| evaluation/episode-length-avg  | 335         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 116         |
| evaluation/episode-length-std  | 333         |
| evaluation/return-average      | 1245.5985   |
| evaluation/return-max          | 4595.46     |
| evaluation/return-min          | 233.88702   |
| evaluation/return-std          | 1671.5814   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45796       |
| perf/AverageLength             | 335         |
| perf/AverageReturn             | 1245.5985   |
| perf/NormalizedReturn          | 0.271       |
| Q-avg                          | 190.19576   |
| Q-std                          | 164.5808    |
| Q_loss                         | 85.32323    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 697         |
| times/epoch_after_hook         | 3.73e-06    |
| times/epoch_before_hook        | 0.000326    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000514    |
| times/evaluation_paths         | 10.2        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00769     |
| times/train                    | 54.9        |
| timestep                       | 1000        |
| timesteps_total                | 698000      |
| train-steps                    | 698000      |
| training/Q/q1_loss             | 89.250885   |
| training/sac_pi/alpha          | 0.1675938   |
| training/sac_pi/alpha_loss     | 0.049854398 |
| training/sac_pi/logp_pi        | 3.9551463   |
| training/sac_pi/pi_entropy     | 3.4739463   |
| training/sac_pi/pi_global_norm | 1.9983486   |
| training/sac_pi/policy_loss    | -214.87378  |
| training/sac_pi/std            | 0.49153545  |
| training/sac_pi/valid_num      | 5034.0      |
| training/sac_Q/q1              | 208.39609   |
| training/sac_Q/q2              | 208.28476   |
| training/sac_Q/q2_loss         | 88.75192    |
| training/sac_Q/q_global_norm   | 178.09937   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16564484 |
| epoch                          | 698        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4731.386   |
| evaluation/return-max          | 4805.5703  |
| evaluation/return-min          | 4617.237   |
| evaluation/return-std          | 55.475655  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45843      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4731.386   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 188.22263  |
| Q-std                          | 169.53575  |
| Q_loss                         | 105.49344  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 698        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000101   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000532   |
| times/evaluation_paths         | 29.9       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00776    |
| times/train                    | 55.5       |
| timestep                       | 1000       |
| timesteps_total                | 699000     |
| train-steps                    | 699000     |
| training/Q/q1_loss             | 105.81433  |
| training/sac_pi/alpha          | 0.16562395 |
| training/sac_pi/alpha_loss     | 0.4127258  |
| training/sac_pi/logp_pi        | 4.44298    |
| training/sac_pi/pi_entropy     | 3.447188   |
| training/sac_pi/pi_global_norm | 2.119531   |
| training/sac_pi/policy_loss    | -206.59352 |
| training/sac_pi/std            | 0.49484926 |
| training/sac_pi/valid_num      | 4988.0     |
| training/sac_Q/q1              | 197.01846  |
| training/sac_Q/q2              | 196.5806   |
| training/sac_Q/q2_loss         | 107.35578  |
| training/sac_Q/q_global_norm   | 253.83073  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16890338 |
| epoch                          | 699        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5153.5864  |
| evaluation/return-max          | 5236.957   |
| evaluation/return-min          | 5067.5747  |
| evaluation/return-std          | 53.84366   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45994      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5153.5864  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 199.48318  |
| Q-std                          | 134.18916  |
| Q_loss                         | 100.89676  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 699        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.0001     |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.00068    |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00786    |
| times/train                    | 55.6       |
| timestep                       | 1000       |
| timesteps_total                | 700000     |
| train-steps                    | 700000     |
| training/Q/q1_loss             | 96.50759   |
| training/sac_pi/alpha          | 0.1688949  |
| training/sac_pi/alpha_loss     | 0.06167426 |
| training/sac_pi/logp_pi        | 4.2634873  |
| training/sac_pi/pi_entropy     | 3.678042   |
| training/sac_pi/pi_global_norm | 1.5800182  |
| training/sac_pi/policy_loss    | -197.62335 |
| training/sac_pi/std            | 0.51709276 |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 185.22298  |
| training/sac_Q/q2              | 182.71053  |
| training/sac_Q/q2_loss         | 96.36297   |
| training/sac_Q/q_global_norm   | 181.7185   |
--------------------------------------------------------------------------------
[WARN] 700 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.17108734 |
| epoch                          | 700        |
| evaluation/episode-length-avg  | 240        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 152        |
| evaluation/episode-length-std  | 253        |
| evaluation/return-average      | 949.6722   |
| evaluation/return-max          | 4885.4917  |
| evaluation/return-min          | 504.54648  |
| evaluation/return-std          | 1311.9524  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45917      |
| perf/AverageLength             | 240        |
| perf/AverageReturn             | 949.6722   |
| perf/NormalizedReturn          | 0.207      |
| Q-avg                          | 184.9043   |
| Q-std                          | 180.33836  |
| Q_loss                         | 97.97329   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 700        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000144   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000473   |
| times/evaluation_paths         | 7.31       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00765    |
| times/train                    | 55.7       |
| timestep                       | 1000       |
| timesteps_total                | 701000     |
| train-steps                    | 701000     |
| training/Q/q1_loss             | 129.3082   |
| training/sac_pi/alpha          | 0.17106503 |
| training/sac_pi/alpha_loss     | 0.252152   |
| training/sac_pi/logp_pi        | 4.1472178  |
| training/sac_pi/pi_entropy     | 3.4445362  |
| training/sac_pi/pi_global_norm | 1.7546904  |
| training/sac_pi/policy_loss    | -199.46059 |
| training/sac_pi/std            | 0.4907171  |
| training/sac_pi/valid_num      | 4990.0     |
| training/sac_Q/q1              | 189.41469  |
| training/sac_Q/q2              | 187.12663  |
| training/sac_Q/q2_loss         | 129.90244  |
| training/sac_Q/q_global_norm   | 232.8827   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1716609   |
| epoch                          | 701         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5200.634    |
| evaluation/return-max          | 5269.5654   |
| evaluation/return-min          | 5084.4404   |
| evaluation/return-std          | 56.19915    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45769       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5200.634    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 176.71701   |
| Q-std                          | 211.39801   |
| Q_loss                         | 106.16148   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 701         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000337    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 30.3        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00787     |
| times/train                    | 55.3        |
| timestep                       | 1000        |
| timesteps_total                | 702000      |
| train-steps                    | 702000      |
| training/Q/q1_loss             | 100.96068   |
| training/sac_pi/alpha          | 0.17164186  |
| training/sac_pi/alpha_loss     | -0.18966164 |
| training/sac_pi/logp_pi        | 4.82624     |
| training/sac_pi/pi_entropy     | 3.6064758   |
| training/sac_pi/pi_global_norm | 1.766251    |
| training/sac_pi/policy_loss    | -203.89998  |
| training/sac_pi/std            | 0.5375597   |
| training/sac_pi/valid_num      | 4910.0      |
| training/sac_Q/q1              | 188.77109   |
| training/sac_Q/q2              | 186.16333   |
| training/sac_Q/q2_loss         | 100.2905    |
| training/sac_Q/q_global_norm   | 184.97987   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16940118  |
| epoch                          | 702         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4789.2593   |
| evaluation/return-max          | 4873.9795   |
| evaluation/return-min          | 4753.097    |
| evaluation/return-std          | 32.63832    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45728       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4789.2593   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 187.6349    |
| Q-std                          | 175.53085   |
| Q_loss                         | 80.81189    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 702         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000104    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000529    |
| times/evaluation_paths         | 31.2        |
| times/timestep_after_hook      | 0.00373     |
| times/timestep_before_hook     | 0.00803     |
| times/train                    | 55.5        |
| timestep                       | 1000        |
| timesteps_total                | 703000      |
| train-steps                    | 703000      |
| training/Q/q1_loss             | 102.952415  |
| training/sac_pi/alpha          | 0.16944356  |
| training/sac_pi/alpha_loss     | -0.41492867 |
| training/sac_pi/logp_pi        | 3.9587123   |
| training/sac_pi/pi_entropy     | 3.606624    |
| training/sac_pi/pi_global_norm | 1.4406408   |
| training/sac_pi/policy_loss    | -204.9443   |
| training/sac_pi/std            | 0.51890695  |
| training/sac_pi/valid_num      | 4969.0      |
| training/sac_Q/q1              | 192.38797   |
| training/sac_Q/q2              | 191.80545   |
| training/sac_Q/q2_loss         | 101.88017   |
| training/sac_Q/q_global_norm   | 203.24721   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17090648  |
| epoch                          | 703         |
| evaluation/episode-length-avg  | 412         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 157         |
| evaluation/episode-length-std  | 385         |
| evaluation/return-average      | 1886.1487   |
| evaluation/return-max          | 5142.3193   |
| evaluation/return-min          | 502.4086    |
| evaluation/return-std          | 2099.6367   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45820       |
| perf/AverageLength             | 412         |
| perf/AverageReturn             | 1886.1487   |
| perf/NormalizedReturn          | 0.411       |
| Q-avg                          | 184.5962    |
| Q-std                          | 183.45071   |
| Q_loss                         | 114.88196   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 703         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000111    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000504    |
| times/evaluation_paths         | 12.4        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00792     |
| times/train                    | 55.8        |
| timestep                       | 1000        |
| timesteps_total                | 704000      |
| train-steps                    | 704000      |
| training/Q/q1_loss             | 87.911385   |
| training/sac_pi/alpha          | 0.17095697  |
| training/sac_pi/alpha_loss     | -0.22121163 |
| training/sac_pi/logp_pi        | 4.198826    |
| training/sac_pi/pi_entropy     | 3.5299478   |
| training/sac_pi/pi_global_norm | 1.5904285   |
| training/sac_pi/policy_loss    | -199.8362   |
| training/sac_pi/std            | 0.49686337  |
| training/sac_pi/valid_num      | 4939.0      |
| training/sac_Q/q1              | 187.41826   |
| training/sac_Q/q2              | 188.99298   |
| training/sac_Q/q2_loss         | 87.132866   |
| training/sac_Q/q_global_norm   | 216.84528   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1680139  |
| epoch                          | 704        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4714.3896  |
| evaluation/return-max          | 4828.5454  |
| evaluation/return-min          | 4564.151   |
| evaluation/return-std          | 77.931595  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45800      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4714.3896  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 187.37761  |
| Q-std                          | 167.83578  |
| Q_loss                         | 87.598785  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 704        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000101   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000535   |
| times/evaluation_paths         | 30.4       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00783    |
| times/train                    | 55.3       |
| timestep                       | 1000       |
| timesteps_total                | 705000     |
| train-steps                    | 705000     |
| training/Q/q1_loss             | 99.325096  |
| training/sac_pi/alpha          | 0.16802603 |
| training/sac_pi/alpha_loss     | 0.20287739 |
| training/sac_pi/logp_pi        | 4.1835966  |
| training/sac_pi/pi_entropy     | 3.3770745  |
| training/sac_pi/pi_global_norm | 1.4326161  |
| training/sac_pi/policy_loss    | -213.00745 |
| training/sac_pi/std            | 0.48509932 |
| training/sac_pi/valid_num      | 5002.0     |
| training/sac_Q/q1              | 204.24966  |
| training/sac_Q/q2              | 205.7791   |
| training/sac_Q/q2_loss         | 99.61805   |
| training/sac_Q/q_global_norm   | 290.3721   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16533189  |
| epoch                          | 705         |
| evaluation/episode-length-avg  | 153         |
| evaluation/episode-length-max  | 160         |
| evaluation/episode-length-min  | 149         |
| evaluation/episode-length-std  | 3.11        |
| evaluation/return-average      | 443.79727   |
| evaluation/return-max          | 468.48587   |
| evaluation/return-min          | 425.83728   |
| evaluation/return-std          | 11.796916   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45944       |
| perf/AverageLength             | 153         |
| perf/AverageReturn             | 443.79727   |
| perf/NormalizedReturn          | 0.0963      |
| Q-avg                          | 196.08723   |
| Q-std                          | 182.8825    |
| Q_loss                         | 120.08213   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 705         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000277    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000501    |
| times/evaluation_paths         | 4.65        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00806     |
| times/train                    | 55.7        |
| timestep                       | 1000        |
| timesteps_total                | 706000      |
| train-steps                    | 706000      |
| training/Q/q1_loss             | 102.25684   |
| training/sac_pi/alpha          | 0.16533202  |
| training/sac_pi/alpha_loss     | 0.067634046 |
| training/sac_pi/logp_pi        | 4.1698866   |
| training/sac_pi/pi_entropy     | 3.4477048   |
| training/sac_pi/pi_global_norm | 1.6263491   |
| training/sac_pi/policy_loss    | -203.21582  |
| training/sac_pi/std            | 0.48370045  |
| training/sac_pi/valid_num      | 4940.0      |
| training/sac_Q/q1              | 193.08598   |
| training/sac_Q/q2              | 193.52481   |
| training/sac_Q/q2_loss         | 103.03459   |
| training/sac_Q/q_global_norm   | 213.03589   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16735865 |
| epoch                          | 706        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4207.3545  |
| evaluation/return-max          | 4242.628   |
| evaluation/return-min          | 4183.8467  |
| evaluation/return-std          | 16.316946  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46007      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4207.3545  |
| perf/NormalizedReturn          | 0.916      |
| Q-avg                          | 193.86757  |
| Q-std                          | 157.11816  |
| Q_loss                         | 80.8854    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 706        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000146   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.00051    |
| times/evaluation_paths         | 30.1       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 55.4       |
| timestep                       | 1000       |
| timesteps_total                | 707000     |
| train-steps                    | 707000     |
| training/Q/q1_loss             | 99.0135    |
| training/sac_pi/alpha          | 0.16735753 |
| training/sac_pi/alpha_loss     | 0.35523233 |
| training/sac_pi/logp_pi        | 5.0499144  |
| training/sac_pi/pi_entropy     | 3.279758   |
| training/sac_pi/pi_global_norm | 1.7349843  |
| training/sac_pi/policy_loss    | -199.79568 |
| training/sac_pi/std            | 0.49366087 |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 185.43538  |
| training/sac_Q/q2              | 184.50212  |
| training/sac_Q/q2_loss         | 99.23933   |
| training/sac_Q/q_global_norm   | 227.52542  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16443841 |
| epoch                          | 707        |
| evaluation/episode-length-avg  | 916        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 158        |
| evaluation/episode-length-std  | 253        |
| evaluation/return-average      | 4307.2173  |
| evaluation/return-max          | 4789.006   |
| evaluation/return-min          | 474.53143  |
| evaluation/return-std          | 1277.9995  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45909      |
| perf/AverageLength             | 916        |
| perf/AverageReturn             | 4307.2173  |
| perf/NormalizedReturn          | 0.938      |
| Q-avg                          | 187.5314   |
| Q-std                          | 186.16553  |
| Q_loss                         | 108.45311  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 707        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000523   |
| times/evaluation_paths         | 28.8       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 56.4       |
| timestep                       | 1000       |
| timesteps_total                | 708000     |
| train-steps                    | 708000     |
| training/Q/q1_loss             | 73.815285  |
| training/sac_pi/alpha          | 0.16443133 |
| training/sac_pi/alpha_loss     | -0.3916503 |
| training/sac_pi/logp_pi        | 4.3798285  |
| training/sac_pi/pi_entropy     | 3.515279   |
| training/sac_pi/pi_global_norm | 1.4712864  |
| training/sac_pi/policy_loss    | -207.75345 |
| training/sac_pi/std            | 0.51923263 |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 194.38452  |
| training/sac_Q/q2              | 195.54514  |
| training/sac_Q/q2_loss         | 74.520164  |
| training/sac_Q/q_global_norm   | 275.88504  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16285755   |
| epoch                          | 708          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4638.8843    |
| evaluation/return-max          | 4696.1396    |
| evaluation/return-min          | 4600.142     |
| evaluation/return-std          | 31.857256    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.99         |
| model/origin_ret               | 85           |
| model/penalty_ret              | 81.6         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45878        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4638.8843    |
| perf/NormalizedReturn          | 1.01         |
| Q-avg                          | 188.34146    |
| Q-std                          | 156.48335    |
| Q_loss                         | 75.40059     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 708          |
| times/epoch_after_hook         | 3.61e-06     |
| times/epoch_before_hook        | 0.000126     |
| times/epoch_rollout_model      | 479          |
| times/evaluation_metrics       | 0.000538     |
| times/evaluation_paths         | 31.3         |
| times/timestep_after_hook      | 0.00388      |
| times/timestep_before_hook     | 0.00827      |
| times/train                    | 57.2         |
| timestep                       | 1000         |
| timesteps_total                | 709000       |
| train-steps                    | 709000       |
| training/Q/q1_loss             | 89.59635     |
| training/sac_pi/alpha          | 0.1628429    |
| training/sac_pi/alpha_loss     | -0.046944514 |
| training/sac_pi/logp_pi        | 5.9885244    |
| training/sac_pi/pi_entropy     | 3.3813667    |
| training/sac_pi/pi_global_norm | 1.508104     |
| training/sac_pi/policy_loss    | -210.98625   |
| training/sac_pi/std            | 0.5741064    |
| training/sac_pi/valid_num      | 4880.0       |
| training/sac_Q/q1              | 177.00389    |
| training/sac_Q/q2              | 173.727      |
| training/sac_Q/q2_loss         | 88.4588      |
| training/sac_Q/q_global_norm   | 199.27632    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1648219   |
| epoch                          | 709         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4881.362    |
| evaluation/return-max          | 4956.5947   |
| evaluation/return-min          | 4802.6016   |
| evaluation/return-std          | 53.147976   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45887       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4881.362    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 207.43823   |
| Q-std                          | 123.06971   |
| Q_loss                         | 75.87297    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 709         |
| times/epoch_after_hook         | 3.32e-06    |
| times/epoch_before_hook        | 0.000286    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000565    |
| times/evaluation_paths         | 30.4        |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 55.7        |
| timestep                       | 1000        |
| timesteps_total                | 710000      |
| train-steps                    | 710000      |
| training/Q/q1_loss             | 107.861145  |
| training/sac_pi/alpha          | 0.16483787  |
| training/sac_pi/alpha_loss     | -0.08366883 |
| training/sac_pi/logp_pi        | 4.251319    |
| training/sac_pi/pi_entropy     | 3.5614758   |
| training/sac_pi/pi_global_norm | 1.437666    |
| training/sac_pi/policy_loss    | -207.54999  |
| training/sac_pi/std            | 0.5168654   |
| training/sac_pi/valid_num      | 4958.0      |
| training/sac_Q/q1              | 194.10681   |
| training/sac_Q/q2              | 193.20068   |
| training/sac_Q/q2_loss         | 108.97667   |
| training/sac_Q/q_global_norm   | 229.62306   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16454308  |
| epoch                          | 710         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5013.869    |
| evaluation/return-max          | 5053.6963   |
| evaluation/return-min          | 4985.4854   |
| evaluation/return-std          | 19.60591    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45791       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5013.869    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 193.48494   |
| Q-std                          | 163.2925    |
| Q_loss                         | 98.446915   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 710         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000557    |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.00396     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 57.1        |
| timestep                       | 1000        |
| timesteps_total                | 711000      |
| train-steps                    | 711000      |
| training/Q/q1_loss             | 94.66397    |
| training/sac_pi/alpha          | 0.1645492   |
| training/sac_pi/alpha_loss     | -0.01963834 |
| training/sac_pi/logp_pi        | 5.2819576   |
| training/sac_pi/pi_entropy     | 3.2602794   |
| training/sac_pi/pi_global_norm | 1.633012    |
| training/sac_pi/policy_loss    | -209.6607   |
| training/sac_pi/std            | 0.52125275  |
| training/sac_pi/valid_num      | 4876.0      |
| training/sac_Q/q1              | 180.93301   |
| training/sac_Q/q2              | 182.66023   |
| training/sac_Q/q2_loss         | 96.06724    |
| training/sac_Q/q_global_norm   | 168.08635   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16716553 |
| epoch                          | 711        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4858.768   |
| evaluation/return-max          | 4953.7334  |
| evaluation/return-min          | 4771.918   |
| evaluation/return-std          | 53.805893  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45769      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4858.768   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 194.4139   |
| Q-std                          | 172.04143  |
| Q_loss                         | 88.03325   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 711        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000102   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000527   |
| times/evaluation_paths         | 31.2       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 56.6       |
| timestep                       | 1000       |
| timesteps_total                | 712000     |
| train-steps                    | 712000     |
| training/Q/q1_loss             | 111.42389  |
| training/sac_pi/alpha          | 0.1671658  |
| training/sac_pi/alpha_loss     | 0.10102765 |
| training/sac_pi/logp_pi        | 4.348501   |
| training/sac_pi/pi_entropy     | 3.565164   |
| training/sac_pi/pi_global_norm | 1.4141142  |
| training/sac_pi/policy_loss    | -201.78944 |
| training/sac_pi/std            | 0.520143   |
| training/sac_pi/valid_num      | 4927.0     |
| training/sac_Q/q1              | 182.32588  |
| training/sac_Q/q2              | 181.71748  |
| training/sac_Q/q2_loss         | 110.19602  |
| training/sac_Q/q_global_norm   | 216.81903  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1647925  |
| epoch                          | 712        |
| evaluation/episode-length-avg  | 936        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 365        |
| evaluation/episode-length-std  | 190        |
| evaluation/return-average      | 4589.9995  |
| evaluation/return-max          | 5005.1777  |
| evaluation/return-min          | 1453.8545  |
| evaluation/return-std          | 1046.9253  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45839      |
| perf/AverageLength             | 936        |
| perf/AverageReturn             | 4589.9995  |
| perf/NormalizedReturn          | 0.999      |
| Q-avg                          | 182.70393  |
| Q-std                          | 213.44244  |
| Q_loss                         | 108.46459  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 712        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000111   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000624   |
| times/evaluation_paths         | 29.3       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 57.4       |
| timestep                       | 1000       |
| timesteps_total                | 713000     |
| train-steps                    | 713000     |
| training/Q/q1_loss             | 84.61069   |
| training/sac_pi/alpha          | 0.16478881 |
| training/sac_pi/alpha_loss     | -0.1655742 |
| training/sac_pi/logp_pi        | 4.285495   |
| training/sac_pi/pi_entropy     | 3.5310009  |
| training/sac_pi/pi_global_norm | 1.5134134  |
| training/sac_pi/policy_loss    | -209.68257 |
| training/sac_pi/std            | 0.51985514 |
| training/sac_pi/valid_num      | 4933.0     |
| training/sac_Q/q1              | 189.42073  |
| training/sac_Q/q2              | 187.28969  |
| training/sac_Q/q2_loss         | 85.43857   |
| training/sac_Q/q_global_norm   | 226.67845  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17298801  |
| epoch                          | 713         |
| evaluation/episode-length-avg  | 827         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 134         |
| evaluation/episode-length-std  | 346         |
| evaluation/return-average      | 3933.1724   |
| evaluation/return-max          | 4877.8804   |
| evaluation/return-min          | 309.9621    |
| evaluation/return-std          | 1811.3557   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45872       |
| perf/AverageLength             | 827         |
| perf/AverageReturn             | 3933.1724   |
| perf/NormalizedReturn          | 0.856       |
| Q-avg                          | 190.17671   |
| Q-std                          | 191.63086   |
| Q_loss                         | 112.34298   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 713         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000373    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000563    |
| times/evaluation_paths         | 25.7        |
| times/timestep_after_hook      | 0.00382     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 57.8        |
| timestep                       | 1000        |
| timesteps_total                | 714000      |
| train-steps                    | 714000      |
| training/Q/q1_loss             | 71.87378    |
| training/sac_pi/alpha          | 0.17300011  |
| training/sac_pi/alpha_loss     | 0.009763348 |
| training/sac_pi/logp_pi        | 5.2871494   |
| training/sac_pi/pi_entropy     | 3.6417828   |
| training/sac_pi/pi_global_norm | 1.3949261   |
| training/sac_pi/policy_loss    | -207.58354  |
| training/sac_pi/std            | 0.5643385   |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 183.94046   |
| training/sac_Q/q2              | 183.0938    |
| training/sac_Q/q2_loss         | 70.983      |
| training/sac_Q/q_global_norm   | 239.50684   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17046715 |
| epoch                          | 714        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4574.4756  |
| evaluation/return-max          | 4620.682   |
| evaluation/return-min          | 4549.188   |
| evaluation/return-std          | 22.2911    |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45795      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4574.4756  |
| perf/NormalizedReturn          | 0.996      |
| Q-avg                          | 185.17598  |
| Q-std                          | 195.23967  |
| Q_loss                         | 95.01723   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 714        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000517   |
| times/evaluation_paths         | 31.3       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 57.4       |
| timestep                       | 1000       |
| timesteps_total                | 715000     |
| train-steps                    | 715000     |
| training/Q/q1_loss             | 90.3469    |
| training/sac_pi/alpha          | 0.17043637 |
| training/sac_pi/alpha_loss     | 0.26446712 |
| training/sac_pi/logp_pi        | 5.2651176  |
| training/sac_pi/pi_entropy     | 3.4317708  |
| training/sac_pi/pi_global_norm | 1.65674    |
| training/sac_pi/policy_loss    | -206.68193 |
| training/sac_pi/std            | 0.5134509  |
| training/sac_pi/valid_num      | 4961.0     |
| training/sac_Q/q1              | 188.17595  |
| training/sac_Q/q2              | 186.8143   |
| training/sac_Q/q2_loss         | 90.17079   |
| training/sac_Q/q_global_norm   | 201.86063  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16200091 |
| epoch                          | 715        |
| evaluation/episode-length-avg  | 666        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 162        |
| evaluation/episode-length-std  | 409        |
| evaluation/return-average      | 3046.9507  |
| evaluation/return-max          | 4872.6836  |
| evaluation/return-min          | 474.98975  |
| evaluation/return-std          | 2094.5764  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45762      |
| perf/AverageLength             | 666        |
| perf/AverageReturn             | 3046.9507  |
| perf/NormalizedReturn          | 0.663      |
| Q-avg                          | 194.97577  |
| Q-std                          | 162.68636  |
| Q_loss                         | 89.42966   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 715        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.00011    |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000541   |
| times/evaluation_paths         | 20.7       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 58.1       |
| timestep                       | 1000       |
| timesteps_total                | 716000     |
| train-steps                    | 716000     |
| training/Q/q1_loss             | 120.778694 |
| training/sac_pi/alpha          | 0.16201282 |
| training/sac_pi/alpha_loss     | 0.28398255 |
| training/sac_pi/logp_pi        | 4.3590813  |
| training/sac_pi/pi_entropy     | 3.2289956  |
| training/sac_pi/pi_global_norm | 1.575416   |
| training/sac_pi/policy_loss    | -211.65738 |
| training/sac_pi/std            | 0.46655643 |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 201.86035  |
| training/sac_Q/q2              | 201.77731  |
| training/sac_Q/q2_loss         | 121.760605 |
| training/sac_Q/q_global_norm   | 357.67975  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16497765   |
| epoch                          | 716          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4911.85      |
| evaluation/return-max          | 4972.633     |
| evaluation/return-min          | 4838.9185    |
| evaluation/return-std          | 43.352364    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.91         |
| model/origin_ret               | 84.4         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45765        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4911.85      |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 188.94229    |
| Q-std                          | 175.21579    |
| Q_loss                         | 105.311226   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 716          |
| times/epoch_after_hook         | 1.77e-06     |
| times/epoch_before_hook        | 0.00013      |
| times/epoch_rollout_model      | 477          |
| times/evaluation_metrics       | 0.000644     |
| times/evaluation_paths         | 30.6         |
| times/timestep_after_hook      | 0.00374      |
| times/timestep_before_hook     | 0.00822      |
| times/train                    | 57           |
| timestep                       | 1000         |
| timesteps_total                | 717000       |
| train-steps                    | 717000       |
| training/Q/q1_loss             | 96.99149     |
| training/sac_pi/alpha          | 0.16497697   |
| training/sac_pi/alpha_loss     | -0.107226945 |
| training/sac_pi/logp_pi        | 4.548808     |
| training/sac_pi/pi_entropy     | 3.3034797    |
| training/sac_pi/pi_global_norm | 1.6109058    |
| training/sac_pi/policy_loss    | -207.02142   |
| training/sac_pi/std            | 0.48469797   |
| training/sac_pi/valid_num      | 4951.0       |
| training/sac_Q/q1              | 192.97672    |
| training/sac_Q/q2              | 192.57657    |
| training/sac_Q/q2_loss         | 97.06783     |
| training/sac_Q/q_global_norm   | 245.37076    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16385327  |
| epoch                          | 717         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4906.812    |
| evaluation/return-max          | 4930.0415   |
| evaluation/return-min          | 4857.983    |
| evaluation/return-std          | 19.768003   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45710       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4906.812    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 185.52774   |
| Q-std                          | 189.74109   |
| Q_loss                         | 111.18954   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 717         |
| times/epoch_after_hook         | 2.08e-06    |
| times/epoch_before_hook        | 0.00028     |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000529    |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 57.5        |
| timestep                       | 1000        |
| timesteps_total                | 718000      |
| train-steps                    | 718000      |
| training/Q/q1_loss             | 108.71966   |
| training/sac_pi/alpha          | 0.16384423  |
| training/sac_pi/alpha_loss     | 0.008642156 |
| training/sac_pi/logp_pi        | 5.002375    |
| training/sac_pi/pi_entropy     | 3.6304336   |
| training/sac_pi/pi_global_norm | 2.0353894   |
| training/sac_pi/policy_loss    | -200.05307  |
| training/sac_pi/std            | 0.5513729   |
| training/sac_pi/valid_num      | 4933.0      |
| training/sac_Q/q1              | 179.20035   |
| training/sac_Q/q2              | 176.9385    |
| training/sac_Q/q2_loss         | 108.63973   |
| training/sac_Q/q_global_norm   | 178.19936   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15957706 |
| epoch                          | 718        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4744.9326  |
| evaluation/return-max          | 4947.7363  |
| evaluation/return-min          | 4594.2725  |
| evaluation/return-std          | 108.86909  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45784      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4744.9326  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 189.78178  |
| Q-std                          | 190.39943  |
| Q_loss                         | 121.261284 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 718        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000532   |
| times/evaluation_paths         | 31.8       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 57.3       |
| timestep                       | 1000       |
| timesteps_total                | 719000     |
| train-steps                    | 719000     |
| training/Q/q1_loss             | 112.92835  |
| training/sac_pi/alpha          | 0.15957761 |
| training/sac_pi/alpha_loss     | 0.17475809 |
| training/sac_pi/logp_pi        | 4.4028096  |
| training/sac_pi/pi_entropy     | 3.2503922  |
| training/sac_pi/pi_global_norm | 1.7602004  |
| training/sac_pi/policy_loss    | -212.30327 |
| training/sac_pi/std            | 0.4767067  |
| training/sac_pi/valid_num      | 4994.0     |
| training/sac_Q/q1              | 199.51779  |
| training/sac_Q/q2              | 196.78181  |
| training/sac_Q/q2_loss         | 113.60014  |
| training/sac_Q/q_global_norm   | 182.80579  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16398945  |
| epoch                          | 719         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5146.601    |
| evaluation/return-max          | 5174.57     |
| evaluation/return-min          | 5094.5234   |
| evaluation/return-std          | 22.81049    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45802       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5146.601    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 196.66158   |
| Q-std                          | 178.30022   |
| Q_loss                         | 87.88898    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 719         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 501         |
| times/evaluation_metrics       | 0.0006      |
| times/evaluation_paths         | 30.2        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00794     |
| times/train                    | 56.5        |
| timestep                       | 1000        |
| timesteps_total                | 720000      |
| train-steps                    | 720000      |
| training/Q/q1_loss             | 85.01744    |
| training/sac_pi/alpha          | 0.164023    |
| training/sac_pi/alpha_loss     | -0.18812814 |
| training/sac_pi/logp_pi        | 3.6081996   |
| training/sac_pi/pi_entropy     | 3.4995728   |
| training/sac_pi/pi_global_norm | 1.3956459   |
| training/sac_pi/policy_loss    | -209.12756  |
| training/sac_pi/std            | 0.4790304   |
| training/sac_pi/valid_num      | 5010.0      |
| training/sac_Q/q1              | 200.93459   |
| training/sac_Q/q2              | 200.7544    |
| training/sac_Q/q2_loss         | 85.11114    |
| training/sac_Q/q_global_norm   | 247.63905   |
---------------------------------------------------------------------------------
[WARN] 720 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.16814391   |
| epoch                          | 720          |
| evaluation/episode-length-avg  | 886          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 386          |
| evaluation/episode-length-std  | 229          |
| evaluation/return-average      | 3964.89      |
| evaluation/return-max          | 4650.37      |
| evaluation/return-min          | 1427.8746    |
| evaluation/return-std          | 1174.5842    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.96         |
| model/origin_ret               | 85.1         |
| model/penalty_ret              | 81.7         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45824        |
| perf/AverageLength             | 886          |
| perf/AverageReturn             | 3964.89      |
| perf/NormalizedReturn          | 0.863        |
| Q-avg                          | 188.15645    |
| Q-std                          | 176.08688    |
| Q_loss                         | 93.857025    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 720          |
| times/epoch_after_hook         | 1.79e-06     |
| times/epoch_before_hook        | 0.000134     |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.000575     |
| times/evaluation_paths         | 28           |
| times/timestep_after_hook      | 0.00392      |
| times/timestep_before_hook     | 0.0084       |
| times/train                    | 58.6         |
| timestep                       | 1000         |
| timesteps_total                | 721000       |
| train-steps                    | 721000       |
| training/Q/q1_loss             | 95.522125    |
| training/sac_pi/alpha          | 0.16816035   |
| training/sac_pi/alpha_loss     | -0.026867317 |
| training/sac_pi/logp_pi        | 4.689641     |
| training/sac_pi/pi_entropy     | 3.6980286    |
| training/sac_pi/pi_global_norm | 1.4936457    |
| training/sac_pi/policy_loss    | -209.50963   |
| training/sac_pi/std            | 0.5435253    |
| training/sac_pi/valid_num      | 4922.0       |
| training/sac_Q/q1              | 193.74564    |
| training/sac_Q/q2              | 190.702      |
| training/sac_Q/q2_loss         | 94.84127     |
| training/sac_Q/q_global_norm   | 246.03137    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16451989  |
| epoch                          | 721         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4520.724    |
| evaluation/return-max          | 4583.663    |
| evaluation/return-min          | 4423.6274   |
| evaluation/return-std          | 48.945312   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45821       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4520.724    |
| perf/NormalizedReturn          | 0.984       |
| Q-avg                          | 184.27255   |
| Q-std                          | 188.47243   |
| Q_loss                         | 123.19537   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 721         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000285    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000525    |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 57.2        |
| timestep                       | 1000        |
| timesteps_total                | 722000      |
| train-steps                    | 722000      |
| training/Q/q1_loss             | 100.691795  |
| training/sac_pi/alpha          | 0.1645229   |
| training/sac_pi/alpha_loss     | -0.11865006 |
| training/sac_pi/logp_pi        | 3.8819957   |
| training/sac_pi/pi_entropy     | 3.3950603   |
| training/sac_pi/pi_global_norm | 1.5416992   |
| training/sac_pi/policy_loss    | -209.95586  |
| training/sac_pi/std            | 0.48322043  |
| training/sac_pi/valid_num      | 4916.0      |
| training/sac_Q/q1              | 195.20102   |
| training/sac_Q/q2              | 196.00935   |
| training/sac_Q/q2_loss         | 99.34722    |
| training/sac_Q/q_global_norm   | 203.63106   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17334636  |
| epoch                          | 722         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4926.683    |
| evaluation/return-max          | 4983.9907   |
| evaluation/return-min          | 4840.536    |
| evaluation/return-std          | 45.91943    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45957       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4926.683    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 194.191     |
| Q-std                          | 189.82973   |
| Q_loss                         | 99.925896   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 722         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000107    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000565    |
| times/evaluation_paths         | 32.4        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 57.3        |
| timestep                       | 1000        |
| timesteps_total                | 723000      |
| train-steps                    | 723000      |
| training/Q/q1_loss             | 93.859314   |
| training/sac_pi/alpha          | 0.17334667  |
| training/sac_pi/alpha_loss     | -0.06255387 |
| training/sac_pi/logp_pi        | 4.5985103   |
| training/sac_pi/pi_entropy     | 3.5821025   |
| training/sac_pi/pi_global_norm | 1.6319144   |
| training/sac_pi/policy_loss    | -207.90598  |
| training/sac_pi/std            | 0.52073133  |
| training/sac_pi/valid_num      | 4952.0      |
| training/sac_Q/q1              | 190.30728   |
| training/sac_Q/q2              | 188.94382   |
| training/sac_Q/q2_loss         | 93.98933    |
| training/sac_Q/q_global_norm   | 296.81952   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1769059  |
| epoch                          | 723        |
| evaluation/episode-length-avg  | 488        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 138        |
| evaluation/episode-length-std  | 418        |
| evaluation/return-average      | 2098.4336  |
| evaluation/return-max          | 4732.767   |
| evaluation/return-min          | 348.98077  |
| evaluation/return-std          | 2119.2544  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45735      |
| perf/AverageLength             | 488        |
| perf/AverageReturn             | 2098.4336  |
| perf/NormalizedReturn          | 0.457      |
| Q-avg                          | 187.83577  |
| Q-std                          | 169.7402   |
| Q_loss                         | 103.858154 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 723        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000571   |
| times/evaluation_paths         | 15         |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 57.9       |
| timestep                       | 1000       |
| timesteps_total                | 724000     |
| train-steps                    | 724000     |
| training/Q/q1_loss             | 95.389244  |
| training/sac_pi/alpha          | 0.17690867 |
| training/sac_pi/alpha_loss     | -0.1933575 |
| training/sac_pi/logp_pi        | 4.010684   |
| training/sac_pi/pi_entropy     | 3.5096138  |
| training/sac_pi/pi_global_norm | 1.7768111  |
| training/sac_pi/policy_loss    | -211.92653 |
| training/sac_pi/std            | 0.48601824 |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 202.62305  |
| training/sac_Q/q2              | 201.8128   |
| training/sac_Q/q2_loss         | 95.11367   |
| training/sac_Q/q_global_norm   | 251.62856  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17146039  |
| epoch                          | 724         |
| evaluation/episode-length-avg  | 406         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 137         |
| evaluation/episode-length-std  | 389         |
| evaluation/return-average      | 1801.0387   |
| evaluation/return-max          | 4961.571    |
| evaluation/return-min          | 400.91144   |
| evaluation/return-std          | 2052.399    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45832       |
| perf/AverageLength             | 406         |
| perf/AverageReturn             | 1801.0387   |
| perf/NormalizedReturn          | 0.392       |
| Q-avg                          | 200.42424   |
| Q-std                          | 149.51993   |
| Q_loss                         | 76.11963    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 724         |
| times/epoch_after_hook         | 2.03e-06    |
| times/epoch_before_hook        | 0.000136    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000412    |
| times/evaluation_paths         | 12.4        |
| times/timestep_after_hook      | 0.00378     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 57          |
| timestep                       | 1000        |
| timesteps_total                | 725000      |
| train-steps                    | 725000      |
| training/Q/q1_loss             | 89.83707    |
| training/sac_pi/alpha          | 0.1714786   |
| training/sac_pi/alpha_loss     | -0.07185215 |
| training/sac_pi/logp_pi        | 4.3606133   |
| training/sac_pi/pi_entropy     | 3.3888493   |
| training/sac_pi/pi_global_norm | 1.667378    |
| training/sac_pi/policy_loss    | -204.6902   |
| training/sac_pi/std            | 0.485617    |
| training/sac_pi/valid_num      | 4964.0      |
| training/sac_Q/q1              | 192.69661   |
| training/sac_Q/q2              | 192.90211   |
| training/sac_Q/q2_loss         | 89.57021    |
| training/sac_Q/q_global_norm   | 168.25435   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16786236 |
| epoch                          | 725        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4995.28    |
| evaluation/return-max          | 5020.6943  |
| evaluation/return-min          | 4957.2915  |
| evaluation/return-std          | 22.098543  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45957      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4995.28    |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 191.24121  |
| Q-std                          | 176.87605  |
| Q_loss                         | 99.97563   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 725        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000284   |
| times/epoch_rollout_model      | 475        |
| times/evaluation_metrics       | 0.000544   |
| times/evaluation_paths         | 31.5       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 58.4       |
| timestep                       | 1000       |
| timesteps_total                | 726000     |
| train-steps                    | 726000     |
| training/Q/q1_loss             | 116.37118  |
| training/sac_pi/alpha          | 0.16786587 |
| training/sac_pi/alpha_loss     | 0.0833936  |
| training/sac_pi/logp_pi        | 4.722602   |
| training/sac_pi/pi_entropy     | 3.5712752  |
| training/sac_pi/pi_global_norm | 1.7425239  |
| training/sac_pi/policy_loss    | -196.56851 |
| training/sac_pi/std            | 0.52578074 |
| training/sac_pi/valid_num      | 4939.0     |
| training/sac_Q/q1              | 178.73936  |
| training/sac_Q/q2              | 179.15446  |
| training/sac_Q/q2_loss         | 116.02217  |
| training/sac_Q/q_global_norm   | 228.1171   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16659865 |
| epoch                          | 726        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5133.189   |
| evaluation/return-max          | 5176.591   |
| evaluation/return-min          | 5092.967   |
| evaluation/return-std          | 23.002678  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45876      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5133.189   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 187.50438  |
| Q-std                          | 184.88156  |
| Q_loss                         | 98.570175  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 726        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000694   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00417    |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 55.4       |
| timestep                       | 1000       |
| timesteps_total                | 727000     |
| train-steps                    | 727000     |
| training/Q/q1_loss             | 87.056335  |
| training/sac_pi/alpha          | 0.16665095 |
| training/sac_pi/alpha_loss     | -0.4351179 |
| training/sac_pi/logp_pi        | 4.342965   |
| training/sac_pi/pi_entropy     | 3.5054169  |
| training/sac_pi/pi_global_norm | 1.5910667  |
| training/sac_pi/policy_loss    | -209.88141 |
| training/sac_pi/std            | 0.502688   |
| training/sac_pi/valid_num      | 4940.0     |
| training/sac_Q/q1              | 194.45853  |
| training/sac_Q/q2              | 193.10767  |
| training/sac_Q/q2_loss         | 85.7572    |
| training/sac_Q/q_global_norm   | 229.3884   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16482681   |
| epoch                          | 727          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4875.1353    |
| evaluation/return-max          | 4899.4595    |
| evaluation/return-min          | 4855.0693    |
| evaluation/return-std          | 12.340468    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.97         |
| model/origin_ret               | 84.7         |
| model/penalty_ret              | 81.6         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45870        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4875.1353    |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 189.25435    |
| Q-std                          | 220.18135    |
| Q_loss                         | 97.92024     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 727          |
| times/epoch_after_hook         | 2e-06        |
| times/epoch_before_hook        | 0.000152     |
| times/epoch_rollout_model      | 478          |
| times/evaluation_metrics       | 0.000615     |
| times/evaluation_paths         | 30.7         |
| times/timestep_after_hook      | 0.00392      |
| times/timestep_before_hook     | 0.00842      |
| times/train                    | 58.4         |
| timestep                       | 1000         |
| timesteps_total                | 728000       |
| train-steps                    | 728000       |
| training/Q/q1_loss             | 92.335236    |
| training/sac_pi/alpha          | 0.16482152   |
| training/sac_pi/alpha_loss     | -0.060171682 |
| training/sac_pi/logp_pi        | 3.9097443    |
| training/sac_pi/pi_entropy     | 3.4064713    |
| training/sac_pi/pi_global_norm | 1.6538113    |
| training/sac_pi/policy_loss    | -203.55286   |
| training/sac_pi/std            | 0.480142     |
| training/sac_pi/valid_num      | 5004.0       |
| training/sac_Q/q1              | 195.96237    |
| training/sac_Q/q2              | 196.43985    |
| training/sac_Q/q2_loss         | 90.966354    |
| training/sac_Q/q_global_norm   | 196.15527    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16221695  |
| epoch                          | 728         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4837.6553   |
| evaluation/return-max          | 4904.0503   |
| evaluation/return-min          | 4744.8857   |
| evaluation/return-std          | 41.60553    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45784       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4837.6553   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 185.9946    |
| Q-std                          | 134.38872   |
| Q_loss                         | 113.46353   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 728         |
| times/epoch_after_hook         | 1.98e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000596    |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 56.3        |
| timestep                       | 1000        |
| timesteps_total                | 729000      |
| train-steps                    | 729000      |
| training/Q/q1_loss             | 107.483665  |
| training/sac_pi/alpha          | 0.16222997  |
| training/sac_pi/alpha_loss     | 0.018086163 |
| training/sac_pi/logp_pi        | 5.1320505   |
| training/sac_pi/pi_entropy     | 3.0334134   |
| training/sac_pi/pi_global_norm | 1.3976083   |
| training/sac_pi/policy_loss    | -203.5802   |
| training/sac_pi/std            | 0.4626812   |
| training/sac_pi/valid_num      | 4909.0      |
| training/sac_Q/q1              | 187.52779   |
| training/sac_Q/q2              | 186.56477   |
| training/sac_Q/q2_loss         | 108.33655   |
| training/sac_Q/q_global_norm   | 223.17957   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16324888 |
| epoch                          | 729        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4804.54    |
| evaluation/return-max          | 4828.7607  |
| evaluation/return-min          | 4770.0464  |
| evaluation/return-std          | 16.71487   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45851      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4804.54    |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 197.73904  |
| Q-std                          | 171.51851  |
| Q_loss                         | 94.90549   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 729        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000279   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000522   |
| times/evaluation_paths         | 31.2       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 57.6       |
| timestep                       | 1000       |
| timesteps_total                | 730000     |
| train-steps                    | 730000     |
| training/Q/q1_loss             | 80.71055   |
| training/sac_pi/alpha          | 0.16324867 |
| training/sac_pi/alpha_loss     | 0.10589658 |
| training/sac_pi/logp_pi        | 4.593782   |
| training/sac_pi/pi_entropy     | 3.3479562  |
| training/sac_pi/pi_global_norm | 1.7050072  |
| training/sac_pi/policy_loss    | -207.02682 |
| training/sac_pi/std            | 0.49858335 |
| training/sac_pi/valid_num      | 4959.0     |
| training/sac_Q/q1              | 194.75327  |
| training/sac_Q/q2              | 191.76993  |
| training/sac_Q/q2_loss         | 79.53681   |
| training/sac_Q/q_global_norm   | 203.9565   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16386464  |
| epoch                          | 730         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4958.7153   |
| evaluation/return-max          | 5029.7163   |
| evaluation/return-min          | 4894.4746   |
| evaluation/return-std          | 40.41995    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45907       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4958.7153   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 196.6082    |
| Q-std                          | 148.1189    |
| Q_loss                         | 101.64794   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 730         |
| times/epoch_after_hook         | 4.13e-06    |
| times/epoch_before_hook        | 0.000108    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000522    |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.00385     |
| times/timestep_before_hook     | 0.00796     |
| times/train                    | 57.8        |
| timestep                       | 1000        |
| timesteps_total                | 731000      |
| train-steps                    | 731000      |
| training/Q/q1_loss             | 108.58895   |
| training/sac_pi/alpha          | 0.16387168  |
| training/sac_pi/alpha_loss     | -0.11491368 |
| training/sac_pi/logp_pi        | 4.015812    |
| training/sac_pi/pi_entropy     | 3.3862567   |
| training/sac_pi/pi_global_norm | 1.467987    |
| training/sac_pi/policy_loss    | -211.01797  |
| training/sac_pi/std            | 0.47301134  |
| training/sac_pi/valid_num      | 4974.0      |
| training/sac_Q/q1              | 202.81943   |
| training/sac_Q/q2              | 202.37338   |
| training/sac_Q/q2_loss         | 110.20991   |
| training/sac_Q/q_global_norm   | 224.78545   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17148834  |
| epoch                          | 731         |
| evaluation/episode-length-avg  | 154         |
| evaluation/episode-length-max  | 166         |
| evaluation/episode-length-min  | 147         |
| evaluation/episode-length-std  | 5.68        |
| evaluation/return-average      | 377.45416   |
| evaluation/return-max          | 414.70898   |
| evaluation/return-min          | 351.08658   |
| evaluation/return-std          | 18.449135   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45886       |
| perf/AverageLength             | 154         |
| perf/AverageReturn             | 377.45416   |
| perf/NormalizedReturn          | 0.0819      |
| Q-avg                          | 193.3822    |
| Q-std                          | 168.70772   |
| Q_loss                         | 98.76059    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 731         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000433    |
| times/evaluation_paths         | 4.8         |
| times/timestep_after_hook      | 0.00381     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 56.5        |
| timestep                       | 1000        |
| timesteps_total                | 732000      |
| train-steps                    | 732000      |
| training/Q/q1_loss             | 73.296906   |
| training/sac_pi/alpha          | 0.17149486  |
| training/sac_pi/alpha_loss     | -0.26446715 |
| training/sac_pi/logp_pi        | 3.4294472   |
| training/sac_pi/pi_entropy     | 3.5635269   |
| training/sac_pi/pi_global_norm | 1.5329695   |
| training/sac_pi/policy_loss    | -211.22202  |
| training/sac_pi/std            | 0.4792946   |
| training/sac_pi/valid_num      | 5013.0      |
| training/sac_Q/q1              | 203.83513   |
| training/sac_Q/q2              | 202.43202   |
| training/sac_Q/q2_loss         | 73.21803    |
| training/sac_Q/q_global_norm   | 153.98482   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17426564 |
| epoch                          | 732        |
| evaluation/episode-length-avg  | 830        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 151        |
| evaluation/episode-length-std  | 339        |
| evaluation/return-average      | 4004.476   |
| evaluation/return-max          | 4961.749   |
| evaluation/return-min          | 384.12897  |
| evaluation/return-std          | 1809.386   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45899      |
| perf/AverageLength             | 830        |
| perf/AverageReturn             | 4004.476   |
| perf/NormalizedReturn          | 0.872      |
| Q-avg                          | 197.90903  |
| Q-std                          | 155.94914  |
| Q_loss                         | 102.05093  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 732        |
| times/epoch_after_hook         | 1.12e-05   |
| times/epoch_before_hook        | 6.62e-05   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000531   |
| times/evaluation_paths         | 26.6       |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 57.2       |
| timestep                       | 1000       |
| timesteps_total                | 733000     |
| train-steps                    | 733000     |
| training/Q/q1_loss             | 105.445    |
| training/sac_pi/alpha          | 0.17429619 |
| training/sac_pi/alpha_loss     | 0.1011229  |
| training/sac_pi/logp_pi        | 4.9181504  |
| training/sac_pi/pi_entropy     | 3.3794968  |
| training/sac_pi/pi_global_norm | 1.7637569  |
| training/sac_pi/policy_loss    | -203.96161 |
| training/sac_pi/std            | 0.49710968 |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 187.61948  |
| training/sac_Q/q2              | 187.25493  |
| training/sac_Q/q2_loss         | 104.78032  |
| training/sac_Q/q_global_norm   | 195.9493   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17069903 |
| epoch                          | 733        |
| evaluation/episode-length-avg  | 827        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 126        |
| evaluation/episode-length-std  | 346        |
| evaluation/return-average      | 3510.3638  |
| evaluation/return-max          | 4384.624   |
| evaluation/return-min          | 259.40582  |
| evaluation/return-std          | 1614.0764  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45932      |
| perf/AverageLength             | 827        |
| perf/AverageReturn             | 3510.3638  |
| perf/NormalizedReturn          | 0.764      |
| Q-avg                          | 186.61392  |
| Q-std                          | 178.27858  |
| Q_loss                         | 100.541504 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 733        |
| times/epoch_after_hook         | 1.97e-06   |
| times/epoch_before_hook        | 0.000281   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000542   |
| times/evaluation_paths         | 25.4       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 56.5       |
| timestep                       | 1000       |
| timesteps_total                | 734000     |
| train-steps                    | 734000     |
| training/Q/q1_loss             | 93.07266   |
| training/sac_pi/alpha          | 0.17071149 |
| training/sac_pi/alpha_loss     | 0.1767762  |
| training/sac_pi/logp_pi        | 4.247417   |
| training/sac_pi/pi_entropy     | 3.530896   |
| training/sac_pi/pi_global_norm | 1.4974785  |
| training/sac_pi/policy_loss    | -207.93471 |
| training/sac_pi/std            | 0.51434964 |
| training/sac_pi/valid_num      | 4944.0     |
| training/sac_Q/q1              | 188.33357  |
| training/sac_Q/q2              | 188.95692  |
| training/sac_Q/q2_loss         | 94.402214  |
| training/sac_Q/q_global_norm   | 230.20541  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16683169  |
| epoch                          | 734         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4838.6787   |
| evaluation/return-max          | 4872.119    |
| evaluation/return-min          | 4797.091    |
| evaluation/return-std          | 21.954054   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45935       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4838.6787   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 189.06352   |
| Q-std                          | 182.64381   |
| Q_loss                         | 111.20229   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 734         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000138    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000619    |
| times/evaluation_paths         | 31.7        |
| times/timestep_after_hook      | 0.00387     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 58.4        |
| timestep                       | 1000        |
| timesteps_total                | 735000      |
| train-steps                    | 735000      |
| training/Q/q1_loss             | 100.30822   |
| training/sac_pi/alpha          | 0.16684186  |
| training/sac_pi/alpha_loss     | -0.23334976 |
| training/sac_pi/logp_pi        | 4.823681    |
| training/sac_pi/pi_entropy     | 3.4220023   |
| training/sac_pi/pi_global_norm | 1.9449656   |
| training/sac_pi/policy_loss    | -209.70941  |
| training/sac_pi/std            | 0.51231503  |
| training/sac_pi/valid_num      | 4885.0      |
| training/sac_Q/q1              | 191.68394   |
| training/sac_Q/q2              | 187.52145   |
| training/sac_Q/q2_loss         | 100.29279   |
| training/sac_Q/q_global_norm   | 188.98332   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16910544   |
| epoch                          | 735          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4696.339     |
| evaluation/return-max          | 4813.209     |
| evaluation/return-min          | 4315.63      |
| evaluation/return-std          | 137.93297    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.96         |
| model/origin_ret               | 84.4         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45766        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4696.339     |
| perf/NormalizedReturn          | 1.02         |
| Q-avg                          | 183.65483    |
| Q-std                          | 210.75175    |
| Q_loss                         | 105.69748    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 735          |
| times/epoch_after_hook         | 1.99e-06     |
| times/epoch_before_hook        | 0.000148     |
| times/epoch_rollout_model      | 482          |
| times/evaluation_metrics       | 0.000593     |
| times/evaluation_paths         | 30.8         |
| times/timestep_after_hook      | 0.00365      |
| times/timestep_before_hook     | 0.00793      |
| times/train                    | 56           |
| timestep                       | 1000         |
| timesteps_total                | 736000       |
| train-steps                    | 736000       |
| training/Q/q1_loss             | 103.75891    |
| training/sac_pi/alpha          | 0.16909239   |
| training/sac_pi/alpha_loss     | -0.057579946 |
| training/sac_pi/logp_pi        | 5.2525764    |
| training/sac_pi/pi_entropy     | 3.6509376    |
| training/sac_pi/pi_global_norm | 1.5994666    |
| training/sac_pi/policy_loss    | -204.01196   |
| training/sac_pi/std            | 0.56324524   |
| training/sac_pi/valid_num      | 4884.0       |
| training/sac_Q/q1              | 178.28111    |
| training/sac_Q/q2              | 174.98618    |
| training/sac_Q/q2_loss         | 102.74486    |
| training/sac_Q/q_global_norm   | 206.19914    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1651778  |
| epoch                          | 736        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5060.881   |
| evaluation/return-max          | 5095.34    |
| evaluation/return-min          | 5015.7637  |
| evaluation/return-std          | 18.963797  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45822      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5060.881   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 180.14876  |
| Q-std                          | 202.873    |
| Q_loss                         | 82.69911   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 736        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000535   |
| times/evaluation_paths         | 31.2       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 57.1       |
| timestep                       | 1000       |
| timesteps_total                | 737000     |
| train-steps                    | 737000     |
| training/Q/q1_loss             | 95.24559   |
| training/sac_pi/alpha          | 0.16518533 |
| training/sac_pi/alpha_loss     | -0.3317602 |
| training/sac_pi/logp_pi        | 4.232623   |
| training/sac_pi/pi_entropy     | 3.5847511  |
| training/sac_pi/pi_global_norm | 1.3852088  |
| training/sac_pi/policy_loss    | -208.55641 |
| training/sac_pi/std            | 0.51752144 |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 188.69559  |
| training/sac_Q/q2              | 184.82327  |
| training/sac_Q/q2_loss         | 93.86843   |
| training/sac_Q/q_global_norm   | 157.09846  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16290984 |
| epoch                          | 737        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4946.165   |
| evaluation/return-max          | 5014.4336  |
| evaluation/return-min          | 4880.827   |
| evaluation/return-std          | 44.431675  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45752      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4946.165   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 198.74126  |
| Q-std                          | 135.47319  |
| Q_loss                         | 105.94067  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 737        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000284   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000623   |
| times/evaluation_paths         | 31.5       |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 57.3       |
| timestep                       | 1000       |
| timesteps_total                | 738000     |
| train-steps                    | 738000     |
| training/Q/q1_loss             | 83.78642   |
| training/sac_pi/alpha          | 0.16293846 |
| training/sac_pi/alpha_loss     | -0.5293683 |
| training/sac_pi/logp_pi        | 4.3336163  |
| training/sac_pi/pi_entropy     | 3.511095   |
| training/sac_pi/pi_global_norm | 1.4627542  |
| training/sac_pi/policy_loss    | -204.80002 |
| training/sac_pi/std            | 0.5286698  |
| training/sac_pi/valid_num      | 4963.0     |
| training/sac_Q/q1              | 186.81247  |
| training/sac_Q/q2              | 187.16281  |
| training/sac_Q/q2_loss         | 84.26941   |
| training/sac_Q/q_global_norm   | 279.9145   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16306126  |
| epoch                          | 738         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4696.4336   |
| evaluation/return-max          | 4757.577    |
| evaluation/return-min          | 4652.564    |
| evaluation/return-std          | 39.31634    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45914       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4696.4336   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 191.50641   |
| Q-std                          | 212.06409   |
| Q_loss                         | 97.65139    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 738         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 476         |
| times/evaluation_metrics       | 0.000523    |
| times/evaluation_paths         | 31.2        |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.00834     |
| times/train                    | 57.9        |
| timestep                       | 1000        |
| timesteps_total                | 739000      |
| train-steps                    | 739000      |
| training/Q/q1_loss             | 97.16892    |
| training/sac_pi/alpha          | 0.16305843  |
| training/sac_pi/alpha_loss     | -0.11275424 |
| training/sac_pi/logp_pi        | 4.012634    |
| training/sac_pi/pi_entropy     | 3.400206    |
| training/sac_pi/pi_global_norm | 1.4242432   |
| training/sac_pi/policy_loss    | -206.97726  |
| training/sac_pi/std            | 0.4971404   |
| training/sac_pi/valid_num      | 4942.0      |
| training/sac_Q/q1              | 195.56291   |
| training/sac_Q/q2              | 194.51694   |
| training/sac_Q/q2_loss         | 96.3202     |
| training/sac_Q/q_global_norm   | 155.62752   |
---------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.17063569    |
| epoch                          | 739           |
| evaluation/episode-length-avg  | 408           |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 150           |
| evaluation/episode-length-std  | 388           |
| evaluation/return-average      | 1831.0367     |
| evaluation/return-max          | 4928.787      |
| evaluation/return-min          | 506.6197      |
| evaluation/return-std          | 2002.9366     |
| model/max_penalty              | 7.34          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 2.91          |
| model/origin_ret               | 83.5          |
| model/penalty_ret              | 81            |
| model/val_loss                 | 0.35430613    |
| model/valid_num                | 45949         |
| perf/AverageLength             | 408           |
| perf/AverageReturn             | 1831.0367     |
| perf/NormalizedReturn          | 0.399         |
| Q-avg                          | 193.39835     |
| Q-std                          | 168.95909     |
| Q_loss                         | 100.54964     |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 739           |
| times/epoch_after_hook         | 2.17e-06      |
| times/epoch_before_hook        | 0.000106      |
| times/epoch_rollout_model      | 477           |
| times/evaluation_metrics       | 0.000503      |
| times/evaluation_paths         | 13.4          |
| times/timestep_after_hook      | 0.00401       |
| times/timestep_before_hook     | 0.00843       |
| times/train                    | 58.1          |
| timestep                       | 1000          |
| timesteps_total                | 740000        |
| train-steps                    | 740000        |
| training/Q/q1_loss             | 81.00572      |
| training/sac_pi/alpha          | 0.17061076    |
| training/sac_pi/alpha_loss     | -0.0026188653 |
| training/sac_pi/logp_pi        | 4.6106153     |
| training/sac_pi/pi_entropy     | 3.5104065     |
| training/sac_pi/pi_global_norm | 1.574064      |
| training/sac_pi/policy_loss    | -213.04387    |
| training/sac_pi/std            | 0.5291448     |
| training/sac_pi/valid_num      | 4940.0        |
| training/sac_Q/q1              | 193.67091     |
| training/sac_Q/q2              | 193.16315     |
| training/sac_Q/q2_loss         | 82.06433      |
| training/sac_Q/q_global_norm   | 166.47324     |
-----------------------------------------------------------------------------------
[WARN] 740 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16585883  |
| epoch                          | 740         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4843.2856   |
| evaluation/return-max          | 4868.393    |
| evaluation/return-min          | 4820.66     |
| evaluation/return-std          | 18.19613    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45926       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4843.2856   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 204.02148   |
| Q-std                          | 150.8449    |
| Q_loss                         | 109.77691   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 740         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000139    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000549    |
| times/evaluation_paths         | 31.5        |
| times/timestep_after_hook      | 0.00393     |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 58.4        |
| timestep                       | 1000        |
| timesteps_total                | 741000      |
| train-steps                    | 741000      |
| training/Q/q1_loss             | 76.71555    |
| training/sac_pi/alpha          | 0.16583371  |
| training/sac_pi/alpha_loss     | -0.22379242 |
| training/sac_pi/logp_pi        | 4.1113997   |
| training/sac_pi/pi_entropy     | 3.401976    |
| training/sac_pi/pi_global_norm | 2.0251188   |
| training/sac_pi/policy_loss    | -211.89522  |
| training/sac_pi/std            | 0.48730126  |
| training/sac_pi/valid_num      | 4930.0      |
| training/sac_Q/q1              | 199.42693   |
| training/sac_Q/q2              | 197.98079   |
| training/sac_Q/q2_loss         | 76.4234     |
| training/sac_Q/q_global_norm   | 204.09193   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16570808 |
| epoch                          | 741        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5164.355   |
| evaluation/return-max          | 5246.721   |
| evaluation/return-min          | 5107.5347  |
| evaluation/return-std          | 38.340843  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45958      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5164.355   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 180.4811   |
| Q-std                          | 175.85196  |
| Q_loss                         | 120.6874   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 741        |
| times/epoch_after_hook         | 2.01e-06   |
| times/epoch_before_hook        | 0.000284   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000557   |
| times/evaluation_paths         | 30.6       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 56.9       |
| timestep                       | 1000       |
| timesteps_total                | 742000     |
| train-steps                    | 742000     |
| training/Q/q1_loss             | 100.87733  |
| training/sac_pi/alpha          | 0.1657006  |
| training/sac_pi/alpha_loss     | 0.13603345 |
| training/sac_pi/logp_pi        | 4.6707816  |
| training/sac_pi/pi_entropy     | 3.467875   |
| training/sac_pi/pi_global_norm | 1.7514526  |
| training/sac_pi/policy_loss    | -209.34033 |
| training/sac_pi/std            | 0.5261247  |
| training/sac_pi/valid_num      | 4920.0     |
| training/sac_Q/q1              | 191.31816  |
| training/sac_Q/q2              | 186.15031  |
| training/sac_Q/q2_loss         | 100.53377  |
| training/sac_Q/q_global_norm   | 166.70604  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16748394 |
| epoch                          | 742        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5049.3823  |
| evaluation/return-max          | 5087.674   |
| evaluation/return-min          | 5014.8936  |
| evaluation/return-std          | 22.089272  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45992      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5049.3823  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 192.53088  |
| Q-std                          | 146.08119  |
| Q_loss                         | 77.22778   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 742        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000114   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000603   |
| times/evaluation_paths         | 32.6       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 58.4       |
| timestep                       | 1000       |
| timesteps_total                | 743000     |
| train-steps                    | 743000     |
| training/Q/q1_loss             | 89.741516  |
| training/sac_pi/alpha          | 0.16749752 |
| training/sac_pi/alpha_loss     | 0.04579584 |
| training/sac_pi/logp_pi        | 4.5064583  |
| training/sac_pi/pi_entropy     | 3.4238877  |
| training/sac_pi/pi_global_norm | 1.5327662  |
| training/sac_pi/policy_loss    | -206.53035 |
| training/sac_pi/std            | 0.50105286 |
| training/sac_pi/valid_num      | 4935.0     |
| training/sac_Q/q1              | 189.68529  |
| training/sac_Q/q2              | 187.663    |
| training/sac_Q/q2_loss         | 89.191154  |
| training/sac_Q/q_global_norm   | 292.27115  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16943274  |
| epoch                          | 743         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4978.689    |
| evaluation/return-max          | 5011.5503   |
| evaluation/return-min          | 4906.214    |
| evaluation/return-std          | 30.276773   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45882       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4978.689    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 191.30225   |
| Q-std                          | 178.45572   |
| Q_loss                         | 102.327126  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 743         |
| times/epoch_after_hook         | 2.19e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000658    |
| times/evaluation_paths         | 31.7        |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.00827     |
| times/train                    | 58.2        |
| timestep                       | 1000        |
| timesteps_total                | 744000      |
| train-steps                    | 744000      |
| training/Q/q1_loss             | 90.59986    |
| training/sac_pi/alpha          | 0.16945976  |
| training/sac_pi/alpha_loss     | -0.22531292 |
| training/sac_pi/logp_pi        | 3.9259925   |
| training/sac_pi/pi_entropy     | 3.73544     |
| training/sac_pi/pi_global_norm | 1.6001201   |
| training/sac_pi/policy_loss    | -211.99509  |
| training/sac_pi/std            | 0.5297616   |
| training/sac_pi/valid_num      | 5014.0      |
| training/sac_Q/q1              | 202.17123   |
| training/sac_Q/q2              | 202.30766   |
| training/sac_Q/q2_loss         | 89.3148     |
| training/sac_Q/q_global_norm   | 166.29478   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1660952   |
| epoch                          | 744         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4924.7637   |
| evaluation/return-max          | 5019.005    |
| evaluation/return-min          | 4849.483    |
| evaluation/return-std          | 45.307663   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45747       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4924.7637   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 189.8189    |
| Q-std                          | 195.46118   |
| Q_loss                         | 95.96019    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 744         |
| times/epoch_after_hook         | 3.82e-06    |
| times/epoch_before_hook        | 0.000151    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000631    |
| times/evaluation_paths         | 32.4        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00847     |
| times/train                    | 58.3        |
| timestep                       | 1000        |
| timesteps_total                | 745000      |
| train-steps                    | 745000      |
| training/Q/q1_loss             | 104.87229   |
| training/sac_pi/alpha          | 0.16612609  |
| training/sac_pi/alpha_loss     | -0.32620028 |
| training/sac_pi/logp_pi        | 5.5670614   |
| training/sac_pi/pi_entropy     | 3.647601    |
| training/sac_pi/pi_global_norm | 1.8051078   |
| training/sac_pi/policy_loss    | -200.69383  |
| training/sac_pi/std            | 0.5730051   |
| training/sac_pi/valid_num      | 4880.0      |
| training/sac_Q/q1              | 169.02573   |
| training/sac_Q/q2              | 164.9592    |
| training/sac_Q/q2_loss         | 104.49678   |
| training/sac_Q/q_global_norm   | 213.15263   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16403714 |
| epoch                          | 745        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4951.1416  |
| evaluation/return-max          | 4997.753   |
| evaluation/return-min          | 4906.222   |
| evaluation/return-std          | 28.4888    |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45923      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4951.1416  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 197.83437  |
| Q-std                          | 141.64148  |
| Q_loss                         | 85.42831   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 745        |
| times/epoch_after_hook         | 3.43e-06   |
| times/epoch_before_hook        | 0.000284   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000628   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 57.5       |
| timestep                       | 1000       |
| timesteps_total                | 746000     |
| train-steps                    | 746000     |
| training/Q/q1_loss             | 101.159195 |
| training/sac_pi/alpha          | 0.16402917 |
| training/sac_pi/alpha_loss     | 0.36887658 |
| training/sac_pi/logp_pi        | 4.2838335  |
| training/sac_pi/pi_entropy     | 3.4214516  |
| training/sac_pi/pi_global_norm | 1.5782077  |
| training/sac_pi/policy_loss    | -211.43349 |
| training/sac_pi/std            | 0.49560955 |
| training/sac_pi/valid_num      | 4959.0     |
| training/sac_Q/q1              | 199.12962  |
| training/sac_Q/q2              | 198.24828  |
| training/sac_Q/q2_loss         | 100.40957  |
| training/sac_Q/q_global_norm   | 217.79507  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16817342 |
| epoch                          | 746        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4795.816   |
| evaluation/return-max          | 4887.2065  |
| evaluation/return-min          | 4672.21    |
| evaluation/return-std          | 60.131866  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46006      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4795.816   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 186.83719  |
| Q-std                          | 164.72948  |
| Q_loss                         | 81.626335  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 746        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000693   |
| times/evaluation_paths         | 33.1       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 57.9       |
| timestep                       | 1000       |
| timesteps_total                | 747000     |
| train-steps                    | 747000     |
| training/Q/q1_loss             | 101.8388   |
| training/sac_pi/alpha          | 0.16813728 |
| training/sac_pi/alpha_loss     | 0.5038198  |
| training/sac_pi/logp_pi        | 4.48638    |
| training/sac_pi/pi_entropy     | 3.240147   |
| training/sac_pi/pi_global_norm | 1.5981203  |
| training/sac_pi/policy_loss    | -213.41406 |
| training/sac_pi/std            | 0.4736244  |
| training/sac_pi/valid_num      | 4998.0     |
| training/sac_Q/q1              | 197.41342  |
| training/sac_Q/q2              | 196.01324  |
| training/sac_Q/q2_loss         | 102.60364  |
| training/sac_Q/q_global_norm   | 173.66534  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16268316  |
| epoch                          | 747         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5017.5625   |
| evaluation/return-max          | 5106.014    |
| evaluation/return-min          | 4881.377    |
| evaluation/return-std          | 55.043674   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45907       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5017.5625   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 189.4426    |
| Q-std                          | 188.24814   |
| Q_loss                         | 128.19753   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 747         |
| times/epoch_after_hook         | 2.14e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 501         |
| times/evaluation_metrics       | 0.00066     |
| times/evaluation_paths         | 32.1        |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.00833     |
| times/train                    | 58.3        |
| timestep                       | 1000        |
| timesteps_total                | 748000      |
| train-steps                    | 748000      |
| training/Q/q1_loss             | 105.2019    |
| training/sac_pi/alpha          | 0.16271617  |
| training/sac_pi/alpha_loss     | -0.09270436 |
| training/sac_pi/logp_pi        | 4.1824174   |
| training/sac_pi/pi_entropy     | 3.4805255   |
| training/sac_pi/pi_global_norm | 1.500842    |
| training/sac_pi/policy_loss    | -208.82059  |
| training/sac_pi/std            | 0.50406355  |
| training/sac_pi/valid_num      | 4988.0      |
| training/sac_Q/q1              | 197.07866   |
| training/sac_Q/q2              | 193.72888   |
| training/sac_Q/q2_loss         | 105.702225  |
| training/sac_Q/q_global_norm   | 207.45619   |
---------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.16695356    |
| epoch                          | 748           |
| evaluation/episode-length-avg  | 1e+03         |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 1000          |
| evaluation/episode-length-std  | 0             |
| evaluation/return-average      | 5013.249      |
| evaluation/return-max          | 5077.717      |
| evaluation/return-min          | 4918.1836     |
| evaluation/return-std          | 48.47813      |
| model/max_penalty              | 7.34          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 3.01          |
| model/origin_ret               | 85.3          |
| model/penalty_ret              | 81.6          |
| model/val_loss                 | 0.35430613    |
| model/valid_num                | 45883         |
| perf/AverageLength             | 1e+03         |
| perf/AverageReturn             | 5013.249      |
| perf/NormalizedReturn          | 1.09          |
| Q-avg                          | 188.7212      |
| Q-std                          | 182.14806     |
| Q_loss                         | 78.056305     |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 748           |
| times/epoch_after_hook         | 2.07e-06      |
| times/epoch_before_hook        | 0.000154      |
| times/epoch_rollout_model      | 481           |
| times/evaluation_metrics       | 0.000603      |
| times/evaluation_paths         | 33.2          |
| times/timestep_after_hook      | 0.004         |
| times/timestep_before_hook     | 0.00847       |
| times/train                    | 58.4          |
| timestep                       | 1000          |
| timesteps_total                | 749000        |
| train-steps                    | 749000        |
| training/Q/q1_loss             | 100.91311     |
| training/sac_pi/alpha          | 0.1669608     |
| training/sac_pi/alpha_loss     | -0.0024547596 |
| training/sac_pi/logp_pi        | 4.902093      |
| training/sac_pi/pi_entropy     | 3.5182064     |
| training/sac_pi/pi_global_norm | 1.9948915     |
| training/sac_pi/policy_loss    | -209.26639    |
| training/sac_pi/std            | 0.5263613     |
| training/sac_pi/valid_num      | 4957.0        |
| training/sac_Q/q1              | 191.01108     |
| training/sac_Q/q2              | 191.12102     |
| training/sac_Q/q2_loss         | 100.71924     |
| training/sac_Q/q_global_norm   | 187.01828     |
-----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16646741  |
| epoch                          | 749         |
| evaluation/episode-length-avg  | 946         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 462         |
| evaluation/episode-length-std  | 161         |
| evaluation/return-average      | 4766.8857   |
| evaluation/return-max          | 5111.7246   |
| evaluation/return-min          | 2020.0863   |
| evaluation/return-std          | 916.2924    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45749       |
| perf/AverageLength             | 946         |
| perf/AverageReturn             | 4766.8857   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 183.10373   |
| Q-std                          | 224.44705   |
| Q_loss                         | 103.86444   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 749         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000367    |
| times/epoch_rollout_model      | 506         |
| times/evaluation_metrics       | 0.000627    |
| times/evaluation_paths         | 30          |
| times/timestep_after_hook      | 0.00393     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 59.2        |
| timestep                       | 1000        |
| timesteps_total                | 750000      |
| train-steps                    | 750000      |
| training/Q/q1_loss             | 104.66774   |
| training/sac_pi/alpha          | 0.16645917  |
| training/sac_pi/alpha_loss     | -0.07678258 |
| training/sac_pi/logp_pi        | 4.7923293   |
| training/sac_pi/pi_entropy     | 3.5373833   |
| training/sac_pi/pi_global_norm | 1.5257438   |
| training/sac_pi/policy_loss    | -195.37094  |
| training/sac_pi/std            | 0.52048177  |
| training/sac_pi/valid_num      | 4962.0      |
| training/sac_Q/q1              | 175.11794   |
| training/sac_Q/q2              | 170.44446   |
| training/sac_Q/q2_loss         | 104.791046  |
| training/sac_Q/q_global_norm   | 182.74574   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16822474 |
| epoch                          | 750        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4733.247   |
| evaluation/return-max          | 4878.3     |
| evaluation/return-min          | 4478.4434  |
| evaluation/return-std          | 114.4879   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45791      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4733.247   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 194.94498  |
| Q-std                          | 159.88513  |
| Q_loss                         | 102.696236 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 750        |
| times/epoch_after_hook         | 2.4e-06    |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 505        |
| times/evaluation_metrics       | 0.000833   |
| times/evaluation_paths         | 33.3       |
| times/timestep_after_hook      | 0.00403    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 751000     |
| train-steps                    | 751000     |
| training/Q/q1_loss             | 94.70034   |
| training/sac_pi/alpha          | 0.16817959 |
| training/sac_pi/alpha_loss     | 0.18966468 |
| training/sac_pi/logp_pi        | 4.219426   |
| training/sac_pi/pi_entropy     | 3.5491664  |
| training/sac_pi/pi_global_norm | 2.1208131  |
| training/sac_pi/policy_loss    | -211.81287 |
| training/sac_pi/std            | 0.50713295 |
| training/sac_pi/valid_num      | 4951.0     |
| training/sac_Q/q1              | 197.63286  |
| training/sac_Q/q2              | 197.58328  |
| training/sac_Q/q2_loss         | 93.95217   |
| training/sac_Q/q_global_norm   | 203.67877  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16707712  |
| epoch                          | 751         |
| evaluation/episode-length-avg  | 744         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 141         |
| evaluation/episode-length-std  | 391         |
| evaluation/return-average      | 3296.787    |
| evaluation/return-max          | 4607.998    |
| evaluation/return-min          | 422.04407   |
| evaluation/return-std          | 1874.0875   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45732       |
| perf/AverageLength             | 744         |
| perf/AverageReturn             | 3296.787    |
| perf/NormalizedReturn          | 0.718       |
| Q-avg                          | 202.10995   |
| Q-std                          | 133.91273   |
| Q_loss                         | 86.57426    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 751         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000151    |
| times/epoch_rollout_model      | 511         |
| times/evaluation_metrics       | 0.000588    |
| times/evaluation_paths         | 24.1        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 752000      |
| train-steps                    | 752000      |
| training/Q/q1_loss             | 114.61665   |
| training/sac_pi/alpha          | 0.16704372  |
| training/sac_pi/alpha_loss     | -0.14789554 |
| training/sac_pi/logp_pi        | 4.073149    |
| training/sac_pi/pi_entropy     | 3.4335365   |
| training/sac_pi/pi_global_norm | 1.636755    |
| training/sac_pi/policy_loss    | -202.85081  |
| training/sac_pi/std            | 0.4938002   |
| training/sac_pi/valid_num      | 4985.0      |
| training/sac_Q/q1              | 192.05234   |
| training/sac_Q/q2              | 192.24263   |
| training/sac_Q/q2_loss         | 113.71483   |
| training/sac_Q/q_global_norm   | 169.86069   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17071876  |
| epoch                          | 752         |
| evaluation/episode-length-avg  | 862         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 307         |
| evaluation/episode-length-std  | 277         |
| evaluation/return-average      | 4110.9067   |
| evaluation/return-max          | 4906.2896   |
| evaluation/return-min          | 1175.1328   |
| evaluation/return-std          | 1467.6821   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45873       |
| perf/AverageLength             | 862         |
| perf/AverageReturn             | 4110.9067   |
| perf/NormalizedReturn          | 0.895       |
| Q-avg                          | 190.65416   |
| Q-std                          | 180.49997   |
| Q_loss                         | 95.94507    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 752         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000136    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000605    |
| times/evaluation_paths         | 27.9        |
| times/timestep_after_hook      | 0.00381     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 58.6        |
| timestep                       | 1000        |
| timesteps_total                | 753000      |
| train-steps                    | 753000      |
| training/Q/q1_loss             | 100.18923   |
| training/sac_pi/alpha          | 0.17074658  |
| training/sac_pi/alpha_loss     | -0.26673585 |
| training/sac_pi/logp_pi        | 4.609811    |
| training/sac_pi/pi_entropy     | 3.7282996   |
| training/sac_pi/pi_global_norm | 1.5064509   |
| training/sac_pi/policy_loss    | -204.92546  |
| training/sac_pi/std            | 0.55545455  |
| training/sac_pi/valid_num      | 4937.0      |
| training/sac_Q/q1              | 183.30644   |
| training/sac_Q/q2              | 182.75345   |
| training/sac_Q/q2_loss         | 99.47226    |
| training/sac_Q/q_global_norm   | 200.23524   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16483018  |
| epoch                          | 753         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5082.569    |
| evaluation/return-max          | 5168.566    |
| evaluation/return-min          | 5014.044    |
| evaluation/return-std          | 45.980476   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45905       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5082.569    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 189.91016   |
| Q-std                          | 176.09315   |
| Q_loss                         | 85.03666    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 753         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000318    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000537    |
| times/evaluation_paths         | 31.7        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 58.7        |
| timestep                       | 1000        |
| timesteps_total                | 754000      |
| train-steps                    | 754000      |
| training/Q/q1_loss             | 76.95597    |
| training/sac_pi/alpha          | 0.16482982  |
| training/sac_pi/alpha_loss     | -0.34533495 |
| training/sac_pi/logp_pi        | 3.7741768   |
| training/sac_pi/pi_entropy     | 3.395927    |
| training/sac_pi/pi_global_norm | 2.0131109   |
| training/sac_pi/policy_loss    | -214.21378  |
| training/sac_pi/std            | 0.49797198  |
| training/sac_pi/valid_num      | 4937.0      |
| training/sac_Q/q1              | 199.1418    |
| training/sac_Q/q2              | 200.29623   |
| training/sac_Q/q2_loss         | 77.12883    |
| training/sac_Q/q_global_norm   | 144.93512   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17409112  |
| epoch                          | 754         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4561.4507   |
| evaluation/return-max          | 4619.737    |
| evaluation/return-min          | 4463.05     |
| evaluation/return-std          | 51.669724   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45979       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4561.4507   |
| perf/NormalizedReturn          | 0.993       |
| Q-avg                          | 192.87283   |
| Q-std                          | 176.36604   |
| Q_loss                         | 93.81972    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 754         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000115    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000601    |
| times/evaluation_paths         | 31.5        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.0113      |
| times/train                    | 58          |
| timestep                       | 1000        |
| timesteps_total                | 755000      |
| train-steps                    | 755000      |
| training/Q/q1_loss             | 85.81018    |
| training/sac_pi/alpha          | 0.17409955  |
| training/sac_pi/alpha_loss     | -0.09167675 |
| training/sac_pi/logp_pi        | 4.3941145   |
| training/sac_pi/pi_entropy     | 3.52093     |
| training/sac_pi/pi_global_norm | 1.481398    |
| training/sac_pi/policy_loss    | -203.3248   |
| training/sac_pi/std            | 0.5046778   |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 192.0599    |
| training/sac_Q/q2              | 190.87631   |
| training/sac_Q/q2_loss         | 86.56526    |
| training/sac_Q/q_global_norm   | 171.66394   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16700517 |
| epoch                          | 755        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 996        |
| evaluation/episode-length-std  | 1.2        |
| evaluation/return-average      | 4573.666   |
| evaluation/return-max          | 4826.2656  |
| evaluation/return-min          | 4460.414   |
| evaluation/return-std          | 127.59089  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 83.8       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45855      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4573.666   |
| perf/NormalizedReturn          | 0.996      |
| Q-avg                          | 182.99036  |
| Q-std                          | 177.03488  |
| Q_loss                         | 107.48165  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 755        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000522   |
| times/evaluation_paths         | 31.4       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 57.5       |
| timestep                       | 1000       |
| timesteps_total                | 756000     |
| train-steps                    | 756000     |
| training/Q/q1_loss             | 86.138985  |
| training/sac_pi/alpha          | 0.16703627 |
| training/sac_pi/alpha_loss     | 0.12904197 |
| training/sac_pi/logp_pi        | 4.666229   |
| training/sac_pi/pi_entropy     | 3.434089   |
| training/sac_pi/pi_global_norm | 1.6639193  |
| training/sac_pi/policy_loss    | -214.88818 |
| training/sac_pi/std            | 0.5060297  |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 198.66092  |
| training/sac_Q/q2              | 202.01788  |
| training/sac_Q/q2_loss         | 86.13541   |
| training/sac_Q/q_global_norm   | 239.39388  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16818434 |
| epoch                          | 756        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4524.47    |
| evaluation/return-max          | 4679.388   |
| evaluation/return-min          | 4434.3735  |
| evaluation/return-std          | 73.08929   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45991      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4524.47    |
| perf/NormalizedReturn          | 0.985      |
| Q-avg                          | 172.62079  |
| Q-std                          | 261.3775   |
| Q_loss                         | 91.20579   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 756        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000528   |
| times/evaluation_paths         | 31.6       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00892    |
| times/train                    | 56.7       |
| timestep                       | 1000       |
| timesteps_total                | 757000     |
| train-steps                    | 757000     |
| training/Q/q1_loss             | 95.70351   |
| training/sac_pi/alpha          | 0.16820195 |
| training/sac_pi/alpha_loss     | -0.1192401 |
| training/sac_pi/logp_pi        | 4.5766006  |
| training/sac_pi/pi_entropy     | 3.5943084  |
| training/sac_pi/pi_global_norm | 1.5856732  |
| training/sac_pi/policy_loss    | -207.58037 |
| training/sac_pi/std            | 0.5212279  |
| training/sac_pi/valid_num      | 4986.0     |
| training/sac_Q/q1              | 190.66037  |
| training/sac_Q/q2              | 189.25847  |
| training/sac_Q/q2_loss         | 95.252785  |
| training/sac_Q/q_global_norm   | 149.5504   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16393897  |
| epoch                          | 757         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4377.8057   |
| evaluation/return-max          | 4441.59     |
| evaluation/return-min          | 4313.5093   |
| evaluation/return-std          | 38.759686   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45840       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4377.8057   |
| perf/NormalizedReturn          | 0.953       |
| Q-avg                          | 191.9594    |
| Q-std                          | 187.89827   |
| Q_loss                         | 93.00454    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 757         |
| times/epoch_after_hook         | 1.95e-06    |
| times/epoch_before_hook        | 0.000286    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.0007      |
| times/evaluation_paths         | 31.7        |
| times/timestep_after_hook      | 0.00393     |
| times/timestep_before_hook     | 0.00829     |
| times/train                    | 57.8        |
| timestep                       | 1000        |
| timesteps_total                | 758000      |
| train-steps                    | 758000      |
| training/Q/q1_loss             | 72.287964   |
| training/sac_pi/alpha          | 0.16393451  |
| training/sac_pi/alpha_loss     | 0.053798378 |
| training/sac_pi/logp_pi        | 3.7608323   |
| training/sac_pi/pi_entropy     | 3.3211663   |
| training/sac_pi/pi_global_norm | 1.6179149   |
| training/sac_pi/policy_loss    | -217.33296  |
| training/sac_pi/std            | 0.47376126  |
| training/sac_pi/valid_num      | 4981.0      |
| training/sac_Q/q1              | 208.70891   |
| training/sac_Q/q2              | 209.06816   |
| training/sac_Q/q2_loss         | 72.59351    |
| training/sac_Q/q_global_norm   | 209.55226   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16529182 |
| epoch                          | 758        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5049.856   |
| evaluation/return-max          | 5097.0557  |
| evaluation/return-min          | 4967.787   |
| evaluation/return-std          | 31.956347  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45813      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5049.856   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 202.95789  |
| Q-std                          | 148.02307  |
| Q_loss                         | 93.66857   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 758        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000157   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000592   |
| times/evaluation_paths         | 31.6       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 58.6       |
| timestep                       | 1000       |
| timesteps_total                | 759000     |
| train-steps                    | 759000     |
| training/Q/q1_loss             | 99.13775   |
| training/sac_pi/alpha          | 0.16529064 |
| training/sac_pi/alpha_loss     | 0.12420772 |
| training/sac_pi/logp_pi        | 4.584058   |
| training/sac_pi/pi_entropy     | 3.5468545  |
| training/sac_pi/pi_global_norm | 1.766294   |
| training/sac_pi/policy_loss    | -214.6692  |
| training/sac_pi/std            | 0.51774055 |
| training/sac_pi/valid_num      | 4937.0     |
| training/sac_Q/q1              | 202.19945  |
| training/sac_Q/q2              | 200.64568  |
| training/sac_Q/q2_loss         | 98.851074  |
| training/sac_Q/q_global_norm   | 285.41962  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15961072 |
| epoch                          | 759        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4786.4385  |
| evaluation/return-max          | 4797.3115  |
| evaluation/return-min          | 4769.159   |
| evaluation/return-std          | 9.032827   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45938      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4786.4385  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 178.39297  |
| Q-std                          | 187.30226  |
| Q_loss                         | 110.92762  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 759        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000521   |
| times/evaluation_paths         | 31.6       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 57.8       |
| timestep                       | 1000       |
| timesteps_total                | 760000     |
| train-steps                    | 760000     |
| training/Q/q1_loss             | 94.01448   |
| training/sac_pi/alpha          | 0.15959918 |
| training/sac_pi/alpha_loss     | 0.1834771  |
| training/sac_pi/logp_pi        | 4.187543   |
| training/sac_pi/pi_entropy     | 3.342031   |
| training/sac_pi/pi_global_norm | 2.1184688  |
| training/sac_pi/policy_loss    | -210.05571 |
| training/sac_pi/std            | 0.49164087 |
| training/sac_pi/valid_num      | 4995.0     |
| training/sac_Q/q1              | 197.8073   |
| training/sac_Q/q2              | 198.47809  |
| training/sac_Q/q2_loss         | 95.49724   |
| training/sac_Q/q_global_norm   | 209.40935  |
--------------------------------------------------------------------------------
[WARN] 760 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.1640978  |
| epoch                          | 760        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4918.8022  |
| evaluation/return-max          | 4941.793   |
| evaluation/return-min          | 4887.4233  |
| evaluation/return-std          | 19.083454  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45916      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4918.8022  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 186.97337  |
| Q-std                          | 158.15404  |
| Q_loss                         | 88.623856  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 760        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000145   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000554   |
| times/evaluation_paths         | 32         |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 58.7       |
| timestep                       | 1000       |
| timesteps_total                | 761000     |
| train-steps                    | 761000     |
| training/Q/q1_loss             | 82.39184   |
| training/sac_pi/alpha          | 0.16404226 |
| training/sac_pi/alpha_loss     | 0.4283105  |
| training/sac_pi/logp_pi        | 4.7259316  |
| training/sac_pi/pi_entropy     | 3.3103855  |
| training/sac_pi/pi_global_norm | 1.7629057  |
| training/sac_pi/policy_loss    | -212.48769 |
| training/sac_pi/std            | 0.50037414 |
| training/sac_pi/valid_num      | 4983.0     |
| training/sac_Q/q1              | 196.43582  |
| training/sac_Q/q2              | 195.62422  |
| training/sac_Q/q2_loss         | 81.98955   |
| training/sac_Q/q_global_norm   | 210.81218  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16644165  |
| epoch                          | 761         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4915.419    |
| evaluation/return-max          | 4971.0303   |
| evaluation/return-min          | 4833.5654   |
| evaluation/return-std          | 37.1373     |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45870       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4915.419    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 192.83014   |
| Q-std                          | 175.26276   |
| Q_loss                         | 94.29379    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 761         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000283    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000514    |
| times/evaluation_paths         | 32.5        |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00847     |
| times/train                    | 59.2        |
| timestep                       | 1000        |
| timesteps_total                | 762000      |
| train-steps                    | 762000      |
| training/Q/q1_loss             | 91.75936    |
| training/sac_pi/alpha          | 0.16643627  |
| training/sac_pi/alpha_loss     | -0.14591363 |
| training/sac_pi/logp_pi        | 3.8741615   |
| training/sac_pi/pi_entropy     | 3.4428284   |
| training/sac_pi/pi_global_norm | 1.5785114   |
| training/sac_pi/policy_loss    | -209.12955  |
| training/sac_pi/std            | 0.4865249   |
| training/sac_pi/valid_num      | 5012.0      |
| training/sac_Q/q1              | 199.35384   |
| training/sac_Q/q2              | 199.25099   |
| training/sac_Q/q2_loss         | 91.83685    |
| training/sac_Q/q_global_norm   | 266.4604    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16372642 |
| epoch                          | 762        |
| evaluation/episode-length-avg  | 137        |
| evaluation/episode-length-max  | 142        |
| evaluation/episode-length-min  | 135        |
| evaluation/episode-length-std  | 2.23       |
| evaluation/return-average      | 377.90387  |
| evaluation/return-max          | 403.64792  |
| evaluation/return-min          | 362.8298   |
| evaluation/return-std          | 13.909938  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45862      |
| perf/AverageLength             | 137        |
| perf/AverageReturn             | 377.90387  |
| perf/NormalizedReturn          | 0.082      |
| Q-avg                          | 189.9867   |
| Q-std                          | 209.54979  |
| Q_loss                         | 86.92477   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 762        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000142   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000471   |
| times/evaluation_paths         | 4.32       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 58.1       |
| timestep                       | 1000       |
| timesteps_total                | 763000     |
| train-steps                    | 763000     |
| training/Q/q1_loss             | 111.63855  |
| training/sac_pi/alpha          | 0.16369012 |
| training/sac_pi/alpha_loss     | 0.21697104 |
| training/sac_pi/logp_pi        | 4.515487   |
| training/sac_pi/pi_entropy     | 3.4998977  |
| training/sac_pi/pi_global_norm | 1.5303825  |
| training/sac_pi/policy_loss    | -209.62473 |
| training/sac_pi/std            | 0.51031965 |
| training/sac_pi/valid_num      | 4959.0     |
| training/sac_Q/q1              | 190.77437  |
| training/sac_Q/q2              | 189.20036  |
| training/sac_Q/q2_loss         | 111.72744  |
| training/sac_Q/q_global_norm   | 216.09813  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16260092  |
| epoch                          | 763         |
| evaluation/episode-length-avg  | 245         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 150         |
| evaluation/episode-length-std  | 252         |
| evaluation/return-average      | 928.30774   |
| evaluation/return-max          | 4893.0024   |
| evaluation/return-min          | 450.8891    |
| evaluation/return-std          | 1321.6404   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45824       |
| perf/AverageLength             | 245         |
| perf/AverageReturn             | 928.30774   |
| perf/NormalizedReturn          | 0.202       |
| Q-avg                          | 195.14365   |
| Q-std                          | 146.65865   |
| Q_loss                         | 89.69209    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 763         |
| times/epoch_after_hook         | 1.95e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000467    |
| times/evaluation_paths         | 7.68        |
| times/timestep_after_hook      | 0.00385     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 57.6        |
| timestep                       | 1000        |
| timesteps_total                | 764000      |
| train-steps                    | 764000      |
| training/Q/q1_loss             | 87.99748    |
| training/sac_pi/alpha          | 0.16261931  |
| training/sac_pi/alpha_loss     | -0.10278863 |
| training/sac_pi/logp_pi        | 4.007469    |
| training/sac_pi/pi_entropy     | 3.3601222   |
| training/sac_pi/pi_global_norm | 1.5137854   |
| training/sac_pi/policy_loss    | -210.57832  |
| training/sac_pi/std            | 0.49519634  |
| training/sac_pi/valid_num      | 4951.0      |
| training/sac_Q/q1              | 194.57469   |
| training/sac_Q/q2              | 194.48909   |
| training/sac_Q/q2_loss         | 88.078476   |
| training/sac_Q/q_global_norm   | 161.92517   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16397935  |
| epoch                          | 764         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5033.108    |
| evaluation/return-max          | 5100.248    |
| evaluation/return-min          | 4969.205    |
| evaluation/return-std          | 41.94215    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45895       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5033.108    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 198.28952   |
| Q-std                          | 156.30298   |
| Q_loss                         | 78.7308     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 764         |
| times/epoch_after_hook         | 1.95e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000514    |
| times/evaluation_paths         | 31.3        |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 57.9        |
| timestep                       | 1000        |
| timesteps_total                | 765000      |
| train-steps                    | 765000      |
| training/Q/q1_loss             | 111.692505  |
| training/sac_pi/alpha          | 0.16399634  |
| training/sac_pi/alpha_loss     | -0.14791769 |
| training/sac_pi/logp_pi        | 4.0957665   |
| training/sac_pi/pi_entropy     | 3.3863044   |
| training/sac_pi/pi_global_norm | 1.7770568   |
| training/sac_pi/policy_loss    | -208.80045  |
| training/sac_pi/std            | 0.49965516  |
| training/sac_pi/valid_num      | 4954.0      |
| training/sac_Q/q1              | 194.62749   |
| training/sac_Q/q2              | 194.13106   |
| training/sac_Q/q2_loss         | 111.71099   |
| training/sac_Q/q_global_norm   | 235.983     |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16494781  |
| epoch                          | 765         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4683.838    |
| evaluation/return-max          | 4917.9756   |
| evaluation/return-min          | 4525.0684   |
| evaluation/return-std          | 120.48301   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45950       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4683.838    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 194.78128   |
| Q-std                          | 170.84828   |
| Q_loss                         | 89.45482    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 765         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000333    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000593    |
| times/evaluation_paths         | 32.2        |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 58.4        |
| timestep                       | 1000        |
| timesteps_total                | 766000      |
| train-steps                    | 766000      |
| training/Q/q1_loss             | 104.02822   |
| training/sac_pi/alpha          | 0.16494061  |
| training/sac_pi/alpha_loss     | 0.039056677 |
| training/sac_pi/logp_pi        | 4.8789253   |
| training/sac_pi/pi_entropy     | 3.348989    |
| training/sac_pi/pi_global_norm | 1.5559484   |
| training/sac_pi/policy_loss    | -199.7546   |
| training/sac_pi/std            | 0.4983306   |
| training/sac_pi/valid_num      | 4890.0      |
| training/sac_Q/q1              | 185.80005   |
| training/sac_Q/q2              | 187.22252   |
| training/sac_Q/q2_loss         | 104.98119   |
| training/sac_Q/q_global_norm   | 219.07954   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16923289 |
| epoch                          | 766        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4928.083   |
| evaluation/return-max          | 5010.575   |
| evaluation/return-min          | 4635.826   |
| evaluation/return-std          | 102.02926  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45885      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4928.083   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 176.87346  |
| Q-std                          | 245.49365  |
| Q_loss                         | 96.54032   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 766        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.00077    |
| times/evaluation_paths         | 31.6       |
| times/timestep_after_hook      | 0.00398    |
| times/timestep_before_hook     | 0.00964    |
| times/train                    | 57.3       |
| timestep                       | 1000       |
| timesteps_total                | 767000     |
| train-steps                    | 767000     |
| training/Q/q1_loss             | 101.76592  |
| training/sac_pi/alpha          | 0.16918893 |
| training/sac_pi/alpha_loss     | 0.4711147  |
| training/sac_pi/logp_pi        | 4.3911996  |
| training/sac_pi/pi_entropy     | 3.3359246  |
| training/sac_pi/pi_global_norm | 1.546348   |
| training/sac_pi/policy_loss    | -209.50697 |
| training/sac_pi/std            | 0.4784293  |
| training/sac_pi/valid_num      | 5015.0     |
| training/sac_Q/q1              | 200.1506   |
| training/sac_Q/q2              | 200.59229  |
| training/sac_Q/q2_loss         | 102.54993  |
| training/sac_Q/q_global_norm   | 206.35083  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16926812   |
| epoch                          | 767          |
| evaluation/episode-length-avg  | 404          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 142          |
| evaluation/episode-length-std  | 390          |
| evaluation/return-average      | 1844.1703    |
| evaluation/return-max          | 5099.793     |
| evaluation/return-min          | 437.81308    |
| evaluation/return-std          | 2107.4949    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3            |
| model/origin_ret               | 85.3         |
| model/penalty_ret              | 80.9         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45895        |
| perf/AverageLength             | 404          |
| perf/AverageReturn             | 1844.1703    |
| perf/NormalizedReturn          | 0.401        |
| Q-avg                          | 200.00856    |
| Q-std                          | 138.2121     |
| Q_loss                         | 77.000175    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 767          |
| times/epoch_after_hook         | 1.73e-06     |
| times/epoch_before_hook        | 0.000125     |
| times/epoch_rollout_model      | 499          |
| times/evaluation_metrics       | 0.000533     |
| times/evaluation_paths         | 13           |
| times/timestep_after_hook      | 0.00406      |
| times/timestep_before_hook     | 0.00827      |
| times/train                    | 58.8         |
| timestep                       | 1000         |
| timesteps_total                | 768000       |
| train-steps                    | 768000       |
| training/Q/q1_loss             | 88.23056     |
| training/sac_pi/alpha          | 0.16926493   |
| training/sac_pi/alpha_loss     | 0.0059254663 |
| training/sac_pi/logp_pi        | 5.7676363    |
| training/sac_pi/pi_entropy     | 3.315089     |
| training/sac_pi/pi_global_norm | 1.6640097    |
| training/sac_pi/policy_loss    | -212.28255   |
| training/sac_pi/std            | 0.51824695   |
| training/sac_pi/valid_num      | 4913.0       |
| training/sac_Q/q1              | 190.33232    |
| training/sac_Q/q2              | 194.23245    |
| training/sac_Q/q2_loss         | 87.505516    |
| training/sac_Q/q_global_norm   | 189.13792    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16428831 |
| epoch                          | 768        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4724.481   |
| evaluation/return-max          | 4777.006   |
| evaluation/return-min          | 4661.663   |
| evaluation/return-std          | 31.846292  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46014      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4724.481   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 189.31483  |
| Q-std                          | 176.5553   |
| Q_loss                         | 91.093094  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 768        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000152   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000555   |
| times/evaluation_paths         | 32         |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 57.7       |
| timestep                       | 1000       |
| timesteps_total                | 769000     |
| train-steps                    | 769000     |
| training/Q/q1_loss             | 118.81581  |
| training/sac_pi/alpha          | 0.16427469 |
| training/sac_pi/alpha_loss     | 0.14195776 |
| training/sac_pi/logp_pi        | 4.3593597  |
| training/sac_pi/pi_entropy     | 3.4443507  |
| training/sac_pi/pi_global_norm | 1.6524742  |
| training/sac_pi/policy_loss    | -209.9043  |
| training/sac_pi/std            | 0.49720687 |
| training/sac_pi/valid_num      | 4961.0     |
| training/sac_Q/q1              | 195.99341  |
| training/sac_Q/q2              | 196.63657  |
| training/sac_Q/q2_loss         | 118.26975  |
| training/sac_Q/q_global_norm   | 214.15103  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16735426  |
| epoch                          | 769         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4878.8916   |
| evaluation/return-max          | 4973.1973   |
| evaluation/return-min          | 4818.0156   |
| evaluation/return-std          | 57.035732   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45905       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4878.8916   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 204.80022   |
| Q-std                          | 140.15309   |
| Q_loss                         | 74.395935   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 769         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000278    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000744    |
| times/evaluation_paths         | 31.6        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.00839     |
| times/train                    | 57.7        |
| timestep                       | 1000        |
| timesteps_total                | 770000      |
| train-steps                    | 770000      |
| training/Q/q1_loss             | 97.05067    |
| training/sac_pi/alpha          | 0.16738881  |
| training/sac_pi/alpha_loss     | -0.34744808 |
| training/sac_pi/logp_pi        | 4.892047    |
| training/sac_pi/pi_entropy     | 3.515688    |
| training/sac_pi/pi_global_norm | 1.6167775   |
| training/sac_pi/policy_loss    | -200.24962  |
| training/sac_pi/std            | 0.53321284  |
| training/sac_pi/valid_num      | 4883.0      |
| training/sac_Q/q1              | 178.96297   |
| training/sac_Q/q2              | 175.62607   |
| training/sac_Q/q2_loss         | 97.6556     |
| training/sac_Q/q_global_norm   | 164.33392   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1630424  |
| epoch                          | 770        |
| evaluation/episode-length-avg  | 481        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 127        |
| evaluation/episode-length-std  | 424        |
| evaluation/return-average      | 2112.7202  |
| evaluation/return-max          | 4836.465   |
| evaluation/return-min          | 321.06946  |
| evaluation/return-std          | 2163.311   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45868      |
| perf/AverageLength             | 481        |
| perf/AverageReturn             | 2112.7202  |
| perf/NormalizedReturn          | 0.46       |
| Q-avg                          | 192.79297  |
| Q-std                          | 175.81674  |
| Q_loss                         | 107.01314  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 770        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000488   |
| times/evaluation_paths         | 15.4       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 58         |
| timestep                       | 1000       |
| timesteps_total                | 771000     |
| train-steps                    | 771000     |
| training/Q/q1_loss             | 114.29564  |
| training/sac_pi/alpha          | 0.16302954 |
| training/sac_pi/alpha_loss     | 0.1186761  |
| training/sac_pi/logp_pi        | 4.3002787  |
| training/sac_pi/pi_entropy     | 3.5824056  |
| training/sac_pi/pi_global_norm | 1.8769423  |
| training/sac_pi/policy_loss    | -205.6687  |
| training/sac_pi/std            | 0.50128305 |
| training/sac_pi/valid_num      | 4963.0     |
| training/sac_Q/q1              | 191.9412   |
| training/sac_Q/q2              | 193.57507  |
| training/sac_Q/q2_loss         | 115.083405 |
| training/sac_Q/q_global_norm   | 220.47151  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16435018  |
| epoch                          | 771         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4895.8223   |
| evaluation/return-max          | 4973.3413   |
| evaluation/return-min          | 4790.882    |
| evaluation/return-std          | 54.40973    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45856       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4895.8223   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 187.37787   |
| Q-std                          | 178.76611   |
| Q_loss                         | 87.04417    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 771         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000149    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000548    |
| times/evaluation_paths         | 31.5        |
| times/timestep_after_hook      | 0.00408     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 58.9        |
| timestep                       | 1000        |
| timesteps_total                | 772000      |
| train-steps                    | 772000      |
| training/Q/q1_loss             | 114.779495  |
| training/sac_pi/alpha          | 0.16435324  |
| training/sac_pi/alpha_loss     | 0.020682033 |
| training/sac_pi/logp_pi        | 5.4783287   |
| training/sac_pi/pi_entropy     | 3.679383    |
| training/sac_pi/pi_global_norm | 1.599592    |
| training/sac_pi/policy_loss    | -203.64577  |
| training/sac_pi/std            | 0.5929582   |
| training/sac_pi/valid_num      | 4871.0      |
| training/sac_Q/q1              | 177.07784   |
| training/sac_Q/q2              | 178.14078   |
| training/sac_Q/q2_loss         | 114.5504    |
| training/sac_Q/q_global_norm   | 167.54945   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17280188 |
| epoch                          | 772        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4919.207   |
| evaluation/return-max          | 4992.409   |
| evaluation/return-min          | 4810.1875  |
| evaluation/return-std          | 53.78432   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 83.4       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45737      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4919.207   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 201.33914  |
| Q-std                          | 143.12009  |
| Q_loss                         | 103.13088  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 772        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000267   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000569   |
| times/evaluation_paths         | 31.9       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 57.5       |
| timestep                       | 1000       |
| timesteps_total                | 773000     |
| train-steps                    | 773000     |
| training/Q/q1_loss             | 131.79237  |
| training/sac_pi/alpha          | 0.17277089 |
| training/sac_pi/alpha_loss     | 0.15715507 |
| training/sac_pi/logp_pi        | 4.4248037  |
| training/sac_pi/pi_entropy     | 3.41958    |
| training/sac_pi/pi_global_norm | 1.693897   |
| training/sac_pi/policy_loss    | -205.96089 |
| training/sac_pi/std            | 0.4914298  |
| training/sac_pi/valid_num      | 4992.0     |
| training/sac_Q/q1              | 195.00652  |
| training/sac_Q/q2              | 191.85521  |
| training/sac_Q/q2_loss         | 131.17334  |
| training/sac_Q/q_global_norm   | 255.08836  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17189242  |
| epoch                          | 773         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4972.551    |
| evaluation/return-max          | 4987.1255   |
| evaluation/return-min          | 4944.6963   |
| evaluation/return-std          | 12.291248   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 82.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45726       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4972.551    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 175.01454   |
| Q-std                          | 218.65817   |
| Q_loss                         | 134.95851   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 773         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000277    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.00055     |
| times/evaluation_paths         | 31.7        |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00829     |
| times/train                    | 56.9        |
| timestep                       | 1000        |
| timesteps_total                | 774000      |
| train-steps                    | 774000      |
| training/Q/q1_loss             | 110.97154   |
| training/sac_pi/alpha          | 0.1718516   |
| training/sac_pi/alpha_loss     | 0.030706113 |
| training/sac_pi/logp_pi        | 4.4334154   |
| training/sac_pi/pi_entropy     | 3.333044    |
| training/sac_pi/pi_global_norm | 1.5383202   |
| training/sac_pi/policy_loss    | -206.91277  |
| training/sac_pi/std            | 0.48439547  |
| training/sac_pi/valid_num      | 4974.0      |
| training/sac_Q/q1              | 191.72816   |
| training/sac_Q/q2              | 190.31808   |
| training/sac_Q/q2_loss         | 110.180046  |
| training/sac_Q/q_global_norm   | 225.3695    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17377788 |
| epoch                          | 774        |
| evaluation/episode-length-avg  | 576        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 145        |
| evaluation/episode-length-std  | 424        |
| evaluation/return-average      | 2697.9     |
| evaluation/return-max          | 4996.965   |
| evaluation/return-min          | 407.33557  |
| evaluation/return-std          | 2268.9453  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45877      |
| perf/AverageLength             | 576        |
| perf/AverageReturn             | 2697.9     |
| perf/NormalizedReturn          | 0.587      |
| Q-avg                          | 196.60054  |
| Q-std                          | 163.29218  |
| Q_loss                         | 87.13258   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 774        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.00054    |
| times/evaluation_paths         | 18.6       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 57.4       |
| timestep                       | 1000       |
| timesteps_total                | 775000     |
| train-steps                    | 775000     |
| training/Q/q1_loss             | 87.69037   |
| training/sac_pi/alpha          | 0.1737551  |
| training/sac_pi/alpha_loss     | 0.28145656 |
| training/sac_pi/logp_pi        | 4.088235   |
| training/sac_pi/pi_entropy     | 3.4891257  |
| training/sac_pi/pi_global_norm | 2.305371   |
| training/sac_pi/policy_loss    | -214.99306 |
| training/sac_pi/std            | 0.48758993 |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 203.34343  |
| training/sac_Q/q2              | 202.07474  |
| training/sac_Q/q2_loss         | 88.37754   |
| training/sac_Q/q_global_norm   | 236.24019  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17099974   |
| epoch                          | 775          |
| evaluation/episode-length-avg  | 916          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 156          |
| evaluation/episode-length-std  | 253          |
| evaluation/return-average      | 4651.9067    |
| evaluation/return-max          | 5160.56      |
| evaluation/return-min          | 497.2165     |
| evaluation/return-std          | 1385.0692    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.97         |
| model/origin_ret               | 84.6         |
| model/penalty_ret              | 81.4         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45899        |
| perf/AverageLength             | 916          |
| perf/AverageReturn             | 4651.9067    |
| perf/NormalizedReturn          | 1.01         |
| Q-avg                          | 169.4047     |
| Q-std                          | 276.38873    |
| Q_loss                         | 102.253525   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 775          |
| times/epoch_after_hook         | 2.01e-06     |
| times/epoch_before_hook        | 0.000121     |
| times/epoch_rollout_model      | 495          |
| times/evaluation_metrics       | 0.000563     |
| times/evaluation_paths         | 28.6         |
| times/timestep_after_hook      | 0.00383      |
| times/timestep_before_hook     | 0.00831      |
| times/train                    | 56.2         |
| timestep                       | 1000         |
| timesteps_total                | 776000       |
| train-steps                    | 776000       |
| training/Q/q1_loss             | 105.655205   |
| training/sac_pi/alpha          | 0.17101207   |
| training/sac_pi/alpha_loss     | -0.056106724 |
| training/sac_pi/logp_pi        | 5.1752486    |
| training/sac_pi/pi_entropy     | 3.6231258    |
| training/sac_pi/pi_global_norm | 1.6653757    |
| training/sac_pi/policy_loss    | -205.71361   |
| training/sac_pi/std            | 0.55299634   |
| training/sac_pi/valid_num      | 4914.0       |
| training/sac_Q/q1              | 182.29002    |
| training/sac_Q/q2              | 179.03433    |
| training/sac_Q/q2_loss         | 107.1437     |
| training/sac_Q/q_global_norm   | 230.59268    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16916142  |
| epoch                          | 776         |
| evaluation/episode-length-avg  | 572         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 143         |
| evaluation/episode-length-std  | 428         |
| evaluation/return-average      | 2717.273    |
| evaluation/return-max          | 5078.5405   |
| evaluation/return-min          | 384.69543   |
| evaluation/return-std          | 2317.8433   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45901       |
| perf/AverageLength             | 572         |
| perf/AverageReturn             | 2717.273    |
| perf/NormalizedReturn          | 0.592       |
| Q-avg                          | 203.30644   |
| Q-std                          | 139.99135   |
| Q_loss                         | 106.961105  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 776         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000487    |
| times/evaluation_paths         | 18.3        |
| times/timestep_after_hook      | 0.00387     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 57.1        |
| timestep                       | 1000        |
| timesteps_total                | 777000      |
| train-steps                    | 777000      |
| training/Q/q1_loss             | 84.955055   |
| training/sac_pi/alpha          | 0.1691531   |
| training/sac_pi/alpha_loss     | -0.32438877 |
| training/sac_pi/logp_pi        | 4.652901    |
| training/sac_pi/pi_entropy     | 3.5455422   |
| training/sac_pi/pi_global_norm | 1.6885395   |
| training/sac_pi/policy_loss    | -208.8728   |
| training/sac_pi/std            | 0.54024184  |
| training/sac_pi/valid_num      | 4939.0      |
| training/sac_Q/q1              | 187.48622   |
| training/sac_Q/q2              | 186.05597   |
| training/sac_Q/q2_loss         | 84.80286    |
| training/sac_Q/q_global_norm   | 256.28284   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16343059 |
| epoch                          | 777        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5013.3486  |
| evaluation/return-max          | 5055.5605  |
| evaluation/return-min          | 4963.5137  |
| evaluation/return-std          | 27.53592   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45939      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5013.3486  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 179.53581  |
| Q-std                          | 219.94539  |
| Q_loss                         | 85.1064    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 777        |
| times/epoch_after_hook         | 2.01e-06   |
| times/epoch_before_hook        | 0.000272   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000551   |
| times/evaluation_paths         | 31.7       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 57.3       |
| timestep                       | 1000       |
| timesteps_total                | 778000     |
| train-steps                    | 778000     |
| training/Q/q1_loss             | 124.95807  |
| training/sac_pi/alpha          | 0.16341645 |
| training/sac_pi/alpha_loss     | 0.15034582 |
| training/sac_pi/logp_pi        | 5.1952753  |
| training/sac_pi/pi_entropy     | 3.4072776  |
| training/sac_pi/pi_global_norm | 1.8898125  |
| training/sac_pi/policy_loss    | -205.91599 |
| training/sac_pi/std            | 0.5311321  |
| training/sac_pi/valid_num      | 4919.0     |
| training/sac_Q/q1              | 185.39644  |
| training/sac_Q/q2              | 185.05505  |
| training/sac_Q/q2_loss         | 125.813126 |
| training/sac_Q/q_global_norm   | 229.6214   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16355748   |
| epoch                          | 778          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4755.4976    |
| evaluation/return-max          | 4791.043     |
| evaluation/return-min          | 4668.919     |
| evaluation/return-std          | 33.074947    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.97         |
| model/origin_ret               | 85.1         |
| model/penalty_ret              | 81.6         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45803        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4755.4976    |
| perf/NormalizedReturn          | 1.04         |
| Q-avg                          | 187.56516    |
| Q-std                          | 169.33449    |
| Q_loss                         | 99.07315     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 778          |
| times/epoch_after_hook         | 1.74e-06     |
| times/epoch_before_hook        | 0.000138     |
| times/epoch_rollout_model      | 495          |
| times/evaluation_metrics       | 0.000465     |
| times/evaluation_paths         | 31.6         |
| times/timestep_after_hook      | 0.004        |
| times/timestep_before_hook     | 0.00833      |
| times/train                    | 57.6         |
| timestep                       | 1000         |
| timesteps_total                | 779000       |
| train-steps                    | 779000       |
| training/Q/q1_loss             | 79.539734    |
| training/sac_pi/alpha          | 0.16353819   |
| training/sac_pi/alpha_loss     | -0.010449723 |
| training/sac_pi/logp_pi        | 4.6410913    |
| training/sac_pi/pi_entropy     | 3.502002     |
| training/sac_pi/pi_global_norm | 1.6250311    |
| training/sac_pi/policy_loss    | -201.00287   |
| training/sac_pi/std            | 0.51262325   |
| training/sac_pi/valid_num      | 4967.0       |
| training/sac_Q/q1              | 182.22966    |
| training/sac_Q/q2              | 182.92741    |
| training/sac_Q/q2_loss         | 79.07452     |
| training/sac_Q/q_global_norm   | 167.4055     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16365306 |
| epoch                          | 779        |
| evaluation/episode-length-avg  | 150        |
| evaluation/episode-length-max  | 152        |
| evaluation/episode-length-min  | 149        |
| evaluation/episode-length-std  | 1.02       |
| evaluation/return-average      | 453.86166  |
| evaluation/return-max          | 465.64264  |
| evaluation/return-min          | 444.69415  |
| evaluation/return-std          | 6.089375   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 84         |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45811      |
| perf/AverageLength             | 150        |
| perf/AverageReturn             | 453.86166  |
| perf/NormalizedReturn          | 0.0985     |
| Q-avg                          | 195.13737  |
| Q-std                          | 168.89328  |
| Q_loss                         | 104.0211   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 779        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 8.17e-05   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000481   |
| times/evaluation_paths         | 4.68       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 57.8       |
| timestep                       | 1000       |
| timesteps_total                | 780000     |
| train-steps                    | 780000     |
| training/Q/q1_loss             | 104.813576 |
| training/sac_pi/alpha          | 0.16364923 |
| training/sac_pi/alpha_loss     | 0.652019   |
| training/sac_pi/logp_pi        | 3.789322   |
| training/sac_pi/pi_entropy     | 3.4040565  |
| training/sac_pi/pi_global_norm | 1.745159   |
| training/sac_pi/policy_loss    | -201.50043 |
| training/sac_pi/std            | 0.4600696  |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 193.81143  |
| training/sac_Q/q2              | 193.70837  |
| training/sac_Q/q2_loss         | 104.428276 |
| training/sac_Q/q_global_norm   | 214.01675  |
--------------------------------------------------------------------------------
[WARN] 780 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16297446  |
| epoch                          | 780         |
| evaluation/episode-length-avg  | 871         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 429         |
| evaluation/episode-length-std  | 225         |
| evaluation/return-average      | 3933.1511   |
| evaluation/return-max          | 4772.7734   |
| evaluation/return-min          | 1776.0366   |
| evaluation/return-std          | 1102.0779   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45898       |
| perf/AverageLength             | 871         |
| perf/AverageReturn             | 3933.1511   |
| perf/NormalizedReturn          | 0.856       |
| Q-avg                          | 182.51668   |
| Q-std                          | 177.97229   |
| Q_loss                         | 114.048935  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 780         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000565    |
| times/evaluation_paths         | 28.4        |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 58.3        |
| timestep                       | 1000        |
| timesteps_total                | 781000      |
| train-steps                    | 781000      |
| training/Q/q1_loss             | 122.06822   |
| training/sac_pi/alpha          | 0.16296966  |
| training/sac_pi/alpha_loss     | -0.14795586 |
| training/sac_pi/logp_pi        | 4.0864363   |
| training/sac_pi/pi_entropy     | 3.5798721   |
| training/sac_pi/pi_global_norm | 2.579324    |
| training/sac_pi/policy_loss    | -206.04602  |
| training/sac_pi/std            | 0.5192525   |
| training/sac_pi/valid_num      | 4962.0      |
| training/sac_Q/q1              | 194.3875    |
| training/sac_Q/q2              | 193.60724   |
| training/sac_Q/q2_loss         | 121.92897   |
| training/sac_Q/q_global_norm   | 208.8529    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16628906  |
| epoch                          | 781         |
| evaluation/episode-length-avg  | 152         |
| evaluation/episode-length-max  | 157         |
| evaluation/episode-length-min  | 149         |
| evaluation/episode-length-std  | 2.52        |
| evaluation/return-average      | 428.01398   |
| evaluation/return-max          | 451.95996   |
| evaluation/return-min          | 411.08203   |
| evaluation/return-std          | 11.972998   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45768       |
| perf/AverageLength             | 152         |
| perf/AverageReturn             | 428.01398   |
| perf/NormalizedReturn          | 0.0929      |
| Q-avg                          | 189.07153   |
| Q-std                          | 192.9326    |
| Q_loss                         | 86.958466   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 781         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000278    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000434    |
| times/evaluation_paths         | 4.88        |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.00802     |
| times/train                    | 57.5        |
| timestep                       | 1000        |
| timesteps_total                | 782000      |
| train-steps                    | 782000      |
| training/Q/q1_loss             | 84.23165    |
| training/sac_pi/alpha          | 0.16627519  |
| training/sac_pi/alpha_loss     | -0.13390978 |
| training/sac_pi/logp_pi        | 3.8829358   |
| training/sac_pi/pi_entropy     | 3.594143    |
| training/sac_pi/pi_global_norm | 1.6983483   |
| training/sac_pi/policy_loss    | -204.54536  |
| training/sac_pi/std            | 0.5007248   |
| training/sac_pi/valid_num      | 4997.0      |
| training/sac_Q/q1              | 194.0544    |
| training/sac_Q/q2              | 193.20264   |
| training/sac_Q/q2_loss         | 83.34553    |
| training/sac_Q/q_global_norm   | 161.46617   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17190038 |
| epoch                          | 782        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4854.25    |
| evaluation/return-max          | 4937.9736  |
| evaluation/return-min          | 4596.7754  |
| evaluation/return-std          | 98.15418   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45936      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4854.25    |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 197.85461  |
| Q-std                          | 137.02536  |
| Q_loss                         | 90.48633   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 782        |
| times/epoch_after_hook         | 2e-06      |
| times/epoch_before_hook        | 8.58e-05   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000548   |
| times/evaluation_paths         | 31.5       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 58.8       |
| timestep                       | 1000       |
| timesteps_total                | 783000     |
| train-steps                    | 783000     |
| training/Q/q1_loss             | 94.03905   |
| training/sac_pi/alpha          | 0.17188811 |
| training/sac_pi/alpha_loss     | 0.08761315 |
| training/sac_pi/logp_pi        | 4.646894   |
| training/sac_pi/pi_entropy     | 3.3447998  |
| training/sac_pi/pi_global_norm | 2.0051053  |
| training/sac_pi/policy_loss    | -205.52255 |
| training/sac_pi/std            | 0.4913409  |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 188.18706  |
| training/sac_Q/q2              | 185.99355  |
| training/sac_Q/q2_loss         | 93.68531   |
| training/sac_Q/q_global_norm   | 357.76578  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16628551 |
| epoch                          | 783        |
| evaluation/episode-length-avg  | 576        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 152        |
| evaluation/episode-length-std  | 424        |
| evaluation/return-average      | 2559.8252  |
| evaluation/return-max          | 4798.177   |
| evaluation/return-min          | 465.16394  |
| evaluation/return-std          | 2087.971   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45820      |
| perf/AverageLength             | 576        |
| perf/AverageReturn             | 2559.8252  |
| perf/NormalizedReturn          | 0.557      |
| Q-avg                          | 180.7635   |
| Q-std                          | 205.17592  |
| Q_loss                         | 93.4624    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 783        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000468   |
| times/evaluation_paths         | 18.3       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 57.5       |
| timestep                       | 1000       |
| timesteps_total                | 784000     |
| train-steps                    | 784000     |
| training/Q/q1_loss             | 101.03357  |
| training/sac_pi/alpha          | 0.16626815 |
| training/sac_pi/alpha_loss     | 0.4014575  |
| training/sac_pi/logp_pi        | 3.6215966  |
| training/sac_pi/pi_entropy     | 3.3410912  |
| training/sac_pi/pi_global_norm | 1.5031749  |
| training/sac_pi/policy_loss    | -207.21155 |
| training/sac_pi/std            | 0.45240587 |
| training/sac_pi/valid_num      | 5059.0     |
| training/sac_Q/q1              | 203.30891  |
| training/sac_Q/q2              | 203.62827  |
| training/sac_Q/q2_loss         | 100.76128  |
| training/sac_Q/q_global_norm   | 178.37622  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16844985 |
| epoch                          | 784        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4870.8184  |
| evaluation/return-max          | 4906.284   |
| evaluation/return-min          | 4824.8955  |
| evaluation/return-std          | 25.928022  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 83.5       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45863      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4870.8184  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 181.99483  |
| Q-std                          | 209.89563  |
| Q_loss                         | 82.39599   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 784        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000681   |
| times/evaluation_paths         | 32.3       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 58.6       |
| timestep                       | 1000       |
| timesteps_total                | 785000     |
| train-steps                    | 785000     |
| training/Q/q1_loss             | 79.44251   |
| training/sac_pi/alpha          | 0.16843098 |
| training/sac_pi/alpha_loss     | 0.10000856 |
| training/sac_pi/logp_pi        | 4.750444   |
| training/sac_pi/pi_entropy     | 3.470918   |
| training/sac_pi/pi_global_norm | 1.5977728  |
| training/sac_pi/policy_loss    | -200.62538 |
| training/sac_pi/std            | 0.51891285 |
| training/sac_pi/valid_num      | 4960.0     |
| training/sac_Q/q1              | 184.01411  |
| training/sac_Q/q2              | 182.89731  |
| training/sac_Q/q2_loss         | 80.709656  |
| training/sac_Q/q_global_norm   | 199.44601  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17011498 |
| epoch                          | 785        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4873.266   |
| evaluation/return-max          | 4958.0713  |
| evaluation/return-min          | 4801.7476  |
| evaluation/return-std          | 49.611668  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45755      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4873.266   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 190.05563  |
| Q-std                          | 182.94022  |
| Q_loss                         | 84.851074  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 785        |
| times/epoch_after_hook         | 1.97e-06   |
| times/epoch_before_hook        | 0.000337   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000541   |
| times/evaluation_paths         | 31.8       |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 57.5       |
| timestep                       | 1000       |
| timesteps_total                | 786000     |
| train-steps                    | 786000     |
| training/Q/q1_loss             | 103.21917  |
| training/sac_pi/alpha          | 0.17010957 |
| training/sac_pi/alpha_loss     | 0.30327204 |
| training/sac_pi/logp_pi        | 4.38922    |
| training/sac_pi/pi_entropy     | 3.4016685  |
| training/sac_pi/pi_global_norm | 1.8127291  |
| training/sac_pi/policy_loss    | -205.44612 |
| training/sac_pi/std            | 0.4934944  |
| training/sac_pi/valid_num      | 5002.0     |
| training/sac_Q/q1              | 191.70454  |
| training/sac_Q/q2              | 192.49725  |
| training/sac_Q/q2_loss         | 101.88626  |
| training/sac_Q/q_global_norm   | 187.23004  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16772199  |
| epoch                          | 786         |
| evaluation/episode-length-avg  | 318         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 146         |
| evaluation/episode-length-std  | 341         |
| evaluation/return-average      | 1228.5269   |
| evaluation/return-max          | 4634.462    |
| evaluation/return-min          | 385.32956   |
| evaluation/return-std          | 1674.7233   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45876       |
| perf/AverageLength             | 318         |
| perf/AverageReturn             | 1228.5269   |
| perf/NormalizedReturn          | 0.267       |
| Q-avg                          | 191.90706   |
| Q-std                          | 198.29701   |
| Q_loss                         | 103.62242   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 786         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000483    |
| times/evaluation_paths         | 10          |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 58.1        |
| timestep                       | 1000        |
| timesteps_total                | 787000      |
| train-steps                    | 787000      |
| training/Q/q1_loss             | 92.83768    |
| training/sac_pi/alpha          | 0.16771647  |
| training/sac_pi/alpha_loss     | -0.08596764 |
| training/sac_pi/logp_pi        | 4.664199    |
| training/sac_pi/pi_entropy     | 3.432283    |
| training/sac_pi/pi_global_norm | 1.5776296   |
| training/sac_pi/policy_loss    | -208.50987  |
| training/sac_pi/std            | 0.5211241   |
| training/sac_pi/valid_num      | 4912.0      |
| training/sac_Q/q1              | 186.21944   |
| training/sac_Q/q2              | 186.11934   |
| training/sac_Q/q2_loss         | 92.4129     |
| training/sac_Q/q_global_norm   | 162.27414   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16133672  |
| epoch                          | 787         |
| evaluation/episode-length-avg  | 494         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 148         |
| evaluation/episode-length-std  | 413         |
| evaluation/return-average      | 2133.3186   |
| evaluation/return-max          | 4671.177    |
| evaluation/return-min          | 433.54337   |
| evaluation/return-std          | 2038.8088   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45835       |
| perf/AverageLength             | 494         |
| perf/AverageReturn             | 2133.3186   |
| perf/NormalizedReturn          | 0.464       |
| Q-avg                          | 188.02762   |
| Q-std                          | 161.7717    |
| Q_loss                         | 88.1126     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 787         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000477    |
| times/evaluation_paths         | 15.6        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 56.7        |
| timestep                       | 1000        |
| timesteps_total                | 788000      |
| train-steps                    | 788000      |
| training/Q/q1_loss             | 78.21996    |
| training/sac_pi/alpha          | 0.16131441  |
| training/sac_pi/alpha_loss     | -0.09474288 |
| training/sac_pi/logp_pi        | 4.5661287   |
| training/sac_pi/pi_entropy     | 3.271834    |
| training/sac_pi/pi_global_norm | 1.6987319   |
| training/sac_pi/policy_loss    | -212.63222  |
| training/sac_pi/std            | 0.50919235  |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 192.64885   |
| training/sac_Q/q2              | 192.4076    |
| training/sac_Q/q2_loss         | 78.326546   |
| training/sac_Q/q_global_norm   | 124.77027   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16768284  |
| epoch                          | 788         |
| evaluation/episode-length-avg  | 148         |
| evaluation/episode-length-max  | 156         |
| evaluation/episode-length-min  | 144         |
| evaluation/episode-length-std  | 3.78        |
| evaluation/return-average      | 439.77304   |
| evaluation/return-max          | 468.24475   |
| evaluation/return-min          | 421.65546   |
| evaluation/return-std          | 14.297173   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45836       |
| perf/AverageLength             | 148         |
| perf/AverageReturn             | 439.77304   |
| perf/NormalizedReturn          | 0.0954      |
| Q-avg                          | 178.2943    |
| Q-std                          | 181.72815   |
| Q_loss                         | 102.67993   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 788         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000482    |
| times/evaluation_paths         | 4.69        |
| times/timestep_after_hook      | 0.00386     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 57.2        |
| timestep                       | 1000        |
| timesteps_total                | 789000      |
| train-steps                    | 789000      |
| training/Q/q1_loss             | 93.8281     |
| training/sac_pi/alpha          | 0.16768119  |
| training/sac_pi/alpha_loss     | -0.15224361 |
| training/sac_pi/logp_pi        | 4.261537    |
| training/sac_pi/pi_entropy     | 3.364996    |
| training/sac_pi/pi_global_norm | 1.5374929   |
| training/sac_pi/policy_loss    | -202.67429  |
| training/sac_pi/std            | 0.4904932   |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 188.64513   |
| training/sac_Q/q2              | 190.55408   |
| training/sac_Q/q2_loss         | 93.42302    |
| training/sac_Q/q_global_norm   | 152.46909   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16416463   |
| epoch                          | 789          |
| evaluation/episode-length-avg  | 160          |
| evaluation/episode-length-max  | 166          |
| evaluation/episode-length-min  | 155          |
| evaluation/episode-length-std  | 3.93         |
| evaluation/return-average      | 506.01984    |
| evaluation/return-max          | 527.6433     |
| evaluation/return-min          | 487.5311     |
| evaluation/return-std          | 12.051865    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.88         |
| model/origin_ret               | 83.8         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45695        |
| perf/AverageLength             | 160          |
| perf/AverageReturn             | 506.01984    |
| perf/NormalizedReturn          | 0.11         |
| Q-avg                          | 197.75421    |
| Q-std                          | 144.09538    |
| Q_loss                         | 82.68849     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 789          |
| times/epoch_after_hook         | 1.82e-06     |
| times/epoch_before_hook        | 0.000282     |
| times/epoch_rollout_model      | 496          |
| times/evaluation_metrics       | 0.00065      |
| times/evaluation_paths         | 5.1          |
| times/timestep_after_hook      | 0.0039       |
| times/timestep_before_hook     | 0.00818      |
| times/train                    | 57.3         |
| timestep                       | 1000         |
| timesteps_total                | 790000       |
| train-steps                    | 790000       |
| training/Q/q1_loss             | 102.79141    |
| training/sac_pi/alpha          | 0.16416577   |
| training/sac_pi/alpha_loss     | -0.038574275 |
| training/sac_pi/logp_pi        | 4.5728827    |
| training/sac_pi/pi_entropy     | 3.1670365    |
| training/sac_pi/pi_global_norm | 1.8740313    |
| training/sac_pi/policy_loss    | -210.72636   |
| training/sac_pi/std            | 0.4687222    |
| training/sac_pi/valid_num      | 4970.0       |
| training/sac_Q/q1              | 198.36617    |
| training/sac_Q/q2              | 195.74385    |
| training/sac_Q/q2_loss         | 102.42486    |
| training/sac_Q/q_global_norm   | 281.31415    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1742683  |
| epoch                          | 790        |
| evaluation/episode-length-avg  | 152        |
| evaluation/episode-length-max  | 163        |
| evaluation/episode-length-min  | 144        |
| evaluation/episode-length-std  | 6.33       |
| evaluation/return-average      | 475.98077  |
| evaluation/return-max          | 518.6903   |
| evaluation/return-min          | 433.64465  |
| evaluation/return-std          | 26.681944  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45941      |
| perf/AverageLength             | 152        |
| perf/AverageReturn             | 475.98077  |
| perf/NormalizedReturn          | 0.103      |
| Q-avg                          | 178.53293  |
| Q-std                          | 217.93503  |
| Q_loss                         | 123.297775 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 790        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.000475   |
| times/evaluation_paths         | 4.76       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 57.6       |
| timestep                       | 1000       |
| timesteps_total                | 791000     |
| train-steps                    | 791000     |
| training/Q/q1_loss             | 100.603485 |
| training/sac_pi/alpha          | 0.17424716 |
| training/sac_pi/alpha_loss     | 0.08140455 |
| training/sac_pi/logp_pi        | 4.7065167  |
| training/sac_pi/pi_entropy     | 3.5466945  |
| training/sac_pi/pi_global_norm | 2.0523283  |
| training/sac_pi/policy_loss    | -202.22534 |
| training/sac_pi/std            | 0.5257714  |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 187.19173  |
| training/sac_Q/q2              | 185.2814   |
| training/sac_Q/q2_loss         | 100.97155  |
| training/sac_Q/q_global_norm   | 144.02048  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17438775 |
| epoch                          | 791        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5105.0034  |
| evaluation/return-max          | 5151.373   |
| evaluation/return-min          | 5053.001   |
| evaluation/return-std          | 25.20863   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45811      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5105.0034  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 198.50894  |
| Q-std                          | 142.58525  |
| Q_loss                         | 118.425995 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 791        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.00063    |
| times/evaluation_paths         | 31.5       |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 56.7       |
| timestep                       | 1000       |
| timesteps_total                | 792000     |
| train-steps                    | 792000     |
| training/Q/q1_loss             | 106.76234  |
| training/sac_pi/alpha          | 0.17436798 |
| training/sac_pi/alpha_loss     | 0.21269807 |
| training/sac_pi/logp_pi        | 4.444479   |
| training/sac_pi/pi_entropy     | 3.6059747  |
| training/sac_pi/pi_global_norm | 1.4762368  |
| training/sac_pi/policy_loss    | -207.91022 |
| training/sac_pi/std            | 0.5074835  |
| training/sac_pi/valid_num      | 4985.0     |
| training/sac_Q/q1              | 194.93192  |
| training/sac_Q/q2              | 195.3031   |
| training/sac_Q/q2_loss         | 105.359856 |
| training/sac_Q/q_global_norm   | 208.16277  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17194179  |
| epoch                          | 792         |
| evaluation/episode-length-avg  | 149         |
| evaluation/episode-length-max  | 164         |
| evaluation/episode-length-min  | 144         |
| evaluation/episode-length-std  | 5.87        |
| evaluation/return-average      | 429.03653   |
| evaluation/return-max          | 481.20477   |
| evaluation/return-min          | 410.73547   |
| evaluation/return-std          | 21.571125   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45859       |
| perf/AverageLength             | 149         |
| perf/AverageReturn             | 429.03653   |
| perf/NormalizedReturn          | 0.0931      |
| Q-avg                          | 189.91904   |
| Q-std                          | 236.5289    |
| Q_loss                         | 87.806755   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 792         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000139    |
| times/epoch_rollout_model      | 504         |
| times/evaluation_metrics       | 0.000434    |
| times/evaluation_paths         | 4.68        |
| times/timestep_after_hook      | 0.00378     |
| times/timestep_before_hook     | 0.00799     |
| times/train                    | 56.5        |
| timestep                       | 1000        |
| timesteps_total                | 793000      |
| train-steps                    | 793000      |
| training/Q/q1_loss             | 78.7812     |
| training/sac_pi/alpha          | 0.17198297  |
| training/sac_pi/alpha_loss     | -0.15805338 |
| training/sac_pi/logp_pi        | 4.705916    |
| training/sac_pi/pi_entropy     | 3.6302903   |
| training/sac_pi/pi_global_norm | 1.58901     |
| training/sac_pi/policy_loss    | -207.27342  |
| training/sac_pi/std            | 0.52821666  |
| training/sac_pi/valid_num      | 4942.0      |
| training/sac_Q/q1              | 190.68185   |
| training/sac_Q/q2              | 193.61877   |
| training/sac_Q/q2_loss         | 79.025536   |
| training/sac_Q/q_global_norm   | 173.9999    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17085944 |
| epoch                          | 793        |
| evaluation/episode-length-avg  | 832        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 161        |
| evaluation/episode-length-std  | 336        |
| evaluation/return-average      | 3982.1367  |
| evaluation/return-max          | 5008.0684  |
| evaluation/return-min          | 535.48645  |
| evaluation/return-std          | 1729.1849  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45784      |
| perf/AverageLength             | 832        |
| perf/AverageReturn             | 3982.1367  |
| perf/NormalizedReturn          | 0.867      |
| Q-avg                          | 178.72981  |
| Q-std                          | 203.77122  |
| Q_loss                         | 99.092834  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 793        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000338   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 25.7       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 57.8       |
| timestep                       | 1000       |
| timesteps_total                | 794000     |
| train-steps                    | 794000     |
| training/Q/q1_loss             | 118.37347  |
| training/sac_pi/alpha          | 0.17084266 |
| training/sac_pi/alpha_loss     | 0.14286605 |
| training/sac_pi/logp_pi        | 4.615247   |
| training/sac_pi/pi_entropy     | 3.398643   |
| training/sac_pi/pi_global_norm | 1.6021339  |
| training/sac_pi/policy_loss    | -201.94798 |
| training/sac_pi/std            | 0.48942944 |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 183.9205   |
| training/sac_Q/q2              | 181.88316  |
| training/sac_Q/q2_loss         | 119.3818   |
| training/sac_Q/q_global_norm   | 239.24648  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16507523 |
| epoch                          | 794        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4850.8286  |
| evaluation/return-max          | 4963.413   |
| evaluation/return-min          | 4762.172   |
| evaluation/return-std          | 66.15795   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45892      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4850.8286  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 198.36531  |
| Q-std                          | 151.70567  |
| Q_loss                         | 103.95026  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 794        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 511        |
| times/evaluation_metrics       | 0.000539   |
| times/evaluation_paths         | 30.6       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 57.3       |
| timestep                       | 1000       |
| timesteps_total                | 795000     |
| train-steps                    | 795000     |
| training/Q/q1_loss             | 87.370834  |
| training/sac_pi/alpha          | 0.16506188 |
| training/sac_pi/alpha_loss     | 0.10742726 |
| training/sac_pi/logp_pi        | 4.7820344  |
| training/sac_pi/pi_entropy     | 3.285396   |
| training/sac_pi/pi_global_norm | 1.9305558  |
| training/sac_pi/policy_loss    | -204.3318  |
| training/sac_pi/std            | 0.4991143  |
| training/sac_pi/valid_num      | 4928.0     |
| training/sac_Q/q1              | 186.26505  |
| training/sac_Q/q2              | 180.59003  |
| training/sac_Q/q2_loss         | 86.75813   |
| training/sac_Q/q_global_norm   | 201.88815  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16978064 |
| epoch                          | 795        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4732.172   |
| evaluation/return-max          | 4807.7866  |
| evaluation/return-min          | 4647.4395  |
| evaluation/return-std          | 41.74382   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45918      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4732.172   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 185.0591   |
| Q-std                          | 180.82071  |
| Q_loss                         | 86.87968   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 795        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000538   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 57.6       |
| timestep                       | 1000       |
| timesteps_total                | 796000     |
| train-steps                    | 796000     |
| training/Q/q1_loss             | 102.78308  |
| training/sac_pi/alpha          | 0.16978166 |
| training/sac_pi/alpha_loss     | 0.11149234 |
| training/sac_pi/logp_pi        | 4.5768723  |
| training/sac_pi/pi_entropy     | 3.5994942  |
| training/sac_pi/pi_global_norm | 1.8062965  |
| training/sac_pi/policy_loss    | -188.59239 |
| training/sac_pi/std            | 0.527291   |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 166.69916  |
| training/sac_Q/q2              | 166.7299   |
| training/sac_Q/q2_loss         | 103.24132  |
| training/sac_Q/q_global_norm   | 206.31995  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17206886   |
| epoch                          | 796          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4965.3057    |
| evaluation/return-max          | 5017.1035    |
| evaluation/return-min          | 4900.9585    |
| evaluation/return-std          | 35.104847    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.96         |
| model/origin_ret               | 84.6         |
| model/penalty_ret              | 80.6         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45836        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4965.3057    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 195.59378    |
| Q-std                          | 135.21779    |
| Q_loss                         | 87.45562     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 796          |
| times/epoch_after_hook         | 1.83e-06     |
| times/epoch_before_hook        | 0.00012      |
| times/epoch_rollout_model      | 497          |
| times/evaluation_metrics       | 0.000535     |
| times/evaluation_paths         | 30.6         |
| times/timestep_after_hook      | 0.00385      |
| times/timestep_before_hook     | 0.0081       |
| times/train                    | 57.2         |
| timestep                       | 1000         |
| timesteps_total                | 797000       |
| train-steps                    | 797000       |
| training/Q/q1_loss             | 86.449844    |
| training/sac_pi/alpha          | 0.17208055   |
| training/sac_pi/alpha_loss     | -0.022835795 |
| training/sac_pi/logp_pi        | 4.417943     |
| training/sac_pi/pi_entropy     | 3.406818     |
| training/sac_pi/pi_global_norm | 2.2355285    |
| training/sac_pi/policy_loss    | -206.04587   |
| training/sac_pi/std            | 0.49990985   |
| training/sac_pi/valid_num      | 4938.0       |
| training/sac_Q/q1              | 186.47256    |
| training/sac_Q/q2              | 183.30377    |
| training/sac_Q/q2_loss         | 86.93448     |
| training/sac_Q/q_global_norm   | 203.01053    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1750548    |
| epoch                          | 797          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5060.5366    |
| evaluation/return-max          | 5084.735     |
| evaluation/return-min          | 5034.3184    |
| evaluation/return-std          | 16.294445    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.95         |
| model/origin_ret               | 84           |
| model/penalty_ret              | 81.6         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45926        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5060.5366    |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 176.21582    |
| Q-std                          | 243.54207    |
| Q_loss                         | 85.913155    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 797          |
| times/epoch_after_hook         | 1.91e-06     |
| times/epoch_before_hook        | 0.000273     |
| times/epoch_rollout_model      | 482          |
| times/evaluation_metrics       | 0.000592     |
| times/evaluation_paths         | 30.9         |
| times/timestep_after_hook      | 0.00388      |
| times/timestep_before_hook     | 0.00809      |
| times/train                    | 57.8         |
| timestep                       | 1000         |
| timesteps_total                | 798000       |
| train-steps                    | 798000       |
| training/Q/q1_loss             | 87.276146    |
| training/sac_pi/alpha          | 0.17507239   |
| training/sac_pi/alpha_loss     | -0.097457334 |
| training/sac_pi/logp_pi        | 4.141603     |
| training/sac_pi/pi_entropy     | 3.5771942    |
| training/sac_pi/pi_global_norm | 1.5030085    |
| training/sac_pi/policy_loss    | -202.18214   |
| training/sac_pi/std            | 0.4994       |
| training/sac_pi/valid_num      | 4926.0       |
| training/sac_Q/q1              | 188.76053    |
| training/sac_Q/q2              | 187.63266    |
| training/sac_Q/q2_loss         | 88.4042      |
| training/sac_Q/q_global_norm   | 259.63794    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17406286  |
| epoch                          | 798         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4929.822    |
| evaluation/return-max          | 5017.2603   |
| evaluation/return-min          | 4874.15     |
| evaluation/return-std          | 38.748466   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45885       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4929.822    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 192.27959   |
| Q-std                          | 151.31015   |
| Q_loss                         | 90.1359     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 798         |
| times/epoch_after_hook         | 2.18e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000565    |
| times/evaluation_paths         | 32.3        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 58.4        |
| timestep                       | 1000        |
| timesteps_total                | 799000      |
| train-steps                    | 799000      |
| training/Q/q1_loss             | 95.100464   |
| training/sac_pi/alpha          | 0.17410125  |
| training/sac_pi/alpha_loss     | -0.33525988 |
| training/sac_pi/logp_pi        | 4.1403685   |
| training/sac_pi/pi_entropy     | 3.6741548   |
| training/sac_pi/pi_global_norm | 1.7752978   |
| training/sac_pi/policy_loss    | -201.3866   |
| training/sac_pi/std            | 0.5204996   |
| training/sac_pi/valid_num      | 4881.0      |
| training/sac_Q/q1              | 179.10672   |
| training/sac_Q/q2              | 175.52007   |
| training/sac_Q/q2_loss         | 94.68943    |
| training/sac_Q/q_global_norm   | 195.17412   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16996315 |
| epoch                          | 799        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5101.565   |
| evaluation/return-max          | 5132.548   |
| evaluation/return-min          | 5075.878   |
| evaluation/return-std          | 18.585844  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45768      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5101.565   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 193.55548  |
| Q-std                          | 171.10184  |
| Q_loss                         | 70.67783   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 799        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000141   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 31.5       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 58.3       |
| timestep                       | 1000       |
| timesteps_total                | 800000     |
| train-steps                    | 800000     |
| training/Q/q1_loss             | 86.69862   |
| training/sac_pi/alpha          | 0.17000544 |
| training/sac_pi/alpha_loss     | -0.2575405 |
| training/sac_pi/logp_pi        | 4.2081623  |
| training/sac_pi/pi_entropy     | 3.5342598  |
| training/sac_pi/pi_global_norm | 1.5990237  |
| training/sac_pi/policy_loss    | -205.96971 |
| training/sac_pi/std            | 0.50579685 |
| training/sac_pi/valid_num      | 4962.0     |
| training/sac_Q/q1              | 193.89131  |
| training/sac_Q/q2              | 191.64595  |
| training/sac_Q/q2_loss         | 85.960144  |
| training/sac_Q/q_global_norm   | 189.27725  |
--------------------------------------------------------------------------------
[WARN] 800 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.16933541   |
| epoch                          | 800          |
| evaluation/episode-length-avg  | 749          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 162          |
| evaluation/episode-length-std  | 384          |
| evaluation/return-average      | 3495.7668    |
| evaluation/return-max          | 4868.58      |
| evaluation/return-min          | 538.0875     |
| evaluation/return-std          | 1936.218     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.93         |
| model/origin_ret               | 84.5         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45720        |
| perf/AverageLength             | 749          |
| perf/AverageReturn             | 3495.7668    |
| perf/NormalizedReturn          | 0.761        |
| Q-avg                          | 193.67303    |
| Q-std                          | 175.28816    |
| Q_loss                         | 95.258606    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 800          |
| times/epoch_after_hook         | 1.85e-06     |
| times/epoch_before_hook        | 0.000128     |
| times/epoch_rollout_model      | 494          |
| times/evaluation_metrics       | 0.000592     |
| times/evaluation_paths         | 24.5         |
| times/timestep_after_hook      | 0.00399      |
| times/timestep_before_hook     | 0.00831      |
| times/train                    | 58.9         |
| timestep                       | 1000         |
| timesteps_total                | 801000       |
| train-steps                    | 801000       |
| training/Q/q1_loss             | 100.401085   |
| training/sac_pi/alpha          | 0.16930403   |
| training/sac_pi/alpha_loss     | -0.010219482 |
| training/sac_pi/logp_pi        | 4.405013     |
| training/sac_pi/pi_entropy     | 3.4284134    |
| training/sac_pi/pi_global_norm | 1.5424182    |
| training/sac_pi/policy_loss    | -208.63158   |
| training/sac_pi/std            | 0.5062492    |
| training/sac_pi/valid_num      | 4976.0       |
| training/sac_Q/q1              | 190.90869    |
| training/sac_Q/q2              | 185.16121    |
| training/sac_Q/q2_loss         | 100.59509    |
| training/sac_Q/q_global_norm   | 250.28207    |
----------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.16372956    |
| epoch                          | 801           |
| evaluation/episode-length-avg  | 579           |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 153           |
| evaluation/episode-length-std  | 421           |
| evaluation/return-average      | 2558.6597     |
| evaluation/return-max          | 4708.0728     |
| evaluation/return-min          | 480.43118     |
| evaluation/return-std          | 2063.8635     |
| model/max_penalty              | 7.34          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 2.95          |
| model/origin_ret               | 84.6          |
| model/penalty_ret              | 81.5          |
| model/val_loss                 | 0.35430613    |
| model/valid_num                | 45841         |
| perf/AverageLength             | 579           |
| perf/AverageReturn             | 2558.6597     |
| perf/NormalizedReturn          | 0.557         |
| Q-avg                          | 192.96745     |
| Q-std                          | 135.16927     |
| Q_loss                         | 85.81326      |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 801           |
| times/epoch_after_hook         | 1.93e-06      |
| times/epoch_before_hook        | 0.0144        |
| times/epoch_rollout_model      | 499           |
| times/evaluation_metrics       | 0.000633      |
| times/evaluation_paths         | 18.2          |
| times/timestep_after_hook      | 0.00391       |
| times/timestep_before_hook     | 0.00824       |
| times/train                    | 58.6          |
| timestep                       | 1000          |
| timesteps_total                | 802000        |
| train-steps                    | 802000        |
| training/Q/q1_loss             | 91.60105      |
| training/sac_pi/alpha          | 0.16375127    |
| training/sac_pi/alpha_loss     | -0.0066572055 |
| training/sac_pi/logp_pi        | 5.2287836     |
| training/sac_pi/pi_entropy     | 3.4148421     |
| training/sac_pi/pi_global_norm | 1.8292335     |
| training/sac_pi/policy_loss    | -203.41617    |
| training/sac_pi/std            | 0.5241405     |
| training/sac_pi/valid_num      | 4923.0        |
| training/sac_Q/q1              | 184.98892     |
| training/sac_Q/q2              | 182.07716     |
| training/sac_Q/q2_loss         | 91.03989      |
| training/sac_Q/q_global_norm   | 182.09889     |
-----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.168685    |
| epoch                          | 802         |
| evaluation/episode-length-avg  | 147         |
| evaluation/episode-length-max  | 159         |
| evaluation/episode-length-min  | 143         |
| evaluation/episode-length-std  | 4.55        |
| evaluation/return-average      | 464.4562    |
| evaluation/return-max          | 504.55515   |
| evaluation/return-min          | 442.93884   |
| evaluation/return-std          | 17.306253   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45945       |
| perf/AverageLength             | 147         |
| perf/AverageReturn             | 464.4562    |
| perf/NormalizedReturn          | 0.101       |
| Q-avg                          | 190.30457   |
| Q-std                          | 224.25266   |
| Q_loss                         | 90.12395    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 802         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 514         |
| times/evaluation_metrics       | 0.000479    |
| times/evaluation_paths         | 4.72        |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 59          |
| timestep                       | 1000        |
| timesteps_total                | 803000      |
| train-steps                    | 803000      |
| training/Q/q1_loss             | 81.58552    |
| training/sac_pi/alpha          | 0.16866441  |
| training/sac_pi/alpha_loss     | -0.20823056 |
| training/sac_pi/logp_pi        | 4.559695    |
| training/sac_pi/pi_entropy     | 3.5677102   |
| training/sac_pi/pi_global_norm | 2.325506    |
| training/sac_pi/policy_loss    | -202.84543  |
| training/sac_pi/std            | 0.53096277  |
| training/sac_pi/valid_num      | 4929.0      |
| training/sac_Q/q1              | 184.58603   |
| training/sac_Q/q2              | 185.07991   |
| training/sac_Q/q2_loss         | 81.70933    |
| training/sac_Q/q_global_norm   | 158.25052   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1649561   |
| epoch                          | 803         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4949.566    |
| evaluation/return-max          | 5077.9043   |
| evaluation/return-min          | 4899.997    |
| evaluation/return-std          | 47.06237    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45785       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4949.566    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 190.94194   |
| Q-std                          | 202.5476    |
| Q_loss                         | 108.69518   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 803         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000108    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000608    |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.0081      |
| times/train                    | 58.4        |
| timestep                       | 1000        |
| timesteps_total                | 804000      |
| train-steps                    | 804000      |
| training/Q/q1_loss             | 88.02173    |
| training/sac_pi/alpha          | 0.16496804  |
| training/sac_pi/alpha_loss     | -0.28469914 |
| training/sac_pi/logp_pi        | 4.393387    |
| training/sac_pi/pi_entropy     | 3.6180687   |
| training/sac_pi/pi_global_norm | 1.6763622   |
| training/sac_pi/policy_loss    | -209.36377  |
| training/sac_pi/std            | 0.5302802   |
| training/sac_pi/valid_num      | 4956.0      |
| training/sac_Q/q1              | 194.68253   |
| training/sac_Q/q2              | 195.67581   |
| training/sac_Q/q2_loss         | 86.729996   |
| training/sac_Q/q_global_norm   | 171.82979   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16780022  |
| epoch                          | 804         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4987.043    |
| evaluation/return-max          | 5049.4824   |
| evaluation/return-min          | 4859.761    |
| evaluation/return-std          | 52.002678   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45820       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4987.043    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 194.12148   |
| Q-std                          | 174.15367   |
| Q_loss                         | 73.658646   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 804         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000548    |
| times/evaluation_paths         | 32.7        |
| times/timestep_after_hook      | 0.00413     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 58.8        |
| timestep                       | 1000        |
| timesteps_total                | 805000      |
| train-steps                    | 805000      |
| training/Q/q1_loss             | 83.345474   |
| training/sac_pi/alpha          | 0.1678374   |
| training/sac_pi/alpha_loss     | -0.24287349 |
| training/sac_pi/logp_pi        | 3.9935875   |
| training/sac_pi/pi_entropy     | 3.3195946   |
| training/sac_pi/pi_global_norm | 1.710591    |
| training/sac_pi/policy_loss    | -213.27611  |
| training/sac_pi/std            | 0.46788442  |
| training/sac_pi/valid_num      | 5019.0      |
| training/sac_Q/q1              | 205.17758   |
| training/sac_Q/q2              | 206.13057   |
| training/sac_Q/q2_loss         | 83.45594    |
| training/sac_Q/q_global_norm   | 171.65001   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16792698  |
| epoch                          | 805         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5173.836    |
| evaluation/return-max          | 5214.0625   |
| evaluation/return-min          | 5067.213    |
| evaluation/return-std          | 41.398365   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45854       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5173.836    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 183.77019   |
| Q-std                          | 195.2503    |
| Q_loss                         | 83.74273    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 805         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000291    |
| times/epoch_rollout_model      | 506         |
| times/evaluation_metrics       | 0.000548    |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00805     |
| times/train                    | 58          |
| timestep                       | 1000        |
| timesteps_total                | 806000      |
| train-steps                    | 806000      |
| training/Q/q1_loss             | 96.071335   |
| training/sac_pi/alpha          | 0.16792625  |
| training/sac_pi/alpha_loss     | -0.15438114 |
| training/sac_pi/logp_pi        | 5.2648873   |
| training/sac_pi/pi_entropy     | 3.5555148   |
| training/sac_pi/pi_global_norm | 2.263623    |
| training/sac_pi/policy_loss    | -204.43437  |
| training/sac_pi/std            | 0.56628     |
| training/sac_pi/valid_num      | 4926.0      |
| training/sac_Q/q1              | 176.92122   |
| training/sac_Q/q2              | 173.5261    |
| training/sac_Q/q2_loss         | 96.48559    |
| training/sac_Q/q_global_norm   | 212.34686   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1698033   |
| epoch                          | 806         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5009.7354   |
| evaluation/return-max          | 5067.0566   |
| evaluation/return-min          | 4967.125    |
| evaluation/return-std          | 27.92123    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45807       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5009.7354   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 182.3432    |
| Q-std                          | 215.87094   |
| Q_loss                         | 105.6101    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 806         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000599    |
| times/evaluation_paths         | 31.1        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 57.3        |
| timestep                       | 1000        |
| timesteps_total                | 807000      |
| train-steps                    | 807000      |
| training/Q/q1_loss             | 95.801315   |
| training/sac_pi/alpha          | 0.16984235  |
| training/sac_pi/alpha_loss     | -0.67794937 |
| training/sac_pi/logp_pi        | 3.832077    |
| training/sac_pi/pi_entropy     | 3.5511978   |
| training/sac_pi/pi_global_norm | 1.7420231   |
| training/sac_pi/policy_loss    | -211.37683  |
| training/sac_pi/std            | 0.5201314   |
| training/sac_pi/valid_num      | 4938.0      |
| training/sac_Q/q1              | 194.08293   |
| training/sac_Q/q2              | 195.32578   |
| training/sac_Q/q2_loss         | 95.74364    |
| training/sac_Q/q_global_norm   | 208.03572   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16920279  |
| epoch                          | 807         |
| evaluation/episode-length-avg  | 117         |
| evaluation/episode-length-max  | 118         |
| evaluation/episode-length-min  | 116         |
| evaluation/episode-length-std  | 0.632       |
| evaluation/return-average      | 281.0219    |
| evaluation/return-max          | 285.3783    |
| evaluation/return-min          | 278.13638   |
| evaluation/return-std          | 2.0445013   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 83          |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45918       |
| perf/AverageLength             | 117         |
| perf/AverageReturn             | 281.0219    |
| perf/NormalizedReturn          | 0.0609      |
| Q-avg                          | 192.16629   |
| Q-std                          | 181.2848    |
| Q_loss                         | 94.00297    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 807         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 514         |
| times/evaluation_metrics       | 0.000461    |
| times/evaluation_paths         | 3.7         |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 58          |
| timestep                       | 1000        |
| timesteps_total                | 808000      |
| train-steps                    | 808000      |
| training/Q/q1_loss             | 75.26228    |
| training/sac_pi/alpha          | 0.16924419  |
| training/sac_pi/alpha_loss     | -0.14366761 |
| training/sac_pi/logp_pi        | 4.3493776   |
| training/sac_pi/pi_entropy     | 3.3865952   |
| training/sac_pi/pi_global_norm | 1.7071612   |
| training/sac_pi/policy_loss    | -210.02464  |
| training/sac_pi/std            | 0.49788722  |
| training/sac_pi/valid_num      | 4992.0      |
| training/sac_Q/q1              | 194.26045   |
| training/sac_Q/q2              | 195.10587   |
| training/sac_Q/q2_loss         | 75.33724    |
| training/sac_Q/q_global_norm   | 159.60088   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17373091 |
| epoch                          | 808        |
| evaluation/episode-length-avg  | 746        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 152        |
| evaluation/episode-length-std  | 388        |
| evaluation/return-average      | 3537.64    |
| evaluation/return-max          | 4923.093   |
| evaluation/return-min          | 478.10797  |
| evaluation/return-std          | 1999.2949  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46012      |
| perf/AverageLength             | 746        |
| perf/AverageReturn             | 3537.64    |
| perf/NormalizedReturn          | 0.77       |
| Q-avg                          | 177.23941  |
| Q-std                          | 250.34271  |
| Q_loss                         | 83.977844  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 808        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 9.57e-05   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.00048    |
| times/evaluation_paths         | 23.2       |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 58.2       |
| timestep                       | 1000       |
| timesteps_total                | 809000     |
| train-steps                    | 809000     |
| training/Q/q1_loss             | 122.190315 |
| training/sac_pi/alpha          | 0.17370181 |
| training/sac_pi/alpha_loss     | 0.3327151  |
| training/sac_pi/logp_pi        | 4.9642158  |
| training/sac_pi/pi_entropy     | 3.2537556  |
| training/sac_pi/pi_global_norm | 1.4165981  |
| training/sac_pi/policy_loss    | -199.0008  |
| training/sac_pi/std            | 0.48958892 |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 179.51385  |
| training/sac_Q/q2              | 178.67227  |
| training/sac_Q/q2_loss         | 123.06499  |
| training/sac_Q/q_global_norm   | 263.37122  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1724372   |
| epoch                          | 809         |
| evaluation/episode-length-avg  | 139         |
| evaluation/episode-length-max  | 139         |
| evaluation/episode-length-min  | 138         |
| evaluation/episode-length-std  | 0.458       |
| evaluation/return-average      | 416.70786   |
| evaluation/return-max          | 426.16156   |
| evaluation/return-min          | 410.2859    |
| evaluation/return-std          | 4.5510592   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45911       |
| perf/AverageLength             | 139         |
| perf/AverageReturn             | 416.70786   |
| perf/NormalizedReturn          | 0.0904      |
| Q-avg                          | 193.06264   |
| Q-std                          | 175.18611   |
| Q_loss                         | 88.50539    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 809         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000277    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000422    |
| times/evaluation_paths         | 4.31        |
| times/timestep_after_hook      | 0.00396     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 58.3        |
| timestep                       | 1000        |
| timesteps_total                | 810000      |
| train-steps                    | 810000      |
| training/Q/q1_loss             | 115.21622   |
| training/sac_pi/alpha          | 0.17242907  |
| training/sac_pi/alpha_loss     | 0.018442076 |
| training/sac_pi/logp_pi        | 4.421497    |
| training/sac_pi/pi_entropy     | 3.5055923   |
| training/sac_pi/pi_global_norm | 1.341709    |
| training/sac_pi/policy_loss    | -201.28528  |
| training/sac_pi/std            | 0.49871388  |
| training/sac_pi/valid_num      | 4988.0      |
| training/sac_Q/q1              | 192.16353   |
| training/sac_Q/q2              | 191.40503   |
| training/sac_Q/q2_loss         | 114.858345  |
| training/sac_Q/q_global_norm   | 235.29735   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1750723  |
| epoch                          | 810        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4850.6235  |
| evaluation/return-max          | 4925.371   |
| evaluation/return-min          | 4794.3076  |
| evaluation/return-std          | 39.471176  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46030      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4850.6235  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 195.64572  |
| Q-std                          | 158.66197  |
| Q_loss                         | 93.48022   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 810        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 8.22e-05   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.00059    |
| times/evaluation_paths         | 31.7       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 59         |
| timestep                       | 1000       |
| timesteps_total                | 811000     |
| train-steps                    | 811000     |
| training/Q/q1_loss             | 90.03019   |
| training/sac_pi/alpha          | 0.1750672  |
| training/sac_pi/alpha_loss     | 0.23667693 |
| training/sac_pi/logp_pi        | 4.6373963  |
| training/sac_pi/pi_entropy     | 3.3869808  |
| training/sac_pi/pi_global_norm | 1.4497448  |
| training/sac_pi/policy_loss    | -214.58995 |
| training/sac_pi/std            | 0.4930285  |
| training/sac_pi/valid_num      | 4992.0     |
| training/sac_Q/q1              | 201.20439  |
| training/sac_Q/q2              | 201.9427   |
| training/sac_Q/q2_loss         | 89.70514   |
| training/sac_Q/q_global_norm   | 241.76837  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17126462  |
| epoch                          | 811         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4878.415    |
| evaluation/return-max          | 4950.218    |
| evaluation/return-min          | 4807.6904   |
| evaluation/return-std          | 45.672462   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45897       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4878.415    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 185.35873   |
| Q-std                          | 212.9403    |
| Q_loss                         | 104.844124  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 811         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000535    |
| times/evaluation_paths         | 31.8        |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 58.3        |
| timestep                       | 1000        |
| timesteps_total                | 812000      |
| train-steps                    | 812000      |
| training/Q/q1_loss             | 103.44239   |
| training/sac_pi/alpha          | 0.17130314  |
| training/sac_pi/alpha_loss     | -0.24671285 |
| training/sac_pi/logp_pi        | 4.284865    |
| training/sac_pi/pi_entropy     | 3.6375923   |
| training/sac_pi/pi_global_norm | 1.438138    |
| training/sac_pi/policy_loss    | -202.96605  |
| training/sac_pi/std            | 0.5164755   |
| training/sac_pi/valid_num      | 4911.0      |
| training/sac_Q/q1              | 182.68684   |
| training/sac_Q/q2              | 182.08286   |
| training/sac_Q/q2_loss         | 103.11283   |
| training/sac_Q/q_global_norm   | 171.42244   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16989236  |
| epoch                          | 812         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4594.835    |
| evaluation/return-max          | 4955.891    |
| evaluation/return-min          | 4331.466    |
| evaluation/return-std          | 197.81058   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 82.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45832       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4594.835    |
| perf/NormalizedReturn          | 1           |
| Q-avg                          | 195.31303   |
| Q-std                          | 114.62985   |
| Q_loss                         | 109.51087   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 812         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000549    |
| times/evaluation_paths         | 31.4        |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 58.2        |
| timestep                       | 1000        |
| timesteps_total                | 813000      |
| train-steps                    | 813000      |
| training/Q/q1_loss             | 100.73695   |
| training/sac_pi/alpha          | 0.16993178  |
| training/sac_pi/alpha_loss     | -0.14571403 |
| training/sac_pi/logp_pi        | 4.435552    |
| training/sac_pi/pi_entropy     | 3.5064607   |
| training/sac_pi/pi_global_norm | 1.8409986   |
| training/sac_pi/policy_loss    | -212.62302  |
| training/sac_pi/std            | 0.5091921   |
| training/sac_pi/valid_num      | 4934.0      |
| training/sac_Q/q1              | 192.50557   |
| training/sac_Q/q2              | 194.16066   |
| training/sac_Q/q2_loss         | 100.609825  |
| training/sac_Q/q_global_norm   | 173.6799    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17414358  |
| epoch                          | 813         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5208.9717   |
| evaluation/return-max          | 5271.0166   |
| evaluation/return-min          | 5145.194    |
| evaluation/return-std          | 45.092648   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 83.6        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45925       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5208.9717   |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 192.3906    |
| Q-std                          | 153.04865   |
| Q_loss                         | 83.08281    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 813         |
| times/epoch_after_hook         | 2.11e-06    |
| times/epoch_before_hook        | 0.0003      |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000608    |
| times/evaluation_paths         | 32.9        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.0091      |
| times/train                    | 59.1        |
| timestep                       | 1000        |
| timesteps_total                | 814000      |
| train-steps                    | 814000      |
| training/Q/q1_loss             | 92.682625   |
| training/sac_pi/alpha          | 0.17416038  |
| training/sac_pi/alpha_loss     | 0.035427302 |
| training/sac_pi/logp_pi        | 5.5357733   |
| training/sac_pi/pi_entropy     | 3.6982827   |
| training/sac_pi/pi_global_norm | 1.4771792   |
| training/sac_pi/policy_loss    | -215.24013  |
| training/sac_pi/std            | 0.58039576  |
| training/sac_pi/valid_num      | 4874.0      |
| training/sac_Q/q1              | 181.21445   |
| training/sac_Q/q2              | 179.16975   |
| training/sac_Q/q2_loss         | 92.40113    |
| training/sac_Q/q_global_norm   | 210.28311   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16565093 |
| epoch                          | 814        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4991.598   |
| evaluation/return-max          | 5058.464   |
| evaluation/return-min          | 4929.72    |
| evaluation/return-std          | 45.5878    |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45961      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4991.598   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 190.36667  |
| Q-std                          | 161.03848  |
| Q_loss                         | 88.4074    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 814        |
| times/epoch_after_hook         | 2.28e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000663   |
| times/evaluation_paths         | 31.8       |
| times/timestep_after_hook      | 0.0041     |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 58.9       |
| timestep                       | 1000       |
| timesteps_total                | 815000     |
| train-steps                    | 815000     |
| training/Q/q1_loss             | 114.62821  |
| training/sac_pi/alpha          | 0.16565095 |
| training/sac_pi/alpha_loss     | 0.2871941  |
| training/sac_pi/logp_pi        | 3.9432716  |
| training/sac_pi/pi_entropy     | 3.4997451  |
| training/sac_pi/pi_global_norm | 1.4386113  |
| training/sac_pi/policy_loss    | -207.10255 |
| training/sac_pi/std            | 0.48202908 |
| training/sac_pi/valid_num      | 5005.0     |
| training/sac_Q/q1              | 199.05511  |
| training/sac_Q/q2              | 198.94441  |
| training/sac_Q/q2_loss         | 114.12244  |
| training/sac_Q/q_global_norm   | 262.13965  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16606279  |
| epoch                          | 815         |
| evaluation/episode-length-avg  | 146         |
| evaluation/episode-length-max  | 150         |
| evaluation/episode-length-min  | 144         |
| evaluation/episode-length-std  | 1.8         |
| evaluation/return-average      | 476.11118   |
| evaluation/return-max          | 487.8379    |
| evaluation/return-min          | 471.6172    |
| evaluation/return-std          | 4.7110877   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45849       |
| perf/AverageLength             | 146         |
| perf/AverageReturn             | 476.11118   |
| perf/NormalizedReturn          | 0.103       |
| Q-avg                          | 185.29404   |
| Q-std                          | 194.13696   |
| Q_loss                         | 123.59      |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 815         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000675    |
| times/evaluation_paths         | 4.75        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00809     |
| times/train                    | 57.6        |
| timestep                       | 1000        |
| timesteps_total                | 816000      |
| train-steps                    | 816000      |
| training/Q/q1_loss             | 115.06603   |
| training/sac_pi/alpha          | 0.1660695   |
| training/sac_pi/alpha_loss     | -0.10155498 |
| training/sac_pi/logp_pi        | 4.9156113   |
| training/sac_pi/pi_entropy     | 3.382949    |
| training/sac_pi/pi_global_norm | 1.8509365   |
| training/sac_pi/policy_loss    | -203.20699  |
| training/sac_pi/std            | 0.5112055   |
| training/sac_pi/valid_num      | 4882.0      |
| training/sac_Q/q1              | 180.21045   |
| training/sac_Q/q2              | 179.89706   |
| training/sac_Q/q2_loss         | 113.36488   |
| training/sac_Q/q_global_norm   | 192.98914   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16659738 |
| epoch                          | 816        |
| evaluation/episode-length-avg  | 915        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 148        |
| evaluation/episode-length-std  | 256        |
| evaluation/return-average      | 4459.3784  |
| evaluation/return-max          | 4944.7227  |
| evaluation/return-min          | 409.4033   |
| evaluation/return-std          | 1350.249   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45872      |
| perf/AverageLength             | 915        |
| perf/AverageReturn             | 4459.3784  |
| perf/NormalizedReturn          | 0.971      |
| Q-avg                          | 194.6445   |
| Q-std                          | 130.56076  |
| Q_loss                         | 73.200325  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 816        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000115   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000684   |
| times/evaluation_paths         | 29         |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 57.6       |
| timestep                       | 1000       |
| timesteps_total                | 817000     |
| train-steps                    | 817000     |
| training/Q/q1_loss             | 114.71576  |
| training/sac_pi/alpha          | 0.16655914 |
| training/sac_pi/alpha_loss     | 0.20439753 |
| training/sac_pi/logp_pi        | 4.8074894  |
| training/sac_pi/pi_entropy     | 3.346476   |
| training/sac_pi/pi_global_norm | 1.8608501  |
| training/sac_pi/policy_loss    | -208.31084 |
| training/sac_pi/std            | 0.5074021  |
| training/sac_pi/valid_num      | 4926.0     |
| training/sac_Q/q1              | 193.7732   |
| training/sac_Q/q2              | 191.44446  |
| training/sac_Q/q2_loss         | 115.29388  |
| training/sac_Q/q_global_norm   | 194.75589  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16480349 |
| epoch                          | 817        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4883.0127  |
| evaluation/return-max          | 4942.1523  |
| evaluation/return-min          | 4781.8325  |
| evaluation/return-std          | 43.38412   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45978      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4883.0127  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 187.11386  |
| Q-std                          | 206.42168  |
| Q_loss                         | 91.734665  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 817        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000294   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000544   |
| times/evaluation_paths         | 31.9       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00809    |
| times/train                    | 58.8       |
| timestep                       | 1000       |
| timesteps_total                | 818000     |
| train-steps                    | 818000     |
| training/Q/q1_loss             | 88.93037   |
| training/sac_pi/alpha          | 0.16481511 |
| training/sac_pi/alpha_loss     | 0.13146205 |
| training/sac_pi/logp_pi        | 4.7610993  |
| training/sac_pi/pi_entropy     | 3.245256   |
| training/sac_pi/pi_global_norm | 1.4492396  |
| training/sac_pi/policy_loss    | -204.07797 |
| training/sac_pi/std            | 0.4868088  |
| training/sac_pi/valid_num      | 4991.0     |
| training/sac_Q/q1              | 188.34329  |
| training/sac_Q/q2              | 188.96109  |
| training/sac_Q/q2_loss         | 88.43881   |
| training/sac_Q/q_global_norm   | 166.85133  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16651087  |
| epoch                          | 818         |
| evaluation/episode-length-avg  | 858         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 229         |
| evaluation/episode-length-std  | 260         |
| evaluation/return-average      | 4259.3896   |
| evaluation/return-max          | 5138.075    |
| evaluation/return-min          | 865.4486    |
| evaluation/return-std          | 1415.893    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45843       |
| perf/AverageLength             | 858         |
| perf/AverageReturn             | 4259.3896   |
| perf/NormalizedReturn          | 0.927       |
| Q-avg                          | 201.91806   |
| Q-std                          | 128.66167   |
| Q_loss                         | 81.20032    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 818         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000544    |
| times/evaluation_paths         | 26.9        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00832     |
| times/train                    | 57.4        |
| timestep                       | 1000        |
| timesteps_total                | 819000      |
| train-steps                    | 819000      |
| training/Q/q1_loss             | 111.4594    |
| training/sac_pi/alpha          | 0.16652377  |
| training/sac_pi/alpha_loss     | -0.07332745 |
| training/sac_pi/logp_pi        | 4.9892397   |
| training/sac_pi/pi_entropy     | 3.570356    |
| training/sac_pi/pi_global_norm | 2.0082545   |
| training/sac_pi/policy_loss    | -203.09772  |
| training/sac_pi/std            | 0.53708386  |
| training/sac_pi/valid_num      | 4892.0      |
| training/sac_Q/q1              | 182.1207    |
| training/sac_Q/q2              | 184.27087   |
| training/sac_Q/q2_loss         | 110.993256  |
| training/sac_Q/q_global_norm   | 181.57764   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17171395  |
| epoch                          | 819         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4967.73     |
| evaluation/return-max          | 4992.751    |
| evaluation/return-min          | 4952.2764   |
| evaluation/return-std          | 12.138837   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45968       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4967.73     |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 178.48128   |
| Q-std                          | 200.95316   |
| Q_loss                         | 126.14654   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 819         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000602    |
| times/evaluation_paths         | 31.1        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 57.6        |
| timestep                       | 1000        |
| timesteps_total                | 820000      |
| train-steps                    | 820000      |
| training/Q/q1_loss             | 91.67429    |
| training/sac_pi/alpha          | 0.17170179  |
| training/sac_pi/alpha_loss     | -0.43978545 |
| training/sac_pi/logp_pi        | 4.9922967   |
| training/sac_pi/pi_entropy     | 3.5377285   |
| training/sac_pi/pi_global_norm | 1.747593    |
| training/sac_pi/policy_loss    | -202.00235  |
| training/sac_pi/std            | 0.5195608   |
| training/sac_pi/valid_num      | 4909.0      |
| training/sac_Q/q1              | 175.4218    |
| training/sac_Q/q2              | 175.37793   |
| training/sac_Q/q2_loss         | 90.593544   |
| training/sac_Q/q_global_norm   | 173.09157   |
---------------------------------------------------------------------------------
[WARN] 820 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.168736    |
| epoch                          | 820         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4334.486    |
| evaluation/return-max          | 4520.991    |
| evaluation/return-min          | 4237.3867   |
| evaluation/return-std          | 88.988525   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45649       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4334.486    |
| perf/NormalizedReturn          | 0.944       |
| Q-avg                          | 199.23851   |
| Q-std                          | 138.57486   |
| Q_loss                         | 96.35107    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 820         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000547    |
| times/evaluation_paths         | 31.3        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 56.7        |
| timestep                       | 1000        |
| timesteps_total                | 821000      |
| train-steps                    | 821000      |
| training/Q/q1_loss             | 103.75498   |
| training/sac_pi/alpha          | 0.16873136  |
| training/sac_pi/alpha_loss     | -0.06789274 |
| training/sac_pi/logp_pi        | 5.4347544   |
| training/sac_pi/pi_entropy     | 3.4250798   |
| training/sac_pi/pi_global_norm | 1.7071897   |
| training/sac_pi/policy_loss    | -209.45576  |
| training/sac_pi/std            | 0.5298721   |
| training/sac_pi/valid_num      | 4889.0      |
| training/sac_Q/q1              | 187.3948    |
| training/sac_Q/q2              | 190.03583   |
| training/sac_Q/q2_loss         | 102.73577   |
| training/sac_Q/q_global_norm   | 177.99783   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17019436   |
| epoch                          | 821          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4948.8184    |
| evaluation/return-max          | 4962.9688    |
| evaluation/return-min          | 4935.5054    |
| evaluation/return-std          | 9.190122     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.95         |
| model/origin_ret               | 83.9         |
| model/penalty_ret              | 81.1         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45747        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4948.8184    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 193.64351    |
| Q-std                          | 162.82268    |
| Q_loss                         | 110.28449    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 821          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.000273     |
| times/epoch_rollout_model      | 499          |
| times/evaluation_metrics       | 0.000642     |
| times/evaluation_paths         | 31.7         |
| times/timestep_after_hook      | 0.00389      |
| times/timestep_before_hook     | 0.00812      |
| times/train                    | 57.1         |
| timestep                       | 1000         |
| timesteps_total                | 822000       |
| train-steps                    | 822000       |
| training/Q/q1_loss             | 85.42797     |
| training/sac_pi/alpha          | 0.1702246    |
| training/sac_pi/alpha_loss     | -0.086652234 |
| training/sac_pi/logp_pi        | 4.7008524    |
| training/sac_pi/pi_entropy     | 3.5640202    |
| training/sac_pi/pi_global_norm | 1.6117913    |
| training/sac_pi/policy_loss    | -198.59906   |
| training/sac_pi/std            | 0.5267749    |
| training/sac_pi/valid_num      | 4926.0       |
| training/sac_Q/q1              | 180.43562    |
| training/sac_Q/q2              | 178.8495     |
| training/sac_Q/q2_loss         | 84.510475    |
| training/sac_Q/q_global_norm   | 192.15556    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16563216  |
| epoch                          | 822         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4968.4863   |
| evaluation/return-max          | 5052.1777   |
| evaluation/return-min          | 4919.087    |
| evaluation/return-std          | 40.692257   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45947       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4968.4863   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 199.59366   |
| Q-std                          | 159.03563   |
| Q_loss                         | 93.332565   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 822         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000527    |
| times/evaluation_paths         | 31.5        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 57.8        |
| timestep                       | 1000        |
| timesteps_total                | 823000      |
| train-steps                    | 823000      |
| training/Q/q1_loss             | 103.18174   |
| training/sac_pi/alpha          | 0.16564742  |
| training/sac_pi/alpha_loss     | 0.079043716 |
| training/sac_pi/logp_pi        | 4.6802936   |
| training/sac_pi/pi_entropy     | 3.5100656   |
| training/sac_pi/pi_global_norm | 1.7699031   |
| training/sac_pi/policy_loss    | -206.71143  |
| training/sac_pi/std            | 0.5179622   |
| training/sac_pi/valid_num      | 4914.0      |
| training/sac_Q/q1              | 187.59322   |
| training/sac_Q/q2              | 187.19284   |
| training/sac_Q/q2_loss         | 104.177605  |
| training/sac_Q/q_global_norm   | 175.57047   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1708426  |
| epoch                          | 823        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4865.253   |
| evaluation/return-max          | 4915.3     |
| evaluation/return-min          | 4793.337   |
| evaluation/return-std          | 34.37331   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46010      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4865.253   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 182.49153  |
| Q-std                          | 219.05771  |
| Q_loss                         | 90.82355   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 823        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000141   |
| times/epoch_rollout_model      | 512        |
| times/evaluation_metrics       | 0.000573   |
| times/evaluation_paths         | 31.7       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 56.8       |
| timestep                       | 1000       |
| timesteps_total                | 824000     |
| train-steps                    | 824000     |
| training/Q/q1_loss             | 98.686554  |
| training/sac_pi/alpha          | 0.17084204 |
| training/sac_pi/alpha_loss     | -0.2427232 |
| training/sac_pi/logp_pi        | 5.439258   |
| training/sac_pi/pi_entropy     | 3.6009178  |
| training/sac_pi/pi_global_norm | 1.9165666  |
| training/sac_pi/policy_loss    | -203.96179 |
| training/sac_pi/std            | 0.56311363 |
| training/sac_pi/valid_num      | 4874.0     |
| training/sac_Q/q1              | 180.99556  |
| training/sac_Q/q2              | 180.29167  |
| training/sac_Q/q2_loss         | 99.00139   |
| training/sac_Q/q_global_norm   | 242.74008  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17276521   |
| epoch                          | 824          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4765.2764    |
| evaluation/return-max          | 4848.3457    |
| evaluation/return-min          | 4638.1235    |
| evaluation/return-std          | 61.514275    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.98         |
| model/origin_ret               | 84.6         |
| model/penalty_ret              | 81.6         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45811        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4765.2764    |
| perf/NormalizedReturn          | 1.04         |
| Q-avg                          | 177.12953    |
| Q-std                          | 242.31223    |
| Q_loss                         | 112.3263     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 824          |
| times/epoch_after_hook         | 1.75e-06     |
| times/epoch_before_hook        | 0.00013      |
| times/epoch_rollout_model      | 490          |
| times/evaluation_metrics       | 0.000534     |
| times/evaluation_paths         | 31.6         |
| times/timestep_after_hook      | 0.00388      |
| times/timestep_before_hook     | 0.00813      |
| times/train                    | 57.9         |
| timestep                       | 1000         |
| timesteps_total                | 825000       |
| train-steps                    | 825000       |
| training/Q/q1_loss             | 98.71497     |
| training/sac_pi/alpha          | 0.17277642   |
| training/sac_pi/alpha_loss     | -0.037482683 |
| training/sac_pi/logp_pi        | 5.122995     |
| training/sac_pi/pi_entropy     | 3.8052735    |
| training/sac_pi/pi_global_norm | 1.5810448    |
| training/sac_pi/policy_loss    | -194.34572   |
| training/sac_pi/std            | 0.57964534   |
| training/sac_pi/valid_num      | 4927.0       |
| training/sac_Q/q1              | 177.25557    |
| training/sac_Q/q2              | 177.32149    |
| training/sac_Q/q2_loss         | 96.571884    |
| training/sac_Q/q_global_norm   | 185.08255    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17703152  |
| epoch                          | 825         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5163.1553   |
| evaluation/return-max          | 5198.931    |
| evaluation/return-min          | 5131.706    |
| evaluation/return-std          | 19.002506   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45782       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5163.1553   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 200.80634   |
| Q-std                          | 161.2077    |
| Q_loss                         | 100.49953   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 825         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000328    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000624    |
| times/evaluation_paths         | 31.3        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 57.7        |
| timestep                       | 1000        |
| timesteps_total                | 826000      |
| train-steps                    | 826000      |
| training/Q/q1_loss             | 82.92653    |
| training/sac_pi/alpha          | 0.17706205  |
| training/sac_pi/alpha_loss     | -0.30859977 |
| training/sac_pi/logp_pi        | 3.8216996   |
| training/sac_pi/pi_entropy     | 3.6882415   |
| training/sac_pi/pi_global_norm | 1.367565    |
| training/sac_pi/policy_loss    | -213.03062  |
| training/sac_pi/std            | 0.5203959   |
| training/sac_pi/valid_num      | 4999.0      |
| training/sac_Q/q1              | 205.27402   |
| training/sac_Q/q2              | 204.78017   |
| training/sac_Q/q2_loss         | 83.672775   |
| training/sac_Q/q_global_norm   | 229.50587   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16569678  |
| epoch                          | 826         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5009.0244   |
| evaluation/return-max          | 5037.423    |
| evaluation/return-min          | 4984.567    |
| evaluation/return-std          | 15.251937   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45873       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5009.0244   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 181.64006   |
| Q-std                          | 215.47084   |
| Q_loss                         | 102.04573   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 826         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.00012     |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000544    |
| times/evaluation_paths         | 31.7        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 57.5        |
| timestep                       | 1000        |
| timesteps_total                | 827000      |
| train-steps                    | 827000      |
| training/Q/q1_loss             | 86.780754   |
| training/sac_pi/alpha          | 0.16572422  |
| training/sac_pi/alpha_loss     | -0.13121544 |
| training/sac_pi/logp_pi        | 4.088206    |
| training/sac_pi/pi_entropy     | 3.3085942   |
| training/sac_pi/pi_global_norm | 1.6377981   |
| training/sac_pi/policy_loss    | -209.26091  |
| training/sac_pi/std            | 0.49094275  |
| training/sac_pi/valid_num      | 4969.0      |
| training/sac_Q/q1              | 198.15645   |
| training/sac_Q/q2              | 196.82832   |
| training/sac_Q/q2_loss         | 86.75283    |
| training/sac_Q/q_global_norm   | 193.58125   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16843063 |
| epoch                          | 827        |
| evaluation/episode-length-avg  | 917        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 170        |
| evaluation/episode-length-std  | 249        |
| evaluation/return-average      | 4670.917   |
| evaluation/return-max          | 5168.05    |
| evaluation/return-min          | 560.6059   |
| evaluation/return-std          | 1370.2104  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45927      |
| perf/AverageLength             | 917        |
| perf/AverageReturn             | 4670.917   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 178.79834  |
| Q-std                          | 184.3482   |
| Q_loss                         | 110.94657  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 827        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000563   |
| times/evaluation_paths         | 28.8       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 56.9       |
| timestep                       | 1000       |
| timesteps_total                | 828000     |
| train-steps                    | 828000     |
| training/Q/q1_loss             | 114.68056  |
| training/sac_pi/alpha          | 0.16839936 |
| training/sac_pi/alpha_loss     | 0.09066876 |
| training/sac_pi/logp_pi        | 4.4787464  |
| training/sac_pi/pi_entropy     | 3.4149852  |
| training/sac_pi/pi_global_norm | 1.7946801  |
| training/sac_pi/policy_loss    | -205.71533 |
| training/sac_pi/std            | 0.5109857  |
| training/sac_pi/valid_num      | 4958.0     |
| training/sac_Q/q1              | 191.55263  |
| training/sac_Q/q2              | 187.6877   |
| training/sac_Q/q2_loss         | 114.894844 |
| training/sac_Q/q_global_norm   | 206.08427  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16599561 |
| epoch                          | 828        |
| evaluation/episode-length-avg  | 324        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 153        |
| evaluation/episode-length-std  | 338        |
| evaluation/return-average      | 1364.0787  |
| evaluation/return-max          | 5055.8936  |
| evaluation/return-min          | 433.95474  |
| evaluation/return-std          | 1827.8601  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45992      |
| perf/AverageLength             | 324        |
| perf/AverageReturn             | 1364.0787  |
| perf/NormalizedReturn          | 0.297      |
| Q-avg                          | 197.03381  |
| Q-std                          | 165.6433   |
| Q_loss                         | 97.956825  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 828        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000525   |
| times/evaluation_paths         | 10.1       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 58.4       |
| timestep                       | 1000       |
| timesteps_total                | 829000     |
| train-steps                    | 829000     |
| training/Q/q1_loss             | 83.34631   |
| training/sac_pi/alpha          | 0.16599452 |
| training/sac_pi/alpha_loss     | 0.13751408 |
| training/sac_pi/logp_pi        | 4.4903536  |
| training/sac_pi/pi_entropy     | 3.3535886  |
| training/sac_pi/pi_global_norm | 1.4821196  |
| training/sac_pi/policy_loss    | -212.74011 |
| training/sac_pi/std            | 0.4986967  |
| training/sac_pi/valid_num      | 4955.0     |
| training/sac_Q/q1              | 201.98975  |
| training/sac_Q/q2              | 199.74391  |
| training/sac_Q/q2_loss         | 83.291275  |
| training/sac_Q/q_global_norm   | 149.22824  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16414437 |
| epoch                          | 829        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4633.4253  |
| evaluation/return-max          | 4696.818   |
| evaluation/return-min          | 4506.4854  |
| evaluation/return-std          | 54.640408  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45993      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4633.4253  |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 207.97688  |
| Q-std                          | 100.34917  |
| Q_loss                         | 97.375435  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 829        |
| times/epoch_after_hook         | 2.29e-06   |
| times/epoch_before_hook        | 0.00028    |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000547   |
| times/evaluation_paths         | 31.8       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 58.2       |
| timestep                       | 1000       |
| timesteps_total                | 830000     |
| train-steps                    | 830000     |
| training/Q/q1_loss             | 112.000435 |
| training/sac_pi/alpha          | 0.16415817 |
| training/sac_pi/alpha_loss     | -0.5274471 |
| training/sac_pi/logp_pi        | 4.7408495  |
| training/sac_pi/pi_entropy     | 3.453591   |
| training/sac_pi/pi_global_norm | 1.5073267  |
| training/sac_pi/policy_loss    | -213.50859 |
| training/sac_pi/std            | 0.54823935 |
| training/sac_pi/valid_num      | 4918.0     |
| training/sac_Q/q1              | 192.90701  |
| training/sac_Q/q2              | 195.32759  |
| training/sac_Q/q2_loss         | 112.81315  |
| training/sac_Q/q_global_norm   | 232.40419  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17323585  |
| epoch                          | 830         |
| evaluation/episode-length-avg  | 662         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 150         |
| evaluation/episode-length-std  | 413         |
| evaluation/return-average      | 3130.2178   |
| evaluation/return-max          | 4974.02     |
| evaluation/return-min          | 443.47934   |
| evaluation/return-std          | 2182.1584   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45738       |
| perf/AverageLength             | 662         |
| perf/AverageReturn             | 3130.2178   |
| perf/NormalizedReturn          | 0.682       |
| Q-avg                          | 198.80379   |
| Q-std                          | 175.68994   |
| Q_loss                         | 92.54908    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 830         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 501         |
| times/evaluation_metrics       | 0.000575    |
| times/evaluation_paths         | 20.6        |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 57.5        |
| timestep                       | 1000        |
| timesteps_total                | 831000      |
| train-steps                    | 831000      |
| training/Q/q1_loss             | 127.28708   |
| training/sac_pi/alpha          | 0.17324863  |
| training/sac_pi/alpha_loss     | -0.42915672 |
| training/sac_pi/logp_pi        | 5.1879287   |
| training/sac_pi/pi_entropy     | 3.7907772   |
| training/sac_pi/pi_global_norm | 1.6542848   |
| training/sac_pi/policy_loss    | -205.70665  |
| training/sac_pi/std            | 0.60389113  |
| training/sac_pi/valid_num      | 4861.0      |
| training/sac_Q/q1              | 174.22844   |
| training/sac_Q/q2              | 171.5242    |
| training/sac_Q/q2_loss         | 126.9582    |
| training/sac_Q/q_global_norm   | 250.2461    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17307492  |
| epoch                          | 831         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5027.4233   |
| evaluation/return-max          | 5089.332    |
| evaluation/return-min          | 4993.3164   |
| evaluation/return-std          | 29.385923   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45896       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5027.4233   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 188.32935   |
| Q-std                          | 204.9409    |
| Q_loss                         | 92.273636   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 831         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000526    |
| times/evaluation_paths         | 31.3        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 57.9        |
| timestep                       | 1000        |
| timesteps_total                | 832000      |
| train-steps                    | 832000      |
| training/Q/q1_loss             | 94.50006    |
| training/sac_pi/alpha          | 0.17309496  |
| training/sac_pi/alpha_loss     | -0.35316733 |
| training/sac_pi/logp_pi        | 4.1218796   |
| training/sac_pi/pi_entropy     | 3.4735649   |
| training/sac_pi/pi_global_norm | 1.7274957   |
| training/sac_pi/policy_loss    | -207.86555  |
| training/sac_pi/std            | 0.51142603  |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 194.42781   |
| training/sac_Q/q2              | 193.87259   |
| training/sac_Q/q2_loss         | 95.05109    |
| training/sac_Q/q_global_norm   | 159.89203   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1717996   |
| epoch                          | 832         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5021.3447   |
| evaluation/return-max          | 5038.829    |
| evaluation/return-min          | 5003.135    |
| evaluation/return-std          | 10.819234   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 82.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45983       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5021.3447   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 205.59583   |
| Q-std                          | 109.01364   |
| Q_loss                         | 70.65107    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 832         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000534    |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00803     |
| times/train                    | 56.4        |
| timestep                       | 1000        |
| timesteps_total                | 833000      |
| train-steps                    | 833000      |
| training/Q/q1_loss             | 119.75958   |
| training/sac_pi/alpha          | 0.1717971   |
| training/sac_pi/alpha_loss     | 0.028459562 |
| training/sac_pi/logp_pi        | 4.6729383   |
| training/sac_pi/pi_entropy     | 3.2487233   |
| training/sac_pi/pi_global_norm | 1.7895236   |
| training/sac_pi/policy_loss    | -205.40677  |
| training/sac_pi/std            | 0.47918     |
| training/sac_pi/valid_num      | 4918.0      |
| training/sac_Q/q1              | 189.37042   |
| training/sac_Q/q2              | 190.47209   |
| training/sac_Q/q2_loss         | 119.73574   |
| training/sac_Q/q_global_norm   | 365.11993   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17045476 |
| epoch                          | 833        |
| evaluation/episode-length-avg  | 323        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 151        |
| evaluation/episode-length-std  | 338        |
| evaluation/return-average      | 1442.053   |
| evaluation/return-max          | 5218.6978  |
| evaluation/return-min          | 483.0169   |
| evaluation/return-std          | 1886.8577  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45995      |
| perf/AverageLength             | 323        |
| perf/AverageReturn             | 1442.053   |
| perf/NormalizedReturn          | 0.314      |
| Q-avg                          | 192.32384  |
| Q-std                          | 138.8271   |
| Q_loss                         | 103.441025 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 833        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000271   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000421   |
| times/evaluation_paths         | 10.2       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 57.1       |
| timestep                       | 1000       |
| timesteps_total                | 834000     |
| train-steps                    | 834000     |
| training/Q/q1_loss             | 122.73105  |
| training/sac_pi/alpha          | 0.17045905 |
| training/sac_pi/alpha_loss     | 0.39159435 |
| training/sac_pi/logp_pi        | 4.4535565  |
| training/sac_pi/pi_entropy     | 3.5279503  |
| training/sac_pi/pi_global_norm | 1.4641643  |
| training/sac_pi/policy_loss    | -211.48639 |
| training/sac_pi/std            | 0.5065848  |
| training/sac_pi/valid_num      | 4960.0     |
| training/sac_Q/q1              | 198.6288   |
| training/sac_Q/q2              | 198.56688  |
| training/sac_Q/q2_loss         | 123.78494  |
| training/sac_Q/q_global_norm   | 220.82388  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17032602 |
| epoch                          | 834        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4863.2983  |
| evaluation/return-max          | 4909.3555  |
| evaluation/return-min          | 4835.212   |
| evaluation/return-std          | 20.404957  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45844      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4863.2983  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 206.8193   |
| Q-std                          | 107.5894   |
| Q_loss                         | 84.738464  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 834        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 8.13e-05   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000554   |
| times/evaluation_paths         | 31.3       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00783    |
| times/train                    | 56.7       |
| timestep                       | 1000       |
| timesteps_total                | 835000     |
| train-steps                    | 835000     |
| training/Q/q1_loss             | 99.17871   |
| training/sac_pi/alpha          | 0.17034507 |
| training/sac_pi/alpha_loss     | -0.4381864 |
| training/sac_pi/logp_pi        | 4.2805977  |
| training/sac_pi/pi_entropy     | 3.343207   |
| training/sac_pi/pi_global_norm | 1.4975381  |
| training/sac_pi/policy_loss    | -211.60655 |
| training/sac_pi/std            | 0.4923486  |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 196.53487  |
| training/sac_Q/q2              | 195.65797  |
| training/sac_Q/q2_loss         | 98.39261   |
| training/sac_Q/q_global_norm   | 156.75523  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1637993  |
| epoch                          | 835        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4925.9297  |
| evaluation/return-max          | 5035.6465  |
| evaluation/return-min          | 4843.873   |
| evaluation/return-std          | 57.025352  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45864      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4925.9297  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 192.35857  |
| Q-std                          | 147.55565  |
| Q_loss                         | 95.79454   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 835        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000584   |
| times/evaluation_paths         | 31.3       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 56.7       |
| timestep                       | 1000       |
| timesteps_total                | 836000     |
| train-steps                    | 836000     |
| training/Q/q1_loss             | 97.27632   |
| training/sac_pi/alpha          | 0.16378874 |
| training/sac_pi/alpha_loss     | 0.02560822 |
| training/sac_pi/logp_pi        | 3.81184    |
| training/sac_pi/pi_entropy     | 3.5142074  |
| training/sac_pi/pi_global_norm | 1.827438   |
| training/sac_pi/policy_loss    | -200.65364 |
| training/sac_pi/std            | 0.48082215 |
| training/sac_pi/valid_num      | 4998.0     |
| training/sac_Q/q1              | 193.10326  |
| training/sac_Q/q2              | 193.81161  |
| training/sac_Q/q2_loss         | 97.055786  |
| training/sac_Q/q_global_norm   | 199.12671  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16653435 |
| epoch                          | 836        |
| evaluation/episode-length-avg  | 469        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 115        |
| evaluation/episode-length-std  | 433        |
| evaluation/return-average      | 2179.5059  |
| evaluation/return-max          | 5037.792   |
| evaluation/return-min          | 280.74408  |
| evaluation/return-std          | 2313.455   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45815      |
| perf/AverageLength             | 469        |
| perf/AverageReturn             | 2179.5059  |
| perf/NormalizedReturn          | 0.474      |
| Q-avg                          | 186.17435  |
| Q-std                          | 161.23691  |
| Q_loss                         | 106.42917  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 836        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000514   |
| times/evaluation_paths         | 14.8       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 57.1       |
| timestep                       | 1000       |
| timesteps_total                | 837000     |
| train-steps                    | 837000     |
| training/Q/q1_loss             | 111.52672  |
| training/sac_pi/alpha          | 0.16654563 |
| training/sac_pi/alpha_loss     | 0.27503663 |
| training/sac_pi/logp_pi        | 5.0306478  |
| training/sac_pi/pi_entropy     | 3.3583534  |
| training/sac_pi/pi_global_norm | 1.8605288  |
| training/sac_pi/policy_loss    | -200.64772 |
| training/sac_pi/std            | 0.5238732  |
| training/sac_pi/valid_num      | 4936.0     |
| training/sac_Q/q1              | 180.76382  |
| training/sac_Q/q2              | 178.97856  |
| training/sac_Q/q2_loss         | 111.1466   |
| training/sac_Q/q_global_norm   | 201.07098  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17167807   |
| epoch                          | 837          |
| evaluation/episode-length-avg  | 656          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 139          |
| evaluation/episode-length-std  | 421          |
| evaluation/return-average      | 3162.9873    |
| evaluation/return-max          | 5028.849     |
| evaluation/return-min          | 387.65707    |
| evaluation/return-std          | 2262.4194    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.95         |
| model/origin_ret               | 83.7         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 46001        |
| perf/AverageLength             | 656          |
| perf/AverageReturn             | 3162.9873    |
| perf/NormalizedReturn          | 0.689        |
| Q-avg                          | 185.55037    |
| Q-std                          | 172.80688    |
| Q_loss                         | 103.666855   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 837          |
| times/epoch_after_hook         | 1.96e-06     |
| times/epoch_before_hook        | 0.000337     |
| times/epoch_rollout_model      | 493          |
| times/evaluation_metrics       | 0.000646     |
| times/evaluation_paths         | 21.1         |
| times/timestep_after_hook      | 0.00381      |
| times/timestep_before_hook     | 0.00797      |
| times/train                    | 57.6         |
| timestep                       | 1000         |
| timesteps_total                | 838000       |
| train-steps                    | 838000       |
| training/Q/q1_loss             | 97.00567     |
| training/sac_pi/alpha          | 0.17169254   |
| training/sac_pi/alpha_loss     | 0.0012850965 |
| training/sac_pi/logp_pi        | 4.5966067    |
| training/sac_pi/pi_entropy     | 3.4310615    |
| training/sac_pi/pi_global_norm | 1.5392033    |
| training/sac_pi/policy_loss    | -204.85648   |
| training/sac_pi/std            | 0.50913036   |
| training/sac_pi/valid_num      | 4939.0       |
| training/sac_Q/q1              | 185.71257    |
| training/sac_Q/q2              | 179.57048    |
| training/sac_Q/q2_loss         | 96.454544    |
| training/sac_Q/q_global_norm   | 143.87643    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16771033  |
| epoch                          | 838         |
| evaluation/episode-length-avg  | 915         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 147         |
| evaluation/episode-length-std  | 256         |
| evaluation/return-average      | 4628.6943   |
| evaluation/return-max          | 5154.5117   |
| evaluation/return-min          | 370.84937   |
| evaluation/return-std          | 1419.522    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45948       |
| perf/AverageLength             | 915         |
| perf/AverageReturn             | 4628.6943   |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 170.04889   |
| Q-std                          | 229.692     |
| Q_loss                         | 97.74852    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 838         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000153    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000555    |
| times/evaluation_paths         | 29.1        |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 58.2        |
| timestep                       | 1000        |
| timesteps_total                | 839000      |
| train-steps                    | 839000      |
| training/Q/q1_loss             | 88.70336    |
| training/sac_pi/alpha          | 0.16770747  |
| training/sac_pi/alpha_loss     | -0.06615797 |
| training/sac_pi/logp_pi        | 4.5811205   |
| training/sac_pi/pi_entropy     | 3.5800774   |
| training/sac_pi/pi_global_norm | 1.8737721   |
| training/sac_pi/policy_loss    | -207.05876  |
| training/sac_pi/std            | 0.5215684   |
| training/sac_pi/valid_num      | 4977.0      |
| training/sac_Q/q1              | 193.06398   |
| training/sac_Q/q2              | 192.22464   |
| training/sac_Q/q2_loss         | 88.53602    |
| training/sac_Q/q_global_norm   | 181.12033   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16808352 |
| epoch                          | 839        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4909.708   |
| evaluation/return-max          | 4934.7793  |
| evaluation/return-min          | 4890.1465  |
| evaluation/return-std          | 13.924854  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45877      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4909.708   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 179.53062  |
| Q-std                          | 176.63098  |
| Q_loss                         | 94.447945  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 839        |
| times/epoch_after_hook         | 2.06e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000543   |
| times/evaluation_paths         | 31.5       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 56.6       |
| timestep                       | 1000       |
| timesteps_total                | 840000     |
| train-steps                    | 840000     |
| training/Q/q1_loss             | 119.99681  |
| training/sac_pi/alpha          | 0.1681238  |
| training/sac_pi/alpha_loss     | 0.09153216 |
| training/sac_pi/logp_pi        | 4.2183585  |
| training/sac_pi/pi_entropy     | 3.5062904  |
| training/sac_pi/pi_global_norm | 1.6035856  |
| training/sac_pi/policy_loss    | -194.03311 |
| training/sac_pi/std            | 0.48650128 |
| training/sac_pi/valid_num      | 5023.0     |
| training/sac_Q/q1              | 184.58943  |
| training/sac_Q/q2              | 183.94646  |
| training/sac_Q/q2_loss         | 119.584946 |
| training/sac_Q/q_global_norm   | 240.3041   |
--------------------------------------------------------------------------------
[WARN] 840 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16412114 |
| epoch                          | 840        |
| evaluation/episode-length-avg  | 142        |
| evaluation/episode-length-max  | 144        |
| evaluation/episode-length-min  | 140        |
| evaluation/episode-length-std  | 1.08       |
| evaluation/return-average      | 422.1906   |
| evaluation/return-max          | 429.39243  |
| evaluation/return-min          | 413.65363  |
| evaluation/return-std          | 4.403339   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46083      |
| perf/AverageLength             | 142        |
| perf/AverageReturn             | 422.1906   |
| perf/NormalizedReturn          | 0.0916     |
| Q-avg                          | 184.17787  |
| Q-std                          | 165.0695   |
| Q_loss                         | 110.01184  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 840        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000436   |
| times/evaluation_paths         | 4.46       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 57.8       |
| timestep                       | 1000       |
| timesteps_total                | 841000     |
| train-steps                    | 841000     |
| training/Q/q1_loss             | 85.12235   |
| training/sac_pi/alpha          | 0.16409169 |
| training/sac_pi/alpha_loss     | 0.15772901 |
| training/sac_pi/logp_pi        | 4.8884463  |
| training/sac_pi/pi_entropy     | 3.616228   |
| training/sac_pi/pi_global_norm | 1.6824974  |
| training/sac_pi/policy_loss    | -207.11719 |
| training/sac_pi/std            | 0.54706013 |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 187.26697  |
| training/sac_Q/q2              | 183.50746  |
| training/sac_Q/q2_loss         | 85.39011   |
| training/sac_Q/q_global_norm   | 148.0509   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16120914   |
| epoch                          | 841          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5072.0913    |
| evaluation/return-max          | 5107.667     |
| evaluation/return-min          | 5044.465     |
| evaluation/return-std          | 18.961828    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.02         |
| model/origin_ret               | 85.6         |
| model/penalty_ret              | 81.5         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 46053        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5072.0913    |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 193.74101    |
| Q-std                          | 139.92845    |
| Q_loss                         | 86.89054     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 841          |
| times/epoch_after_hook         | 1.92e-06     |
| times/epoch_before_hook        | 0.000282     |
| times/epoch_rollout_model      | 498          |
| times/evaluation_metrics       | 0.000582     |
| times/evaluation_paths         | 31.6         |
| times/timestep_after_hook      | 0.0039       |
| times/timestep_before_hook     | 0.00822      |
| times/train                    | 56.6         |
| timestep                       | 1000         |
| timesteps_total                | 842000       |
| train-steps                    | 842000       |
| training/Q/q1_loss             | 105.15367    |
| training/sac_pi/alpha          | 0.16121194   |
| training/sac_pi/alpha_loss     | -0.109215386 |
| training/sac_pi/logp_pi        | 4.7432556    |
| training/sac_pi/pi_entropy     | 3.511676     |
| training/sac_pi/pi_global_norm | 1.6103538    |
| training/sac_pi/policy_loss    | -202.2002    |
| training/sac_pi/std            | 0.543204     |
| training/sac_pi/valid_num      | 4937.0       |
| training/sac_Q/q1              | 183.74654    |
| training/sac_Q/q2              | 184.19475    |
| training/sac_Q/q2_loss         | 104.37467    |
| training/sac_Q/q_global_norm   | 210.42424    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1636692    |
| epoch                          | 842          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4885.424     |
| evaluation/return-max          | 4949.4365    |
| evaluation/return-min          | 4747.6416    |
| evaluation/return-std          | 53.208294    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.92         |
| model/origin_ret               | 84.6         |
| model/penalty_ret              | 81.4         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45701        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4885.424     |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 190.85185    |
| Q-std                          | 174.79587    |
| Q_loss                         | 94.73674     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 842          |
| times/epoch_after_hook         | 1.88e-06     |
| times/epoch_before_hook        | 0.000117     |
| times/epoch_rollout_model      | 504          |
| times/evaluation_metrics       | 0.000514     |
| times/evaluation_paths         | 31.4         |
| times/timestep_after_hook      | 0.00387      |
| times/timestep_before_hook     | 0.00795      |
| times/train                    | 56.7         |
| timestep                       | 1000         |
| timesteps_total                | 843000       |
| train-steps                    | 843000       |
| training/Q/q1_loss             | 86.213135    |
| training/sac_pi/alpha          | 0.16367245   |
| training/sac_pi/alpha_loss     | -0.091170706 |
| training/sac_pi/logp_pi        | 4.830508     |
| training/sac_pi/pi_entropy     | 3.6395054    |
| training/sac_pi/pi_global_norm | 1.6585056    |
| training/sac_pi/policy_loss    | -215.78902   |
| training/sac_pi/std            | 0.5524438    |
| training/sac_pi/valid_num      | 4908.0       |
| training/sac_Q/q1              | 200.8261     |
| training/sac_Q/q2              | 198.13832    |
| training/sac_Q/q2_loss         | 86.580734    |
| training/sac_Q/q_global_norm   | 168.77364    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16396406   |
| epoch                          | 843          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4445.099     |
| evaluation/return-max          | 4701.354     |
| evaluation/return-min          | 4248.691     |
| evaluation/return-std          | 157.00658    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.99         |
| model/origin_ret               | 84.8         |
| model/penalty_ret              | 80.6         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45874        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4445.099     |
| perf/NormalizedReturn          | 0.968        |
| Q-avg                          | 188.89665    |
| Q-std                          | 166.73894    |
| Q_loss                         | 101.70584    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 843          |
| times/epoch_after_hook         | 2.04e-06     |
| times/epoch_before_hook        | 0.000135     |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.00055      |
| times/evaluation_paths         | 31.3         |
| times/timestep_after_hook      | 0.00392      |
| times/timestep_before_hook     | 0.00816      |
| times/train                    | 57.5         |
| timestep                       | 1000         |
| timesteps_total                | 844000       |
| train-steps                    | 844000       |
| training/Q/q1_loss             | 88.09484     |
| training/sac_pi/alpha          | 0.16394679   |
| training/sac_pi/alpha_loss     | -0.056991924 |
| training/sac_pi/logp_pi        | 4.713249     |
| training/sac_pi/pi_entropy     | 3.4315038    |
| training/sac_pi/pi_global_norm | 1.5909669    |
| training/sac_pi/policy_loss    | -207.92905   |
| training/sac_pi/std            | 0.5207819    |
| training/sac_pi/valid_num      | 4955.0       |
| training/sac_Q/q1              | 192.5104     |
| training/sac_Q/q2              | 192.01266    |
| training/sac_Q/q2_loss         | 87.92024     |
| training/sac_Q/q_global_norm   | 182.76817    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16739437 |
| epoch                          | 844        |
| evaluation/episode-length-avg  | 488        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 138        |
| evaluation/episode-length-std  | 418        |
| evaluation/return-average      | 2222.9656  |
| evaluation/return-max          | 5040.3154  |
| evaluation/return-min          | 364.44565  |
| evaluation/return-std          | 2246.5989  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45863      |
| perf/AverageLength             | 488        |
| perf/AverageReturn             | 2222.9656  |
| perf/NormalizedReturn          | 0.484      |
| Q-avg                          | 187.18954  |
| Q-std                          | 196.5042   |
| Q_loss                         | 97.07846   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 844        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000494   |
| times/evaluation_paths         | 15.1       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 57         |
| timestep                       | 1000       |
| timesteps_total                | 845000     |
| train-steps                    | 845000     |
| training/Q/q1_loss             | 86.07438   |
| training/sac_pi/alpha          | 0.16732423 |
| training/sac_pi/alpha_loss     | 0.48082343 |
| training/sac_pi/logp_pi        | 4.128148   |
| training/sac_pi/pi_entropy     | 3.3874314  |
| training/sac_pi/pi_global_norm | 1.8450532  |
| training/sac_pi/policy_loss    | -207.8452  |
| training/sac_pi/std            | 0.48854885 |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 196.39275  |
| training/sac_Q/q2              | 197.27937  |
| training/sac_Q/q2_loss         | 87.22292   |
| training/sac_Q/q_global_norm   | 183.82356  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16620573  |
| epoch                          | 845         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4840.783    |
| evaluation/return-max          | 4970.952    |
| evaluation/return-min          | 4775.2246   |
| evaluation/return-std          | 59.13312    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45913       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4840.783    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 193.26065   |
| Q-std                          | 119.50568   |
| Q_loss                         | 87.76143    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 845         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.00033     |
| times/epoch_rollout_model      | 504         |
| times/evaluation_metrics       | 0.000632    |
| times/evaluation_paths         | 31.6        |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 57.7        |
| timestep                       | 1000        |
| timesteps_total                | 846000      |
| train-steps                    | 846000      |
| training/Q/q1_loss             | 100.617516  |
| training/sac_pi/alpha          | 0.16622496  |
| training/sac_pi/alpha_loss     | -0.01746785 |
| training/sac_pi/logp_pi        | 4.4591713   |
| training/sac_pi/pi_entropy     | 3.3967178   |
| training/sac_pi/pi_global_norm | 1.9137632   |
| training/sac_pi/policy_loss    | -203.99753  |
| training/sac_pi/std            | 0.49507606  |
| training/sac_pi/valid_num      | 4950.0      |
| training/sac_Q/q1              | 188.94838   |
| training/sac_Q/q2              | 188.74675   |
| training/sac_Q/q2_loss         | 100.89788   |
| training/sac_Q/q_global_norm   | 181.38698   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1689035  |
| epoch                          | 846        |
| evaluation/episode-length-avg  | 577        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 151        |
| evaluation/episode-length-std  | 423        |
| evaluation/return-average      | 2722.478   |
| evaluation/return-max          | 5085.674   |
| evaluation/return-min          | 457.83792  |
| evaluation/return-std          | 2249.7712  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45832      |
| perf/AverageLength             | 577        |
| perf/AverageReturn             | 2722.478   |
| perf/NormalizedReturn          | 0.593      |
| Q-avg                          | 190.55832  |
| Q-std                          | 138.66939  |
| Q_loss                         | 86.19902   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 846        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000106   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000489   |
| times/evaluation_paths         | 18.2       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00804    |
| times/train                    | 57.3       |
| timestep                       | 1000       |
| timesteps_total                | 847000     |
| train-steps                    | 847000     |
| training/Q/q1_loss             | 95.887344  |
| training/sac_pi/alpha          | 0.16890912 |
| training/sac_pi/alpha_loss     | 0.18566184 |
| training/sac_pi/logp_pi        | 4.4773307  |
| training/sac_pi/pi_entropy     | 3.4477391  |
| training/sac_pi/pi_global_norm | 1.5444762  |
| training/sac_pi/policy_loss    | -209.64044 |
| training/sac_pi/std            | 0.48612973 |
| training/sac_pi/valid_num      | 4948.0     |
| training/sac_Q/q1              | 195.93542  |
| training/sac_Q/q2              | 196.55968  |
| training/sac_Q/q2_loss         | 96.698456  |
| training/sac_Q/q_global_norm   | 178.00923  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16628945 |
| epoch                          | 847        |
| evaluation/episode-length-avg  | 917        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 173        |
| evaluation/episode-length-std  | 248        |
| evaluation/return-average      | 4507.356   |
| evaluation/return-max          | 4993.339   |
| evaluation/return-min          | 457.90668  |
| evaluation/return-std          | 1349.9028  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45881      |
| perf/AverageLength             | 917        |
| perf/AverageReturn             | 4507.356   |
| perf/NormalizedReturn          | 0.981      |
| Q-avg                          | 197.5627   |
| Q-std                          | 132.88881  |
| Q_loss                         | 95.07554   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 847        |
| times/epoch_after_hook         | 3.44e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000517   |
| times/evaluation_paths         | 28.5       |
| times/timestep_after_hook      | 0.00398    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 57.7       |
| timestep                       | 1000       |
| timesteps_total                | 848000     |
| train-steps                    | 848000     |
| training/Q/q1_loss             | 106.47497  |
| training/sac_pi/alpha          | 0.16631557 |
| training/sac_pi/alpha_loss     | 0.17239933 |
| training/sac_pi/logp_pi        | 4.32545    |
| training/sac_pi/pi_entropy     | 3.359651   |
| training/sac_pi/pi_global_norm | 1.45223    |
| training/sac_pi/policy_loss    | -211.66838 |
| training/sac_pi/std            | 0.48501384 |
| training/sac_pi/valid_num      | 4993.0     |
| training/sac_Q/q1              | 201.91643  |
| training/sac_Q/q2              | 202.22519  |
| training/sac_Q/q2_loss         | 107.72528  |
| training/sac_Q/q_global_norm   | 224.81735  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16401811 |
| epoch                          | 848        |
| evaluation/episode-length-avg  | 216        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 127        |
| evaluation/episode-length-std  | 261        |
| evaluation/return-average      | 780.7192   |
| evaluation/return-max          | 4874.5684  |
| evaluation/return-min          | 317.9539   |
| evaluation/return-std          | 1364.6412  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45916      |
| perf/AverageLength             | 216        |
| perf/AverageReturn             | 780.7192   |
| perf/NormalizedReturn          | 0.17       |
| Q-avg                          | 186.96469  |
| Q-std                          | 197.72812  |
| Q_loss                         | 92.60398   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 848        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000112   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.00051    |
| times/evaluation_paths         | 6.84       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 57.1       |
| timestep                       | 1000       |
| timesteps_total                | 849000     |
| train-steps                    | 849000     |
| training/Q/q1_loss             | 79.63714   |
| training/sac_pi/alpha          | 0.16398056 |
| training/sac_pi/alpha_loss     | 0.26823214 |
| training/sac_pi/logp_pi        | 4.2981877  |
| training/sac_pi/pi_entropy     | 3.4457488  |
| training/sac_pi/pi_global_norm | 1.8224546  |
| training/sac_pi/policy_loss    | -212.43723 |
| training/sac_pi/std            | 0.50603616 |
| training/sac_pi/valid_num      | 4994.0     |
| training/sac_Q/q1              | 198.71443  |
| training/sac_Q/q2              | 197.16606  |
| training/sac_Q/q2_loss         | 80.02876   |
| training/sac_Q/q_global_norm   | 164.06708  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16195738 |
| epoch                          | 849        |
| evaluation/episode-length-avg  | 829        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 143        |
| evaluation/episode-length-std  | 342        |
| evaluation/return-average      | 3657.9714  |
| evaluation/return-max          | 4604.257   |
| evaluation/return-min          | 360.86987  |
| evaluation/return-std          | 1641.5295  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46043      |
| perf/AverageLength             | 829        |
| perf/AverageReturn             | 3657.9714  |
| perf/NormalizedReturn          | 0.796      |
| Q-avg                          | 192.46648  |
| Q-std                          | 178.35815  |
| Q_loss                         | 90.877335  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 849        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000351   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000496   |
| times/evaluation_paths         | 25.9       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 56.7       |
| timestep                       | 1000       |
| timesteps_total                | 850000     |
| train-steps                    | 850000     |
| training/Q/q1_loss             | 90.49095   |
| training/sac_pi/alpha          | 0.16192664 |
| training/sac_pi/alpha_loss     | 0.13135596 |
| training/sac_pi/logp_pi        | 4.2092133  |
| training/sac_pi/pi_entropy     | 3.37824    |
| training/sac_pi/pi_global_norm | 1.5611172  |
| training/sac_pi/policy_loss    | -212.16763 |
| training/sac_pi/std            | 0.49186566 |
| training/sac_pi/valid_num      | 4979.0     |
| training/sac_Q/q1              | 201.86073  |
| training/sac_Q/q2              | 199.6099   |
| training/sac_Q/q2_loss         | 90.00964   |
| training/sac_Q/q_global_norm   | 162.87912  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1650004  |
| epoch                          | 850        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4937.7188  |
| evaluation/return-max          | 5050.3784  |
| evaluation/return-min          | 4540.413   |
| evaluation/return-std          | 191.43475  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45970      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4937.7188  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 193.44223  |
| Q-std                          | 202.49863  |
| Q_loss                         | 99.269745  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 850        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 31.8       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 57.8       |
| timestep                       | 1000       |
| timesteps_total                | 851000     |
| train-steps                    | 851000     |
| training/Q/q1_loss             | 109.06607  |
| training/sac_pi/alpha          | 0.16499503 |
| training/sac_pi/alpha_loss     | 0.15139556 |
| training/sac_pi/logp_pi        | 4.689912   |
| training/sac_pi/pi_entropy     | 3.5215225  |
| training/sac_pi/pi_global_norm | 1.4392608  |
| training/sac_pi/policy_loss    | -210.5234  |
| training/sac_pi/std            | 0.53114974 |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 193.16757  |
| training/sac_Q/q2              | 187.52397  |
| training/sac_Q/q2_loss         | 110.21096  |
| training/sac_Q/q_global_norm   | 233.15298  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1610872  |
| epoch                          | 851        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5167.56    |
| evaluation/return-max          | 5204.388   |
| evaluation/return-min          | 5126.552   |
| evaluation/return-std          | 23.986311  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46025      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5167.56    |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 196.7494   |
| Q-std                          | 152.4669   |
| Q_loss                         | 93.93046   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 851        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000141   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000564   |
| times/evaluation_paths         | 31.3       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 56.7       |
| timestep                       | 1000       |
| timesteps_total                | 852000     |
| train-steps                    | 852000     |
| training/Q/q1_loss             | 92.04472   |
| training/sac_pi/alpha          | 0.16113587 |
| training/sac_pi/alpha_loss     | -0.5898515 |
| training/sac_pi/logp_pi        | 4.346385   |
| training/sac_pi/pi_entropy     | 3.6749237  |
| training/sac_pi/pi_global_norm | 2.5853524  |
| training/sac_pi/policy_loss    | -214.07994 |
| training/sac_pi/std            | 0.54774696 |
| training/sac_pi/valid_num      | 4890.0     |
| training/sac_Q/q1              | 195.6118   |
| training/sac_Q/q2              | 192.6656   |
| training/sac_Q/q2_loss         | 91.12977   |
| training/sac_Q/q_global_norm   | 166.35486  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16532445  |
| epoch                          | 852         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4900.869    |
| evaluation/return-max          | 4949.5156   |
| evaluation/return-min          | 4853.3926   |
| evaluation/return-std          | 28.918854   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45740       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4900.869    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 186.79941   |
| Q-std                          | 177.57982   |
| Q_loss                         | 106.49337   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 852         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000118    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.00052     |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.004       |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 57.9        |
| timestep                       | 1000        |
| timesteps_total                | 853000      |
| train-steps                    | 853000      |
| training/Q/q1_loss             | 115.62215   |
| training/sac_pi/alpha          | 0.1653191   |
| training/sac_pi/alpha_loss     | -0.19350678 |
| training/sac_pi/logp_pi        | 4.7850533   |
| training/sac_pi/pi_entropy     | 3.5363717   |
| training/sac_pi/pi_global_norm | 1.7234793   |
| training/sac_pi/policy_loss    | -204.10423  |
| training/sac_pi/std            | 0.53045315  |
| training/sac_pi/valid_num      | 4928.0      |
| training/sac_Q/q1              | 185.5269    |
| training/sac_Q/q2              | 181.585     |
| training/sac_Q/q2_loss         | 115.501854  |
| training/sac_Q/q_global_norm   | 191.25446   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16593954  |
| epoch                          | 853         |
| evaluation/episode-length-avg  | 143         |
| evaluation/episode-length-max  | 144         |
| evaluation/episode-length-min  | 142         |
| evaluation/episode-length-std  | 0.6         |
| evaluation/return-average      | 459.40884   |
| evaluation/return-max          | 474.0396    |
| evaluation/return-min          | 441.8418    |
| evaluation/return-std          | 10.797636   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45787       |
| perf/AverageLength             | 143         |
| perf/AverageReturn             | 459.40884   |
| perf/NormalizedReturn          | 0.0997      |
| Q-avg                          | 187.20595   |
| Q-std                          | 156.16815   |
| Q_loss                         | 101.5105    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 853         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000332    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000467    |
| times/evaluation_paths         | 4.48        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 56.5        |
| timestep                       | 1000        |
| timesteps_total                | 854000      |
| train-steps                    | 854000      |
| training/Q/q1_loss             | 87.51528    |
| training/sac_pi/alpha          | 0.16594698  |
| training/sac_pi/alpha_loss     | -0.13155536 |
| training/sac_pi/logp_pi        | 4.607568    |
| training/sac_pi/pi_entropy     | 3.6397667   |
| training/sac_pi/pi_global_norm | 1.7160721   |
| training/sac_pi/policy_loss    | -213.6551   |
| training/sac_pi/std            | 0.5341301   |
| training/sac_pi/valid_num      | 4958.0      |
| training/sac_Q/q1              | 196.57553   |
| training/sac_Q/q2              | 195.91922   |
| training/sac_Q/q2_loss         | 86.868706   |
| training/sac_Q/q_global_norm   | 192.67044   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1729622    |
| epoch                          | 854          |
| evaluation/episode-length-avg  | 126          |
| evaluation/episode-length-max  | 136          |
| evaluation/episode-length-min  | 122          |
| evaluation/episode-length-std  | 4.69         |
| evaluation/return-average      | 311.90073    |
| evaluation/return-max          | 349.5885     |
| evaluation/return-min          | 295.01907    |
| evaluation/return-std          | 17.495823    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.95         |
| model/origin_ret               | 84.4         |
| model/penalty_ret              | 80.8         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45862        |
| perf/AverageLength             | 126          |
| perf/AverageReturn             | 311.90073    |
| perf/NormalizedReturn          | 0.0676       |
| Q-avg                          | 197.2153     |
| Q-std                          | 170.30984    |
| Q_loss                         | 107.27135    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 854          |
| times/epoch_after_hook         | 1.76e-06     |
| times/epoch_before_hook        | 0.000128     |
| times/epoch_rollout_model      | 506          |
| times/evaluation_metrics       | 0.000482     |
| times/evaluation_paths         | 4.02         |
| times/timestep_after_hook      | 0.00397      |
| times/timestep_before_hook     | 0.00826      |
| times/train                    | 57.8         |
| timestep                       | 1000         |
| timesteps_total                | 855000       |
| train-steps                    | 855000       |
| training/Q/q1_loss             | 90.77742     |
| training/sac_pi/alpha          | 0.1729328    |
| training/sac_pi/alpha_loss     | -0.089494385 |
| training/sac_pi/logp_pi        | 4.259168     |
| training/sac_pi/pi_entropy     | 3.646974     |
| training/sac_pi/pi_global_norm | 1.5339997    |
| training/sac_pi/policy_loss    | -209.46684   |
| training/sac_pi/std            | 0.532836     |
| training/sac_pi/valid_num      | 5010.0       |
| training/sac_Q/q1              | 197.1706     |
| training/sac_Q/q2              | 194.99178    |
| training/sac_Q/q2_loss         | 90.76286     |
| training/sac_Q/q_global_norm   | 165.28296    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1695629  |
| epoch                          | 855        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4854.892   |
| evaluation/return-max          | 5065.5684  |
| evaluation/return-min          | 4524.0127  |
| evaluation/return-std          | 202.74341  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45766      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4854.892   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 187.0325   |
| Q-std                          | 206.06778  |
| Q_loss                         | 93.53156   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 855        |
| times/epoch_after_hook         | 2e-06      |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000521   |
| times/evaluation_paths         | 31.8       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 57.4       |
| timestep                       | 1000       |
| timesteps_total                | 856000     |
| train-steps                    | 856000     |
| training/Q/q1_loss             | 91.03217   |
| training/sac_pi/alpha          | 0.16960546 |
| training/sac_pi/alpha_loss     | -0.5840254 |
| training/sac_pi/logp_pi        | 4.2821665  |
| training/sac_pi/pi_entropy     | 3.5765862  |
| training/sac_pi/pi_global_norm | 1.6725007  |
| training/sac_pi/policy_loss    | -213.17506 |
| training/sac_pi/std            | 0.529541   |
| training/sac_pi/valid_num      | 4976.0     |
| training/sac_Q/q1              | 198.14528  |
| training/sac_Q/q2              | 194.85811  |
| training/sac_Q/q2_loss         | 91.55991   |
| training/sac_Q/q_global_norm   | 212.02458  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16996068   |
| epoch                          | 856          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4504.9556    |
| evaluation/return-max          | 4610.052     |
| evaluation/return-min          | 4417.8936    |
| evaluation/return-std          | 53.283604    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.98         |
| model/origin_ret               | 85.1         |
| model/penalty_ret              | 81.8         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45894        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4504.9556    |
| perf/NormalizedReturn          | 0.981        |
| Q-avg                          | 184.45218    |
| Q-std                          | 169.71915    |
| Q_loss                         | 119.10066    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 856          |
| times/epoch_after_hook         | 1.83e-06     |
| times/epoch_before_hook        | 0.000135     |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.000545     |
| times/evaluation_paths         | 32           |
| times/timestep_after_hook      | 0.00404      |
| times/timestep_before_hook     | 0.00834      |
| times/train                    | 58.2         |
| timestep                       | 1000         |
| timesteps_total                | 857000       |
| train-steps                    | 857000       |
| training/Q/q1_loss             | 102.79734    |
| training/sac_pi/alpha          | 0.16996174   |
| training/sac_pi/alpha_loss     | -0.011455391 |
| training/sac_pi/logp_pi        | 4.21556      |
| training/sac_pi/pi_entropy     | 3.3421187    |
| training/sac_pi/pi_global_norm | 1.7211546    |
| training/sac_pi/policy_loss    | -206.75961   |
| training/sac_pi/std            | 0.47854316   |
| training/sac_pi/valid_num      | 4967.0       |
| training/sac_Q/q1              | 198.13174    |
| training/sac_Q/q2              | 197.0875     |
| training/sac_Q/q2_loss         | 103.09578    |
| training/sac_Q/q_global_norm   | 189.6802     |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1680875   |
| epoch                          | 857         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4735.352    |
| evaluation/return-max          | 4866.4385   |
| evaluation/return-min          | 4571.0913   |
| evaluation/return-std          | 97.74295    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45857       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4735.352    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 194.39124   |
| Q-std                          | 171.84451   |
| Q_loss                         | 90.60186    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 857         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000338    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.00052     |
| times/evaluation_paths         | 32.1        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 57.4        |
| timestep                       | 1000        |
| timesteps_total                | 858000      |
| train-steps                    | 858000      |
| training/Q/q1_loss             | 101.09793   |
| training/sac_pi/alpha          | 0.16808142  |
| training/sac_pi/alpha_loss     | -0.15811194 |
| training/sac_pi/logp_pi        | 4.2548814   |
| training/sac_pi/pi_entropy     | 3.4838738   |
| training/sac_pi/pi_global_norm | 1.6854472   |
| training/sac_pi/policy_loss    | -199.78477  |
| training/sac_pi/std            | 0.51224715  |
| training/sac_pi/valid_num      | 4892.0      |
| training/sac_Q/q1              | 184.18283   |
| training/sac_Q/q2              | 181.73013   |
| training/sac_Q/q2_loss         | 99.312744   |
| training/sac_Q/q_global_norm   | 174.0313    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16982333  |
| epoch                          | 858         |
| evaluation/episode-length-avg  | 591         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 139         |
| evaluation/episode-length-std  | 411         |
| evaluation/return-average      | 2730.4414   |
| evaluation/return-max          | 5042.631    |
| evaluation/return-min          | 407.6113    |
| evaluation/return-std          | 2144.2078   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45992       |
| perf/AverageLength             | 591         |
| perf/AverageReturn             | 2730.4414   |
| perf/NormalizedReturn          | 0.594       |
| Q-avg                          | 197.0105    |
| Q-std                          | 165.25061   |
| Q_loss                         | 97.11487    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 858         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 503         |
| times/evaluation_metrics       | 0.000487    |
| times/evaluation_paths         | 18.6        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 57.6        |
| timestep                       | 1000        |
| timesteps_total                | 859000      |
| train-steps                    | 859000      |
| training/Q/q1_loss             | 110.312485  |
| training/sac_pi/alpha          | 0.16980231  |
| training/sac_pi/alpha_loss     | 0.107946366 |
| training/sac_pi/logp_pi        | 4.230175    |
| training/sac_pi/pi_entropy     | 3.5176673   |
| training/sac_pi/pi_global_norm | 1.4041133   |
| training/sac_pi/policy_loss    | -202.42085  |
| training/sac_pi/std            | 0.5107536   |
| training/sac_pi/valid_num      | 4998.0      |
| training/sac_Q/q1              | 190.3536    |
| training/sac_Q/q2              | 188.36029   |
| training/sac_Q/q2_loss         | 110.48717   |
| training/sac_Q/q_global_norm   | 273.228     |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16992755 |
| epoch                          | 859        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5047.034   |
| evaluation/return-max          | 5144.841   |
| evaluation/return-min          | 4903.376   |
| evaluation/return-std          | 68.65798   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45853      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5047.034   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 195.86922  |
| Q-std                          | 149.20421  |
| Q_loss                         | 100.27402  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 859        |
| times/epoch_after_hook         | 2.09e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 505        |
| times/evaluation_metrics       | 0.000663   |
| times/evaluation_paths         | 32.6       |
| times/timestep_after_hook      | 0.00409    |
| times/timestep_before_hook     | 0.00852    |
| times/train                    | 60.2       |
| timestep                       | 1000       |
| timesteps_total                | 860000     |
| train-steps                    | 860000     |
| training/Q/q1_loss             | 102.14926  |
| training/sac_pi/alpha          | 0.16993825 |
| training/sac_pi/alpha_loss     | -0.2113867 |
| training/sac_pi/logp_pi        | 4.0990057  |
| training/sac_pi/pi_entropy     | 3.372664   |
| training/sac_pi/pi_global_norm | 1.2946726  |
| training/sac_pi/policy_loss    | -211.31557 |
| training/sac_pi/std            | 0.495114   |
| training/sac_pi/valid_num      | 4981.0     |
| training/sac_Q/q1              | 199.12335  |
| training/sac_Q/q2              | 200.08542  |
| training/sac_Q/q2_loss         | 101.82139  |
| training/sac_Q/q_global_norm   | 197.18314  |
--------------------------------------------------------------------------------
[WARN] 860 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16885991  |
| epoch                          | 860         |
| evaluation/episode-length-avg  | 833         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 162         |
| evaluation/episode-length-std  | 335         |
| evaluation/return-average      | 4143.5205   |
| evaluation/return-max          | 5134.1094   |
| evaluation/return-min          | 504.26254   |
| evaluation/return-std          | 1815.0428   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45978       |
| perf/AverageLength             | 833         |
| perf/AverageReturn             | 4143.5205   |
| perf/NormalizedReturn          | 0.902       |
| Q-avg                          | 204.49284   |
| Q-std                          | 113.649376  |
| Q_loss                         | 104.025375  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 860         |
| times/epoch_after_hook         | 2.03e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 534         |
| times/evaluation_metrics       | 0.000769    |
| times/evaluation_paths         | 27.5        |
| times/timestep_after_hook      | 0.00446     |
| times/timestep_before_hook     | 0.00863     |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 861000      |
| train-steps                    | 861000      |
| training/Q/q1_loss             | 93.49844    |
| training/sac_pi/alpha          | 0.16888508  |
| training/sac_pi/alpha_loss     | -0.09787231 |
| training/sac_pi/logp_pi        | 4.340888    |
| training/sac_pi/pi_entropy     | 3.4110444   |
| training/sac_pi/pi_global_norm | 1.6496896   |
| training/sac_pi/policy_loss    | -216.6908   |
| training/sac_pi/std            | 0.5158333   |
| training/sac_pi/valid_num      | 4945.0      |
| training/sac_Q/q1              | 200.00137   |
| training/sac_Q/q2              | 199.01233   |
| training/sac_Q/q2_loss         | 94.193794   |
| training/sac_Q/q_global_norm   | 197.13033   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17286642 |
| epoch                          | 861        |
| evaluation/episode-length-avg  | 144        |
| evaluation/episode-length-max  | 148        |
| evaluation/episode-length-min  | 142        |
| evaluation/episode-length-std  | 1.83       |
| evaluation/return-average      | 403.2643   |
| evaluation/return-max          | 420.8078   |
| evaluation/return-min          | 385.62128  |
| evaluation/return-std          | 10.947482  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45952      |
| perf/AverageLength             | 144        |
| perf/AverageReturn             | 403.2643   |
| perf/NormalizedReturn          | 0.0875     |
| Q-avg                          | 194.10144  |
| Q-std                          | 152.7395   |
| Q_loss                         | 100.219406 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 861        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000386   |
| times/epoch_rollout_model      | 530        |
| times/evaluation_metrics       | 0.000489   |
| times/evaluation_paths         | 4.72       |
| times/timestep_after_hook      | 0.00412    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 62.2       |
| timestep                       | 1000       |
| timesteps_total                | 862000     |
| train-steps                    | 862000     |
| training/Q/q1_loss             | 82.365036  |
| training/sac_pi/alpha          | 0.17281182 |
| training/sac_pi/alpha_loss     | 0.14094748 |
| training/sac_pi/logp_pi        | 3.897367   |
| training/sac_pi/pi_entropy     | 3.4542282  |
| training/sac_pi/pi_global_norm | 1.6043985  |
| training/sac_pi/policy_loss    | -208.94803 |
| training/sac_pi/std            | 0.48739263 |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 197.58432  |
| training/sac_Q/q2              | 199.1324   |
| training/sac_Q/q2_loss         | 82.47921   |
| training/sac_Q/q_global_norm   | 175.49857  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17158483  |
| epoch                          | 862         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5033.2573   |
| evaluation/return-max          | 5114.5312   |
| evaluation/return-min          | 4952.592    |
| evaluation/return-std          | 41.134323   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45827       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5033.2573   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 193.2454    |
| Q-std                          | 173.62457   |
| Q_loss                         | 99.64091    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 862         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 9.25e-05    |
| times/epoch_rollout_model      | 516         |
| times/evaluation_metrics       | 0.000568    |
| times/evaluation_paths         | 31.8        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00847     |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 863000      |
| train-steps                    | 863000      |
| training/Q/q1_loss             | 106.035866  |
| training/sac_pi/alpha          | 0.17159349  |
| training/sac_pi/alpha_loss     | -0.27228054 |
| training/sac_pi/logp_pi        | 4.1742573   |
| training/sac_pi/pi_entropy     | 3.4906094   |
| training/sac_pi/pi_global_norm | 1.4064728   |
| training/sac_pi/policy_loss    | -205.71442  |
| training/sac_pi/std            | 0.50506485  |
| training/sac_pi/valid_num      | 4975.0      |
| training/sac_Q/q1              | 191.13033   |
| training/sac_Q/q2              | 190.82454   |
| training/sac_Q/q2_loss         | 106.58819   |
| training/sac_Q/q_global_norm   | 183.12094   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16206118  |
| epoch                          | 863         |
| evaluation/episode-length-avg  | 962         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 625         |
| evaluation/episode-length-std  | 112         |
| evaluation/return-average      | 4489.0464   |
| evaluation/return-max          | 5067.5986   |
| evaluation/return-min          | 2672.5796   |
| evaluation/return-std          | 646.2799    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45779       |
| perf/AverageLength             | 962         |
| perf/AverageReturn             | 4489.0464   |
| perf/NormalizedReturn          | 0.978       |
| Q-avg                          | 199.0778    |
| Q-std                          | 143.4153    |
| Q_loss                         | 90.17843    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 863         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 503         |
| times/evaluation_metrics       | 0.000546    |
| times/evaluation_paths         | 30.9        |
| times/timestep_after_hook      | 0.00376     |
| times/timestep_before_hook     | 0.00809     |
| times/train                    | 58.8        |
| timestep                       | 1000        |
| timesteps_total                | 864000      |
| train-steps                    | 864000      |
| training/Q/q1_loss             | 112.55048   |
| training/sac_pi/alpha          | 0.16209416  |
| training/sac_pi/alpha_loss     | -0.37621495 |
| training/sac_pi/logp_pi        | 4.7070537   |
| training/sac_pi/pi_entropy     | 3.5384338   |
| training/sac_pi/pi_global_norm | 1.7239803   |
| training/sac_pi/policy_loss    | -208.10771  |
| training/sac_pi/std            | 0.53592545  |
| training/sac_pi/valid_num      | 4947.0      |
| training/sac_Q/q1              | 189.36044   |
| training/sac_Q/q2              | 191.1811    |
| training/sac_Q/q2_loss         | 112.93434   |
| training/sac_Q/q_global_norm   | 216.44312   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16348514 |
| epoch                          | 864        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4978.627   |
| evaluation/return-max          | 5031.7188  |
| evaluation/return-min          | 4921.681   |
| evaluation/return-std          | 33.011185  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 83.8       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46079      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4978.627   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 194.22043  |
| Q-std                          | 185.95776  |
| Q_loss                         | 94.267715  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 864        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 516        |
| times/evaluation_metrics       | 0.000563   |
| times/evaluation_paths         | 32.4       |
| times/timestep_after_hook      | 0.00398    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 865000     |
| train-steps                    | 865000     |
| training/Q/q1_loss             | 100.53571  |
| training/sac_pi/alpha          | 0.16344017 |
| training/sac_pi/alpha_loss     | 0.8261461  |
| training/sac_pi/logp_pi        | 5.0907164  |
| training/sac_pi/pi_entropy     | 3.2257867  |
| training/sac_pi/pi_global_norm | 1.5352188  |
| training/sac_pi/policy_loss    | -218.3339  |
| training/sac_pi/std            | 0.5027006  |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 204.46179  |
| training/sac_Q/q2              | 202.10321  |
| training/sac_Q/q2_loss         | 101.06268  |
| training/sac_Q/q_global_norm   | 214.66899  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1647909  |
| epoch                          | 865        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5014.7725  |
| evaluation/return-max          | 5160.221   |
| evaluation/return-min          | 4776.4175  |
| evaluation/return-std          | 108.27539  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46048      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5014.7725  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 191.83011  |
| Q-std                          | 171.42844  |
| Q_loss                         | 98.116066  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 865        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000282   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000511   |
| times/evaluation_paths         | 31.6       |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 56.9       |
| timestep                       | 1000       |
| timesteps_total                | 866000     |
| train-steps                    | 866000     |
| training/Q/q1_loss             | 112.80462  |
| training/sac_pi/alpha          | 0.16481861 |
| training/sac_pi/alpha_loss     | -0.2244827 |
| training/sac_pi/logp_pi        | 5.1531663  |
| training/sac_pi/pi_entropy     | 3.4012368  |
| training/sac_pi/pi_global_norm | 1.6536069  |
| training/sac_pi/policy_loss    | -212.67645 |
| training/sac_pi/std            | 0.53643423 |
| training/sac_pi/valid_num      | 4903.0     |
| training/sac_Q/q1              | 195.60031  |
| training/sac_Q/q2              | 191.36931  |
| training/sac_Q/q2_loss         | 112.33188  |
| training/sac_Q/q_global_norm   | 270.87253  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17055541  |
| epoch                          | 866         |
| evaluation/episode-length-avg  | 950         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 504         |
| evaluation/episode-length-std  | 149         |
| evaluation/return-average      | 4512.8804   |
| evaluation/return-max          | 4899.5723   |
| evaluation/return-min          | 2161.8735   |
| evaluation/return-std          | 786.10095   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 83.6        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45895       |
| perf/AverageLength             | 950         |
| perf/AverageReturn             | 4512.8804   |
| perf/NormalizedReturn          | 0.983       |
| Q-avg                          | 184.93909   |
| Q-std                          | 225.96379   |
| Q_loss                         | 99.75444    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 866         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 29.2        |
| times/timestep_after_hook      | 0.00386     |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 56.2        |
| timestep                       | 1000        |
| timesteps_total                | 867000      |
| train-steps                    | 867000      |
| training/Q/q1_loss             | 81.094154   |
| training/sac_pi/alpha          | 0.17057124  |
| training/sac_pi/alpha_loss     | -0.27251822 |
| training/sac_pi/logp_pi        | 5.071786    |
| training/sac_pi/pi_entropy     | 3.6888714   |
| training/sac_pi/pi_global_norm | 1.4057789   |
| training/sac_pi/policy_loss    | -208.01726  |
| training/sac_pi/std            | 0.5605554   |
| training/sac_pi/valid_num      | 4855.0      |
| training/sac_Q/q1              | 180.88681   |
| training/sac_Q/q2              | 179.69804   |
| training/sac_Q/q2_loss         | 80.42287    |
| training/sac_Q/q_global_norm   | 195.59491   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16891916 |
| epoch                          | 867        |
| evaluation/episode-length-avg  | 913        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 133        |
| evaluation/episode-length-std  | 260        |
| evaluation/return-average      | 4310.6157  |
| evaluation/return-max          | 4929.546   |
| evaluation/return-min          | 361.1464   |
| evaluation/return-std          | 1326.2794  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45965      |
| perf/AverageLength             | 913        |
| perf/AverageReturn             | 4310.6157  |
| perf/NormalizedReturn          | 0.939      |
| Q-avg                          | 192.88582  |
| Q-std                          | 150.55644  |
| Q_loss                         | 80.86976   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 867        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000534   |
| times/evaluation_paths         | 28.9       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 57         |
| timestep                       | 1000       |
| timesteps_total                | 868000     |
| train-steps                    | 868000     |
| training/Q/q1_loss             | 106.66091  |
| training/sac_pi/alpha          | 0.16890676 |
| training/sac_pi/alpha_loss     | 0.17631342 |
| training/sac_pi/logp_pi        | 4.445055   |
| training/sac_pi/pi_entropy     | 3.4749093  |
| training/sac_pi/pi_global_norm | 1.9433609  |
| training/sac_pi/policy_loss    | -208.27673 |
| training/sac_pi/std            | 0.50399977 |
| training/sac_pi/valid_num      | 4960.0     |
| training/sac_Q/q1              | 195.11832  |
| training/sac_Q/q2              | 196.22058  |
| training/sac_Q/q2_loss         | 105.98629  |
| training/sac_Q/q_global_norm   | 233.73146  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17119674 |
| epoch                          | 868        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4833.9556  |
| evaluation/return-max          | 4901.0625  |
| evaluation/return-min          | 4790.9033  |
| evaluation/return-std          | 40.094387  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45939      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4833.9556  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 199.36592  |
| Q-std                          | 155.10706  |
| Q_loss                         | 93.57848   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 868        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000545   |
| times/evaluation_paths         | 31.5       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 57.2       |
| timestep                       | 1000       |
| timesteps_total                | 869000     |
| train-steps                    | 869000     |
| training/Q/q1_loss             | 94.78537   |
| training/sac_pi/alpha          | 0.1712405  |
| training/sac_pi/alpha_loss     | -0.1612366 |
| training/sac_pi/logp_pi        | 4.521081   |
| training/sac_pi/pi_entropy     | 3.7615783  |
| training/sac_pi/pi_global_norm | 1.6654648  |
| training/sac_pi/policy_loss    | -211.23433 |
| training/sac_pi/std            | 0.56340444 |
| training/sac_pi/valid_num      | 4908.0     |
| training/sac_Q/q1              | 193.68271  |
| training/sac_Q/q2              | 192.06282  |
| training/sac_Q/q2_loss         | 95.76264   |
| training/sac_Q/q_global_norm   | 200.31659  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16936077  |
| epoch                          | 869         |
| evaluation/episode-length-avg  | 148         |
| evaluation/episode-length-max  | 151         |
| evaluation/episode-length-min  | 144         |
| evaluation/episode-length-std  | 2.02        |
| evaluation/return-average      | 434.35645   |
| evaluation/return-max          | 449.93063   |
| evaluation/return-min          | 420.7914    |
| evaluation/return-std          | 7.6978498   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45805       |
| perf/AverageLength             | 148         |
| perf/AverageReturn             | 434.35645   |
| perf/NormalizedReturn          | 0.0943      |
| Q-avg                          | 203.44955   |
| Q-std                          | 150.7583    |
| Q_loss                         | 103.33739   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 869         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000278    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.00043     |
| times/evaluation_paths         | 4.57        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00827     |
| times/train                    | 57.5        |
| timestep                       | 1000        |
| timesteps_total                | 870000      |
| train-steps                    | 870000      |
| training/Q/q1_loss             | 92.998695   |
| training/sac_pi/alpha          | 0.16939981  |
| training/sac_pi/alpha_loss     | -0.23848237 |
| training/sac_pi/logp_pi        | 4.2052884   |
| training/sac_pi/pi_entropy     | 3.4478736   |
| training/sac_pi/pi_global_norm | 1.4418775   |
| training/sac_pi/policy_loss    | -211.94858  |
| training/sac_pi/std            | 0.49966422  |
| training/sac_pi/valid_num      | 5005.0      |
| training/sac_Q/q1              | 200.65285   |
| training/sac_Q/q2              | 200.75198   |
| training/sac_Q/q2_loss         | 92.7459     |
| training/sac_Q/q_global_norm   | 255.0949    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16646369 |
| epoch                          | 870        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4534.677   |
| evaluation/return-max          | 4740.4395  |
| evaluation/return-min          | 4417.9873  |
| evaluation/return-std          | 96.65689   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45961      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4534.677   |
| perf/NormalizedReturn          | 0.987      |
| Q-avg                          | 192.70764  |
| Q-std                          | 142.6852   |
| Q_loss                         | 104.495705 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 870        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 8.47e-05   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000535   |
| times/evaluation_paths         | 31.2       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 57.2       |
| timestep                       | 1000       |
| timesteps_total                | 871000     |
| train-steps                    | 871000     |
| training/Q/q1_loss             | 91.04142   |
| training/sac_pi/alpha          | 0.16641404 |
| training/sac_pi/alpha_loss     | 0.4997054  |
| training/sac_pi/logp_pi        | 4.5749755  |
| training/sac_pi/pi_entropy     | 3.5024834  |
| training/sac_pi/pi_global_norm | 1.4455991  |
| training/sac_pi/policy_loss    | -197.46767 |
| training/sac_pi/std            | 0.49786767 |
| training/sac_pi/valid_num      | 4930.0     |
| training/sac_Q/q1              | 185.54303  |
| training/sac_Q/q2              | 185.2853   |
| training/sac_Q/q2_loss         | 90.82446   |
| training/sac_Q/q_global_norm   | 160.56717  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16465561 |
| epoch                          | 871        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4778.3096  |
| evaluation/return-max          | 4852.034   |
| evaluation/return-min          | 4677.879   |
| evaluation/return-std          | 45.85756   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45905      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4778.3096  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 187.37508  |
| Q-std                          | 200.5395   |
| Q_loss                         | 135.4811   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 871        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.000141   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000552   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 56.8       |
| timestep                       | 1000       |
| timesteps_total                | 872000     |
| train-steps                    | 872000     |
| training/Q/q1_loss             | 99.698746  |
| training/sac_pi/alpha          | 0.1646929  |
| training/sac_pi/alpha_loss     | 0.10073906 |
| training/sac_pi/logp_pi        | 4.202876   |
| training/sac_pi/pi_entropy     | 3.3737667  |
| training/sac_pi/pi_global_norm | 1.9308226  |
| training/sac_pi/policy_loss    | -210.83974 |
| training/sac_pi/std            | 0.50041556 |
| training/sac_pi/valid_num      | 4961.0     |
| training/sac_Q/q1              | 197.62369  |
| training/sac_Q/q2              | 199.25864  |
| training/sac_Q/q2_loss         | 98.9965    |
| training/sac_Q/q_global_norm   | 214.66646  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16163743  |
| epoch                          | 872         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4965.9854   |
| evaluation/return-max          | 4995.779    |
| evaluation/return-min          | 4932.5195   |
| evaluation/return-std          | 20.652424   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45847       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4965.9854   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 189.91956   |
| Q-std                          | 168.21774   |
| Q_loss                         | 117.99675   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 872         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000144    |
| times/epoch_rollout_model      | 503         |
| times/evaluation_metrics       | 0.000672    |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.00393     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 57.9        |
| timestep                       | 1000        |
| timesteps_total                | 873000      |
| train-steps                    | 873000      |
| training/Q/q1_loss             | 104.37805   |
| training/sac_pi/alpha          | 0.1616154   |
| training/sac_pi/alpha_loss     | -0.09246471 |
| training/sac_pi/logp_pi        | 4.634688    |
| training/sac_pi/pi_entropy     | 3.2940354   |
| training/sac_pi/pi_global_norm | 1.599944    |
| training/sac_pi/policy_loss    | -207.63232  |
| training/sac_pi/std            | 0.5031249   |
| training/sac_pi/valid_num      | 4951.0      |
| training/sac_Q/q1              | 190.37846   |
| training/sac_Q/q2              | 187.66301   |
| training/sac_Q/q2_loss         | 105.82396   |
| training/sac_Q/q_global_norm   | 187.89449   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16455233  |
| epoch                          | 873         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4917.2354   |
| evaluation/return-max          | 5014.342    |
| evaluation/return-min          | 4804.4746   |
| evaluation/return-std          | 58.54353    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45683       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4917.2354   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 195.34651   |
| Q-std                          | 196.77025   |
| Q_loss                         | 110.4966    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 873         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.000359    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000642    |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.00382     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 57.2        |
| timestep                       | 1000        |
| timesteps_total                | 874000      |
| train-steps                    | 874000      |
| training/Q/q1_loss             | 98.602295   |
| training/sac_pi/alpha          | 0.16456582  |
| training/sac_pi/alpha_loss     | -0.37190035 |
| training/sac_pi/logp_pi        | 4.740821    |
| training/sac_pi/pi_entropy     | 3.331494    |
| training/sac_pi/pi_global_norm | 1.8380536   |
| training/sac_pi/policy_loss    | -212.42763  |
| training/sac_pi/std            | 0.50959045  |
| training/sac_pi/valid_num      | 4910.0      |
| training/sac_Q/q1              | 194.47563   |
| training/sac_Q/q2              | 191.77014   |
| training/sac_Q/q2_loss         | 99.80723    |
| training/sac_Q/q_global_norm   | 218.91953   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16612047 |
| epoch                          | 874        |
| evaluation/episode-length-avg  | 152        |
| evaluation/episode-length-max  | 156        |
| evaluation/episode-length-min  | 149        |
| evaluation/episode-length-std  | 2.14       |
| evaluation/return-average      | 448.55673  |
| evaluation/return-max          | 471.68036  |
| evaluation/return-min          | 431.92145  |
| evaluation/return-std          | 12.362158  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45921      |
| perf/AverageLength             | 152        |
| perf/AverageReturn             | 448.55673  |
| perf/NormalizedReturn          | 0.0974     |
| Q-avg                          | 196.08023  |
| Q-std                          | 126.44974  |
| Q_loss                         | 90.84616   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 874        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000113   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000523   |
| times/evaluation_paths         | 4.81       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 57.1       |
| timestep                       | 1000       |
| timesteps_total                | 875000     |
| train-steps                    | 875000     |
| training/Q/q1_loss             | 96.12587   |
| training/sac_pi/alpha          | 0.16609684 |
| training/sac_pi/alpha_loss     | 0.06217622 |
| training/sac_pi/logp_pi        | 4.842829   |
| training/sac_pi/pi_entropy     | 3.5238411  |
| training/sac_pi/pi_global_norm | 1.6604613  |
| training/sac_pi/policy_loss    | -209.03    |
| training/sac_pi/std            | 0.53469974 |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 190.38512  |
| training/sac_Q/q2              | 191.29799  |
| training/sac_Q/q2_loss         | 95.60935   |
| training/sac_Q/q_global_norm   | 183.88043  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17114592  |
| epoch                          | 875         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4792.2393   |
| evaluation/return-max          | 4890.5767   |
| evaluation/return-min          | 4717.94     |
| evaluation/return-std          | 51.82358    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45881       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4792.2393   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 182.78772   |
| Q-std                          | 194.64644   |
| Q_loss                         | 114.697586  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 875         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000266    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000526    |
| times/evaluation_paths         | 31.5        |
| times/timestep_after_hook      | 0.00385     |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 56.9        |
| timestep                       | 1000        |
| timesteps_total                | 876000      |
| train-steps                    | 876000      |
| training/Q/q1_loss             | 101.022964  |
| training/sac_pi/alpha          | 0.17114094  |
| training/sac_pi/alpha_loss     | -0.14841107 |
| training/sac_pi/logp_pi        | 4.0575204   |
| training/sac_pi/pi_entropy     | 3.5975525   |
| training/sac_pi/pi_global_norm | 1.4444045   |
| training/sac_pi/policy_loss    | -208.54318  |
| training/sac_pi/std            | 0.5111989   |
| training/sac_pi/valid_num      | 4956.0      |
| training/sac_Q/q1              | 197.26082   |
| training/sac_Q/q2              | 195.17564   |
| training/sac_Q/q2_loss         | 101.820595  |
| training/sac_Q/q_global_norm   | 168.37793   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17050944 |
| epoch                          | 876        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4613.794   |
| evaluation/return-max          | 4810.5938  |
| evaluation/return-min          | 4477.0127  |
| evaluation/return-std          | 84.806015  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45852      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4613.794   |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 188.4257   |
| Q-std                          | 219.59747  |
| Q_loss                         | 93.72611   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 876        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000529   |
| times/evaluation_paths         | 32.1       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 56.9       |
| timestep                       | 1000       |
| timesteps_total                | 877000     |
| train-steps                    | 877000     |
| training/Q/q1_loss             | 102.907104 |
| training/sac_pi/alpha          | 0.17049676 |
| training/sac_pi/alpha_loss     | 0.1313931  |
| training/sac_pi/logp_pi        | 3.8351655  |
| training/sac_pi/pi_entropy     | 3.4394257  |
| training/sac_pi/pi_global_norm | 1.5880618  |
| training/sac_pi/policy_loss    | -213.5162  |
| training/sac_pi/std            | 0.47873288 |
| training/sac_pi/valid_num      | 5024.0     |
| training/sac_Q/q1              | 206.63187  |
| training/sac_Q/q2              | 205.4401   |
| training/sac_Q/q2_loss         | 103.94227  |
| training/sac_Q/q_global_norm   | 289.04626  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17177804 |
| epoch                          | 877        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5058.3657  |
| evaluation/return-max          | 5125.0     |
| evaluation/return-min          | 4963.282   |
| evaluation/return-std          | 57.359493  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45903      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5058.3657  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 185.61357  |
| Q-std                          | 204.02309  |
| Q_loss                         | 90.9829    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 877        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000383   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000645   |
| times/evaluation_paths         | 31.6       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 57.7       |
| timestep                       | 1000       |
| timesteps_total                | 878000     |
| train-steps                    | 878000     |
| training/Q/q1_loss             | 94.58517   |
| training/sac_pi/alpha          | 0.17177504 |
| training/sac_pi/alpha_loss     | 0.23216498 |
| training/sac_pi/logp_pi        | 4.761396   |
| training/sac_pi/pi_entropy     | 3.4637284  |
| training/sac_pi/pi_global_norm | 1.8491697  |
| training/sac_pi/policy_loss    | -218.51932 |
| training/sac_pi/std            | 0.5219515  |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 203.73892  |
| training/sac_Q/q2              | 202.12892  |
| training/sac_Q/q2_loss         | 95.25905   |
| training/sac_Q/q_global_norm   | 224.25981  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16740341 |
| epoch                          | 878        |
| evaluation/episode-length-avg  | 562        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 121        |
| evaluation/episode-length-std  | 438        |
| evaluation/return-average      | 2604.0435  |
| evaluation/return-max          | 5019.8975  |
| evaluation/return-min          | 296.7536   |
| evaluation/return-std          | 2291.9502  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46132      |
| perf/AverageLength             | 562        |
| perf/AverageReturn             | 2604.0435  |
| perf/NormalizedReturn          | 0.567      |
| Q-avg                          | 198.87465  |
| Q-std                          | 166.26643  |
| Q_loss                         | 95.525856  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 878        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000116   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000534   |
| times/evaluation_paths         | 17.8       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 56.5       |
| timestep                       | 1000       |
| timesteps_total                | 879000     |
| train-steps                    | 879000     |
| training/Q/q1_loss             | 122.06283  |
| training/sac_pi/alpha          | 0.16741315 |
| training/sac_pi/alpha_loss     | 0.0962787  |
| training/sac_pi/logp_pi        | 5.232508   |
| training/sac_pi/pi_entropy     | 3.776858   |
| training/sac_pi/pi_global_norm | 2.003759   |
| training/sac_pi/policy_loss    | -201.25058 |
| training/sac_pi/std            | 0.5905728  |
| training/sac_pi/valid_num      | 4917.0     |
| training/sac_Q/q1              | 181.12668  |
| training/sac_Q/q2              | 179.8249   |
| training/sac_Q/q2_loss         | 122.18177  |
| training/sac_Q/q_global_norm   | 288.68848  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17246552 |
| epoch                          | 879        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5070.469   |
| evaluation/return-max          | 5105.0044  |
| evaluation/return-min          | 4986.786   |
| evaluation/return-std          | 32.572697  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 83.8       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46082      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5070.469   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 184.66696  |
| Q-std                          | 229.84038  |
| Q_loss                         | 92.62576   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 879        |
| times/epoch_after_hook         | 1.98e-06   |
| times/epoch_before_hook        | 0.00011    |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000531   |
| times/evaluation_paths         | 31.2       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 56.9       |
| timestep                       | 1000       |
| timesteps_total                | 880000     |
| train-steps                    | 880000     |
| training/Q/q1_loss             | 94.35906   |
| training/sac_pi/alpha          | 0.1724659  |
| training/sac_pi/alpha_loss     | 0.04761353 |
| training/sac_pi/logp_pi        | 4.529676   |
| training/sac_pi/pi_entropy     | 3.328682   |
| training/sac_pi/pi_global_norm | 1.7006401  |
| training/sac_pi/policy_loss    | -213.16133 |
| training/sac_pi/std            | 0.49147263 |
| training/sac_pi/valid_num      | 4944.0     |
| training/sac_Q/q1              | 199.12503  |
| training/sac_Q/q2              | 197.96892  |
| training/sac_Q/q2_loss         | 93.88036   |
| training/sac_Q/q_global_norm   | 155.04189  |
--------------------------------------------------------------------------------
[WARN] 880 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16752066 |
| epoch                          | 880        |
| evaluation/episode-length-avg  | 827        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 421        |
| evaluation/episode-length-std  | 264        |
| evaluation/return-average      | 3753.0027  |
| evaluation/return-max          | 4733.713   |
| evaluation/return-min          | 1715.1843  |
| evaluation/return-std          | 1325.2434  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45855      |
| perf/AverageLength             | 827        |
| perf/AverageReturn             | 3753.0027  |
| perf/NormalizedReturn          | 0.817      |
| Q-avg                          | 201.00128  |
| Q-std                          | 138.23497  |
| Q_loss                         | 95.84728   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 880        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 505        |
| times/evaluation_metrics       | 0.000521   |
| times/evaluation_paths         | 26.1       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 57         |
| timestep                       | 1000       |
| timesteps_total                | 881000     |
| train-steps                    | 881000     |
| training/Q/q1_loss             | 99.326     |
| training/sac_pi/alpha          | 0.16751298 |
| training/sac_pi/alpha_loss     | 0.05577855 |
| training/sac_pi/logp_pi        | 4.13106    |
| training/sac_pi/pi_entropy     | 3.3325982  |
| training/sac_pi/pi_global_norm | 1.7917953  |
| training/sac_pi/policy_loss    | -204.14978 |
| training/sac_pi/std            | 0.481059   |
| training/sac_pi/valid_num      | 4960.0     |
| training/sac_Q/q1              | 192.79263  |
| training/sac_Q/q2              | 192.88521  |
| training/sac_Q/q2_loss         | 100.95498  |
| training/sac_Q/q_global_norm   | 247.77107  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16561458   |
| epoch                          | 881          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4985.282     |
| evaluation/return-max          | 5027.893     |
| evaluation/return-min          | 4903.45      |
| evaluation/return-std          | 31.345926    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.91         |
| model/origin_ret               | 83.6         |
| model/penalty_ret              | 80.8         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45870        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4985.282     |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 199.30876    |
| Q-std                          | 144.20256    |
| Q_loss                         | 69.1256      |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 881          |
| times/epoch_after_hook         | 1.66e-06     |
| times/epoch_before_hook        | 0.000279     |
| times/epoch_rollout_model      | 499          |
| times/evaluation_metrics       | 0.000669     |
| times/evaluation_paths         | 31.3         |
| times/timestep_after_hook      | 0.00398      |
| times/timestep_before_hook     | 0.00823      |
| times/train                    | 57.3         |
| timestep                       | 1000         |
| timesteps_total                | 882000       |
| train-steps                    | 882000       |
| training/Q/q1_loss             | 94.37588     |
| training/sac_pi/alpha          | 0.16561794   |
| training/sac_pi/alpha_loss     | -0.079420164 |
| training/sac_pi/logp_pi        | 4.5076995    |
| training/sac_pi/pi_entropy     | 3.5909824    |
| training/sac_pi/pi_global_norm | 1.585373     |
| training/sac_pi/policy_loss    | -207.26656   |
| training/sac_pi/std            | 0.5306315    |
| training/sac_pi/valid_num      | 4968.0       |
| training/sac_Q/q1              | 191.29935    |
| training/sac_Q/q2              | 190.27707    |
| training/sac_Q/q2_loss         | 94.48991     |
| training/sac_Q/q_global_norm   | 158.48163    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16488807  |
| epoch                          | 882         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4888.398    |
| evaluation/return-max          | 4986.5586   |
| evaluation/return-min          | 4685.3223   |
| evaluation/return-std          | 102.07273   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45821       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4888.398    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 193.66609   |
| Q-std                          | 168.64268   |
| Q_loss                         | 93.39815    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 882         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000147    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000528    |
| times/evaluation_paths         | 31.3        |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 57          |
| timestep                       | 1000        |
| timesteps_total                | 883000      |
| train-steps                    | 883000      |
| training/Q/q1_loss             | 102.964294  |
| training/sac_pi/alpha          | 0.1649164   |
| training/sac_pi/alpha_loss     | -0.19318154 |
| training/sac_pi/logp_pi        | 5.2712564   |
| training/sac_pi/pi_entropy     | 3.501979    |
| training/sac_pi/pi_global_norm | 1.7063817   |
| training/sac_pi/policy_loss    | -204.34789  |
| training/sac_pi/std            | 0.5490599   |
| training/sac_pi/valid_num      | 4877.0      |
| training/sac_Q/q1              | 183.37785   |
| training/sac_Q/q2              | 185.47922   |
| training/sac_Q/q2_loss         | 101.2897    |
| training/sac_Q/q_global_norm   | 201.94014   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1659511   |
| epoch                          | 883         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4741.605    |
| evaluation/return-max          | 4837.429    |
| evaluation/return-min          | 4620.165    |
| evaluation/return-std          | 67.43225    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45862       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4741.605    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 188.99417   |
| Q-std                          | 165.59497   |
| Q_loss                         | 110.19767   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 883         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000622    |
| times/evaluation_paths         | 32.2        |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 56.6        |
| timestep                       | 1000        |
| timesteps_total                | 884000      |
| train-steps                    | 884000      |
| training/Q/q1_loss             | 111.91438   |
| training/sac_pi/alpha          | 0.16594811  |
| training/sac_pi/alpha_loss     | -0.17563085 |
| training/sac_pi/logp_pi        | 4.017827    |
| training/sac_pi/pi_entropy     | 3.4797447   |
| training/sac_pi/pi_global_norm | 1.4803929   |
| training/sac_pi/policy_loss    | -197.92574  |
| training/sac_pi/std            | 0.49513665  |
| training/sac_pi/valid_num      | 4959.0      |
| training/sac_Q/q1              | 187.41983   |
| training/sac_Q/q2              | 185.77347   |
| training/sac_Q/q2_loss         | 112.15991   |
| training/sac_Q/q_global_norm   | 282.10547   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1671037  |
| epoch                          | 884        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4759.371   |
| evaluation/return-max          | 4799.502   |
| evaluation/return-min          | 4663.953   |
| evaluation/return-std          | 39.688206  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46011      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4759.371   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 182.97812  |
| Q-std                          | 234.3737   |
| Q_loss                         | 119.811295 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 884        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 8.95e-05   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 31.5       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 58.8       |
| timestep                       | 1000       |
| timesteps_total                | 885000     |
| train-steps                    | 885000     |
| training/Q/q1_loss             | 118.1238   |
| training/sac_pi/alpha          | 0.16708817 |
| training/sac_pi/alpha_loss     | 0.07948197 |
| training/sac_pi/logp_pi        | 5.1892033  |
| training/sac_pi/pi_entropy     | 3.6693478  |
| training/sac_pi/pi_global_norm | 1.5531641  |
| training/sac_pi/policy_loss    | -210.80272 |
| training/sac_pi/std            | 0.5715914  |
| training/sac_pi/valid_num      | 4860.0     |
| training/sac_Q/q1              | 188.22993  |
| training/sac_Q/q2              | 186.63313  |
| training/sac_Q/q2_loss         | 117.809494 |
| training/sac_Q/q_global_norm   | 241.77173  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1637203   |
| epoch                          | 885         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4893.267    |
| evaluation/return-max          | 4991.334    |
| evaluation/return-min          | 4788.5576   |
| evaluation/return-std          | 70.814384   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46116       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4893.267    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 193.37112   |
| Q-std                          | 143.70897   |
| Q_loss                         | 91.41966    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 885         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000329    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000565    |
| times/evaluation_paths         | 31.7        |
| times/timestep_after_hook      | 0.00386     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 56.9        |
| timestep                       | 1000        |
| timesteps_total                | 886000      |
| train-steps                    | 886000      |
| training/Q/q1_loss             | 88.73889    |
| training/sac_pi/alpha          | 0.16374286  |
| training/sac_pi/alpha_loss     | -0.27332988 |
| training/sac_pi/logp_pi        | 5.390872    |
| training/sac_pi/pi_entropy     | 3.5209892   |
| training/sac_pi/pi_global_norm | 1.648674    |
| training/sac_pi/policy_loss    | -200.40578  |
| training/sac_pi/std            | 0.5525376   |
| training/sac_pi/valid_num      | 4886.0      |
| training/sac_Q/q1              | 177.7437    |
| training/sac_Q/q2              | 172.20903   |
| training/sac_Q/q2_loss         | 89.24474    |
| training/sac_Q/q_global_norm   | 172.47679   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16640675  |
| epoch                          | 886         |
| evaluation/episode-length-avg  | 833         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 154         |
| evaluation/episode-length-std  | 334         |
| evaluation/return-average      | 4103.3994   |
| evaluation/return-max          | 5046.7686   |
| evaluation/return-min          | 472.18777   |
| evaluation/return-std          | 1790.0248   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45955       |
| perf/AverageLength             | 833         |
| perf/AverageReturn             | 4103.3994   |
| perf/NormalizedReturn          | 0.894       |
| Q-avg                          | 189.07697   |
| Q-std                          | 177.33527   |
| Q_loss                         | 109.651276  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 886         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000567    |
| times/evaluation_paths         | 26.4        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.0081      |
| times/train                    | 57.6        |
| timestep                       | 1000        |
| timesteps_total                | 887000      |
| train-steps                    | 887000      |
| training/Q/q1_loss             | 124.57533   |
| training/sac_pi/alpha          | 0.16639724  |
| training/sac_pi/alpha_loss     | -0.07745773 |
| training/sac_pi/logp_pi        | 4.0297594   |
| training/sac_pi/pi_entropy     | 3.4293983   |
| training/sac_pi/pi_global_norm | 1.680203    |
| training/sac_pi/policy_loss    | -206.90692  |
| training/sac_pi/std            | 0.49018013  |
| training/sac_pi/valid_num      | 4992.0      |
| training/sac_Q/q1              | 196.7321    |
| training/sac_Q/q2              | 196.28185   |
| training/sac_Q/q2_loss         | 124.01798   |
| training/sac_Q/q_global_norm   | 199.66083   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16600493 |
| epoch                          | 887        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4932.5615  |
| evaluation/return-max          | 4956.0195  |
| evaluation/return-min          | 4905.2715  |
| evaluation/return-std          | 20.340523  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46122      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4932.5615  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 192.11978  |
| Q-std                          | 174.16147  |
| Q_loss                         | 89.265     |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 887        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000542   |
| times/evaluation_paths         | 31.1       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 57.4       |
| timestep                       | 1000       |
| timesteps_total                | 888000     |
| train-steps                    | 888000     |
| training/Q/q1_loss             | 100.686874 |
| training/sac_pi/alpha          | 0.1660292  |
| training/sac_pi/alpha_loss     | -0.0864777 |
| training/sac_pi/logp_pi        | 4.467328   |
| training/sac_pi/pi_entropy     | 3.3981087  |
| training/sac_pi/pi_global_norm | 1.5593256  |
| training/sac_pi/policy_loss    | -207.74309 |
| training/sac_pi/std            | 0.49178162 |
| training/sac_pi/valid_num      | 4918.0     |
| training/sac_Q/q1              | 195.4502   |
| training/sac_Q/q2              | 192.80417  |
| training/sac_Q/q2_loss         | 101.09391  |
| training/sac_Q/q_global_norm   | 220.83945  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16838452  |
| epoch                          | 888         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4943.1675   |
| evaluation/return-max          | 4997.126    |
| evaluation/return-min          | 4848.204    |
| evaluation/return-std          | 45.576935   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45859       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4943.1675   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 193.68677   |
| Q-std                          | 185.77798   |
| Q_loss                         | 106.87467   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 888         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000568    |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 56.8        |
| timestep                       | 1000        |
| timesteps_total                | 889000      |
| train-steps                    | 889000      |
| training/Q/q1_loss             | 96.861465   |
| training/sac_pi/alpha          | 0.16840552  |
| training/sac_pi/alpha_loss     | -0.29737303 |
| training/sac_pi/logp_pi        | 4.5965095   |
| training/sac_pi/pi_entropy     | 3.4149184   |
| training/sac_pi/pi_global_norm | 1.5697076   |
| training/sac_pi/policy_loss    | -209.73445  |
| training/sac_pi/std            | 0.5128793   |
| training/sac_pi/valid_num      | 4914.0      |
| training/sac_Q/q1              | 189.44083   |
| training/sac_Q/q2              | 191.62434   |
| training/sac_Q/q2_loss         | 96.32866    |
| training/sac_Q/q_global_norm   | 187.30676   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1726047    |
| epoch                          | 889          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5044.176     |
| evaluation/return-max          | 5108.6787    |
| evaluation/return-min          | 4986.2666    |
| evaluation/return-std          | 39.160103    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3            |
| model/origin_ret               | 85.3         |
| model/penalty_ret              | 81.1         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45858        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5044.176     |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 196.47266    |
| Q-std                          | 139.71606    |
| Q_loss                         | 108.26927    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 889          |
| times/epoch_after_hook         | 1.74e-06     |
| times/epoch_before_hook        | 0.000328     |
| times/epoch_rollout_model      | 491          |
| times/evaluation_metrics       | 0.000568     |
| times/evaluation_paths         | 31.7         |
| times/timestep_after_hook      | 0.00402      |
| times/timestep_before_hook     | 0.00821      |
| times/train                    | 58.1         |
| timestep                       | 1000         |
| timesteps_total                | 890000       |
| train-steps                    | 890000       |
| training/Q/q1_loss             | 103.303734   |
| training/sac_pi/alpha          | 0.17263101   |
| training/sac_pi/alpha_loss     | -0.037770268 |
| training/sac_pi/logp_pi        | 4.4910636    |
| training/sac_pi/pi_entropy     | 3.5213466    |
| training/sac_pi/pi_global_norm | 1.7061507    |
| training/sac_pi/policy_loss    | -208.27255   |
| training/sac_pi/std            | 0.5233369    |
| training/sac_pi/valid_num      | 4950.0       |
| training/sac_Q/q1              | 188.7009     |
| training/sac_Q/q2              | 194.08606    |
| training/sac_Q/q2_loss         | 103.521866   |
| training/sac_Q/q_global_norm   | 173.1552     |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17210273  |
| epoch                          | 890         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5140.9033   |
| evaluation/return-max          | 5206.4277   |
| evaluation/return-min          | 5057.5996   |
| evaluation/return-std          | 47.035313   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45936       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5140.9033   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 201.16342   |
| Q-std                          | 172.77483   |
| Q_loss                         | 93.35726    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 890         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000527    |
| times/evaluation_paths         | 31.9        |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 57.6        |
| timestep                       | 1000        |
| timesteps_total                | 891000      |
| train-steps                    | 891000      |
| training/Q/q1_loss             | 80.64267    |
| training/sac_pi/alpha          | 0.17210484  |
| training/sac_pi/alpha_loss     | -0.09406324 |
| training/sac_pi/logp_pi        | 4.6191382   |
| training/sac_pi/pi_entropy     | 3.4137375   |
| training/sac_pi/pi_global_norm | 1.40028     |
| training/sac_pi/policy_loss    | -211.55894  |
| training/sac_pi/std            | 0.5052851   |
| training/sac_pi/valid_num      | 4954.0      |
| training/sac_Q/q1              | 195.66672   |
| training/sac_Q/q2              | 197.08646   |
| training/sac_Q/q2_loss         | 80.194046   |
| training/sac_Q/q_global_norm   | 180.54103   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16611263  |
| epoch                          | 891         |
| evaluation/episode-length-avg  | 148         |
| evaluation/episode-length-max  | 159         |
| evaluation/episode-length-min  | 144         |
| evaluation/episode-length-std  | 4           |
| evaluation/return-average      | 473.80225   |
| evaluation/return-max          | 511.1677    |
| evaluation/return-min          | 454.00452   |
| evaluation/return-std          | 15.4852085  |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46085       |
| perf/AverageLength             | 148         |
| perf/AverageReturn             | 473.80225   |
| perf/NormalizedReturn          | 0.103       |
| Q-avg                          | 192.65053   |
| Q-std                          | 177.175     |
| Q_loss                         | 85.22781    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 891         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000454    |
| times/evaluation_paths         | 4.78        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 58.5        |
| timestep                       | 1000        |
| timesteps_total                | 892000      |
| train-steps                    | 892000      |
| training/Q/q1_loss             | 96.16162    |
| training/sac_pi/alpha          | 0.16613343  |
| training/sac_pi/alpha_loss     | -0.32161665 |
| training/sac_pi/logp_pi        | 3.8237908   |
| training/sac_pi/pi_entropy     | 3.4453206   |
| training/sac_pi/pi_global_norm | 1.6014879   |
| training/sac_pi/policy_loss    | -207.34448  |
| training/sac_pi/std            | 0.49123806  |
| training/sac_pi/valid_num      | 4997.0      |
| training/sac_Q/q1              | 196.82303   |
| training/sac_Q/q2              | 194.56181   |
| training/sac_Q/q2_loss         | 98.14493    |
| training/sac_Q/q_global_norm   | 206.18008   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16448641 |
| epoch                          | 892        |
| evaluation/episode-length-avg  | 152        |
| evaluation/episode-length-max  | 155        |
| evaluation/episode-length-min  | 150        |
| evaluation/episode-length-std  | 1.87       |
| evaluation/return-average      | 507.33374  |
| evaluation/return-max          | 525.6466   |
| evaluation/return-min          | 489.56604  |
| evaluation/return-std          | 12.246985  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46047      |
| perf/AverageLength             | 152        |
| perf/AverageReturn             | 507.33374  |
| perf/NormalizedReturn          | 0.11       |
| Q-avg                          | 193.46892  |
| Q-std                          | 167.39722  |
| Q_loss                         | 101.48589  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 892        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 8.2e-05    |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000465   |
| times/evaluation_paths         | 4.9        |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 57.5       |
| timestep                       | 1000       |
| timesteps_total                | 893000     |
| train-steps                    | 893000     |
| training/Q/q1_loss             | 98.555435  |
| training/sac_pi/alpha          | 0.16445726 |
| training/sac_pi/alpha_loss     | 0.5509715  |
| training/sac_pi/logp_pi        | 4.427873   |
| training/sac_pi/pi_entropy     | 3.3254828  |
| training/sac_pi/pi_global_norm | 1.7684633  |
| training/sac_pi/policy_loss    | -200.26585 |
| training/sac_pi/std            | 0.49231988 |
| training/sac_pi/valid_num      | 4993.0     |
| training/sac_Q/q1              | 187.0054   |
| training/sac_Q/q2              | 186.19376  |
| training/sac_Q/q2_loss         | 97.37505   |
| training/sac_Q/q_global_norm   | 246.1332   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17319505  |
| epoch                          | 893         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5033.074    |
| evaluation/return-max          | 5100.177    |
| evaluation/return-min          | 4981.9863   |
| evaluation/return-std          | 31.980295   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45987       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5033.074    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 195.53282   |
| Q-std                          | 211.86987   |
| Q_loss                         | 99.51992    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 893         |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 0.00033     |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000546    |
| times/evaluation_paths         | 31.3        |
| times/timestep_after_hook      | 0.00409     |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 57.4        |
| timestep                       | 1000        |
| timesteps_total                | 894000      |
| train-steps                    | 894000      |
| training/Q/q1_loss             | 94.107056   |
| training/sac_pi/alpha          | 0.17321606  |
| training/sac_pi/alpha_loss     | -0.15528071 |
| training/sac_pi/logp_pi        | 3.87711     |
| training/sac_pi/pi_entropy     | 3.5651345   |
| training/sac_pi/pi_global_norm | 1.672509    |
| training/sac_pi/policy_loss    | -212.9083   |
| training/sac_pi/std            | 0.49736768  |
| training/sac_pi/valid_num      | 4985.0      |
| training/sac_Q/q1              | 200.41      |
| training/sac_Q/q2              | 200.39868   |
| training/sac_Q/q2_loss         | 94.496574   |
| training/sac_Q/q_global_norm   | 258.77396   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17002924 |
| epoch                          | 894        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4868.7407  |
| evaluation/return-max          | 4898.3066  |
| evaluation/return-min          | 4823.302   |
| evaluation/return-std          | 21.56022   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46006      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4868.7407  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 195.55016  |
| Q-std                          | 187.13058  |
| Q_loss                         | 86.6052    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 894        |
| times/epoch_after_hook         | 1.98e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000624   |
| times/evaluation_paths         | 31.3       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 56.9       |
| timestep                       | 1000       |
| timesteps_total                | 895000     |
| train-steps                    | 895000     |
| training/Q/q1_loss             | 103.203316 |
| training/sac_pi/alpha          | 0.17003766 |
| training/sac_pi/alpha_loss     | 0.26670274 |
| training/sac_pi/logp_pi        | 5.094777   |
| training/sac_pi/pi_entropy     | 3.527832   |
| training/sac_pi/pi_global_norm | 1.8441439  |
| training/sac_pi/policy_loss    | -206.49547 |
| training/sac_pi/std            | 0.553044   |
| training/sac_pi/valid_num      | 4929.0     |
| training/sac_Q/q1              | 181.8403   |
| training/sac_Q/q2              | 179.2521   |
| training/sac_Q/q2_loss         | 103.07118  |
| training/sac_Q/q_global_norm   | 222.22649  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17196019  |
| epoch                          | 895         |
| evaluation/episode-length-avg  | 152         |
| evaluation/episode-length-max  | 159         |
| evaluation/episode-length-min  | 146         |
| evaluation/episode-length-std  | 3.07        |
| evaluation/return-average      | 425.23697   |
| evaluation/return-max          | 444.0333    |
| evaluation/return-min          | 401.93713   |
| evaluation/return-std          | 12.054025   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45904       |
| perf/AverageLength             | 152         |
| perf/AverageReturn             | 425.23697   |
| perf/NormalizedReturn          | 0.0923      |
| Q-avg                          | 187.8663    |
| Q-std                          | 180.78407   |
| Q_loss                         | 100.52928   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 895         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000151    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000481    |
| times/evaluation_paths         | 4.7         |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00833     |
| times/train                    | 57.8        |
| timestep                       | 1000        |
| timesteps_total                | 896000      |
| train-steps                    | 896000      |
| training/Q/q1_loss             | 110.81132   |
| training/sac_pi/alpha          | 0.17197375  |
| training/sac_pi/alpha_loss     | 0.117190965 |
| training/sac_pi/logp_pi        | 3.9398627   |
| training/sac_pi/pi_entropy     | 3.5368257   |
| training/sac_pi/pi_global_norm | 1.576376    |
| training/sac_pi/policy_loss    | -204.38086  |
| training/sac_pi/std            | 0.496185    |
| training/sac_pi/valid_num      | 4972.0      |
| training/sac_Q/q1              | 192.96652   |
| training/sac_Q/q2              | 192.20004   |
| training/sac_Q/q2_loss         | 111.44591   |
| training/sac_Q/q_global_norm   | 208.13387   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17081185 |
| epoch                          | 896        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4647.035   |
| evaluation/return-max          | 4801.3613  |
| evaluation/return-min          | 4489.909   |
| evaluation/return-std          | 105.79209  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45965      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4647.035   |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 196.09793  |
| Q-std                          | 138.25156  |
| Q_loss                         | 102.30731  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 896        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000113   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000596   |
| times/evaluation_paths         | 32.1       |
| times/timestep_after_hook      | 0.00481    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 57.8       |
| timestep                       | 1000       |
| timesteps_total                | 897000     |
| train-steps                    | 897000     |
| training/Q/q1_loss             | 104.562584 |
| training/sac_pi/alpha          | 0.17076638 |
| training/sac_pi/alpha_loss     | 0.16066988 |
| training/sac_pi/logp_pi        | 4.042248   |
| training/sac_pi/pi_entropy     | 3.558155   |
| training/sac_pi/pi_global_norm | 1.7436167  |
| training/sac_pi/policy_loss    | -202.90118 |
| training/sac_pi/std            | 0.5018446  |
| training/sac_pi/valid_num      | 4971.0     |
| training/sac_Q/q1              | 193.34229  |
| training/sac_Q/q2              | 192.45772  |
| training/sac_Q/q2_loss         | 104.9285   |
| training/sac_Q/q_global_norm   | 178.10132  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1663369   |
| epoch                          | 897         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4762.6235   |
| evaluation/return-max          | 4961.8857   |
| evaluation/return-min          | 4638.3096   |
| evaluation/return-std          | 108.77179   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45642       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4762.6235   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 185.30794   |
| Q-std                          | 213.84349   |
| Q_loss                         | 127.686226  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 897         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000274    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000543    |
| times/evaluation_paths         | 31.6        |
| times/timestep_after_hook      | 0.00387     |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 57          |
| timestep                       | 1000        |
| timesteps_total                | 898000      |
| train-steps                    | 898000      |
| training/Q/q1_loss             | 88.50078    |
| training/sac_pi/alpha          | 0.1663755   |
| training/sac_pi/alpha_loss     | -0.21363588 |
| training/sac_pi/logp_pi        | 4.4787955   |
| training/sac_pi/pi_entropy     | 3.421144    |
| training/sac_pi/pi_global_norm | 1.5143853   |
| training/sac_pi/policy_loss    | -206.12341  |
| training/sac_pi/std            | 0.5140211   |
| training/sac_pi/valid_num      | 4966.0      |
| training/sac_Q/q1              | 189.89859   |
| training/sac_Q/q2              | 191.86035   |
| training/sac_Q/q2_loss         | 89.003975   |
| training/sac_Q/q_global_norm   | 206.45392   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16990367  |
| epoch                          | 898         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4754.297    |
| evaluation/return-max          | 4843.0967   |
| evaluation/return-min          | 4711.4893   |
| evaluation/return-std          | 38.649418   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45770       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4754.297    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 185.93214   |
| Q-std                          | 189.75983   |
| Q_loss                         | 99.09158    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 898         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000536    |
| times/evaluation_paths         | 31.6        |
| times/timestep_after_hook      | 0.00407     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 57.7        |
| timestep                       | 1000        |
| timesteps_total                | 899000      |
| train-steps                    | 899000      |
| training/Q/q1_loss             | 95.973274   |
| training/sac_pi/alpha          | 0.16990104  |
| training/sac_pi/alpha_loss     | -0.23158728 |
| training/sac_pi/logp_pi        | 4.722005    |
| training/sac_pi/pi_entropy     | 3.3725114   |
| training/sac_pi/pi_global_norm | 1.4903097   |
| training/sac_pi/policy_loss    | -205.61806  |
| training/sac_pi/std            | 0.5196359   |
| training/sac_pi/valid_num      | 4946.0      |
| training/sac_Q/q1              | 191.33165   |
| training/sac_Q/q2              | 188.06252   |
| training/sac_Q/q2_loss         | 97.916405   |
| training/sac_Q/q_global_norm   | 210.44684   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16815051 |
| epoch                          | 899        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4689.075   |
| evaluation/return-max          | 4939.9595  |
| evaluation/return-min          | 4490.499   |
| evaluation/return-std          | 127.06767  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45988      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4689.075   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 183.43948  |
| Q-std                          | 205.36989  |
| Q_loss                         | 96.67154   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 899        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000575   |
| times/evaluation_paths         | 31.6       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 57.7       |
| timestep                       | 1000       |
| timesteps_total                | 900000     |
| train-steps                    | 900000     |
| training/Q/q1_loss             | 93.23468   |
| training/sac_pi/alpha          | 0.16818076 |
| training/sac_pi/alpha_loss     | -0.5205574 |
| training/sac_pi/logp_pi        | 4.019094   |
| training/sac_pi/pi_entropy     | 3.5043113  |
| training/sac_pi/pi_global_norm | 1.5264783  |
| training/sac_pi/policy_loss    | -205.67313 |
| training/sac_pi/std            | 0.5156728  |
| training/sac_pi/valid_num      | 4971.0     |
| training/sac_Q/q1              | 190.58902  |
| training/sac_Q/q2              | 190.18404  |
| training/sac_Q/q2_loss         | 92.67628   |
| training/sac_Q/q_global_norm   | 222.82344  |
--------------------------------------------------------------------------------
[WARN] 900 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16989186 |
| epoch                          | 900        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5000.732   |
| evaluation/return-max          | 5087.9985  |
| evaluation/return-min          | 4930.3237  |
| evaluation/return-std          | 47.899345  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 83.8       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45855      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5000.732   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 190.32948  |
| Q-std                          | 168.62505  |
| Q_loss                         | 101.64946  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 900        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000572   |
| times/evaluation_paths         | 32.1       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00799    |
| times/train                    | 57.9       |
| timestep                       | 1000       |
| timesteps_total                | 901000     |
| train-steps                    | 901000     |
| training/Q/q1_loss             | 120.49923  |
| training/sac_pi/alpha          | 0.16989104 |
| training/sac_pi/alpha_loss     | 0.12475084 |
| training/sac_pi/logp_pi        | 5.0829873  |
| training/sac_pi/pi_entropy     | 3.6296768  |
| training/sac_pi/pi_global_norm | 1.6786888  |
| training/sac_pi/policy_loss    | -208.76434 |
| training/sac_pi/std            | 0.5493214  |
| training/sac_pi/valid_num      | 4948.0     |
| training/sac_Q/q1              | 190.49405  |
| training/sac_Q/q2              | 187.2063   |
| training/sac_Q/q2_loss         | 120.0829   |
| training/sac_Q/q_global_norm   | 252.39354  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16995849  |
| epoch                          | 901         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4832.5605   |
| evaluation/return-max          | 4923.63     |
| evaluation/return-min          | 4785.9385   |
| evaluation/return-std          | 36.727753   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45823       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4832.5605   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 181.52051   |
| Q-std                          | 176.71617   |
| Q_loss                         | 113.86328   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 901         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000322    |
| times/epoch_rollout_model      | 506         |
| times/evaluation_metrics       | 0.000537    |
| times/evaluation_paths         | 31.6        |
| times/timestep_after_hook      | 0.00381     |
| times/timestep_before_hook     | 0.00798     |
| times/train                    | 57.7        |
| timestep                       | 1000        |
| timesteps_total                | 902000      |
| train-steps                    | 902000      |
| training/Q/q1_loss             | 104.1731    |
| training/sac_pi/alpha          | 0.16993494  |
| training/sac_pi/alpha_loss     | 0.052607294 |
| training/sac_pi/logp_pi        | 5.7574277   |
| training/sac_pi/pi_entropy     | 3.5799842   |
| training/sac_pi/pi_global_norm | 1.543817    |
| training/sac_pi/policy_loss    | -207.61871  |
| training/sac_pi/std            | 0.5788576   |
| training/sac_pi/valid_num      | 4886.0      |
| training/sac_Q/q1              | 183.68706   |
| training/sac_Q/q2              | 186.34041   |
| training/sac_Q/q2_loss         | 104.40955   |
| training/sac_Q/q_global_norm   | 235.84856   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1652869   |
| epoch                          | 902         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4870.5195   |
| evaluation/return-max          | 4888.1484   |
| evaluation/return-min          | 4852.73     |
| evaluation/return-std          | 10.326988   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45915       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4870.5195   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 195.72348   |
| Q-std                          | 167.49295   |
| Q_loss                         | 81.74629    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 902         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000154    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000517    |
| times/evaluation_paths         | 31.6        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 58.6        |
| timestep                       | 1000        |
| timesteps_total                | 903000      |
| train-steps                    | 903000      |
| training/Q/q1_loss             | 90.16332    |
| training/sac_pi/alpha          | 0.16528998  |
| training/sac_pi/alpha_loss     | -0.18707952 |
| training/sac_pi/logp_pi        | 4.012931    |
| training/sac_pi/pi_entropy     | 3.4302711   |
| training/sac_pi/pi_global_norm | 1.554893    |
| training/sac_pi/policy_loss    | -215.13521  |
| training/sac_pi/std            | 0.4971036   |
| training/sac_pi/valid_num      | 5018.0      |
| training/sac_Q/q1              | 200.53645   |
| training/sac_Q/q2              | 199.38376   |
| training/sac_Q/q2_loss         | 90.0485     |
| training/sac_Q/q_global_norm   | 188.5258    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16681448 |
| epoch                          | 903        |
| evaluation/episode-length-avg  | 919        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 492        |
| evaluation/episode-length-std  | 169        |
| evaluation/return-average      | 4191.0146  |
| evaluation/return-max          | 4766.2324  |
| evaluation/return-min          | 1968.9955  |
| evaluation/return-std          | 904.5323   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45993      |
| perf/AverageLength             | 919        |
| perf/AverageReturn             | 4191.0146  |
| perf/NormalizedReturn          | 0.913      |
| Q-avg                          | 194.4169   |
| Q-std                          | 186.15321  |
| Q_loss                         | 122.897705 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 903        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000551   |
| times/evaluation_paths         | 29.2       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00795    |
| times/train                    | 57         |
| timestep                       | 1000       |
| timesteps_total                | 904000     |
| train-steps                    | 904000     |
| training/Q/q1_loss             | 89.408     |
| training/sac_pi/alpha          | 0.16680795 |
| training/sac_pi/alpha_loss     | 0.18063812 |
| training/sac_pi/logp_pi        | 5.211441   |
| training/sac_pi/pi_entropy     | 3.3344378  |
| training/sac_pi/pi_global_norm | 1.6752303  |
| training/sac_pi/policy_loss    | -203.08807 |
| training/sac_pi/std            | 0.5150577  |
| training/sac_pi/valid_num      | 4927.0     |
| training/sac_Q/q1              | 185.86926  |
| training/sac_Q/q2              | 188.45865  |
| training/sac_Q/q2_loss         | 90.01323   |
| training/sac_Q/q_global_norm   | 176.01656  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16375339 |
| epoch                          | 904        |
| evaluation/episode-length-avg  | 785        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 427        |
| evaluation/episode-length-std  | 266        |
| evaluation/return-average      | 3494.4211  |
| evaluation/return-max          | 4717.9023  |
| evaluation/return-min          | 1703.5895  |
| evaluation/return-std          | 1338.6338  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 83         |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45948      |
| perf/AverageLength             | 785        |
| perf/AverageReturn             | 3494.4211  |
| perf/NormalizedReturn          | 0.761      |
| Q-avg                          | 202.64746  |
| Q-std                          | 151.68939  |
| Q_loss                         | 95.378494  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 904        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000543   |
| times/evaluation_paths         | 24.6       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 58.1       |
| timestep                       | 1000       |
| timesteps_total                | 905000     |
| train-steps                    | 905000     |
| training/Q/q1_loss             | 93.76115   |
| training/sac_pi/alpha          | 0.16374518 |
| training/sac_pi/alpha_loss     | 0.02488441 |
| training/sac_pi/logp_pi        | 3.9908555  |
| training/sac_pi/pi_entropy     | 3.2038789  |
| training/sac_pi/pi_global_norm | 1.5645784  |
| training/sac_pi/policy_loss    | -216.37291 |
| training/sac_pi/std            | 0.46655262 |
| training/sac_pi/valid_num      | 5013.0     |
| training/sac_Q/q1              | 209.0507   |
| training/sac_Q/q2              | 211.7961   |
| training/sac_Q/q2_loss         | 93.513885  |
| training/sac_Q/q_global_norm   | 203.42007  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16399576  |
| epoch                          | 905         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5041.2075   |
| evaluation/return-max          | 5081.783    |
| evaluation/return-min          | 4985.1797   |
| evaluation/return-std          | 26.479593   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46085       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5041.2075   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 198.15541   |
| Q-std                          | 143.70999   |
| Q_loss                         | 98.669395   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 905         |
| times/epoch_after_hook         | 3.26e-06    |
| times/epoch_before_hook        | 0.000272    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000508    |
| times/evaluation_paths         | 32.6        |
| times/timestep_after_hook      | 0.00386     |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 58.4        |
| timestep                       | 1000        |
| timesteps_total                | 906000      |
| train-steps                    | 906000      |
| training/Q/q1_loss             | 108.29303   |
| training/sac_pi/alpha          | 0.16400775  |
| training/sac_pi/alpha_loss     | -0.17170659 |
| training/sac_pi/logp_pi        | 4.665891    |
| training/sac_pi/pi_entropy     | 3.3950036   |
| training/sac_pi/pi_global_norm | 2.2022977   |
| training/sac_pi/policy_loss    | -214.52293  |
| training/sac_pi/std            | 0.5199778   |
| training/sac_pi/valid_num      | 4933.0      |
| training/sac_Q/q1              | 196.78394   |
| training/sac_Q/q2              | 196.05032   |
| training/sac_Q/q2_loss         | 108.818085  |
| training/sac_Q/q_global_norm   | 240.09525   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17125349  |
| epoch                          | 906         |
| evaluation/episode-length-avg  | 142         |
| evaluation/episode-length-max  | 153         |
| evaluation/episode-length-min  | 137         |
| evaluation/episode-length-std  | 5.01        |
| evaluation/return-average      | 378.68518   |
| evaluation/return-max          | 414.53207   |
| evaluation/return-min          | 360.04327   |
| evaluation/return-std          | 17.086267   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46063       |
| perf/AverageLength             | 142         |
| perf/AverageReturn             | 378.68518   |
| perf/NormalizedReturn          | 0.0821      |
| Q-avg                          | 200.51866   |
| Q-std                          | 190.85004   |
| Q_loss                         | 85.70292    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 906         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000557    |
| times/evaluation_paths         | 4.6         |
| times/timestep_after_hook      | 0.00386     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 58.7        |
| timestep                       | 1000        |
| timesteps_total                | 907000      |
| train-steps                    | 907000      |
| training/Q/q1_loss             | 93.81853    |
| training/sac_pi/alpha          | 0.17126094  |
| training/sac_pi/alpha_loss     | -0.17744988 |
| training/sac_pi/logp_pi        | 4.6890435   |
| training/sac_pi/pi_entropy     | 3.702369    |
| training/sac_pi/pi_global_norm | 1.7136763   |
| training/sac_pi/policy_loss    | -204.05206  |
| training/sac_pi/std            | 0.5529972   |
| training/sac_pi/valid_num      | 4893.0      |
| training/sac_Q/q1              | 182.74992   |
| training/sac_Q/q2              | 182.15579   |
| training/sac_Q/q2_loss         | 94.198524   |
| training/sac_Q/q_global_norm   | 181.10406   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17077382  |
| epoch                          | 907         |
| evaluation/episode-length-avg  | 747         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 152         |
| evaluation/episode-length-std  | 387         |
| evaluation/return-average      | 3555.7083   |
| evaluation/return-max          | 4945.6445   |
| evaluation/return-min          | 380.53976   |
| evaluation/return-std          | 2066.884    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46001       |
| perf/AverageLength             | 747         |
| perf/AverageReturn             | 3555.7083   |
| perf/NormalizedReturn          | 0.774       |
| Q-avg                          | 185.68222   |
| Q-std                          | 191.43864   |
| Q_loss                         | 119.75442   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 907         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000107    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000703    |
| times/evaluation_paths         | 23.4        |
| times/timestep_after_hook      | 0.00383     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 58          |
| timestep                       | 1000        |
| timesteps_total                | 908000      |
| train-steps                    | 908000      |
| training/Q/q1_loss             | 87.80832    |
| training/sac_pi/alpha          | 0.17079851  |
| training/sac_pi/alpha_loss     | -0.36980358 |
| training/sac_pi/logp_pi        | 4.18114     |
| training/sac_pi/pi_entropy     | 3.577851    |
| training/sac_pi/pi_global_norm | 1.6253359   |
| training/sac_pi/policy_loss    | -205.92422  |
| training/sac_pi/std            | 0.51677114  |
| training/sac_pi/valid_num      | 4983.0      |
| training/sac_Q/q1              | 188.06929   |
| training/sac_Q/q2              | 189.69328   |
| training/sac_Q/q2_loss         | 88.80247    |
| training/sac_Q/q_global_norm   | 200.54892   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16956265 |
| epoch                          | 908        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4950.6284  |
| evaluation/return-max          | 4988.532   |
| evaluation/return-min          | 4832.9336  |
| evaluation/return-std          | 41.33796   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45815      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4950.6284  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 185.03108  |
| Q-std                          | 190.79607  |
| Q_loss                         | 92.96839   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 908        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000196   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 31.4       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 58.3       |
| timestep                       | 1000       |
| timesteps_total                | 909000     |
| train-steps                    | 909000     |
| training/Q/q1_loss             | 119.28971  |
| training/sac_pi/alpha          | 0.16952974 |
| training/sac_pi/alpha_loss     | 0.4017096  |
| training/sac_pi/logp_pi        | 3.9979248  |
| training/sac_pi/pi_entropy     | 3.512078   |
| training/sac_pi/pi_global_norm | 1.9919661  |
| training/sac_pi/policy_loss    | -203.04509 |
| training/sac_pi/std            | 0.49759477 |
| training/sac_pi/valid_num      | 4999.0     |
| training/sac_Q/q1              | 193.39577  |
| training/sac_Q/q2              | 194.08286  |
| training/sac_Q/q2_loss         | 119.62265  |
| training/sac_Q/q_global_norm   | 242.20245  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16795853   |
| epoch                          | 909          |
| evaluation/episode-length-avg  | 915          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 151          |
| evaluation/episode-length-std  | 255          |
| evaluation/return-average      | 4383.5225    |
| evaluation/return-max          | 4885.2944    |
| evaluation/return-min          | 417.1131     |
| evaluation/return-std          | 1324.7706    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.98         |
| model/origin_ret               | 84.6         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45944        |
| perf/AverageLength             | 915          |
| perf/AverageReturn             | 4383.5225    |
| perf/NormalizedReturn          | 0.955        |
| Q-avg                          | 187.41922    |
| Q-std                          | 170.09784    |
| Q_loss                         | 99.04606     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 909          |
| times/epoch_after_hook         | 1.86e-06     |
| times/epoch_before_hook        | 0.000568     |
| times/epoch_rollout_model      | 512          |
| times/evaluation_metrics       | 0.000589     |
| times/evaluation_paths         | 29.1         |
| times/timestep_after_hook      | 0.00386      |
| times/timestep_before_hook     | 0.00822      |
| times/train                    | 58.9         |
| timestep                       | 1000         |
| timesteps_total                | 910000       |
| train-steps                    | 910000       |
| training/Q/q1_loss             | 86.65054     |
| training/sac_pi/alpha          | 0.16794097   |
| training/sac_pi/alpha_loss     | -0.039890595 |
| training/sac_pi/logp_pi        | 3.9558303    |
| training/sac_pi/pi_entropy     | 3.4773765    |
| training/sac_pi/pi_global_norm | 1.698279     |
| training/sac_pi/policy_loss    | -209.28773   |
| training/sac_pi/std            | 0.49503943   |
| training/sac_pi/valid_num      | 4968.0       |
| training/sac_Q/q1              | 196.91138    |
| training/sac_Q/q2              | 197.67905    |
| training/sac_Q/q2_loss         | 88.099236    |
| training/sac_Q/q_global_norm   | 183.22926    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16951667  |
| epoch                          | 910         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4943.949    |
| evaluation/return-max          | 4999.014    |
| evaluation/return-min          | 4875.544    |
| evaluation/return-std          | 41.049747   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45958       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4943.949    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 197.51826   |
| Q-std                          | 193.88217   |
| Q_loss                         | 82.48237    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 910         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000164    |
| times/epoch_rollout_model      | 513         |
| times/evaluation_metrics       | 0.000552    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00386     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 58.5        |
| timestep                       | 1000        |
| timesteps_total                | 911000      |
| train-steps                    | 911000      |
| training/Q/q1_loss             | 112.15724   |
| training/sac_pi/alpha          | 0.16953684  |
| training/sac_pi/alpha_loss     | -0.18058886 |
| training/sac_pi/logp_pi        | 4.289172    |
| training/sac_pi/pi_entropy     | 3.7203274   |
| training/sac_pi/pi_global_norm | 1.5129445   |
| training/sac_pi/policy_loss    | -205.45334  |
| training/sac_pi/std            | 0.534367    |
| training/sac_pi/valid_num      | 4873.0      |
| training/sac_Q/q1              | 188.32481   |
| training/sac_Q/q2              | 188.15999   |
| training/sac_Q/q2_loss         | 112.84564   |
| training/sac_Q/q_global_norm   | 234.95323   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17372823   |
| epoch                          | 911          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5017.4937    |
| evaluation/return-max          | 5043.252     |
| evaluation/return-min          | 4960.635     |
| evaluation/return-std          | 21.800875    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.94         |
| model/origin_ret               | 83.7         |
| model/penalty_ret              | 80.9         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 46021        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5017.4937    |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 205.77144    |
| Q-std                          | 136.16507    |
| Q_loss                         | 74.62847     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 911          |
| times/epoch_after_hook         | 1.75e-06     |
| times/epoch_before_hook        | 0.000127     |
| times/epoch_rollout_model      | 504          |
| times/evaluation_metrics       | 0.000538     |
| times/evaluation_paths         | 32.1         |
| times/timestep_after_hook      | 0.0039       |
| times/timestep_before_hook     | 0.00826      |
| times/train                    | 58.7         |
| timestep                       | 1000         |
| timesteps_total                | 912000       |
| train-steps                    | 912000       |
| training/Q/q1_loss             | 88.381424    |
| training/sac_pi/alpha          | 0.17373188   |
| training/sac_pi/alpha_loss     | -0.021948991 |
| training/sac_pi/logp_pi        | 4.7321525    |
| training/sac_pi/pi_entropy     | 3.5277145    |
| training/sac_pi/pi_global_norm | 1.8206868    |
| training/sac_pi/policy_loss    | -203.7656    |
| training/sac_pi/std            | 0.5312642    |
| training/sac_pi/valid_num      | 4886.0       |
| training/sac_Q/q1              | 182.10025    |
| training/sac_Q/q2              | 183.61894    |
| training/sac_Q/q2_loss         | 88.88792     |
| training/sac_Q/q_global_norm   | 255.10007    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1667969  |
| epoch                          | 912        |
| evaluation/episode-length-avg  | 577        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 143        |
| evaluation/episode-length-std  | 423        |
| evaluation/return-average      | 2782.786   |
| evaluation/return-max          | 5092.1787  |
| evaluation/return-min          | 487.2097   |
| evaluation/return-std          | 2254.47    |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45934      |
| perf/AverageLength             | 577        |
| perf/AverageReturn             | 2782.786   |
| perf/NormalizedReturn          | 0.606      |
| Q-avg                          | 188.95071  |
| Q-std                          | 171.05379  |
| Q_loss                         | 88.75515   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 912        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000549   |
| times/evaluation_paths         | 18.1       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00806    |
| times/train                    | 57.4       |
| timestep                       | 1000       |
| timesteps_total                | 913000     |
| train-steps                    | 913000     |
| training/Q/q1_loss             | 83.37972   |
| training/sac_pi/alpha          | 0.16678181 |
| training/sac_pi/alpha_loss     | -0.2758907 |
| training/sac_pi/logp_pi        | 4.117757   |
| training/sac_pi/pi_entropy     | 3.4423165  |
| training/sac_pi/pi_global_norm | 1.7090207  |
| training/sac_pi/policy_loss    | -214.13846 |
| training/sac_pi/std            | 0.5072579  |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 198.46121  |
| training/sac_Q/q2              | 196.29759  |
| training/sac_Q/q2_loss         | 82.760605  |
| training/sac_Q/q_global_norm   | 181.4904   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16801722  |
| epoch                          | 913         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4985.0674   |
| evaluation/return-max          | 5020.5957   |
| evaluation/return-min          | 4892.705    |
| evaluation/return-std          | 34.99453    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46068       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4985.0674   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 207.04443   |
| Q-std                          | 124.66726   |
| Q_loss                         | 99.5368     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 913         |
| times/epoch_after_hook         | 1.99e-06    |
| times/epoch_before_hook        | 0.00035     |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000536    |
| times/evaluation_paths         | 31.4        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00809     |
| times/train                    | 58          |
| timestep                       | 1000        |
| timesteps_total                | 914000      |
| train-steps                    | 914000      |
| training/Q/q1_loss             | 86.11599    |
| training/sac_pi/alpha          | 0.16803613  |
| training/sac_pi/alpha_loss     | 0.010029639 |
| training/sac_pi/logp_pi        | 4.510914    |
| training/sac_pi/pi_entropy     | 3.520794    |
| training/sac_pi/pi_global_norm | 1.5740417   |
| training/sac_pi/policy_loss    | -212.8614   |
| training/sac_pi/std            | 0.5360366   |
| training/sac_pi/valid_num      | 4925.0      |
| training/sac_Q/q1              | 193.32573   |
| training/sac_Q/q2              | 194.27226   |
| training/sac_Q/q2_loss         | 86.67947    |
| training/sac_Q/q_global_norm   | 231.76967   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17030303 |
| epoch                          | 914        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4944.011   |
| evaluation/return-max          | 5006.4893  |
| evaluation/return-min          | 4860.6143  |
| evaluation/return-std          | 45.29573   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45911      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4944.011   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 194.74707  |
| Q-std                          | 175.0064   |
| Q_loss                         | 85.20439   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 914        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 510        |
| times/evaluation_metrics       | 0.000617   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 57.7       |
| timestep                       | 1000       |
| timesteps_total                | 915000     |
| train-steps                    | 915000     |
| training/Q/q1_loss             | 101.83289  |
| training/sac_pi/alpha          | 0.1703073  |
| training/sac_pi/alpha_loss     | 0.20452866 |
| training/sac_pi/logp_pi        | 4.888583   |
| training/sac_pi/pi_entropy     | 3.3555298  |
| training/sac_pi/pi_global_norm | 1.4513084  |
| training/sac_pi/policy_loss    | -207.82066 |
| training/sac_pi/std            | 0.5103101  |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 195.06049  |
| training/sac_Q/q2              | 193.04118  |
| training/sac_Q/q2_loss         | 101.22042  |
| training/sac_Q/q_global_norm   | 183.38599  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17058077  |
| epoch                          | 915         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5272.309    |
| evaluation/return-max          | 5284.49     |
| evaluation/return-min          | 5241.215    |
| evaluation/return-std          | 12.657148   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45973       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5272.309    |
| perf/NormalizedReturn          | 1.15        |
| Q-avg                          | 188.6446    |
| Q-std                          | 189.37402   |
| Q_loss                         | 101.119736  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 915         |
| times/epoch_after_hook         | 2.13e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000569    |
| times/evaluation_paths         | 31.1        |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.00806     |
| times/train                    | 58.3        |
| timestep                       | 1000        |
| timesteps_total                | 916000      |
| train-steps                    | 916000      |
| training/Q/q1_loss             | 112.63372   |
| training/sac_pi/alpha          | 0.17058547  |
| training/sac_pi/alpha_loss     | 0.007412412 |
| training/sac_pi/logp_pi        | 4.43372     |
| training/sac_pi/pi_entropy     | 3.7253175   |
| training/sac_pi/pi_global_norm | 1.6364748   |
| training/sac_pi/policy_loss    | -205.21964  |
| training/sac_pi/std            | 0.5461499   |
| training/sac_pi/valid_num      | 4960.0      |
| training/sac_Q/q1              | 185.44177   |
| training/sac_Q/q2              | 184.29013   |
| training/sac_Q/q2_loss         | 111.871254  |
| training/sac_Q/q_global_norm   | 217.90013   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17077628  |
| epoch                          | 916         |
| evaluation/episode-length-avg  | 575         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 144         |
| evaluation/episode-length-std  | 425         |
| evaluation/return-average      | 2730.869    |
| evaluation/return-max          | 5024.7144   |
| evaluation/return-min          | 452.52942   |
| evaluation/return-std          | 2248.685    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45993       |
| perf/AverageLength             | 575         |
| perf/AverageReturn             | 2730.869    |
| perf/NormalizedReturn          | 0.595       |
| Q-avg                          | 196.49707   |
| Q-std                          | 169.71275   |
| Q_loss                         | 101.439606  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 916         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 506         |
| times/evaluation_metrics       | 0.000539    |
| times/evaluation_paths         | 18          |
| times/timestep_after_hook      | 0.00386     |
| times/timestep_before_hook     | 0.00809     |
| times/train                    | 57.9        |
| timestep                       | 1000        |
| timesteps_total                | 917000      |
| train-steps                    | 917000      |
| training/Q/q1_loss             | 98.03292    |
| training/sac_pi/alpha          | 0.17076814  |
| training/sac_pi/alpha_loss     | 0.013684103 |
| training/sac_pi/logp_pi        | 4.464846    |
| training/sac_pi/pi_entropy     | 3.573606    |
| training/sac_pi/pi_global_norm | 1.787574    |
| training/sac_pi/policy_loss    | -212.09914  |
| training/sac_pi/std            | 0.52591234  |
| training/sac_pi/valid_num      | 4949.0      |
| training/sac_Q/q1              | 195.77774   |
| training/sac_Q/q2              | 191.38676   |
| training/sac_Q/q2_loss         | 97.546715   |
| training/sac_Q/q_global_norm   | 216.9104    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17019068  |
| epoch                          | 917         |
| evaluation/episode-length-avg  | 832         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 157         |
| evaluation/episode-length-std  | 336         |
| evaluation/return-average      | 4136.3267   |
| evaluation/return-max          | 5120.5684   |
| evaluation/return-min          | 507.7218    |
| evaluation/return-std          | 1807.6991   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45893       |
| perf/AverageLength             | 832         |
| perf/AverageReturn             | 4136.3267   |
| perf/NormalizedReturn          | 0.901       |
| Q-avg                          | 180.3995    |
| Q-std                          | 253.74791   |
| Q_loss                         | 103.477585  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 917         |
| times/epoch_after_hook         | 2.05e-06    |
| times/epoch_before_hook        | 0.000329    |
| times/epoch_rollout_model      | 511         |
| times/evaluation_metrics       | 0.00055     |
| times/evaluation_paths         | 25.9        |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 58          |
| timestep                       | 1000        |
| timesteps_total                | 918000      |
| train-steps                    | 918000      |
| training/Q/q1_loss             | 88.469215   |
| training/sac_pi/alpha          | 0.17022419  |
| training/sac_pi/alpha_loss     | 0.061233543 |
| training/sac_pi/logp_pi        | 4.3245325   |
| training/sac_pi/pi_entropy     | 3.2825646   |
| training/sac_pi/pi_global_norm | 1.3986511   |
| training/sac_pi/policy_loss    | -216.60657  |
| training/sac_pi/std            | 0.47778887  |
| training/sac_pi/valid_num      | 5025.0      |
| training/sac_Q/q1              | 207.38525   |
| training/sac_Q/q2              | 206.59421   |
| training/sac_Q/q2_loss         | 88.70481    |
| training/sac_Q/q_global_norm   | 189.93588   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16873112  |
| epoch                          | 918         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5018.087    |
| evaluation/return-max          | 5062.658    |
| evaluation/return-min          | 4969.917    |
| evaluation/return-std          | 29.961214   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46059       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5018.087    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 186.00989   |
| Q-std                          | 169.43375   |
| Q_loss                         | 77.57472    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 918         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000533    |
| times/evaluation_paths         | 31.4        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 58.2        |
| timestep                       | 1000        |
| timesteps_total                | 919000      |
| train-steps                    | 919000      |
| training/Q/q1_loss             | 97.53943    |
| training/sac_pi/alpha          | 0.16875091  |
| training/sac_pi/alpha_loss     | -0.51197064 |
| training/sac_pi/logp_pi        | 4.365008    |
| training/sac_pi/pi_entropy     | 3.3029296   |
| training/sac_pi/pi_global_norm | 1.5199691   |
| training/sac_pi/policy_loss    | -208.67651  |
| training/sac_pi/std            | 0.49613267  |
| training/sac_pi/valid_num      | 4940.0      |
| training/sac_Q/q1              | 190.05814   |
| training/sac_Q/q2              | 187.44675   |
| training/sac_Q/q2_loss         | 97.120575   |
| training/sac_Q/q_global_norm   | 262.60822   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16684034  |
| epoch                          | 919         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5034.236    |
| evaluation/return-max          | 5151.7134   |
| evaluation/return-min          | 4971.5073   |
| evaluation/return-std          | 59.04521    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46011       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5034.236    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 185.30963   |
| Q-std                          | 193.34108   |
| Q_loss                         | 98.34766    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 919         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000535    |
| times/evaluation_paths         | 30.4        |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00783     |
| times/train                    | 56.7        |
| timestep                       | 1000        |
| timesteps_total                | 920000      |
| train-steps                    | 920000      |
| training/Q/q1_loss             | 104.39643   |
| training/sac_pi/alpha          | 0.16683336  |
| training/sac_pi/alpha_loss     | 0.011283242 |
| training/sac_pi/logp_pi        | 4.995327    |
| training/sac_pi/pi_entropy     | 3.4539714   |
| training/sac_pi/pi_global_norm | 1.717431    |
| training/sac_pi/policy_loss    | -207.2561   |
| training/sac_pi/std            | 0.5299377   |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 186.05661   |
| training/sac_Q/q2              | 185.4403    |
| training/sac_Q/q2_loss         | 103.92551   |
| training/sac_Q/q_global_norm   | 221.5788    |
---------------------------------------------------------------------------------
[WARN] 920 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.17267954  |
| epoch                          | 920         |
| evaluation/episode-length-avg  | 576         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 150         |
| evaluation/episode-length-std  | 424         |
| evaluation/return-average      | 2669.7585   |
| evaluation/return-max          | 4953.042    |
| evaluation/return-min          | 416.22232   |
| evaluation/return-std          | 2238.161    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46057       |
| perf/AverageLength             | 576         |
| perf/AverageReturn             | 2669.7585   |
| perf/NormalizedReturn          | 0.581       |
| Q-avg                          | 186.52034   |
| Q-std                          | 236.60071   |
| Q_loss                         | 87.45148    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 920         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000104    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000519    |
| times/evaluation_paths         | 18.4        |
| times/timestep_after_hook      | 0.00386     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 58.8        |
| timestep                       | 1000        |
| timesteps_total                | 921000      |
| train-steps                    | 921000      |
| training/Q/q1_loss             | 94.69221    |
| training/sac_pi/alpha          | 0.1726699   |
| training/sac_pi/alpha_loss     | -0.09970604 |
| training/sac_pi/logp_pi        | 4.2039227   |
| training/sac_pi/pi_entropy     | 3.5095055   |
| training/sac_pi/pi_global_norm | 1.659093    |
| training/sac_pi/policy_loss    | -208.84604  |
| training/sac_pi/std            | 0.5141736   |
| training/sac_pi/valid_num      | 4922.0      |
| training/sac_Q/q1              | 190.56982   |
| training/sac_Q/q2              | 191.7738    |
| training/sac_Q/q2_loss         | 94.807365   |
| training/sac_Q/q_global_norm   | 255.47806   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17032817   |
| epoch                          | 921          |
| evaluation/episode-length-avg  | 155          |
| evaluation/episode-length-max  | 163          |
| evaluation/episode-length-min  | 152          |
| evaluation/episode-length-std  | 2.91         |
| evaluation/return-average      | 503.3667     |
| evaluation/return-max          | 524.8131     |
| evaluation/return-min          | 481.60254    |
| evaluation/return-std          | 12.709947    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.98         |
| model/origin_ret               | 84.8         |
| model/penalty_ret              | 81.4         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45937        |
| perf/AverageLength             | 155          |
| perf/AverageReturn             | 503.3667     |
| perf/NormalizedReturn          | 0.109        |
| Q-avg                          | 185.9574     |
| Q-std                          | 242.89417    |
| Q_loss                         | 97.01902     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 921          |
| times/epoch_after_hook         | 1.77e-06     |
| times/epoch_before_hook        | 0.000325     |
| times/epoch_rollout_model      | 495          |
| times/evaluation_metrics       | 0.00048      |
| times/evaluation_paths         | 4.81         |
| times/timestep_after_hook      | 0.00355      |
| times/timestep_before_hook     | 0.00779      |
| times/train                    | 56.1         |
| timestep                       | 1000         |
| timesteps_total                | 922000       |
| train-steps                    | 922000       |
| training/Q/q1_loss             | 74.51347     |
| training/sac_pi/alpha          | 0.17034172   |
| training/sac_pi/alpha_loss     | -0.031009408 |
| training/sac_pi/logp_pi        | 4.1744432    |
| training/sac_pi/pi_entropy     | 3.4185662    |
| training/sac_pi/pi_global_norm | 1.6025323    |
| training/sac_pi/policy_loss    | -214.28767   |
| training/sac_pi/std            | 0.5019019    |
| training/sac_pi/valid_num      | 5023.0       |
| training/sac_Q/q1              | 203.07832    |
| training/sac_Q/q2              | 200.69797    |
| training/sac_Q/q2_loss         | 74.52742     |
| training/sac_Q/q_global_norm   | 267.22855    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16762851   |
| epoch                          | 922          |
| evaluation/episode-length-avg  | 916          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 164          |
| evaluation/episode-length-std  | 251          |
| evaluation/return-average      | 4402.399     |
| evaluation/return-max          | 4854.4       |
| evaluation/return-min          | 462.90448    |
| evaluation/return-std          | 1313.1863    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.01         |
| model/origin_ret               | 85.2         |
| model/penalty_ret              | 81           |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45915        |
| perf/AverageLength             | 916          |
| perf/AverageReturn             | 4402.399     |
| perf/NormalizedReturn          | 0.959        |
| Q-avg                          | 193.73283    |
| Q-std                          | 175.53043    |
| Q_loss                         | 87.0566      |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 922          |
| times/epoch_after_hook         | 1.73e-06     |
| times/epoch_before_hook        | 0.000126     |
| times/epoch_rollout_model      | 497          |
| times/evaluation_metrics       | 0.000535     |
| times/evaluation_paths         | 28.7         |
| times/timestep_after_hook      | 0.00376      |
| times/timestep_before_hook     | 0.00814      |
| times/train                    | 57.9         |
| timestep                       | 1000         |
| timesteps_total                | 923000       |
| train-steps                    | 923000       |
| training/Q/q1_loss             | 89.93176     |
| training/sac_pi/alpha          | 0.16761295   |
| training/sac_pi/alpha_loss     | -0.045541592 |
| training/sac_pi/logp_pi        | 5.0591993    |
| training/sac_pi/pi_entropy     | 3.326091     |
| training/sac_pi/pi_global_norm | 1.8273447    |
| training/sac_pi/policy_loss    | -217.68654   |
| training/sac_pi/std            | 0.52316606   |
| training/sac_pi/valid_num      | 4948.0       |
| training/sac_Q/q1              | 194.97818    |
| training/sac_Q/q2              | 193.90143    |
| training/sac_Q/q2_loss         | 90.59397     |
| training/sac_Q/q_global_norm   | 164.97441    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16925044  |
| epoch                          | 923         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4957.409    |
| evaluation/return-max          | 4979.4697   |
| evaluation/return-min          | 4930.7383   |
| evaluation/return-std          | 15.844691   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46005       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4957.409    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 195.43025   |
| Q-std                          | 200.057     |
| Q_loss                         | 91.6245     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 923         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000118    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000522    |
| times/evaluation_paths         | 33.3        |
| times/timestep_after_hook      | 0.00397     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 59.9        |
| timestep                       | 1000        |
| timesteps_total                | 924000      |
| train-steps                    | 924000      |
| training/Q/q1_loss             | 80.26306    |
| training/sac_pi/alpha          | 0.16926424  |
| training/sac_pi/alpha_loss     | -0.27316505 |
| training/sac_pi/logp_pi        | 5.076255    |
| training/sac_pi/pi_entropy     | 3.7009792   |
| training/sac_pi/pi_global_norm | 1.6155671   |
| training/sac_pi/policy_loss    | -203.94002  |
| training/sac_pi/std            | 0.5695982   |
| training/sac_pi/valid_num      | 4907.0      |
| training/sac_Q/q1              | 173.63159   |
| training/sac_Q/q2              | 173.62688   |
| training/sac_Q/q2_loss         | 78.40203    |
| training/sac_Q/q_global_norm   | 207.94762   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16908981  |
| epoch                          | 924         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4664.1177   |
| evaluation/return-max          | 4765.7236   |
| evaluation/return-min          | 4542.343    |
| evaluation/return-std          | 78.656906   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45766       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4664.1177   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 200.00192   |
| Q-std                          | 172.62158   |
| Q_loss                         | 105.62701   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 924         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000145    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000535    |
| times/evaluation_paths         | 33.1        |
| times/timestep_after_hook      | 0.00414     |
| times/timestep_before_hook     | 0.00838     |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 925000      |
| train-steps                    | 925000      |
| training/Q/q1_loss             | 90.310356   |
| training/sac_pi/alpha          | 0.16906695  |
| training/sac_pi/alpha_loss     | -0.03726261 |
| training/sac_pi/logp_pi        | 4.9317265   |
| training/sac_pi/pi_entropy     | 3.5112224   |
| training/sac_pi/pi_global_norm | 1.524134    |
| training/sac_pi/policy_loss    | -204.00009  |
| training/sac_pi/std            | 0.55791163  |
| training/sac_pi/valid_num      | 4934.0      |
| training/sac_Q/q1              | 182.17548   |
| training/sac_Q/q2              | 181.9091    |
| training/sac_Q/q2_loss         | 91.069824   |
| training/sac_Q/q_global_norm   | 156.06326   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1674137  |
| epoch                          | 925        |
| evaluation/episode-length-avg  | 579        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 150        |
| evaluation/episode-length-std  | 421        |
| evaluation/return-average      | 2635.5208  |
| evaluation/return-max          | 4840.236   |
| evaluation/return-min          | 453.21112  |
| evaluation/return-std          | 2160.2412  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45920      |
| perf/AverageLength             | 579        |
| perf/AverageReturn             | 2635.5208  |
| perf/NormalizedReturn          | 0.574      |
| Q-avg                          | 195.0689   |
| Q-std                          | 182.95183  |
| Q_loss                         | 85.37441   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 925        |
| times/epoch_after_hook         | 2.18e-06   |
| times/epoch_before_hook        | 0.000323   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000672   |
| times/evaluation_paths         | 19.1       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 59.5       |
| timestep                       | 1000       |
| timesteps_total                | 926000     |
| train-steps                    | 926000     |
| training/Q/q1_loss             | 106.91599  |
| training/sac_pi/alpha          | 0.16742302 |
| training/sac_pi/alpha_loss     | 0.08959208 |
| training/sac_pi/logp_pi        | 4.0647597  |
| training/sac_pi/pi_entropy     | 3.4681382  |
| training/sac_pi/pi_global_norm | 1.9311876  |
| training/sac_pi/policy_loss    | -200.7746  |
| training/sac_pi/std            | 0.4933775  |
| training/sac_pi/valid_num      | 4992.0     |
| training/sac_Q/q1              | 191.78836  |
| training/sac_Q/q2              | 192.41978  |
| training/sac_Q/q2_loss         | 106.75199  |
| training/sac_Q/q_global_norm   | 155.78674  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16247186 |
| epoch                          | 926        |
| evaluation/episode-length-avg  | 921        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 568        |
| evaluation/episode-length-std  | 142        |
| evaluation/return-average      | 4376.3916  |
| evaluation/return-max          | 4875.984   |
| evaluation/return-min          | 2526.3657  |
| evaluation/return-std          | 750.15204  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45936      |
| perf/AverageLength             | 921        |
| perf/AverageReturn             | 4376.3916  |
| perf/NormalizedReturn          | 0.953      |
| Q-avg                          | 189.98575  |
| Q-std                          | 209.9823   |
| Q_loss                         | 118.06769  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 926        |
| times/epoch_after_hook         | 3.43e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000511   |
| times/evaluation_paths         | 31.1       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 927000     |
| train-steps                    | 927000     |
| training/Q/q1_loss             | 92.147514  |
| training/sac_pi/alpha          | 0.16244948 |
| training/sac_pi/alpha_loss     | 0.11371841 |
| training/sac_pi/logp_pi        | 4.7747903  |
| training/sac_pi/pi_entropy     | 3.3056397  |
| training/sac_pi/pi_global_norm | 2.2041025  |
| training/sac_pi/policy_loss    | -213.6054  |
| training/sac_pi/std            | 0.5077038  |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 194.44484  |
| training/sac_Q/q2              | 198.95001  |
| training/sac_Q/q2_loss         | 93.039116  |
| training/sac_Q/q_global_norm   | 222.86534  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16936514 |
| epoch                          | 927        |
| evaluation/episode-length-avg  | 654        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 130        |
| evaluation/episode-length-std  | 424        |
| evaluation/return-average      | 3030.53    |
| evaluation/return-max          | 4847.585   |
| evaluation/return-min          | 325.94043  |
| evaluation/return-std          | 2198.7268  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45862      |
| perf/AverageLength             | 654        |
| perf/AverageReturn             | 3030.53    |
| perf/NormalizedReturn          | 0.66       |
| Q-avg                          | 183.9397   |
| Q-std                          | 250.83804  |
| Q_loss                         | 87.28771   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 927        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000634   |
| times/evaluation_paths         | 21.8       |
| times/timestep_after_hook      | 0.00421    |
| times/timestep_before_hook     | 0.00856    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 928000     |
| train-steps                    | 928000     |
| training/Q/q1_loss             | 86.16463   |
| training/sac_pi/alpha          | 0.1693771  |
| training/sac_pi/alpha_loss     | -0.5378313 |
| training/sac_pi/logp_pi        | 3.9554634  |
| training/sac_pi/pi_entropy     | 3.3448074  |
| training/sac_pi/pi_global_norm | 1.477397   |
| training/sac_pi/policy_loss    | -208.13002 |
| training/sac_pi/std            | 0.48795053 |
| training/sac_pi/valid_num      | 4930.0     |
| training/sac_Q/q1              | 192.5815   |
| training/sac_Q/q2              | 193.71255  |
| training/sac_Q/q2_loss         | 84.52372   |
| training/sac_Q/q_global_norm   | 176.70245  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16965696 |
| epoch                          | 928        |
| evaluation/episode-length-avg  | 661        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 149        |
| evaluation/episode-length-std  | 415        |
| evaluation/return-average      | 3043.596   |
| evaluation/return-max          | 4800.9307  |
| evaluation/return-min          | 463.3053   |
| evaluation/return-std          | 2098.2864  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46052      |
| perf/AverageLength             | 661        |
| perf/AverageReturn             | 3043.596   |
| perf/NormalizedReturn          | 0.663      |
| Q-avg                          | 192.45119  |
| Q-std                          | 145.9828   |
| Q_loss                         | 102.09267  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 928        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000145   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000527   |
| times/evaluation_paths         | 21.8       |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 929000     |
| train-steps                    | 929000     |
| training/Q/q1_loss             | 90.659164  |
| training/sac_pi/alpha          | 0.16966115 |
| training/sac_pi/alpha_loss     | 0.09790842 |
| training/sac_pi/logp_pi        | 5.0484486  |
| training/sac_pi/pi_entropy     | 3.5206692  |
| training/sac_pi/pi_global_norm | 1.663579   |
| training/sac_pi/policy_loss    | -208.40396 |
| training/sac_pi/std            | 0.54228854 |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 188.20836  |
| training/sac_Q/q2              | 190.42526  |
| training/sac_Q/q2_loss         | 90.34924   |
| training/sac_Q/q_global_norm   | 185.28177  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1689671   |
| epoch                          | 929         |
| evaluation/episode-length-avg  | 829         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 145         |
| evaluation/episode-length-std  | 341         |
| evaluation/return-average      | 4036.7114   |
| evaluation/return-max          | 4957.6934   |
| evaluation/return-min          | 459.58325   |
| evaluation/return-std          | 1786.7871   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46081       |
| perf/AverageLength             | 829         |
| perf/AverageReturn             | 4036.7114   |
| perf/NormalizedReturn          | 0.879       |
| Q-avg                          | 200.81418   |
| Q-std                          | 191.7679    |
| Q_loss                         | 89.62859    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 929         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000328    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000537    |
| times/evaluation_paths         | 27.3        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.009       |
| times/train                    | 59.8        |
| timestep                       | 1000        |
| timesteps_total                | 930000      |
| train-steps                    | 930000      |
| training/Q/q1_loss             | 99.69553    |
| training/sac_pi/alpha          | 0.16894571  |
| training/sac_pi/alpha_loss     | 0.044762142 |
| training/sac_pi/logp_pi        | 4.5029564   |
| training/sac_pi/pi_entropy     | 3.476953    |
| training/sac_pi/pi_global_norm | 2.5538397   |
| training/sac_pi/policy_loss    | -211.66025  |
| training/sac_pi/std            | 0.52046144  |
| training/sac_pi/valid_num      | 4949.0      |
| training/sac_Q/q1              | 196.72163   |
| training/sac_Q/q2              | 193.80505   |
| training/sac_Q/q2_loss         | 99.663605   |
| training/sac_Q/q_global_norm   | 208.68834   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17393258 |
| epoch                          | 930        |
| evaluation/episode-length-avg  | 400        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 134        |
| evaluation/episode-length-std  | 393        |
| evaluation/return-average      | 1731.8961  |
| evaluation/return-max          | 4798.838   |
| evaluation/return-min          | 382.6308   |
| evaluation/return-std          | 1983.72    |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46008      |
| perf/AverageLength             | 400        |
| perf/AverageReturn             | 1731.8961  |
| perf/NormalizedReturn          | 0.377      |
| Q-avg                          | 198.58408  |
| Q-std                          | 166.78201  |
| Q_loss                         | 97.83988   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 930        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000141   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000559   |
| times/evaluation_paths         | 13.3       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 931000     |
| train-steps                    | 931000     |
| training/Q/q1_loss             | 88.6336    |
| training/sac_pi/alpha          | 0.17390262 |
| training/sac_pi/alpha_loss     | 0.37048608 |
| training/sac_pi/logp_pi        | 4.3179307  |
| training/sac_pi/pi_entropy     | 3.5954547  |
| training/sac_pi/pi_global_norm | 1.6286424  |
| training/sac_pi/policy_loss    | -210.78925 |
| training/sac_pi/std            | 0.5129418  |
| training/sac_pi/valid_num      | 5017.0     |
| training/sac_Q/q1              | 199.0283   |
| training/sac_Q/q2              | 200.39915  |
| training/sac_Q/q2_loss         | 88.92649   |
| training/sac_Q/q_global_norm   | 244.53285  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1648913  |
| epoch                          | 931        |
| evaluation/episode-length-avg  | 402        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 137        |
| evaluation/episode-length-std  | 392        |
| evaluation/return-average      | 1769.7418  |
| evaluation/return-max          | 4947.6206  |
| evaluation/return-min          | 390.63803  |
| evaluation/return-std          | 2064.0837  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45918      |
| perf/AverageLength             | 402        |
| perf/AverageReturn             | 1769.7418  |
| perf/NormalizedReturn          | 0.385      |
| Q-avg                          | 197.16698  |
| Q-std                          | 192.08122  |
| Q_loss                         | 93.55048   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 931        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000564   |
| times/evaluation_paths         | 13.2       |
| times/timestep_after_hook      | 0.00403    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 59.2       |
| timestep                       | 1000       |
| timesteps_total                | 932000     |
| train-steps                    | 932000     |
| training/Q/q1_loss             | 104.55767  |
| training/sac_pi/alpha          | 0.16490152 |
| training/sac_pi/alpha_loss     | 0.16488285 |
| training/sac_pi/logp_pi        | 3.9171364  |
| training/sac_pi/pi_entropy     | 3.4868073  |
| training/sac_pi/pi_global_norm | 1.8470424  |
| training/sac_pi/policy_loss    | -203.74153 |
| training/sac_pi/std            | 0.48710665 |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 194.38884  |
| training/sac_Q/q2              | 193.88681  |
| training/sac_Q/q2_loss         | 104.36109  |
| training/sac_Q/q_global_norm   | 196.78635  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16463956 |
| epoch                          | 932        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4702.1543  |
| evaluation/return-max          | 4776.4873  |
| evaluation/return-min          | 4526.0605  |
| evaluation/return-std          | 83.973114  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45900      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4702.1543  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 193.2655   |
| Q-std                          | 166.97491  |
| Q_loss                         | 81.99995   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 932        |
| times/epoch_after_hook         | 2.01e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000623   |
| times/evaluation_paths         | 32.9       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 60         |
| timestep                       | 1000       |
| timesteps_total                | 933000     |
| train-steps                    | 933000     |
| training/Q/q1_loss             | 110.13858  |
| training/sac_pi/alpha          | 0.16466483 |
| training/sac_pi/alpha_loss     | 0.3971171  |
| training/sac_pi/logp_pi        | 5.2298555  |
| training/sac_pi/pi_entropy     | 3.577374   |
| training/sac_pi/pi_global_norm | 1.8838636  |
| training/sac_pi/policy_loss    | -201.37799 |
| training/sac_pi/std            | 0.5472691  |
| training/sac_pi/valid_num      | 4934.0     |
| training/sac_Q/q1              | 183.3088   |
| training/sac_Q/q2              | 183.05461  |
| training/sac_Q/q2_loss         | 108.71139  |
| training/sac_Q/q_global_norm   | 181.9822   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16626573 |
| epoch                          | 933        |
| evaluation/episode-length-avg  | 914        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 137        |
| evaluation/episode-length-std  | 259        |
| evaluation/return-average      | 4386.976   |
| evaluation/return-max          | 4919.583   |
| evaluation/return-min          | 328.38828  |
| evaluation/return-std          | 1354.1188  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46057      |
| perf/AverageLength             | 914        |
| perf/AverageReturn             | 4386.976   |
| perf/NormalizedReturn          | 0.955      |
| Q-avg                          | 201.81422  |
| Q-std                          | 129.10078  |
| Q_loss                         | 73.00645   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 933        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000299   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000533   |
| times/evaluation_paths         | 30.4       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 934000     |
| train-steps                    | 934000     |
| training/Q/q1_loss             | 99.60182   |
| training/sac_pi/alpha          | 0.1662544  |
| training/sac_pi/alpha_loss     | 0.26401997 |
| training/sac_pi/logp_pi        | 4.82846    |
| training/sac_pi/pi_entropy     | 3.436706   |
| training/sac_pi/pi_global_norm | 1.684757   |
| training/sac_pi/policy_loss    | -204.30893 |
| training/sac_pi/std            | 0.5127943  |
| training/sac_pi/valid_num      | 4980.0     |
| training/sac_Q/q1              | 187.8902   |
| training/sac_Q/q2              | 189.15218  |
| training/sac_Q/q2_loss         | 100.18971  |
| training/sac_Q/q_global_norm   | 238.18033  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16353205  |
| epoch                          | 934         |
| evaluation/episode-length-avg  | 141         |
| evaluation/episode-length-max  | 143         |
| evaluation/episode-length-min  | 140         |
| evaluation/episode-length-std  | 0.9         |
| evaluation/return-average      | 414.83994   |
| evaluation/return-max          | 422.98804   |
| evaluation/return-min          | 405.26703   |
| evaluation/return-std          | 5.78259     |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45818       |
| perf/AverageLength             | 141         |
| perf/AverageReturn             | 414.83994   |
| perf/NormalizedReturn          | 0.09        |
| Q-avg                          | 201.60088   |
| Q-std                          | 154.29369   |
| Q_loss                         | 84.20959    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 934         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000481    |
| times/evaluation_paths         | 4.74        |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00841     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 935000      |
| train-steps                    | 935000      |
| training/Q/q1_loss             | 72.97276    |
| training/sac_pi/alpha          | 0.16356634  |
| training/sac_pi/alpha_loss     | -0.29974893 |
| training/sac_pi/logp_pi        | 3.6326728   |
| training/sac_pi/pi_entropy     | 3.417179    |
| training/sac_pi/pi_global_norm | 1.6236967   |
| training/sac_pi/policy_loss    | -214.21663  |
| training/sac_pi/std            | 0.47963697  |
| training/sac_pi/valid_num      | 5027.0      |
| training/sac_Q/q1              | 204.8372    |
| training/sac_Q/q2              | 205.89511   |
| training/sac_Q/q2_loss         | 72.638306   |
| training/sac_Q/q_global_norm   | 216.21846   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1629577   |
| epoch                          | 935         |
| evaluation/episode-length-avg  | 659         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 141         |
| evaluation/episode-length-std  | 417         |
| evaluation/return-average      | 3115.5151   |
| evaluation/return-max          | 4965.601    |
| evaluation/return-min          | 401.91306   |
| evaluation/return-std          | 2196.0803   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46238       |
| perf/AverageLength             | 659         |
| perf/AverageReturn             | 3115.5151   |
| perf/NormalizedReturn          | 0.678       |
| Q-avg                          | 180.43628   |
| Q-std                          | 203.3101    |
| Q_loss                         | 114.673164  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 935         |
| times/epoch_after_hook         | 3.68e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000537    |
| times/evaluation_paths         | 21.7        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 936000      |
| train-steps                    | 936000      |
| training/Q/q1_loss             | 104.08761   |
| training/sac_pi/alpha          | 0.16294816  |
| training/sac_pi/alpha_loss     | -0.15191957 |
| training/sac_pi/logp_pi        | 3.9302902   |
| training/sac_pi/pi_entropy     | 3.4265304   |
| training/sac_pi/pi_global_norm | 1.6666453   |
| training/sac_pi/policy_loss    | -212.81317  |
| training/sac_pi/std            | 0.491804    |
| training/sac_pi/valid_num      | 4988.0      |
| training/sac_Q/q1              | 200.03557   |
| training/sac_Q/q2              | 201.55112   |
| training/sac_Q/q2_loss         | 102.233734  |
| training/sac_Q/q_global_norm   | 206.40889   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1655852   |
| epoch                          | 936         |
| evaluation/episode-length-avg  | 315         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 142         |
| evaluation/episode-length-std  | 342         |
| evaluation/return-average      | 1337.3923   |
| evaluation/return-max          | 4878.491    |
| evaluation/return-min          | 451.8493    |
| evaluation/return-std          | 1747.8724   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46120       |
| perf/AverageLength             | 315         |
| perf/AverageReturn             | 1337.3923   |
| perf/NormalizedReturn          | 0.291       |
| Q-avg                          | 192.55392   |
| Q-std                          | 167.9872    |
| Q_loss                         | 99.618866   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 936         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000113    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000634    |
| times/evaluation_paths         | 10.5        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.00841     |
| times/train                    | 60.5        |
| timestep                       | 1000        |
| timesteps_total                | 937000      |
| train-steps                    | 937000      |
| training/Q/q1_loss             | 92.961525   |
| training/sac_pi/alpha          | 0.16558778  |
| training/sac_pi/alpha_loss     | -0.22898132 |
| training/sac_pi/logp_pi        | 4.973886    |
| training/sac_pi/pi_entropy     | 3.6483216   |
| training/sac_pi/pi_global_norm | 1.9467808   |
| training/sac_pi/policy_loss    | -208.0433   |
| training/sac_pi/std            | 0.56469077  |
| training/sac_pi/valid_num      | 4863.0      |
| training/sac_Q/q1              | 184.12732   |
| training/sac_Q/q2              | 186.0779    |
| training/sac_Q/q2_loss         | 92.99535    |
| training/sac_Q/q_global_norm   | 231.7944    |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1610623    |
| epoch                          | 937          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4946.3057    |
| evaluation/return-max          | 5016.6597    |
| evaluation/return-min          | 4612.226     |
| evaluation/return-std          | 114.23851    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3            |
| model/origin_ret               | 84.1         |
| model/penalty_ret              | 80.5         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45991        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4946.3057    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 198.74718    |
| Q-std                          | 183.13582    |
| Q_loss                         | 114.075935   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 937          |
| times/epoch_after_hook         | 2.43e-05     |
| times/epoch_before_hook        | 0.00032      |
| times/epoch_rollout_model      | 480          |
| times/evaluation_metrics       | 0.00055      |
| times/evaluation_paths         | 31.3         |
| times/timestep_after_hook      | 0.00389      |
| times/timestep_before_hook     | 0.00801      |
| times/train                    | 57.9         |
| timestep                       | 1000         |
| timesteps_total                | 938000       |
| train-steps                    | 938000       |
| training/Q/q1_loss             | 98.585884    |
| training/sac_pi/alpha          | 0.1610576    |
| training/sac_pi/alpha_loss     | -0.033299062 |
| training/sac_pi/logp_pi        | 4.546582     |
| training/sac_pi/pi_entropy     | 3.6322474    |
| training/sac_pi/pi_global_norm | 2.1120605    |
| training/sac_pi/policy_loss    | -208.79008   |
| training/sac_pi/std            | 0.551135     |
| training/sac_pi/valid_num      | 4936.0       |
| training/sac_Q/q1              | 184.88896    |
| training/sac_Q/q2              | 183.19304    |
| training/sac_Q/q2_loss         | 98.03097     |
| training/sac_Q/q_global_norm   | 181.14398    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16154368 |
| epoch                          | 938        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5027.8174  |
| evaluation/return-max          | 5123.669   |
| evaluation/return-min          | 4952.817   |
| evaluation/return-std          | 48.024994  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45954      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5027.8174  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 202.67456  |
| Q-std                          | 138.00067  |
| Q_loss                         | 100.95802  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 938        |
| times/epoch_after_hook         | 2.04e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.00136    |
| times/evaluation_paths         | 34         |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 61.5       |
| timestep                       | 1000       |
| timesteps_total                | 939000     |
| train-steps                    | 939000     |
| training/Q/q1_loss             | 88.042145  |
| training/sac_pi/alpha          | 0.16153325 |
| training/sac_pi/alpha_loss     | -0.1816927 |
| training/sac_pi/logp_pi        | 3.7116501  |
| training/sac_pi/pi_entropy     | 3.1797135  |
| training/sac_pi/pi_global_norm | 1.6819365  |
| training/sac_pi/policy_loss    | -221.52902 |
| training/sac_pi/std            | 0.45347893 |
| training/sac_pi/valid_num      | 5019.0     |
| training/sac_Q/q1              | 214.35123  |
| training/sac_Q/q2              | 214.84834  |
| training/sac_Q/q2_loss         | 87.63832   |
| training/sac_Q/q_global_norm   | 241.6053   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16507098 |
| epoch                          | 939        |
| evaluation/episode-length-avg  | 412        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 154        |
| evaluation/episode-length-std  | 385        |
| evaluation/return-average      | 1812.3422  |
| evaluation/return-max          | 4933.548   |
| evaluation/return-min          | 463.69705  |
| evaluation/return-std          | 2018.3195  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45961      |
| perf/AverageLength             | 412        |
| perf/AverageReturn             | 1812.3422  |
| perf/NormalizedReturn          | 0.394      |
| Q-avg                          | 195.65959  |
| Q-std                          | 175.60504  |
| Q_loss                         | 104.2365   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 939        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000112   |
| times/epoch_rollout_model      | 510        |
| times/evaluation_metrics       | 0.000551   |
| times/evaluation_paths         | 14.2       |
| times/timestep_after_hook      | 0.00412    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 64.8       |
| timestep                       | 1000       |
| timesteps_total                | 940000     |
| train-steps                    | 940000     |
| training/Q/q1_loss             | 109.01905  |
| training/sac_pi/alpha          | 0.16506326 |
| training/sac_pi/alpha_loss     | 0.20875077 |
| training/sac_pi/logp_pi        | 4.9026175  |
| training/sac_pi/pi_entropy     | 3.3448822  |
| training/sac_pi/pi_global_norm | 1.5060834  |
| training/sac_pi/policy_loss    | -206.60268 |
| training/sac_pi/std            | 0.50037086 |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 189.9183   |
| training/sac_Q/q2              | 191.28842  |
| training/sac_Q/q2_loss         | 108.98895  |
| training/sac_Q/q_global_norm   | 181.04677  |
--------------------------------------------------------------------------------
[WARN] 940 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.15982912 |
| epoch                          | 940        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4964.298   |
| evaluation/return-max          | 4997.981   |
| evaluation/return-min          | 4933.76    |
| evaluation/return-std          | 17.58321   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45878      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4964.298   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 187.04347  |
| Q-std                          | 189.39482  |
| Q_loss                         | 124.654335 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 940        |
| times/epoch_after_hook         | 2.03e-06   |
| times/epoch_before_hook        | 0.000145   |
| times/epoch_rollout_model      | 512        |
| times/evaluation_metrics       | 0.000663   |
| times/evaluation_paths         | 33.7       |
| times/timestep_after_hook      | 0.00462    |
| times/timestep_before_hook     | 0.00895    |
| times/train                    | 64.5       |
| timestep                       | 1000       |
| timesteps_total                | 941000     |
| train-steps                    | 941000     |
| training/Q/q1_loss             | 114.02476  |
| training/sac_pi/alpha          | 0.15979816 |
| training/sac_pi/alpha_loss     | 0.28396618 |
| training/sac_pi/logp_pi        | 4.0978823  |
| training/sac_pi/pi_entropy     | 3.2994683  |
| training/sac_pi/pi_global_norm | 1.6110386  |
| training/sac_pi/policy_loss    | -212.4029  |
| training/sac_pi/std            | 0.47332472 |
| training/sac_pi/valid_num      | 4971.0     |
| training/sac_Q/q1              | 196.32979  |
| training/sac_Q/q2              | 201.70212  |
| training/sac_Q/q2_loss         | 114.15544  |
| training/sac_Q/q_global_norm   | 283.62628  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.163081    |
| epoch                          | 941         |
| evaluation/episode-length-avg  | 925         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 250         |
| evaluation/episode-length-std  | 225         |
| evaluation/return-average      | 4358.814    |
| evaluation/return-max          | 4829.248    |
| evaluation/return-min          | 964.8087    |
| evaluation/return-std          | 1132.0087   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45830       |
| perf/AverageLength             | 925         |
| perf/AverageReturn             | 4358.814    |
| perf/NormalizedReturn          | 0.949       |
| Q-avg                          | 198.15317   |
| Q-std                          | 160.93945   |
| Q_loss                         | 87.26997    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 941         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000411    |
| times/epoch_rollout_model      | 535         |
| times/evaluation_metrics       | 0.00051     |
| times/evaluation_paths         | 31.2        |
| times/timestep_after_hook      | 0.0044      |
| times/timestep_before_hook     | 0.00894     |
| times/train                    | 63.9        |
| timestep                       | 1000        |
| timesteps_total                | 942000      |
| train-steps                    | 942000      |
| training/Q/q1_loss             | 106.614204  |
| training/sac_pi/alpha          | 0.16308825  |
| training/sac_pi/alpha_loss     | -0.14242488 |
| training/sac_pi/logp_pi        | 4.4377966   |
| training/sac_pi/pi_entropy     | 3.534697    |
| training/sac_pi/pi_global_norm | 1.5727097   |
| training/sac_pi/policy_loss    | -203.94368  |
| training/sac_pi/std            | 0.5210425   |
| training/sac_pi/valid_num      | 4984.0      |
| training/sac_Q/q1              | 190.04765   |
| training/sac_Q/q2              | 191.5326    |
| training/sac_Q/q2_loss         | 107.066025  |
| training/sac_Q/q_global_norm   | 229.3062    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16582519 |
| epoch                          | 942        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4917.636   |
| evaluation/return-max          | 4946.893   |
| evaluation/return-min          | 4851.011   |
| evaluation/return-std          | 26.879972  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46026      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4917.636   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 195.05655  |
| Q-std                          | 182.70378  |
| Q_loss                         | 87.720856  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 942        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 540        |
| times/evaluation_metrics       | 0.000842   |
| times/evaluation_paths         | 34         |
| times/timestep_after_hook      | 0.00421    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 62.8       |
| timestep                       | 1000       |
| timesteps_total                | 943000     |
| train-steps                    | 943000     |
| training/Q/q1_loss             | 88.03164   |
| training/sac_pi/alpha          | 0.16579627 |
| training/sac_pi/alpha_loss     | 0.04495771 |
| training/sac_pi/logp_pi        | 4.3660574  |
| training/sac_pi/pi_entropy     | 3.595456   |
| training/sac_pi/pi_global_norm | 1.6859812  |
| training/sac_pi/policy_loss    | -203.9786  |
| training/sac_pi/std            | 0.5228062  |
| training/sac_pi/valid_num      | 4929.0     |
| training/sac_Q/q1              | 187.68268  |
| training/sac_Q/q2              | 187.69763  |
| training/sac_Q/q2_loss         | 87.761116  |
| training/sac_Q/q_global_norm   | 178.37993  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16585635 |
| epoch                          | 943        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4994.9805  |
| evaluation/return-max          | 5020.542   |
| evaluation/return-min          | 4972.8335  |
| evaluation/return-std          | 14.750626  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45998      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4994.9805  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 203.61655  |
| Q-std                          | 177.88623  |
| Q_loss                         | 101.118576 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 943        |
| times/epoch_after_hook         | 2.14e-06   |
| times/epoch_before_hook        | 0.000365   |
| times/epoch_rollout_model      | 536        |
| times/evaluation_metrics       | 0.000658   |
| times/evaluation_paths         | 33.5       |
| times/timestep_after_hook      | 0.00436    |
| times/timestep_before_hook     | 0.00884    |
| times/train                    | 63.2       |
| timestep                       | 1000       |
| timesteps_total                | 944000     |
| train-steps                    | 944000     |
| training/Q/q1_loss             | 88.45471   |
| training/sac_pi/alpha          | 0.16588981 |
| training/sac_pi/alpha_loss     | -0.321336  |
| training/sac_pi/logp_pi        | 3.9403024  |
| training/sac_pi/pi_entropy     | 3.7416358  |
| training/sac_pi/pi_global_norm | 1.5769677  |
| training/sac_pi/policy_loss    | -210.85294 |
| training/sac_pi/std            | 0.53132826 |
| training/sac_pi/valid_num      | 4929.0     |
| training/sac_Q/q1              | 195.13977  |
| training/sac_Q/q2              | 196.3813   |
| training/sac_Q/q2_loss         | 87.97318   |
| training/sac_Q/q_global_norm   | 180.50478  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16664718   |
| epoch                          | 944          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5128.618     |
| evaluation/return-max          | 5196.9707    |
| evaluation/return-min          | 5080.9404    |
| evaluation/return-std          | 33.643196    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3            |
| model/origin_ret               | 85.2         |
| model/penalty_ret              | 80.9         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45945        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5128.618     |
| perf/NormalizedReturn          | 1.12         |
| Q-avg                          | 197.29375    |
| Q-std                          | 160.46632    |
| Q_loss                         | 65.65976     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 944          |
| times/epoch_after_hook         | 1.75e-06     |
| times/epoch_before_hook        | 0.000137     |
| times/epoch_rollout_model      | 511          |
| times/evaluation_metrics       | 0.000562     |
| times/evaluation_paths         | 31.1         |
| times/timestep_after_hook      | 0.00393      |
| times/timestep_before_hook     | 0.00819      |
| times/train                    | 58.9         |
| timestep                       | 1000         |
| timesteps_total                | 945000       |
| train-steps                    | 945000       |
| training/Q/q1_loss             | 75.479744    |
| training/sac_pi/alpha          | 0.16665931   |
| training/sac_pi/alpha_loss     | -0.034411248 |
| training/sac_pi/logp_pi        | 3.9555085    |
| training/sac_pi/pi_entropy     | 3.4276547    |
| training/sac_pi/pi_global_norm | 1.6841063    |
| training/sac_pi/policy_loss    | -210.27722   |
| training/sac_pi/std            | 0.49591175   |
| training/sac_pi/valid_num      | 4976.0       |
| training/sac_Q/q1              | 197.83484    |
| training/sac_Q/q2              | 197.50241    |
| training/sac_Q/q2_loss         | 76.344475    |
| training/sac_Q/q_global_norm   | 234.63159    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16201816   |
| epoch                          | 945          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4826.935     |
| evaluation/return-max          | 4943.773     |
| evaluation/return-min          | 4651.9756    |
| evaluation/return-std          | 108.88373    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.02         |
| model/origin_ret               | 85.3         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 46014        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4826.935     |
| perf/NormalizedReturn          | 1.05         |
| Q-avg                          | 187.50041    |
| Q-std                          | 182.07149    |
| Q_loss                         | 112.62609    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 945          |
| times/epoch_after_hook         | 2.15e-06     |
| times/epoch_before_hook        | 0.000325     |
| times/epoch_rollout_model      | 476          |
| times/evaluation_metrics       | 0.00052      |
| times/evaluation_paths         | 30.8         |
| times/timestep_after_hook      | 0.00398      |
| times/timestep_before_hook     | 0.00809      |
| times/train                    | 58.1         |
| timestep                       | 1000         |
| timesteps_total                | 946000       |
| train-steps                    | 946000       |
| training/Q/q1_loss             | 96.858055    |
| training/sac_pi/alpha          | 0.16203241   |
| training/sac_pi/alpha_loss     | -0.104117796 |
| training/sac_pi/logp_pi        | 4.669835     |
| training/sac_pi/pi_entropy     | 3.2604537    |
| training/sac_pi/pi_global_norm | 1.5106537    |
| training/sac_pi/policy_loss    | -206.37154   |
| training/sac_pi/std            | 0.50858957   |
| training/sac_pi/valid_num      | 4876.0       |
| training/sac_Q/q1              | 186.5954     |
| training/sac_Q/q2              | 187.45596    |
| training/sac_Q/q2_loss         | 97.81625     |
| training/sac_Q/q_global_norm   | 156.57375    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16559026  |
| epoch                          | 946         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5079.5156   |
| evaluation/return-max          | 5092.253    |
| evaluation/return-min          | 5047.878    |
| evaluation/return-std          | 14.143099   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46093       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5079.5156   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 192.8127    |
| Q-std                          | 193.20091   |
| Q_loss                         | 110.0771    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 946         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000579    |
| times/evaluation_paths         | 31.9        |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 58.2        |
| timestep                       | 1000        |
| timesteps_total                | 947000      |
| train-steps                    | 947000      |
| training/Q/q1_loss             | 101.22817   |
| training/sac_pi/alpha          | 0.16562302  |
| training/sac_pi/alpha_loss     | -0.44999328 |
| training/sac_pi/logp_pi        | 4.1687818   |
| training/sac_pi/pi_entropy     | 3.5997589   |
| training/sac_pi/pi_global_norm | 1.4483407   |
| training/sac_pi/policy_loss    | -204.2027   |
| training/sac_pi/std            | 0.5264133   |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 186.71503   |
| training/sac_Q/q2              | 188.34282   |
| training/sac_Q/q2_loss         | 100.61348   |
| training/sac_Q/q_global_norm   | 176.34224   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1686149   |
| epoch                          | 947         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4726.2275   |
| evaluation/return-max          | 4791.229    |
| evaluation/return-min          | 4638.7544   |
| evaluation/return-std          | 40.683674   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45936       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4726.2275   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 196.48154   |
| Q-std                          | 156.39008   |
| Q_loss                         | 74.89046    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 947         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000619    |
| times/evaluation_paths         | 31.2        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 57.7        |
| timestep                       | 1000        |
| timesteps_total                | 948000      |
| train-steps                    | 948000      |
| training/Q/q1_loss             | 105.64302   |
| training/sac_pi/alpha          | 0.16861682  |
| training/sac_pi/alpha_loss     | 0.010546294 |
| training/sac_pi/logp_pi        | 3.6760802   |
| training/sac_pi/pi_entropy     | 3.4303615   |
| training/sac_pi/pi_global_norm | 1.8213565   |
| training/sac_pi/policy_loss    | -207.2083   |
| training/sac_pi/std            | 0.47650406  |
| training/sac_pi/valid_num      | 5021.0      |
| training/sac_Q/q1              | 199.32446   |
| training/sac_Q/q2              | 198.21883   |
| training/sac_Q/q2_loss         | 106.54444   |
| training/sac_Q/q_global_norm   | 245.88977   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16873349 |
| epoch                          | 948        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5069.419   |
| evaluation/return-max          | 5091.3174  |
| evaluation/return-min          | 5049.3657  |
| evaluation/return-std          | 14.135647  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 83.5       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46041      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5069.419   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 195.91136  |
| Q-std                          | 164.66995  |
| Q_loss                         | 108.72776  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 948        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000558   |
| times/evaluation_paths         | 31.2       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 58.6       |
| timestep                       | 1000       |
| timesteps_total                | 949000     |
| train-steps                    | 949000     |
| training/Q/q1_loss             | 99.47047   |
| training/sac_pi/alpha          | 0.16869923 |
| training/sac_pi/alpha_loss     | 0.1603769  |
| training/sac_pi/logp_pi        | 4.933473   |
| training/sac_pi/pi_entropy     | 3.6581407  |
| training/sac_pi/pi_global_norm | 1.7083081  |
| training/sac_pi/policy_loss    | -210.05435 |
| training/sac_pi/std            | 0.55206776 |
| training/sac_pi/valid_num      | 4940.0     |
| training/sac_Q/q1              | 192.25533  |
| training/sac_Q/q2              | 192.50182  |
| training/sac_Q/q2_loss         | 99.51335   |
| training/sac_Q/q_global_norm   | 218.31885  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16881053 |
| epoch                          | 949        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4961.996   |
| evaluation/return-max          | 4983.802   |
| evaluation/return-min          | 4904.4316  |
| evaluation/return-std          | 21.974274  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45866      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4961.996   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 192.01682  |
| Q-std                          | 215.33168  |
| Q_loss                         | 82.821724  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 949        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000278   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000516   |
| times/evaluation_paths         | 30.4       |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 57.6       |
| timestep                       | 1000       |
| timesteps_total                | 950000     |
| train-steps                    | 950000     |
| training/Q/q1_loss             | 84.52842   |
| training/sac_pi/alpha          | 0.16879469 |
| training/sac_pi/alpha_loss     | 0.26093268 |
| training/sac_pi/logp_pi        | 4.398462   |
| training/sac_pi/pi_entropy     | 3.2977493  |
| training/sac_pi/pi_global_norm | 1.567192   |
| training/sac_pi/policy_loss    | -217.87294 |
| training/sac_pi/std            | 0.47251734 |
| training/sac_pi/valid_num      | 4979.0     |
| training/sac_Q/q1              | 205.4078   |
| training/sac_Q/q2              | 204.32834  |
| training/sac_Q/q2_loss         | 84.55307   |
| training/sac_Q/q_global_norm   | 174.46347  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17174904 |
| epoch                          | 950        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4969.5977  |
| evaluation/return-max          | 5082.4116  |
| evaluation/return-min          | 4922.7812  |
| evaluation/return-std          | 46.93642   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46014      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4969.5977  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 204.49821  |
| Q-std                          | 125.8573   |
| Q_loss                         | 93.50278   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 950        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 31.3       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 57.6       |
| timestep                       | 1000       |
| timesteps_total                | 951000     |
| train-steps                    | 951000     |
| training/Q/q1_loss             | 99.60486   |
| training/sac_pi/alpha          | 0.17178063 |
| training/sac_pi/alpha_loss     | -0.2625164 |
| training/sac_pi/logp_pi        | 3.9214084  |
| training/sac_pi/pi_entropy     | 3.3981996  |
| training/sac_pi/pi_global_norm | 2.396403   |
| training/sac_pi/policy_loss    | -209.69966 |
| training/sac_pi/std            | 0.48270166 |
| training/sac_pi/valid_num      | 4993.0     |
| training/sac_Q/q1              | 201.06471  |
| training/sac_Q/q2              | 202.03174  |
| training/sac_Q/q2_loss         | 100.27437  |
| training/sac_Q/q_global_norm   | 174.98163  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17291535 |
| epoch                          | 951        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4998.2173  |
| evaluation/return-max          | 5101.631   |
| evaluation/return-min          | 4936.2236  |
| evaluation/return-std          | 45.78542   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45838      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4998.2173  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 197.87715  |
| Q-std                          | 159.41975  |
| Q_loss                         | 80.15058   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 951        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000711   |
| times/evaluation_paths         | 31.8       |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 58.3       |
| timestep                       | 1000       |
| timesteps_total                | 952000     |
| train-steps                    | 952000     |
| training/Q/q1_loss             | 100.972916 |
| training/sac_pi/alpha          | 0.17292215 |
| training/sac_pi/alpha_loss     | 0.22381358 |
| training/sac_pi/logp_pi        | 4.4637246  |
| training/sac_pi/pi_entropy     | 3.5478873  |
| training/sac_pi/pi_global_norm | 1.5618507  |
| training/sac_pi/policy_loss    | -209.24887 |
| training/sac_pi/std            | 0.52180505 |
| training/sac_pi/valid_num      | 4920.0     |
| training/sac_Q/q1              | 196.74094  |
| training/sac_Q/q2              | 197.41377  |
| training/sac_Q/q2_loss         | 101.57792  |
| training/sac_Q/q_global_norm   | 228.07222  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17235923 |
| epoch                          | 952        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4849.5522  |
| evaluation/return-max          | 4996.1104  |
| evaluation/return-min          | 4631.6714  |
| evaluation/return-std          | 101.693184 |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45811      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4849.5522  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 204.27335  |
| Q-std                          | 108.72709  |
| Q_loss                         | 83.96048   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 952        |
| times/epoch_after_hook         | 1.99e-06   |
| times/epoch_before_hook        | 0.000174   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000562   |
| times/evaluation_paths         | 31.1       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 58.1       |
| timestep                       | 1000       |
| timesteps_total                | 953000     |
| train-steps                    | 953000     |
| training/Q/q1_loss             | 99.83415   |
| training/sac_pi/alpha          | 0.17233494 |
| training/sac_pi/alpha_loss     | 0.14206538 |
| training/sac_pi/logp_pi        | 4.3438387  |
| training/sac_pi/pi_entropy     | 3.3519032  |
| training/sac_pi/pi_global_norm | 1.8537488  |
| training/sac_pi/policy_loss    | -205.1589  |
| training/sac_pi/std            | 0.4915189  |
| training/sac_pi/valid_num      | 5009.0     |
| training/sac_Q/q1              | 195.32275  |
| training/sac_Q/q2              | 194.8735   |
| training/sac_Q/q2_loss         | 100.527725 |
| training/sac_Q/q_global_norm   | 305.95367  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17241816  |
| epoch                          | 953         |
| evaluation/episode-length-avg  | 925         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 247         |
| evaluation/episode-length-std  | 226         |
| evaluation/return-average      | 4409.8105   |
| evaluation/return-max          | 5016.4336   |
| evaluation/return-min          | 980.9409    |
| evaluation/return-std          | 1157.8352   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45971       |
| perf/AverageLength             | 925         |
| perf/AverageReturn             | 4409.8105   |
| perf/NormalizedReturn          | 0.96        |
| Q-avg                          | 187.62076   |
| Q-std                          | 173.61737   |
| Q_loss                         | 85.673454   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 953         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000281    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000566    |
| times/evaluation_paths         | 28.5        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 57.3        |
| timestep                       | 1000        |
| timesteps_total                | 954000      |
| train-steps                    | 954000      |
| training/Q/q1_loss             | 86.0305     |
| training/sac_pi/alpha          | 0.17240828  |
| training/sac_pi/alpha_loss     | 0.106678635 |
| training/sac_pi/logp_pi        | 4.3883414   |
| training/sac_pi/pi_entropy     | 3.3747878   |
| training/sac_pi/pi_global_norm | 1.8776687   |
| training/sac_pi/policy_loss    | -219.45143  |
| training/sac_pi/std            | 0.48839322  |
| training/sac_pi/valid_num      | 5011.0      |
| training/sac_Q/q1              | 206.95053   |
| training/sac_Q/q2              | 209.20903   |
| training/sac_Q/q2_loss         | 86.07688    |
| training/sac_Q/q_global_norm   | 211.43854   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17110242   |
| epoch                          | 954          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4936.8896    |
| evaluation/return-max          | 4952.831     |
| evaluation/return-min          | 4896.158     |
| evaluation/return-std          | 16.019073    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.96         |
| model/origin_ret               | 84.4         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 46034        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4936.8896    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 191.29654    |
| Q-std                          | 156.25433    |
| Q_loss                         | 110.741646   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 954          |
| times/epoch_after_hook         | 1.88e-06     |
| times/epoch_before_hook        | 0.000142     |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.000531     |
| times/evaluation_paths         | 31.2         |
| times/timestep_after_hook      | 0.00411      |
| times/timestep_before_hook     | 0.0084       |
| times/train                    | 57.4         |
| timestep                       | 1000         |
| timesteps_total                | 955000       |
| train-steps                    | 955000       |
| training/Q/q1_loss             | 104.03831    |
| training/sac_pi/alpha          | 0.17108959   |
| training/sac_pi/alpha_loss     | -0.092627525 |
| training/sac_pi/logp_pi        | 4.6351376    |
| training/sac_pi/pi_entropy     | 3.427405     |
| training/sac_pi/pi_global_norm | 1.766243     |
| training/sac_pi/policy_loss    | -206.29532   |
| training/sac_pi/std            | 0.5044554    |
| training/sac_pi/valid_num      | 4977.0       |
| training/sac_Q/q1              | 190.49397    |
| training/sac_Q/q2              | 189.86166    |
| training/sac_Q/q2_loss         | 104.453804   |
| training/sac_Q/q_global_norm   | 203.65123    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16536084 |
| epoch                          | 955        |
| evaluation/episode-length-avg  | 942        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 419        |
| evaluation/episode-length-std  | 174        |
| evaluation/return-average      | 4497.7695  |
| evaluation/return-max          | 4900.3394  |
| evaluation/return-min          | 1754.3093  |
| evaluation/return-std          | 916.02246  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45964      |
| perf/AverageLength             | 942        |
| perf/AverageReturn             | 4497.7695  |
| perf/NormalizedReturn          | 0.979      |
| Q-avg                          | 198.09615  |
| Q-std                          | 150.56831  |
| Q_loss                         | 92.324196  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 955        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000114   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000546   |
| times/evaluation_paths         | 29         |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 57.3       |
| timestep                       | 1000       |
| timesteps_total                | 956000     |
| train-steps                    | 956000     |
| training/Q/q1_loss             | 106.095116 |
| training/sac_pi/alpha          | 0.1653995  |
| training/sac_pi/alpha_loss     | 0.0733923  |
| training/sac_pi/logp_pi        | 4.9631844  |
| training/sac_pi/pi_entropy     | 3.4241097  |
| training/sac_pi/pi_global_norm | 1.8928609  |
| training/sac_pi/policy_loss    | -209.53577 |
| training/sac_pi/std            | 0.52733225 |
| training/sac_pi/valid_num      | 4942.0     |
| training/sac_Q/q1              | 192.02524  |
| training/sac_Q/q2              | 189.85352  |
| training/sac_Q/q2_loss         | 105.43609  |
| training/sac_Q/q_global_norm   | 253.93315  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16694175  |
| epoch                          | 956         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4966.427    |
| evaluation/return-max          | 5015.0806   |
| evaluation/return-min          | 4934.3276   |
| evaluation/return-std          | 25.095457   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45910       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4966.427    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 198.1315    |
| Q-std                          | 175.42508   |
| Q_loss                         | 100.48311   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 956         |
| times/epoch_after_hook         | 2e-06       |
| times/epoch_before_hook        | 0.000138    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000542    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.0084      |
| times/train                    | 57.6        |
| timestep                       | 1000        |
| timesteps_total                | 957000      |
| train-steps                    | 957000      |
| training/Q/q1_loss             | 75.65168    |
| training/sac_pi/alpha          | 0.16692898  |
| training/sac_pi/alpha_loss     | -0.25691462 |
| training/sac_pi/logp_pi        | 4.2016716   |
| training/sac_pi/pi_entropy     | 3.4058144   |
| training/sac_pi/pi_global_norm | 1.7739381   |
| training/sac_pi/policy_loss    | -213.58673  |
| training/sac_pi/std            | 0.5121805   |
| training/sac_pi/valid_num      | 4975.0      |
| training/sac_Q/q1              | 201.36554   |
| training/sac_Q/q2              | 199.23672   |
| training/sac_Q/q2_loss         | 76.47497    |
| training/sac_Q/q_global_norm   | 169.943     |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16938442 |
| epoch                          | 957        |
| evaluation/episode-length-avg  | 136        |
| evaluation/episode-length-max  | 138        |
| evaluation/episode-length-min  | 134        |
| evaluation/episode-length-std  | 1.19       |
| evaluation/return-average      | 369.13443  |
| evaluation/return-max          | 380.2992   |
| evaluation/return-min          | 360.68378  |
| evaluation/return-std          | 5.4112577  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46026      |
| perf/AverageLength             | 136        |
| perf/AverageReturn             | 369.13443  |
| perf/NormalizedReturn          | 0.0801     |
| Q-avg                          | 198.6124   |
| Q-std                          | 199.154    |
| Q_loss                         | 81.525406  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 957        |
| times/epoch_after_hook         | 2.01e-06   |
| times/epoch_before_hook        | 0.00028    |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000438   |
| times/evaluation_paths         | 4.25       |
| times/timestep_after_hook      | 0.00403    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 57.3       |
| timestep                       | 1000       |
| timesteps_total                | 958000     |
| train-steps                    | 958000     |
| training/Q/q1_loss             | 95.7677    |
| training/sac_pi/alpha          | 0.16937423 |
| training/sac_pi/alpha_loss     | 0.14702395 |
| training/sac_pi/logp_pi        | 4.689364   |
| training/sac_pi/pi_entropy     | 3.4870727  |
| training/sac_pi/pi_global_norm | 1.6244313  |
| training/sac_pi/policy_loss    | -210.2124  |
| training/sac_pi/std            | 0.51659787 |
| training/sac_pi/valid_num      | 4944.0     |
| training/sac_Q/q1              | 193.46996  |
| training/sac_Q/q2              | 193.85239  |
| training/sac_Q/q2_loss         | 95.51163   |
| training/sac_Q/q_global_norm   | 219.04047  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16705987  |
| epoch                          | 958         |
| evaluation/episode-length-avg  | 915         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 152         |
| evaluation/episode-length-std  | 254         |
| evaluation/return-average      | 4485.0557   |
| evaluation/return-max          | 5030.1475   |
| evaluation/return-min          | 486.27118   |
| evaluation/return-std          | 1334.5751   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45970       |
| perf/AverageLength             | 915         |
| perf/AverageReturn             | 4485.0557   |
| perf/NormalizedReturn          | 0.977       |
| Q-avg                          | 187.44875   |
| Q-std                          | 218.13448   |
| Q_loss                         | 84.70739    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 958         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 8.26e-05    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000581    |
| times/evaluation_paths         | 28.2        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.00827     |
| times/train                    | 57.2        |
| timestep                       | 1000        |
| timesteps_total                | 959000      |
| train-steps                    | 959000      |
| training/Q/q1_loss             | 90.6754     |
| training/sac_pi/alpha          | 0.16706978  |
| training/sac_pi/alpha_loss     | -0.16421016 |
| training/sac_pi/logp_pi        | 4.2947817   |
| training/sac_pi/pi_entropy     | 3.4759247   |
| training/sac_pi/pi_global_norm | 1.6292632   |
| training/sac_pi/policy_loss    | -209.20009  |
| training/sac_pi/std            | 0.50760967  |
| training/sac_pi/valid_num      | 4983.0      |
| training/sac_Q/q1              | 194.81009   |
| training/sac_Q/q2              | 195.10907   |
| training/sac_Q/q2_loss         | 91.58647    |
| training/sac_Q/q_global_norm   | 177.48091   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17325161  |
| epoch                          | 959         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4804.9404   |
| evaluation/return-max          | 4864.078    |
| evaluation/return-min          | 4774.704    |
| evaluation/return-std          | 28.039333   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45870       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4804.9404   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 199.19685   |
| Q-std                          | 167.4646    |
| Q_loss                         | 87.52381    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 959         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000535    |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.00413     |
| times/timestep_before_hook     | 0.00847     |
| times/train                    | 57.7        |
| timestep                       | 1000        |
| timesteps_total                | 960000      |
| train-steps                    | 960000      |
| training/Q/q1_loss             | 93.16326    |
| training/sac_pi/alpha          | 0.1732116   |
| training/sac_pi/alpha_loss     | -0.08140178 |
| training/sac_pi/logp_pi        | 4.5506268   |
| training/sac_pi/pi_entropy     | 3.6406975   |
| training/sac_pi/pi_global_norm | 1.6783761   |
| training/sac_pi/policy_loss    | -205.28806  |
| training/sac_pi/std            | 0.5317975   |
| training/sac_pi/valid_num      | 4925.0      |
| training/sac_Q/q1              | 184.4697    |
| training/sac_Q/q2              | 185.2295    |
| training/sac_Q/q2_loss         | 92.49964    |
| training/sac_Q/q_global_norm   | 177.02406   |
---------------------------------------------------------------------------------
[WARN] 960 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.17066143  |
| epoch                          | 960         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5020.5205   |
| evaluation/return-max          | 5042.8135   |
| evaluation/return-min          | 4988.7334   |
| evaluation/return-std          | 17.486347   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45956       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5020.5205   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 191.00699   |
| Q-std                          | 183.14432   |
| Q_loss                         | 84.0588     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 960         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000589    |
| times/evaluation_paths         | 31.5        |
| times/timestep_after_hook      | 0.00408     |
| times/timestep_before_hook     | 0.0081      |
| times/train                    | 57.9        |
| timestep                       | 1000        |
| timesteps_total                | 961000      |
| train-steps                    | 961000      |
| training/Q/q1_loss             | 104.192085  |
| training/sac_pi/alpha          | 0.17065302  |
| training/sac_pi/alpha_loss     | -0.06625526 |
| training/sac_pi/logp_pi        | 3.984511    |
| training/sac_pi/pi_entropy     | 3.3985982   |
| training/sac_pi/pi_global_norm | 1.6132156   |
| training/sac_pi/policy_loss    | -209.01674  |
| training/sac_pi/std            | 0.49564356  |
| training/sac_pi/valid_num      | 4993.0      |
| training/sac_Q/q1              | 196.16931   |
| training/sac_Q/q2              | 195.73705   |
| training/sac_Q/q2_loss         | 103.123024  |
| training/sac_Q/q_global_norm   | 166.52231   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16095372 |
| epoch                          | 961        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5023.577   |
| evaluation/return-max          | 5158.8535  |
| evaluation/return-min          | 4924.082   |
| evaluation/return-std          | 84.64293   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46031      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5023.577   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 210.9207   |
| Q-std                          | 126.194046 |
| Q_loss                         | 93.08912   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 961        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000332   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000579   |
| times/evaluation_paths         | 31.1       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00798    |
| times/train                    | 57.7       |
| timestep                       | 1000       |
| timesteps_total                | 962000     |
| train-steps                    | 962000     |
| training/Q/q1_loss             | 101.47619  |
| training/sac_pi/alpha          | 0.16093864 |
| training/sac_pi/alpha_loss     | 0.06363944 |
| training/sac_pi/logp_pi        | 4.563775   |
| training/sac_pi/pi_entropy     | 3.3859649  |
| training/sac_pi/pi_global_norm | 1.6505995  |
| training/sac_pi/policy_loss    | -207.3767  |
| training/sac_pi/std            | 0.5096204  |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 196.769    |
| training/sac_Q/q2              | 197.06308  |
| training/sac_Q/q2_loss         | 101.66184  |
| training/sac_Q/q_global_norm   | 156.16295  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16687931  |
| epoch                          | 962         |
| evaluation/episode-length-avg  | 148         |
| evaluation/episode-length-max  | 149         |
| evaluation/episode-length-min  | 148         |
| evaluation/episode-length-std  | 0.458       |
| evaluation/return-average      | 461.67783   |
| evaluation/return-max          | 473.70193   |
| evaluation/return-min          | 454.37997   |
| evaluation/return-std          | 5.343887    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45823       |
| perf/AverageLength             | 148         |
| perf/AverageReturn             | 461.67783   |
| perf/NormalizedReturn          | 0.1         |
| Q-avg                          | 183.60612   |
| Q-std                          | 222.99718   |
| Q_loss                         | 84.97785    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 962         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000439    |
| times/evaluation_paths         | 4.83        |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 57.6        |
| timestep                       | 1000        |
| timesteps_total                | 963000      |
| train-steps                    | 963000      |
| training/Q/q1_loss             | 84.42502    |
| training/sac_pi/alpha          | 0.16688551  |
| training/sac_pi/alpha_loss     | -0.06199812 |
| training/sac_pi/logp_pi        | 4.444942    |
| training/sac_pi/pi_entropy     | 3.350293    |
| training/sac_pi/pi_global_norm | 1.8838834   |
| training/sac_pi/policy_loss    | -205.55157  |
| training/sac_pi/std            | 0.49825352  |
| training/sac_pi/valid_num      | 4967.0      |
| training/sac_Q/q1              | 191.11752   |
| training/sac_Q/q2              | 188.56589   |
| training/sac_Q/q2_loss         | 85.90914    |
| training/sac_Q/q_global_norm   | 179.66689   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16988704 |
| epoch                          | 963        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4918.1777  |
| evaluation/return-max          | 5000.6016  |
| evaluation/return-min          | 4776.802   |
| evaluation/return-std          | 63.589188  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45933      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4918.1777  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 205.46155  |
| Q-std                          | 129.87505  |
| Q_loss                         | 94.62597   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 963        |
| times/epoch_after_hook         | 2.11e-06   |
| times/epoch_before_hook        | 8.76e-05   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000539   |
| times/evaluation_paths         | 30.9       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 58         |
| timestep                       | 1000       |
| timesteps_total                | 964000     |
| train-steps                    | 964000     |
| training/Q/q1_loss             | 83.9503    |
| training/sac_pi/alpha          | 0.16983588 |
| training/sac_pi/alpha_loss     | 0.57845914 |
| training/sac_pi/logp_pi        | 4.3375716  |
| training/sac_pi/pi_entropy     | 3.5280585  |
| training/sac_pi/pi_global_norm | 1.3518512  |
| training/sac_pi/policy_loss    | -213.35419 |
| training/sac_pi/std            | 0.5066836  |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 200.49838  |
| training/sac_Q/q2              | 197.1367   |
| training/sac_Q/q2_loss         | 84.71145   |
| training/sac_Q/q_global_norm   | 186.59521  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16216259 |
| epoch                          | 964        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5151.015   |
| evaluation/return-max          | 5226.9253  |
| evaluation/return-min          | 5038.959   |
| evaluation/return-std          | 51.769993  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45977      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5151.015   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 195.0256   |
| Q-std                          | 133.25453  |
| Q_loss                         | 99.507385  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 964        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000532   |
| times/evaluation_paths         | 31.8       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 58.1       |
| timestep                       | 1000       |
| timesteps_total                | 965000     |
| train-steps                    | 965000     |
| training/Q/q1_loss             | 100.261284 |
| training/sac_pi/alpha          | 0.16216142 |
| training/sac_pi/alpha_loss     | 0.3398394  |
| training/sac_pi/logp_pi        | 4.8498473  |
| training/sac_pi/pi_entropy     | 3.420834   |
| training/sac_pi/pi_global_norm | 1.9389752  |
| training/sac_pi/policy_loss    | -208.9586  |
| training/sac_pi/std            | 0.50830805 |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 189.04979  |
| training/sac_Q/q2              | 190.44968  |
| training/sac_Q/q2_loss         | 101.12702  |
| training/sac_Q/q_global_norm   | 191.51176  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16905427 |
| epoch                          | 965        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5046.094   |
| evaluation/return-max          | 5141.706   |
| evaluation/return-min          | 4919.747   |
| evaluation/return-std          | 57.787804  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46074      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5046.094   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 200.5203   |
| Q-std                          | 170.28223  |
| Q_loss                         | 81.06174   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 965        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000296   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000603   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00797    |
| times/train                    | 56.4       |
| timestep                       | 1000       |
| timesteps_total                | 966000     |
| train-steps                    | 966000     |
| training/Q/q1_loss             | 104.74414  |
| training/sac_pi/alpha          | 0.16904798 |
| training/sac_pi/alpha_loss     | 0.34021422 |
| training/sac_pi/logp_pi        | 5.4771466  |
| training/sac_pi/pi_entropy     | 3.7863784  |
| training/sac_pi/pi_global_norm | 1.4177293  |
| training/sac_pi/policy_loss    | -209.14159 |
| training/sac_pi/std            | 0.5912921  |
| training/sac_pi/valid_num      | 4905.0     |
| training/sac_Q/q1              | 184.23886  |
| training/sac_Q/q2              | 184.49182  |
| training/sac_Q/q2_loss         | 105.08923  |
| training/sac_Q/q_global_norm   | 178.31839  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17058456 |
| epoch                          | 966        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4748.1553  |
| evaluation/return-max          | 4804.343   |
| evaluation/return-min          | 4674.215   |
| evaluation/return-std          | 45.085987  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45908      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4748.1553  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 185.84306  |
| Q-std                          | 231.79053  |
| Q_loss                         | 71.44506   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 966        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000114   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000545   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00804    |
| times/train                    | 57.4       |
| timestep                       | 1000       |
| timesteps_total                | 967000     |
| train-steps                    | 967000     |
| training/Q/q1_loss             | 89.67433   |
| training/sac_pi/alpha          | 0.1705788  |
| training/sac_pi/alpha_loss     | 0.13631554 |
| training/sac_pi/logp_pi        | 5.083174   |
| training/sac_pi/pi_entropy     | 3.3254426  |
| training/sac_pi/pi_global_norm | 1.6075369  |
| training/sac_pi/policy_loss    | -209.73563 |
| training/sac_pi/std            | 0.5184363  |
| training/sac_pi/valid_num      | 4894.0     |
| training/sac_Q/q1              | 184.8875   |
| training/sac_Q/q2              | 183.76682  |
| training/sac_Q/q2_loss         | 90.39194   |
| training/sac_Q/q_global_norm   | 168.519    |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16526821   |
| epoch                          | 967          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5010.8735    |
| evaluation/return-max          | 5079.8364    |
| evaluation/return-min          | 4942.032     |
| evaluation/return-std          | 45.52792     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.98         |
| model/origin_ret               | 84.5         |
| model/penalty_ret              | 80.4         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45887        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5010.8735    |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 203.77185    |
| Q-std                          | 164.63777    |
| Q_loss                         | 128.6264     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 967          |
| times/epoch_after_hook         | 1.97e-06     |
| times/epoch_before_hook        | 0.000128     |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.000562     |
| times/evaluation_paths         | 31.7         |
| times/timestep_after_hook      | 0.00397      |
| times/timestep_before_hook     | 0.00814      |
| times/train                    | 57.3         |
| timestep                       | 1000         |
| timesteps_total                | 968000       |
| train-steps                    | 968000       |
| training/Q/q1_loss             | 95.115654    |
| training/sac_pi/alpha          | 0.16528188   |
| training/sac_pi/alpha_loss     | -0.021399451 |
| training/sac_pi/logp_pi        | 4.377505     |
| training/sac_pi/pi_entropy     | 3.3131745    |
| training/sac_pi/pi_global_norm | 2.0084295    |
| training/sac_pi/policy_loss    | -212.55795   |
| training/sac_pi/std            | 0.49119368   |
| training/sac_pi/valid_num      | 4963.0       |
| training/sac_Q/q1              | 195.20038    |
| training/sac_Q/q2              | 195.47214    |
| training/sac_Q/q2_loss         | 95.75007     |
| training/sac_Q/q_global_norm   | 245.52669    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16833653  |
| epoch                          | 968         |
| evaluation/episode-length-avg  | 239         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 148         |
| evaluation/episode-length-std  | 254         |
| evaluation/return-average      | 947.43567   |
| evaluation/return-max          | 4777.6636   |
| evaluation/return-min          | 499.85724   |
| evaluation/return-std          | 1276.8501   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45804       |
| perf/AverageLength             | 239         |
| perf/AverageReturn             | 947.43567   |
| perf/NormalizedReturn          | 0.206       |
| Q-avg                          | 174.01332   |
| Q-std                          | 255.2725    |
| Q_loss                         | 109.23138   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 968         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000505    |
| times/evaluation_paths         | 7.47        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00791     |
| times/train                    | 57.8        |
| timestep                       | 1000        |
| timesteps_total                | 969000      |
| train-steps                    | 969000      |
| training/Q/q1_loss             | 93.75754    |
| training/sac_pi/alpha          | 0.16836205  |
| training/sac_pi/alpha_loss     | 0.016026357 |
| training/sac_pi/logp_pi        | 4.4047155   |
| training/sac_pi/pi_entropy     | 3.6103249   |
| training/sac_pi/pi_global_norm | 1.8557811   |
| training/sac_pi/policy_loss    | -214.14162  |
| training/sac_pi/std            | 0.52240384  |
| training/sac_pi/valid_num      | 5010.0      |
| training/sac_Q/q1              | 196.17595   |
| training/sac_Q/q2              | 196.7909    |
| training/sac_Q/q2_loss         | 94.87868    |
| training/sac_Q/q_global_norm   | 202.44678   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16698956  |
| epoch                          | 969         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4912.623    |
| evaluation/return-max          | 4936.48     |
| evaluation/return-min          | 4886.338    |
| evaluation/return-std          | 14.784651   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45986       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4912.623    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 186.37947   |
| Q-std                          | 212.16905   |
| Q_loss                         | 105.70562   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 969         |
| times/epoch_after_hook         | 2.04e-06    |
| times/epoch_before_hook        | 0.000389    |
| times/epoch_rollout_model      | 504         |
| times/evaluation_metrics       | 0.000583    |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 57.7        |
| timestep                       | 1000        |
| timesteps_total                | 970000      |
| train-steps                    | 970000      |
| training/Q/q1_loss             | 100.985214  |
| training/sac_pi/alpha          | 0.16696402  |
| training/sac_pi/alpha_loss     | -0.16365245 |
| training/sac_pi/logp_pi        | 4.1233444   |
| training/sac_pi/pi_entropy     | 3.331923    |
| training/sac_pi/pi_global_norm | 1.7626082   |
| training/sac_pi/policy_loss    | -211.72517  |
| training/sac_pi/std            | 0.48470095  |
| training/sac_pi/valid_num      | 4981.0      |
| training/sac_Q/q1              | 198.65903   |
| training/sac_Q/q2              | 200.47498   |
| training/sac_Q/q2_loss         | 99.878174   |
| training/sac_Q/q_global_norm   | 278.61316   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16573213 |
| epoch                          | 970        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4970.5713  |
| evaluation/return-max          | 5038.2676  |
| evaluation/return-min          | 4902.6743  |
| evaluation/return-std          | 39.865036  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45896      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4970.5713  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 195.87099  |
| Q-std                          | 165.60646  |
| Q_loss                         | 80.49066   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 970        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 516        |
| times/evaluation_metrics       | 0.000571   |
| times/evaluation_paths         | 30.4       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 57         |
| timestep                       | 1000       |
| timesteps_total                | 971000     |
| train-steps                    | 971000     |
| training/Q/q1_loss             | 91.044495  |
| training/sac_pi/alpha          | 0.16574737 |
| training/sac_pi/alpha_loss     | 0.05962633 |
| training/sac_pi/logp_pi        | 5.0523796  |
| training/sac_pi/pi_entropy     | 3.3128827  |
| training/sac_pi/pi_global_norm | 1.6170188  |
| training/sac_pi/policy_loss    | -215.90582 |
| training/sac_pi/std            | 0.5053222  |
| training/sac_pi/valid_num      | 4992.0     |
| training/sac_Q/q1              | 197.25508  |
| training/sac_Q/q2              | 199.29549  |
| training/sac_Q/q2_loss         | 92.45936   |
| training/sac_Q/q_global_norm   | 170.74821  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1690595   |
| epoch                          | 971         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5008.1494   |
| evaluation/return-max          | 5057.0244   |
| evaluation/return-min          | 4954.3555   |
| evaluation/return-std          | 32.083725   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45871       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5008.1494   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 198.98314   |
| Q-std                          | 196.00717   |
| Q_loss                         | 96.3263     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 971         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000529    |
| times/evaluation_paths         | 30.5        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 56.8        |
| timestep                       | 1000        |
| timesteps_total                | 972000      |
| train-steps                    | 972000      |
| training/Q/q1_loss             | 92.772896   |
| training/sac_pi/alpha          | 0.16907576  |
| training/sac_pi/alpha_loss     | -0.43484753 |
| training/sac_pi/logp_pi        | 3.8382201   |
| training/sac_pi/pi_entropy     | 3.5995228   |
| training/sac_pi/pi_global_norm | 1.7335937   |
| training/sac_pi/policy_loss    | -212.50073  |
| training/sac_pi/std            | 0.51591486  |
| training/sac_pi/valid_num      | 4952.0      |
| training/sac_Q/q1              | 199.814     |
| training/sac_Q/q2              | 200.47159   |
| training/sac_Q/q2_loss         | 92.99428    |
| training/sac_Q/q_global_norm   | 208.3026    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16976734  |
| epoch                          | 972         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4972.8857   |
| evaluation/return-max          | 5030.466    |
| evaluation/return-min          | 4917.7812   |
| evaluation/return-std          | 31.912292   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45998       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4972.8857   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 196.87569   |
| Q-std                          | 191.59247   |
| Q_loss                         | 105.67097   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 972         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 535         |
| times/evaluation_metrics       | 0.000646    |
| times/evaluation_paths         | 34.3        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 63.5        |
| timestep                       | 1000        |
| timesteps_total                | 973000      |
| train-steps                    | 973000      |
| training/Q/q1_loss             | 98.12995    |
| training/sac_pi/alpha          | 0.16976836  |
| training/sac_pi/alpha_loss     | -0.03353571 |
| training/sac_pi/logp_pi        | 4.9361215   |
| training/sac_pi/pi_entropy     | 3.4422958   |
| training/sac_pi/pi_global_norm | 1.6390953   |
| training/sac_pi/policy_loss    | -211.9151   |
| training/sac_pi/std            | 0.53234637  |
| training/sac_pi/valid_num      | 4932.0      |
| training/sac_Q/q1              | 191.45181   |
| training/sac_Q/q2              | 192.41145   |
| training/sac_Q/q2_loss         | 99.43961    |
| training/sac_Q/q_global_norm   | 181.5504    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16768076  |
| epoch                          | 973         |
| evaluation/episode-length-avg  | 926         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 259         |
| evaluation/episode-length-std  | 222         |
| evaluation/return-average      | 4745.1436   |
| evaluation/return-max          | 5251.7993   |
| evaluation/return-min          | 1021.96936  |
| evaluation/return-std          | 1243.2852   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45875       |
| perf/AverageLength             | 926         |
| perf/AverageReturn             | 4745.1436   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 199.04599   |
| Q-std                          | 200.6161    |
| Q_loss                         | 76.57685    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 973         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000551    |
| times/epoch_rollout_model      | 534         |
| times/evaluation_metrics       | 0.000595    |
| times/evaluation_paths         | 29.3        |
| times/timestep_after_hook      | 0.00413     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 60.5        |
| timestep                       | 1000        |
| timesteps_total                | 974000      |
| train-steps                    | 974000      |
| training/Q/q1_loss             | 83.750374   |
| training/sac_pi/alpha          | 0.16770785  |
| training/sac_pi/alpha_loss     | -0.19064245 |
| training/sac_pi/logp_pi        | 4.2574644   |
| training/sac_pi/pi_entropy     | 3.4699128   |
| training/sac_pi/pi_global_norm | 1.6818413   |
| training/sac_pi/policy_loss    | -215.6373   |
| training/sac_pi/std            | 0.5213551   |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 197.71054   |
| training/sac_Q/q2              | 196.68562   |
| training/sac_Q/q2_loss         | 81.872314   |
| training/sac_Q/q_global_norm   | 132.61761   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16781124  |
| epoch                          | 974         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4812.6484   |
| evaluation/return-max          | 4914.323    |
| evaluation/return-min          | 4746.1665   |
| evaluation/return-std          | 55.10444    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45980       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4812.6484   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 185.42366   |
| Q-std                          | 180.28783   |
| Q_loss                         | 99.68228    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 974         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000563    |
| times/evaluation_paths         | 31.2        |
| times/timestep_after_hook      | 0.00382     |
| times/timestep_before_hook     | 0.0079      |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 975000      |
| train-steps                    | 975000      |
| training/Q/q1_loss             | 115.8614    |
| training/sac_pi/alpha          | 0.16780365  |
| training/sac_pi/alpha_loss     | -0.14502439 |
| training/sac_pi/logp_pi        | 4.640566    |
| training/sac_pi/pi_entropy     | 3.5224342   |
| training/sac_pi/pi_global_norm | 1.6879637   |
| training/sac_pi/policy_loss    | -212.52843  |
| training/sac_pi/std            | 0.5540178   |
| training/sac_pi/valid_num      | 4947.0      |
| training/sac_Q/q1              | 191.10112   |
| training/sac_Q/q2              | 191.75876   |
| training/sac_Q/q2_loss         | 115.81516   |
| training/sac_Q/q_global_norm   | 249.81264   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16739012  |
| epoch                          | 975         |
| evaluation/episode-length-avg  | 745         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 145         |
| evaluation/episode-length-std  | 389         |
| evaluation/return-average      | 3454.9536   |
| evaluation/return-max          | 4845.8413   |
| evaluation/return-min          | 348.90857   |
| evaluation/return-std          | 2024.4292   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45881       |
| perf/AverageLength             | 745         |
| perf/AverageReturn             | 3454.9536   |
| perf/NormalizedReturn          | 0.752       |
| Q-avg                          | 197.90677   |
| Q-std                          | 165.3674    |
| Q_loss                         | 94.85164    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 975         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000142    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000538    |
| times/evaluation_paths         | 23          |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.00805     |
| times/train                    | 58.7        |
| timestep                       | 1000        |
| timesteps_total                | 976000      |
| train-steps                    | 976000      |
| training/Q/q1_loss             | 101.94166   |
| training/sac_pi/alpha          | 0.16740243  |
| training/sac_pi/alpha_loss     | 0.011416397 |
| training/sac_pi/logp_pi        | 4.854248    |
| training/sac_pi/pi_entropy     | 3.589334    |
| training/sac_pi/pi_global_norm | 1.7275056   |
| training/sac_pi/policy_loss    | -203.85039  |
| training/sac_pi/std            | 0.5482561   |
| training/sac_pi/valid_num      | 4902.0      |
| training/sac_Q/q1              | 179.40547   |
| training/sac_Q/q2              | 184.3272    |
| training/sac_Q/q2_loss         | 103.56628   |
| training/sac_Q/q_global_norm   | 198.26454   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16698976  |
| epoch                          | 976         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4962.607    |
| evaluation/return-max          | 4992.051    |
| evaluation/return-min          | 4931.8716   |
| evaluation/return-std          | 17.15541    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45998       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4962.607    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 190.08293   |
| Q-std                          | 178.86566   |
| Q_loss                         | 91.776886   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 976         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000138    |
| times/epoch_rollout_model      | 518         |
| times/evaluation_metrics       | 0.000548    |
| times/evaluation_paths         | 33          |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 977000      |
| train-steps                    | 977000      |
| training/Q/q1_loss             | 95.146286   |
| training/sac_pi/alpha          | 0.1670014   |
| training/sac_pi/alpha_loss     | -0.14831623 |
| training/sac_pi/logp_pi        | 4.692401    |
| training/sac_pi/pi_entropy     | 3.4798722   |
| training/sac_pi/pi_global_norm | 1.5087006   |
| training/sac_pi/policy_loss    | -213.37848  |
| training/sac_pi/std            | 0.5354788   |
| training/sac_pi/valid_num      | 4897.0      |
| training/sac_Q/q1              | 195.70898   |
| training/sac_Q/q2              | 197.00102   |
| training/sac_Q/q2_loss         | 94.71222    |
| training/sac_Q/q_global_norm   | 187.08728   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16411471 |
| epoch                          | 977        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4865.79    |
| evaluation/return-max          | 4977.356   |
| evaluation/return-min          | 4767.058   |
| evaluation/return-std          | 60.112453  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46033      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4865.79    |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 187.6395   |
| Q-std                          | 204.33069  |
| Q_loss                         | 96.35506   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 977        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000274   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000505   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00799    |
| times/train                    | 57.3       |
| timestep                       | 1000       |
| timesteps_total                | 978000     |
| train-steps                    | 978000     |
| training/Q/q1_loss             | 69.88749   |
| training/sac_pi/alpha          | 0.1641195  |
| training/sac_pi/alpha_loss     | -0.290373  |
| training/sac_pi/logp_pi        | 3.957605   |
| training/sac_pi/pi_entropy     | 3.3923066  |
| training/sac_pi/pi_global_norm | 1.2844098  |
| training/sac_pi/policy_loss    | -214.17097 |
| training/sac_pi/std            | 0.4972709  |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 197.24321  |
| training/sac_Q/q2              | 197.16751  |
| training/sac_Q/q2_loss         | 69.74772   |
| training/sac_Q/q_global_norm   | 148.86676  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16394211 |
| epoch                          | 978        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5083.4624  |
| evaluation/return-max          | 5102.3726  |
| evaluation/return-min          | 5051.3604  |
| evaluation/return-std          | 17.129168  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45982      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5083.4624  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 201.7161   |
| Q-std                          | 124.93065  |
| Q_loss                         | 91.28764   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 978        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000555   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.00795    |
| times/train                    | 56.2       |
| timestep                       | 1000       |
| timesteps_total                | 979000     |
| train-steps                    | 979000     |
| training/Q/q1_loss             | 83.19849   |
| training/sac_pi/alpha          | 0.16393624 |
| training/sac_pi/alpha_loss     | -0.4288038 |
| training/sac_pi/logp_pi        | 4.430398   |
| training/sac_pi/pi_entropy     | 3.6755257  |
| training/sac_pi/pi_global_norm | 2.2427227  |
| training/sac_pi/policy_loss    | -201.52869 |
| training/sac_pi/std            | 0.5396189  |
| training/sac_pi/valid_num      | 4959.0     |
| training/sac_Q/q1              | 183.80995  |
| training/sac_Q/q2              | 184.33073  |
| training/sac_Q/q2_loss         | 83.67865   |
| training/sac_Q/q_global_norm   | 134.83585  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16885518 |
| epoch                          | 979        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5007.6455  |
| evaluation/return-max          | 5056.5264  |
| evaluation/return-min          | 4936.431   |
| evaluation/return-std          | 35.32108   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45873      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5007.6455  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 196.61765  |
| Q-std                          | 169.8161   |
| Q_loss                         | 98.000534  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 979        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 522        |
| times/evaluation_metrics       | 0.000618   |
| times/evaluation_paths         | 32.7       |
| times/timestep_after_hook      | 0.00406    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 980000     |
| train-steps                    | 980000     |
| training/Q/q1_loss             | 90.66313   |
| training/sac_pi/alpha          | 0.16879848 |
| training/sac_pi/alpha_loss     | 0.16193305 |
| training/sac_pi/logp_pi        | 4.0497184  |
| training/sac_pi/pi_entropy     | 3.3862388  |
| training/sac_pi/pi_global_norm | 1.457249   |
| training/sac_pi/policy_loss    | -215.42766 |
| training/sac_pi/std            | 0.48724106 |
| training/sac_pi/valid_num      | 4959.0     |
| training/sac_Q/q1              | 199.31735  |
| training/sac_Q/q2              | 201.36938  |
| training/sac_Q/q2_loss         | 92.09518   |
| training/sac_Q/q_global_norm   | 188.16457  |
--------------------------------------------------------------------------------
[WARN] 980 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16404743 |
| epoch                          | 980        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4906.518   |
| evaluation/return-max          | 4958.9893  |
| evaluation/return-min          | 4838.415   |
| evaluation/return-std          | 39.345844  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45796      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4906.518   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 201.50659  |
| Q-std                          | 141.91486  |
| Q_loss                         | 87.02981   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 980        |
| times/epoch_after_hook         | 2.03e-06   |
| times/epoch_before_hook        | 0.000141   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000589   |
| times/evaluation_paths         | 31.9       |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 981000     |
| train-steps                    | 981000     |
| training/Q/q1_loss             | 106.52628  |
| training/sac_pi/alpha          | 0.16404116 |
| training/sac_pi/alpha_loss     | 0.09695213 |
| training/sac_pi/logp_pi        | 5.1370835  |
| training/sac_pi/pi_entropy     | 3.3033566  |
| training/sac_pi/pi_global_norm | 1.4948106  |
| training/sac_pi/policy_loss    | -209.96999 |
| training/sac_pi/std            | 0.51887876 |
| training/sac_pi/valid_num      | 4932.0     |
| training/sac_Q/q1              | 187.4314   |
| training/sac_Q/q2              | 190.1655   |
| training/sac_Q/q2_loss         | 106.05291  |
| training/sac_Q/q_global_norm   | 160.84113  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16293396 |
| epoch                          | 981        |
| evaluation/episode-length-avg  | 243        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 151        |
| evaluation/episode-length-std  | 252        |
| evaluation/return-average      | 883.3712   |
| evaluation/return-max          | 4752.493   |
| evaluation/return-min          | 419.9296   |
| evaluation/return-std          | 1289.8505  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45959      |
| perf/AverageLength             | 243        |
| perf/AverageReturn             | 883.3712   |
| perf/NormalizedReturn          | 0.192      |
| Q-avg                          | 188.47452  |
| Q-std                          | 190.21954  |
| Q_loss                         | 74.567444  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 981        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000501   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000511   |
| times/evaluation_paths         | 7.75       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 59.5       |
| timestep                       | 1000       |
| timesteps_total                | 982000     |
| train-steps                    | 982000     |
| training/Q/q1_loss             | 104.56882  |
| training/sac_pi/alpha          | 0.1629157  |
| training/sac_pi/alpha_loss     | 0.45253915 |
| training/sac_pi/logp_pi        | 4.9020333  |
| training/sac_pi/pi_entropy     | 3.5348709  |
| training/sac_pi/pi_global_norm | 2.1636424  |
| training/sac_pi/policy_loss    | -203.80713 |
| training/sac_pi/std            | 0.5352989  |
| training/sac_pi/valid_num      | 4971.0     |
| training/sac_Q/q1              | 184.31209  |
| training/sac_Q/q2              | 183.22772  |
| training/sac_Q/q2_loss         | 104.65504  |
| training/sac_Q/q_global_norm   | 171.27937  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16108757  |
| epoch                          | 982         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5012.6265   |
| evaluation/return-max          | 5053.047    |
| evaluation/return-min          | 4981.1943   |
| evaluation/return-std          | 17.832888   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 46039       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5012.6265   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 197.08984   |
| Q-std                          | 188.57303   |
| Q_loss                         | 84.10417    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 982         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 511         |
| times/evaluation_metrics       | 0.00064     |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.00393     |
| times/timestep_before_hook     | 0.00795     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 983000      |
| train-steps                    | 983000      |
| training/Q/q1_loss             | 86.803925   |
| training/sac_pi/alpha          | 0.16111924  |
| training/sac_pi/alpha_loss     | -0.11050408 |
| training/sac_pi/logp_pi        | 4.090287    |
| training/sac_pi/pi_entropy     | 3.3683724   |
| training/sac_pi/pi_global_norm | 1.4331152   |
| training/sac_pi/policy_loss    | -214.88565  |
| training/sac_pi/std            | 0.48351803  |
| training/sac_pi/valid_num      | 4987.0      |
| training/sac_Q/q1              | 204.0232    |
| training/sac_Q/q2              | 206.89648   |
| training/sac_Q/q2_loss         | 86.74886    |
| training/sac_Q/q_global_norm   | 239.45502   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16358398  |
| epoch                          | 983         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4920.6333   |
| evaluation/return-max          | 5023.8867   |
| evaluation/return-min          | 4828.8154   |
| evaluation/return-std          | 53.05665    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 82.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45924       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4920.6333   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 189.8786    |
| Q-std                          | 189.85968   |
| Q_loss                         | 99.32808    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 983         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000184    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000568    |
| times/evaluation_paths         | 31.1        |
| times/timestep_after_hook      | 0.00383     |
| times/timestep_before_hook     | 0.00806     |
| times/train                    | 58.7        |
| timestep                       | 1000        |
| timesteps_total                | 984000      |
| train-steps                    | 984000      |
| training/Q/q1_loss             | 93.26184    |
| training/sac_pi/alpha          | 0.16355643  |
| training/sac_pi/alpha_loss     | 0.055577938 |
| training/sac_pi/logp_pi        | 3.7526393   |
| training/sac_pi/pi_entropy     | 3.2077775   |
| training/sac_pi/pi_global_norm | 1.7082895   |
| training/sac_pi/policy_loss    | -212.06827  |
| training/sac_pi/std            | 0.45073992  |
| training/sac_pi/valid_num      | 5026.0      |
| training/sac_Q/q1              | 204.5283    |
| training/sac_Q/q2              | 206.38692   |
| training/sac_Q/q2_loss         | 92.74857    |
| training/sac_Q/q_global_norm   | 223.97939   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16125533  |
| epoch                          | 984         |
| evaluation/episode-length-avg  | 237         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 147         |
| evaluation/episode-length-std  | 254         |
| evaluation/return-average      | 971.7041    |
| evaluation/return-max          | 5141.3384   |
| evaluation/return-min          | 483.052     |
| evaluation/return-std          | 1389.9934   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45947       |
| perf/AverageLength             | 237         |
| perf/AverageReturn             | 971.7041    |
| perf/NormalizedReturn          | 0.211       |
| Q-avg                          | 199.45563   |
| Q-std                          | 169.35999   |
| Q_loss                         | 87.60764    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 984         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000144    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000482    |
| times/evaluation_paths         | 7.28        |
| times/timestep_after_hook      | 0.00382     |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 58.1        |
| timestep                       | 1000        |
| timesteps_total                | 985000      |
| train-steps                    | 985000      |
| training/Q/q1_loss             | 112.44697   |
| training/sac_pi/alpha          | 0.1612908   |
| training/sac_pi/alpha_loss     | -0.18969898 |
| training/sac_pi/logp_pi        | 5.003129    |
| training/sac_pi/pi_entropy     | 3.681312    |
| training/sac_pi/pi_global_norm | 1.7709163   |
| training/sac_pi/policy_loss    | -209.70854  |
| training/sac_pi/std            | 0.5653579   |
| training/sac_pi/valid_num      | 4932.0      |
| training/sac_Q/q1              | 188.16858   |
| training/sac_Q/q2              | 188.7601    |
| training/sac_Q/q2_loss         | 112.37646   |
| training/sac_Q/q_global_norm   | 201.34253   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17037511   |
| epoch                          | 985          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4937.8037    |
| evaluation/return-max          | 4967.9277    |
| evaluation/return-min          | 4890.256     |
| evaluation/return-std          | 20.13363     |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.99         |
| model/origin_ret               | 84.8         |
| model/penalty_ret              | 81.7         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45858        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4937.8037    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 198.81761    |
| Q-std                          | 176.0791     |
| Q_loss                         | 105.81689    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 985          |
| times/epoch_after_hook         | 2e-06        |
| times/epoch_before_hook        | 0.000323     |
| times/epoch_rollout_model      | 495          |
| times/evaluation_metrics       | 0.000557     |
| times/evaluation_paths         | 30.7         |
| times/timestep_after_hook      | 0.00384      |
| times/timestep_before_hook     | 0.00808      |
| times/train                    | 57.8         |
| timestep                       | 1000         |
| timesteps_total                | 986000       |
| train-steps                    | 986000       |
| training/Q/q1_loss             | 104.49859    |
| training/sac_pi/alpha          | 0.17034361   |
| training/sac_pi/alpha_loss     | -0.059678387 |
| training/sac_pi/logp_pi        | 4.903421     |
| training/sac_pi/pi_entropy     | 3.7700267    |
| training/sac_pi/pi_global_norm | 1.5312235    |
| training/sac_pi/policy_loss    | -208.29945   |
| training/sac_pi/std            | 0.5646847    |
| training/sac_pi/valid_num      | 4908.0       |
| training/sac_Q/q1              | 184.94894    |
| training/sac_Q/q2              | 185.97824    |
| training/sac_Q/q2_loss         | 105.933426   |
| training/sac_Q/q_global_norm   | 207.36285    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16857204 |
| epoch                          | 986        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5130.3857  |
| evaluation/return-max          | 5164.1875  |
| evaluation/return-min          | 5042.8506  |
| evaluation/return-std          | 33.325394  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45816      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5130.3857  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 196.47849  |
| Q-std                          | 168.36185  |
| Q_loss                         | 105.92603  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 986        |
| times/epoch_after_hook         | 2.03e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000575   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.00799    |
| times/train                    | 57.1       |
| timestep                       | 1000       |
| timesteps_total                | 987000     |
| train-steps                    | 987000     |
| training/Q/q1_loss             | 88.230545  |
| training/sac_pi/alpha          | 0.16858447 |
| training/sac_pi/alpha_loss     | -0.3326246 |
| training/sac_pi/logp_pi        | 4.113237   |
| training/sac_pi/pi_entropy     | 3.4291313  |
| training/sac_pi/pi_global_norm | 1.6965837  |
| training/sac_pi/policy_loss    | -212.64838 |
| training/sac_pi/std            | 0.49794883 |
| training/sac_pi/valid_num      | 4988.0     |
| training/sac_Q/q1              | 196.74356  |
| training/sac_Q/q2              | 199.80452  |
| training/sac_Q/q2_loss         | 88.476166  |
| training/sac_Q/q_global_norm   | 174.531    |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17312054  |
| epoch                          | 987         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5110.9136   |
| evaluation/return-max          | 5145.683    |
| evaluation/return-min          | 5008.8076   |
| evaluation/return-std          | 37.070995   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45936       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5110.9136   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 192.617     |
| Q-std                          | 135.37419   |
| Q_loss                         | 106.85884   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 987         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000536    |
| times/evaluation_paths         | 30.4        |
| times/timestep_after_hook      | 0.00382     |
| times/timestep_before_hook     | 0.00788     |
| times/train                    | 57          |
| timestep                       | 1000        |
| timesteps_total                | 988000      |
| train-steps                    | 988000      |
| training/Q/q1_loss             | 80.83335    |
| training/sac_pi/alpha          | 0.17315367  |
| training/sac_pi/alpha_loss     | -0.32414025 |
| training/sac_pi/logp_pi        | 4.7482386   |
| training/sac_pi/pi_entropy     | 3.4842422   |
| training/sac_pi/pi_global_norm | 1.5681355   |
| training/sac_pi/policy_loss    | -205.35123  |
| training/sac_pi/std            | 0.52377486  |
| training/sac_pi/valid_num      | 4897.0      |
| training/sac_Q/q1              | 185.22757   |
| training/sac_Q/q2              | 185.98001   |
| training/sac_Q/q2_loss         | 81.3868     |
| training/sac_Q/q_global_norm   | 234.13548   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17192248 |
| epoch                          | 988        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4722.747   |
| evaluation/return-max          | 4761.7236  |
| evaluation/return-min          | 4654.257   |
| evaluation/return-std          | 30.492516  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45949      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4722.747   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 193.84714  |
| Q-std                          | 159.54884  |
| Q_loss                         | 86.00026   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 988        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000583   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00381    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 58.4       |
| timestep                       | 1000       |
| timesteps_total                | 989000     |
| train-steps                    | 989000     |
| training/Q/q1_loss             | 89.61764   |
| training/sac_pi/alpha          | 0.1719018  |
| training/sac_pi/alpha_loss     | 0.37767744 |
| training/sac_pi/logp_pi        | 4.5802927  |
| training/sac_pi/pi_entropy     | 3.4182258  |
| training/sac_pi/pi_global_norm | 2.289984   |
| training/sac_pi/policy_loss    | -209.09624 |
| training/sac_pi/std            | 0.5141199  |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 191.67273  |
| training/sac_Q/q2              | 191.89487  |
| training/sac_Q/q2_loss         | 89.77526   |
| training/sac_Q/q_global_norm   | 142.9232   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17247409   |
| epoch                          | 989          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4771.243     |
| evaluation/return-max          | 4822.6465    |
| evaluation/return-min          | 4684.9727    |
| evaluation/return-std          | 46.576157    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.94         |
| model/origin_ret               | 84.3         |
| model/penalty_ret              | 81.5         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45900        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4771.243     |
| perf/NormalizedReturn          | 1.04         |
| Q-avg                          | 184.17297    |
| Q-std                          | 169.04259    |
| Q_loss                         | 109.62274    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 989          |
| times/epoch_after_hook         | 1.93e-06     |
| times/epoch_before_hook        | 0.000326     |
| times/epoch_rollout_model      | 503          |
| times/evaluation_metrics       | 0.000556     |
| times/evaluation_paths         | 30.6         |
| times/timestep_after_hook      | 0.00378      |
| times/timestep_before_hook     | 0.00795      |
| times/train                    | 56.6         |
| timestep                       | 1000         |
| timesteps_total                | 990000       |
| train-steps                    | 990000       |
| training/Q/q1_loss             | 104.9615     |
| training/sac_pi/alpha          | 0.17248222   |
| training/sac_pi/alpha_loss     | -0.114585124 |
| training/sac_pi/logp_pi        | 4.723384     |
| training/sac_pi/pi_entropy     | 3.4686966    |
| training/sac_pi/pi_global_norm | 1.8185341    |
| training/sac_pi/policy_loss    | -205.25644   |
| training/sac_pi/std            | 0.5195142    |
| training/sac_pi/valid_num      | 4906.0       |
| training/sac_Q/q1              | 188.00343    |
| training/sac_Q/q2              | 190.56851    |
| training/sac_Q/q2_loss         | 104.922134   |
| training/sac_Q/q_global_norm   | 237.43831    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16966407 |
| epoch                          | 990        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4673.089   |
| evaluation/return-max          | 4725.1733  |
| evaluation/return-min          | 4615.2886  |
| evaluation/return-std          | 32.442127  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46082      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4673.089   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 198.50276  |
| Q-std                          | 182.24657  |
| Q_loss                         | 111.47685  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 990        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000561   |
| times/evaluation_paths         | 31.4       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 58.5       |
| timestep                       | 1000       |
| timesteps_total                | 991000     |
| train-steps                    | 991000     |
| training/Q/q1_loss             | 111.833115 |
| training/sac_pi/alpha          | 0.1696595  |
| training/sac_pi/alpha_loss     | 0.2591655  |
| training/sac_pi/logp_pi        | 4.8169823  |
| training/sac_pi/pi_entropy     | 3.4874458  |
| training/sac_pi/pi_global_norm | 1.757553   |
| training/sac_pi/policy_loss    | -214.68405 |
| training/sac_pi/std            | 0.520819   |
| training/sac_pi/valid_num      | 4924.0     |
| training/sac_Q/q1              | 196.95593  |
| training/sac_Q/q2              | 199.03549  |
| training/sac_Q/q2_loss         | 111.18714  |
| training/sac_Q/q_global_norm   | 207.18857  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16603768 |
| epoch                          | 991        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4839.695   |
| evaluation/return-max          | 4905.5596  |
| evaluation/return-min          | 4760.8926  |
| evaluation/return-std          | 40.541744  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45867      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4839.695   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 201.81326  |
| Q-std                          | 123.3065   |
| Q_loss                         | 98.77277   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 991        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000237   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000602   |
| times/evaluation_paths         | 30.4       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 57.4       |
| timestep                       | 1000       |
| timesteps_total                | 992000     |
| train-steps                    | 992000     |
| training/Q/q1_loss             | 113.09304  |
| training/sac_pi/alpha          | 0.16603214 |
| training/sac_pi/alpha_loss     | 0.09760137 |
| training/sac_pi/logp_pi        | 4.3589797  |
| training/sac_pi/pi_entropy     | 3.6833565  |
| training/sac_pi/pi_global_norm | 1.5331973  |
| training/sac_pi/policy_loss    | -212.70888 |
| training/sac_pi/std            | 0.53770566 |
| training/sac_pi/valid_num      | 4940.0     |
| training/sac_Q/q1              | 197.16995  |
| training/sac_Q/q2              | 198.21957  |
| training/sac_Q/q2_loss         | 113.16471  |
| training/sac_Q/q_global_norm   | 216.73517  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16261744 |
| epoch                          | 992        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4731.4424  |
| evaluation/return-max          | 4803.4     |
| evaluation/return-min          | 4631.7563  |
| evaluation/return-std          | 56.14955   |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45946      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4731.4424  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 204.78023  |
| Q-std                          | 140.02905  |
| Q_loss                         | 83.47222   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 992        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000559   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 57.2       |
| timestep                       | 1000       |
| timesteps_total                | 993000     |
| train-steps                    | 993000     |
| training/Q/q1_loss             | 100.106026 |
| training/sac_pi/alpha          | 0.16259855 |
| training/sac_pi/alpha_loss     | 0.22505732 |
| training/sac_pi/logp_pi        | 3.9166367  |
| training/sac_pi/pi_entropy     | 3.4688668  |
| training/sac_pi/pi_global_norm | 1.8558618  |
| training/sac_pi/policy_loss    | -207.17804 |
| training/sac_pi/std            | 0.49533197 |
| training/sac_pi/valid_num      | 5006.0     |
| training/sac_Q/q1              | 198.74773  |
| training/sac_Q/q2              | 199.56367  |
| training/sac_Q/q2_loss         | 99.860146  |
| training/sac_Q/q_global_norm   | 173.46713  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16651778  |
| epoch                          | 993         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4836.593    |
| evaluation/return-max          | 4920.077    |
| evaluation/return-min          | 4678.297    |
| evaluation/return-std          | 72.82125    |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45873       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4836.593    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 199.26839   |
| Q-std                          | 180.60298   |
| Q_loss                         | 83.09533    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 993         |
| times/epoch_after_hook         | 2.01e-06    |
| times/epoch_before_hook        | 0.000274    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 31.3        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 58.1        |
| timestep                       | 1000        |
| timesteps_total                | 994000      |
| train-steps                    | 994000      |
| training/Q/q1_loss             | 103.264824  |
| training/sac_pi/alpha          | 0.16650917  |
| training/sac_pi/alpha_loss     | -0.21418269 |
| training/sac_pi/logp_pi        | 4.0968027   |
| training/sac_pi/pi_entropy     | 3.5467472   |
| training/sac_pi/pi_global_norm | 2.322317    |
| training/sac_pi/policy_loss    | -206.74226  |
| training/sac_pi/std            | 0.5070802   |
| training/sac_pi/valid_num      | 4995.0      |
| training/sac_Q/q1              | 193.59554   |
| training/sac_Q/q2              | 196.22713   |
| training/sac_Q/q2_loss         | 104.420975  |
| training/sac_Q/q_global_norm   | 211.4471    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1666329  |
| epoch                          | 994        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4946.036   |
| evaluation/return-max          | 4978.417   |
| evaluation/return-min          | 4907.165   |
| evaluation/return-std          | 19.937181  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45896      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4946.036   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 194.5459   |
| Q-std                          | 206.06932  |
| Q_loss                         | 104.108315 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 994        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000168   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000522   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 57.5       |
| timestep                       | 1000       |
| timesteps_total                | 995000     |
| train-steps                    | 995000     |
| training/Q/q1_loss             | 104.38642  |
| training/sac_pi/alpha          | 0.16663495 |
| training/sac_pi/alpha_loss     | 0.26369596 |
| training/sac_pi/logp_pi        | 5.169038   |
| training/sac_pi/pi_entropy     | 3.358104   |
| training/sac_pi/pi_global_norm | 1.7277235  |
| training/sac_pi/policy_loss    | -213.84029 |
| training/sac_pi/std            | 0.5087042  |
| training/sac_pi/valid_num      | 4962.0     |
| training/sac_Q/q1              | 193.16414  |
| training/sac_Q/q2              | 194.06859  |
| training/sac_Q/q2_loss         | 103.177956 |
| training/sac_Q/q_global_norm   | 195.79529  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16517083 |
| epoch                          | 995        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5179.0273  |
| evaluation/return-max          | 5294.997   |
| evaluation/return-min          | 5009.6924  |
| evaluation/return-std          | 94.216545  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45821      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5179.0273  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 197.85097  |
| Q-std                          | 124.18795  |
| Q_loss                         | 99.0093    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 995        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000643   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 58.2       |
| timestep                       | 1000       |
| timesteps_total                | 996000     |
| train-steps                    | 996000     |
| training/Q/q1_loss             | 94.92257   |
| training/sac_pi/alpha          | 0.16517252 |
| training/sac_pi/alpha_loss     | -0.104233  |
| training/sac_pi/logp_pi        | 4.312102   |
| training/sac_pi/pi_entropy     | 3.4776454  |
| training/sac_pi/pi_global_norm | 1.5859855  |
| training/sac_pi/policy_loss    | -212.9734  |
| training/sac_pi/std            | 0.5097495  |
| training/sac_pi/valid_num      | 5001.0     |
| training/sac_Q/q1              | 199.74255  |
| training/sac_Q/q2              | 201.21275  |
| training/sac_Q/q2_loss         | 94.726105  |
| training/sac_Q/q_global_norm   | 184.9533   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1626549  |
| epoch                          | 996        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4983.516   |
| evaluation/return-max          | 5036.9736  |
| evaluation/return-min          | 4907.677   |
| evaluation/return-std          | 40.667507  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 46006      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4983.516   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 199.63246  |
| Q-std                          | 175.40515  |
| Q_loss                         | 100.52607  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 996        |
| times/epoch_after_hook         | 2e-06      |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000547   |
| times/evaluation_paths         | 30.6       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 57.1       |
| timestep                       | 1000       |
| timesteps_total                | 997000     |
| train-steps                    | 997000     |
| training/Q/q1_loss             | 110.107635 |
| training/sac_pi/alpha          | 0.16266015 |
| training/sac_pi/alpha_loss     | 0.53802484 |
| training/sac_pi/logp_pi        | 5.1401796  |
| training/sac_pi/pi_entropy     | 3.4115193  |
| training/sac_pi/pi_global_norm | 1.609409   |
| training/sac_pi/policy_loss    | -207.58586 |
| training/sac_pi/std            | 0.5268871  |
| training/sac_pi/valid_num      | 4913.0     |
| training/sac_Q/q1              | 182.77072  |
| training/sac_Q/q2              | 185.29514  |
| training/sac_Q/q2_loss         | 111.09475  |
| training/sac_Q/q_global_norm   | 220.11928  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16851515 |
| epoch                          | 997        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4971.748   |
| evaluation/return-max          | 5022.102   |
| evaluation/return-min          | 4892.3896  |
| evaluation/return-std          | 41.146183  |
| model/max_penalty              | 7.34       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.35430613 |
| model/valid_num                | 45960      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4971.748   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 199.27689  |
| Q-std                          | 162.11502  |
| Q_loss                         | 106.662796 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 997        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000275   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000561   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 57.3       |
| timestep                       | 1000       |
| timesteps_total                | 998000     |
| train-steps                    | 998000     |
| training/Q/q1_loss             | 80.64031   |
| training/sac_pi/alpha          | 0.16851278 |
| training/sac_pi/alpha_loss     | 0.15308659 |
| training/sac_pi/logp_pi        | 5.330497   |
| training/sac_pi/pi_entropy     | 3.7365448  |
| training/sac_pi/pi_global_norm | 2.1752577  |
| training/sac_pi/policy_loss    | -203.88907 |
| training/sac_pi/std            | 0.56912005 |
| training/sac_pi/valid_num      | 4841.0     |
| training/sac_Q/q1              | 174.78915  |
| training/sac_Q/q2              | 170.24333  |
| training/sac_Q/q2_loss         | 79.85096   |
| training/sac_Q/q_global_norm   | 145.88443  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17053498  |
| epoch                          | 998         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4981.7217   |
| evaluation/return-max          | 5009.3677   |
| evaluation/return-min          | 4936.617    |
| evaluation/return-std          | 23.197176   |
| model/max_penalty              | 7.34        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.35430613  |
| model/valid_num                | 45964       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4981.7217   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 205.85796   |
| Q-std                          | 146.54807   |
| Q_loss                         | 94.39869    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 998         |
| times/epoch_after_hook         | 1.93e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000531    |
| times/evaluation_paths         | 30.6        |
| times/timestep_after_hook      | 0.00383     |
| times/timestep_before_hook     | 0.00798     |
| times/train                    | 56.9        |
| timestep                       | 1000        |
| timesteps_total                | 999000      |
| train-steps                    | 999000      |
| training/Q/q1_loss             | 83.41652    |
| training/sac_pi/alpha          | 0.1705259   |
| training/sac_pi/alpha_loss     | -0.21445431 |
| training/sac_pi/logp_pi        | 3.7749462   |
| training/sac_pi/pi_entropy     | 3.5604768   |
| training/sac_pi/pi_global_norm | 1.6366539   |
| training/sac_pi/policy_loss    | -211.26517  |
| training/sac_pi/std            | 0.49026516  |
| training/sac_pi/valid_num      | 4976.0      |
| training/sac_Q/q1              | 199.50687   |
| training/sac_Q/q2              | 200.19893   |
| training/sac_Q/q2_loss         | 83.07378    |
| training/sac_Q/q_global_norm   | 156.07826   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17064044   |
| epoch                          | 999          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4879.401     |
| evaluation/return-max          | 5034.924     |
| evaluation/return-min          | 4644.861     |
| evaluation/return-std          | 142.86476    |
| model/max_penalty              | 7.34         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.99         |
| model/origin_ret               | 84.7         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.35430613   |
| model/valid_num                | 45880        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4879.401     |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 210.08487    |
| Q-std                          | 123.443855   |
| Q_loss                         | 67.303795    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 999          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.000127     |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.000583     |
| times/evaluation_paths         | 30.1         |
| times/timestep_after_hook      | 0.00385      |
| times/timestep_before_hook     | 0.00807      |
| times/train                    | 56.6         |
| timestep                       | 1000         |
| timesteps_total                | 1000000      |
| train-steps                    | 1000000      |
| training/Q/q1_loss             | 99.29926     |
| training/sac_pi/alpha          | 0.1706522    |
| training/sac_pi/alpha_loss     | -0.027963784 |
| training/sac_pi/logp_pi        | 4.914242     |
| training/sac_pi/pi_entropy     | 3.3225818    |
| training/sac_pi/pi_global_norm | 1.7652903    |
| training/sac_pi/policy_loss    | -200.14516   |
| training/sac_pi/std            | 0.5055522    |
| training/sac_pi/valid_num      | 4938.0       |
| training/sac_Q/q1              | 181.15071    |
| training/sac_Q/q2              | 186.03949    |
| training/sac_Q/q2_loss         | 98.91115     |
| training/sac_Q/q_global_norm   | 225.54007    |
----------------------------------------------------------------------------------
