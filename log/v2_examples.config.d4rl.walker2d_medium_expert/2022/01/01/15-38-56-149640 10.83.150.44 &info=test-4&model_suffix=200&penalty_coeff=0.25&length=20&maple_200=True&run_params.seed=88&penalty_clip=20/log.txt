Logging to /nfs/project/chenxionghui/proj/MAPLE/log/v2_examples.config.d4rl.walker2d_medium_expert/2022/01/01/15-38-56-149640 10.83.150.44 &info=test-4&model_suffix=200&penalty_coeff=0.25&length=20&maple_200=True&run_params.seed=88&penalty_clip=20/
log dir: /nfs/project/chenxionghui/proj/MAPLE/log/v2_examples.config.d4rl.walker2d_medium_expert/2022/01/01/15-38-56-149640 10.83.150.44 &info=test-4&model_suffix=200&penalty_coeff=0.25&length=20&maple_200=True&run_params.seed=88&penalty_clip=20/
pkl_file: /nfs/project/chenxionghui/proj/MAPLE/archive_tester/v2_examples.config.d4rl.walker2d_medium_expert/2022/01/01/15-38-56-149640 10.83.150.44 &info=test-4&model_suffix=200&penalty_coeff=0.25&length=20&maple_200=True&run_params.seed=88&penalty_clip=20.pkl
checkpoint_dir: /nfs/project/chenxionghui/proj/MAPLE/checkpoint/v2_examples.config.d4rl.walker2d_medium_expert/2022/01/01/15-38-56-149640 10.83.150.44 &info=test-4&model_suffix=200&penalty_coeff=0.25&length=20&maple_200=True&run_params.seed=88&penalty_clip=20/
results_dir: /nfs/project/chenxionghui/proj/MAPLE/results/v2_examples.config.d4rl.walker2d_medium_expert/2022/01/01/15-38-56-149640 10.83.150.44 &info=test-4&model_suffix=200&penalty_coeff=0.25&length=20&maple_200=True&run_params.seed=88&penalty_clip=20/
key: Q_params, value: {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}
key: algorithm_params, value: DotMap(type='MAPLE', universe='gym', kwargs=DotMap(epoch_length=1000, train_every_n_steps=1, n_train_repeat=1, eval_render_mode=None, eval_n_episodes=10, eval_deterministic=True, discount=0.99, tau=0.005, reward_scale=1.0, model_train_freq=1000, model_retain_epochs=5, rollout_batch_size=50000.0, deterministic=False, num_networks=7, num_elites=5, real_ratio=0.05, target_entropy=-3, max_model_t=None, separate_mean_var=True, penalty_learned_var=True, pool_load_path='d4rl/walker2d-medium-expert-v0', pool_load_max_size=2000000, rollout_length=1, penalty_coeff=2.0, reparameterize=True, lr=0.0003, target_update_interval=1, store_extra_policy_info=False, action_prior='uniform', n_initial_exploration_steps=5000, model_load_dir='/nfs/project/chenxionghui/proj/MAPLE/models', network_kwargs=DotMap(hidden_sizes=[256, 256], activation=<function relu at 0x7f81e8eb53b0>, output_activation=None, lstm_hidden_unit=128, embedding_size=16)), domain='walker2d', task='medium-expert-v0', exp_name='walker2d_medium_expert')
key: config, value: examples.config.d4rl.walker2d_medium_expert
key: custom_config, value: False
key: elite_num, value: -1
key: emb_size, value: 16
key: environment_params, value: {'training': {'domain': 'walker2d', 'task': 'medium-expert-v0', 'universe': 'gym', 'kwargs': {'use_neorl': False}}, 'evaluation': <function get_variant_spec_base.<locals>.<lambda> at 0x7f82523795f0>}
key: info, value: test-4
key: length, value: 20
key: load_date, value: 
key: load_task_name, value: 
key: maple_200, value: True
key: model_suffix, value: 200
key: n_epochs, value: 1000
key: not_inherit_hp, value: True
key: penalty_clip, value: 20
key: penalty_coeff, value: 0.25
key: policy, value: gaussian
key: policy_params, value: {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}
key: replay_pool_params, value: {'type': 'SimpleReplayPool', 'kwargs': {'max_size': <function get_variant_spec_base.<locals>.<lambda> at 0x7f8252379440>}}
key: retrain_model, value: False
key: run_params, value: {'seed': 88, 'checkpoint_at_end': True, 'checkpoint_frequency': 20, 'checkpoint_replay_pool': False, 'info': ''}
key: sampler_params, value: {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}
key: seed, value: 88
save variable :
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/Scaler/scaler_mu:0' shape=(1, 23) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/Scaler/scaler_std:0' shape=(1, 23) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/max_log_var:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/min_log_var:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/Layer0_mean/FC_weights:0' shape=(200, 23, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/Layer0_mean/FC_biases:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/Layer1_mean/FC_weights:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/Layer1_mean/FC_biases:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/Layer2_mean/FC_weights:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/Layer2_mean/FC_biases:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/Layer3_mean/FC_weights:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/Layer3_mean/FC_biases:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/Layer4_mean/FC_weights:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/Layer4_mean/FC_biases:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/Layer0_var/FC_weights:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/Layer0_var/FC_biases:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200_1/beta1_power:0' shape=() dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200_1/beta2_power:0' shape=() dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer0_mean/FC_weights/Adam:0' shape=(200, 23, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer0_mean/FC_weights/Adam_1:0' shape=(200, 23, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer0_mean/FC_biases/Adam:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer0_mean/FC_biases/Adam_1:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer1_mean/FC_weights/Adam:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer1_mean/FC_weights/Adam_1:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer1_mean/FC_biases/Adam:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer1_mean/FC_biases/Adam_1:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer2_mean/FC_weights/Adam:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer2_mean/FC_weights/Adam_1:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer2_mean/FC_biases/Adam:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer2_mean/FC_biases/Adam_1:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer3_mean/FC_weights/Adam:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer3_mean/FC_weights/Adam_1:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer3_mean/FC_biases/Adam:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer3_mean/FC_biases/Adam_1:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer4_mean/FC_weights/Adam:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer4_mean/FC_weights/Adam_1:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer4_mean/FC_biases/Adam:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer4_mean/FC_biases/Adam_1:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer0_var/FC_weights/Adam:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer0_var/FC_weights/Adam_1:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer0_var/FC_biases/Adam:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/Layer0_var/FC_biases/Adam_1:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/max_log_var/Adam:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/max_log_var/Adam_1:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/min_log_var/Adam:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_88_200/walker2d-medium-expert-v0_smv_88_200/min_log_var/Adam_1:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'global_step:0' shape=() dtype=int64_ref>
<tf.Variable 'lstm_net_p/rnn/gru_cell/gates/kernel:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_p/rnn/gru_cell/gates/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_p/rnn/gru_cell/candidate/kernel:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_p/rnn/gru_cell/candidate/bias:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_p/dense/kernel:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_p/dense/bias:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/kernel:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/kernel:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/bias:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/kernel:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/bias:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'main/pi/dense/kernel:0' shape=(33, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/kernel:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/bias:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/kernel:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/bias:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'main/q1/dense/kernel:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/kernel:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/bias:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'main/q2/dense/kernel:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/kernel:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/bias:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'target/pi/dense/kernel:0' shape=(33, 256) dtype=float32_ref>
<tf.Variable 'target/pi/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/pi/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'target/pi/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/pi/dense_2/kernel:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'target/pi/dense_2/bias:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'target/pi/dense_3/kernel:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'target/pi/dense_3/bias:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'target/q1/dense/kernel:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'target/q1/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/q1/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'target/q1/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/q1/dense_2/kernel:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'target/q1/dense_2/bias:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'target/q2/dense/kernel:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'target/q2/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/q2/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'target/q2/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/q2/dense_2/kernel:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'target/q2/dense_2/bias:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'log_alpha:0' shape=() dtype=float32_ref>
<tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>
<tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>
<tf.Variable 'main/pi/dense/kernel/Adam:0' shape=(33, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense/kernel/Adam_1:0' shape=(33, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/kernel/Adam:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/kernel/Adam_1:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/kernel/Adam:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/kernel/Adam_1:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/bias/Adam:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/bias/Adam_1:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/kernel/Adam:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/kernel/Adam_1:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/bias/Adam:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/bias/Adam_1:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'beta1_power_1:0' shape=() dtype=float32_ref>
<tf.Variable 'beta2_power_1:0' shape=() dtype=float32_ref>
<tf.Variable 'main/q1/dense/kernel/Adam:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense/kernel/Adam_1:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/kernel/Adam:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/kernel/Adam_1:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/kernel/Adam:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/kernel/Adam_1:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/bias/Adam:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/bias/Adam_1:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/kernel/Adam:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/kernel/Adam_1:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/kernel/Adam:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/kernel/Adam_1:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/bias/Adam:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/bias/Adam_1:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/kernel/Adam:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/kernel/Adam_1:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/bias/Adam:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/bias/Adam_1:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'beta1_power_2:0' shape=() dtype=float32_ref>
<tf.Variable 'beta2_power_2:0' shape=() dtype=float32_ref>
<tf.Variable 'main/q2/dense/kernel/Adam:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense/kernel/Adam_1:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/kernel/Adam:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/kernel/Adam_1:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/kernel/Adam:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/kernel/Adam_1:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/bias/Adam:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/bias/Adam_1:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/kernel/Adam_2:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/kernel/Adam_3:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/bias/Adam_2:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/bias/Adam_3:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/kernel/Adam_2:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/kernel/Adam_3:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/bias/Adam_2:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/bias/Adam_3:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/kernel/Adam_2:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/kernel/Adam_3:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/bias/Adam_2:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/bias/Adam_3:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'beta1_power_3:0' shape=() dtype=float32_ref>
<tf.Variable 'beta2_power_3:0' shape=() dtype=float32_ref>
<tf.Variable 'log_alpha/alpha_optimizer:0' shape=() dtype=float32_ref>
<tf.Variable 'log_alpha/alpha_optimizer_1:0' shape=() dtype=float32_ref>
[WARN] 0 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.74226546 |
| epoch                          | 0          |
| evaluation/episode-length-avg  | 147        |
| evaluation/episode-length-max  | 161        |
| evaluation/episode-length-min  | 137        |
| evaluation/episode-length-std  | 5.83       |
| evaluation/return-average      | 265.48032  |
| evaluation/return-max          | 280.3027   |
| evaluation/return-min          | 254.73793  |
| evaluation/return-std          | 6.2825203  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | -6.94      |
| model/origin_ret               | 9.7        |
| model/penalty_ret              | 69.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 2623       |
| perf/AverageLength             | 147        |
| perf/AverageReturn             | 265.48032  |
| perf/NormalizedReturn          | 0.0575     |
| Q-avg                          | 3.584851   |
| Q-std                          | 28.465315  |
| Q_loss                         | 5.9797482  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 0          |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000111   |
| times/epoch_rollout_model      | 513        |
| times/evaluation_metrics       | 0.000465   |
| times/evaluation_paths         | 7.05       |
| times/timestep_after_hook      | 0.00413    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 80.7       |
| timestep                       | 1000       |
| timesteps_total                | 1000       |
| train-steps                    | 1000       |
| training/Q/q1_loss             | 7.048434   |
| training/sac_pi/alpha          | 0.74247116 |
| training/sac_pi/alpha_loss     | -1.8042691 |
| training/sac_pi/logp_pi        | 15.590817  |
| training/sac_pi/pi_entropy     | 6.112466   |
| training/sac_pi/pi_global_norm | 3.0059714  |
| training/sac_pi/policy_loss    | -18.912954 |
| training/sac_pi/std            | 1.508178   |
| training/sac_pi/valid_num      | 2545.0     |
| training/sac_Q/q1              | 3.9693265  |
| training/sac_Q/q2              | 3.15237    |
| training/sac_Q/q2_loss         | 7.0257583  |
| training/sac_Q/q_global_norm   | 15.32648   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.5576405  |
| epoch                          | 1          |
| evaluation/episode-length-avg  | 181        |
| evaluation/episode-length-max  | 196        |
| evaluation/episode-length-min  | 167        |
| evaluation/episode-length-std  | 9.5        |
| evaluation/return-average      | 303.01532  |
| evaluation/return-max          | 319.8583   |
| evaluation/return-min          | 287.24344  |
| evaluation/return-std          | 9.94874    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | -0.152     |
| model/origin_ret               | 69.1       |
| model/penalty_ret              | 101        |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 26997      |
| perf/AverageLength             | 181        |
| perf/AverageReturn             | 303.01532  |
| perf/NormalizedReturn          | 0.0657     |
| Q-avg                          | 20.367214  |
| Q-std                          | 39.394142  |
| Q_loss                         | 11.869052  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 1          |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000247   |
| times/epoch_rollout_model      | 525        |
| times/evaluation_metrics       | 0.000613   |
| times/evaluation_paths         | 6.95       |
| times/timestep_after_hook      | 0.00403    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 78.7       |
| timestep                       | 1000       |
| timesteps_total                | 2000       |
| train-steps                    | 2000       |
| training/Q/q1_loss             | 11.6008    |
| training/sac_pi/alpha          | 0.55779177 |
| training/sac_pi/alpha_loss     | -3.2479331 |
| training/sac_pi/logp_pi        | 8.866789   |
| training/sac_pi/pi_entropy     | 6.7006516  |
| training/sac_pi/pi_global_norm | 1.0741535  |
| training/sac_pi/policy_loss    | -33.800426 |
| training/sac_pi/std            | 1.1751112  |
| training/sac_pi/valid_num      | 3547.0     |
| training/sac_Q/q1              | 19.626616  |
| training/sac_Q/q2              | 19.811848  |
| training/sac_Q/q2_loss         | 11.566407  |
| training/sac_Q/q_global_norm   | 32.614464  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.42648193 |
| epoch                          | 2          |
| evaluation/episode-length-avg  | 244        |
| evaluation/episode-length-max  | 326        |
| evaluation/episode-length-min  | 201        |
| evaluation/episode-length-std  | 40.9       |
| evaluation/return-average      | 299.0478   |
| evaluation/return-max          | 439.10916  |
| evaluation/return-min          | 96.69473   |
| evaluation/return-std          | 112.75183  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 0.683      |
| model/origin_ret               | 80         |
| model/penalty_ret              | 107        |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 32610      |
| perf/AverageLength             | 244        |
| perf/AverageReturn             | 299.0478   |
| perf/NormalizedReturn          | 0.0648     |
| Q-avg                          | 32.78291   |
| Q-std                          | 41.21398   |
| Q_loss                         | 18.364126  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 2          |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000169   |
| times/epoch_rollout_model      | 526        |
| times/evaluation_metrics       | 0.000611   |
| times/evaluation_paths         | 9.55       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 65.4       |
| timestep                       | 1000       |
| timesteps_total                | 3000       |
| train-steps                    | 3000       |
| training/Q/q1_loss             | 20.148836  |
| training/sac_pi/alpha          | 0.42659053 |
| training/sac_pi/alpha_loss     | -3.7583365 |
| training/sac_pi/logp_pi        | 8.020691   |
| training/sac_pi/pi_entropy     | 6.405637   |
| training/sac_pi/pi_global_norm | 1.9259393  |
| training/sac_pi/policy_loss    | -45.470398 |
| training/sac_pi/std            | 1.085789   |
| training/sac_pi/valid_num      | 3936.0     |
| training/sac_Q/q1              | 30.721884  |
| training/sac_Q/q2              | 31.958569  |
| training/sac_Q/q2_loss         | 20.22959   |
| training/sac_Q/q_global_norm   | 50.489902  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.32793003 |
| epoch                          | 3          |
| evaluation/episode-length-avg  | 206        |
| evaluation/episode-length-max  | 208        |
| evaluation/episode-length-min  | 203        |
| evaluation/episode-length-std  | 1.68       |
| evaluation/return-average      | 48.879395  |
| evaluation/return-max          | 52.862915  |
| evaluation/return-min          | 45.395454  |
| evaluation/return-std          | 2.2522142  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.14       |
| model/origin_ret               | 88.3       |
| model/penalty_ret              | 98.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 39073      |
| perf/AverageLength             | 206        |
| perf/AverageReturn             | 48.879395  |
| perf/NormalizedReturn          | 0.0103     |
| Q-avg                          | 42.788788  |
| Q-std                          | 49.123978  |
| Q_loss                         | 24.023878  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 3          |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000149   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000456   |
| times/evaluation_paths         | 7.73       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 66.6       |
| timestep                       | 1000       |
| timesteps_total                | 4000       |
| train-steps                    | 4000       |
| training/Q/q1_loss             | 22.241995  |
| training/sac_pi/alpha          | 0.3280136  |
| training/sac_pi/alpha_loss     | -4.7361655 |
| training/sac_pi/logp_pi        | 6.658259   |
| training/sac_pi/pi_entropy     | 6.031707   |
| training/sac_pi/pi_global_norm | 1.4531642  |
| training/sac_pi/policy_loss    | -56.38535  |
| training/sac_pi/std            | 0.9930318  |
| training/sac_pi/valid_num      | 4082.0     |
| training/sac_Q/q1              | 42.65963   |
| training/sac_Q/q2              | 44.02442   |
| training/sac_Q/q2_loss         | 22.198145  |
| training/sac_Q/q_global_norm   | 59.311157  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.2560699  |
| epoch                          | 4          |
| evaluation/episode-length-avg  | 277        |
| evaluation/episode-length-max  | 379        |
| evaluation/episode-length-min  | 214        |
| evaluation/episode-length-std  | 48.5       |
| evaluation/return-average      | 368.94763  |
| evaluation/return-max          | 522.2755   |
| evaluation/return-min          | 151.20573  |
| evaluation/return-std          | 114.88775  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.41       |
| model/origin_ret               | 83.5       |
| model/penalty_ret              | 91.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 43133      |
| perf/AverageLength             | 277        |
| perf/AverageReturn             | 368.94763  |
| perf/NormalizedReturn          | 0.08       |
| Q-avg                          | 50.066803  |
| Q-std                          | 51.64146   |
| Q_loss                         | 33.086376  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 4          |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000589   |
| times/evaluation_paths         | 11.5       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 68.3       |
| timestep                       | 1000       |
| timesteps_total                | 5000       |
| train-steps                    | 5000       |
| training/Q/q1_loss             | 31.147339  |
| training/sac_pi/alpha          | 0.2561288  |
| training/sac_pi/alpha_loss     | -4.183602  |
| training/sac_pi/logp_pi        | 6.347032   |
| training/sac_pi/pi_entropy     | 5.0965533  |
| training/sac_pi/pi_global_norm | 0.7875747  |
| training/sac_pi/policy_loss    | -60.952675 |
| training/sac_pi/std            | 0.8234419  |
| training/sac_pi/valid_num      | 4148.0     |
| training/sac_Q/q1              | 46.061756  |
| training/sac_Q/q2              | 47.356525  |
| training/sac_Q/q2_loss         | 30.95154   |
| training/sac_Q/q_global_norm   | 68.06616   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.20144212 |
| epoch                          | 5          |
| evaluation/episode-length-avg  | 227        |
| evaluation/episode-length-max  | 297        |
| evaluation/episode-length-min  | 187        |
| evaluation/episode-length-std  | 32         |
| evaluation/return-average      | 354.8333   |
| evaluation/return-max          | 426.35855  |
| evaluation/return-min          | 182.52614  |
| evaluation/return-std          | 61.607365  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.65       |
| model/origin_ret               | 87.7       |
| model/penalty_ret              | 91.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 43728      |
| perf/AverageLength             | 227        |
| perf/AverageReturn             | 354.8333   |
| perf/NormalizedReturn          | 0.0769     |
| Q-avg                          | 66.049065  |
| Q-std                          | 45.06651   |
| Q_loss                         | 30.600794  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 5          |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000252   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000465   |
| times/evaluation_paths         | 9.84       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 66.4       |
| timestep                       | 1000       |
| timesteps_total                | 6000       |
| train-steps                    | 6000       |
| training/Q/q1_loss             | 31.859165  |
| training/sac_pi/alpha          | 0.20148806 |
| training/sac_pi/alpha_loss     | -4.2011485 |
| training/sac_pi/logp_pi        | 2.8126006  |
| training/sac_pi/pi_entropy     | 4.541406   |
| training/sac_pi/pi_global_norm | 0.8313817  |
| training/sac_pi/policy_loss    | -75.220505 |
| training/sac_pi/std            | 0.62938464 |
| training/sac_pi/valid_num      | 4685.0     |
| training/sac_Q/q1              | 67.52196   |
| training/sac_Q/q2              | 67.85878   |
| training/sac_Q/q2_loss         | 31.74125   |
| training/sac_Q/q_global_norm   | 139.40172  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1613812  |
| epoch                          | 6          |
| evaluation/episode-length-avg  | 240        |
| evaluation/episode-length-max  | 244        |
| evaluation/episode-length-min  | 237        |
| evaluation/episode-length-std  | 2.02       |
| evaluation/return-average      | 121.187485 |
| evaluation/return-max          | 125.0071   |
| evaluation/return-min          | 119.02837  |
| evaluation/return-std          | 1.7846872  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.69       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 89.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 44763      |
| perf/AverageLength             | 240        |
| perf/AverageReturn             | 121.187485 |
| perf/NormalizedReturn          | 0.026      |
| Q-avg                          | 77.13501   |
| Q-std                          | 45.802704  |
| Q_loss                         | 33.08109   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 6          |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000477   |
| times/evaluation_paths         | 8.44       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 67         |
| timestep                       | 1000       |
| timesteps_total                | 7000       |
| train-steps                    | 7000       |
| training/Q/q1_loss             | 30.536953  |
| training/sac_pi/alpha          | 0.16141523 |
| training/sac_pi/alpha_loss     | -3.6274726 |
| training/sac_pi/logp_pi        | 2.839496   |
| training/sac_pi/pi_entropy     | 4.0210443  |
| training/sac_pi/pi_global_norm | 0.83929193 |
| training/sac_pi/policy_loss    | -84.6804   |
| training/sac_pi/std            | 0.55840075 |
| training/sac_pi/valid_num      | 4789.0     |
| training/sac_Q/q1              | 78.4259    |
| training/sac_Q/q2              | 78.321655  |
| training/sac_Q/q2_loss         | 30.700594  |
| training/sac_Q/q_global_norm   | 72.57022   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13370514 |
| epoch                          | 7          |
| evaluation/episode-length-avg  | 130        |
| evaluation/episode-length-max  | 133        |
| evaluation/episode-length-min  | 127        |
| evaluation/episode-length-std  | 2.2        |
| evaluation/return-average      | 284.72736  |
| evaluation/return-max          | 293.8236   |
| evaluation/return-min          | 278.64893  |
| evaluation/return-std          | 5.2771435  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.71       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 86.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45025      |
| perf/AverageLength             | 130        |
| perf/AverageReturn             | 284.72736  |
| perf/NormalizedReturn          | 0.0617     |
| Q-avg                          | 84.643105  |
| Q-std                          | 46.58685   |
| Q_loss                         | 31.309092  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 7          |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.00055    |
| times/evaluation_paths         | 4.28       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 66.6       |
| timestep                       | 1000       |
| timesteps_total                | 8000       |
| train-steps                    | 8000       |
| training/Q/q1_loss             | 27.99551   |
| training/sac_pi/alpha          | 0.13372727 |
| training/sac_pi/alpha_loss     | -2.2887955 |
| training/sac_pi/logp_pi        | 2.7527957  |
| training/sac_pi/pi_entropy     | 3.606678   |
| training/sac_pi/pi_global_norm | 0.8411888  |
| training/sac_pi/policy_loss    | -93.41241  |
| training/sac_pi/std            | 0.49163342 |
| training/sac_pi/valid_num      | 4900.0     |
| training/sac_Q/q1              | 89.112625  |
| training/sac_Q/q2              | 88.920616  |
| training/sac_Q/q2_loss         | 27.926882  |
| training/sac_Q/q_global_norm   | 117.86747  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.119263485 |
| epoch                          | 8           |
| evaluation/episode-length-avg  | 217         |
| evaluation/episode-length-max  | 276         |
| evaluation/episode-length-min  | 185         |
| evaluation/episode-length-std  | 25.8        |
| evaluation/return-average      | 455.65015   |
| evaluation/return-max          | 530.6498    |
| evaluation/return-min          | 384.31702   |
| evaluation/return-std          | 41.671837   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.56        |
| model/origin_ret               | 83.6        |
| model/penalty_ret              | 85.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 44364       |
| perf/AverageLength             | 217         |
| perf/AverageReturn             | 455.65015   |
| perf/NormalizedReturn          | 0.0989      |
| Q-avg                          | 95.16776    |
| Q-std                          | 52.31676    |
| Q_loss                         | 37.25958    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 8           |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000152    |
| times/epoch_rollout_model      | 516         |
| times/evaluation_metrics       | 0.000577    |
| times/evaluation_paths         | 7.11        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 68          |
| timestep                       | 1000        |
| timesteps_total                | 9000        |
| train-steps                    | 9000        |
| training/Q/q1_loss             | 28.828566   |
| training/sac_pi/alpha          | 0.119271055 |
| training/sac_pi/alpha_loss     | -0.14789006 |
| training/sac_pi/logp_pi        | 4.2353787   |
| training/sac_pi/pi_entropy     | 3.4652393   |
| training/sac_pi/pi_global_norm | 0.88667107  |
| training/sac_pi/policy_loss    | -109.90834  |
| training/sac_pi/std            | 0.49248886  |
| training/sac_pi/valid_num      | 4936.0      |
| training/sac_Q/q1              | 106.02295   |
| training/sac_Q/q2              | 105.92061   |
| training/sac_Q/q2_loss         | 28.98865    |
| training/sac_Q/q_global_norm   | 131.25615   |
---------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.110466234   |
| epoch                          | 9             |
| evaluation/episode-length-avg  | 64.1          |
| evaluation/episode-length-max  | 65            |
| evaluation/episode-length-min  | 64            |
| evaluation/episode-length-std  | 0.3           |
| evaluation/return-average      | 41.40789      |
| evaluation/return-max          | 44.944828     |
| evaluation/return-min          | 39.19597      |
| evaluation/return-std          | 1.4699353     |
| model/max_penalty              | 7.27          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 2.64          |
| model/origin_ret               | 88            |
| model/penalty_ret              | 86.8          |
| model/val_loss                 | 0.39125705    |
| model/valid_num                | 43157         |
| perf/AverageLength             | 64.1          |
| perf/AverageReturn             | 41.40789      |
| perf/NormalizedReturn          | 0.00867       |
| Q-avg                          | 105.92747     |
| Q-std                          | 53.76365      |
| Q_loss                         | 42.800873     |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 9             |
| times/epoch_after_hook         | 1.71e-06      |
| times/epoch_before_hook        | 0.0003        |
| times/epoch_rollout_model      | 501           |
| times/evaluation_metrics       | 0.000505      |
| times/evaluation_paths         | 2.27          |
| times/timestep_after_hook      | 0.00401       |
| times/timestep_before_hook     | 0.00819       |
| times/train                    | 67            |
| timestep                       | 1000          |
| timesteps_total                | 10000         |
| train-steps                    | 10000         |
| training/Q/q1_loss             | 42.14811      |
| training/sac_pi/alpha          | 0.11047458    |
| training/sac_pi/alpha_loss     | -0.0042779627 |
| training/sac_pi/logp_pi        | 4.5292068     |
| training/sac_pi/pi_entropy     | 3.279822      |
| training/sac_pi/pi_global_norm | 0.9776274     |
| training/sac_pi/policy_loss    | -110.01574    |
| training/sac_pi/std            | 0.48799664    |
| training/sac_pi/valid_num      | 4884.0        |
| training/sac_Q/q1              | 105.00879     |
| training/sac_Q/q2              | 105.097305    |
| training/sac_Q/q2_loss         | 42.158604     |
| training/sac_Q/q_global_norm   | 148.31586     |
-----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.116808854 |
| epoch                          | 10          |
| evaluation/episode-length-avg  | 167         |
| evaluation/episode-length-max  | 180         |
| evaluation/episode-length-min  | 158         |
| evaluation/episode-length-std  | 7.96        |
| evaluation/return-average      | 375.433     |
| evaluation/return-max          | 399.94348   |
| evaluation/return-min          | 361.19025   |
| evaluation/return-std          | 13.762321   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.62        |
| model/origin_ret               | 81.7        |
| model/penalty_ret              | 84.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45046       |
| perf/AverageLength             | 167         |
| perf/AverageReturn             | 375.433     |
| perf/NormalizedReturn          | 0.0814      |
| Q-avg                          | 110.432945  |
| Q-std                          | 52.97168    |
| Q_loss                         | 50.44366    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 10          |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 7.79e-05    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000553    |
| times/evaluation_paths         | 7.38        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 64.6        |
| timestep                       | 1000        |
| timesteps_total                | 11000       |
| train-steps                    | 11000       |
| training/Q/q1_loss             | 45.810173   |
| training/sac_pi/alpha          | 0.11681058  |
| training/sac_pi/alpha_loss     | -0.19331701 |
| training/sac_pi/logp_pi        | 3.3303192   |
| training/sac_pi/pi_entropy     | 3.372158    |
| training/sac_pi/pi_global_norm | 1.0038009   |
| training/sac_pi/policy_loss    | -112.86843  |
| training/sac_pi/std            | 0.4494631   |
| training/sac_pi/valid_num      | 4987.0      |
| training/sac_Q/q1              | 110.24259   |
| training/sac_Q/q2              | 110.436386  |
| training/sac_Q/q2_loss         | 46.065083   |
| training/sac_Q/q_global_norm   | 153.20175   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.12404951 |
| epoch                          | 11         |
| evaluation/episode-length-avg  | 173        |
| evaluation/episode-length-max  | 180        |
| evaluation/episode-length-min  | 170        |
| evaluation/episode-length-std  | 2.94       |
| evaluation/return-average      | 364.14917  |
| evaluation/return-max          | 370.7317   |
| evaluation/return-min          | 359.51132  |
| evaluation/return-std          | 3.3509512  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.62       |
| model/origin_ret               | 83.2       |
| model/penalty_ret              | 85.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45045      |
| perf/AverageLength             | 173        |
| perf/AverageReturn             | 364.14917  |
| perf/NormalizedReturn          | 0.079      |
| Q-avg                          | 117.05762  |
| Q-std                          | 56.912487  |
| Q_loss                         | 39.577095  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 11         |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000601   |
| times/evaluation_paths         | 7.65       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 62.7       |
| timestep                       | 1000       |
| timesteps_total                | 12000      |
| train-steps                    | 12000      |
| training/Q/q1_loss             | 46.609825  |
| training/sac_pi/alpha          | 0.12404258 |
| training/sac_pi/alpha_loss     | 0.20451097 |
| training/sac_pi/logp_pi        | 3.8293118  |
| training/sac_pi/pi_entropy     | 3.6293697  |
| training/sac_pi/pi_global_norm | 0.804383   |
| training/sac_pi/policy_loss    | -122.94113 |
| training/sac_pi/std            | 0.49213618 |
| training/sac_pi/valid_num      | 4953.0     |
| training/sac_Q/q1              | 119.0896   |
| training/sac_Q/q2              | 119.03628  |
| training/sac_Q/q2_loss         | 46.625908  |
| training/sac_Q/q_global_norm   | 259.8537   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.12404327  |
| epoch                          | 12          |
| evaluation/episode-length-avg  | 161         |
| evaluation/episode-length-max  | 186         |
| evaluation/episode-length-min  | 154         |
| evaluation/episode-length-std  | 8.99        |
| evaluation/return-average      | 284.71124   |
| evaluation/return-max          | 307.63586   |
| evaluation/return-min          | 277.6793    |
| evaluation/return-std          | 8.279764    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.79        |
| model/origin_ret               | 87.5        |
| model/penalty_ret              | 87.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 44752       |
| perf/AverageLength             | 161         |
| perf/AverageReturn             | 284.71124   |
| perf/NormalizedReturn          | 0.0617      |
| Q-avg                          | 125.29498   |
| Q-std                          | 54.999207   |
| Q_loss                         | 41.348103   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 12          |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000645    |
| times/evaluation_paths         | 6.93        |
| times/timestep_after_hook      | 0.00383     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 64.6        |
| timestep                       | 1000        |
| timesteps_total                | 13000       |
| train-steps                    | 13000       |
| training/Q/q1_loss             | 47.76057    |
| training/sac_pi/alpha          | 0.12405596  |
| training/sac_pi/alpha_loss     | -0.16225795 |
| training/sac_pi/logp_pi        | 5.0055003   |
| training/sac_pi/pi_entropy     | 3.7280822   |
| training/sac_pi/pi_global_norm | 1.2510852   |
| training/sac_pi/policy_loss    | -123.23234  |
| training/sac_pi/std            | 0.54513943  |
| training/sac_pi/valid_num      | 4841.0      |
| training/sac_Q/q1              | 116.64781   |
| training/sac_Q/q2              | 117.131546  |
| training/sac_Q/q2_loss         | 47.334427   |
| training/sac_Q/q_global_norm   | 254.53587   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.12643008 |
| epoch                          | 13         |
| evaluation/episode-length-avg  | 858        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 289        |
| evaluation/episode-length-std  | 283        |
| evaluation/return-average      | 915.7189   |
| evaluation/return-max          | 1012.4309  |
| evaluation/return-min          | 538.9962   |
| evaluation/return-std          | 186.0684   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.78       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 85.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45240      |
| perf/AverageLength             | 858        |
| perf/AverageReturn             | 915.7189   |
| perf/NormalizedReturn          | 0.199      |
| Q-avg                          | 122.86983  |
| Q-std                          | 59.753616  |
| Q_loss                         | 45.94172   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 13         |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.00026    |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000656   |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 67.1       |
| timestep                       | 1000       |
| timesteps_total                | 14000      |
| train-steps                    | 14000      |
| training/Q/q1_loss             | 48.91471   |
| training/sac_pi/alpha          | 0.12639041 |
| training/sac_pi/alpha_loss     | 0.23453179 |
| training/sac_pi/logp_pi        | 4.336001   |
| training/sac_pi/pi_entropy     | 3.446813   |
| training/sac_pi/pi_global_norm | 1.0779163  |
| training/sac_pi/policy_loss    | -130.87627 |
| training/sac_pi/std            | 0.48487923 |
| training/sac_pi/valid_num      | 4961.0     |
| training/sac_Q/q1              | 127.12334  |
| training/sac_Q/q2              | 127.59401  |
| training/sac_Q/q2_loss         | 48.746574  |
| training/sac_Q/q_global_norm   | 130.68076  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13439755 |
| epoch                          | 14         |
| evaluation/episode-length-avg  | 229        |
| evaluation/episode-length-max  | 247        |
| evaluation/episode-length-min  | 206        |
| evaluation/episode-length-std  | 13.5       |
| evaluation/return-average      | 488.30112  |
| evaluation/return-max          | 524.8896   |
| evaluation/return-min          | 369.21564  |
| evaluation/return-std          | 45.19215   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.75       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 85.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 44942      |
| perf/AverageLength             | 229        |
| perf/AverageReturn             | 488.30112  |
| perf/NormalizedReturn          | 0.106      |
| Q-avg                          | 127.94004  |
| Q-std                          | 63.152332  |
| Q_loss                         | 59.888493  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 14         |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000573   |
| times/evaluation_paths         | 7.51       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 67.4       |
| timestep                       | 1000       |
| timesteps_total                | 15000      |
| train-steps                    | 15000      |
| training/Q/q1_loss             | 53.881798  |
| training/sac_pi/alpha          | 0.13434024 |
| training/sac_pi/alpha_loss     | 0.18891692 |
| training/sac_pi/logp_pi        | 4.249457   |
| training/sac_pi/pi_entropy     | 3.7848976  |
| training/sac_pi/pi_global_norm | 0.9545195  |
| training/sac_pi/policy_loss    | -135.1179  |
| training/sac_pi/std            | 0.5066366  |
| training/sac_pi/valid_num      | 4911.0     |
| training/sac_Q/q1              | 130.24162  |
| training/sac_Q/q2              | 130.29272  |
| training/sac_Q/q2_loss         | 53.517136  |
| training/sac_Q/q_global_norm   | 202.33421  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.12532662  |
| epoch                          | 15          |
| evaluation/episode-length-avg  | 27.9        |
| evaluation/episode-length-max  | 28          |
| evaluation/episode-length-min  | 27          |
| evaluation/episode-length-std  | 0.3         |
| evaluation/return-average      | 21.363646   |
| evaluation/return-max          | 21.98546    |
| evaluation/return-min          | 19.88004    |
| evaluation/return-std          | 0.5528474   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.85        |
| model/origin_ret               | 88.9        |
| model/penalty_ret              | 85.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 44375       |
| perf/AverageLength             | 27.9        |
| perf/AverageReturn             | 21.363646   |
| perf/NormalizedReturn          | 0.0043      |
| Q-avg                          | 131.78014   |
| Q-std                          | 64.68949    |
| Q_loss                         | 60.260384   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 15          |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000157    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000456    |
| times/evaluation_paths         | 1.19        |
| times/timestep_after_hook      | 0.00412     |
| times/timestep_before_hook     | 0.0084      |
| times/train                    | 70.5        |
| timestep                       | 1000        |
| timesteps_total                | 16000       |
| train-steps                    | 16000       |
| training/Q/q1_loss             | 53.08648    |
| training/sac_pi/alpha          | 0.12534767  |
| training/sac_pi/alpha_loss     | -0.04936075 |
| training/sac_pi/logp_pi        | 3.628994    |
| training/sac_pi/pi_entropy     | 3.7121024   |
| training/sac_pi/pi_global_norm | 2.9314837   |
| training/sac_pi/policy_loss    | -140.89864  |
| training/sac_pi/std            | 0.48479348  |
| training/sac_pi/valid_num      | 4998.0      |
| training/sac_Q/q1              | 137.57921   |
| training/sac_Q/q2              | 137.9849    |
| training/sac_Q/q2_loss         | 53.07653    |
| training/sac_Q/q_global_norm   | 327.09155   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.12692797 |
| epoch                          | 16         |
| evaluation/episode-length-avg  | 139        |
| evaluation/episode-length-max  | 143        |
| evaluation/episode-length-min  | 136        |
| evaluation/episode-length-std  | 1.9        |
| evaluation/return-average      | 20.646732  |
| evaluation/return-max          | 23.54921   |
| evaluation/return-min          | 18.915924  |
| evaluation/return-std          | 1.3064067  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.54       |
| model/origin_ret               | 80.9       |
| model/penalty_ret              | 83.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45112      |
| perf/AverageLength             | 139        |
| perf/AverageReturn             | 20.646732  |
| perf/NormalizedReturn          | 0.00414    |
| Q-avg                          | 139.08327  |
| Q-std                          | 61.701912  |
| Q_loss                         | 62.743446  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 16         |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 8.44e-05   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000509   |
| times/evaluation_paths         | 4.29       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 59.5       |
| timestep                       | 1000       |
| timesteps_total                | 17000      |
| train-steps                    | 17000      |
| training/Q/q1_loss             | 67.74522   |
| training/sac_pi/alpha          | 0.12690552 |
| training/sac_pi/alpha_loss     | 0.1923392  |
| training/sac_pi/logp_pi        | 4.220594   |
| training/sac_pi/pi_entropy     | 3.6980553  |
| training/sac_pi/pi_global_norm | 0.7456298  |
| training/sac_pi/policy_loss    | -139.8911  |
| training/sac_pi/std            | 0.5032903  |
| training/sac_pi/valid_num      | 4945.0     |
| training/sac_Q/q1              | 135.64946  |
| training/sac_Q/q2              | 135.87367  |
| training/sac_Q/q2_loss         | 67.47935   |
| training/sac_Q/q_global_norm   | 287.9706   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.13787417   |
| epoch                          | 17           |
| evaluation/episode-length-avg  | 237          |
| evaluation/episode-length-max  | 460          |
| evaluation/episode-length-min  | 152          |
| evaluation/episode-length-std  | 86.9         |
| evaluation/return-average      | 227.61934    |
| evaluation/return-max          | 733.6151     |
| evaluation/return-min          | 35.7061      |
| evaluation/return-std          | 214.63094    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.73         |
| model/origin_ret               | 84.5         |
| model/penalty_ret              | 85           |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45047        |
| perf/AverageLength             | 237          |
| perf/AverageReturn             | 227.61934    |
| perf/NormalizedReturn          | 0.0492       |
| Q-avg                          | 148.50104    |
| Q-std                          | 61.43304     |
| Q_loss                         | 58.26334     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 17           |
| times/epoch_after_hook         | 1.76e-06     |
| times/epoch_before_hook        | 0.000261     |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.000616     |
| times/evaluation_paths         | 7.42         |
| times/timestep_after_hook      | 0.00386      |
| times/timestep_before_hook     | 0.00813      |
| times/train                    | 58.4         |
| timestep                       | 1000         |
| timesteps_total                | 18000        |
| train-steps                    | 18000        |
| training/Q/q1_loss             | 61.890068    |
| training/sac_pi/alpha          | 0.13789293   |
| training/sac_pi/alpha_loss     | -0.052139483 |
| training/sac_pi/logp_pi        | 5.467393     |
| training/sac_pi/pi_entropy     | 3.7240844    |
| training/sac_pi/pi_global_norm | 1.0659924    |
| training/sac_pi/policy_loss    | -145.87358   |
| training/sac_pi/std            | 0.5476306    |
| training/sac_pi/valid_num      | 4789.0       |
| training/sac_Q/q1              | 135.91333    |
| training/sac_Q/q2              | 136.92532    |
| training/sac_Q/q2_loss         | 61.885212    |
| training/sac_Q/q_global_norm   | 204.06813    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14043202 |
| epoch                          | 18         |
| evaluation/episode-length-avg  | 413        |
| evaluation/episode-length-max  | 597        |
| evaluation/episode-length-min  | 191        |
| evaluation/episode-length-std  | 128        |
| evaluation/return-average      | 1103.4382  |
| evaluation/return-max          | 2208.3105  |
| evaluation/return-min          | 153.7805   |
| evaluation/return-std          | 906.36694  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.82       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 85         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45208      |
| perf/AverageLength             | 413        |
| perf/AverageReturn             | 1103.4382  |
| perf/NormalizedReturn          | 0.24       |
| Q-avg                          | 143.65482  |
| Q-std                          | 72.25782   |
| Q_loss                         | 61.30439   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 18         |
| times/epoch_after_hook         | 9.88e-06   |
| times/epoch_before_hook        | 0.000144   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000701   |
| times/evaluation_paths         | 14.5       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 58.6       |
| timestep                       | 1000       |
| timesteps_total                | 19000      |
| train-steps                    | 19000      |
| training/Q/q1_loss             | 54.08291   |
| training/sac_pi/alpha          | 0.14039278 |
| training/sac_pi/alpha_loss     | 0.4208757  |
| training/sac_pi/logp_pi        | 4.301083   |
| training/sac_pi/pi_entropy     | 3.9444318  |
| training/sac_pi/pi_global_norm | 0.70212036 |
| training/sac_pi/policy_loss    | -147.27997 |
| training/sac_pi/std            | 0.525348   |
| training/sac_pi/valid_num      | 4960.0     |
| training/sac_Q/q1              | 143.09247  |
| training/sac_Q/q2              | 143.40416  |
| training/sac_Q/q2_loss         | 53.907814  |
| training/sac_Q/q_global_norm   | 210.14084  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.135339    |
| epoch                          | 19          |
| evaluation/episode-length-avg  | 146         |
| evaluation/episode-length-max  | 160         |
| evaluation/episode-length-min  | 136         |
| evaluation/episode-length-std  | 9.19        |
| evaluation/return-average      | 352.87054   |
| evaluation/return-max          | 414.01016   |
| evaluation/return-min          | 304.351     |
| evaluation/return-std          | 42.596367   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 89.1        |
| model/penalty_ret              | 86.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45034       |
| perf/AverageLength             | 146         |
| perf/AverageReturn             | 352.87054   |
| perf/NormalizedReturn          | 0.0765      |
| Q-avg                          | 143.50249   |
| Q-std                          | 66.92449    |
| Q_loss                         | 70.91999    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 19          |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000526    |
| times/evaluation_paths         | 4.5         |
| times/timestep_after_hook      | 0.00382     |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 60.3        |
| timestep                       | 1000        |
| timesteps_total                | 20000       |
| train-steps                    | 20000       |
| training/Q/q1_loss             | 65.79306    |
| training/sac_pi/alpha          | 0.1353346   |
| training/sac_pi/alpha_loss     | -0.45661354 |
| training/sac_pi/logp_pi        | 4.1697316   |
| training/sac_pi/pi_entropy     | 4.12015     |
| training/sac_pi/pi_global_norm | 1.0519948   |
| training/sac_pi/policy_loss    | -142.11476  |
| training/sac_pi/std            | 0.55795956  |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 138.79697   |
| training/sac_Q/q2              | 139.38242   |
| training/sac_Q/q2_loss         | 66.04079    |
| training/sac_Q/q_global_norm   | 223.36807   |
---------------------------------------------------------------------------------
[WARN] 20 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.13383816  |
| epoch                          | 20          |
| evaluation/episode-length-avg  | 178         |
| evaluation/episode-length-max  | 194         |
| evaluation/episode-length-min  | 153         |
| evaluation/episode-length-std  | 10.7        |
| evaluation/return-average      | 333.24692   |
| evaluation/return-max          | 353.61234   |
| evaluation/return-min          | 296.59238   |
| evaluation/return-std          | 14.925811   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.8         |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 85.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45514       |
| perf/AverageLength             | 178         |
| perf/AverageReturn             | 333.24692   |
| perf/NormalizedReturn          | 0.0722      |
| Q-avg                          | 138.42996   |
| Q-std                          | 71.41468    |
| Q_loss                         | 75.02217    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 20          |
| times/epoch_after_hook         | 1.95e-06    |
| times/epoch_before_hook        | 8.19e-05    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000613    |
| times/evaluation_paths         | 5.84        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 59.1        |
| timestep                       | 1000        |
| timesteps_total                | 21000       |
| train-steps                    | 21000       |
| training/Q/q1_loss             | 69.60687    |
| training/sac_pi/alpha          | 0.13382734  |
| training/sac_pi/alpha_loss     | 0.023208942 |
| training/sac_pi/logp_pi        | 4.157182    |
| training/sac_pi/pi_entropy     | 3.9261985   |
| training/sac_pi/pi_global_norm | 1.0661561   |
| training/sac_pi/policy_loss    | -149.34048  |
| training/sac_pi/std            | 0.5326716   |
| training/sac_pi/valid_num      | 4951.0      |
| training/sac_Q/q1              | 144.62965   |
| training/sac_Q/q2              | 145.089     |
| training/sac_Q/q2_loss         | 69.6295     |
| training/sac_Q/q_global_norm   | 317.11404   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1403389    |
| epoch                          | 21           |
| evaluation/episode-length-avg  | 681          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 112          |
| evaluation/episode-length-std  | 331          |
| evaluation/return-average      | 734.58215    |
| evaluation/return-max          | 1046.8579    |
| evaluation/return-min          | 177.27042    |
| evaluation/return-std          | 328.44794    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.83         |
| model/origin_ret               | 85.9         |
| model/penalty_ret              | 86.5         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45423        |
| perf/AverageLength             | 681          |
| perf/AverageReturn             | 734.58215    |
| perf/NormalizedReturn          | 0.16         |
| Q-avg                          | 149.81819    |
| Q-std                          | 66.47814     |
| Q_loss                         | 65.28709     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 21           |
| times/epoch_after_hook         | 2.26e-06     |
| times/epoch_before_hook        | 0.000251     |
| times/epoch_rollout_model      | 487          |
| times/evaluation_metrics       | 0.000531     |
| times/evaluation_paths         | 22.8         |
| times/timestep_after_hook      | 0.00385      |
| times/timestep_before_hook     | 0.00819      |
| times/train                    | 58.4         |
| timestep                       | 1000         |
| timesteps_total                | 22000        |
| train-steps                    | 22000        |
| training/Q/q1_loss             | 68.32426     |
| training/sac_pi/alpha          | 0.14033693   |
| training/sac_pi/alpha_loss     | -0.016703552 |
| training/sac_pi/logp_pi        | 4.099945     |
| training/sac_pi/pi_entropy     | 3.8558755    |
| training/sac_pi/pi_global_norm | 1.1080092    |
| training/sac_pi/policy_loss    | -150.39375   |
| training/sac_pi/std            | 0.5152882    |
| training/sac_pi/valid_num      | 4948.0       |
| training/sac_Q/q1              | 146.62119    |
| training/sac_Q/q2              | 147.18533    |
| training/sac_Q/q2_loss         | 68.19461     |
| training/sac_Q/q_global_norm   | 370.70883    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13804154 |
| epoch                          | 22         |
| evaluation/episode-length-avg  | 150        |
| evaluation/episode-length-max  | 156        |
| evaluation/episode-length-min  | 145        |
| evaluation/episode-length-std  | 3.67       |
| evaluation/return-average      | 294.34216  |
| evaluation/return-max          | 322.79535  |
| evaluation/return-min          | 276.8203   |
| evaluation/return-std          | 16.924736  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.81       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 85         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45130      |
| perf/AverageLength             | 150        |
| perf/AverageReturn             | 294.34216  |
| perf/NormalizedReturn          | 0.0638     |
| Q-avg                          | 157.63931  |
| Q-std                          | 71.087074  |
| Q_loss                         | 73.8326    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 22         |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000739   |
| times/evaluation_paths         | 4.94       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 59.5       |
| timestep                       | 1000       |
| timesteps_total                | 23000      |
| train-steps                    | 23000      |
| training/Q/q1_loss             | 73.59338   |
| training/sac_pi/alpha          | 0.1380346  |
| training/sac_pi/alpha_loss     | -0.1617524 |
| training/sac_pi/logp_pi        | 4.0589843  |
| training/sac_pi/pi_entropy     | 3.940002   |
| training/sac_pi/pi_global_norm | 0.87363267 |
| training/sac_pi/policy_loss    | -164.14421 |
| training/sac_pi/std            | 0.5294188  |
| training/sac_pi/valid_num      | 4934.0     |
| training/sac_Q/q1              | 158.63068  |
| training/sac_Q/q2              | 158.75806  |
| training/sac_Q/q2_loss         | 73.079254  |
| training/sac_Q/q_global_norm   | 226.47159  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14697607 |
| epoch                          | 23         |
| evaluation/episode-length-avg  | 113        |
| evaluation/episode-length-max  | 121        |
| evaluation/episode-length-min  | 108        |
| evaluation/episode-length-std  | 3.89       |
| evaluation/return-average      | 221.4448   |
| evaluation/return-max          | 250.7627   |
| evaluation/return-min          | 210.10252  |
| evaluation/return-std          | 11.028258  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.51       |
| model/origin_ret               | 79.5       |
| model/penalty_ret              | 83         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45198      |
| perf/AverageLength             | 113        |
| perf/AverageReturn             | 221.4448   |
| perf/NormalizedReturn          | 0.0479     |
| Q-avg                          | 154.32832  |
| Q-std                          | 69.252594  |
| Q_loss                         | 69.98199   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 23         |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000469   |
| times/evaluation_paths         | 3.47       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 24000      |
| train-steps                    | 24000      |
| training/Q/q1_loss             | 91.751656  |
| training/sac_pi/alpha          | 0.14696889 |
| training/sac_pi/alpha_loss     | 0.07271738 |
| training/sac_pi/logp_pi        | 5.0736823  |
| training/sac_pi/pi_entropy     | 4.0098786  |
| training/sac_pi/pi_global_norm | 1.048673   |
| training/sac_pi/policy_loss    | -154.9548  |
| training/sac_pi/std            | 0.5563108  |
| training/sac_pi/valid_num      | 4856.0     |
| training/sac_Q/q1              | 146.7468   |
| training/sac_Q/q2              | 147.60861  |
| training/sac_Q/q2_loss         | 92.00421   |
| training/sac_Q/q_global_norm   | 314.90042  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15438446  |
| epoch                          | 24          |
| evaluation/episode-length-avg  | 268         |
| evaluation/episode-length-max  | 475         |
| evaluation/episode-length-min  | 194         |
| evaluation/episode-length-std  | 83.9        |
| evaluation/return-average      | 317.62857   |
| evaluation/return-max          | 526.5007    |
| evaluation/return-min          | 242.20956   |
| evaluation/return-std          | 85.12427    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.83        |
| model/origin_ret               | 87.7        |
| model/penalty_ret              | 86.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45129       |
| perf/AverageLength             | 268         |
| perf/AverageReturn             | 317.62857   |
| perf/NormalizedReturn          | 0.0688      |
| Q-avg                          | 157.1222    |
| Q-std                          | 64.72673    |
| Q_loss                         | 53.500126   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 24          |
| times/epoch_after_hook         | 1.98e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000463    |
| times/evaluation_paths         | 8.56        |
| times/timestep_after_hook      | 0.00385     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 25000       |
| train-steps                    | 25000       |
| training/Q/q1_loss             | 63.539696   |
| training/sac_pi/alpha          | 0.1544326   |
| training/sac_pi/alpha_loss     | -0.30177608 |
| training/sac_pi/logp_pi        | 3.5041587   |
| training/sac_pi/pi_entropy     | 3.7956123   |
| training/sac_pi/pi_global_norm | 0.93517107  |
| training/sac_pi/policy_loss    | -161.227    |
| training/sac_pi/std            | 0.49933916  |
| training/sac_pi/valid_num      | 4984.0      |
| training/sac_Q/q1              | 157.61172   |
| training/sac_Q/q2              | 157.70236   |
| training/sac_Q/q2_loss         | 63.972004   |
| training/sac_Q/q_global_norm   | 268.56555   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1493712   |
| epoch                          | 25          |
| evaluation/episode-length-avg  | 501         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 151         |
| evaluation/episode-length-std  | 407         |
| evaluation/return-average      | 711.4906    |
| evaluation/return-max          | 1194.6877   |
| evaluation/return-min          | 387.8352    |
| evaluation/return-std          | 392.3494    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.83        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 84.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45254       |
| perf/AverageLength             | 501         |
| perf/AverageReturn             | 711.4906    |
| perf/NormalizedReturn          | 0.155       |
| Q-avg                          | 159.73318   |
| Q-std                          | 67.34344    |
| Q_loss                         | 78.314476   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 25          |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.00025     |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000793    |
| times/evaluation_paths         | 15.8        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 62          |
| timestep                       | 1000        |
| timesteps_total                | 26000       |
| train-steps                    | 26000       |
| training/Q/q1_loss             | 76.88877    |
| training/sac_pi/alpha          | 0.14940818  |
| training/sac_pi/alpha_loss     | -0.39055106 |
| training/sac_pi/logp_pi        | 4.3067503   |
| training/sac_pi/pi_entropy     | 3.8303533   |
| training/sac_pi/pi_global_norm | 1.2586358   |
| training/sac_pi/policy_loss    | -160.80518  |
| training/sac_pi/std            | 0.5225968   |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 156.54602   |
| training/sac_Q/q2              | 156.75636   |
| training/sac_Q/q2_loss         | 76.702034   |
| training/sac_Q/q_global_norm   | 337.83325   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1501372  |
| epoch                          | 26         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4794.6143  |
| evaluation/return-max          | 4864.749   |
| evaluation/return-min          | 4701.864   |
| evaluation/return-std          | 52.04452   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.8        |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 85.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45276      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4794.6143  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 148.60727  |
| Q-std                          | 80.703865  |
| Q_loss                         | 89.08482   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 26         |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000157   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000514   |
| times/evaluation_paths         | 33.6       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 58.5       |
| timestep                       | 1000       |
| timesteps_total                | 27000      |
| train-steps                    | 27000      |
| training/Q/q1_loss             | 72.73199   |
| training/sac_pi/alpha          | 0.15017411 |
| training/sac_pi/alpha_loss     | -0.5328344 |
| training/sac_pi/logp_pi        | 4.253484   |
| training/sac_pi/pi_entropy     | 3.8166115  |
| training/sac_pi/pi_global_norm | 1.294093   |
| training/sac_pi/policy_loss    | -163.3522  |
| training/sac_pi/std            | 0.52189034 |
| training/sac_pi/valid_num      | 4928.0     |
| training/sac_Q/q1              | 157.81113  |
| training/sac_Q/q2              | 158.40488  |
| training/sac_Q/q2_loss         | 71.959076  |
| training/sac_Q/q_global_norm   | 339.3698   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1604885  |
| epoch                          | 27         |
| evaluation/episode-length-avg  | 289        |
| evaluation/episode-length-max  | 349        |
| evaluation/episode-length-min  | 252        |
| evaluation/episode-length-std  | 27.6       |
| evaluation/return-average      | 464.0918   |
| evaluation/return-max          | 526.66833  |
| evaluation/return-min          | 427.1076   |
| evaluation/return-std          | 28.179508  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.75       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 85         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45274      |
| perf/AverageLength             | 289        |
| perf/AverageReturn             | 464.0918   |
| perf/NormalizedReturn          | 0.101      |
| Q-avg                          | 149.99228  |
| Q-std                          | 79.89009   |
| Q_loss                         | 79.367645  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 27         |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000116   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.00058    |
| times/evaluation_paths         | 10.4       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 58.8       |
| timestep                       | 1000       |
| timesteps_total                | 28000      |
| train-steps                    | 28000      |
| training/Q/q1_loss             | 86.25445   |
| training/sac_pi/alpha          | 0.16053632 |
| training/sac_pi/alpha_loss     | -0.1706798 |
| training/sac_pi/logp_pi        | 5.528601   |
| training/sac_pi/pi_entropy     | 3.8905048  |
| training/sac_pi/pi_global_norm | 1.2457302  |
| training/sac_pi/policy_loss    | -154.91359 |
| training/sac_pi/std            | 0.5707734  |
| training/sac_pi/valid_num      | 4832.0     |
| training/sac_Q/q1              | 146.50237  |
| training/sac_Q/q2              | 147.69852  |
| training/sac_Q/q2_loss         | 86.884415  |
| training/sac_Q/q_global_norm   | 316.39838  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15035887  |
| epoch                          | 28          |
| evaluation/episode-length-avg  | 262         |
| evaluation/episode-length-max  | 288         |
| evaluation/episode-length-min  | 217         |
| evaluation/episode-length-std  | 24.9        |
| evaluation/return-average      | 377.86786   |
| evaluation/return-max          | 401.6648    |
| evaluation/return-min          | 316.7083    |
| evaluation/return-std          | 27.24373    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.79        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 83.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45449       |
| perf/AverageLength             | 262         |
| perf/AverageReturn             | 377.86786   |
| perf/NormalizedReturn          | 0.082       |
| Q-avg                          | 155.02237   |
| Q-std                          | 73.84287    |
| Q_loss                         | 76.91785    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 28          |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000139    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000559    |
| times/evaluation_paths         | 9.53        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 57.8        |
| timestep                       | 1000        |
| timesteps_total                | 29000       |
| train-steps                    | 29000       |
| training/Q/q1_loss             | 75.83129    |
| training/sac_pi/alpha          | 0.1503786   |
| training/sac_pi/alpha_loss     | -0.07227576 |
| training/sac_pi/logp_pi        | 5.0765524   |
| training/sac_pi/pi_entropy     | 3.9555893   |
| training/sac_pi/pi_global_norm | 0.7713651   |
| training/sac_pi/policy_loss    | -157.72133  |
| training/sac_pi/std            | 0.5726224   |
| training/sac_pi/valid_num      | 4880.0      |
| training/sac_Q/q1              | 150.13867   |
| training/sac_Q/q2              | 151.07147   |
| training/sac_Q/q2_loss         | 75.95388    |
| training/sac_Q/q_global_norm   | 256.359     |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14416282 |
| epoch                          | 29         |
| evaluation/episode-length-avg  | 333        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 222        |
| evaluation/episode-length-std  | 224        |
| evaluation/return-average      | 975.1317   |
| evaluation/return-max          | 4404.509   |
| evaluation/return-min          | 548.746    |
| evaluation/return-std          | 1143.8156  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.85       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 84.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45587      |
| perf/AverageLength             | 333        |
| perf/AverageReturn             | 975.1317   |
| perf/NormalizedReturn          | 0.212      |
| Q-avg                          | 148.36282  |
| Q-std                          | 77.43588   |
| Q_loss                         | 72.99237   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 29         |
| times/epoch_after_hook         | 2.08e-06   |
| times/epoch_before_hook        | 0.00025    |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000482   |
| times/evaluation_paths         | 11.9       |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 30000      |
| train-steps                    | 30000      |
| training/Q/q1_loss             | 88.36879   |
| training/sac_pi/alpha          | 0.14415471 |
| training/sac_pi/alpha_loss     | 0.5903178  |
| training/sac_pi/logp_pi        | 4.7535324  |
| training/sac_pi/pi_entropy     | 3.9635506  |
| training/sac_pi/pi_global_norm | 1.3896807  |
| training/sac_pi/policy_loss    | -160.3051  |
| training/sac_pi/std            | 0.54978025 |
| training/sac_pi/valid_num      | 4942.0     |
| training/sac_Q/q1              | 154.7609   |
| training/sac_Q/q2              | 155.07008  |
| training/sac_Q/q2_loss         | 88.61692   |
| training/sac_Q/q_global_norm   | 322.4079   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14861993  |
| epoch                          | 30          |
| evaluation/episode-length-avg  | 118         |
| evaluation/episode-length-max  | 120         |
| evaluation/episode-length-min  | 116         |
| evaluation/episode-length-std  | 1.1         |
| evaluation/return-average      | 279.30756   |
| evaluation/return-max          | 292.06793   |
| evaluation/return-min          | 273.3392    |
| evaluation/return-std          | 5.048731    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.68        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 86.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45490       |
| perf/AverageLength             | 118         |
| perf/AverageReturn             | 279.30756   |
| perf/NormalizedReturn          | 0.0605      |
| Q-avg                          | 161.61807   |
| Q-std                          | 72.46918    |
| Q_loss                         | 85.400925   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 30          |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000508    |
| times/evaluation_paths         | 3.67        |
| times/timestep_after_hook      | 0.00382     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 59.5        |
| timestep                       | 1000        |
| timesteps_total                | 31000       |
| train-steps                    | 31000       |
| training/Q/q1_loss             | 83.695145   |
| training/sac_pi/alpha          | 0.1486382   |
| training/sac_pi/alpha_loss     | -0.19701444 |
| training/sac_pi/logp_pi        | 4.367171    |
| training/sac_pi/pi_entropy     | 4.0099325   |
| training/sac_pi/pi_global_norm | 0.939624    |
| training/sac_pi/policy_loss    | -162.65108  |
| training/sac_pi/std            | 0.5471591   |
| training/sac_pi/valid_num      | 4941.0      |
| training/sac_Q/q1              | 157.00894   |
| training/sac_Q/q2              | 156.98372   |
| training/sac_Q/q2_loss         | 84.13886    |
| training/sac_Q/q_global_norm   | 216.13963   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15649566  |
| epoch                          | 31          |
| evaluation/episode-length-avg  | 185         |
| evaluation/episode-length-max  | 189         |
| evaluation/episode-length-min  | 177         |
| evaluation/episode-length-std  | 4.61        |
| evaluation/return-average      | 472.36578   |
| evaluation/return-max          | 492.42105   |
| evaluation/return-min          | 458.81003   |
| evaluation/return-std          | 10.03836    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.77        |
| model/origin_ret               | 82.9        |
| model/penalty_ret              | 83.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45509       |
| perf/AverageLength             | 185         |
| perf/AverageReturn             | 472.36578   |
| perf/NormalizedReturn          | 0.103       |
| Q-avg                          | 168.91508   |
| Q-std                          | 73.60074    |
| Q_loss                         | 97.67417    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 31          |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000146    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000474    |
| times/evaluation_paths         | 5.8         |
| times/timestep_after_hook      | 0.00382     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 58.5        |
| timestep                       | 1000        |
| timesteps_total                | 32000       |
| train-steps                    | 32000       |
| training/Q/q1_loss             | 94.84592    |
| training/sac_pi/alpha          | 0.15653645  |
| training/sac_pi/alpha_loss     | -0.19547755 |
| training/sac_pi/logp_pi        | 4.54791     |
| training/sac_pi/pi_entropy     | 4.1604834   |
| training/sac_pi/pi_global_norm | 1.0596681   |
| training/sac_pi/policy_loss    | -168.06833  |
| training/sac_pi/std            | 0.57199377  |
| training/sac_pi/valid_num      | 4928.0      |
| training/sac_Q/q1              | 161.64087   |
| training/sac_Q/q2              | 162.09192   |
| training/sac_Q/q2_loss         | 95.24441    |
| training/sac_Q/q_global_norm   | 398.7489    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16411535 |
| epoch                          | 32         |
| evaluation/episode-length-avg  | 147        |
| evaluation/episode-length-max  | 173        |
| evaluation/episode-length-min  | 133        |
| evaluation/episode-length-std  | 16.3       |
| evaluation/return-average      | 273.0331   |
| evaluation/return-max          | 365.35596  |
| evaluation/return-min          | 230.66402  |
| evaluation/return-std          | 58.166862  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.86       |
| model/origin_ret               | 86.8       |
| model/penalty_ret              | 85.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45208      |
| perf/AverageLength             | 147        |
| perf/AverageReturn             | 273.0331   |
| perf/NormalizedReturn          | 0.0591     |
| Q-avg                          | 165.72095  |
| Q-std                          | 78.39547   |
| Q_loss                         | 80.68758   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 32         |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000517   |
| times/evaluation_paths         | 4.51       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 58         |
| timestep                       | 1000       |
| timesteps_total                | 33000      |
| train-steps                    | 33000      |
| training/Q/q1_loss             | 91.37363   |
| training/sac_pi/alpha          | 0.16407143 |
| training/sac_pi/alpha_loss     | 0.17109737 |
| training/sac_pi/logp_pi        | 5.1376567  |
| training/sac_pi/pi_entropy     | 4.049554   |
| training/sac_pi/pi_global_norm | 1.4751773  |
| training/sac_pi/policy_loss    | -169.18433 |
| training/sac_pi/std            | 0.56855756 |
| training/sac_pi/valid_num      | 4912.0     |
| training/sac_Q/q1              | 161.87769  |
| training/sac_Q/q2              | 162.9067   |
| training/sac_Q/q2_loss         | 91.918884  |
| training/sac_Q/q_global_norm   | 244.84573  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15914184 |
| epoch                          | 33         |
| evaluation/episode-length-avg  | 221        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 128        |
| evaluation/episode-length-std  | 260        |
| evaluation/return-average      | 863.2806   |
| evaluation/return-max          | 4758.5547  |
| evaluation/return-min          | 397.29852  |
| evaluation/return-std          | 1298.6188  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 83.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45391      |
| perf/AverageLength             | 221        |
| perf/AverageReturn             | 863.2806   |
| perf/NormalizedReturn          | 0.188      |
| Q-avg                          | 154.93958  |
| Q-std                          | 77.98608   |
| Q_loss                         | 101.79516  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 33         |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000248   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000543   |
| times/evaluation_paths         | 6.77       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 34000      |
| train-steps                    | 34000      |
| training/Q/q1_loss             | 79.9008    |
| training/sac_pi/alpha          | 0.15914914 |
| training/sac_pi/alpha_loss     | -0.1319037 |
| training/sac_pi/logp_pi        | 3.9174914  |
| training/sac_pi/pi_entropy     | 3.9429657  |
| training/sac_pi/pi_global_norm | 1.583726   |
| training/sac_pi/policy_loss    | -170.41774 |
| training/sac_pi/std            | 0.52695495 |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 164.98093  |
| training/sac_Q/q2              | 165.59978  |
| training/sac_Q/q2_loss         | 80.32476   |
| training/sac_Q/q_global_norm   | 303.1073   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16574527 |
| epoch                          | 34         |
| evaluation/episode-length-avg  | 152        |
| evaluation/episode-length-max  | 157        |
| evaluation/episode-length-min  | 146        |
| evaluation/episode-length-std  | 3.37       |
| evaluation/return-average      | 351.99414  |
| evaluation/return-max          | 372.50012  |
| evaluation/return-min          | 338.93494  |
| evaluation/return-std          | 10.195813  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.83       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 83.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45852      |
| perf/AverageLength             | 152        |
| perf/AverageReturn             | 351.99414  |
| perf/NormalizedReturn          | 0.0763     |
| Q-avg                          | 176.46883  |
| Q-std                          | 71.22197   |
| Q_loss                         | 83.16222   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 34         |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 6.92e-05   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000463   |
| times/evaluation_paths         | 4.58       |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.00804    |
| times/train                    | 59.7       |
| timestep                       | 1000       |
| timesteps_total                | 35000      |
| train-steps                    | 35000      |
| training/Q/q1_loss             | 85.6747    |
| training/sac_pi/alpha          | 0.16571122 |
| training/sac_pi/alpha_loss     | -0.3907907 |
| training/sac_pi/logp_pi        | 4.514081   |
| training/sac_pi/pi_entropy     | 4.2448816  |
| training/sac_pi/pi_global_norm | 1.4852656  |
| training/sac_pi/policy_loss    | -177.39484 |
| training/sac_pi/std            | 0.58388424 |
| training/sac_pi/valid_num      | 4914.0     |
| training/sac_Q/q1              | 170.04568  |
| training/sac_Q/q2              | 170.71786  |
| training/sac_Q/q2_loss         | 86.22403   |
| training/sac_Q/q_global_norm   | 245.8252   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15892425  |
| epoch                          | 35          |
| evaluation/episode-length-avg  | 493         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 167         |
| evaluation/episode-length-std  | 332         |
| evaluation/return-average      | 1842.3223   |
| evaluation/return-max          | 4186.8105   |
| evaluation/return-min          | 374.69647   |
| evaluation/return-std          | 1504.9062   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.86        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 83.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45629       |
| perf/AverageLength             | 493         |
| perf/AverageReturn             | 1842.3223   |
| perf/NormalizedReturn          | 0.401       |
| Q-avg                          | 157.97395   |
| Q-std                          | 74.91385    |
| Q_loss                         | 95.33384    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 35          |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 7.91e-05    |
| times/epoch_rollout_model      | 476         |
| times/evaluation_metrics       | 0.000577    |
| times/evaluation_paths         | 16.5        |
| times/timestep_after_hook      | 0.00393     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 59.3        |
| timestep                       | 1000        |
| timesteps_total                | 36000       |
| train-steps                    | 36000       |
| training/Q/q1_loss             | 75.74451    |
| training/sac_pi/alpha          | 0.15892656  |
| training/sac_pi/alpha_loss     | 0.063157804 |
| training/sac_pi/logp_pi        | 3.7841783   |
| training/sac_pi/pi_entropy     | 3.675939    |
| training/sac_pi/pi_global_norm | 1.5709409   |
| training/sac_pi/policy_loss    | -170.52742  |
| training/sac_pi/std            | 0.49775875  |
| training/sac_pi/valid_num      | 5038.0      |
| training/sac_Q/q1              | 168.24223   |
| training/sac_Q/q2              | 168.57129   |
| training/sac_Q/q2_loss         | 75.804405   |
| training/sac_Q/q_global_norm   | 278.72104   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15869427 |
| epoch                          | 36         |
| evaluation/episode-length-avg  | 30.1       |
| evaluation/episode-length-max  | 31         |
| evaluation/episode-length-min  | 30         |
| evaluation/episode-length-std  | 0.3        |
| evaluation/return-average      | 30.511978  |
| evaluation/return-max          | 34.067596  |
| evaluation/return-min          | 29.711416  |
| evaluation/return-std          | 1.2086266  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.74       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 83.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45659      |
| perf/AverageLength             | 30.1       |
| perf/AverageReturn             | 30.511978  |
| perf/NormalizedReturn          | 0.00629    |
| Q-avg                          | 163.72705  |
| Q-std                          | 74.806786  |
| Q_loss                         | 76.293846  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 36         |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000114   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000424   |
| times/evaluation_paths         | 0.931      |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 58.6       |
| timestep                       | 1000       |
| timesteps_total                | 37000      |
| train-steps                    | 37000      |
| training/Q/q1_loss             | 72.31348   |
| training/sac_pi/alpha          | 0.15867706 |
| training/sac_pi/alpha_loss     | 0.44028237 |
| training/sac_pi/logp_pi        | 3.8298097  |
| training/sac_pi/pi_entropy     | 3.6076035  |
| training/sac_pi/pi_global_norm | 1.2549179  |
| training/sac_pi/policy_loss    | -175.59428 |
| training/sac_pi/std            | 0.4787831  |
| training/sac_pi/valid_num      | 5022.0     |
| training/sac_Q/q1              | 172.86577  |
| training/sac_Q/q2              | 173.08247  |
| training/sac_Q/q2_loss         | 71.77021   |
| training/sac_Q/q_global_norm   | 199.54385  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16346563  |
| epoch                          | 37          |
| evaluation/episode-length-avg  | 149         |
| evaluation/episode-length-max  | 154         |
| evaluation/episode-length-min  | 146         |
| evaluation/episode-length-std  | 2.18        |
| evaluation/return-average      | 331.99097   |
| evaluation/return-max          | 341.53046   |
| evaluation/return-min          | 325.79974   |
| evaluation/return-std          | 5.149737    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.74        |
| model/origin_ret               | 82.5        |
| model/penalty_ret              | 83          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45321       |
| perf/AverageLength             | 149         |
| perf/AverageReturn             | 331.99097   |
| perf/NormalizedReturn          | 0.072       |
| Q-avg                          | 160.9904    |
| Q-std                          | 80.15084    |
| Q_loss                         | 86.502304   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 37          |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000251    |
| times/epoch_rollout_model      | 475         |
| times/evaluation_metrics       | 0.00055     |
| times/evaluation_paths         | 4.4         |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 59.5        |
| timestep                       | 1000        |
| timesteps_total                | 38000       |
| train-steps                    | 38000       |
| training/Q/q1_loss             | 79.982445   |
| training/sac_pi/alpha          | 0.1634662   |
| training/sac_pi/alpha_loss     | 0.015565012 |
| training/sac_pi/logp_pi        | 4.287764    |
| training/sac_pi/pi_entropy     | 3.71602     |
| training/sac_pi/pi_global_norm | 1.1408838   |
| training/sac_pi/policy_loss    | -169.20349  |
| training/sac_pi/std            | 0.50784415  |
| training/sac_pi/valid_num      | 4980.0      |
| training/sac_Q/q1              | 164.49336   |
| training/sac_Q/q2              | 164.28787   |
| training/sac_Q/q2_loss         | 80.34177    |
| training/sac_Q/q_global_norm   | 273.07407   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15099072  |
| epoch                          | 38          |
| evaluation/episode-length-avg  | 120         |
| evaluation/episode-length-max  | 123         |
| evaluation/episode-length-min  | 116         |
| evaluation/episode-length-std  | 2.41        |
| evaluation/return-average      | 376.64508   |
| evaluation/return-max          | 391.5044    |
| evaluation/return-min          | 358.8715    |
| evaluation/return-std          | 11.51134    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.87        |
| model/origin_ret               | 87.1        |
| model/penalty_ret              | 85.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45491       |
| perf/AverageLength             | 120         |
| perf/AverageReturn             | 376.64508   |
| perf/NormalizedReturn          | 0.0817      |
| Q-avg                          | 171.23514   |
| Q-std                          | 74.718956   |
| Q_loss                         | 86.43626    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 38          |
| times/epoch_after_hook         | 1.99e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 476         |
| times/evaluation_metrics       | 0.00052     |
| times/evaluation_paths         | 4.89        |
| times/timestep_after_hook      | 0.00393     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 39000       |
| train-steps                    | 39000       |
| training/Q/q1_loss             | 82.407425   |
| training/sac_pi/alpha          | 0.1510285   |
| training/sac_pi/alpha_loss     | -0.28422612 |
| training/sac_pi/logp_pi        | 4.3122005   |
| training/sac_pi/pi_entropy     | 3.7385764   |
| training/sac_pi/pi_global_norm | 1.2544312   |
| training/sac_pi/policy_loss    | -175.54083  |
| training/sac_pi/std            | 0.5216151   |
| training/sac_pi/valid_num      | 4921.0      |
| training/sac_Q/q1              | 169.27817   |
| training/sac_Q/q2              | 169.32272   |
| training/sac_Q/q2_loss         | 82.74444    |
| training/sac_Q/q_global_norm   | 298.531     |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15609434  |
| epoch                          | 39          |
| evaluation/episode-length-avg  | 121         |
| evaluation/episode-length-max  | 125         |
| evaluation/episode-length-min  | 117         |
| evaluation/episode-length-std  | 2.52        |
| evaluation/return-average      | 252.59163   |
| evaluation/return-max          | 261.70557   |
| evaluation/return-min          | 243.85156   |
| evaluation/return-std          | 5.196743    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.83        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 82.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45671       |
| perf/AverageLength             | 121         |
| perf/AverageReturn             | 252.59163   |
| perf/NormalizedReturn          | 0.0547      |
| Q-avg                          | 169.19264   |
| Q-std                          | 77.34225    |
| Q_loss                         | 83.08161    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 39          |
| times/epoch_after_hook         | 1.95e-06    |
| times/epoch_before_hook        | 0.000115    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000454    |
| times/evaluation_paths         | 3.81        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.0081      |
| times/train                    | 58.7        |
| timestep                       | 1000        |
| timesteps_total                | 40000       |
| train-steps                    | 40000       |
| training/Q/q1_loss             | 86.92879    |
| training/sac_pi/alpha          | 0.15610835  |
| training/sac_pi/alpha_loss     | -0.21632437 |
| training/sac_pi/logp_pi        | 4.406604    |
| training/sac_pi/pi_entropy     | 3.9223385   |
| training/sac_pi/pi_global_norm | 1.6908906   |
| training/sac_pi/policy_loss    | -171.14171  |
| training/sac_pi/std            | 0.5564191   |
| training/sac_pi/valid_num      | 4936.0      |
| training/sac_Q/q1              | 164.69339   |
| training/sac_Q/q2              | 164.59587   |
| training/sac_Q/q2_loss         | 87.13638    |
| training/sac_Q/q_global_norm   | 182.865     |
---------------------------------------------------------------------------------
[WARN] 40 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.15180112   |
| epoch                          | 40           |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4603.238     |
| evaluation/return-max          | 4701.204     |
| evaluation/return-min          | 4438.4575    |
| evaluation/return-std          | 92.83294     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.92         |
| model/origin_ret               | 86.4         |
| model/penalty_ret              | 84.5         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45694        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4603.238     |
| perf/NormalizedReturn          | 1            |
| Q-avg                          | 171.91162    |
| Q-std                          | 77.58953     |
| Q_loss                         | 83.99088     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 40           |
| times/epoch_after_hook         | 1.83e-06     |
| times/epoch_before_hook        | 7.92e-05     |
| times/epoch_rollout_model      | 496          |
| times/evaluation_metrics       | 0.000573     |
| times/evaluation_paths         | 31.9         |
| times/timestep_after_hook      | 0.00387      |
| times/timestep_before_hook     | 0.00798      |
| times/train                    | 59.9         |
| timestep                       | 1000         |
| timesteps_total                | 41000        |
| train-steps                    | 41000        |
| training/Q/q1_loss             | 73.62054     |
| training/sac_pi/alpha          | 0.1518046    |
| training/sac_pi/alpha_loss     | -0.073058546 |
| training/sac_pi/logp_pi        | 3.7030385    |
| training/sac_pi/pi_entropy     | 3.639569     |
| training/sac_pi/pi_global_norm | 1.2149671    |
| training/sac_pi/policy_loss    | -171.54723   |
| training/sac_pi/std            | 0.48654574   |
| training/sac_pi/valid_num      | 4982.0       |
| training/sac_Q/q1              | 167.11739    |
| training/sac_Q/q2              | 167.18741    |
| training/sac_Q/q2_loss         | 73.03825     |
| training/sac_Q/q_global_norm   | 295.61563    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.14580049   |
| epoch                          | 41           |
| evaluation/episode-length-avg  | 262          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 153          |
| evaluation/episode-length-std  | 249          |
| evaluation/return-average      | 1030.5592    |
| evaluation/return-max          | 4751.042     |
| evaluation/return-min          | 496.94684    |
| evaluation/return-std          | 1253.7109    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.91         |
| model/origin_ret               | 86.2         |
| model/penalty_ret              | 83.5         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45716        |
| perf/AverageLength             | 262          |
| perf/AverageReturn             | 1030.5592    |
| perf/NormalizedReturn          | 0.224        |
| Q-avg                          | 160.43555    |
| Q-std                          | 78.470856    |
| Q_loss                         | 87.53852     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 41           |
| times/epoch_after_hook         | 1.98e-06     |
| times/epoch_before_hook        | 0.0003       |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.000664     |
| times/evaluation_paths         | 7.97         |
| times/timestep_after_hook      | 0.00385      |
| times/timestep_before_hook     | 0.00824      |
| times/train                    | 59.9         |
| timestep                       | 1000         |
| timesteps_total                | 42000        |
| train-steps                    | 42000        |
| training/Q/q1_loss             | 72.63436     |
| training/sac_pi/alpha          | 0.14579442   |
| training/sac_pi/alpha_loss     | -0.030294424 |
| training/sac_pi/logp_pi        | 4.467588     |
| training/sac_pi/pi_entropy     | 3.5364983    |
| training/sac_pi/pi_global_norm | 1.2720723    |
| training/sac_pi/policy_loss    | -179.08598   |
| training/sac_pi/std            | 0.49917313   |
| training/sac_pi/valid_num      | 4992.0       |
| training/sac_Q/q1              | 174.78743    |
| training/sac_Q/q2              | 175.21558    |
| training/sac_Q/q2_loss         | 72.88128     |
| training/sac_Q/q_global_norm   | 325.88226    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14985967  |
| epoch                          | 42          |
| evaluation/episode-length-avg  | 171         |
| evaluation/episode-length-max  | 174         |
| evaluation/episode-length-min  | 168         |
| evaluation/episode-length-std  | 1.94        |
| evaluation/return-average      | 398.4847    |
| evaluation/return-max          | 408.40796   |
| evaluation/return-min          | 391.59485   |
| evaluation/return-std          | 5.3196454   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 84.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45608       |
| perf/AverageLength             | 171         |
| perf/AverageReturn             | 398.4847    |
| perf/NormalizedReturn          | 0.0864      |
| Q-avg                          | 169.92628   |
| Q-std                          | 80.02669    |
| Q_loss                         | 89.376076   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 42          |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.00056     |
| times/evaluation_paths         | 5.23        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 43000       |
| train-steps                    | 43000       |
| training/Q/q1_loss             | 95.021255   |
| training/sac_pi/alpha          | 0.14986934  |
| training/sac_pi/alpha_loss     | -0.27272415 |
| training/sac_pi/logp_pi        | 3.686615    |
| training/sac_pi/pi_entropy     | 3.678495    |
| training/sac_pi/pi_global_norm | 1.0688162   |
| training/sac_pi/policy_loss    | -177.55275  |
| training/sac_pi/std            | 0.48762268  |
| training/sac_pi/valid_num      | 5031.0      |
| training/sac_Q/q1              | 174.94946   |
| training/sac_Q/q2              | 174.93692   |
| training/sac_Q/q2_loss         | 94.86268    |
| training/sac_Q/q_global_norm   | 233.5127    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15394847 |
| epoch                          | 43         |
| evaluation/episode-length-avg  | 156        |
| evaluation/episode-length-max  | 157        |
| evaluation/episode-length-min  | 155        |
| evaluation/episode-length-std  | 0.539      |
| evaluation/return-average      | 409.5342   |
| evaluation/return-max          | 412.1916   |
| evaluation/return-min          | 404.21533  |
| evaluation/return-std          | 2.444771   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.73       |
| model/origin_ret               | 81.7       |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45664      |
| perf/AverageLength             | 156        |
| perf/AverageReturn             | 409.5342   |
| perf/NormalizedReturn          | 0.0889     |
| Q-avg                          | 166.24539  |
| Q-std                          | 77.49231   |
| Q_loss                         | 80.739075  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 43         |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000443   |
| times/evaluation_paths         | 4.6        |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 44000      |
| train-steps                    | 44000      |
| training/Q/q1_loss             | 90.53147   |
| training/sac_pi/alpha          | 0.15393277 |
| training/sac_pi/alpha_loss     | 0.39054486 |
| training/sac_pi/logp_pi        | 5.1873245  |
| training/sac_pi/pi_entropy     | 3.7511337  |
| training/sac_pi/pi_global_norm | 1.4205188  |
| training/sac_pi/policy_loss    | -172.08124 |
| training/sac_pi/std            | 0.53641284 |
| training/sac_pi/valid_num      | 4913.0     |
| training/sac_Q/q1              | 165.41333  |
| training/sac_Q/q2              | 165.40819  |
| training/sac_Q/q2_loss         | 89.887314  |
| training/sac_Q/q_global_norm   | 272.6488   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1497838   |
| epoch                          | 44          |
| evaluation/episode-length-avg  | 123         |
| evaluation/episode-length-max  | 124         |
| evaluation/episode-length-min  | 123         |
| evaluation/episode-length-std  | 0.4         |
| evaluation/return-average      | 360.2488    |
| evaluation/return-max          | 363.83853   |
| evaluation/return-min          | 354.8009    |
| evaluation/return-std          | 2.4715962   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 82.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45771       |
| perf/AverageLength             | 123         |
| perf/AverageReturn             | 360.2488    |
| perf/NormalizedReturn          | 0.0781      |
| Q-avg                          | 171.15344   |
| Q-std                          | 75.59721    |
| Q_loss                         | 92.27221    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 44          |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 7.79e-05    |
| times/epoch_rollout_model      | 476         |
| times/evaluation_metrics       | 0.000608    |
| times/evaluation_paths         | 4.26        |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 61.8        |
| timestep                       | 1000        |
| timesteps_total                | 45000       |
| train-steps                    | 45000       |
| training/Q/q1_loss             | 88.12886    |
| training/sac_pi/alpha          | 0.14977483  |
| training/sac_pi/alpha_loss     | -0.15416919 |
| training/sac_pi/logp_pi        | 3.871411    |
| training/sac_pi/pi_entropy     | 3.683419    |
| training/sac_pi/pi_global_norm | 1.5254602   |
| training/sac_pi/policy_loss    | -180.24599  |
| training/sac_pi/std            | 0.49317533  |
| training/sac_pi/valid_num      | 4984.0      |
| training/sac_Q/q1              | 176.01155   |
| training/sac_Q/q2              | 176.02974   |
| training/sac_Q/q2_loss         | 88.62755    |
| training/sac_Q/q_global_norm   | 361.2712    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15104204  |
| epoch                          | 45          |
| evaluation/episode-length-avg  | 134         |
| evaluation/episode-length-max  | 137         |
| evaluation/episode-length-min  | 133         |
| evaluation/episode-length-std  | 1.43        |
| evaluation/return-average      | 386.7105    |
| evaluation/return-max          | 399.41565   |
| evaluation/return-min          | 377.42032   |
| evaluation/return-std          | 6.6378403   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.84        |
| model/origin_ret               | 83.6        |
| model/penalty_ret              | 82.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45861       |
| perf/AverageLength             | 134         |
| perf/AverageReturn             | 386.7105    |
| perf/NormalizedReturn          | 0.0839      |
| Q-avg                          | 164.26746   |
| Q-std                          | 77.66263    |
| Q_loss                         | 89.47523    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 45          |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000247    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000572    |
| times/evaluation_paths         | 4.21        |
| times/timestep_after_hook      | 0.00385     |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 57.9        |
| timestep                       | 1000        |
| timesteps_total                | 46000       |
| train-steps                    | 46000       |
| training/Q/q1_loss             | 79.86439    |
| training/sac_pi/alpha          | 0.1510767   |
| training/sac_pi/alpha_loss     | -0.30091918 |
| training/sac_pi/logp_pi        | 4.3439765   |
| training/sac_pi/pi_entropy     | 3.6371326   |
| training/sac_pi/pi_global_norm | 1.143385    |
| training/sac_pi/policy_loss    | -173.78531  |
| training/sac_pi/std            | 0.5148221   |
| training/sac_pi/valid_num      | 4939.0      |
| training/sac_Q/q1              | 167.71078   |
| training/sac_Q/q2              | 167.7655    |
| training/sac_Q/q2_loss         | 80.48855    |
| training/sac_Q/q_global_norm   | 286.91318   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14942862 |
| epoch                          | 46         |
| evaluation/episode-length-avg  | 579        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 150        |
| evaluation/episode-length-std  | 421        |
| evaluation/return-average      | 2672.362   |
| evaluation/return-max          | 4882.4014  |
| evaluation/return-min          | 499.5249   |
| evaluation/return-std          | 2145.1135  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.85       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 83.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45792      |
| perf/AverageLength             | 579        |
| perf/AverageReturn             | 2672.362   |
| perf/NormalizedReturn          | 0.582      |
| Q-avg                          | 180.87512  |
| Q-std                          | 77.88128   |
| Q_loss                         | 79.583046  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 46         |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 8.26e-05   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000529   |
| times/evaluation_paths         | 17.5       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 60         |
| timestep                       | 1000       |
| timesteps_total                | 47000      |
| train-steps                    | 47000      |
| training/Q/q1_loss             | 78.68656   |
| training/sac_pi/alpha          | 0.1494038  |
| training/sac_pi/alpha_loss     | 0.39744723 |
| training/sac_pi/logp_pi        | 4.1820803  |
| training/sac_pi/pi_entropy     | 3.852349   |
| training/sac_pi/pi_global_norm | 1.1059542  |
| training/sac_pi/policy_loss    | -183.3582  |
| training/sac_pi/std            | 0.52825105 |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 177.53537  |
| training/sac_Q/q2              | 177.4804   |
| training/sac_Q/q2_loss         | 79.57333   |
| training/sac_Q/q_global_norm   | 246.88832  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14897254 |
| epoch                          | 47         |
| evaluation/episode-length-avg  | 913        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 132        |
| evaluation/episode-length-std  | 260        |
| evaluation/return-average      | 4157.3613  |
| evaluation/return-max          | 4666.613   |
| evaluation/return-min          | 412.41672  |
| evaluation/return-std          | 1249.9358  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.85       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 82.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45707      |
| perf/AverageLength             | 913        |
| perf/AverageReturn             | 4157.3613  |
| perf/NormalizedReturn          | 0.905      |
| Q-avg                          | 178.88455  |
| Q-std                          | 75.68039   |
| Q_loss                         | 80.84428   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 47         |
| times/epoch_after_hook         | 2.13e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000525   |
| times/evaluation_paths         | 29.4       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00798    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 48000      |
| train-steps                    | 48000      |
| training/Q/q1_loss             | 83.258     |
| training/sac_pi/alpha          | 0.14898892 |
| training/sac_pi/alpha_loss     | 0.07519434 |
| training/sac_pi/logp_pi        | 4.541059   |
| training/sac_pi/pi_entropy     | 3.6613822  |
| training/sac_pi/pi_global_norm | 1.2222415  |
| training/sac_pi/policy_loss    | -180.73354 |
| training/sac_pi/std            | 0.5132677  |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 175.46121  |
| training/sac_Q/q2              | 175.35197  |
| training/sac_Q/q2_loss         | 83.80321   |
| training/sac_Q/q_global_norm   | 331.23788  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14854452 |
| epoch                          | 48         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4763.0757  |
| evaluation/return-max          | 4801.027   |
| evaluation/return-min          | 4740.954   |
| evaluation/return-std          | 18.791483  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 84.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45650      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4763.0757  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 170.57658  |
| Q-std                          | 79.13385   |
| Q_loss                         | 82.69236   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 48         |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000559   |
| times/evaluation_paths         | 32.1       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 49000      |
| train-steps                    | 49000      |
| training/Q/q1_loss             | 85.01644   |
| training/sac_pi/alpha          | 0.14853889 |
| training/sac_pi/alpha_loss     | 0.3093122  |
| training/sac_pi/logp_pi        | 4.3267345  |
| training/sac_pi/pi_entropy     | 3.5536294  |
| training/sac_pi/pi_global_norm | 1.0368564  |
| training/sac_pi/policy_loss    | -179.25299 |
| training/sac_pi/std            | 0.49539185 |
| training/sac_pi/valid_num      | 4972.0     |
| training/sac_Q/q1              | 174.79678  |
| training/sac_Q/q2              | 174.50607  |
| training/sac_Q/q2_loss         | 85.090355  |
| training/sac_Q/q_global_norm   | 293.327    |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15109465  |
| epoch                          | 49          |
| evaluation/episode-length-avg  | 175         |
| evaluation/episode-length-max  | 178         |
| evaluation/episode-length-min  | 172         |
| evaluation/episode-length-std  | 1.5         |
| evaluation/return-average      | 460.87955   |
| evaluation/return-max          | 468.07248   |
| evaluation/return-min          | 454.3004    |
| evaluation/return-std          | 4.515255    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 87          |
| model/penalty_ret              | 84.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45783       |
| perf/AverageLength             | 175         |
| perf/AverageReturn             | 460.87955   |
| perf/NormalizedReturn          | 0.1         |
| Q-avg                          | 171.27153   |
| Q-std                          | 76.34577    |
| Q_loss                         | 75.07191    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 49          |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000248    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000497    |
| times/evaluation_paths         | 6.87        |
| times/timestep_after_hook      | 0.00385     |
| times/timestep_before_hook     | 0.00806     |
| times/train                    | 59.2        |
| timestep                       | 1000        |
| timesteps_total                | 50000       |
| train-steps                    | 50000       |
| training/Q/q1_loss             | 97.10629    |
| training/sac_pi/alpha          | 0.15110685  |
| training/sac_pi/alpha_loss     | -0.31800508 |
| training/sac_pi/logp_pi        | 4.1008663   |
| training/sac_pi/pi_entropy     | 3.7827096   |
| training/sac_pi/pi_global_norm | 1.5252669   |
| training/sac_pi/policy_loss    | -171.62665  |
| training/sac_pi/std            | 0.51693857  |
| training/sac_pi/valid_num      | 4943.0      |
| training/sac_Q/q1              | 165.7381    |
| training/sac_Q/q2              | 165.67984   |
| training/sac_Q/q2_loss         | 97.08377    |
| training/sac_Q/q_global_norm   | 304.6231    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15075335  |
| epoch                          | 50          |
| evaluation/episode-length-avg  | 120         |
| evaluation/episode-length-max  | 125         |
| evaluation/episode-length-min  | 113         |
| evaluation/episode-length-std  | 4.02        |
| evaluation/return-average      | 268.92905   |
| evaluation/return-max          | 292.18332   |
| evaluation/return-min          | 241.58176   |
| evaluation/return-std          | 18.362276   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.79        |
| model/origin_ret               | 83.4        |
| model/penalty_ret              | 83          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45799       |
| perf/AverageLength             | 120         |
| perf/AverageReturn             | 268.92905   |
| perf/NormalizedReturn          | 0.0582      |
| Q-avg                          | 176.73581   |
| Q-std                          | 87.10566    |
| Q_loss                         | 77.28834    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 50          |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000111    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000471    |
| times/evaluation_paths         | 3.9         |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 51000       |
| train-steps                    | 51000       |
| training/Q/q1_loss             | 81.57337    |
| training/sac_pi/alpha          | 0.1507309   |
| training/sac_pi/alpha_loss     | 0.027189769 |
| training/sac_pi/logp_pi        | 4.1537595   |
| training/sac_pi/pi_entropy     | 3.651237    |
| training/sac_pi/pi_global_norm | 1.2429577   |
| training/sac_pi/policy_loss    | -182.83815  |
| training/sac_pi/std            | 0.5047457   |
| training/sac_pi/valid_num      | 4974.0      |
| training/sac_Q/q1              | 177.93631   |
| training/sac_Q/q2              | 177.97005   |
| training/sac_Q/q2_loss         | 81.11694    |
| training/sac_Q/q_global_norm   | 378.43253   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15036476 |
| epoch                          | 51         |
| evaluation/episode-length-avg  | 655        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 130        |
| evaluation/episode-length-std  | 422        |
| evaluation/return-average      | 2907.647   |
| evaluation/return-max          | 4655.9478  |
| evaluation/return-min          | 404.9217   |
| evaluation/return-std          | 2028.4498  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 83.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45802      |
| perf/AverageLength             | 655        |
| perf/AverageReturn             | 2907.647   |
| perf/NormalizedReturn          | 0.633      |
| Q-avg                          | 179.73904  |
| Q-std                          | 78.271706  |
| Q_loss                         | 81.145035  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 51         |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000589   |
| times/evaluation_paths         | 22.2       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 60.2       |
| timestep                       | 1000       |
| timesteps_total                | 52000      |
| train-steps                    | 52000      |
| training/Q/q1_loss             | 88.90696   |
| training/sac_pi/alpha          | 0.15036803 |
| training/sac_pi/alpha_loss     | 0.18960346 |
| training/sac_pi/logp_pi        | 4.032996   |
| training/sac_pi/pi_entropy     | 3.5651717  |
| training/sac_pi/pi_global_norm | 1.2505282  |
| training/sac_pi/policy_loss    | -180.73494 |
| training/sac_pi/std            | 0.49124926 |
| training/sac_pi/valid_num      | 4995.0     |
| training/sac_Q/q1              | 176.78162  |
| training/sac_Q/q2              | 176.24959  |
| training/sac_Q/q2_loss         | 89.60895   |
| training/sac_Q/q_global_norm   | 191.10808  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15043472 |
| epoch                          | 52         |
| evaluation/episode-length-avg  | 152        |
| evaluation/episode-length-max  | 157        |
| evaluation/episode-length-min  | 147        |
| evaluation/episode-length-std  | 2.61       |
| evaluation/return-average      | 318.45648  |
| evaluation/return-max          | 364.57593  |
| evaluation/return-min          | 276.86212  |
| evaluation/return-std          | 27.852734  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.82       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 83.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45754      |
| perf/AverageLength             | 152        |
| perf/AverageReturn             | 318.45648  |
| perf/NormalizedReturn          | 0.069      |
| Q-avg                          | 173.95375  |
| Q-std                          | 79.806725  |
| Q_loss                         | 79.338295  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 52         |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000484   |
| times/evaluation_paths         | 4.78       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 58.6       |
| timestep                       | 1000       |
| timesteps_total                | 53000      |
| train-steps                    | 53000      |
| training/Q/q1_loss             | 88.717125  |
| training/sac_pi/alpha          | 0.15044487 |
| training/sac_pi/alpha_loss     | 0.3249076  |
| training/sac_pi/logp_pi        | 3.9986598  |
| training/sac_pi/pi_entropy     | 3.8352325  |
| training/sac_pi/pi_global_norm | 1.2548364  |
| training/sac_pi/policy_loss    | -178.99731 |
| training/sac_pi/std            | 0.5188567  |
| training/sac_pi/valid_num      | 4992.0     |
| training/sac_Q/q1              | 174.26308  |
| training/sac_Q/q2              | 174.77312  |
| training/sac_Q/q2_loss         | 89.20443   |
| training/sac_Q/q_global_norm   | 296.52002  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.155491   |
| epoch                          | 53         |
| evaluation/episode-length-avg  | 134        |
| evaluation/episode-length-max  | 137        |
| evaluation/episode-length-min  | 132        |
| evaluation/episode-length-std  | 1.61       |
| evaluation/return-average      | 434.83807  |
| evaluation/return-max          | 443.46603  |
| evaluation/return-min          | 427.0674   |
| evaluation/return-std          | 5.180431   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.77       |
| model/origin_ret               | 82.6       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45853      |
| perf/AverageLength             | 134        |
| perf/AverageReturn             | 434.83807  |
| perf/NormalizedReturn          | 0.0944     |
| Q-avg                          | 168.36624  |
| Q-std                          | 87.595375  |
| Q_loss                         | 67.71703   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 53         |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000257   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000492   |
| times/evaluation_paths         | 5.53       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 58.9       |
| timestep                       | 1000       |
| timesteps_total                | 54000      |
| train-steps                    | 54000      |
| training/Q/q1_loss             | 87.45091   |
| training/sac_pi/alpha          | 0.1554792  |
| training/sac_pi/alpha_loss     | 0.47132793 |
| training/sac_pi/logp_pi        | 3.9985194  |
| training/sac_pi/pi_entropy     | 3.818669   |
| training/sac_pi/pi_global_norm | 1.1244429  |
| training/sac_pi/policy_loss    | -179.51053 |
| training/sac_pi/std            | 0.50151604 |
| training/sac_pi/valid_num      | 4986.0     |
| training/sac_Q/q1              | 174.76714  |
| training/sac_Q/q2              | 175.07602  |
| training/sac_Q/q2_loss         | 86.29801   |
| training/sac_Q/q_global_norm   | 250.07114  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1552746    |
| epoch                          | 54           |
| evaluation/episode-length-avg  | 915          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 150          |
| evaluation/episode-length-std  | 255          |
| evaluation/return-average      | 4564.19      |
| evaluation/return-max          | 5136.837     |
| evaluation/return-min          | 473.46573    |
| evaluation/return-std          | 1365.2708    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.01         |
| model/origin_ret               | 87.7         |
| model/penalty_ret              | 83.2         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45782        |
| perf/AverageLength             | 915          |
| perf/AverageReturn             | 4564.19      |
| perf/NormalizedReturn          | 0.994        |
| Q-avg                          | 169.8171     |
| Q-std                          | 91.975914    |
| Q_loss                         | 104.420525   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 54           |
| times/epoch_after_hook         | 1.79e-06     |
| times/epoch_before_hook        | 6.75e-05     |
| times/epoch_rollout_model      | 485          |
| times/evaluation_metrics       | 0.000506     |
| times/evaluation_paths         | 29.6         |
| times/timestep_after_hook      | 0.00392      |
| times/timestep_before_hook     | 0.00806      |
| times/train                    | 59.6         |
| timestep                       | 1000         |
| timesteps_total                | 55000        |
| train-steps                    | 55000        |
| training/Q/q1_loss             | 91.433655    |
| training/sac_pi/alpha          | 0.15528572   |
| training/sac_pi/alpha_loss     | -0.016062433 |
| training/sac_pi/logp_pi        | 4.039857     |
| training/sac_pi/pi_entropy     | 3.7927577    |
| training/sac_pi/pi_global_norm | 1.3832064    |
| training/sac_pi/policy_loss    | -181.92574   |
| training/sac_pi/std            | 0.50939125   |
| training/sac_pi/valid_num      | 4970.0       |
| training/sac_Q/q1              | 176.58023    |
| training/sac_Q/q2              | 176.67032    |
| training/sac_Q/q2_loss         | 92.27433     |
| training/sac_Q/q_global_norm   | 391.17654    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1527885   |
| epoch                          | 55          |
| evaluation/episode-length-avg  | 587         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 365         |
| evaluation/episode-length-std  | 278         |
| evaluation/return-average      | 2681.3965   |
| evaluation/return-max          | 4918.21     |
| evaluation/return-min          | 1538.4149   |
| evaluation/return-std          | 1454.8533   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.87        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 83.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45846       |
| perf/AverageLength             | 587         |
| perf/AverageReturn             | 2681.3965   |
| perf/NormalizedReturn          | 0.584       |
| Q-avg                          | 181.42598   |
| Q-std                          | 84.969864   |
| Q_loss                         | 106.55015   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 55          |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000154    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000628    |
| times/evaluation_paths         | 19.3        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 59          |
| timestep                       | 1000        |
| timesteps_total                | 56000       |
| train-steps                    | 56000       |
| training/Q/q1_loss             | 88.7973     |
| training/sac_pi/alpha          | 0.15280652  |
| training/sac_pi/alpha_loss     | -0.17736648 |
| training/sac_pi/logp_pi        | 3.5636115   |
| training/sac_pi/pi_entropy     | 3.7526374   |
| training/sac_pi/pi_global_norm | 1.9668343   |
| training/sac_pi/policy_loss    | -186.85889  |
| training/sac_pi/std            | 0.496359    |
| training/sac_pi/valid_num      | 5017.0      |
| training/sac_Q/q1              | 183.82684   |
| training/sac_Q/q2              | 183.8259    |
| training/sac_Q/q2_loss         | 88.50977    |
| training/sac_Q/q_global_norm   | 342.80447   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15865485 |
| epoch                          | 56         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4497.6084  |
| evaluation/return-max          | 4533.1904  |
| evaluation/return-min          | 4447.952   |
| evaluation/return-std          | 22.482609  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.82       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 84         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45801      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4497.6084  |
| perf/NormalizedReturn          | 0.979      |
| Q-avg                          | 190.54721  |
| Q-std                          | 73.340126  |
| Q_loss                         | 83.245995  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 56         |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000594   |
| times/evaluation_paths         | 32.3       |
| times/timestep_after_hook      | 0.00381    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 59         |
| timestep                       | 1000       |
| timesteps_total                | 57000      |
| train-steps                    | 57000      |
| training/Q/q1_loss             | 105.89751  |
| training/sac_pi/alpha          | 0.15855774 |
| training/sac_pi/alpha_loss     | 0.26078692 |
| training/sac_pi/logp_pi        | 4.380951   |
| training/sac_pi/pi_entropy     | 4.0360403  |
| training/sac_pi/pi_global_norm | 1.3886434  |
| training/sac_pi/policy_loss    | -179.93352 |
| training/sac_pi/std            | 0.5453855  |
| training/sac_pi/valid_num      | 4963.0     |
| training/sac_Q/q1              | 174.60762  |
| training/sac_Q/q2              | 174.8427   |
| training/sac_Q/q2_loss         | 105.799515 |
| training/sac_Q/q_global_norm   | 255.87975  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16045456 |
| epoch                          | 57         |
| evaluation/episode-length-avg  | 148        |
| evaluation/episode-length-max  | 150        |
| evaluation/episode-length-min  | 146        |
| evaluation/episode-length-std  | 1.72       |
| evaluation/return-average      | 272.81805  |
| evaluation/return-max          | 279.95428  |
| evaluation/return-min          | 268.41794  |
| evaluation/return-std          | 3.574204   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.87       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 84.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45266      |
| perf/AverageLength             | 148        |
| perf/AverageReturn             | 272.81805  |
| perf/NormalizedReturn          | 0.0591     |
| Q-avg                          | 175.1304   |
| Q-std                          | 94.87022   |
| Q_loss                         | 96.81542   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 57         |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000302   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000518   |
| times/evaluation_paths         | 4.42       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00801    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 58000      |
| train-steps                    | 58000      |
| training/Q/q1_loss             | 88.87358   |
| training/sac_pi/alpha          | 0.1604424  |
| training/sac_pi/alpha_loss     | 0.7532502  |
| training/sac_pi/logp_pi        | 4.1287436  |
| training/sac_pi/pi_entropy     | 3.7350185  |
| training/sac_pi/pi_global_norm | 1.330761   |
| training/sac_pi/policy_loss    | -185.99506 |
| training/sac_pi/std            | 0.49956423 |
| training/sac_pi/valid_num      | 5011.0     |
| training/sac_Q/q1              | 182.69585  |
| training/sac_Q/q2              | 182.24496  |
| training/sac_Q/q2_loss         | 89.784996  |
| training/sac_Q/q_global_norm   | 386.0469   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15816124 |
| epoch                          | 58         |
| evaluation/episode-length-avg  | 147        |
| evaluation/episode-length-max  | 152        |
| evaluation/episode-length-min  | 142        |
| evaluation/episode-length-std  | 3.29       |
| evaluation/return-average      | 487.6253   |
| evaluation/return-max          | 505.69058  |
| evaluation/return-min          | 459.46722  |
| evaluation/return-std          | 13.1163645 |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 83.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45849      |
| perf/AverageLength             | 147        |
| perf/AverageReturn             | 487.6253   |
| perf/NormalizedReturn          | 0.106      |
| Q-avg                          | 178.62852  |
| Q-std                          | 88.96412   |
| Q_loss                         | 93.39896   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 58         |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000437   |
| times/evaluation_paths         | 4.65       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 59000      |
| train-steps                    | 59000      |
| training/Q/q1_loss             | 84.90703   |
| training/sac_pi/alpha          | 0.15820554 |
| training/sac_pi/alpha_loss     | -0.3936922 |
| training/sac_pi/logp_pi        | 3.9393668  |
| training/sac_pi/pi_entropy     | 3.732428   |
| training/sac_pi/pi_global_norm | 1.2319428  |
| training/sac_pi/policy_loss    | -184.40402 |
| training/sac_pi/std            | 0.5101469  |
| training/sac_pi/valid_num      | 5018.0     |
| training/sac_Q/q1              | 180.05045  |
| training/sac_Q/q2              | 179.98569  |
| training/sac_Q/q2_loss         | 85.18871   |
| training/sac_Q/q_global_norm   | 199.73613  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16171221 |
| epoch                          | 59         |
| evaluation/episode-length-avg  | 914        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 145        |
| evaluation/episode-length-std  | 256        |
| evaluation/return-average      | 4492.9697  |
| evaluation/return-max          | 4989.009   |
| evaluation/return-min          | 462.13727  |
| evaluation/return-std          | 1344.1388  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45863      |
| perf/AverageLength             | 914        |
| perf/AverageReturn             | 4492.9697  |
| perf/NormalizedReturn          | 0.978      |
| Q-avg                          | 170.96297  |
| Q-std                          | 83.11329   |
| Q_loss                         | 72.332794  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 59         |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 6.41e-05   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000598   |
| times/evaluation_paths         | 29.7       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 60000      |
| train-steps                    | 60000      |
| training/Q/q1_loss             | 93.042755  |
| training/sac_pi/alpha          | 0.16170551 |
| training/sac_pi/alpha_loss     | 0.05301029 |
| training/sac_pi/logp_pi        | 4.660186   |
| training/sac_pi/pi_entropy     | 3.8709843  |
| training/sac_pi/pi_global_norm | 1.4545923  |
| training/sac_pi/policy_loss    | -175.27238 |
| training/sac_pi/std            | 0.5368625  |
| training/sac_pi/valid_num      | 4893.0     |
| training/sac_Q/q1              | 167.33571  |
| training/sac_Q/q2              | 167.46594  |
| training/sac_Q/q2_loss         | 92.93074   |
| training/sac_Q/q_global_norm   | 226.99321  |
--------------------------------------------------------------------------------
[WARN] 60 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16482879 |
| epoch                          | 60         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4854.8716  |
| evaluation/return-max          | 4870.062   |
| evaluation/return-min          | 4830.2646  |
| evaluation/return-std          | 12.677814  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 83.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45791      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4854.8716  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 177.4044   |
| Q-std                          | 83.15764   |
| Q_loss                         | 88.83632   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 60         |
| times/epoch_after_hook         | 2.11e-06   |
| times/epoch_before_hook        | 0.000116   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000581   |
| times/evaluation_paths         | 32.7       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 61000      |
| train-steps                    | 61000      |
| training/Q/q1_loss             | 86.42272   |
| training/sac_pi/alpha          | 0.1648172  |
| training/sac_pi/alpha_loss     | 0.372201   |
| training/sac_pi/logp_pi        | 5.04889    |
| training/sac_pi/pi_entropy     | 4.019542   |
| training/sac_pi/pi_global_norm | 1.0693022  |
| training/sac_pi/policy_loss    | -180.32443 |
| training/sac_pi/std            | 0.5802898  |
| training/sac_pi/valid_num      | 4949.0     |
| training/sac_Q/q1              | 172.3349   |
| training/sac_Q/q2              | 172.85028  |
| training/sac_Q/q2_loss         | 86.07398   |
| training/sac_Q/q_global_norm   | 227.79807  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15744162 |
| epoch                          | 61         |
| evaluation/episode-length-avg  | 926        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 263        |
| evaluation/episode-length-std  | 221        |
| evaluation/return-average      | 4295.411   |
| evaluation/return-max          | 4908.927   |
| evaluation/return-min          | 831.49036  |
| evaluation/return-std          | 1159.4978  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 83.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45665      |
| perf/AverageLength             | 926        |
| perf/AverageReturn             | 4295.411   |
| perf/NormalizedReturn          | 0.935      |
| Q-avg                          | 178.38213  |
| Q-std                          | 83.54869   |
| Q_loss                         | 93.250565  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 61         |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000253   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000504   |
| times/evaluation_paths         | 31.5       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 57.6       |
| timestep                       | 1000       |
| timesteps_total                | 62000      |
| train-steps                    | 62000      |
| training/Q/q1_loss             | 97.01899   |
| training/sac_pi/alpha          | 0.1574172  |
| training/sac_pi/alpha_loss     | 0.14462376 |
| training/sac_pi/logp_pi        | 4.6358786  |
| training/sac_pi/pi_entropy     | 3.7511525  |
| training/sac_pi/pi_global_norm | 1.7140121  |
| training/sac_pi/policy_loss    | -179.6491  |
| training/sac_pi/std            | 0.5398432  |
| training/sac_pi/valid_num      | 4951.0     |
| training/sac_Q/q1              | 173.39745  |
| training/sac_Q/q2              | 173.77747  |
| training/sac_Q/q2_loss         | 97.02611   |
| training/sac_Q/q_global_norm   | 294.57196  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15954907  |
| epoch                          | 62          |
| evaluation/episode-length-avg  | 171         |
| evaluation/episode-length-max  | 272         |
| evaluation/episode-length-min  | 143         |
| evaluation/episode-length-std  | 42.6        |
| evaluation/return-average      | 574.20197   |
| evaluation/return-max          | 1037.2295   |
| evaluation/return-min          | 460.7906    |
| evaluation/return-std          | 185.52396   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 83.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45996       |
| perf/AverageLength             | 171         |
| perf/AverageReturn             | 574.20197   |
| perf/NormalizedReturn          | 0.125       |
| Q-avg                          | 181.49854   |
| Q-std                          | 77.848366   |
| Q_loss                         | 99.28996    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 62          |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 474         |
| times/evaluation_metrics       | 0.00046     |
| times/evaluation_paths         | 6.81        |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 58.4        |
| timestep                       | 1000        |
| timesteps_total                | 63000       |
| train-steps                    | 63000       |
| training/Q/q1_loss             | 94.36258    |
| training/sac_pi/alpha          | 0.15956128  |
| training/sac_pi/alpha_loss     | -0.20223272 |
| training/sac_pi/logp_pi        | 4.081662    |
| training/sac_pi/pi_entropy     | 3.717749    |
| training/sac_pi/pi_global_norm | 1.5577399   |
| training/sac_pi/policy_loss    | -191.63722  |
| training/sac_pi/std            | 0.5211926   |
| training/sac_pi/valid_num      | 4978.0      |
| training/sac_Q/q1              | 185.9464    |
| training/sac_Q/q2              | 186.03067   |
| training/sac_Q/q2_loss         | 94.14486    |
| training/sac_Q/q_global_norm   | 251.32492   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15708852   |
| epoch                          | 63           |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4348.501     |
| evaluation/return-max          | 4413.091     |
| evaluation/return-min          | 4264.95      |
| evaluation/return-std          | 47.38029     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.85         |
| model/origin_ret               | 84.8         |
| model/penalty_ret              | 83.5         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45412        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4348.501     |
| perf/NormalizedReturn          | 0.947        |
| Q-avg                          | 177.0386     |
| Q-std                          | 86.24847     |
| Q_loss                         | 81.65203     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 63           |
| times/epoch_after_hook         | 1.73e-06     |
| times/epoch_before_hook        | 0.000108     |
| times/epoch_rollout_model      | 475          |
| times/evaluation_metrics       | 0.000547     |
| times/evaluation_paths         | 31.8         |
| times/timestep_after_hook      | 0.00386      |
| times/timestep_before_hook     | 0.00815      |
| times/train                    | 59.6         |
| timestep                       | 1000         |
| timesteps_total                | 64000        |
| train-steps                    | 64000        |
| training/Q/q1_loss             | 92.20053     |
| training/sac_pi/alpha          | 0.15709043   |
| training/sac_pi/alpha_loss     | -0.082314245 |
| training/sac_pi/logp_pi        | 3.661132     |
| training/sac_pi/pi_entropy     | 3.8546715    |
| training/sac_pi/pi_global_norm | 1.1689777    |
| training/sac_pi/policy_loss    | -191.50642   |
| training/sac_pi/std            | 0.5157931    |
| training/sac_pi/valid_num      | 4958.0       |
| training/sac_Q/q1              | 185.896      |
| training/sac_Q/q2              | 185.29044    |
| training/sac_Q/q2_loss         | 92.41165     |
| training/sac_Q/q_global_norm   | 256.553      |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15385687   |
| epoch                          | 64           |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4941.5537    |
| evaluation/return-max          | 5008.0547    |
| evaluation/return-min          | 4747.017     |
| evaluation/return-std          | 77.86331     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.9          |
| model/origin_ret               | 85.7         |
| model/penalty_ret              | 83.1         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45625        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4941.5537    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 183.53055    |
| Q-std                          | 79.44986     |
| Q_loss                         | 81.78926     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 64           |
| times/epoch_after_hook         | 2.01e-06     |
| times/epoch_before_hook        | 0.000132     |
| times/epoch_rollout_model      | 479          |
| times/evaluation_metrics       | 0.000539     |
| times/evaluation_paths         | 32.8         |
| times/timestep_after_hook      | 0.00388      |
| times/timestep_before_hook     | 0.00812      |
| times/train                    | 59.7         |
| timestep                       | 1000         |
| timesteps_total                | 65000        |
| train-steps                    | 65000        |
| training/Q/q1_loss             | 71.63826     |
| training/sac_pi/alpha          | 0.1538354    |
| training/sac_pi/alpha_loss     | -0.097813345 |
| training/sac_pi/logp_pi        | 4.6636496    |
| training/sac_pi/pi_entropy     | 3.6041076    |
| training/sac_pi/pi_global_norm | 1.5250909    |
| training/sac_pi/policy_loss    | -185.90688   |
| training/sac_pi/std            | 0.52167684   |
| training/sac_pi/valid_num      | 4940.0       |
| training/sac_Q/q1              | 179.49866    |
| training/sac_Q/q2              | 180.40714    |
| training/sac_Q/q2_loss         | 72.121666    |
| training/sac_Q/q_global_norm   | 196.77034    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15353243 |
| epoch                          | 65         |
| evaluation/episode-length-avg  | 915        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 153        |
| evaluation/episode-length-std  | 254        |
| evaluation/return-average      | 4296.399   |
| evaluation/return-max          | 4787.1353  |
| evaluation/return-min          | 335.0171   |
| evaluation/return-std          | 1320.5991  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45947      |
| perf/AverageLength             | 915        |
| perf/AverageReturn             | 4296.399   |
| perf/NormalizedReturn          | 0.936      |
| Q-avg                          | 176.29263  |
| Q-std                          | 96.52914   |
| Q_loss                         | 85.42425   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 65         |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000265   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000476   |
| times/evaluation_paths         | 29.4       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 58.7       |
| timestep                       | 1000       |
| timesteps_total                | 66000      |
| train-steps                    | 66000      |
| training/Q/q1_loss             | 83.394554  |
| training/sac_pi/alpha          | 0.1535053  |
| training/sac_pi/alpha_loss     | 0.24943534 |
| training/sac_pi/logp_pi        | 5.3731613  |
| training/sac_pi/pi_entropy     | 3.8348663  |
| training/sac_pi/pi_global_norm | 1.0313952  |
| training/sac_pi/policy_loss    | -182.11935 |
| training/sac_pi/std            | 0.57028633 |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 173.81007  |
| training/sac_Q/q2              | 174.29544  |
| training/sac_Q/q2_loss         | 83.30675   |
| training/sac_Q/q_global_norm   | 184.27155  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16096665  |
| epoch                          | 66          |
| evaluation/episode-length-avg  | 917         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 172         |
| evaluation/episode-length-std  | 248         |
| evaluation/return-average      | 4151.06     |
| evaluation/return-max          | 4624.6035   |
| evaluation/return-min          | 352.62476   |
| evaluation/return-std          | 1266.3584   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 83.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46034       |
| perf/AverageLength             | 917         |
| perf/AverageReturn             | 4151.06     |
| perf/NormalizedReturn          | 0.904       |
| Q-avg                          | 190.9428    |
| Q-std                          | 70.57533    |
| Q_loss                         | 77.590195   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 66          |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000565    |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00383     |
| times/timestep_before_hook     | 0.0081      |
| times/train                    | 58.4        |
| timestep                       | 1000        |
| timesteps_total                | 67000       |
| train-steps                    | 67000       |
| training/Q/q1_loss             | 93.84669    |
| training/sac_pi/alpha          | 0.16093995  |
| training/sac_pi/alpha_loss     | -0.30357286 |
| training/sac_pi/logp_pi        | 4.472022    |
| training/sac_pi/pi_entropy     | 3.817402    |
| training/sac_pi/pi_global_norm | 1.2933415   |
| training/sac_pi/policy_loss    | -184.20183  |
| training/sac_pi/std            | 0.54575485  |
| training/sac_pi/valid_num      | 4907.0      |
| training/sac_Q/q1              | 175.50113   |
| training/sac_Q/q2              | 176.17343   |
| training/sac_Q/q2_loss         | 93.69786    |
| training/sac_Q/q_global_norm   | 266.69092   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1640299  |
| epoch                          | 67         |
| evaluation/episode-length-avg  | 586        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 163        |
| evaluation/episode-length-std  | 414        |
| evaluation/return-average      | 2592.0046  |
| evaluation/return-max          | 4880.4536  |
| evaluation/return-min          | 390.7251   |
| evaluation/return-std          | 2174.882   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 84         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45749      |
| perf/AverageLength             | 586        |
| perf/AverageReturn             | 2592.0046  |
| perf/NormalizedReturn          | 0.564      |
| Q-avg                          | 183.12718  |
| Q-std                          | 82.866455  |
| Q_loss                         | 95.53639   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 67         |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000599   |
| times/evaluation_paths         | 19.5       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 59.2       |
| timestep                       | 1000       |
| timesteps_total                | 68000      |
| train-steps                    | 68000      |
| training/Q/q1_loss             | 77.64237   |
| training/sac_pi/alpha          | 0.16400725 |
| training/sac_pi/alpha_loss     | 0.15916002 |
| training/sac_pi/logp_pi        | 4.8663697  |
| training/sac_pi/pi_entropy     | 3.8375258  |
| training/sac_pi/pi_global_norm | 1.508279   |
| training/sac_pi/policy_loss    | -183.57227 |
| training/sac_pi/std            | 0.5615331  |
| training/sac_pi/valid_num      | 4945.0     |
| training/sac_Q/q1              | 176.85767  |
| training/sac_Q/q2              | 178.07576  |
| training/sac_Q/q2_loss         | 77.65379   |
| training/sac_Q/q_global_norm   | 306.66476  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16371147  |
| epoch                          | 68          |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4615.164    |
| evaluation/return-max          | 4695.4043   |
| evaluation/return-min          | 4484.9907   |
| evaluation/return-std          | 57.34199    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 82.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45831       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4615.164    |
| perf/NormalizedReturn          | 1           |
| Q-avg                          | 182.53256   |
| Q-std                          | 82.79286    |
| Q_loss                         | 97.91637    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 68          |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000528    |
| times/evaluation_paths         | 31.9        |
| times/timestep_after_hook      | 0.00383     |
| times/timestep_before_hook     | 0.00801     |
| times/train                    | 59.5        |
| timestep                       | 1000        |
| timesteps_total                | 69000       |
| train-steps                    | 69000       |
| training/Q/q1_loss             | 72.97395    |
| training/sac_pi/alpha          | 0.16369744  |
| training/sac_pi/alpha_loss     | -0.11573542 |
| training/sac_pi/logp_pi        | 4.136136    |
| training/sac_pi/pi_entropy     | 3.7585723   |
| training/sac_pi/pi_global_norm | 1.2885723   |
| training/sac_pi/policy_loss    | -186.60956  |
| training/sac_pi/std            | 0.5108102   |
| training/sac_pi/valid_num      | 4964.0      |
| training/sac_Q/q1              | 180.70064   |
| training/sac_Q/q2              | 180.18987   |
| training/sac_Q/q2_loss         | 72.790344   |
| training/sac_Q/q_global_norm   | 234.42369   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17134558   |
| epoch                          | 69           |
| evaluation/episode-length-avg  | 374          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 186          |
| evaluation/episode-length-std  | 315          |
| evaluation/return-average      | 1417.9465    |
| evaluation/return-max          | 4705.8477    |
| evaluation/return-min          | 463.32684    |
| evaluation/return-std          | 1644.2394    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.82         |
| model/origin_ret               | 84.8         |
| model/penalty_ret              | 83.4         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45792        |
| perf/AverageLength             | 374          |
| perf/AverageReturn             | 1417.9465    |
| perf/NormalizedReturn          | 0.309        |
| Q-avg                          | 174.37851    |
| Q-std                          | 90.86174     |
| Q_loss                         | 90.734665    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 69           |
| times/epoch_after_hook         | 1.85e-06     |
| times/epoch_before_hook        | 0.000255     |
| times/epoch_rollout_model      | 482          |
| times/evaluation_metrics       | 0.000478     |
| times/evaluation_paths         | 12.9         |
| times/timestep_after_hook      | 0.00386      |
| times/timestep_before_hook     | 0.00801      |
| times/train                    | 57.7         |
| timestep                       | 1000         |
| timesteps_total                | 70000        |
| train-steps                    | 70000        |
| training/Q/q1_loss             | 94.71769     |
| training/sac_pi/alpha          | 0.17130886   |
| training/sac_pi/alpha_loss     | -0.051233187 |
| training/sac_pi/logp_pi        | 4.533901     |
| training/sac_pi/pi_entropy     | 3.771006     |
| training/sac_pi/pi_global_norm | 1.398678     |
| training/sac_pi/policy_loss    | -187.16542   |
| training/sac_pi/std            | 0.5174164    |
| training/sac_pi/valid_num      | 4946.0       |
| training/sac_Q/q1              | 180.4072     |
| training/sac_Q/q2              | 180.52666    |
| training/sac_Q/q2_loss         | 94.44384     |
| training/sac_Q/q_global_norm   | 280.19516    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16080232 |
| epoch                          | 70         |
| evaluation/episode-length-avg  | 612        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 371        |
| evaluation/episode-length-std  | 289        |
| evaluation/return-average      | 2233.0215  |
| evaluation/return-max          | 4305.189   |
| evaluation/return-min          | 1056.5355  |
| evaluation/return-std          | 1426.3665  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45736      |
| perf/AverageLength             | 612        |
| perf/AverageReturn             | 2233.0215  |
| perf/NormalizedReturn          | 0.486      |
| Q-avg                          | 180.72928  |
| Q-std                          | 84.064026  |
| Q_loss                         | 73.559326  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 70         |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000146   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.00054    |
| times/evaluation_paths         | 20.4       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00809    |
| times/train                    | 57.4       |
| timestep                       | 1000       |
| timesteps_total                | 71000      |
| train-steps                    | 71000      |
| training/Q/q1_loss             | 85.47701   |
| training/sac_pi/alpha          | 0.16083844 |
| training/sac_pi/alpha_loss     | -0.1948468 |
| training/sac_pi/logp_pi        | 4.0111175  |
| training/sac_pi/pi_entropy     | 3.770637   |
| training/sac_pi/pi_global_norm | 1.3809305  |
| training/sac_pi/policy_loss    | -189.36893 |
| training/sac_pi/std            | 0.5181821  |
| training/sac_pi/valid_num      | 4940.0     |
| training/sac_Q/q1              | 181.81264  |
| training/sac_Q/q2              | 182.02022  |
| training/sac_Q/q2_loss         | 85.12376   |
| training/sac_Q/q_global_norm   | 263.18735  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16375485  |
| epoch                          | 71          |
| evaluation/episode-length-avg  | 576         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 289         |
| evaluation/episode-length-std  | 346         |
| evaluation/return-average      | 2262.3215   |
| evaluation/return-max          | 4544.326    |
| evaluation/return-min          | 783.50684   |
| evaluation/return-std          | 1796.9962   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.81        |
| model/origin_ret               | 83.4        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45887       |
| perf/AverageLength             | 576         |
| perf/AverageReturn             | 2262.3215   |
| perf/NormalizedReturn          | 0.492       |
| Q-avg                          | 176.51237   |
| Q-std                          | 81.948494   |
| Q_loss                         | 109.30062   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 71          |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000115    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000622    |
| times/evaluation_paths         | 17.9        |
| times/timestep_after_hook      | 0.00386     |
| times/timestep_before_hook     | 0.00799     |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 72000       |
| train-steps                    | 72000       |
| training/Q/q1_loss             | 89.30005    |
| training/sac_pi/alpha          | 0.16377982  |
| training/sac_pi/alpha_loss     | 0.055391174 |
| training/sac_pi/logp_pi        | 3.8695302   |
| training/sac_pi/pi_entropy     | 3.8637874   |
| training/sac_pi/pi_global_norm | 1.2996963   |
| training/sac_pi/policy_loss    | -177.2563   |
| training/sac_pi/std            | 0.5080444   |
| training/sac_pi/valid_num      | 4934.0      |
| training/sac_Q/q1              | 170.87004   |
| training/sac_Q/q2              | 170.84586   |
| training/sac_Q/q2_loss         | 89.31344    |
| training/sac_Q/q_global_norm   | 316.08124   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16607732   |
| epoch                          | 72           |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4658.54      |
| evaluation/return-max          | 4709.586     |
| evaluation/return-min          | 4584.0947    |
| evaluation/return-std          | 43.535126    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.84         |
| model/origin_ret               | 83.9         |
| model/penalty_ret              | 82.1         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45961        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4658.54      |
| perf/NormalizedReturn          | 1.01         |
| Q-avg                          | 171.55013    |
| Q-std                          | 88.7446      |
| Q_loss                         | 85.58896     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 72           |
| times/epoch_after_hook         | 3.34e-06     |
| times/epoch_before_hook        | 0.000128     |
| times/epoch_rollout_model      | 487          |
| times/evaluation_metrics       | 0.000512     |
| times/evaluation_paths         | 33.8         |
| times/timestep_after_hook      | 0.00387      |
| times/timestep_before_hook     | 0.00821      |
| times/train                    | 58.4         |
| timestep                       | 1000         |
| timesteps_total                | 73000        |
| train-steps                    | 73000        |
| training/Q/q1_loss             | 83.22999     |
| training/sac_pi/alpha          | 0.16607255   |
| training/sac_pi/alpha_loss     | -0.056390706 |
| training/sac_pi/logp_pi        | 4.122718     |
| training/sac_pi/pi_entropy     | 3.7391777    |
| training/sac_pi/pi_global_norm | 1.5036315    |
| training/sac_pi/policy_loss    | -186.82895   |
| training/sac_pi/std            | 0.5206614    |
| training/sac_pi/valid_num      | 4965.0       |
| training/sac_Q/q1              | 181.19756    |
| training/sac_Q/q2              | 181.33575    |
| training/sac_Q/q2_loss         | 83.76859     |
| training/sac_Q/q_global_norm   | 275.57855    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16733839  |
| epoch                          | 73          |
| evaluation/episode-length-avg  | 659         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 139         |
| evaluation/episode-length-std  | 418         |
| evaluation/return-average      | 3013.396    |
| evaluation/return-max          | 4822.1626   |
| evaluation/return-min          | 354.8157    |
| evaluation/return-std          | 2143.2185   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 82.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45838       |
| perf/AverageLength             | 659         |
| perf/AverageReturn             | 3013.396    |
| perf/NormalizedReturn          | 0.656       |
| Q-avg                          | 178.02547   |
| Q-std                          | 88.575325   |
| Q_loss                         | 101.47538   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 73          |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000305    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000527    |
| times/evaluation_paths         | 21.6        |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 58.8        |
| timestep                       | 1000        |
| timesteps_total                | 74000       |
| train-steps                    | 74000       |
| training/Q/q1_loss             | 88.17804    |
| training/sac_pi/alpha          | 0.1673146   |
| training/sac_pi/alpha_loss     | 0.029439485 |
| training/sac_pi/logp_pi        | 4.437108    |
| training/sac_pi/pi_entropy     | 4.1314597   |
| training/sac_pi/pi_global_norm | 1.279561    |
| training/sac_pi/policy_loss    | -180.25703  |
| training/sac_pi/std            | 0.56243366  |
| training/sac_pi/valid_num      | 4875.0      |
| training/sac_Q/q1              | 170.40227   |
| training/sac_Q/q2              | 170.31503   |
| training/sac_Q/q2_loss         | 88.748055   |
| training/sac_Q/q_global_norm   | 280.9798    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16197248 |
| epoch                          | 74         |
| evaluation/episode-length-avg  | 368        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 271        |
| evaluation/episode-length-std  | 211        |
| evaluation/return-average      | 1121.4865  |
| evaluation/return-max          | 4223.797   |
| evaluation/return-min          | 718.56024  |
| evaluation/return-std          | 1034.6476  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 82.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45490      |
| perf/AverageLength             | 368        |
| perf/AverageReturn             | 1121.4865  |
| perf/NormalizedReturn          | 0.244      |
| Q-avg                          | 176.5379   |
| Q-std                          | 98.026695  |
| Q_loss                         | 100.738045 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 74         |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000532   |
| times/evaluation_paths         | 13         |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 59.5       |
| timestep                       | 1000       |
| timesteps_total                | 75000      |
| train-steps                    | 75000      |
| training/Q/q1_loss             | 95.81506   |
| training/sac_pi/alpha          | 0.16195953 |
| training/sac_pi/alpha_loss     | 0.3484438  |
| training/sac_pi/logp_pi        | 4.7771974  |
| training/sac_pi/pi_entropy     | 3.6781306  |
| training/sac_pi/pi_global_norm | 1.361524   |
| training/sac_pi/policy_loss    | -190.82661 |
| training/sac_pi/std            | 0.5334034  |
| training/sac_pi/valid_num      | 4961.0     |
| training/sac_Q/q1              | 184.64946  |
| training/sac_Q/q2              | 183.56735  |
| training/sac_Q/q2_loss         | 96.53078   |
| training/sac_Q/q_global_norm   | 226.62302  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.162321   |
| epoch                          | 75         |
| evaluation/episode-length-avg  | 834        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 171        |
| evaluation/episode-length-std  | 332        |
| evaluation/return-average      | 3958.2866  |
| evaluation/return-max          | 4908.995   |
| evaluation/return-min          | 495.8523   |
| evaluation/return-std          | 1730.2062  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45912      |
| perf/AverageLength             | 834        |
| perf/AverageReturn             | 3958.2866  |
| perf/NormalizedReturn          | 0.862      |
| Q-avg                          | 172.3846   |
| Q-std                          | 94.14816   |
| Q_loss                         | 105.6924   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 75         |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000113   |
| times/epoch_rollout_model      | 515        |
| times/evaluation_metrics       | 0.000577   |
| times/evaluation_paths         | 27.5       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00809    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 76000      |
| train-steps                    | 76000      |
| training/Q/q1_loss             | 86.08572   |
| training/sac_pi/alpha          | 0.16235793 |
| training/sac_pi/alpha_loss     | -0.2438741 |
| training/sac_pi/logp_pi        | 4.178019   |
| training/sac_pi/pi_entropy     | 3.7644992  |
| training/sac_pi/pi_global_norm | 1.2253331  |
| training/sac_pi/policy_loss    | -185.81393 |
| training/sac_pi/std            | 0.5128738  |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 179.67545  |
| training/sac_Q/q2              | 179.52296  |
| training/sac_Q/q2_loss         | 86.19072   |
| training/sac_Q/q_global_norm   | 289.45444  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16119531  |
| epoch                          | 76          |
| evaluation/episode-length-avg  | 143         |
| evaluation/episode-length-max  | 144         |
| evaluation/episode-length-min  | 141         |
| evaluation/episode-length-std  | 1.2         |
| evaluation/return-average      | 367.00787   |
| evaluation/return-max          | 373.4624    |
| evaluation/return-min          | 359.64136   |
| evaluation/return-std          | 5.2209177   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 82.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45832       |
| perf/AverageLength             | 143         |
| perf/AverageReturn             | 367.00787   |
| perf/NormalizedReturn          | 0.0796      |
| Q-avg                          | 176.72563   |
| Q-std                          | 87.351456   |
| Q_loss                         | 96.71183    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 76          |
| times/epoch_after_hook         | 2.14e-06    |
| times/epoch_before_hook        | 0.000138    |
| times/epoch_rollout_model      | 529         |
| times/evaluation_metrics       | 0.000547    |
| times/evaluation_paths         | 4.39        |
| times/timestep_after_hook      | 0.00387     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 77000       |
| train-steps                    | 77000       |
| training/Q/q1_loss             | 95.189674   |
| training/sac_pi/alpha          | 0.16118552  |
| training/sac_pi/alpha_loss     | -0.17126974 |
| training/sac_pi/logp_pi        | 4.9789934   |
| training/sac_pi/pi_entropy     | 3.8108966   |
| training/sac_pi/pi_global_norm | 1.384201    |
| training/sac_pi/policy_loss    | -183.94586  |
| training/sac_pi/std            | 0.55559707  |
| training/sac_pi/valid_num      | 4914.0      |
| training/sac_Q/q1              | 174.62302   |
| training/sac_Q/q2              | 173.57834   |
| training/sac_Q/q2_loss         | 95.11265    |
| training/sac_Q/q_global_norm   | 325.2879    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1697212   |
| epoch                          | 77          |
| evaluation/episode-length-avg  | 696         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 240         |
| evaluation/episode-length-std  | 372         |
| evaluation/return-average      | 3209.271    |
| evaluation/return-max          | 4834.1606   |
| evaluation/return-min          | 833.7294    |
| evaluation/return-std          | 1928.8466   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45864       |
| perf/AverageLength             | 696         |
| perf/AverageReturn             | 3209.271    |
| perf/NormalizedReturn          | 0.699       |
| Q-avg                          | 176.20854   |
| Q-std                          | 86.22581    |
| Q_loss                         | 104.014145  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 77          |
| times/epoch_after_hook         | 1.98e-06    |
| times/epoch_before_hook        | 0.000251    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000714    |
| times/evaluation_paths         | 23.1        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00798     |
| times/train                    | 59.3        |
| timestep                       | 1000        |
| timesteps_total                | 78000       |
| train-steps                    | 78000       |
| training/Q/q1_loss             | 92.29921    |
| training/sac_pi/alpha          | 0.1697835   |
| training/sac_pi/alpha_loss     | -0.29985452 |
| training/sac_pi/logp_pi        | 4.125991    |
| training/sac_pi/pi_entropy     | 3.8268387   |
| training/sac_pi/pi_global_norm | 1.6294367   |
| training/sac_pi/policy_loss    | -191.26097  |
| training/sac_pi/std            | 0.52472013  |
| training/sac_pi/valid_num      | 4959.0      |
| training/sac_Q/q1              | 184.82439   |
| training/sac_Q/q2              | 184.35228   |
| training/sac_Q/q2_loss         | 93.0812     |
| training/sac_Q/q_global_norm   | 383.57846   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17193863  |
| epoch                          | 78          |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5013.7725   |
| evaluation/return-max          | 5035.203    |
| evaluation/return-min          | 4990.881    |
| evaluation/return-std          | 14.4462805  |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.79        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 83.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45478       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5013.7725   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 171.53728   |
| Q-std                          | 91.757805   |
| Q_loss                         | 93.8631     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 78          |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.00058     |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00802     |
| times/train                    | 58.4        |
| timestep                       | 1000        |
| timesteps_total                | 79000       |
| train-steps                    | 79000       |
| training/Q/q1_loss             | 102.40019   |
| training/sac_pi/alpha          | 0.1719446   |
| training/sac_pi/alpha_loss     | 0.110938154 |
| training/sac_pi/logp_pi        | 4.0440254   |
| training/sac_pi/pi_entropy     | 3.9049487   |
| training/sac_pi/pi_global_norm | 1.1976646   |
| training/sac_pi/policy_loss    | -183.22466  |
| training/sac_pi/std            | 0.5191792   |
| training/sac_pi/valid_num      | 4901.0      |
| training/sac_Q/q1              | 175.69519   |
| training/sac_Q/q2              | 175.65486   |
| training/sac_Q/q2_loss         | 102.152596  |
| training/sac_Q/q_global_norm   | 253.47992   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1657908  |
| epoch                          | 79         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4671.8955  |
| evaluation/return-max          | 4700.9946  |
| evaluation/return-min          | 4628.9487  |
| evaluation/return-std          | 20.671911  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 82.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45913      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4671.8955  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 181.95158  |
| Q-std                          | 85.7502    |
| Q_loss                         | 80.92938   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 79         |
| times/epoch_after_hook         | 2e-06      |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000598   |
| times/evaluation_paths         | 31.9       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00809    |
| times/train                    | 58         |
| timestep                       | 1000       |
| timesteps_total                | 80000      |
| train-steps                    | 80000      |
| training/Q/q1_loss             | 101.79845  |
| training/sac_pi/alpha          | 0.16582513 |
| training/sac_pi/alpha_loss     | -0.1599652 |
| training/sac_pi/logp_pi        | 3.9289513  |
| training/sac_pi/pi_entropy     | 3.745385   |
| training/sac_pi/pi_global_norm | 1.310413   |
| training/sac_pi/policy_loss    | -190.15213 |
| training/sac_pi/std            | 0.50796735 |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 185.62823  |
| training/sac_Q/q2              | 186.08994  |
| training/sac_Q/q2_loss         | 101.104675 |
| training/sac_Q/q_global_norm   | 249.01369  |
--------------------------------------------------------------------------------
[WARN] 80 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16846372 |
| epoch                          | 80         |
| evaluation/episode-length-avg  | 741        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 522        |
| evaluation/episode-length-std  | 187        |
| evaluation/return-average      | 3194.3218  |
| evaluation/return-max          | 4533.996   |
| evaluation/return-min          | 2018.5875  |
| evaluation/return-std          | 947.22974  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 83.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45759      |
| perf/AverageLength             | 741        |
| perf/AverageReturn             | 3194.3218  |
| perf/NormalizedReturn          | 0.695      |
| Q-avg                          | 177.04344  |
| Q-std                          | 92.56259   |
| Q_loss                         | 89.70619   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 80         |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000503   |
| times/evaluation_paths         | 24.9       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 81000      |
| train-steps                    | 81000      |
| training/Q/q1_loss             | 97.81724   |
| training/sac_pi/alpha          | 0.1684816  |
| training/sac_pi/alpha_loss     | 0.24214517 |
| training/sac_pi/logp_pi        | 4.3189983  |
| training/sac_pi/pi_entropy     | 3.710362   |
| training/sac_pi/pi_global_norm | 1.9259005  |
| training/sac_pi/policy_loss    | -192.11699 |
| training/sac_pi/std            | 0.5110256  |
| training/sac_pi/valid_num      | 5011.0     |
| training/sac_Q/q1              | 186.8997   |
| training/sac_Q/q2              | 186.71469  |
| training/sac_Q/q2_loss         | 96.88307   |
| training/sac_Q/q_global_norm   | 209.36386  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16895638  |
| epoch                          | 81          |
| evaluation/episode-length-avg  | 825         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 409         |
| evaluation/episode-length-std  | 268         |
| evaluation/return-average      | 3450.2676   |
| evaluation/return-max          | 4475.4873   |
| evaluation/return-min          | 1126.8732   |
| evaluation/return-std          | 1499.7361   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.78        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 83.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45850       |
| perf/AverageLength             | 825         |
| perf/AverageReturn             | 3450.2676   |
| perf/NormalizedReturn          | 0.751       |
| Q-avg                          | 179.75049   |
| Q-std                          | 94.47913    |
| Q_loss                         | 109.64812   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 81          |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000302    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000554    |
| times/evaluation_paths         | 26.8        |
| times/timestep_after_hook      | 0.00393     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 59.3        |
| timestep                       | 1000        |
| timesteps_total                | 82000       |
| train-steps                    | 82000       |
| training/Q/q1_loss             | 79.25013    |
| training/sac_pi/alpha          | 0.1689519   |
| training/sac_pi/alpha_loss     | -0.11495244 |
| training/sac_pi/logp_pi        | 4.3039885   |
| training/sac_pi/pi_entropy     | 4.0550714   |
| training/sac_pi/pi_global_norm | 1.6976486   |
| training/sac_pi/policy_loss    | -184.18915  |
| training/sac_pi/std            | 0.5414791   |
| training/sac_pi/valid_num      | 4928.0      |
| training/sac_Q/q1              | 176.28073   |
| training/sac_Q/q2              | 175.86125   |
| training/sac_Q/q2_loss         | 79.602615   |
| training/sac_Q/q_global_norm   | 221.63339   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1593326  |
| epoch                          | 82         |
| evaluation/episode-length-avg  | 659        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 296        |
| evaluation/episode-length-std  | 343        |
| evaluation/return-average      | 2759.2935  |
| evaluation/return-max          | 4570.4272  |
| evaluation/return-min          | 939.6415   |
| evaluation/return-std          | 1734.7773  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45947      |
| perf/AverageLength             | 659        |
| perf/AverageReturn             | 2759.2935  |
| perf/NormalizedReturn          | 0.601      |
| Q-avg                          | 183.47928  |
| Q-std                          | 90.20849   |
| Q_loss                         | 88.88975   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 82         |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000518   |
| times/evaluation_paths         | 21.7       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 58.9       |
| timestep                       | 1000       |
| timesteps_total                | 83000      |
| train-steps                    | 83000      |
| training/Q/q1_loss             | 93.70778   |
| training/sac_pi/alpha          | 0.159335   |
| training/sac_pi/alpha_loss     | -0.207662  |
| training/sac_pi/logp_pi        | 4.563345   |
| training/sac_pi/pi_entropy     | 3.6945908  |
| training/sac_pi/pi_global_norm | 2.0509884  |
| training/sac_pi/policy_loss    | -189.3538  |
| training/sac_pi/std            | 0.5347112  |
| training/sac_pi/valid_num      | 4947.0     |
| training/sac_Q/q1              | 181.6073   |
| training/sac_Q/q2              | 181.38344  |
| training/sac_Q/q2_loss         | 93.382164  |
| training/sac_Q/q_global_norm   | 326.8719   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.162447    |
| epoch                          | 83          |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 3514.1987   |
| evaluation/return-max          | 3754.5537   |
| evaluation/return-min          | 3306.8057   |
| evaluation/return-std          | 122.06968   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46209       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 3514.1987   |
| perf/NormalizedReturn          | 0.765       |
| Q-avg                          | 177.7402    |
| Q-std                          | 87.96795    |
| Q_loss                         | 97.997116   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 83          |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000569    |
| times/evaluation_paths         | 33.5        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.00803     |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 84000       |
| train-steps                    | 84000       |
| training/Q/q1_loss             | 111.047844  |
| training/sac_pi/alpha          | 0.16248319  |
| training/sac_pi/alpha_loss     | -0.13753653 |
| training/sac_pi/logp_pi        | 4.283685    |
| training/sac_pi/pi_entropy     | 3.7897613   |
| training/sac_pi/pi_global_norm | 1.3671407   |
| training/sac_pi/policy_loss    | -182.0296   |
| training/sac_pi/std            | 0.53170896  |
| training/sac_pi/valid_num      | 4943.0      |
| training/sac_Q/q1              | 175.06131   |
| training/sac_Q/q2              | 174.83653   |
| training/sac_Q/q2_loss         | 111.45187   |
| training/sac_Q/q_global_norm   | 271.26727   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15615079 |
| epoch                          | 84         |
| evaluation/episode-length-avg  | 829        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 141        |
| evaluation/episode-length-std  | 342        |
| evaluation/return-average      | 4100.2314  |
| evaluation/return-max          | 5073.334   |
| evaluation/return-min          | 398.87048  |
| evaluation/return-std          | 1839.7819  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46012      |
| perf/AverageLength             | 829        |
| perf/AverageReturn             | 4100.2314  |
| perf/NormalizedReturn          | 0.893      |
| Q-avg                          | 184.51587  |
| Q-std                          | 98.6592    |
| Q_loss                         | 123.54375  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 84         |
| times/epoch_after_hook         | 2.2e-06    |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000578   |
| times/evaluation_paths         | 28.6       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 85000      |
| train-steps                    | 85000      |
| training/Q/q1_loss             | 85.707085  |
| training/sac_pi/alpha          | 0.15610443 |
| training/sac_pi/alpha_loss     | 0.13125862 |
| training/sac_pi/logp_pi        | 4.277972   |
| training/sac_pi/pi_entropy     | 3.7928329  |
| training/sac_pi/pi_global_norm | 1.5465853  |
| training/sac_pi/policy_loss    | -189.10457 |
| training/sac_pi/std            | 0.5258744  |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 182.47043  |
| training/sac_Q/q2              | 182.0895   |
| training/sac_Q/q2_loss         | 84.50261   |
| training/sac_Q/q_global_norm   | 299.70587  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15869777  |
| epoch                          | 85          |
| evaluation/episode-length-avg  | 647         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 285         |
| evaluation/episode-length-std  | 353         |
| evaluation/return-average      | 2914.0542   |
| evaluation/return-max          | 5085.6523   |
| evaluation/return-min          | 969.49854   |
| evaluation/return-std          | 1911.2042   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 82.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45822       |
| perf/AverageLength             | 647         |
| perf/AverageReturn             | 2914.0542   |
| perf/NormalizedReturn          | 0.634       |
| Q-avg                          | 178.67436   |
| Q-std                          | 92.29621    |
| Q_loss                         | 103.70454   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 85          |
| times/epoch_after_hook         | 3.42e-06    |
| times/epoch_before_hook        | 0.000246    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000576    |
| times/evaluation_paths         | 21.4        |
| times/timestep_after_hook      | 0.00385     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 58.5        |
| timestep                       | 1000        |
| timesteps_total                | 86000       |
| train-steps                    | 86000       |
| training/Q/q1_loss             | 101.91535   |
| training/sac_pi/alpha          | 0.15868999  |
| training/sac_pi/alpha_loss     | 0.012681796 |
| training/sac_pi/logp_pi        | 4.49982     |
| training/sac_pi/pi_entropy     | 3.7719522   |
| training/sac_pi/pi_global_norm | 1.5863549   |
| training/sac_pi/policy_loss    | -187.03651  |
| training/sac_pi/std            | 0.5282472   |
| training/sac_pi/valid_num      | 4974.0      |
| training/sac_Q/q1              | 180.4261    |
| training/sac_Q/q2              | 180.878     |
| training/sac_Q/q2_loss         | 101.804955  |
| training/sac_Q/q_global_norm   | 241.03796   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15957037 |
| epoch                          | 86         |
| evaluation/episode-length-avg  | 885        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 315        |
| evaluation/episode-length-std  | 235        |
| evaluation/return-average      | 3714.7993  |
| evaluation/return-max          | 4510.5947  |
| evaluation/return-min          | 865.1098   |
| evaluation/return-std          | 1205.419   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45995      |
| perf/AverageLength             | 885        |
| perf/AverageReturn             | 3714.7993  |
| perf/NormalizedReturn          | 0.809      |
| Q-avg                          | 175.39642  |
| Q-std                          | 91.45498   |
| Q_loss                         | 96.12925   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 86         |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.00011    |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000686   |
| times/evaluation_paths         | 29.2       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 87000      |
| train-steps                    | 87000      |
| training/Q/q1_loss             | 86.00142   |
| training/sac_pi/alpha          | 0.15959467 |
| training/sac_pi/alpha_loss     | -0.435334  |
| training/sac_pi/logp_pi        | 4.261489   |
| training/sac_pi/pi_entropy     | 3.6783166  |
| training/sac_pi/pi_global_norm | 1.4859664  |
| training/sac_pi/policy_loss    | -190.22601 |
| training/sac_pi/std            | 0.52117556 |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 183.98117  |
| training/sac_Q/q2              | 184.83768  |
| training/sac_Q/q2_loss         | 87.17894   |
| training/sac_Q/q_global_norm   | 374.7637   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16935496  |
| epoch                          | 87          |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4540.4546   |
| evaluation/return-max          | 4572.2495   |
| evaluation/return-min          | 4462.279    |
| evaluation/return-std          | 31.114464   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.81        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 84.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45708       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4540.4546   |
| perf/NormalizedReturn          | 0.989       |
| Q-avg                          | 176.86256   |
| Q-std                          | 97.89019    |
| Q_loss                         | 83.56829    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 87          |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000157    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000682    |
| times/evaluation_paths         | 43.9        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 58.7        |
| timestep                       | 1000        |
| timesteps_total                | 88000       |
| train-steps                    | 88000       |
| training/Q/q1_loss             | 91.70175    |
| training/sac_pi/alpha          | 0.16933632  |
| training/sac_pi/alpha_loss     | -0.47197756 |
| training/sac_pi/logp_pi        | 3.3357613   |
| training/sac_pi/pi_entropy     | 3.919108    |
| training/sac_pi/pi_global_norm | 1.5366457   |
| training/sac_pi/policy_loss    | -191.10472  |
| training/sac_pi/std            | 0.50695926  |
| training/sac_pi/valid_num      | 4974.0      |
| training/sac_Q/q1              | 186.09004   |
| training/sac_Q/q2              | 186.33151   |
| training/sac_Q/q2_loss         | 93.186264   |
| training/sac_Q/q_global_norm   | 247.01674   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16596684  |
| epoch                          | 88          |
| evaluation/episode-length-avg  | 30.3        |
| evaluation/episode-length-max  | 31          |
| evaluation/episode-length-min  | 30          |
| evaluation/episode-length-std  | 0.458       |
| evaluation/return-average      | 24.070377   |
| evaluation/return-max          | 26.847702   |
| evaluation/return-min          | 22.538034   |
| evaluation/return-std          | 1.6731015   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45846       |
| perf/AverageLength             | 30.3        |
| perf/AverageReturn             | 24.070377   |
| perf/NormalizedReturn          | 0.00489     |
| Q-avg                          | 178.12057   |
| Q-std                          | 87.317406   |
| Q_loss                         | 81.47341    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 88          |
| times/epoch_after_hook         | 1.62e-06    |
| times/epoch_before_hook        | 0.000179    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000411    |
| times/evaluation_paths         | 1.41        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 67.3        |
| timestep                       | 1000        |
| timesteps_total                | 89000       |
| train-steps                    | 89000       |
| training/Q/q1_loss             | 86.932465   |
| training/sac_pi/alpha          | 0.1659932   |
| training/sac_pi/alpha_loss     | -0.15758759 |
| training/sac_pi/logp_pi        | 4.5091176   |
| training/sac_pi/pi_entropy     | 3.7943587   |
| training/sac_pi/pi_global_norm | 1.5322      |
| training/sac_pi/policy_loss    | -180.44131  |
| training/sac_pi/std            | 0.53376275  |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 174.67226   |
| training/sac_Q/q2              | 174.21858   |
| training/sac_Q/q2_loss         | 87.20863    |
| training/sac_Q/q_global_norm   | 334.67996   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1684377  |
| epoch                          | 89         |
| evaluation/episode-length-avg  | 929        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 287        |
| evaluation/episode-length-std  | 214        |
| evaluation/return-average      | 4477.374   |
| evaluation/return-max          | 4907.1387  |
| evaluation/return-min          | 984.87524  |
| evaluation/return-std          | 1164.4381  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.84       |
| model/origin_ret               | 83.4       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46008      |
| perf/AverageLength             | 929        |
| perf/AverageReturn             | 4477.374   |
| perf/NormalizedReturn          | 0.975      |
| Q-avg                          | 186.03793  |
| Q-std                          | 87.35762   |
| Q_loss                         | 107.646095 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 89         |
| times/epoch_after_hook         | 2.02e-06   |
| times/epoch_before_hook        | 0.00046    |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000622   |
| times/evaluation_paths         | 42.9       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 60.2       |
| timestep                       | 1000       |
| timesteps_total                | 90000      |
| train-steps                    | 90000      |
| training/Q/q1_loss             | 99.80496   |
| training/sac_pi/alpha          | 0.16845769 |
| training/sac_pi/alpha_loss     | 0.2299822  |
| training/sac_pi/logp_pi        | 3.8371239  |
| training/sac_pi/pi_entropy     | 3.6033974  |
| training/sac_pi/pi_global_norm | 1.4030465  |
| training/sac_pi/policy_loss    | -194.53767 |
| training/sac_pi/std            | 0.4849076  |
| training/sac_pi/valid_num      | 5006.0     |
| training/sac_Q/q1              | 190.8899   |
| training/sac_Q/q2              | 190.77274  |
| training/sac_Q/q2_loss         | 100.2022   |
| training/sac_Q/q_global_norm   | 243.88353  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16564104   |
| epoch                          | 90           |
| evaluation/episode-length-avg  | 831          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 151          |
| evaluation/episode-length-std  | 339          |
| evaluation/return-average      | 4154.876     |
| evaluation/return-max          | 5133.8438    |
| evaluation/return-min          | 494.47287    |
| evaluation/return-std          | 1825.2917    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.97         |
| model/origin_ret               | 86.4         |
| model/penalty_ret              | 82.8         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45764        |
| perf/AverageLength             | 831          |
| perf/AverageReturn             | 4154.876     |
| perf/NormalizedReturn          | 0.905        |
| Q-avg                          | 191.48409    |
| Q-std                          | 85.81759     |
| Q_loss                         | 72.21755     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 90           |
| times/epoch_after_hook         | 1.9e-06      |
| times/epoch_before_hook        | 0.000176     |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.000587     |
| times/evaluation_paths         | 36.7         |
| times/timestep_after_hook      | 0.00393      |
| times/timestep_before_hook     | 0.00821      |
| times/train                    | 67.5         |
| timestep                       | 1000         |
| timesteps_total                | 91000        |
| train-steps                    | 91000        |
| training/Q/q1_loss             | 87.96578     |
| training/sac_pi/alpha          | 0.16564241   |
| training/sac_pi/alpha_loss     | -0.100085974 |
| training/sac_pi/logp_pi        | 4.1831365    |
| training/sac_pi/pi_entropy     | 3.8404088    |
| training/sac_pi/pi_global_norm | 1.6548253    |
| training/sac_pi/policy_loss    | -192.34727   |
| training/sac_pi/std            | 0.5246393    |
| training/sac_pi/valid_num      | 5008.0       |
| training/sac_Q/q1              | 188.46613    |
| training/sac_Q/q2              | 188.30563    |
| training/sac_Q/q2_loss         | 87.14101     |
| training/sac_Q/q_global_norm   | 280.9979     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16697729 |
| epoch                          | 91         |
| evaluation/episode-length-avg  | 806        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 317        |
| evaluation/episode-length-std  | 298        |
| evaluation/return-average      | 3569.4817  |
| evaluation/return-max          | 4592.502   |
| evaluation/return-min          | 1178.3223  |
| evaluation/return-std          | 1471.0812  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45919      |
| perf/AverageLength             | 806        |
| perf/AverageReturn             | 3569.4817  |
| perf/NormalizedReturn          | 0.777      |
| Q-avg                          | 178.76706  |
| Q-std                          | 89.14345   |
| Q_loss                         | 86.26661   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 91         |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.0005     |
| times/evaluation_paths         | 36.7       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00809    |
| times/train                    | 66         |
| timestep                       | 1000       |
| timesteps_total                | 92000      |
| train-steps                    | 92000      |
| training/Q/q1_loss             | 87.381134  |
| training/sac_pi/alpha          | 0.16695127 |
| training/sac_pi/alpha_loss     | 0.13074434 |
| training/sac_pi/logp_pi        | 4.278076   |
| training/sac_pi/pi_entropy     | 3.616099   |
| training/sac_pi/pi_global_norm | 1.2006103  |
| training/sac_pi/policy_loss    | -188.10461 |
| training/sac_pi/std            | 0.50085694 |
| training/sac_pi/valid_num      | 4962.0     |
| training/sac_Q/q1              | 180.65945  |
| training/sac_Q/q2              | 180.82259  |
| training/sac_Q/q2_loss         | 86.49655   |
| training/sac_Q/q_global_norm   | 229.27979  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16274594  |
| epoch                          | 92          |
| evaluation/episode-length-avg  | 144         |
| evaluation/episode-length-max  | 149         |
| evaluation/episode-length-min  | 141         |
| evaluation/episode-length-std  | 2.52        |
| evaluation/return-average      | 451.774     |
| evaluation/return-max          | 474.56277   |
| evaluation/return-min          | 441.2738    |
| evaluation/return-std          | 10.989379   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.89        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 82.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46077       |
| perf/AverageLength             | 144         |
| perf/AverageReturn             | 451.774     |
| perf/NormalizedReturn          | 0.0981      |
| Q-avg                          | 191.89865   |
| Q-std                          | 89.71446    |
| Q_loss                         | 77.47277    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 92          |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000154    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000513    |
| times/evaluation_paths         | 6.57        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 70.4        |
| timestep                       | 1000        |
| timesteps_total                | 93000       |
| train-steps                    | 93000       |
| training/Q/q1_loss             | 73.36255    |
| training/sac_pi/alpha          | 0.16274449  |
| training/sac_pi/alpha_loss     | -0.49143076 |
| training/sac_pi/logp_pi        | 4.1480613   |
| training/sac_pi/pi_entropy     | 3.7358117   |
| training/sac_pi/pi_global_norm | 1.1371149   |
| training/sac_pi/policy_loss    | -189.41151  |
| training/sac_pi/std            | 0.53005767  |
| training/sac_pi/valid_num      | 4929.0      |
| training/sac_Q/q1              | 181.2731    |
| training/sac_Q/q2              | 181.52658   |
| training/sac_Q/q2_loss         | 73.38812    |
| training/sac_Q/q_global_norm   | 196.37549   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16295257 |
| epoch                          | 93         |
| evaluation/episode-length-avg  | 234        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 141        |
| evaluation/episode-length-std  | 255        |
| evaluation/return-average      | 925.05695  |
| evaluation/return-max          | 4749.893   |
| evaluation/return-min          | 474.5904   |
| evaluation/return-std          | 1275.0576  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 83.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46002      |
| perf/AverageLength             | 234        |
| perf/AverageReturn             | 925.05695  |
| perf/NormalizedReturn          | 0.201      |
| Q-avg                          | 183.04126  |
| Q-std                          | 95.74944   |
| Q_loss                         | 88.93654   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 93         |
| times/epoch_after_hook         | 2.18e-06   |
| times/epoch_before_hook        | 0.000262   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000602   |
| times/evaluation_paths         | 10.8       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 63.2       |
| timestep                       | 1000       |
| timesteps_total                | 94000      |
| train-steps                    | 94000      |
| training/Q/q1_loss             | 82.747475  |
| training/sac_pi/alpha          | 0.16297156 |
| training/sac_pi/alpha_loss     | -0.3624656 |
| training/sac_pi/logp_pi        | 3.892025   |
| training/sac_pi/pi_entropy     | 3.7650158  |
| training/sac_pi/pi_global_norm | 1.411951   |
| training/sac_pi/policy_loss    | -190.24866 |
| training/sac_pi/std            | 0.5113529  |
| training/sac_pi/valid_num      | 4993.0     |
| training/sac_Q/q1              | 185.52525  |
| training/sac_Q/q2              | 185.2748   |
| training/sac_Q/q2_loss         | 82.38983   |
| training/sac_Q/q_global_norm   | 277.41058  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16071315 |
| epoch                          | 94         |
| evaluation/episode-length-avg  | 245        |
| evaluation/episode-length-max  | 510        |
| evaluation/episode-length-min  | 196        |
| evaluation/episode-length-std  | 98.2       |
| evaluation/return-average      | 720.2434   |
| evaluation/return-max          | 1836.5414  |
| evaluation/return-min          | 522.91125  |
| evaluation/return-std          | 400.55942  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 82.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45963      |
| perf/AverageLength             | 245        |
| perf/AverageReturn             | 720.2434   |
| perf/NormalizedReturn          | 0.157      |
| Q-avg                          | 185.53398  |
| Q-std                          | 89.057594  |
| Q_loss                         | 94.92327   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 94         |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000143   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000605   |
| times/evaluation_paths         | 7.94       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 95000      |
| train-steps                    | 95000      |
| training/Q/q1_loss             | 102.104355 |
| training/sac_pi/alpha          | 0.16066857 |
| training/sac_pi/alpha_loss     | 0.20338525 |
| training/sac_pi/logp_pi        | 5.0261555  |
| training/sac_pi/pi_entropy     | 4.038205   |
| training/sac_pi/pi_global_norm | 1.1608604  |
| training/sac_pi/policy_loss    | -183.22502 |
| training/sac_pi/std            | 0.5788947  |
| training/sac_pi/valid_num      | 4840.0     |
| training/sac_Q/q1              | 172.36763  |
| training/sac_Q/q2              | 172.27036  |
| training/sac_Q/q2_loss         | 102.19743  |
| training/sac_Q/q_global_norm   | 238.99094  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17021231 |
| epoch                          | 95         |
| evaluation/episode-length-avg  | 155        |
| evaluation/episode-length-max  | 165        |
| evaluation/episode-length-min  | 147        |
| evaluation/episode-length-std  | 5.92       |
| evaluation/return-average      | 387.0455   |
| evaluation/return-max          | 421.34515  |
| evaluation/return-min          | 360.8389   |
| evaluation/return-std          | 21.405043  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.82       |
| model/origin_ret               | 82.1       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45824      |
| perf/AverageLength             | 155        |
| perf/AverageReturn             | 387.0455   |
| perf/NormalizedReturn          | 0.084      |
| Q-avg                          | 192.26437  |
| Q-std                          | 88.68155   |
| Q_loss                         | 88.07794   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 95         |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.0005     |
| times/evaluation_paths         | 5.19       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 96000      |
| train-steps                    | 96000      |
| training/Q/q1_loss             | 84.81532   |
| training/sac_pi/alpha          | 0.1701404  |
| training/sac_pi/alpha_loss     | 0.24009028 |
| training/sac_pi/logp_pi        | 3.5788727  |
| training/sac_pi/pi_entropy     | 3.8699105  |
| training/sac_pi/pi_global_norm | 1.2202157  |
| training/sac_pi/policy_loss    | -193.5703  |
| training/sac_pi/std            | 0.49940416 |
| training/sac_pi/valid_num      | 4999.0     |
| training/sac_Q/q1              | 189.12776  |
| training/sac_Q/q2              | 188.89214  |
| training/sac_Q/q2_loss         | 84.59521   |
| training/sac_Q/q_global_norm   | 198.40976  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16697276 |
| epoch                          | 96         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4937.862   |
| evaluation/return-max          | 4983.571   |
| evaluation/return-min          | 4888.033   |
| evaluation/return-std          | 31.555653  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 87.3       |
| model/penalty_ret              | 83.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45628      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4937.862   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 178.17842  |
| Q-std                          | 99.84165   |
| Q_loss                         | 90.866936  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 96         |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 8.13e-05   |
| times/epoch_rollout_model      | 526        |
| times/evaluation_metrics       | 0.000508   |
| times/evaluation_paths         | 40.1       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 97000      |
| train-steps                    | 97000      |
| training/Q/q1_loss             | 94.22059   |
| training/sac_pi/alpha          | 0.16693549 |
| training/sac_pi/alpha_loss     | 0.13346434 |
| training/sac_pi/logp_pi        | 4.132167   |
| training/sac_pi/pi_entropy     | 3.7388825  |
| training/sac_pi/pi_global_norm | 1.3948674  |
| training/sac_pi/policy_loss    | -181.15047 |
| training/sac_pi/std            | 0.50522584 |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 175.35376  |
| training/sac_Q/q2              | 175.20183  |
| training/sac_Q/q2_loss         | 94.37346   |
| training/sac_Q/q_global_norm   | 214.38971  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16769464   |
| epoch                          | 97           |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4646.4897    |
| evaluation/return-max          | 4785.216     |
| evaluation/return-min          | 4586.258     |
| evaluation/return-std          | 51.781578    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.93         |
| model/origin_ret               | 86.1         |
| model/penalty_ret              | 83.2         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45935        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4646.4897    |
| perf/NormalizedReturn          | 1.01         |
| Q-avg                          | 182.35687    |
| Q-std                          | 95.37089     |
| Q_loss                         | 99.78334     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 97           |
| times/epoch_after_hook         | 1.84e-06     |
| times/epoch_before_hook        | 0.000309     |
| times/epoch_rollout_model      | 489          |
| times/evaluation_metrics       | 0.000596     |
| times/evaluation_paths         | 42.6         |
| times/timestep_after_hook      | 0.00388      |
| times/timestep_before_hook     | 0.00821      |
| times/train                    | 59.1         |
| timestep                       | 1000         |
| timesteps_total                | 98000        |
| train-steps                    | 98000        |
| training/Q/q1_loss             | 90.511215    |
| training/sac_pi/alpha          | 0.16769248   |
| training/sac_pi/alpha_loss     | -0.038655628 |
| training/sac_pi/logp_pi        | 5.0608416    |
| training/sac_pi/pi_entropy     | 3.7936249    |
| training/sac_pi/pi_global_norm | 1.5986451    |
| training/sac_pi/policy_loss    | -197.73409   |
| training/sac_pi/std            | 0.5590756    |
| training/sac_pi/valid_num      | 4919.0       |
| training/sac_Q/q1              | 186.16908    |
| training/sac_Q/q2              | 185.91817    |
| training/sac_Q/q2_loss         | 90.14527     |
| training/sac_Q/q_global_norm   | 306.01428    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17027421 |
| epoch                          | 98         |
| evaluation/episode-length-avg  | 679        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 514        |
| evaluation/episode-length-std  | 170        |
| evaluation/return-average      | 2972.6204  |
| evaluation/return-max          | 4826.638   |
| evaluation/return-min          | 2096.0947  |
| evaluation/return-std          | 925.2391   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 87.4       |
| model/penalty_ret              | 83.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45924      |
| perf/AverageLength             | 679        |
| perf/AverageReturn             | 2972.6204  |
| perf/NormalizedReturn          | 0.647      |
| Q-avg                          | 181.23633  |
| Q-std                          | 91.34562   |
| Q_loss                         | 90.41025   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 98         |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000505   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 99000      |
| train-steps                    | 99000      |
| training/Q/q1_loss             | 84.21029   |
| training/sac_pi/alpha          | 0.17026003 |
| training/sac_pi/alpha_loss     | 0.33510357 |
| training/sac_pi/logp_pi        | 4.326777   |
| training/sac_pi/pi_entropy     | 3.8374448  |
| training/sac_pi/pi_global_norm | 1.4128857  |
| training/sac_pi/policy_loss    | -190.32086 |
| training/sac_pi/std            | 0.5330817  |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 183.6424   |
| training/sac_Q/q2              | 183.45752  |
| training/sac_Q/q2_loss         | 83.879974  |
| training/sac_Q/q_global_norm   | 310.9735   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16403565  |
| epoch                          | 99          |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5209.7646   |
| evaluation/return-max          | 5239.636    |
| evaluation/return-min          | 5187.5566   |
| evaluation/return-std          | 16.315437   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45890       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5209.7646   |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 179.18929   |
| Q-std                          | 94.14199    |
| Q_loss                         | 118.35672   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 99          |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000154    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000688    |
| times/evaluation_paths         | 44          |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 64.4        |
| timestep                       | 1000        |
| timesteps_total                | 100000      |
| train-steps                    | 100000      |
| training/Q/q1_loss             | 85.15663    |
| training/sac_pi/alpha          | 0.16412441  |
| training/sac_pi/alpha_loss     | -0.48544893 |
| training/sac_pi/logp_pi        | 4.4701085   |
| training/sac_pi/pi_entropy     | 3.6847606   |
| training/sac_pi/pi_global_norm | 2.252251    |
| training/sac_pi/policy_loss    | -190.86385  |
| training/sac_pi/std            | 0.52895147  |
| training/sac_pi/valid_num      | 4942.0      |
| training/sac_Q/q1              | 183.11917   |
| training/sac_Q/q2              | 182.91728   |
| training/sac_Q/q2_loss         | 85.837265   |
| training/sac_Q/q_global_norm   | 276.14474   |
---------------------------------------------------------------------------------
[WARN] 100 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.1644721   |
| epoch                          | 100         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5135.1396   |
| evaluation/return-max          | 5172.546    |
| evaluation/return-min          | 5086.856    |
| evaluation/return-std          | 21.485888   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 82.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45943       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5135.1396   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 188.77359   |
| Q-std                          | 87.72037    |
| Q_loss                         | 106.62241   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 100         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.0006      |
| times/evaluation_paths         | 44.2        |
| times/timestep_after_hook      | 0.00393     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 64.6        |
| timestep                       | 1000        |
| timesteps_total                | 101000      |
| train-steps                    | 101000      |
| training/Q/q1_loss             | 88.61525    |
| training/sac_pi/alpha          | 0.16450587  |
| training/sac_pi/alpha_loss     | -0.35133132 |
| training/sac_pi/logp_pi        | 4.7350054   |
| training/sac_pi/pi_entropy     | 3.6814542   |
| training/sac_pi/pi_global_norm | 1.3719757   |
| training/sac_pi/policy_loss    | -196.38579  |
| training/sac_pi/std            | 0.55190057  |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 188.85217   |
| training/sac_Q/q2              | 188.82071   |
| training/sac_Q/q2_loss         | 89.1911     |
| training/sac_Q/q_global_norm   | 254.13576   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16445124 |
| epoch                          | 101        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4661.9893  |
| evaluation/return-max          | 4800.165   |
| evaluation/return-min          | 4567.212   |
| evaluation/return-std          | 69.39      |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46031      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4661.9893  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 183.8195   |
| Q-std                          | 92.48785   |
| Q_loss                         | 111.07621  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 101        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000306   |
| times/epoch_rollout_model      | 515        |
| times/evaluation_metrics       | 0.000854   |
| times/evaluation_paths         | 44.1       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 65.4       |
| timestep                       | 1000       |
| timesteps_total                | 102000     |
| train-steps                    | 102000     |
| training/Q/q1_loss             | 108.549736 |
| training/sac_pi/alpha          | 0.16443491 |
| training/sac_pi/alpha_loss     | 0.43722248 |
| training/sac_pi/logp_pi        | 5.7280755  |
| training/sac_pi/pi_entropy     | 4.054251   |
| training/sac_pi/pi_global_norm | 1.3506947  |
| training/sac_pi/policy_loss    | -188.19048 |
| training/sac_pi/std            | 0.6190631  |
| training/sac_pi/valid_num      | 4848.0     |
| training/sac_Q/q1              | 174.55228  |
| training/sac_Q/q2              | 173.18198  |
| training/sac_Q/q2_loss         | 109.23938  |
| training/sac_Q/q_global_norm   | 378.91992  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1594421  |
| epoch                          | 102        |
| evaluation/episode-length-avg  | 857        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 373        |
| evaluation/episode-length-std  | 197        |
| evaluation/return-average      | 4020.4849  |
| evaluation/return-max          | 4793.49    |
| evaluation/return-min          | 1565.2041  |
| evaluation/return-std          | 1007.4049  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 87.2       |
| model/penalty_ret              | 83.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45743      |
| perf/AverageLength             | 857        |
| perf/AverageReturn             | 4020.4849  |
| perf/NormalizedReturn          | 0.875      |
| Q-avg                          | 173.55466  |
| Q-std                          | 105.083    |
| Q_loss                         | 101.1769   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 102        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000153   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000655   |
| times/evaluation_paths         | 38.2       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00806    |
| times/train                    | 66.3       |
| timestep                       | 1000       |
| timesteps_total                | 103000     |
| train-steps                    | 103000     |
| training/Q/q1_loss             | 75.1958    |
| training/sac_pi/alpha          | 0.15945344 |
| training/sac_pi/alpha_loss     | -0.1360566 |
| training/sac_pi/logp_pi        | 4.2679358  |
| training/sac_pi/pi_entropy     | 3.603019   |
| training/sac_pi/pi_global_norm | 1.348615   |
| training/sac_pi/policy_loss    | -192.58284 |
| training/sac_pi/std            | 0.5238084  |
| training/sac_pi/valid_num      | 4970.0     |
| training/sac_Q/q1              | 185.82776  |
| training/sac_Q/q2              | 185.50267  |
| training/sac_Q/q2_loss         | 75.66191   |
| training/sac_Q/q_global_norm   | 174.41158  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16131796 |
| epoch                          | 103        |
| evaluation/episode-length-avg  | 233        |
| evaluation/episode-length-max  | 932        |
| evaluation/episode-length-min  | 153        |
| evaluation/episode-length-std  | 233        |
| evaluation/return-average      | 924.78064  |
| evaluation/return-max          | 4649.9614  |
| evaluation/return-min          | 494.26074  |
| evaluation/return-std          | 1241.745   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46008      |
| perf/AverageLength             | 233        |
| perf/AverageReturn             | 924.78064  |
| perf/NormalizedReturn          | 0.201      |
| Q-avg                          | 191.19394  |
| Q-std                          | 93.35863   |
| Q_loss                         | 95.1726    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 103        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000615   |
| times/evaluation_paths         | 8.9        |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 73.9       |
| timestep                       | 1000       |
| timesteps_total                | 104000     |
| train-steps                    | 104000     |
| training/Q/q1_loss             | 76.54298   |
| training/sac_pi/alpha          | 0.16134338 |
| training/sac_pi/alpha_loss     | -0.3096894 |
| training/sac_pi/logp_pi        | 3.9695706  |
| training/sac_pi/pi_entropy     | 3.5100303  |
| training/sac_pi/pi_global_norm | 1.4146631  |
| training/sac_pi/policy_loss    | -192.11409 |
| training/sac_pi/std            | 0.49825662 |
| training/sac_pi/valid_num      | 5008.0     |
| training/sac_Q/q1              | 186.41365  |
| training/sac_Q/q2              | 187.44955  |
| training/sac_Q/q2_loss         | 75.692535  |
| training/sac_Q/q_global_norm   | 262.2324   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15496427  |
| epoch                          | 104         |
| evaluation/episode-length-avg  | 922         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 589         |
| evaluation/episode-length-std  | 157         |
| evaluation/return-average      | 4460.825    |
| evaluation/return-max          | 4949.264    |
| evaluation/return-min          | 2769.9421   |
| evaluation/return-std          | 818.7425    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45818       |
| perf/AverageLength             | 922         |
| perf/AverageReturn             | 4460.825    |
| perf/NormalizedReturn          | 0.971       |
| Q-avg                          | 186.0094    |
| Q-std                          | 93.56618    |
| Q_loss                         | 80.695244   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 104         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000111    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000512    |
| times/evaluation_paths         | 36.9        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 68.7        |
| timestep                       | 1000        |
| timesteps_total                | 105000      |
| train-steps                    | 105000      |
| training/Q/q1_loss             | 97.30303    |
| training/sac_pi/alpha          | 0.15497075  |
| training/sac_pi/alpha_loss     | 0.060843155 |
| training/sac_pi/logp_pi        | 3.9959378   |
| training/sac_pi/pi_entropy     | 3.5640252   |
| training/sac_pi/pi_global_norm | 1.3734742   |
| training/sac_pi/policy_loss    | -197.3264   |
| training/sac_pi/std            | 0.50073624  |
| training/sac_pi/valid_num      | 4975.0      |
| training/sac_Q/q1              | 191.30478   |
| training/sac_Q/q2              | 191.86632   |
| training/sac_Q/q2_loss         | 96.93745    |
| training/sac_Q/q_global_norm   | 312.7787    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16322185 |
| epoch                          | 105        |
| evaluation/episode-length-avg  | 149        |
| evaluation/episode-length-max  | 151        |
| evaluation/episode-length-min  | 145        |
| evaluation/episode-length-std  | 2.07       |
| evaluation/return-average      | 521.57446  |
| evaluation/return-max          | 531.94354  |
| evaluation/return-min          | 503.7641   |
| evaluation/return-std          | 8.794714   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45966      |
| perf/AverageLength             | 149        |
| perf/AverageReturn             | 521.57446  |
| perf/NormalizedReturn          | 0.113      |
| Q-avg                          | 182.44894  |
| Q-std                          | 97.62633   |
| Q_loss                         | 107.30296  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 105        |
| times/epoch_after_hook         | 2.02e-06   |
| times/epoch_before_hook        | 0.000305   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000666   |
| times/evaluation_paths         | 5.35       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00806    |
| times/train                    | 71.5       |
| timestep                       | 1000       |
| timesteps_total                | 106000     |
| train-steps                    | 106000     |
| training/Q/q1_loss             | 88.75649   |
| training/sac_pi/alpha          | 0.16319315 |
| training/sac_pi/alpha_loss     | 0.10134591 |
| training/sac_pi/logp_pi        | 4.253408   |
| training/sac_pi/pi_entropy     | 3.5453084  |
| training/sac_pi/pi_global_norm | 1.6396006  |
| training/sac_pi/policy_loss    | -193.53801 |
| training/sac_pi/std            | 0.5041451  |
| training/sac_pi/valid_num      | 4962.0     |
| training/sac_Q/q1              | 185.78732  |
| training/sac_Q/q2              | 185.78181  |
| training/sac_Q/q2_loss         | 89.145226  |
| training/sac_Q/q_global_norm   | 236.74263  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16378635 |
| epoch                          | 106        |
| evaluation/episode-length-avg  | 967        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 668        |
| evaluation/episode-length-std  | 99.6       |
| evaluation/return-average      | 4537.5107  |
| evaluation/return-max          | 4785.1943  |
| evaluation/return-min          | 2991.0474  |
| evaluation/return-std          | 520.6979   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 83.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45719      |
| perf/AverageLength             | 967        |
| perf/AverageReturn             | 4537.5107  |
| perf/NormalizedReturn          | 0.988      |
| Q-avg                          | 189.66537  |
| Q-std                          | 92.12209   |
| Q_loss                         | 84.001686  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 106        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000503   |
| times/evaluation_paths         | 41.3       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 67.2       |
| timestep                       | 1000       |
| timesteps_total                | 107000     |
| train-steps                    | 107000     |
| training/Q/q1_loss             | 117.23465  |
| training/sac_pi/alpha          | 0.16378313 |
| training/sac_pi/alpha_loss     | 0.13872981 |
| training/sac_pi/logp_pi        | 4.766623   |
| training/sac_pi/pi_entropy     | 3.5024161  |
| training/sac_pi/pi_global_norm | 1.4848651  |
| training/sac_pi/policy_loss    | -192.57182 |
| training/sac_pi/std            | 0.50188196 |
| training/sac_pi/valid_num      | 4944.0     |
| training/sac_Q/q1              | 184.5583   |
| training/sac_Q/q2              | 184.99496  |
| training/sac_Q/q2_loss         | 117.18535  |
| training/sac_Q/q_global_norm   | 311.49222  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17362675 |
| epoch                          | 107        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5062.1743  |
| evaluation/return-max          | 5091.258   |
| evaluation/return-min          | 5021.423   |
| evaluation/return-std          | 22.848148  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45973      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5062.1743  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 186.60521  |
| Q-std                          | 98.12296   |
| Q_loss                         | 78.40789   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 107        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000202   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000647   |
| times/evaluation_paths         | 37.4       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 70         |
| timestep                       | 1000       |
| timesteps_total                | 108000     |
| train-steps                    | 108000     |
| training/Q/q1_loss             | 104.17555  |
| training/sac_pi/alpha          | 0.17366351 |
| training/sac_pi/alpha_loss     | -0.539329  |
| training/sac_pi/logp_pi        | 4.5894246  |
| training/sac_pi/pi_entropy     | 3.9262524  |
| training/sac_pi/pi_global_norm | 1.3617373  |
| training/sac_pi/policy_loss    | -183.69095 |
| training/sac_pi/std            | 0.5628062  |
| training/sac_pi/valid_num      | 4932.0     |
| training/sac_Q/q1              | 174.72641  |
| training/sac_Q/q2              | 174.75053  |
| training/sac_Q/q2_loss         | 105.38567  |
| training/sac_Q/q_global_norm   | 272.99704  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17111778 |
| epoch                          | 108        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4735.1694  |
| evaluation/return-max          | 4804.978   |
| evaluation/return-min          | 4623.967   |
| evaluation/return-std          | 51.718636  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46077      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4735.1694  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 179.75046  |
| Q-std                          | 85.93789   |
| Q_loss                         | 104.07427  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 108        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000511   |
| times/evaluation_paths         | 35.1       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 70.8       |
| timestep                       | 1000       |
| timesteps_total                | 109000     |
| train-steps                    | 109000     |
| training/Q/q1_loss             | 105.60681  |
| training/sac_pi/alpha          | 0.17104842 |
| training/sac_pi/alpha_loss     | 0.44188988 |
| training/sac_pi/logp_pi        | 4.722534   |
| training/sac_pi/pi_entropy     | 3.7601097  |
| training/sac_pi/pi_global_norm | 1.5069606  |
| training/sac_pi/policy_loss    | -198.26225 |
| training/sac_pi/std            | 0.5415767  |
| training/sac_pi/valid_num      | 4925.0     |
| training/sac_Q/q1              | 188.94388  |
| training/sac_Q/q2              | 189.25581  |
| training/sac_Q/q2_loss         | 105.8442   |
| training/sac_Q/q_global_norm   | 315.69077  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16962531 |
| epoch                          | 109        |
| evaluation/episode-length-avg  | 836        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 179        |
| evaluation/episode-length-std  | 328        |
| evaluation/return-average      | 3574.5137  |
| evaluation/return-max          | 4403.1294  |
| evaluation/return-min          | 416.58624  |
| evaluation/return-std          | 1577.9137  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 86.8       |
| model/penalty_ret              | 83.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45718      |
| perf/AverageLength             | 836        |
| perf/AverageReturn             | 3574.5137  |
| perf/NormalizedReturn          | 0.778      |
| Q-avg                          | 184.96393  |
| Q-std                          | 98.07183   |
| Q_loss                         | 92.51785   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 109        |
| times/epoch_after_hook         | 1.97e-06   |
| times/epoch_before_hook        | 0.000257   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.0007     |
| times/evaluation_paths         | 30.9       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 72.9       |
| timestep                       | 1000       |
| timesteps_total                | 110000     |
| train-steps                    | 110000     |
| training/Q/q1_loss             | 94.39178   |
| training/sac_pi/alpha          | 0.16960786 |
| training/sac_pi/alpha_loss     | -0.2871112 |
| training/sac_pi/logp_pi        | 4.1529694  |
| training/sac_pi/pi_entropy     | 3.6442935  |
| training/sac_pi/pi_global_norm | 1.8162314  |
| training/sac_pi/policy_loss    | -197.09341 |
| training/sac_pi/std            | 0.5094545  |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 191.3179   |
| training/sac_Q/q2              | 190.84398  |
| training/sac_Q/q2_loss         | 95.28559   |
| training/sac_Q/q_global_norm   | 232.78384  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17252675  |
| epoch                          | 110         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4707.629    |
| evaluation/return-max          | 4778.1187   |
| evaluation/return-min          | 4607.8345   |
| evaluation/return-std          | 50.634743   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46180       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4707.629    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 182.97801   |
| Q-std                          | 95.15989    |
| Q_loss                         | 107.38025   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 110         |
| times/epoch_after_hook         | 3.19e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000577    |
| times/evaluation_paths         | 33.2        |
| times/timestep_after_hook      | 0.00387     |
| times/timestep_before_hook     | 0.0081      |
| times/train                    | 73.3        |
| timestep                       | 1000        |
| timesteps_total                | 111000      |
| train-steps                    | 111000      |
| training/Q/q1_loss             | 71.70121    |
| training/sac_pi/alpha          | 0.17251348  |
| training/sac_pi/alpha_loss     | -0.03623419 |
| training/sac_pi/logp_pi        | 4.6295214   |
| training/sac_pi/pi_entropy     | 3.599043    |
| training/sac_pi/pi_global_norm | 1.1520324   |
| training/sac_pi/policy_loss    | -188.25085  |
| training/sac_pi/std            | 0.51413035  |
| training/sac_pi/valid_num      | 4939.0      |
| training/sac_Q/q1              | 179.21533   |
| training/sac_Q/q2              | 177.5927    |
| training/sac_Q/q2_loss         | 72.079384   |
| training/sac_Q/q_global_norm   | 299.06332   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1727498  |
| epoch                          | 111        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4215.062   |
| evaluation/return-max          | 4334.071   |
| evaluation/return-min          | 3967.846   |
| evaluation/return-std          | 106.35115  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46034      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4215.062   |
| perf/NormalizedReturn          | 0.918      |
| Q-avg                          | 187.31665  |
| Q-std                          | 86.72874   |
| Q_loss                         | 93.72701   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 111        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000681   |
| times/evaluation_paths         | 36.6       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 67.1       |
| timestep                       | 1000       |
| timesteps_total                | 112000     |
| train-steps                    | 112000     |
| training/Q/q1_loss             | 89.88179   |
| training/sac_pi/alpha          | 0.17274323 |
| training/sac_pi/alpha_loss     | 0.24796218 |
| training/sac_pi/logp_pi        | 4.297316   |
| training/sac_pi/pi_entropy     | 3.612493   |
| training/sac_pi/pi_global_norm | 1.6353457  |
| training/sac_pi/policy_loss    | -186.99036 |
| training/sac_pi/std            | 0.4962819  |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 180.89589  |
| training/sac_Q/q2              | 179.92542  |
| training/sac_Q/q2_loss         | 89.31      |
| training/sac_Q/q_global_norm   | 259.5032   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17051256  |
| epoch                          | 112         |
| evaluation/episode-length-avg  | 587         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 142         |
| evaluation/episode-length-std  | 415         |
| evaluation/return-average      | 2673.2795   |
| evaluation/return-max          | 4847.667    |
| evaluation/return-min          | 456.14697   |
| evaluation/return-std          | 2083.281    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 83          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45746       |
| perf/AverageLength             | 587         |
| perf/AverageReturn             | 2673.2795   |
| perf/NormalizedReturn          | 0.582       |
| Q-avg                          | 194.16331   |
| Q-std                          | 81.00962    |
| Q_loss                         | 83.18881    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 112         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000555    |
| times/evaluation_paths         | 19.9        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 69.1        |
| timestep                       | 1000        |
| timesteps_total                | 113000      |
| train-steps                    | 113000      |
| training/Q/q1_loss             | 97.319954   |
| training/sac_pi/alpha          | 0.1705335   |
| training/sac_pi/alpha_loss     | -0.30158222 |
| training/sac_pi/logp_pi        | 3.8868089   |
| training/sac_pi/pi_entropy     | 3.7222457   |
| training/sac_pi/pi_global_norm | 1.4278259   |
| training/sac_pi/policy_loss    | -182.91576  |
| training/sac_pi/std            | 0.50460654  |
| training/sac_pi/valid_num      | 4965.0      |
| training/sac_Q/q1              | 177.26729   |
| training/sac_Q/q2              | 177.22633   |
| training/sac_Q/q2_loss         | 97.66906    |
| training/sac_Q/q_global_norm   | 362.88556   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1705302  |
| epoch                          | 113        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 1153.6853  |
| evaluation/return-max          | 1161.0149  |
| evaluation/return-min          | 1146.2489  |
| evaluation/return-std          | 4.038341   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45952      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 1153.6853  |
| perf/NormalizedReturn          | 0.251      |
| Q-avg                          | 187.97354  |
| Q-std                          | 89.17766   |
| Q_loss                         | 79.22831   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 113        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.00031    |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000588   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 71.4       |
| timestep                       | 1000       |
| timesteps_total                | 114000     |
| train-steps                    | 114000     |
| training/Q/q1_loss             | 95.35435   |
| training/sac_pi/alpha          | 0.17052864 |
| training/sac_pi/alpha_loss     | 0.0863733  |
| training/sac_pi/logp_pi        | 4.7716     |
| training/sac_pi/pi_entropy     | 3.7429283  |
| training/sac_pi/pi_global_norm | 1.0912551  |
| training/sac_pi/policy_loss    | -196.734   |
| training/sac_pi/std            | 0.548239   |
| training/sac_pi/valid_num      | 4973.0     |
| training/sac_Q/q1              | 189.40196  |
| training/sac_Q/q2              | 188.88103  |
| training/sac_Q/q2_loss         | 95.2462    |
| training/sac_Q/q_global_norm   | 236.81447  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16131814 |
| epoch                          | 114        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4887.88    |
| evaluation/return-max          | 4950.7627  |
| evaluation/return-min          | 4830.851   |
| evaluation/return-std          | 34.309055  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46053      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4887.88    |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 200.30293  |
| Q-std                          | 91.989075  |
| Q_loss                         | 76.93155   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 114        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000142   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.00061    |
| times/evaluation_paths         | 36.1       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 68.3       |
| timestep                       | 1000       |
| timesteps_total                | 115000     |
| train-steps                    | 115000     |
| training/Q/q1_loss             | 88.67011   |
| training/sac_pi/alpha          | 0.16125154 |
| training/sac_pi/alpha_loss     | 0.3408559  |
| training/sac_pi/logp_pi        | 4.3535776  |
| training/sac_pi/pi_entropy     | 3.6863754  |
| training/sac_pi/pi_global_norm | 1.2567534  |
| training/sac_pi/policy_loss    | -196.50461 |
| training/sac_pi/std            | 0.517945   |
| training/sac_pi/valid_num      | 4990.0     |
| training/sac_Q/q1              | 191.24509  |
| training/sac_Q/q2              | 190.49654  |
| training/sac_Q/q2_loss         | 88.49329   |
| training/sac_Q/q_global_norm   | 224.94739  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16342336 |
| epoch                          | 115        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4880.669   |
| evaluation/return-max          | 4961.379   |
| evaluation/return-min          | 4753.6025  |
| evaluation/return-std          | 55.958717  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 82.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45666      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4880.669   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 177.23172  |
| Q-std                          | 96.1832    |
| Q_loss                         | 97.18311   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 115        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000643   |
| times/evaluation_paths         | 33.3       |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 70.4       |
| timestep                       | 1000       |
| timesteps_total                | 116000     |
| train-steps                    | 116000     |
| training/Q/q1_loss             | 83.41557   |
| training/sac_pi/alpha          | 0.16339825 |
| training/sac_pi/alpha_loss     | 0.24357817 |
| training/sac_pi/logp_pi        | 3.899079   |
| training/sac_pi/pi_entropy     | 3.5488846  |
| training/sac_pi/pi_global_norm | 1.6242594  |
| training/sac_pi/policy_loss    | -188.52296 |
| training/sac_pi/std            | 0.48267785 |
| training/sac_pi/valid_num      | 4995.0     |
| training/sac_Q/q1              | 183.90854  |
| training/sac_Q/q2              | 183.3111   |
| training/sac_Q/q2_loss         | 83.98566   |
| training/sac_Q/q_global_norm   | 381.9507   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16042024  |
| epoch                          | 116         |
| evaluation/episode-length-avg  | 141         |
| evaluation/episode-length-max  | 145         |
| evaluation/episode-length-min  | 138         |
| evaluation/episode-length-std  | 2.7         |
| evaluation/return-average      | 453.30615   |
| evaluation/return-max          | 469.72858   |
| evaluation/return-min          | 437.5239    |
| evaluation/return-std          | 9.424029    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45965       |
| perf/AverageLength             | 141         |
| perf/AverageReturn             | 453.30615   |
| perf/NormalizedReturn          | 0.0984      |
| Q-avg                          | 191.54105   |
| Q-std                          | 95.56757    |
| Q_loss                         | 93.482155   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 116         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000506    |
| times/evaluation_paths         | 5.35        |
| times/timestep_after_hook      | 0.00382     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 117000      |
| train-steps                    | 117000      |
| training/Q/q1_loss             | 74.61967    |
| training/sac_pi/alpha          | 0.160437    |
| training/sac_pi/alpha_loss     | -0.08581727 |
| training/sac_pi/logp_pi        | 3.7660058   |
| training/sac_pi/pi_entropy     | 3.6363502   |
| training/sac_pi/pi_global_norm | 1.5098251   |
| training/sac_pi/policy_loss    | -198.50244  |
| training/sac_pi/std            | 0.49822918  |
| training/sac_pi/valid_num      | 4971.0      |
| training/sac_Q/q1              | 192.8481    |
| training/sac_Q/q2              | 193.13495   |
| training/sac_Q/q2_loss         | 74.116264   |
| training/sac_Q/q_global_norm   | 335.09927   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16091515 |
| epoch                          | 117        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4868.66    |
| evaluation/return-max          | 5034.381   |
| evaluation/return-min          | 4720.082   |
| evaluation/return-std          | 84.12126   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46106      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4868.66    |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 178.73746  |
| Q-std                          | 113.643486 |
| Q_loss                         | 105.177475 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 117        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000253   |
| times/epoch_rollout_model      | 523        |
| times/evaluation_metrics       | 0.000554   |
| times/evaluation_paths         | 32.9       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 65         |
| timestep                       | 1000       |
| timesteps_total                | 118000     |
| train-steps                    | 118000     |
| training/Q/q1_loss             | 99.58521   |
| training/sac_pi/alpha          | 0.16089487 |
| training/sac_pi/alpha_loss     | 0.1924403  |
| training/sac_pi/logp_pi        | 4.4622107  |
| training/sac_pi/pi_entropy     | 3.6240983  |
| training/sac_pi/pi_global_norm | 1.9039055  |
| training/sac_pi/policy_loss    | -197.28001 |
| training/sac_pi/std            | 0.501109   |
| training/sac_pi/valid_num      | 4981.0     |
| training/sac_Q/q1              | 190.52731  |
| training/sac_Q/q2              | 190.10364  |
| training/sac_Q/q2_loss         | 100.17183  |
| training/sac_Q/q_global_norm   | 292.82306  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15981352 |
| epoch                          | 118        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 3735.518   |
| evaluation/return-max          | 3874.5374  |
| evaluation/return-min          | 3576.2207  |
| evaluation/return-std          | 97.86603   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 82.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46041      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 3735.518   |
| perf/NormalizedReturn          | 0.813      |
| Q-avg                          | 197.74295  |
| Q-std                          | 81.05232   |
| Q_loss                         | 103.21719  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 118        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000624   |
| times/evaluation_paths         | 32.8       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 119000     |
| train-steps                    | 119000     |
| training/Q/q1_loss             | 77.1884    |
| training/sac_pi/alpha          | 0.15976387 |
| training/sac_pi/alpha_loss     | 0.38224563 |
| training/sac_pi/logp_pi        | 5.4187226  |
| training/sac_pi/pi_entropy     | 3.786969   |
| training/sac_pi/pi_global_norm | 1.3044981  |
| training/sac_pi/policy_loss    | -195.07587 |
| training/sac_pi/std            | 0.57109296 |
| training/sac_pi/valid_num      | 4804.0     |
| training/sac_Q/q1              | 181.13199  |
| training/sac_Q/q2              | 179.72342  |
| training/sac_Q/q2_loss         | 77.45305   |
| training/sac_Q/q_global_norm   | 240.42407  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16037804  |
| epoch                          | 119         |
| evaluation/episode-length-avg  | 179         |
| evaluation/episode-length-max  | 367         |
| evaluation/episode-length-min  | 148         |
| evaluation/episode-length-std  | 63.4        |
| evaluation/return-average      | 596.7667    |
| evaluation/return-max          | 1552.9652   |
| evaluation/return-min          | 446.3844    |
| evaluation/return-std          | 320.41714   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 87.1        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46067       |
| perf/AverageLength             | 179         |
| perf/AverageReturn             | 596.7667    |
| perf/NormalizedReturn          | 0.13        |
| Q-avg                          | 192.77573   |
| Q-std                          | 90.51393    |
| Q_loss                         | 103.7479    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 119         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000147    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000532    |
| times/evaluation_paths         | 5.74        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00803     |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 120000      |
| train-steps                    | 120000      |
| training/Q/q1_loss             | 79.847786   |
| training/sac_pi/alpha          | 0.16043492  |
| training/sac_pi/alpha_loss     | -0.59977937 |
| training/sac_pi/logp_pi        | 4.0767913   |
| training/sac_pi/pi_entropy     | 3.7042804   |
| training/sac_pi/pi_global_norm | 1.7840091   |
| training/sac_pi/policy_loss    | -198.17957  |
| training/sac_pi/std            | 0.52027214  |
| training/sac_pi/valid_num      | 4944.0      |
| training/sac_Q/q1              | 190.04158   |
| training/sac_Q/q2              | 189.59758   |
| training/sac_Q/q2_loss         | 79.82       |
| training/sac_Q/q_global_norm   | 191.14221   |
---------------------------------------------------------------------------------
[WARN] 120 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.16992086   |
| epoch                          | 120          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4806.637     |
| evaluation/return-max          | 4866.0684    |
| evaluation/return-min          | 4722.248     |
| evaluation/return-std          | 48.738644    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.92         |
| model/origin_ret               | 83.2         |
| model/penalty_ret              | 81           |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45828        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4806.637     |
| perf/NormalizedReturn          | 1.05         |
| Q-avg                          | 191.8945     |
| Q-std                          | 93.71046     |
| Q_loss                         | 62.735218    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 120          |
| times/epoch_after_hook         | 1.79e-06     |
| times/epoch_before_hook        | 9.04e-05     |
| times/epoch_rollout_model      | 479          |
| times/evaluation_metrics       | 0.000574     |
| times/evaluation_paths         | 32.8         |
| times/timestep_after_hook      | 0.00389      |
| times/timestep_before_hook     | 0.00798      |
| times/train                    | 60.5         |
| timestep                       | 1000         |
| timesteps_total                | 121000       |
| train-steps                    | 121000       |
| training/Q/q1_loss             | 103.630165   |
| training/sac_pi/alpha          | 0.16991405   |
| training/sac_pi/alpha_loss     | -0.038444106 |
| training/sac_pi/logp_pi        | 4.8752112    |
| training/sac_pi/pi_entropy     | 3.6833599    |
| training/sac_pi/pi_global_norm | 1.3994185    |
| training/sac_pi/policy_loss    | -201.53041   |
| training/sac_pi/std            | 0.5232612    |
| training/sac_pi/valid_num      | 4911.0       |
| training/sac_Q/q1              | 192.86838    |
| training/sac_Q/q2              | 191.85815    |
| training/sac_Q/q2_loss         | 103.248      |
| training/sac_Q/q_global_norm   | 254.34485    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.163421    |
| epoch                          | 121         |
| evaluation/episode-length-avg  | 751         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 484         |
| evaluation/episode-length-std  | 224         |
| evaluation/return-average      | 2475.167    |
| evaluation/return-max          | 3797.699    |
| evaluation/return-min          | 1229.2256   |
| evaluation/return-std          | 1094.409    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 87.1        |
| model/penalty_ret              | 83.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45871       |
| perf/AverageLength             | 751         |
| perf/AverageReturn             | 2475.167    |
| perf/NormalizedReturn          | 0.539       |
| Q-avg                          | 183.44229   |
| Q-std                          | 95.69767    |
| Q_loss                         | 83.650215   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 121         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.00028     |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000703    |
| times/evaluation_paths         | 25.9        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 62.9        |
| timestep                       | 1000        |
| timesteps_total                | 122000      |
| train-steps                    | 122000      |
| training/Q/q1_loss             | 92.43774    |
| training/sac_pi/alpha          | 0.1633999   |
| training/sac_pi/alpha_loss     | -0.10715412 |
| training/sac_pi/logp_pi        | 3.9736495   |
| training/sac_pi/pi_entropy     | 3.8063316   |
| training/sac_pi/pi_global_norm | 1.5009415   |
| training/sac_pi/policy_loss    | -182.14938  |
| training/sac_pi/std            | 0.5189559   |
| training/sac_pi/valid_num      | 4956.0      |
| training/sac_Q/q1              | 175.86923   |
| training/sac_Q/q2              | 175.04074   |
| training/sac_Q/q2_loss         | 93.72855    |
| training/sac_Q/q_global_norm   | 292.17322   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16634335   |
| epoch                          | 122          |
| evaluation/episode-length-avg  | 350          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 168          |
| evaluation/episode-length-std  | 325          |
| evaluation/return-average      | 1311.5383    |
| evaluation/return-max          | 4690.4014    |
| evaluation/return-min          | 434.18903    |
| evaluation/return-std          | 1675.0529    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.9          |
| model/origin_ret               | 83.2         |
| model/penalty_ret              | 80.7         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46115        |
| perf/AverageLength             | 350          |
| perf/AverageReturn             | 1311.5383    |
| perf/NormalizedReturn          | 0.285        |
| Q-avg                          | 189.17911    |
| Q-std                          | 96.52999     |
| Q_loss                         | 88.111176    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 122          |
| times/epoch_after_hook         | 1.85e-06     |
| times/epoch_before_hook        | 0.00013      |
| times/epoch_rollout_model      | 481          |
| times/evaluation_metrics       | 0.00069      |
| times/evaluation_paths         | 11.6         |
| times/timestep_after_hook      | 0.00388      |
| times/timestep_before_hook     | 0.00801      |
| times/train                    | 61.7         |
| timestep                       | 1000         |
| timesteps_total                | 123000       |
| train-steps                    | 123000       |
| training/Q/q1_loss             | 97.50893     |
| training/sac_pi/alpha          | 0.16633622   |
| training/sac_pi/alpha_loss     | 0.0050225197 |
| training/sac_pi/logp_pi        | 3.8866642    |
| training/sac_pi/pi_entropy     | 3.757529     |
| training/sac_pi/pi_global_norm | 1.5231913    |
| training/sac_pi/policy_loss    | -193.77026   |
| training/sac_pi/std            | 0.5129301    |
| training/sac_pi/valid_num      | 4966.0       |
| training/sac_Q/q1              | 187.88977    |
| training/sac_Q/q2              | 187.8321     |
| training/sac_Q/q2_loss         | 98.30453     |
| training/sac_Q/q_global_norm   | 293.78485    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16913909   |
| epoch                          | 123          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4866.2734    |
| evaluation/return-max          | 4896.2944    |
| evaluation/return-min          | 4844.2173    |
| evaluation/return-std          | 17.095135    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.07         |
| model/origin_ret               | 87           |
| model/penalty_ret              | 82.1         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46108        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4866.2734    |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 191.66176    |
| Q-std                          | 95.284904    |
| Q_loss                         | 100.07341    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 123          |
| times/epoch_after_hook         | 1.91e-06     |
| times/epoch_before_hook        | 0.000113     |
| times/epoch_rollout_model      | 482          |
| times/evaluation_metrics       | 0.000615     |
| times/evaluation_paths         | 33.2         |
| times/timestep_after_hook      | 0.00398      |
| times/timestep_before_hook     | 0.00809      |
| times/train                    | 63.2         |
| timestep                       | 1000         |
| timesteps_total                | 124000       |
| train-steps                    | 124000       |
| training/Q/q1_loss             | 99.23687     |
| training/sac_pi/alpha          | 0.16913855   |
| training/sac_pi/alpha_loss     | -0.037315056 |
| training/sac_pi/logp_pi        | 5.2065234    |
| training/sac_pi/pi_entropy     | 3.742372     |
| training/sac_pi/pi_global_norm | 1.3587471    |
| training/sac_pi/policy_loss    | -198.35689   |
| training/sac_pi/std            | 0.56379724   |
| training/sac_pi/valid_num      | 4904.0       |
| training/sac_Q/q1              | 186.88737    |
| training/sac_Q/q2              | 186.40756    |
| training/sac_Q/q2_loss         | 99.893585    |
| training/sac_Q/q_global_norm   | 320.54742    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16360523 |
| epoch                          | 124        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4370.1377  |
| evaluation/return-max          | 4643.1406  |
| evaluation/return-min          | 3999.1863  |
| evaluation/return-std          | 195.69815  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45956      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4370.1377  |
| perf/NormalizedReturn          | 0.952      |
| Q-avg                          | 194.9816   |
| Q-std                          | 90.85132   |
| Q_loss                         | 115.2618   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 124        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000643   |
| times/evaluation_paths         | 34.1       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 64.3       |
| timestep                       | 1000       |
| timesteps_total                | 125000     |
| train-steps                    | 125000     |
| training/Q/q1_loss             | 107.02539  |
| training/sac_pi/alpha          | 0.16355823 |
| training/sac_pi/alpha_loss     | 0.07636765 |
| training/sac_pi/logp_pi        | 3.8715966  |
| training/sac_pi/pi_entropy     | 3.3730202  |
| training/sac_pi/pi_global_norm | 1.478268   |
| training/sac_pi/policy_loss    | -198.83083 |
| training/sac_pi/std            | 0.47079837 |
| training/sac_pi/valid_num      | 4985.0     |
| training/sac_Q/q1              | 192.86353  |
| training/sac_Q/q2              | 192.9864   |
| training/sac_Q/q2_loss         | 107.26728  |
| training/sac_Q/q_global_norm   | 304.49625  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15546347 |
| epoch                          | 125        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4941.126   |
| evaluation/return-max          | 4965.998   |
| evaluation/return-min          | 4905.3887  |
| evaluation/return-std          | 19.887255  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46207      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4941.126   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 182.67459  |
| Q-std                          | 91.34164   |
| Q_loss                         | 94.08324   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 125        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000261   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.00064    |
| times/evaluation_paths         | 36.9       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 126000     |
| train-steps                    | 126000     |
| training/Q/q1_loss             | 84.90302   |
| training/sac_pi/alpha          | 0.15545821 |
| training/sac_pi/alpha_loss     | -0.3874501 |
| training/sac_pi/logp_pi        | 4.579951   |
| training/sac_pi/pi_entropy     | 3.4652069  |
| training/sac_pi/pi_global_norm | 1.4853417  |
| training/sac_pi/policy_loss    | -190.44902 |
| training/sac_pi/std            | 0.51573485 |
| training/sac_pi/valid_num      | 4918.0     |
| training/sac_Q/q1              | 180.62755  |
| training/sac_Q/q2              | 179.95686  |
| training/sac_Q/q2_loss         | 85.24244   |
| training/sac_Q/q_global_norm   | 335.76517  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16736954 |
| epoch                          | 126        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4543.1064  |
| evaluation/return-max          | 4632.2036  |
| evaluation/return-min          | 4359.792   |
| evaluation/return-std          | 83.28722   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45980      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4543.1064  |
| perf/NormalizedReturn          | 0.989      |
| Q-avg                          | 185.2275   |
| Q-std                          | 103.15963  |
| Q_loss                         | 106.588234 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 126        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000616   |
| times/evaluation_paths         | 34.5       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 127000     |
| train-steps                    | 127000     |
| training/Q/q1_loss             | 95.195366  |
| training/sac_pi/alpha          | 0.16740526 |
| training/sac_pi/alpha_loss     | -0.3397573 |
| training/sac_pi/logp_pi        | 4.2420783  |
| training/sac_pi/pi_entropy     | 3.5926368  |
| training/sac_pi/pi_global_norm | 1.105545   |
| training/sac_pi/policy_loss    | -193.08852 |
| training/sac_pi/std            | 0.49733305 |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 186.61609  |
| training/sac_Q/q2              | 185.71284  |
| training/sac_Q/q2_loss         | 94.82293   |
| training/sac_Q/q_global_norm   | 342.40665  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16705574  |
| epoch                          | 127         |
| evaluation/episode-length-avg  | 927         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 632         |
| evaluation/episode-length-std  | 145         |
| evaluation/return-average      | 3781.7102   |
| evaluation/return-max          | 4287.2314   |
| evaluation/return-min          | 2213.0728   |
| evaluation/return-std          | 784.4366    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46118       |
| perf/AverageLength             | 927         |
| perf/AverageReturn             | 3781.7102   |
| perf/NormalizedReturn          | 0.823       |
| Q-avg                          | 179.55403   |
| Q-std                          | 98.39392    |
| Q_loss                         | 92.873604   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 127         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000236    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.00054     |
| times/evaluation_paths         | 33.2        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 128000      |
| train-steps                    | 128000      |
| training/Q/q1_loss             | 89.83859    |
| training/sac_pi/alpha          | 0.1670651   |
| training/sac_pi/alpha_loss     | -0.21560456 |
| training/sac_pi/logp_pi        | 4.1708183   |
| training/sac_pi/pi_entropy     | 3.6575909   |
| training/sac_pi/pi_global_norm | 1.5751381   |
| training/sac_pi/policy_loss    | -193.76862  |
| training/sac_pi/std            | 0.5225432   |
| training/sac_pi/valid_num      | 4981.0      |
| training/sac_Q/q1              | 188.03922   |
| training/sac_Q/q2              | 187.36435   |
| training/sac_Q/q2_loss         | 90.6145     |
| training/sac_Q/q_global_norm   | 222.64137   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16440333  |
| epoch                          | 128         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5004.8833   |
| evaluation/return-max          | 5104.273    |
| evaluation/return-min          | 4897.844    |
| evaluation/return-std          | 69.61862    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46044       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5004.8833   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 186.01003   |
| Q-std                          | 96.710724   |
| Q_loss                         | 82.62407    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 128         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000143    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000649    |
| times/evaluation_paths         | 35.8        |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 62.8        |
| timestep                       | 1000        |
| timesteps_total                | 129000      |
| train-steps                    | 129000      |
| training/Q/q1_loss             | 92.1236     |
| training/sac_pi/alpha          | 0.1644094   |
| training/sac_pi/alpha_loss     | -0.23931898 |
| training/sac_pi/logp_pi        | 3.8034387   |
| training/sac_pi/pi_entropy     | 3.596473    |
| training/sac_pi/pi_global_norm | 1.3686601   |
| training/sac_pi/policy_loss    | -197.3177   |
| training/sac_pi/std            | 0.4951689   |
| training/sac_pi/valid_num      | 4989.0      |
| training/sac_Q/q1              | 191.15067   |
| training/sac_Q/q2              | 191.16856   |
| training/sac_Q/q2_loss         | 92.52661    |
| training/sac_Q/q_global_norm   | 203.68585   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16512573 |
| epoch                          | 129        |
| evaluation/episode-length-avg  | 852        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 479        |
| evaluation/episode-length-std  | 204        |
| evaluation/return-average      | 3962.0938  |
| evaluation/return-max          | 4765.169   |
| evaluation/return-min          | 2097.1594  |
| evaluation/return-std          | 1021.5191  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45886      |
| perf/AverageLength             | 852        |
| perf/AverageReturn             | 3962.0938  |
| perf/NormalizedReturn          | 0.863      |
| Q-avg                          | 191.39606  |
| Q-std                          | 81.5158    |
| Q_loss                         | 90.78428   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 129        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000307   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000567   |
| times/evaluation_paths         | 32.8       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 130000     |
| train-steps                    | 130000     |
| training/Q/q1_loss             | 82.93577   |
| training/sac_pi/alpha          | 0.16511078 |
| training/sac_pi/alpha_loss     | 0.28737542 |
| training/sac_pi/logp_pi        | 3.936692   |
| training/sac_pi/pi_entropy     | 3.5676377  |
| training/sac_pi/pi_global_norm | 1.4407496  |
| training/sac_pi/policy_loss    | -201.08006 |
| training/sac_pi/std            | 0.48745358 |
| training/sac_pi/valid_num      | 5023.0     |
| training/sac_Q/q1              | 196.98131  |
| training/sac_Q/q2              | 196.18362  |
| training/sac_Q/q2_loss         | 82.57073   |
| training/sac_Q/q_global_norm   | 228.68828  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1641725    |
| epoch                          | 130          |
| evaluation/episode-length-avg  | 146          |
| evaluation/episode-length-max  | 153          |
| evaluation/episode-length-min  | 140          |
| evaluation/episode-length-std  | 4.18         |
| evaluation/return-average      | 485.6368     |
| evaluation/return-max          | 513.595      |
| evaluation/return-min          | 461.85376    |
| evaluation/return-std          | 16.407787    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.93         |
| model/origin_ret               | 85.1         |
| model/penalty_ret              | 81.6         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45884        |
| perf/AverageLength             | 146          |
| perf/AverageReturn             | 485.6368     |
| perf/NormalizedReturn          | 0.105        |
| Q-avg                          | 193.28166    |
| Q-std                          | 104.36545    |
| Q_loss                         | 89.94272     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 130          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.000131     |
| times/epoch_rollout_model      | 485          |
| times/evaluation_metrics       | 0.00071      |
| times/evaluation_paths         | 6.4          |
| times/timestep_after_hook      | 0.00392      |
| times/timestep_before_hook     | 0.00824      |
| times/train                    | 60.8         |
| timestep                       | 1000         |
| timesteps_total                | 131000       |
| train-steps                    | 131000       |
| training/Q/q1_loss             | 83.82379     |
| training/sac_pi/alpha          | 0.16417143   |
| training/sac_pi/alpha_loss     | -0.074659236 |
| training/sac_pi/logp_pi        | 3.990892     |
| training/sac_pi/pi_entropy     | 3.5926461    |
| training/sac_pi/pi_global_norm | 1.6299006    |
| training/sac_pi/policy_loss    | -209.5233    |
| training/sac_pi/std            | 0.5031812    |
| training/sac_pi/valid_num      | 4993.0       |
| training/sac_Q/q1              | 202.80647    |
| training/sac_Q/q2              | 202.81006    |
| training/sac_Q/q2_loss         | 83.58186     |
| training/sac_Q/q_global_norm   | 219.97696    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16304815 |
| epoch                          | 131        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4815.0005  |
| evaluation/return-max          | 4856.615   |
| evaluation/return-min          | 4757.049   |
| evaluation/return-std          | 29.688297  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46094      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4815.0005  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 192.4003   |
| Q-std                          | 96.46081   |
| Q_loss                         | 73.40938   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 131        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 511        |
| times/evaluation_metrics       | 0.000605   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 132000     |
| train-steps                    | 132000     |
| training/Q/q1_loss             | 88.24493   |
| training/sac_pi/alpha          | 0.16300333 |
| training/sac_pi/alpha_loss     | 0.2656662  |
| training/sac_pi/logp_pi        | 4.368313   |
| training/sac_pi/pi_entropy     | 3.6653848  |
| training/sac_pi/pi_global_norm | 1.3732582  |
| training/sac_pi/policy_loss    | -198.79723 |
| training/sac_pi/std            | 0.5225286  |
| training/sac_pi/valid_num      | 5005.0     |
| training/sac_Q/q1              | 191.84378  |
| training/sac_Q/q2              | 192.2487   |
| training/sac_Q/q2_loss         | 88.9348    |
| training/sac_Q/q_global_norm   | 231.2676   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16539675 |
| epoch                          | 132        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4673.7783  |
| evaluation/return-max          | 4708.8643  |
| evaluation/return-min          | 4614.5146  |
| evaluation/return-std          | 29.080505  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46236      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4673.7783  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 186.49454  |
| Q-std                          | 96.76416   |
| Q_loss                         | 104.12793  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 132        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000571   |
| times/evaluation_paths         | 34.5       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 62.2       |
| timestep                       | 1000       |
| timesteps_total                | 133000     |
| train-steps                    | 133000     |
| training/Q/q1_loss             | 107.4212   |
| training/sac_pi/alpha          | 0.16534801 |
| training/sac_pi/alpha_loss     | 0.6476691  |
| training/sac_pi/logp_pi        | 4.2001863  |
| training/sac_pi/pi_entropy     | 3.7434907  |
| training/sac_pi/pi_global_norm | 1.4131873  |
| training/sac_pi/policy_loss    | -199.38216 |
| training/sac_pi/std            | 0.50509953 |
| training/sac_pi/valid_num      | 5025.0     |
| training/sac_Q/q1              | 194.66203  |
| training/sac_Q/q2              | 194.55327  |
| training/sac_Q/q2_loss         | 107.68981  |
| training/sac_Q/q_global_norm   | 263.91568  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16160625 |
| epoch                          | 133        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4923.395   |
| evaluation/return-max          | 5017.334   |
| evaluation/return-min          | 4818.712   |
| evaluation/return-std          | 55.06787   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45956      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4923.395   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 193.64261  |
| Q-std                          | 88.89927   |
| Q_loss                         | 95.32449   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 133        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000305   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000586   |
| times/evaluation_paths         | 35.6       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 134000     |
| train-steps                    | 134000     |
| training/Q/q1_loss             | 87.27388   |
| training/sac_pi/alpha          | 0.16160059 |
| training/sac_pi/alpha_loss     | 0.18571895 |
| training/sac_pi/logp_pi        | 3.7606246  |
| training/sac_pi/pi_entropy     | 3.5713367  |
| training/sac_pi/pi_global_norm | 1.3066914  |
| training/sac_pi/policy_loss    | -203.8659  |
| training/sac_pi/std            | 0.4742664  |
| training/sac_pi/valid_num      | 4991.0     |
| training/sac_Q/q1              | 198.59732  |
| training/sac_Q/q2              | 198.76714  |
| training/sac_Q/q2_loss         | 88.10972   |
| training/sac_Q/q_global_norm   | 243.09354  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17102668 |
| epoch                          | 134        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4548.921   |
| evaluation/return-max          | 4651.873   |
| evaluation/return-min          | 4467.1753  |
| evaluation/return-std          | 57.762074  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 82.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46079      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4548.921   |
| perf/NormalizedReturn          | 0.991      |
| Q-avg                          | 180.44891  |
| Q-std                          | 104.48174  |
| Q_loss                         | 83.71225   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 134        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.00054    |
| times/evaluation_paths         | 36.8       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 62.6       |
| timestep                       | 1000       |
| timesteps_total                | 135000     |
| train-steps                    | 135000     |
| training/Q/q1_loss             | 76.76103   |
| training/sac_pi/alpha          | 0.17098105 |
| training/sac_pi/alpha_loss     | 0.5401507  |
| training/sac_pi/logp_pi        | 4.886007   |
| training/sac_pi/pi_entropy     | 3.79001    |
| training/sac_pi/pi_global_norm | 1.3486022  |
| training/sac_pi/policy_loss    | -196.06088 |
| training/sac_pi/std            | 0.5401246  |
| training/sac_pi/valid_num      | 4928.0     |
| training/sac_Q/q1              | 187.47836  |
| training/sac_Q/q2              | 186.98395  |
| training/sac_Q/q2_loss         | 76.411285  |
| training/sac_Q/q_global_norm   | 271.80115  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1721022   |
| epoch                          | 135         |
| evaluation/episode-length-avg  | 157         |
| evaluation/episode-length-max  | 159         |
| evaluation/episode-length-min  | 154         |
| evaluation/episode-length-std  | 1.62        |
| evaluation/return-average      | 477.90118   |
| evaluation/return-max          | 486.93576   |
| evaluation/return-min          | 470.80453   |
| evaluation/return-std          | 4.7127357   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45943       |
| perf/AverageLength             | 157         |
| perf/AverageReturn             | 477.90118   |
| perf/NormalizedReturn          | 0.104       |
| Q-avg                          | 189.85269   |
| Q-std                          | 101.93919   |
| Q_loss                         | 115.98962   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 135         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000564    |
| times/evaluation_paths         | 4.98        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00801     |
| times/train                    | 63.6        |
| timestep                       | 1000        |
| timesteps_total                | 136000      |
| train-steps                    | 136000      |
| training/Q/q1_loss             | 77.607185   |
| training/sac_pi/alpha          | 0.17210853  |
| training/sac_pi/alpha_loss     | -0.06509548 |
| training/sac_pi/logp_pi        | 4.377565    |
| training/sac_pi/pi_entropy     | 3.781922    |
| training/sac_pi/pi_global_norm | 1.4390993   |
| training/sac_pi/policy_loss    | -200.61244  |
| training/sac_pi/std            | 0.5229627   |
| training/sac_pi/valid_num      | 4935.0      |
| training/sac_Q/q1              | 190.81406   |
| training/sac_Q/q2              | 190.24254   |
| training/sac_Q/q2_loss         | 77.682304   |
| training/sac_Q/q_global_norm   | 270.40076   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16616555  |
| epoch                          | 136         |
| evaluation/episode-length-avg  | 532         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 159         |
| evaluation/episode-length-std  | 308         |
| evaluation/return-average      | 2387.0835   |
| evaluation/return-max          | 4952.9795   |
| evaluation/return-min          | 463.87988   |
| evaluation/return-std          | 1634.1927   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45910       |
| perf/AverageLength             | 532         |
| perf/AverageReturn             | 2387.0835   |
| perf/NormalizedReturn          | 0.52        |
| Q-avg                          | 194.90665   |
| Q-std                          | 101.481125  |
| Q_loss                         | 88.47509    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 136         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000503    |
| times/evaluation_paths         | 18.2        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 63.3        |
| timestep                       | 1000        |
| timesteps_total                | 137000      |
| train-steps                    | 137000      |
| training/Q/q1_loss             | 86.6255     |
| training/sac_pi/alpha          | 0.16617374  |
| training/sac_pi/alpha_loss     | -0.17923602 |
| training/sac_pi/logp_pi        | 3.4595451   |
| training/sac_pi/pi_entropy     | 3.5848708   |
| training/sac_pi/pi_global_norm | 1.2657068   |
| training/sac_pi/policy_loss    | -205.46327  |
| training/sac_pi/std            | 0.48246115  |
| training/sac_pi/valid_num      | 5047.0      |
| training/sac_Q/q1              | 201.8453    |
| training/sac_Q/q2              | 201.86191   |
| training/sac_Q/q2_loss         | 86.50781    |
| training/sac_Q/q_global_norm   | 229.95085   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17085265  |
| epoch                          | 137         |
| evaluation/episode-length-avg  | 153         |
| evaluation/episode-length-max  | 156         |
| evaluation/episode-length-min  | 150         |
| evaluation/episode-length-std  | 1.79        |
| evaluation/return-average      | 453.712     |
| evaluation/return-max          | 464.5819    |
| evaluation/return-min          | 443.10596   |
| evaluation/return-std          | 6.165457    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46084       |
| perf/AverageLength             | 153         |
| perf/AverageReturn             | 453.712     |
| perf/NormalizedReturn          | 0.0985      |
| Q-avg                          | 187.93983   |
| Q-std                          | 101.736015  |
| Q_loss                         | 104.47772   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 137         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000306    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.00059     |
| times/evaluation_paths         | 6.43        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.0081      |
| times/train                    | 61.8        |
| timestep                       | 1000        |
| timesteps_total                | 138000      |
| train-steps                    | 138000      |
| training/Q/q1_loss             | 93.83366    |
| training/sac_pi/alpha          | 0.17084883  |
| training/sac_pi/alpha_loss     | 0.115027755 |
| training/sac_pi/logp_pi        | 4.0861635   |
| training/sac_pi/pi_entropy     | 3.5777836   |
| training/sac_pi/pi_global_norm | 1.758752    |
| training/sac_pi/policy_loss    | -192.29977  |
| training/sac_pi/std            | 0.487545    |
| training/sac_pi/valid_num      | 5012.0      |
| training/sac_Q/q1              | 187.80707   |
| training/sac_Q/q2              | 187.62924   |
| training/sac_Q/q2_loss         | 92.52778    |
| training/sac_Q/q_global_norm   | 299.49066   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16477653 |
| epoch                          | 138        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4941.8965  |
| evaluation/return-max          | 5028.6025  |
| evaluation/return-min          | 4908.219   |
| evaluation/return-std          | 34.07317   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46103      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4941.8965  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 189.60727  |
| Q-std                          | 91.35206   |
| Q_loss                         | 75.03513   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 138        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000626   |
| times/evaluation_paths         | 33.6       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 139000     |
| train-steps                    | 139000     |
| training/Q/q1_loss             | 95.39651   |
| training/sac_pi/alpha          | 0.16476315 |
| training/sac_pi/alpha_loss     | 0.22096811 |
| training/sac_pi/logp_pi        | 3.9866643  |
| training/sac_pi/pi_entropy     | 3.645745   |
| training/sac_pi/pi_global_norm | 1.5128592  |
| training/sac_pi/policy_loss    | -195.29794 |
| training/sac_pi/std            | 0.5042973  |
| training/sac_pi/valid_num      | 4970.0     |
| training/sac_Q/q1              | 189.24045  |
| training/sac_Q/q2              | 188.7609   |
| training/sac_Q/q2_loss         | 94.921745  |
| training/sac_Q/q_global_norm   | 306.7921   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16136105 |
| epoch                          | 139        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4806.872   |
| evaluation/return-max          | 4876.967   |
| evaluation/return-min          | 4728.3555  |
| evaluation/return-std          | 38.13769   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46205      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4806.872   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 194.9444   |
| Q-std                          | 80.183044  |
| Q_loss                         | 86.887825  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 139        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000628   |
| times/evaluation_paths         | 36.1       |
| times/timestep_after_hook      | 0.00398    |
| times/timestep_before_hook     | 0.0091     |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 140000     |
| train-steps                    | 140000     |
| training/Q/q1_loss             | 108.99414  |
| training/sac_pi/alpha          | 0.16133797 |
| training/sac_pi/alpha_loss     | 0.12948933 |
| training/sac_pi/logp_pi        | 3.942864   |
| training/sac_pi/pi_entropy     | 3.723713   |
| training/sac_pi/pi_global_norm | 1.6899725  |
| training/sac_pi/policy_loss    | -201.54959 |
| training/sac_pi/std            | 0.50432324 |
| training/sac_pi/valid_num      | 4993.0     |
| training/sac_Q/q1              | 195.7903   |
| training/sac_Q/q2              | 194.97441  |
| training/sac_Q/q2_loss         | 109.52222  |
| training/sac_Q/q_global_norm   | 249.76965  |
--------------------------------------------------------------------------------
[WARN] 140 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16130519 |
| epoch                          | 140        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4599.5747  |
| evaluation/return-max          | 4690.8975  |
| evaluation/return-min          | 4489.0654  |
| evaluation/return-std          | 61.01678   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 82.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45933      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4599.5747  |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 184.71353  |
| Q-std                          | 102.33487  |
| Q_loss                         | 96.58612   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 140        |
| times/epoch_after_hook         | 2.06e-06   |
| times/epoch_before_hook        | 0.000144   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000789   |
| times/evaluation_paths         | 35.6       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.0106     |
| times/train                    | 62.7       |
| timestep                       | 1000       |
| timesteps_total                | 141000     |
| train-steps                    | 141000     |
| training/Q/q1_loss             | 98.55394   |
| training/sac_pi/alpha          | 0.16128929 |
| training/sac_pi/alpha_loss     | 0.1730039  |
| training/sac_pi/logp_pi        | 4.538989   |
| training/sac_pi/pi_entropy     | 3.6066399  |
| training/sac_pi/pi_global_norm | 1.4981083  |
| training/sac_pi/policy_loss    | -202.89879 |
| training/sac_pi/std            | 0.5180842  |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 194.73161  |
| training/sac_Q/q2              | 193.54962  |
| training/sac_Q/q2_loss         | 98.91409   |
| training/sac_Q/q_global_norm   | 269.19043  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16059728 |
| epoch                          | 141        |
| evaluation/episode-length-avg  | 374        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 148        |
| evaluation/episode-length-std  | 329        |
| evaluation/return-average      | 1562.1825  |
| evaluation/return-max          | 4793.17    |
| evaluation/return-min          | 451.676    |
| evaluation/return-std          | 1635.8033  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 83.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45666      |
| perf/AverageLength             | 374        |
| perf/AverageReturn             | 1562.1825  |
| perf/NormalizedReturn          | 0.34       |
| Q-avg                          | 195.77782  |
| Q-std                          | 85.36805   |
| Q_loss                         | 99.738716  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 141        |
| times/epoch_after_hook         | 3.41e-06   |
| times/epoch_before_hook        | 0.000259   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000622   |
| times/evaluation_paths         | 12         |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 64.3       |
| timestep                       | 1000       |
| timesteps_total                | 142000     |
| train-steps                    | 142000     |
| training/Q/q1_loss             | 94.65448   |
| training/sac_pi/alpha          | 0.16057411 |
| training/sac_pi/alpha_loss     | 0.28019476 |
| training/sac_pi/logp_pi        | 5.1010976  |
| training/sac_pi/pi_entropy     | 3.9476829  |
| training/sac_pi/pi_global_norm | 1.805389   |
| training/sac_pi/policy_loss    | -192.26555 |
| training/sac_pi/std            | 0.5874708  |
| training/sac_pi/valid_num      | 4885.0     |
| training/sac_Q/q1              | 181.85913  |
| training/sac_Q/q2              | 181.14816  |
| training/sac_Q/q2_loss         | 94.85272   |
| training/sac_Q/q_global_norm   | 399.9002   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16628033  |
| epoch                          | 142         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4669.409    |
| evaluation/return-max          | 4788.0254   |
| evaluation/return-min          | 4500.723    |
| evaluation/return-std          | 80.77504    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.84        |
| model/origin_ret               | 82.8        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45940       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4669.409    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 191.92545   |
| Q-std                          | 96.014824   |
| Q_loss                         | 88.47083    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 142         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000727    |
| times/evaluation_paths         | 37.2        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00822     |
| times/train                    | 63          |
| timestep                       | 1000        |
| timesteps_total                | 143000      |
| train-steps                    | 143000      |
| training/Q/q1_loss             | 98.43937    |
| training/sac_pi/alpha          | 0.16631131  |
| training/sac_pi/alpha_loss     | -0.25141197 |
| training/sac_pi/logp_pi        | 4.7373624   |
| training/sac_pi/pi_entropy     | 3.6485126   |
| training/sac_pi/pi_global_norm | 1.3676276   |
| training/sac_pi/policy_loss    | -195.72626  |
| training/sac_pi/std            | 0.5238558   |
| training/sac_pi/valid_num      | 4961.0      |
| training/sac_Q/q1              | 187.65767   |
| training/sac_Q/q2              | 186.62723   |
| training/sac_Q/q2_loss         | 99.18815    |
| training/sac_Q/q_global_norm   | 287.69394   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16765872  |
| epoch                          | 143         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5185.666    |
| evaluation/return-max          | 5221.7715   |
| evaluation/return-min          | 5152.629    |
| evaluation/return-std          | 21.945076   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46115       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5185.666    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 192.38237   |
| Q-std                          | 87.29937    |
| Q_loss                         | 93.00319    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 143         |
| times/epoch_after_hook         | 2.17e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000577    |
| times/evaluation_paths         | 35          |
| times/timestep_after_hook      | 0.00409     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 63.6        |
| timestep                       | 1000        |
| timesteps_total                | 144000      |
| train-steps                    | 144000      |
| training/Q/q1_loss             | 88.59284    |
| training/sac_pi/alpha          | 0.16766712  |
| training/sac_pi/alpha_loss     | -0.35804498 |
| training/sac_pi/logp_pi        | 4.2163124   |
| training/sac_pi/pi_entropy     | 3.7155175   |
| training/sac_pi/pi_global_norm | 1.7324102   |
| training/sac_pi/policy_loss    | -207.68799  |
| training/sac_pi/std            | 0.5147374   |
| training/sac_pi/valid_num      | 4940.0      |
| training/sac_Q/q1              | 199.89609   |
| training/sac_Q/q2              | 198.36514   |
| training/sac_Q/q2_loss         | 88.93481    |
| training/sac_Q/q_global_norm   | 256.9545    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17720805 |
| epoch                          | 144        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4686.1475  |
| evaluation/return-max          | 4771.744   |
| evaluation/return-min          | 4499.1157  |
| evaluation/return-std          | 79.69296   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45960      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4686.1475  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 182.75208  |
| Q-std                          | 104.883415 |
| Q_loss                         | 105.78306  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 144        |
| times/epoch_after_hook         | 2.53e-06   |
| times/epoch_before_hook        | 0.000141   |
| times/epoch_rollout_model      | 519        |
| times/evaluation_metrics       | 0.000633   |
| times/evaluation_paths         | 35.2       |
| times/timestep_after_hook      | 0.0041     |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 145000     |
| train-steps                    | 145000     |
| training/Q/q1_loss             | 79.15236   |
| training/sac_pi/alpha          | 0.17718723 |
| training/sac_pi/alpha_loss     | 0.05569243 |
| training/sac_pi/logp_pi        | 3.972258   |
| training/sac_pi/pi_entropy     | 3.6393867  |
| training/sac_pi/pi_global_norm | 1.900096   |
| training/sac_pi/policy_loss    | -202.27832 |
| training/sac_pi/std            | 0.5028212  |
| training/sac_pi/valid_num      | 4987.0     |
| training/sac_Q/q1              | 196.63712  |
| training/sac_Q/q2              | 196.18614  |
| training/sac_Q/q2_loss         | 78.96468   |
| training/sac_Q/q_global_norm   | 253.55385  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16856633   |
| epoch                          | 145          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4790.239     |
| evaluation/return-max          | 4872.951     |
| evaluation/return-min          | 4737.1436    |
| evaluation/return-std          | 47.44975     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.97         |
| model/origin_ret               | 86           |
| model/penalty_ret              | 82.2         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46041        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4790.239     |
| perf/NormalizedReturn          | 1.04         |
| Q-avg                          | 188.67819    |
| Q-std                          | 87.2827      |
| Q_loss                         | 98.28        |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 145          |
| times/epoch_after_hook         | 1.93e-06     |
| times/epoch_before_hook        | 0.000311     |
| times/epoch_rollout_model      | 487          |
| times/evaluation_metrics       | 0.000531     |
| times/evaluation_paths         | 34.5         |
| times/timestep_after_hook      | 0.00396      |
| times/timestep_before_hook     | 0.00815      |
| times/train                    | 62.8         |
| timestep                       | 1000         |
| timesteps_total                | 146000       |
| train-steps                    | 146000       |
| training/Q/q1_loss             | 103.7848     |
| training/sac_pi/alpha          | 0.16857974   |
| training/sac_pi/alpha_loss     | -0.050921455 |
| training/sac_pi/logp_pi        | 3.9991806    |
| training/sac_pi/pi_entropy     | 3.8972344    |
| training/sac_pi/pi_global_norm | 1.513629     |
| training/sac_pi/policy_loss    | -192.46523   |
| training/sac_pi/std            | 0.540293     |
| training/sac_pi/valid_num      | 4927.0       |
| training/sac_Q/q1              | 184.91971    |
| training/sac_Q/q2              | 184.76291    |
| training/sac_Q/q2_loss         | 103.27957    |
| training/sac_Q/q_global_norm   | 317.28754    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1712311   |
| epoch                          | 146         |
| evaluation/episode-length-avg  | 588         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 144         |
| evaluation/episode-length-std  | 344         |
| evaluation/return-average      | 2656.9746   |
| evaluation/return-max          | 4918.198    |
| evaluation/return-min          | 448.41003   |
| evaluation/return-std          | 1752.24     |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45963       |
| perf/AverageLength             | 588         |
| perf/AverageReturn             | 2656.9746   |
| perf/NormalizedReturn          | 0.578       |
| Q-avg                          | 188.14474   |
| Q-std                          | 103.12574   |
| Q_loss                         | 99.31914    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 146         |
| times/epoch_after_hook         | 2.13e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000533    |
| times/evaluation_paths         | 20.7        |
| times/timestep_after_hook      | 0.00397     |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 147000      |
| train-steps                    | 147000      |
| training/Q/q1_loss             | 93.066185   |
| training/sac_pi/alpha          | 0.17124376  |
| training/sac_pi/alpha_loss     | -0.13364422 |
| training/sac_pi/logp_pi        | 3.7251287   |
| training/sac_pi/pi_entropy     | 3.772287    |
| training/sac_pi/pi_global_norm | 1.6794183   |
| training/sac_pi/policy_loss    | -204.41937  |
| training/sac_pi/std            | 0.50925785  |
| training/sac_pi/valid_num      | 4949.0      |
| training/sac_Q/q1              | 196.78221   |
| training/sac_Q/q2              | 196.65784   |
| training/sac_Q/q2_loss         | 92.43697    |
| training/sac_Q/q_global_norm   | 197.5622    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17016393  |
| epoch                          | 147         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4815.7373   |
| evaluation/return-max          | 4837.5015   |
| evaluation/return-min          | 4796.2954   |
| evaluation/return-std          | 13.146973   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45993       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4815.7373   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 198.5817    |
| Q-std                          | 96.68954    |
| Q_loss                         | 99.04289    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 147         |
| times/epoch_after_hook         | 2.01e-06    |
| times/epoch_before_hook        | 0.000155    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000577    |
| times/evaluation_paths         | 34.6        |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 148000      |
| train-steps                    | 148000      |
| training/Q/q1_loss             | 98.94933    |
| training/sac_pi/alpha          | 0.17013207  |
| training/sac_pi/alpha_loss     | 0.035829343 |
| training/sac_pi/logp_pi        | 3.8113918   |
| training/sac_pi/pi_entropy     | 3.6947167   |
| training/sac_pi/pi_global_norm | 1.4422549   |
| training/sac_pi/policy_loss    | -200.86292  |
| training/sac_pi/std            | 0.49974808  |
| training/sac_pi/valid_num      | 5012.0      |
| training/sac_Q/q1              | 196.09592   |
| training/sac_Q/q2              | 195.82262   |
| training/sac_Q/q2_loss         | 98.4822     |
| training/sac_Q/q_global_norm   | 258.20953   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16475697 |
| epoch                          | 148        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5067.1636  |
| evaluation/return-max          | 5194.372   |
| evaluation/return-min          | 4905.3335  |
| evaluation/return-std          | 90.13332   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46092      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5067.1636  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 184.21408  |
| Q-std                          | 99.01471   |
| Q_loss                         | 83.471146  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 148        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000584   |
| times/evaluation_paths         | 36.7       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 149000     |
| train-steps                    | 149000     |
| training/Q/q1_loss             | 79.602486  |
| training/sac_pi/alpha          | 0.16480039 |
| training/sac_pi/alpha_loss     | -0.2288747 |
| training/sac_pi/logp_pi        | 3.8835838  |
| training/sac_pi/pi_entropy     | 3.556752   |
| training/sac_pi/pi_global_norm | 1.4604235  |
| training/sac_pi/policy_loss    | -198.18074 |
| training/sac_pi/std            | 0.49863726 |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 192.82913  |
| training/sac_Q/q2              | 192.33806  |
| training/sac_Q/q2_loss         | 79.58851   |
| training/sac_Q/q_global_norm   | 250.15327  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16250199 |
| epoch                          | 149        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4991.246   |
| evaluation/return-max          | 5069.1953  |
| evaluation/return-min          | 4899.969   |
| evaluation/return-std          | 52.206394  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46039      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4991.246   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 186.93823  |
| Q-std                          | 96.98077   |
| Q_loss                         | 117.96593  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 149        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000386   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000703   |
| times/evaluation_paths         | 34.4       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 70.6       |
| timestep                       | 1000       |
| timesteps_total                | 150000     |
| train-steps                    | 150000     |
| training/Q/q1_loss             | 102.83119  |
| training/sac_pi/alpha          | 0.16247207 |
| training/sac_pi/alpha_loss     | 0.42913917 |
| training/sac_pi/logp_pi        | 5.126628   |
| training/sac_pi/pi_entropy     | 3.8386261  |
| training/sac_pi/pi_global_norm | 1.3074819  |
| training/sac_pi/policy_loss    | -193.48    |
| training/sac_pi/std            | 0.56856245 |
| training/sac_pi/valid_num      | 4916.0     |
| training/sac_Q/q1              | 179.8901   |
| training/sac_Q/q2              | 180.40848  |
| training/sac_Q/q2_loss         | 102.38491  |
| training/sac_Q/q_global_norm   | 267.34726  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16110268  |
| epoch                          | 150         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4876.5977   |
| evaluation/return-max          | 5075.039    |
| evaluation/return-min          | 4816.718    |
| evaluation/return-std          | 69.70777    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46140       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4876.5977   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 191.07423   |
| Q-std                          | 96.49772    |
| Q_loss                         | 88.03174    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 150         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000592    |
| times/evaluation_paths         | 37.6        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.0162      |
| times/train                    | 71.6        |
| timestep                       | 1000        |
| timesteps_total                | 151000      |
| train-steps                    | 151000      |
| training/Q/q1_loss             | 86.39887    |
| training/sac_pi/alpha          | 0.1611281   |
| training/sac_pi/alpha_loss     | -0.25552434 |
| training/sac_pi/logp_pi        | 4.1637716   |
| training/sac_pi/pi_entropy     | 3.460034    |
| training/sac_pi/pi_global_norm | 1.5142285   |
| training/sac_pi/policy_loss    | -201.69334  |
| training/sac_pi/std            | 0.4928309   |
| training/sac_pi/valid_num      | 4973.0      |
| training/sac_Q/q1              | 195.02089   |
| training/sac_Q/q2              | 193.98001   |
| training/sac_Q/q2_loss         | 86.9454     |
| training/sac_Q/q_global_norm   | 231.83517   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1649423   |
| epoch                          | 151         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4800.307    |
| evaluation/return-max          | 5022.131    |
| evaluation/return-min          | 4661.597    |
| evaluation/return-std          | 103.6271    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46182       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4800.307    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 201.65613   |
| Q-std                          | 91.3974     |
| Q_loss                         | 92.30537    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 151         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000637    |
| times/evaluation_paths         | 34.6        |
| times/timestep_after_hook      | 0.00383     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 71.8        |
| timestep                       | 1000        |
| timesteps_total                | 152000      |
| train-steps                    | 152000      |
| training/Q/q1_loss             | 104.3575    |
| training/sac_pi/alpha          | 0.16498253  |
| training/sac_pi/alpha_loss     | -0.02477941 |
| training/sac_pi/logp_pi        | 4.333654    |
| training/sac_pi/pi_entropy     | 3.5120971   |
| training/sac_pi/pi_global_norm | 1.5925338   |
| training/sac_pi/policy_loss    | -204.09122  |
| training/sac_pi/std            | 0.5125083   |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 194.47482   |
| training/sac_Q/q2              | 193.50887   |
| training/sac_Q/q2_loss         | 103.74374   |
| training/sac_Q/q_global_norm   | 313.82455   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1659221  |
| epoch                          | 152        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4481.891   |
| evaluation/return-max          | 4591.244   |
| evaluation/return-min          | 4289.953   |
| evaluation/return-std          | 85.28072   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46161      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4481.891   |
| perf/NormalizedReturn          | 0.976      |
| Q-avg                          | 194.29886  |
| Q-std                          | 87.38907   |
| Q_loss                         | 91.64486   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 152        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000578   |
| times/evaluation_paths         | 34.5       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 69.3       |
| timestep                       | 1000       |
| timesteps_total                | 153000     |
| train-steps                    | 153000     |
| training/Q/q1_loss             | 89.39433   |
| training/sac_pi/alpha          | 0.16586836 |
| training/sac_pi/alpha_loss     | 0.4573484  |
| training/sac_pi/logp_pi        | 4.1728945  |
| training/sac_pi/pi_entropy     | 3.7953262  |
| training/sac_pi/pi_global_norm | 1.2010496  |
| training/sac_pi/policy_loss    | -194.99673 |
| training/sac_pi/std            | 0.51729566 |
| training/sac_pi/valid_num      | 5015.0     |
| training/sac_Q/q1              | 190.96936  |
| training/sac_Q/q2              | 190.71074  |
| training/sac_Q/q2_loss         | 89.918396  |
| training/sac_Q/q_global_norm   | 233.80815  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1693676   |
| epoch                          | 153         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4901.338    |
| evaluation/return-max          | 4986.4595   |
| evaluation/return-min          | 4846.8945   |
| evaluation/return-std          | 46.46126    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45761       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4901.338    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 192.60043   |
| Q-std                          | 101.54718   |
| Q_loss                         | 90.308266   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 153         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000255    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000525    |
| times/evaluation_paths         | 35.2        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00809     |
| times/train                    | 68.8        |
| timestep                       | 1000        |
| timesteps_total                | 154000      |
| train-steps                    | 154000      |
| training/Q/q1_loss             | 80.26062    |
| training/sac_pi/alpha          | 0.16938221  |
| training/sac_pi/alpha_loss     | -0.11770435 |
| training/sac_pi/logp_pi        | 4.293063    |
| training/sac_pi/pi_entropy     | 3.7661636   |
| training/sac_pi/pi_global_norm | 1.2966595   |
| training/sac_pi/policy_loss    | -197.93417  |
| training/sac_pi/std            | 0.5325893   |
| training/sac_pi/valid_num      | 4932.0      |
| training/sac_Q/q1              | 189.76114   |
| training/sac_Q/q2              | 187.95049   |
| training/sac_Q/q2_loss         | 79.89573    |
| training/sac_Q/q_global_norm   | 235.68576   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16619053 |
| epoch                          | 154        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4552.8696  |
| evaluation/return-max          | 4589.9346  |
| evaluation/return-min          | 4446.7495  |
| evaluation/return-std          | 41.032757  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45883      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4552.8696  |
| perf/NormalizedReturn          | 0.991      |
| Q-avg                          | 193.94156  |
| Q-std                          | 90.16312   |
| Q_loss                         | 102.20391  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 154        |
| times/epoch_after_hook         | 1.99e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000559   |
| times/evaluation_paths         | 35.4       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 64         |
| timestep                       | 1000       |
| timesteps_total                | 155000     |
| train-steps                    | 155000     |
| training/Q/q1_loss             | 80.23907   |
| training/sac_pi/alpha          | 0.16618137 |
| training/sac_pi/alpha_loss     | 0.13917512 |
| training/sac_pi/logp_pi        | 4.679828   |
| training/sac_pi/pi_entropy     | 3.5712597  |
| training/sac_pi/pi_global_norm | 1.731884   |
| training/sac_pi/policy_loss    | -198.67346 |
| training/sac_pi/std            | 0.5213694  |
| training/sac_pi/valid_num      | 4930.0     |
| training/sac_Q/q1              | 189.41379  |
| training/sac_Q/q2              | 188.42099  |
| training/sac_Q/q2_loss         | 79.98241   |
| training/sac_Q/q_global_norm   | 329.5858   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16853295 |
| epoch                          | 155        |
| evaluation/episode-length-avg  | 892        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 481        |
| evaluation/episode-length-std  | 185        |
| evaluation/return-average      | 4086.6577  |
| evaluation/return-max          | 4759.6494  |
| evaluation/return-min          | 2004.8206  |
| evaluation/return-std          | 941.40314  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46169      |
| perf/AverageLength             | 892        |
| perf/AverageReturn             | 4086.6577  |
| perf/NormalizedReturn          | 0.89       |
| Q-avg                          | 197.798    |
| Q-std                          | 106.02863  |
| Q_loss                         | 93.29466   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 155        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000667   |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 156000     |
| train-steps                    | 156000     |
| training/Q/q1_loss             | 84.844536  |
| training/sac_pi/alpha          | 0.16848636 |
| training/sac_pi/alpha_loss     | 0.6862943  |
| training/sac_pi/logp_pi        | 4.459306   |
| training/sac_pi/pi_entropy     | 3.7789047  |
| training/sac_pi/pi_global_norm | 1.3287623  |
| training/sac_pi/policy_loss    | -200.2845  |
| training/sac_pi/std            | 0.5158411  |
| training/sac_pi/valid_num      | 4948.0     |
| training/sac_Q/q1              | 191.74019  |
| training/sac_Q/q2              | 191.29985  |
| training/sac_Q/q2_loss         | 84.443756  |
| training/sac_Q/q_global_norm   | 246.35512  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16724055 |
| epoch                          | 156        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5087.3574  |
| evaluation/return-max          | 5198.422   |
| evaluation/return-min          | 5018.617   |
| evaluation/return-std          | 56.717308  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45976      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5087.3574  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 192.36487  |
| Q-std                          | 99.91534   |
| Q_loss                         | 91.30798   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 156        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 34.2       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 157000     |
| train-steps                    | 157000     |
| training/Q/q1_loss             | 97.25667   |
| training/sac_pi/alpha          | 0.16723202 |
| training/sac_pi/alpha_loss     | 0.24571878 |
| training/sac_pi/logp_pi        | 4.7701263  |
| training/sac_pi/pi_entropy     | 3.6974533  |
| training/sac_pi/pi_global_norm | 1.4716495  |
| training/sac_pi/policy_loss    | -199.53616 |
| training/sac_pi/std            | 0.5420343  |
| training/sac_pi/valid_num      | 4961.0     |
| training/sac_Q/q1              | 189.3991   |
| training/sac_Q/q2              | 188.66942  |
| training/sac_Q/q2_loss         | 97.61678   |
| training/sac_Q/q_global_norm   | 227.14479  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16666391 |
| epoch                          | 157        |
| evaluation/episode-length-avg  | 915        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 154        |
| evaluation/episode-length-std  | 254        |
| evaluation/return-average      | 4569.792   |
| evaluation/return-max          | 5174.966   |
| evaluation/return-min          | 475.60526  |
| evaluation/return-std          | 1367.9558  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45957      |
| perf/AverageLength             | 915        |
| perf/AverageReturn             | 4569.792   |
| perf/NormalizedReturn          | 0.995      |
| Q-avg                          | 192.7982   |
| Q-std                          | 93.954544  |
| Q_loss                         | 115.4763   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 157        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000269   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000638   |
| times/evaluation_paths         | 33.4       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 158000     |
| train-steps                    | 158000     |
| training/Q/q1_loss             | 83.06146   |
| training/sac_pi/alpha          | 0.1666857  |
| training/sac_pi/alpha_loss     | -0.3557549 |
| training/sac_pi/logp_pi        | 4.518157   |
| training/sac_pi/pi_entropy     | 3.5796494  |
| training/sac_pi/pi_global_norm | 1.4458854  |
| training/sac_pi/policy_loss    | -204.58762 |
| training/sac_pi/std            | 0.52086186 |
| training/sac_pi/valid_num      | 4956.0     |
| training/sac_Q/q1              | 196.61317  |
| training/sac_Q/q2              | 195.83542  |
| training/sac_Q/q2_loss         | 82.38021   |
| training/sac_Q/q_global_norm   | 185.75734  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16588561 |
| epoch                          | 158        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4849.4434  |
| evaluation/return-max          | 4917.1855  |
| evaluation/return-min          | 4748.669   |
| evaluation/return-std          | 44.71764   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.86       |
| model/origin_ret               | 83.5       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45997      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4849.4434  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 188.15982  |
| Q-std                          | 105.07379  |
| Q_loss                         | 93.03951   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 158        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000638   |
| times/evaluation_paths         | 34.2       |
| times/timestep_after_hook      | 0.00409    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 159000     |
| train-steps                    | 159000     |
| training/Q/q1_loss             | 83.56293   |
| training/sac_pi/alpha          | 0.165863   |
| training/sac_pi/alpha_loss     | 0.09997249 |
| training/sac_pi/logp_pi        | 4.431225   |
| training/sac_pi/pi_entropy     | 3.7296424  |
| training/sac_pi/pi_global_norm | 1.3492175  |
| training/sac_pi/policy_loss    | -195.84895 |
| training/sac_pi/std            | 0.5271729  |
| training/sac_pi/valid_num      | 5002.0     |
| training/sac_Q/q1              | 189.4874   |
| training/sac_Q/q2              | 188.39243  |
| training/sac_Q/q2_loss         | 83.58563   |
| training/sac_Q/q_global_norm   | 334.2486   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16800143 |
| epoch                          | 159        |
| evaluation/episode-length-avg  | 817        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 352        |
| evaluation/episode-length-std  | 225        |
| evaluation/return-average      | 3877.1265  |
| evaluation/return-max          | 4899.5337  |
| evaluation/return-min          | 1421.3741  |
| evaluation/return-std          | 1180.5343  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 82.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45870      |
| perf/AverageLength             | 817        |
| perf/AverageReturn             | 3877.1265  |
| perf/NormalizedReturn          | 0.844      |
| Q-avg                          | 190.03854  |
| Q-std                          | 105.0588   |
| Q_loss                         | 120.23435  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 159        |
| times/epoch_after_hook         | 1.97e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000809   |
| times/evaluation_paths         | 28.4       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 61.5       |
| timestep                       | 1000       |
| timesteps_total                | 160000     |
| train-steps                    | 160000     |
| training/Q/q1_loss             | 81.73296   |
| training/sac_pi/alpha          | 0.16797319 |
| training/sac_pi/alpha_loss     | 0.11373978 |
| training/sac_pi/logp_pi        | 4.0101748  |
| training/sac_pi/pi_entropy     | 3.685119   |
| training/sac_pi/pi_global_norm | 1.6391139  |
| training/sac_pi/policy_loss    | -203.79117 |
| training/sac_pi/std            | 0.49491903 |
| training/sac_pi/valid_num      | 4987.0     |
| training/sac_Q/q1              | 198.13193  |
| training/sac_Q/q2              | 197.52344  |
| training/sac_Q/q2_loss         | 82.074486  |
| training/sac_Q/q_global_norm   | 193.27864  |
--------------------------------------------------------------------------------
[WARN] 160 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16444096  |
| epoch                          | 160         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4942.3936   |
| evaluation/return-max          | 5018.479    |
| evaluation/return-min          | 4862.7983   |
| evaluation/return-std          | 49.776638   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46152       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4942.3936   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 194.85632   |
| Q-std                          | 100.73992   |
| Q_loss                         | 94.0205     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 160         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000683    |
| times/evaluation_paths         | 34.9        |
| times/timestep_after_hook      | 0.00413     |
| times/timestep_before_hook     | 0.00833     |
| times/train                    | 64.2        |
| timestep                       | 1000        |
| timesteps_total                | 161000      |
| train-steps                    | 161000      |
| training/Q/q1_loss             | 83.9113     |
| training/sac_pi/alpha          | 0.16441877  |
| training/sac_pi/alpha_loss     | -0.22272646 |
| training/sac_pi/logp_pi        | 3.8542664   |
| training/sac_pi/pi_entropy     | 3.4890418   |
| training/sac_pi/pi_global_norm | 1.8130153   |
| training/sac_pi/policy_loss    | -202.98882  |
| training/sac_pi/std            | 0.48651072  |
| training/sac_pi/valid_num      | 5004.0      |
| training/sac_Q/q1              | 198.69827   |
| training/sac_Q/q2              | 198.63553   |
| training/sac_Q/q2_loss         | 83.47155    |
| training/sac_Q/q_global_norm   | 262.39764   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1654051  |
| epoch                          | 161        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4798.9507  |
| evaluation/return-max          | 4918.6313  |
| evaluation/return-min          | 4661.0244  |
| evaluation/return-std          | 68.979515  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45932      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4798.9507  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 198.53525  |
| Q-std                          | 100.757195 |
| Q_loss                         | 89.63117   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 161        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.000255   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000672   |
| times/evaluation_paths         | 35.6       |
| times/timestep_after_hook      | 0.00403    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 162000     |
| train-steps                    | 162000     |
| training/Q/q1_loss             | 120.94097  |
| training/sac_pi/alpha          | 0.1653845  |
| training/sac_pi/alpha_loss     | 0.11413269 |
| training/sac_pi/logp_pi        | 4.389058   |
| training/sac_pi/pi_entropy     | 3.764302   |
| training/sac_pi/pi_global_norm | 1.449798   |
| training/sac_pi/policy_loss    | -200.00063 |
| training/sac_pi/std            | 0.5365909  |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 193.15901  |
| training/sac_Q/q2              | 192.28528  |
| training/sac_Q/q2_loss         | 121.05816  |
| training/sac_Q/q_global_norm   | 305.11615  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17219304 |
| epoch                          | 162        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4800.476   |
| evaluation/return-max          | 4831.1177  |
| evaluation/return-min          | 4728.8267  |
| evaluation/return-std          | 27.16871   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 82.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45971      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4800.476   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 198.67044  |
| Q-std                          | 93.17958   |
| Q_loss                         | 103.20681  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 162        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000153   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000717   |
| times/evaluation_paths         | 36.2       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 163000     |
| train-steps                    | 163000     |
| training/Q/q1_loss             | 98.97951   |
| training/sac_pi/alpha          | 0.17217126 |
| training/sac_pi/alpha_loss     | 0.40529746 |
| training/sac_pi/logp_pi        | 4.109227   |
| training/sac_pi/pi_entropy     | 3.7281556  |
| training/sac_pi/pi_global_norm | 1.2007346  |
| training/sac_pi/policy_loss    | -208.31943 |
| training/sac_pi/std            | 0.4984128  |
| training/sac_pi/valid_num      | 4989.0     |
| training/sac_Q/q1              | 203.3465   |
| training/sac_Q/q2              | 202.2003   |
| training/sac_Q/q2_loss         | 97.67518   |
| training/sac_Q/q_global_norm   | 255.73341  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17117886  |
| epoch                          | 163         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5008.411    |
| evaluation/return-max          | 5174.8457   |
| evaluation/return-min          | 4929.9624   |
| evaluation/return-std          | 67.92       |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46047       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5008.411    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 190.51605   |
| Q-std                          | 112.571465  |
| Q_loss                         | 83.43597    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 163         |
| times/epoch_after_hook         | 2.08e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000827    |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.00412     |
| times/timestep_before_hook     | 0.00809     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 164000      |
| train-steps                    | 164000      |
| training/Q/q1_loss             | 111.2868    |
| training/sac_pi/alpha          | 0.17116591  |
| training/sac_pi/alpha_loss     | -0.29568842 |
| training/sac_pi/logp_pi        | 4.0997543   |
| training/sac_pi/pi_entropy     | 3.7147064   |
| training/sac_pi/pi_global_norm | 1.579671    |
| training/sac_pi/policy_loss    | -197.39935  |
| training/sac_pi/std            | 0.52746886  |
| training/sac_pi/valid_num      | 4989.0      |
| training/sac_Q/q1              | 190.61554   |
| training/sac_Q/q2              | 189.46219   |
| training/sac_Q/q2_loss         | 110.778015  |
| training/sac_Q/q_global_norm   | 278.22964   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17003904 |
| epoch                          | 164        |
| evaluation/episode-length-avg  | 680        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 151        |
| evaluation/episode-length-std  | 310        |
| evaluation/return-average      | 3438.7773  |
| evaluation/return-max          | 5249.703   |
| evaluation/return-min          | 521.2261   |
| evaluation/return-std          | 1727.1774  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45994      |
| perf/AverageLength             | 680        |
| perf/AverageReturn             | 3438.7773  |
| perf/NormalizedReturn          | 0.749      |
| Q-avg                          | 199.50908  |
| Q-std                          | 93.55875   |
| Q_loss                         | 75.471405  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 164        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.00084    |
| times/evaluation_paths         | 23.9       |
| times/timestep_after_hook      | 0.00403    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 165000     |
| train-steps                    | 165000     |
| training/Q/q1_loss             | 88.92095   |
| training/sac_pi/alpha          | 0.16997212 |
| training/sac_pi/alpha_loss     | 0.3547622  |
| training/sac_pi/logp_pi        | 4.248937   |
| training/sac_pi/pi_entropy     | 3.6201851  |
| training/sac_pi/pi_global_norm | 1.849116   |
| training/sac_pi/policy_loss    | -210.4213  |
| training/sac_pi/std            | 0.48886272 |
| training/sac_pi/valid_num      | 4990.0     |
| training/sac_Q/q1              | 205.51993  |
| training/sac_Q/q2              | 204.70018  |
| training/sac_Q/q2_loss         | 89.668396  |
| training/sac_Q/q_global_norm   | 338.17688  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16779628 |
| epoch                          | 165        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4725.694   |
| evaluation/return-max          | 4799.8027  |
| evaluation/return-min          | 4644.5137  |
| evaluation/return-std          | 49.062923  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 87.2       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45927      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4725.694   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 186.44286  |
| Q-std                          | 97.94319   |
| Q_loss                         | 96.24543   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 165        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000263   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000578   |
| times/evaluation_paths         | 33.8       |
| times/timestep_after_hook      | 0.00412    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 166000     |
| train-steps                    | 166000     |
| training/Q/q1_loss             | 89.77662   |
| training/sac_pi/alpha          | 0.16776793 |
| training/sac_pi/alpha_loss     | 0.13320321 |
| training/sac_pi/logp_pi        | 4.5314417  |
| training/sac_pi/pi_entropy     | 3.7580209  |
| training/sac_pi/pi_global_norm | 1.6053884  |
| training/sac_pi/policy_loss    | -197.34082 |
| training/sac_pi/std            | 0.5449474  |
| training/sac_pi/valid_num      | 4931.0     |
| training/sac_Q/q1              | 188.7509   |
| training/sac_Q/q2              | 188.05183  |
| training/sac_Q/q2_loss         | 89.788475  |
| training/sac_Q/q_global_norm   | 290.2859   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16904269 |
| epoch                          | 166        |
| evaluation/episode-length-avg  | 460        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 304        |
| evaluation/episode-length-std  | 270        |
| evaluation/return-average      | 1756.094   |
| evaluation/return-max          | 4465.208   |
| evaluation/return-min          | 983.2077   |
| evaluation/return-std          | 1331.969   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46005      |
| perf/AverageLength             | 460        |
| perf/AverageReturn             | 1756.094   |
| perf/NormalizedReturn          | 0.382      |
| Q-avg                          | 193.43515  |
| Q-std                          | 99.98937   |
| Q_loss                         | 92.85504   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 166        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000488   |
| times/evaluation_paths         | 16.9       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 167000     |
| train-steps                    | 167000     |
| training/Q/q1_loss             | 96.60672   |
| training/sac_pi/alpha          | 0.16905504 |
| training/sac_pi/alpha_loss     | 0.3421643  |
| training/sac_pi/logp_pi        | 4.7740693  |
| training/sac_pi/pi_entropy     | 3.7917778  |
| training/sac_pi/pi_global_norm | 1.3851676  |
| training/sac_pi/policy_loss    | -192.38103 |
| training/sac_pi/std            | 0.52848566 |
| training/sac_pi/valid_num      | 4939.0     |
| training/sac_Q/q1              | 183.45564  |
| training/sac_Q/q2              | 182.68118  |
| training/sac_Q/q2_loss         | 97.47173   |
| training/sac_Q/q_global_norm   | 241.23723  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16781865  |
| epoch                          | 167         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4828.0464   |
| evaluation/return-max          | 4909.7793   |
| evaluation/return-min          | 4689.196    |
| evaluation/return-std          | 62.023727   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46079       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4828.0464   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 198.8314    |
| Q-std                          | 91.05702    |
| Q_loss                         | 84.57809    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 167         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000152    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000621    |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00408     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 168000      |
| train-steps                    | 168000      |
| training/Q/q1_loss             | 102.324165  |
| training/sac_pi/alpha          | 0.16782577  |
| training/sac_pi/alpha_loss     | -0.08847989 |
| training/sac_pi/logp_pi        | 4.4456677   |
| training/sac_pi/pi_entropy     | 3.7947001   |
| training/sac_pi/pi_global_norm | 1.8567481   |
| training/sac_pi/policy_loss    | -204.94559  |
| training/sac_pi/std            | 0.5394704   |
| training/sac_pi/valid_num      | 4966.0      |
| training/sac_Q/q1              | 193.9001    |
| training/sac_Q/q2              | 193.23933   |
| training/sac_Q/q2_loss         | 101.97142   |
| training/sac_Q/q_global_norm   | 236.40723   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17111471  |
| epoch                          | 168         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4648.6455   |
| evaluation/return-max          | 4732.8164   |
| evaluation/return-min          | 4547.7905   |
| evaluation/return-std          | 60.972157   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46043       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4648.6455   |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 194.60132   |
| Q-std                          | 101.47848   |
| Q_loss                         | 93.92301    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 168         |
| times/epoch_after_hook         | 3.72e-06    |
| times/epoch_before_hook        | 0.00014     |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000867    |
| times/evaluation_paths         | 34.3        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 62.2        |
| timestep                       | 1000        |
| timesteps_total                | 169000      |
| train-steps                    | 169000      |
| training/Q/q1_loss             | 81.29149    |
| training/sac_pi/alpha          | 0.17114101  |
| training/sac_pi/alpha_loss     | -0.22347309 |
| training/sac_pi/logp_pi        | 3.7266145   |
| training/sac_pi/pi_entropy     | 3.6273575   |
| training/sac_pi/pi_global_norm | 1.4379098   |
| training/sac_pi/policy_loss    | -202.26935  |
| training/sac_pi/std            | 0.49365124  |
| training/sac_pi/valid_num      | 4986.0      |
| training/sac_Q/q1              | 196.68674   |
| training/sac_Q/q2              | 196.25467   |
| training/sac_Q/q2_loss         | 81.44153    |
| training/sac_Q/q_global_norm   | 195.26735   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17015892   |
| epoch                          | 169          |
| evaluation/episode-length-avg  | 925          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 391          |
| evaluation/episode-length-std  | 183          |
| evaluation/return-average      | 4103.3555    |
| evaluation/return-max          | 4732.5723    |
| evaluation/return-min          | 1433.8958    |
| evaluation/return-std          | 928.42206    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3            |
| model/origin_ret               | 85.8         |
| model/penalty_ret              | 82.5         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46072        |
| perf/AverageLength             | 925          |
| perf/AverageReturn             | 4103.3555    |
| perf/NormalizedReturn          | 0.893        |
| Q-avg                          | 199.8511     |
| Q-std                          | 84.272736    |
| Q_loss                         | 95.41831     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 169          |
| times/epoch_after_hook         | 2.05e-06     |
| times/epoch_before_hook        | 0.000357     |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.00105      |
| times/evaluation_paths         | 30.8         |
| times/timestep_after_hook      | 0.00403      |
| times/timestep_before_hook     | 0.00819      |
| times/train                    | 61.8         |
| timestep                       | 1000         |
| timesteps_total                | 170000       |
| train-steps                    | 170000       |
| training/Q/q1_loss             | 87.214355    |
| training/sac_pi/alpha          | 0.17014208   |
| training/sac_pi/alpha_loss     | -0.019983822 |
| training/sac_pi/logp_pi        | 4.3079042    |
| training/sac_pi/pi_entropy     | 3.7200172    |
| training/sac_pi/pi_global_norm | 1.5397054    |
| training/sac_pi/policy_loss    | -196.36195   |
| training/sac_pi/std            | 0.51807785   |
| training/sac_pi/valid_num      | 4973.0       |
| training/sac_Q/q1              | 190.24637    |
| training/sac_Q/q2              | 189.22185    |
| training/sac_Q/q2_loss         | 87.84627     |
| training/sac_Q/q_global_norm   | 372.66577    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17438841 |
| epoch                          | 170        |
| evaluation/episode-length-avg  | 938        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 384        |
| evaluation/episode-length-std  | 185        |
| evaluation/return-average      | 4269.073   |
| evaluation/return-max          | 4647.2036  |
| evaluation/return-min          | 1519.416   |
| evaluation/return-std          | 917.5088   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46017      |
| perf/AverageLength             | 938        |
| perf/AverageReturn             | 4269.073   |
| perf/NormalizedReturn          | 0.93       |
| Q-avg                          | 201.90005  |
| Q-std                          | 88.46205   |
| Q_loss                         | 80.66879   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 170        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000369   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000623   |
| times/evaluation_paths         | 31.9       |
| times/timestep_after_hook      | 0.0041     |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 171000     |
| train-steps                    | 171000     |
| training/Q/q1_loss             | 82.55919   |
| training/sac_pi/alpha          | 0.17434897 |
| training/sac_pi/alpha_loss     | 0.15020229 |
| training/sac_pi/logp_pi        | 5.120581   |
| training/sac_pi/pi_entropy     | 3.9767196  |
| training/sac_pi/pi_global_norm | 1.5130242  |
| training/sac_pi/policy_loss    | -208.39877 |
| training/sac_pi/std            | 0.5915311  |
| training/sac_pi/valid_num      | 4933.0     |
| training/sac_Q/q1              | 198.29033  |
| training/sac_Q/q2              | 197.8238   |
| training/sac_Q/q2_loss         | 83.23847   |
| training/sac_Q/q_global_norm   | 208.06934  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16955446 |
| epoch                          | 171        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4648.19    |
| evaluation/return-max          | 4767.996   |
| evaluation/return-min          | 4511.6714  |
| evaluation/return-std          | 71.5372    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45846      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4648.19    |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 192.47107  |
| Q-std                          | 110.746796 |
| Q_loss                         | 97.5151    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 171        |
| times/epoch_after_hook         | 2.26e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.00073    |
| times/evaluation_paths         | 34.1       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 172000     |
| train-steps                    | 172000     |
| training/Q/q1_loss             | 105.14913  |
| training/sac_pi/alpha          | 0.16950883 |
| training/sac_pi/alpha_loss     | 0.30498543 |
| training/sac_pi/logp_pi        | 4.945526   |
| training/sac_pi/pi_entropy     | 3.7719078  |
| training/sac_pi/pi_global_norm | 1.8391422  |
| training/sac_pi/policy_loss    | -209.33023 |
| training/sac_pi/std            | 0.5544512  |
| training/sac_pi/valid_num      | 4914.0     |
| training/sac_Q/q1              | 198.52121  |
| training/sac_Q/q2              | 196.58371  |
| training/sac_Q/q2_loss         | 105.072525 |
| training/sac_Q/q_global_norm   | 253.73001  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16602342  |
| epoch                          | 172         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4760.063    |
| evaluation/return-max          | 4804.6875   |
| evaluation/return-min          | 4716.3315   |
| evaluation/return-std          | 26.267818   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46053       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4760.063    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 194.4017    |
| Q-std                          | 90.75802    |
| Q_loss                         | 100.73879   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 172         |
| times/epoch_after_hook         | 2.06e-06    |
| times/epoch_before_hook        | 0.00014     |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000666    |
| times/evaluation_paths         | 36.3        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 173000      |
| train-steps                    | 173000      |
| training/Q/q1_loss             | 95.298744   |
| training/sac_pi/alpha          | 0.16605084  |
| training/sac_pi/alpha_loss     | -0.47301924 |
| training/sac_pi/logp_pi        | 4.332785    |
| training/sac_pi/pi_entropy     | 3.8485558   |
| training/sac_pi/pi_global_norm | 1.5020827   |
| training/sac_pi/policy_loss    | -195.70433  |
| training/sac_pi/std            | 0.54651105  |
| training/sac_pi/valid_num      | 4899.0      |
| training/sac_Q/q1              | 185.01254   |
| training/sac_Q/q2              | 183.40247   |
| training/sac_Q/q2_loss         | 95.728355   |
| training/sac_Q/q_global_norm   | 336.7641    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16548727  |
| epoch                          | 173         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5045.796    |
| evaluation/return-max          | 5134.466    |
| evaluation/return-min          | 4944.1826   |
| evaluation/return-std          | 59.356335   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45975       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5045.796    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 197.1116    |
| Q-std                          | 104.03374   |
| Q_loss                         | 85.268196   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 173         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000278    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000525    |
| times/evaluation_paths         | 36          |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00803     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 174000      |
| train-steps                    | 174000      |
| training/Q/q1_loss             | 67.02269    |
| training/sac_pi/alpha          | 0.16549551  |
| training/sac_pi/alpha_loss     | -0.45682484 |
| training/sac_pi/logp_pi        | 4.133977    |
| training/sac_pi/pi_entropy     | 3.7592933   |
| training/sac_pi/pi_global_norm | 1.4481497   |
| training/sac_pi/policy_loss    | -206.71187  |
| training/sac_pi/std            | 0.5216168   |
| training/sac_pi/valid_num      | 4981.0      |
| training/sac_Q/q1              | 199.11253   |
| training/sac_Q/q2              | 198.54625   |
| training/sac_Q/q2_loss         | 66.91054    |
| training/sac_Q/q_global_norm   | 249.46933   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17001171  |
| epoch                          | 174         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4418.7144   |
| evaluation/return-max          | 4458.922    |
| evaluation/return-min          | 4387.0312   |
| evaluation/return-std          | 26.598528   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45998       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4418.7144   |
| perf/NormalizedReturn          | 0.962       |
| Q-avg                          | 196.55554   |
| Q-std                          | 95.41287    |
| Q_loss                         | 94.1244     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 174         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000254    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000627    |
| times/evaluation_paths         | 35.7        |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 175000      |
| train-steps                    | 175000      |
| training/Q/q1_loss             | 89.17012    |
| training/sac_pi/alpha          | 0.1700261   |
| training/sac_pi/alpha_loss     | -0.24346182 |
| training/sac_pi/logp_pi        | 3.7160213   |
| training/sac_pi/pi_entropy     | 3.6122468   |
| training/sac_pi/pi_global_norm | 1.2916927   |
| training/sac_pi/policy_loss    | -202.17503  |
| training/sac_pi/std            | 0.4903822   |
| training/sac_pi/valid_num      | 5000.0      |
| training/sac_Q/q1              | 197.12808   |
| training/sac_Q/q2              | 196.24287   |
| training/sac_Q/q2_loss         | 89.82482    |
| training/sac_Q/q_global_norm   | 249.32722   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17014137 |
| epoch                          | 175        |
| evaluation/episode-length-avg  | 934        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 342        |
| evaluation/episode-length-std  | 197        |
| evaluation/return-average      | 4046.9133  |
| evaluation/return-max          | 4471.437   |
| evaluation/return-min          | 1153.2483  |
| evaluation/return-std          | 966.9298   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46234      |
| perf/AverageLength             | 934        |
| perf/AverageReturn             | 4046.9133  |
| perf/NormalizedReturn          | 0.881      |
| Q-avg                          | 184.95564  |
| Q-std                          | 111.429855 |
| Q_loss                         | 130.26424  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 175        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000578   |
| times/evaluation_paths         | 33.1       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 176000     |
| train-steps                    | 176000     |
| training/Q/q1_loss             | 101.2747   |
| training/sac_pi/alpha          | 0.17014037 |
| training/sac_pi/alpha_loss     | -0.314875  |
| training/sac_pi/logp_pi        | 4.2240133  |
| training/sac_pi/pi_entropy     | 3.635324   |
| training/sac_pi/pi_global_norm | 1.4382697  |
| training/sac_pi/policy_loss    | -205.7877  |
| training/sac_pi/std            | 0.516198   |
| training/sac_pi/valid_num      | 4894.0     |
| training/sac_Q/q1              | 196.34721  |
| training/sac_Q/q2              | 194.8866   |
| training/sac_Q/q2_loss         | 101.45724  |
| training/sac_Q/q_global_norm   | 302.7574   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17447971   |
| epoch                          | 176          |
| evaluation/episode-length-avg  | 150          |
| evaluation/episode-length-max  | 159          |
| evaluation/episode-length-min  | 145          |
| evaluation/episode-length-std  | 4.81         |
| evaluation/return-average      | 433.17023    |
| evaluation/return-max          | 462.5515     |
| evaluation/return-min          | 406.7425     |
| evaluation/return-std          | 19.398088    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.95         |
| model/origin_ret               | 84.9         |
| model/penalty_ret              | 81.7         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46139        |
| perf/AverageLength             | 150          |
| perf/AverageReturn             | 433.17023    |
| perf/NormalizedReturn          | 0.094        |
| Q-avg                          | 197.53476    |
| Q-std                          | 90.657524    |
| Q_loss                         | 104.10127    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 176          |
| times/epoch_after_hook         | 1.74e-06     |
| times/epoch_before_hook        | 0.000131     |
| times/epoch_rollout_model      | 491          |
| times/evaluation_metrics       | 0.000576     |
| times/evaluation_paths         | 4.76         |
| times/timestep_after_hook      | 0.00399      |
| times/timestep_before_hook     | 0.00816      |
| times/train                    | 61           |
| timestep                       | 1000         |
| timesteps_total                | 177000       |
| train-steps                    | 177000       |
| training/Q/q1_loss             | 79.45891     |
| training/sac_pi/alpha          | 0.17448905   |
| training/sac_pi/alpha_loss     | -0.063455336 |
| training/sac_pi/logp_pi        | 4.4567356    |
| training/sac_pi/pi_entropy     | 3.73526      |
| training/sac_pi/pi_global_norm | 1.3530532    |
| training/sac_pi/policy_loss    | -209.0988    |
| training/sac_pi/std            | 0.53394735   |
| training/sac_pi/valid_num      | 4974.0       |
| training/sac_Q/q1              | 202.37207    |
| training/sac_Q/q2              | 200.50659    |
| training/sac_Q/q2_loss         | 77.95411     |
| training/sac_Q/q_global_norm   | 302.50513    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17121531 |
| epoch                          | 177        |
| evaluation/episode-length-avg  | 988        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 883        |
| evaluation/episode-length-std  | 35.1       |
| evaluation/return-average      | 4705.458   |
| evaluation/return-max          | 4819.2524  |
| evaluation/return-min          | 4127.3203  |
| evaluation/return-std          | 193.87262  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46052      |
| perf/AverageLength             | 988        |
| perf/AverageReturn             | 4705.458   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 198.87558  |
| Q-std                          | 90.22673   |
| Q_loss                         | 90.89923   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 177        |
| times/epoch_after_hook         | 3.33e-06   |
| times/epoch_before_hook        | 0.000324   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000823   |
| times/evaluation_paths         | 35.5       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 60.2       |
| timestep                       | 1000       |
| timesteps_total                | 178000     |
| train-steps                    | 178000     |
| training/Q/q1_loss             | 105.26206  |
| training/sac_pi/alpha          | 0.17117903 |
| training/sac_pi/alpha_loss     | 0.3112664  |
| training/sac_pi/logp_pi        | 4.3012342  |
| training/sac_pi/pi_entropy     | 3.7369537  |
| training/sac_pi/pi_global_norm | 1.6344346  |
| training/sac_pi/policy_loss    | -204.12767 |
| training/sac_pi/std            | 0.51669556 |
| training/sac_pi/valid_num      | 5004.0     |
| training/sac_Q/q1              | 198.39566  |
| training/sac_Q/q2              | 197.65204  |
| training/sac_Q/q2_loss         | 105.33196  |
| training/sac_Q/q_global_norm   | 250.2997   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1736924   |
| epoch                          | 178         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4781.449    |
| evaluation/return-max          | 4845.973    |
| evaluation/return-min          | 4710.4937   |
| evaluation/return-std          | 36.988346   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45959       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4781.449    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 180.36475   |
| Q-std                          | 114.1171    |
| Q_loss                         | 114.14851   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 178         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000155    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000568    |
| times/evaluation_paths         | 33.9        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00827     |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 179000      |
| train-steps                    | 179000      |
| training/Q/q1_loss             | 101.41319   |
| training/sac_pi/alpha          | 0.1737186   |
| training/sac_pi/alpha_loss     | -0.14749192 |
| training/sac_pi/logp_pi        | 4.4569626   |
| training/sac_pi/pi_entropy     | 3.6747844   |
| training/sac_pi/pi_global_norm | 1.4806968   |
| training/sac_pi/policy_loss    | -212.21277  |
| training/sac_pi/std            | 0.52681637  |
| training/sac_pi/valid_num      | 4935.0      |
| training/sac_Q/q1              | 201.58936   |
| training/sac_Q/q2              | 200.48592   |
| training/sac_Q/q2_loss         | 102.022316  |
| training/sac_Q/q_global_norm   | 228.96384   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1688594   |
| epoch                          | 179         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4969.8413   |
| evaluation/return-max          | 5071.9297   |
| evaluation/return-min          | 4886.945    |
| evaluation/return-std          | 63.5008     |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46149       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4969.8413   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 198.04813   |
| Q-std                          | 89.882416   |
| Q_loss                         | 110.95986   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 179         |
| times/epoch_after_hook         | 2.06e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000535    |
| times/evaluation_paths         | 34.9        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 180000      |
| train-steps                    | 180000      |
| training/Q/q1_loss             | 84.121864   |
| training/sac_pi/alpha          | 0.16889378  |
| training/sac_pi/alpha_loss     | -0.14837043 |
| training/sac_pi/logp_pi        | 3.9999778   |
| training/sac_pi/pi_entropy     | 3.6289318   |
| training/sac_pi/pi_global_norm | 1.817094    |
| training/sac_pi/policy_loss    | -207.69241  |
| training/sac_pi/std            | 0.49609387  |
| training/sac_pi/valid_num      | 4981.0      |
| training/sac_Q/q1              | 202.24687   |
| training/sac_Q/q2              | 201.20859   |
| training/sac_Q/q2_loss         | 83.40671    |
| training/sac_Q/q_global_norm   | 292.19482   |
---------------------------------------------------------------------------------
[WARN] 180 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.1715343    |
| epoch                          | 180          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4928.081     |
| evaluation/return-max          | 5035.538     |
| evaluation/return-min          | 4770.955     |
| evaluation/return-std          | 92.113266    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.99         |
| model/origin_ret               | 85.1         |
| model/penalty_ret              | 81.7         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46092        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4928.081     |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 192.3071     |
| Q-std                          | 96.18284     |
| Q_loss                         | 127.89245    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 180          |
| times/epoch_after_hook         | 1.97e-06     |
| times/epoch_before_hook        | 0.000132     |
| times/epoch_rollout_model      | 487          |
| times/evaluation_metrics       | 0.000602     |
| times/evaluation_paths         | 34.8         |
| times/timestep_after_hook      | 0.00394      |
| times/timestep_before_hook     | 0.00812      |
| times/train                    | 60.7         |
| timestep                       | 1000         |
| timesteps_total                | 181000       |
| train-steps                    | 181000       |
| training/Q/q1_loss             | 96.48994     |
| training/sac_pi/alpha          | 0.17155498   |
| training/sac_pi/alpha_loss     | -0.121104404 |
| training/sac_pi/logp_pi        | 4.849505     |
| training/sac_pi/pi_entropy     | 3.7474341    |
| training/sac_pi/pi_global_norm | 1.5682887    |
| training/sac_pi/policy_loss    | -200.04942   |
| training/sac_pi/std            | 0.5429121    |
| training/sac_pi/valid_num      | 4911.0       |
| training/sac_Q/q1              | 188.5854     |
| training/sac_Q/q2              | 187.30457    |
| training/sac_Q/q2_loss         | 96.25519     |
| training/sac_Q/q_global_norm   | 266.54364    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16948673  |
| epoch                          | 181         |
| evaluation/episode-length-avg  | 902         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 594         |
| evaluation/episode-length-std  | 154         |
| evaluation/return-average      | 4313.7866   |
| evaluation/return-max          | 4909.4746   |
| evaluation/return-min          | 2679.4897   |
| evaluation/return-std          | 799.659     |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46079       |
| perf/AverageLength             | 902         |
| perf/AverageReturn             | 4313.7866   |
| perf/NormalizedReturn          | 0.939       |
| Q-avg                          | 200.27908   |
| Q-std                          | 101.114296  |
| Q_loss                         | 101.67208   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 181         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000275    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000506    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 182000      |
| train-steps                    | 182000      |
| training/Q/q1_loss             | 101.75729   |
| training/sac_pi/alpha          | 0.16951226  |
| training/sac_pi/alpha_loss     | -0.30335996 |
| training/sac_pi/logp_pi        | 4.1313353   |
| training/sac_pi/pi_entropy     | 3.640471    |
| training/sac_pi/pi_global_norm | 1.6847755   |
| training/sac_pi/policy_loss    | -206.00424  |
| training/sac_pi/std            | 0.50181705  |
| training/sac_pi/valid_num      | 4998.0      |
| training/sac_Q/q1              | 201.23743   |
| training/sac_Q/q2              | 200.06377   |
| training/sac_Q/q2_loss         | 101.83949   |
| training/sac_Q/q_global_norm   | 223.26067   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16759777   |
| epoch                          | 182          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4944.0327    |
| evaluation/return-max          | 5002.571     |
| evaluation/return-min          | 4908.1235    |
| evaluation/return-std          | 33.909912    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.99         |
| model/origin_ret               | 85.8         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45889        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4944.0327    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 191.77988    |
| Q-std                          | 103.935356   |
| Q_loss                         | 96.78915     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 182          |
| times/epoch_after_hook         | 1.74e-06     |
| times/epoch_before_hook        | 0.000132     |
| times/epoch_rollout_model      | 490          |
| times/evaluation_metrics       | 0.000562     |
| times/evaluation_paths         | 33.7         |
| times/timestep_after_hook      | 0.00393      |
| times/timestep_before_hook     | 0.00808      |
| times/train                    | 60.9         |
| timestep                       | 1000         |
| timesteps_total                | 183000       |
| train-steps                    | 183000       |
| training/Q/q1_loss             | 106.55447    |
| training/sac_pi/alpha          | 0.1675882    |
| training/sac_pi/alpha_loss     | -0.115866296 |
| training/sac_pi/logp_pi        | 4.055137     |
| training/sac_pi/pi_entropy     | 3.4715233    |
| training/sac_pi/pi_global_norm | 1.3538032    |
| training/sac_pi/policy_loss    | -200.88742   |
| training/sac_pi/std            | 0.48467246   |
| training/sac_pi/valid_num      | 5025.0       |
| training/sac_Q/q1              | 196.21504    |
| training/sac_Q/q2              | 195.84094    |
| training/sac_Q/q2_loss         | 107.3664     |
| training/sac_Q/q_global_norm   | 271.48657    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17307825  |
| epoch                          | 183         |
| evaluation/episode-length-avg  | 524         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 121         |
| evaluation/episode-length-std  | 414         |
| evaluation/return-average      | 2312.4841   |
| evaluation/return-max          | 4818.458    |
| evaluation/return-min          | 272.41415   |
| evaluation/return-std          | 2106.5005   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45990       |
| perf/AverageLength             | 524         |
| perf/AverageReturn             | 2312.4841   |
| perf/NormalizedReturn          | 0.503       |
| Q-avg                          | 193.56323   |
| Q-std                          | 107.43807   |
| Q_loss                         | 106.79239   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 183         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000155    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000504    |
| times/evaluation_paths         | 18.7        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 60.5        |
| timestep                       | 1000        |
| timesteps_total                | 184000      |
| train-steps                    | 184000      |
| training/Q/q1_loss             | 88.55795    |
| training/sac_pi/alpha          | 0.17308824  |
| training/sac_pi/alpha_loss     | -0.20070033 |
| training/sac_pi/logp_pi        | 4.287165    |
| training/sac_pi/pi_entropy     | 3.6943116   |
| training/sac_pi/pi_global_norm | 2.0232744   |
| training/sac_pi/policy_loss    | -202.68787  |
| training/sac_pi/std            | 0.52324903  |
| training/sac_pi/valid_num      | 4941.0      |
| training/sac_Q/q1              | 193.37048   |
| training/sac_Q/q2              | 191.88718   |
| training/sac_Q/q2_loss         | 87.24517    |
| training/sac_Q/q_global_norm   | 313.90524   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17061116 |
| epoch                          | 184        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4621.908   |
| evaluation/return-max          | 4739.3     |
| evaluation/return-min          | 4395.794   |
| evaluation/return-std          | 88.86453   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 83.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46095      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4621.908   |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 186.3936   |
| Q-std                          | 109.59539  |
| Q_loss                         | 81.31541   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 184        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000557   |
| times/evaluation_paths         | 33.8       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 62.2       |
| timestep                       | 1000       |
| timesteps_total                | 185000     |
| train-steps                    | 185000     |
| training/Q/q1_loss             | 92.44866   |
| training/sac_pi/alpha          | 0.17059754 |
| training/sac_pi/alpha_loss     | 0.08440805 |
| training/sac_pi/logp_pi        | 3.6386993  |
| training/sac_pi/pi_entropy     | 3.7284024  |
| training/sac_pi/pi_global_norm | 1.5123632  |
| training/sac_pi/policy_loss    | -207.69218 |
| training/sac_pi/std            | 0.50375235 |
| training/sac_pi/valid_num      | 4999.0     |
| training/sac_Q/q1              | 202.77446  |
| training/sac_Q/q2              | 202.1063   |
| training/sac_Q/q2_loss         | 92.42881   |
| training/sac_Q/q_global_norm   | 214.22774  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16734417 |
| epoch                          | 185        |
| evaluation/episode-length-avg  | 951        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 676        |
| evaluation/episode-length-std  | 104        |
| evaluation/return-average      | 4620.755   |
| evaluation/return-max          | 4973.6973  |
| evaluation/return-min          | 3154.7808  |
| evaluation/return-std          | 552.4383   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 83.4       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46044      |
| perf/AverageLength             | 951        |
| perf/AverageReturn             | 4620.755   |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 190.50174  |
| Q-std                          | 100.74935  |
| Q_loss                         | 90.97449   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 185        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.000265   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000657   |
| times/evaluation_paths         | 33.6       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 186000     |
| train-steps                    | 186000     |
| training/Q/q1_loss             | 89.68757   |
| training/sac_pi/alpha          | 0.16739887 |
| training/sac_pi/alpha_loss     | -0.6093445 |
| training/sac_pi/logp_pi        | 3.774854   |
| training/sac_pi/pi_entropy     | 3.570504   |
| training/sac_pi/pi_global_norm | 1.5153335  |
| training/sac_pi/policy_loss    | -206.909   |
| training/sac_pi/std            | 0.49367374 |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 200.05981  |
| training/sac_Q/q2              | 199.44669  |
| training/sac_Q/q2_loss         | 89.66862   |
| training/sac_Q/q_global_norm   | 228.80943  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16760585 |
| epoch                          | 186        |
| evaluation/episode-length-avg  | 871        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 499        |
| evaluation/episode-length-std  | 176        |
| evaluation/return-average      | 4217.0767  |
| evaluation/return-max          | 4921.874   |
| evaluation/return-min          | 2288.0894  |
| evaluation/return-std          | 924.8245   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 82.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46178      |
| perf/AverageLength             | 871        |
| perf/AverageReturn             | 4217.0767  |
| perf/NormalizedReturn          | 0.918      |
| Q-avg                          | 190.0488   |
| Q-std                          | 117.71485  |
| Q_loss                         | 96.217865  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 186        |
| times/epoch_after_hook         | 2.05e-06   |
| times/epoch_before_hook        | 0.000156   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000602   |
| times/evaluation_paths         | 29.6       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 187000     |
| train-steps                    | 187000     |
| training/Q/q1_loss             | 89.728355  |
| training/sac_pi/alpha          | 0.16763702 |
| training/sac_pi/alpha_loss     | -0.55319   |
| training/sac_pi/logp_pi        | 3.7989902  |
| training/sac_pi/pi_entropy     | 3.6105335  |
| training/sac_pi/pi_global_norm | 1.615827   |
| training/sac_pi/policy_loss    | -208.09259 |
| training/sac_pi/std            | 0.5010941  |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 199.0187   |
| training/sac_Q/q2              | 198.2388   |
| training/sac_Q/q2_loss         | 90.32398   |
| training/sac_Q/q_global_norm   | 256.15378  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16678163 |
| epoch                          | 187        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4812.2437  |
| evaluation/return-max          | 5053.88    |
| evaluation/return-min          | 4548.4136  |
| evaluation/return-std          | 121.72856  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45917      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4812.2437  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 201.70593  |
| Q-std                          | 95.17023   |
| Q_loss                         | 119.723175 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 187        |
| times/epoch_after_hook         | 3.35e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.00069    |
| times/evaluation_paths         | 33.8       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00802    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 188000     |
| train-steps                    | 188000     |
| training/Q/q1_loss             | 107.79348  |
| training/sac_pi/alpha          | 0.16681702 |
| training/sac_pi/alpha_loss     | -0.513199  |
| training/sac_pi/logp_pi        | 3.9782348  |
| training/sac_pi/pi_entropy     | 3.7057433  |
| training/sac_pi/pi_global_norm | 1.3416927  |
| training/sac_pi/policy_loss    | -197.2548  |
| training/sac_pi/std            | 0.5207907  |
| training/sac_pi/valid_num      | 4945.0     |
| training/sac_Q/q1              | 189.3479   |
| training/sac_Q/q2              | 188.04941  |
| training/sac_Q/q2_loss         | 108.262535 |
| training/sac_Q/q_global_norm   | 292.99167  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16863896   |
| epoch                          | 188          |
| evaluation/episode-length-avg  | 232          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 142          |
| evaluation/episode-length-std  | 256          |
| evaluation/return-average      | 861.32275    |
| evaluation/return-max          | 4702.141     |
| evaluation/return-min          | 424.54358    |
| evaluation/return-std          | 1280.3016    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.95         |
| model/origin_ret               | 84.9         |
| model/penalty_ret              | 82           |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45994        |
| perf/AverageLength             | 232          |
| perf/AverageReturn             | 861.32275    |
| perf/NormalizedReturn          | 0.187        |
| Q-avg                          | 182.76166    |
| Q-std                          | 112.38392    |
| Q_loss                         | 101.52932    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 188          |
| times/epoch_after_hook         | 1.73e-06     |
| times/epoch_before_hook        | 0.000175     |
| times/epoch_rollout_model      | 496          |
| times/evaluation_metrics       | 0.000533     |
| times/evaluation_paths         | 7.47         |
| times/timestep_after_hook      | 0.00413      |
| times/timestep_before_hook     | 0.00834      |
| times/train                    | 61.8         |
| timestep                       | 1000         |
| timesteps_total                | 189000       |
| train-steps                    | 189000       |
| training/Q/q1_loss             | 109.34596    |
| training/sac_pi/alpha          | 0.16862266   |
| training/sac_pi/alpha_loss     | -0.109785534 |
| training/sac_pi/logp_pi        | 3.9709282    |
| training/sac_pi/pi_entropy     | 3.784169     |
| training/sac_pi/pi_global_norm | 1.7796441    |
| training/sac_pi/policy_loss    | -202.75854   |
| training/sac_pi/std            | 0.5054533    |
| training/sac_pi/valid_num      | 4970.0       |
| training/sac_Q/q1              | 194.89236    |
| training/sac_Q/q2              | 194.4085     |
| training/sac_Q/q2_loss         | 109.888214   |
| training/sac_Q/q_global_norm   | 201.81557    |
----------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.16999635    |
| epoch                          | 189           |
| evaluation/episode-length-avg  | 745           |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 139           |
| evaluation/episode-length-std  | 389           |
| evaluation/return-average      | 3430.0593     |
| evaluation/return-max          | 4795.212      |
| evaluation/return-min          | 362.43353     |
| evaluation/return-std          | 1988.7936     |
| model/max_penalty              | 7.27          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 2.94          |
| model/origin_ret               | 84.6          |
| model/penalty_ret              | 81.9          |
| model/val_loss                 | 0.39125705    |
| model/valid_num                | 46074         |
| perf/AverageLength             | 745           |
| perf/AverageReturn             | 3430.0593     |
| perf/NormalizedReturn          | 0.747         |
| Q-avg                          | 191.11479     |
| Q-std                          | 98.84044      |
| Q_loss                         | 98.78808      |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 189           |
| times/epoch_after_hook         | 1.88e-06      |
| times/epoch_before_hook        | 0.000275      |
| times/epoch_rollout_model      | 487           |
| times/evaluation_metrics       | 0.000785      |
| times/evaluation_paths         | 25.5          |
| times/timestep_after_hook      | 0.00379       |
| times/timestep_before_hook     | 0.00806       |
| times/train                    | 62            |
| timestep                       | 1000          |
| timesteps_total                | 190000        |
| train-steps                    | 190000        |
| training/Q/q1_loss             | 111.39978     |
| training/sac_pi/alpha          | 0.1700118     |
| training/sac_pi/alpha_loss     | -0.0064355545 |
| training/sac_pi/logp_pi        | 4.3759847     |
| training/sac_pi/pi_entropy     | 3.6086926     |
| training/sac_pi/pi_global_norm | 1.8422272     |
| training/sac_pi/policy_loss    | -202.27348    |
| training/sac_pi/std            | 0.51202786    |
| training/sac_pi/valid_num      | 4994.0        |
| training/sac_Q/q1              | 196.20027     |
| training/sac_Q/q2              | 194.88875     |
| training/sac_Q/q2_loss         | 112.439125    |
| training/sac_Q/q_global_norm   | 266.4094      |
-----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16910511 |
| epoch                          | 190        |
| evaluation/episode-length-avg  | 477        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 128        |
| evaluation/episode-length-std  | 427        |
| evaluation/return-average      | 2154.513   |
| evaluation/return-max          | 4955.0103  |
| evaluation/return-min          | 296.18332  |
| evaluation/return-std          | 2274.3425  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46189      |
| perf/AverageLength             | 477        |
| perf/AverageReturn             | 2154.513   |
| perf/NormalizedReturn          | 0.469      |
| Q-avg                          | 188.129    |
| Q-std                          | 125.41253  |
| Q_loss                         | 82.26383   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 190        |
| times/epoch_after_hook         | 2.02e-06   |
| times/epoch_before_hook        | 0.00017    |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000649   |
| times/evaluation_paths         | 17         |
| times/timestep_after_hook      | 0.00425    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 191000     |
| train-steps                    | 191000     |
| training/Q/q1_loss             | 103.05115  |
| training/sac_pi/alpha          | 0.16908489 |
| training/sac_pi/alpha_loss     | 0.33269334 |
| training/sac_pi/logp_pi        | 4.3631907  |
| training/sac_pi/pi_entropy     | 3.470343   |
| training/sac_pi/pi_global_norm | 1.2318162  |
| training/sac_pi/policy_loss    | -198.38837 |
| training/sac_pi/std            | 0.48371193 |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 190.59644  |
| training/sac_Q/q2              | 190.04762  |
| training/sac_Q/q2_loss         | 102.799644 |
| training/sac_Q/q_global_norm   | 201.32088  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16941291 |
| epoch                          | 191        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4461.5728  |
| evaluation/return-max          | 4538.858   |
| evaluation/return-min          | 4397.589   |
| evaluation/return-std          | 47.39232   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46088      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4461.5728  |
| perf/NormalizedReturn          | 0.972      |
| Q-avg                          | 191.4321   |
| Q-std                          | 101.22513  |
| Q_loss                         | 89.88382   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 191        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000142   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000651   |
| times/evaluation_paths         | 35.7       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 192000     |
| train-steps                    | 192000     |
| training/Q/q1_loss             | 100.56901  |
| training/sac_pi/alpha          | 0.1694056  |
| training/sac_pi/alpha_loss     | 0.2187469  |
| training/sac_pi/logp_pi        | 4.397873   |
| training/sac_pi/pi_entropy     | 3.7182426  |
| training/sac_pi/pi_global_norm | 1.6198378  |
| training/sac_pi/policy_loss    | -197.12186 |
| training/sac_pi/std            | 0.52275646 |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 190.81319  |
| training/sac_Q/q2              | 189.70187  |
| training/sac_Q/q2_loss         | 100.7197   |
| training/sac_Q/q_global_norm   | 277.26624  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16735372  |
| epoch                          | 192         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5045.6104   |
| evaluation/return-max          | 5118.4985   |
| evaluation/return-min          | 4994.9395   |
| evaluation/return-std          | 35.7721     |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46304       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5045.6104   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 197.8083    |
| Q-std                          | 106.03204   |
| Q_loss                         | 95.29865    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 192         |
| times/epoch_after_hook         | 2e-06       |
| times/epoch_before_hook        | 0.000299    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000745    |
| times/evaluation_paths         | 35.8        |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.00832     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 193000      |
| train-steps                    | 193000      |
| training/Q/q1_loss             | 92.385864   |
| training/sac_pi/alpha          | 0.16737303  |
| training/sac_pi/alpha_loss     | -0.24833858 |
| training/sac_pi/logp_pi        | 4.521164    |
| training/sac_pi/pi_entropy     | 3.4985461   |
| training/sac_pi/pi_global_norm | 1.5992849   |
| training/sac_pi/policy_loss    | -205.98491  |
| training/sac_pi/std            | 0.51891214  |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 198.13647   |
| training/sac_Q/q2              | 196.89182   |
| training/sac_Q/q2_loss         | 92.70601    |
| training/sac_Q/q_global_norm   | 253.85806   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17149717  |
| epoch                          | 193         |
| evaluation/episode-length-avg  | 965         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 818         |
| evaluation/episode-length-std  | 69.3        |
| evaluation/return-average      | 4543.9937   |
| evaluation/return-max          | 4817.463    |
| evaluation/return-min          | 3883.9023   |
| evaluation/return-std          | 328.93802   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45986       |
| perf/AverageLength             | 965         |
| perf/AverageReturn             | 4543.9937   |
| perf/NormalizedReturn          | 0.989       |
| Q-avg                          | 191.0682    |
| Q-std                          | 101.655685  |
| Q_loss                         | 97.95811    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 193         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000329    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000871    |
| times/evaluation_paths         | 33.1        |
| times/timestep_after_hook      | 0.00378     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 194000      |
| train-steps                    | 194000      |
| training/Q/q1_loss             | 85.04083    |
| training/sac_pi/alpha          | 0.17148937  |
| training/sac_pi/alpha_loss     | -0.03619658 |
| training/sac_pi/logp_pi        | 4.3856373   |
| training/sac_pi/pi_entropy     | 3.7600493   |
| training/sac_pi/pi_global_norm | 1.902146    |
| training/sac_pi/policy_loss    | -202.21585  |
| training/sac_pi/std            | 0.52687716  |
| training/sac_pi/valid_num      | 4987.0      |
| training/sac_Q/q1              | 195.47023   |
| training/sac_Q/q2              | 193.89522   |
| training/sac_Q/q2_loss         | 85.84514    |
| training/sac_Q/q_global_norm   | 210.57166   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1707966  |
| epoch                          | 194        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5092.0776  |
| evaluation/return-max          | 5149.2275  |
| evaluation/return-min          | 5039.597   |
| evaluation/return-std          | 39.085083  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45986      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5092.0776  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 203.35832  |
| Q-std                          | 98.3181    |
| Q_loss                         | 89.157104  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 194        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000141   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000591   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00802    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 195000     |
| train-steps                    | 195000     |
| training/Q/q1_loss             | 93.40225   |
| training/sac_pi/alpha          | 0.17079216 |
| training/sac_pi/alpha_loss     | 0.07449053 |
| training/sac_pi/logp_pi        | 3.3758533  |
| training/sac_pi/pi_entropy     | 3.4742475  |
| training/sac_pi/pi_global_norm | 1.6881002  |
| training/sac_pi/policy_loss    | -212.62811 |
| training/sac_pi/std            | 0.45808002 |
| training/sac_pi/valid_num      | 4948.0     |
| training/sac_Q/q1              | 205.68954  |
| training/sac_Q/q2              | 205.70377  |
| training/sac_Q/q2_loss         | 92.66201   |
| training/sac_Q/q_global_norm   | 257.84692  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17306939  |
| epoch                          | 195         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4692.7085   |
| evaluation/return-max          | 4856.009    |
| evaluation/return-min          | 4601.1123   |
| evaluation/return-std          | 68.83657    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46068       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4692.7085   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 197.12805   |
| Q-std                          | 115.15661   |
| Q_loss                         | 98.27293    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 195         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000791    |
| times/evaluation_paths         | 33.9        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.0081      |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 196000      |
| train-steps                    | 196000      |
| training/Q/q1_loss             | 82.2982     |
| training/sac_pi/alpha          | 0.17310333  |
| training/sac_pi/alpha_loss     | -0.48320004 |
| training/sac_pi/logp_pi        | 3.6435642   |
| training/sac_pi/pi_entropy     | 3.5192513   |
| training/sac_pi/pi_global_norm | 1.3841555   |
| training/sac_pi/policy_loss    | -215.9565   |
| training/sac_pi/std            | 0.48564497  |
| training/sac_pi/valid_num      | 4989.0      |
| training/sac_Q/q1              | 210.27937   |
| training/sac_Q/q2              | 209.18643   |
| training/sac_Q/q2_loss         | 82.46767    |
| training/sac_Q/q_global_norm   | 305.4745    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1705639   |
| epoch                          | 196         |
| evaluation/episode-length-avg  | 975         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 746         |
| evaluation/episode-length-std  | 76.2        |
| evaluation/return-average      | 4366.334    |
| evaluation/return-max          | 4600.0957   |
| evaluation/return-min          | 3205.4824   |
| evaluation/return-std          | 389.96744   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46351       |
| perf/AverageLength             | 975         |
| perf/AverageReturn             | 4366.334    |
| perf/NormalizedReturn          | 0.951       |
| Q-avg                          | 196.06612   |
| Q-std                          | 94.59847    |
| Q_loss                         | 96.76252    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 196         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000159    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000672    |
| times/evaluation_paths         | 34.7        |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 197000      |
| train-steps                    | 197000      |
| training/Q/q1_loss             | 124.42808   |
| training/sac_pi/alpha          | 0.17059371  |
| training/sac_pi/alpha_loss     | 0.009776923 |
| training/sac_pi/logp_pi        | 4.7860084   |
| training/sac_pi/pi_entropy     | 3.7326958   |
| training/sac_pi/pi_global_norm | 1.6653126   |
| training/sac_pi/policy_loss    | -206.02385  |
| training/sac_pi/std            | 0.5415489   |
| training/sac_pi/valid_num      | 4962.0      |
| training/sac_Q/q1              | 193.9813    |
| training/sac_Q/q2              | 192.3884    |
| training/sac_Q/q2_loss         | 125.037094  |
| training/sac_Q/q_global_norm   | 386.54916   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17123935  |
| epoch                          | 197         |
| evaluation/episode-length-avg  | 888         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 600         |
| evaluation/episode-length-std  | 169         |
| evaluation/return-average      | 4225.93     |
| evaluation/return-max          | 4961.915    |
| evaluation/return-min          | 2638.0366   |
| evaluation/return-std          | 913.6165    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46045       |
| perf/AverageLength             | 888         |
| perf/AverageReturn             | 4225.93     |
| perf/NormalizedReturn          | 0.92        |
| Q-avg                          | 196.95796   |
| Q-std                          | 99.89948    |
| Q_loss                         | 98.16384    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 197         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000321    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000891    |
| times/evaluation_paths         | 30.1        |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00832     |
| times/train                    | 59.8        |
| timestep                       | 1000        |
| timesteps_total                | 198000      |
| train-steps                    | 198000      |
| training/Q/q1_loss             | 105.57859   |
| training/sac_pi/alpha          | 0.17125967  |
| training/sac_pi/alpha_loss     | 0.014130394 |
| training/sac_pi/logp_pi        | 4.219166    |
| training/sac_pi/pi_entropy     | 3.5618255   |
| training/sac_pi/pi_global_norm | 1.7726109   |
| training/sac_pi/policy_loss    | -211.1331   |
| training/sac_pi/std            | 0.49376926  |
| training/sac_pi/valid_num      | 4971.0      |
| training/sac_Q/q1              | 204.94637   |
| training/sac_Q/q2              | 202.80276   |
| training/sac_Q/q2_loss         | 106.12286   |
| training/sac_Q/q_global_norm   | 306.87045   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16374373  |
| epoch                          | 198         |
| evaluation/episode-length-avg  | 748         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 160         |
| evaluation/episode-length-std  | 384         |
| evaluation/return-average      | 3604.859    |
| evaluation/return-max          | 5013.9644   |
| evaluation/return-min          | 519.00366   |
| evaluation/return-std          | 2019.9786   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 82.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45972       |
| perf/AverageLength             | 748         |
| perf/AverageReturn             | 3604.859    |
| perf/NormalizedReturn          | 0.785       |
| Q-avg                          | 202.89029   |
| Q-std                          | 94.7128     |
| Q_loss                         | 80.01955    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 198         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000638    |
| times/evaluation_paths         | 26.4        |
| times/timestep_after_hook      | 0.00396     |
| times/timestep_before_hook     | 0.00822     |
| times/train                    | 60.4        |
| timestep                       | 1000        |
| timesteps_total                | 199000      |
| train-steps                    | 199000      |
| training/Q/q1_loss             | 82.9168     |
| training/sac_pi/alpha          | 0.16374017  |
| training/sac_pi/alpha_loss     | -0.27197656 |
| training/sac_pi/logp_pi        | 4.561998    |
| training/sac_pi/pi_entropy     | 3.3965354   |
| training/sac_pi/pi_global_norm | 1.5507333   |
| training/sac_pi/policy_loss    | -216.27551  |
| training/sac_pi/std            | 0.5038717   |
| training/sac_pi/valid_num      | 4997.0      |
| training/sac_Q/q1              | 208.73442   |
| training/sac_Q/q2              | 206.43442   |
| training/sac_Q/q2_loss         | 83.73338    |
| training/sac_Q/q_global_norm   | 248.478     |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16374893 |
| epoch                          | 199        |
| evaluation/episode-length-avg  | 748        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 157        |
| evaluation/episode-length-std  | 385        |
| evaluation/return-average      | 3448.6304  |
| evaluation/return-max          | 4840.929   |
| evaluation/return-min          | 496.02084  |
| evaluation/return-std          | 1931.6316  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46033      |
| perf/AverageLength             | 748        |
| perf/AverageReturn             | 3448.6304  |
| perf/NormalizedReturn          | 0.751      |
| Q-avg                          | 198.97021  |
| Q-std                          | 108.94045  |
| Q_loss                         | 96.106064  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 199        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000533   |
| times/evaluation_paths         | 25.6       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 61.5       |
| timestep                       | 1000       |
| timesteps_total                | 200000     |
| train-steps                    | 200000     |
| training/Q/q1_loss             | 130.98076  |
| training/sac_pi/alpha          | 0.1637596  |
| training/sac_pi/alpha_loss     | 0.15062131 |
| training/sac_pi/logp_pi        | 4.5956597  |
| training/sac_pi/pi_entropy     | 3.6398826  |
| training/sac_pi/pi_global_norm | 1.8709748  |
| training/sac_pi/policy_loss    | -195.18513 |
| training/sac_pi/std            | 0.52984154 |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 185.2399   |
| training/sac_Q/q2              | 183.4858   |
| training/sac_Q/q2_loss         | 130.38684  |
| training/sac_Q/q_global_norm   | 306.18076  |
--------------------------------------------------------------------------------
[WARN] 200 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16709779 |
| epoch                          | 200        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5196.558   |
| evaluation/return-max          | 5264.261   |
| evaluation/return-min          | 5040.668   |
| evaluation/return-std          | 68.59122   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46083      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5196.558   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 192.92249  |
| Q-std                          | 121.962105 |
| Q_loss                         | 102.05028  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 200        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000616   |
| times/evaluation_paths         | 35.6       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 201000     |
| train-steps                    | 201000     |
| training/Q/q1_loss             | 102.82573  |
| training/sac_pi/alpha          | 0.16707863 |
| training/sac_pi/alpha_loss     | 0.08301385 |
| training/sac_pi/logp_pi        | 4.185124   |
| training/sac_pi/pi_entropy     | 3.720523   |
| training/sac_pi/pi_global_norm | 1.8332095  |
| training/sac_pi/policy_loss    | -200.73563 |
| training/sac_pi/std            | 0.5196716  |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 193.68399  |
| training/sac_Q/q2              | 192.55667  |
| training/sac_Q/q2_loss         | 103.090485 |
| training/sac_Q/q_global_norm   | 250.91777  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16997501  |
| epoch                          | 201         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5030.285    |
| evaluation/return-max          | 5149.8867   |
| evaluation/return-min          | 4905.7827   |
| evaluation/return-std          | 64.06626    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45879       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5030.285    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 205.24332   |
| Q-std                          | 91.68093    |
| Q_loss                         | 90.94195    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 201         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000301    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.00051     |
| times/evaluation_paths         | 33          |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00792     |
| times/train                    | 60          |
| timestep                       | 1000        |
| timesteps_total                | 202000      |
| train-steps                    | 202000      |
| training/Q/q1_loss             | 106.56714   |
| training/sac_pi/alpha          | 0.17001137  |
| training/sac_pi/alpha_loss     | -0.19382013 |
| training/sac_pi/logp_pi        | 4.1157      |
| training/sac_pi/pi_entropy     | 3.6476555   |
| training/sac_pi/pi_global_norm | 1.6657289   |
| training/sac_pi/policy_loss    | -210.83199  |
| training/sac_pi/std            | 0.5127915   |
| training/sac_pi/valid_num      | 4958.0      |
| training/sac_Q/q1              | 201.69316   |
| training/sac_Q/q2              | 199.83208   |
| training/sac_Q/q2_loss         | 106.045555  |
| training/sac_Q/q_global_norm   | 275.92422   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16647069   |
| epoch                          | 202          |
| evaluation/episode-length-avg  | 888          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 398          |
| evaluation/episode-length-std  | 224          |
| evaluation/return-average      | 3962.7754    |
| evaluation/return-max          | 4626.6445    |
| evaluation/return-min          | 1464.6675    |
| evaluation/return-std          | 1176.0337    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.01         |
| model/origin_ret               | 85.1         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46126        |
| perf/AverageLength             | 888          |
| perf/AverageReturn             | 3962.7754    |
| perf/NormalizedReturn          | 0.863        |
| Q-avg                          | 205.22949    |
| Q-std                          | 91.55049     |
| Q_loss                         | 88.00259     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 202          |
| times/epoch_after_hook         | 2.17e-06     |
| times/epoch_before_hook        | 0.000227     |
| times/epoch_rollout_model      | 488          |
| times/evaluation_metrics       | 0.00058      |
| times/evaluation_paths         | 30.3         |
| times/timestep_after_hook      | 0.00401      |
| times/timestep_before_hook     | 0.00816      |
| times/train                    | 61.9         |
| timestep                       | 1000         |
| timesteps_total                | 203000       |
| train-steps                    | 203000       |
| training/Q/q1_loss             | 103.848114   |
| training/sac_pi/alpha          | 0.16648975   |
| training/sac_pi/alpha_loss     | -0.039223712 |
| training/sac_pi/logp_pi        | 4.2896023    |
| training/sac_pi/pi_entropy     | 3.3460908    |
| training/sac_pi/pi_global_norm | 1.3939979    |
| training/sac_pi/policy_loss    | -207.31197   |
| training/sac_pi/std            | 0.47800332   |
| training/sac_pi/valid_num      | 4968.0       |
| training/sac_Q/q1              | 200.01334    |
| training/sac_Q/q2              | 199.79465    |
| training/sac_Q/q2_loss         | 104.17517    |
| training/sac_Q/q_global_norm   | 241.6867     |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1738659   |
| epoch                          | 203         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4934.5874   |
| evaluation/return-max          | 4987.6562   |
| evaluation/return-min          | 4889.6865   |
| evaluation/return-std          | 27.389824   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46296       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4934.5874   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 208.7459    |
| Q-std                          | 86.89181    |
| Q_loss                         | 95.65257    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 203         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000155    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000722    |
| times/evaluation_paths         | 33.9        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 204000      |
| train-steps                    | 204000      |
| training/Q/q1_loss             | 79.76278    |
| training/sac_pi/alpha          | 0.17387737  |
| training/sac_pi/alpha_loss     | -0.21154816 |
| training/sac_pi/logp_pi        | 4.01711     |
| training/sac_pi/pi_entropy     | 3.5558732   |
| training/sac_pi/pi_global_norm | 1.4011588   |
| training/sac_pi/policy_loss    | -213.16081  |
| training/sac_pi/std            | 0.50789845  |
| training/sac_pi/valid_num      | 4963.0      |
| training/sac_Q/q1              | 205.90544   |
| training/sac_Q/q2              | 204.78964   |
| training/sac_Q/q2_loss         | 80.12513    |
| training/sac_Q/q_global_norm   | 258.78918   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17709127 |
| epoch                          | 204        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4880.675   |
| evaluation/return-max          | 4940.9194  |
| evaluation/return-min          | 4788.142   |
| evaluation/return-std          | 51.227688  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46164      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4880.675   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 200.59433  |
| Q-std                          | 98.838486  |
| Q_loss                         | 102.245445 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 204        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000522   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.00406    |
| times/timestep_before_hook     | 0.0102     |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 205000     |
| train-steps                    | 205000     |
| training/Q/q1_loss             | 101.65867  |
| training/sac_pi/alpha          | 0.17705971 |
| training/sac_pi/alpha_loss     | -0.0355376 |
| training/sac_pi/logp_pi        | 4.1083655  |
| training/sac_pi/pi_entropy     | 3.4605994  |
| training/sac_pi/pi_global_norm | 1.396275   |
| training/sac_pi/policy_loss    | -211.48349 |
| training/sac_pi/std            | 0.4826206  |
| training/sac_pi/valid_num      | 5029.0     |
| training/sac_Q/q1              | 208.00395  |
| training/sac_Q/q2              | 205.16768  |
| training/sac_Q/q2_loss         | 101.44536  |
| training/sac_Q/q_global_norm   | 236.2458   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16969639 |
| epoch                          | 205        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4828.507   |
| evaluation/return-max          | 4933.9756  |
| evaluation/return-min          | 4743.9736  |
| evaluation/return-std          | 60.34146   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 82.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45945      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4828.507   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 205.19186  |
| Q-std                          | 101.666725 |
| Q_loss                         | 83.85019   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 205        |
| times/epoch_after_hook         | 2.01e-06   |
| times/epoch_before_hook        | 0.000264   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000695   |
| times/evaluation_paths         | 33.8       |
| times/timestep_after_hook      | 0.00398    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 206000     |
| train-steps                    | 206000     |
| training/Q/q1_loss             | 99.87929   |
| training/sac_pi/alpha          | 0.16970691 |
| training/sac_pi/alpha_loss     | 0.03039455 |
| training/sac_pi/logp_pi        | 4.1278234  |
| training/sac_pi/pi_entropy     | 3.5975041  |
| training/sac_pi/pi_global_norm | 1.6205434  |
| training/sac_pi/policy_loss    | -205.86644 |
| training/sac_pi/std            | 0.5155325  |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 197.95885  |
| training/sac_Q/q2              | 196.88358  |
| training/sac_Q/q2_loss         | 99.23318   |
| training/sac_Q/q_global_norm   | 211.45795  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1716557  |
| epoch                          | 206        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4906.767   |
| evaluation/return-max          | 4961.8174  |
| evaluation/return-min          | 4782.291   |
| evaluation/return-std          | 47.78162   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46030      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4906.767   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 192.21921  |
| Q-std                          | 108.044785 |
| Q_loss                         | 93.51759   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 206        |
| times/epoch_after_hook         | 3.65e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000668   |
| times/evaluation_paths         | 33.9       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00798    |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 207000     |
| train-steps                    | 207000     |
| training/Q/q1_loss             | 88.710014  |
| training/sac_pi/alpha          | 0.17165437 |
| training/sac_pi/alpha_loss     | 0.10992217 |
| training/sac_pi/logp_pi        | 4.071223   |
| training/sac_pi/pi_entropy     | 3.541652   |
| training/sac_pi/pi_global_norm | 1.4827514  |
| training/sac_pi/policy_loss    | -206.5742  |
| training/sac_pi/std            | 0.49280295 |
| training/sac_pi/valid_num      | 4942.0     |
| training/sac_Q/q1              | 199.03528  |
| training/sac_Q/q2              | 198.19357  |
| training/sac_Q/q2_loss         | 88.3738    |
| training/sac_Q/q_global_norm   | 344.1049   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16704358 |
| epoch                          | 207        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4867.654   |
| evaluation/return-max          | 4900.807   |
| evaluation/return-min          | 4796.1357  |
| evaluation/return-std          | 28.14029   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45895      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4867.654   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 200.58382  |
| Q-std                          | 101.73782  |
| Q_loss                         | 81.01945   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 207        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000713   |
| times/evaluation_paths         | 34.1       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 62.4       |
| timestep                       | 1000       |
| timesteps_total                | 208000     |
| train-steps                    | 208000     |
| training/Q/q1_loss             | 102.16943  |
| training/sac_pi/alpha          | 0.16699843 |
| training/sac_pi/alpha_loss     | 0.64824235 |
| training/sac_pi/logp_pi        | 4.654456   |
| training/sac_pi/pi_entropy     | 3.3023095  |
| training/sac_pi/pi_global_norm | 1.7228847  |
| training/sac_pi/policy_loss    | -208.7274  |
| training/sac_pi/std            | 0.4752844  |
| training/sac_pi/valid_num      | 5006.0     |
| training/sac_Q/q1              | 203.17615  |
| training/sac_Q/q2              | 202.41196  |
| training/sac_Q/q2_loss         | 102.88163  |
| training/sac_Q/q_global_norm   | 332.0923   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16564873   |
| epoch                          | 208          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4735.183     |
| evaluation/return-max          | 4864.559     |
| evaluation/return-min          | 4607.4434    |
| evaluation/return-std          | 91.31082     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.94         |
| model/origin_ret               | 84.4         |
| model/penalty_ret              | 80.6         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46159        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4735.183     |
| perf/NormalizedReturn          | 1.03         |
| Q-avg                          | 196.79214    |
| Q-std                          | 104.339584   |
| Q_loss                         | 88.52078     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 208          |
| times/epoch_after_hook         | 1.93e-06     |
| times/epoch_before_hook        | 0.000139     |
| times/epoch_rollout_model      | 489          |
| times/evaluation_metrics       | 0.000612     |
| times/evaluation_paths         | 33.9         |
| times/timestep_after_hook      | 0.00404      |
| times/timestep_before_hook     | 0.00822      |
| times/train                    | 62           |
| timestep                       | 1000         |
| timesteps_total                | 209000       |
| train-steps                    | 209000       |
| training/Q/q1_loss             | 96.36179     |
| training/sac_pi/alpha          | 0.16563545   |
| training/sac_pi/alpha_loss     | -0.055353858 |
| training/sac_pi/logp_pi        | 4.3892465    |
| training/sac_pi/pi_entropy     | 3.6164756    |
| training/sac_pi/pi_global_norm | 1.9818108    |
| training/sac_pi/policy_loss    | -203.55916   |
| training/sac_pi/std            | 0.5296421    |
| training/sac_pi/valid_num      | 4926.0       |
| training/sac_Q/q1              | 195.29575    |
| training/sac_Q/q2              | 194.43753    |
| training/sac_Q/q2_loss         | 96.48203     |
| training/sac_Q/q_global_norm   | 219.14447    |
----------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.17027016    |
| epoch                          | 209           |
| evaluation/episode-length-avg  | 155           |
| evaluation/episode-length-max  | 158           |
| evaluation/episode-length-min  | 151           |
| evaluation/episode-length-std  | 2.18          |
| evaluation/return-average      | 498.4229      |
| evaluation/return-max          | 506.54        |
| evaluation/return-min          | 490.6731      |
| evaluation/return-std          | 3.8348348     |
| model/max_penalty              | 7.27          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 2.9           |
| model/origin_ret               | 85.5          |
| model/penalty_ret              | 83.1          |
| model/val_loss                 | 0.39125705    |
| model/valid_num                | 45856         |
| perf/AverageLength             | 155           |
| perf/AverageReturn             | 498.4229      |
| perf/NormalizedReturn          | 0.108         |
| Q-avg                          | 203.15115     |
| Q-std                          | 100.42888     |
| Q_loss                         | 106.76614     |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 209           |
| times/epoch_after_hook         | 1.73e-06      |
| times/epoch_before_hook        | 0.000252      |
| times/epoch_rollout_model      | 483           |
| times/evaluation_metrics       | 0.000519      |
| times/evaluation_paths         | 5.09          |
| times/timestep_after_hook      | 0.00406       |
| times/timestep_before_hook     | 0.00803       |
| times/train                    | 61.7          |
| timestep                       | 1000          |
| timesteps_total                | 210000        |
| train-steps                    | 210000        |
| training/Q/q1_loss             | 104.845245    |
| training/sac_pi/alpha          | 0.17026526    |
| training/sac_pi/alpha_loss     | -0.0106457565 |
| training/sac_pi/logp_pi        | 5.127227      |
| training/sac_pi/pi_entropy     | 3.5056672     |
| training/sac_pi/pi_global_norm | 1.5314659     |
| training/sac_pi/policy_loss    | -210.51237    |
| training/sac_pi/std            | 0.5218184     |
| training/sac_pi/valid_num      | 4911.0        |
| training/sac_Q/q1              | 197.5052      |
| training/sac_Q/q2              | 197.72493     |
| training/sac_Q/q2_loss         | 105.61325     |
| training/sac_Q/q_global_norm   | 309.144       |
-----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17370312  |
| epoch                          | 210         |
| evaluation/episode-length-avg  | 132         |
| evaluation/episode-length-max  | 134         |
| evaluation/episode-length-min  | 131         |
| evaluation/episode-length-std  | 0.943       |
| evaluation/return-average      | 392.14542   |
| evaluation/return-max          | 407.10062   |
| evaluation/return-min          | 385.938     |
| evaluation/return-std          | 5.501654    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46035       |
| perf/AverageLength             | 132         |
| perf/AverageReturn             | 392.14542   |
| perf/NormalizedReturn          | 0.0851      |
| Q-avg                          | 190.62375   |
| Q-std                          | 113.436     |
| Q_loss                         | 82.78632    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 210         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000159    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.00052     |
| times/evaluation_paths         | 5.62        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 211000      |
| train-steps                    | 211000      |
| training/Q/q1_loss             | 115.341034  |
| training/sac_pi/alpha          | 0.17369024  |
| training/sac_pi/alpha_loss     | -0.17808564 |
| training/sac_pi/logp_pi        | 4.6861978   |
| training/sac_pi/pi_entropy     | 3.7693696   |
| training/sac_pi/pi_global_norm | 1.7376989   |
| training/sac_pi/policy_loss    | -203.07285  |
| training/sac_pi/std            | 0.5430969   |
| training/sac_pi/valid_num      | 4887.0      |
| training/sac_Q/q1              | 189.4335    |
| training/sac_Q/q2              | 188.63472   |
| training/sac_Q/q2_loss         | 116.7659    |
| training/sac_Q/q_global_norm   | 257.75674   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16962577 |
| epoch                          | 211        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4971.949   |
| evaluation/return-max          | 5111.649   |
| evaluation/return-min          | 4875.414   |
| evaluation/return-std          | 74.84922   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46078      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4971.949   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 199.63005  |
| Q-std                          | 95.71596   |
| Q_loss                         | 93.1239    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 211        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000598   |
| times/evaluation_paths         | 33.9       |
| times/timestep_after_hook      | 0.00412    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 212000     |
| train-steps                    | 212000     |
| training/Q/q1_loss             | 107.58854  |
| training/sac_pi/alpha          | 0.1696492  |
| training/sac_pi/alpha_loss     | 0.5362948  |
| training/sac_pi/logp_pi        | 4.805007   |
| training/sac_pi/pi_entropy     | 3.459781   |
| training/sac_pi/pi_global_norm | 1.7273254  |
| training/sac_pi/policy_loss    | -213.04904 |
| training/sac_pi/std            | 0.50779605 |
| training/sac_pi/valid_num      | 4942.0     |
| training/sac_Q/q1              | 203.733    |
| training/sac_Q/q2              | 202.5579   |
| training/sac_Q/q2_loss         | 107.13381  |
| training/sac_Q/q_global_norm   | 317.8213   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17211445  |
| epoch                          | 212         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 1091.9375   |
| evaluation/return-max          | 1094.554    |
| evaluation/return-min          | 1090.7875   |
| evaluation/return-std          | 1.0656235   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46097       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 1091.9375   |
| perf/NormalizedReturn          | 0.238       |
| Q-avg                          | 198.94228   |
| Q-std                          | 114.317345  |
| Q_loss                         | 94.069595   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 212         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000552    |
| times/evaluation_paths         | 33.9        |
| times/timestep_after_hook      | 0.004       |
| times/timestep_before_hook     | 0.00801     |
| times/train                    | 62          |
| timestep                       | 1000        |
| timesteps_total                | 213000      |
| train-steps                    | 213000      |
| training/Q/q1_loss             | 130.08485   |
| training/sac_pi/alpha          | 0.17212498  |
| training/sac_pi/alpha_loss     | -0.03196166 |
| training/sac_pi/logp_pi        | 5.11625     |
| training/sac_pi/pi_entropy     | 3.617794    |
| training/sac_pi/pi_global_norm | 1.9744455   |
| training/sac_pi/policy_loss    | -209.16858  |
| training/sac_pi/std            | 0.5462236   |
| training/sac_pi/valid_num      | 4898.0      |
| training/sac_Q/q1              | 191.9867    |
| training/sac_Q/q2              | 190.54243   |
| training/sac_Q/q2_loss         | 130.52725   |
| training/sac_Q/q_global_norm   | 301.70148   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17152618  |
| epoch                          | 213         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4780.479    |
| evaluation/return-max          | 5017.6978   |
| evaluation/return-min          | 4678.54     |
| evaluation/return-std          | 117.04908   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46040       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4780.479    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 207.18098   |
| Q-std                          | 89.309814   |
| Q_loss                         | 76.23163    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 213         |
| times/epoch_after_hook         | 2e-06       |
| times/epoch_before_hook        | 0.000278    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000648    |
| times/evaluation_paths         | 34.2        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 214000      |
| train-steps                    | 214000      |
| training/Q/q1_loss             | 96.64591    |
| training/sac_pi/alpha          | 0.1715469   |
| training/sac_pi/alpha_loss     | -0.24521445 |
| training/sac_pi/logp_pi        | 3.9058456   |
| training/sac_pi/pi_entropy     | 3.5438526   |
| training/sac_pi/pi_global_norm | 1.511237    |
| training/sac_pi/policy_loss    | -210.20177  |
| training/sac_pi/std            | 0.49253482  |
| training/sac_pi/valid_num      | 4950.0      |
| training/sac_Q/q1              | 202.99905   |
| training/sac_Q/q2              | 202.07193   |
| training/sac_Q/q2_loss         | 96.6399     |
| training/sac_Q/q_global_norm   | 269.25366   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16753456  |
| epoch                          | 214         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4899.9736   |
| evaluation/return-max          | 4954.385    |
| evaluation/return-min          | 4767.414    |
| evaluation/return-std          | 53.00558    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46141       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4899.9736   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 202.67584   |
| Q-std                          | 99.83455    |
| Q_loss                         | 89.67402    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 214         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.00052     |
| times/evaluation_paths         | 34.3        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 215000      |
| train-steps                    | 215000      |
| training/Q/q1_loss             | 95.22867    |
| training/sac_pi/alpha          | 0.16751707  |
| training/sac_pi/alpha_loss     | 0.060679447 |
| training/sac_pi/logp_pi        | 4.2746124   |
| training/sac_pi/pi_entropy     | 3.471814    |
| training/sac_pi/pi_global_norm | 1.376711    |
| training/sac_pi/policy_loss    | -210.02843  |
| training/sac_pi/std            | 0.49751642  |
| training/sac_pi/valid_num      | 4996.0      |
| training/sac_Q/q1              | 204.10893   |
| training/sac_Q/q2              | 202.55331   |
| training/sac_Q/q2_loss         | 94.489845   |
| training/sac_Q/q_global_norm   | 227.80936   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1689309  |
| epoch                          | 215        |
| evaluation/episode-length-avg  | 969        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 691        |
| evaluation/episode-length-std  | 92.7       |
| evaluation/return-average      | 4770.2754  |
| evaluation/return-max          | 5031.4556  |
| evaluation/return-min          | 3340.852   |
| evaluation/return-std          | 478.61237  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46065      |
| perf/AverageLength             | 969        |
| perf/AverageReturn             | 4770.2754  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 194.45297  |
| Q-std                          | 106.27392  |
| Q_loss                         | 103.984    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 215        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000557   |
| times/evaluation_paths         | 32.8       |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 216000     |
| train-steps                    | 216000     |
| training/Q/q1_loss             | 115.64016  |
| training/sac_pi/alpha          | 0.16890243 |
| training/sac_pi/alpha_loss     | 0.35241964 |
| training/sac_pi/logp_pi        | 4.287176   |
| training/sac_pi/pi_entropy     | 3.5768237  |
| training/sac_pi/pi_global_norm | 1.7730844  |
| training/sac_pi/policy_loss    | -209.23082 |
| training/sac_pi/std            | 0.50029665 |
| training/sac_pi/valid_num      | 5001.0     |
| training/sac_Q/q1              | 202.01018  |
| training/sac_Q/q2              | 202.1232   |
| training/sac_Q/q2_loss         | 116.40019  |
| training/sac_Q/q_global_norm   | 223.57693  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16849071 |
| epoch                          | 216        |
| evaluation/episode-length-avg  | 113        |
| evaluation/episode-length-max  | 115        |
| evaluation/episode-length-min  | 108        |
| evaluation/episode-length-std  | 2          |
| evaluation/return-average      | 197.32164  |
| evaluation/return-max          | 204.27937  |
| evaluation/return-min          | 186.59395  |
| evaluation/return-std          | 4.9778214  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 87         |
| model/penalty_ret              | 83.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45802      |
| perf/AverageLength             | 113        |
| perf/AverageReturn             | 197.32164  |
| perf/NormalizedReturn          | 0.0426     |
| Q-avg                          | 199.85112  |
| Q-std                          | 107.48782  |
| Q_loss                         | 111.30299  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 216        |
| times/epoch_after_hook         | 2.09e-06   |
| times/epoch_before_hook        | 0.000144   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000663   |
| times/evaluation_paths         | 3.69       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 217000     |
| train-steps                    | 217000     |
| training/Q/q1_loss             | 99.90478   |
| training/sac_pi/alpha          | 0.16849272 |
| training/sac_pi/alpha_loss     | 0.18310963 |
| training/sac_pi/logp_pi        | 4.0591073  |
| training/sac_pi/pi_entropy     | 3.413939   |
| training/sac_pi/pi_global_norm | 2.0868042  |
| training/sac_pi/policy_loss    | -217.5523  |
| training/sac_pi/std            | 0.48926497 |
| training/sac_pi/valid_num      | 5018.0     |
| training/sac_Q/q1              | 211.53833  |
| training/sac_Q/q2              | 210.37039  |
| training/sac_Q/q2_loss         | 98.52846   |
| training/sac_Q/q_global_norm   | 206.52872  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.169209   |
| epoch                          | 217        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4609.7393  |
| evaluation/return-max          | 4703.186   |
| evaluation/return-min          | 4527.0356  |
| evaluation/return-std          | 60.980923  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 83.1       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46150      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4609.7393  |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 194.21657  |
| Q-std                          | 101.80157  |
| Q_loss                         | 118.24498  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 217        |
| times/epoch_after_hook         | 2.35e-06   |
| times/epoch_before_hook        | 0.000281   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000588   |
| times/evaluation_paths         | 33.4       |
| times/timestep_after_hook      | 0.00412    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 218000     |
| train-steps                    | 218000     |
| training/Q/q1_loss             | 88.585396  |
| training/sac_pi/alpha          | 0.16919488 |
| training/sac_pi/alpha_loss     | 0.19601452 |
| training/sac_pi/logp_pi        | 4.020176   |
| training/sac_pi/pi_entropy     | 3.5917327  |
| training/sac_pi/pi_global_norm | 2.0657067  |
| training/sac_pi/policy_loss    | -197.92975 |
| training/sac_pi/std            | 0.4902603  |
| training/sac_pi/valid_num      | 4996.0     |
| training/sac_Q/q1              | 193.67299  |
| training/sac_Q/q2              | 192.41779  |
| training/sac_Q/q2_loss         | 89.74869   |
| training/sac_Q/q_global_norm   | 216.84073  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16566212 |
| epoch                          | 218        |
| evaluation/episode-length-avg  | 524        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 154        |
| evaluation/episode-length-std  | 332        |
| evaluation/return-average      | 2267.2778  |
| evaluation/return-max          | 4813.259   |
| evaluation/return-min          | 368.23834  |
| evaluation/return-std          | 1726.7228  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46079      |
| perf/AverageLength             | 524        |
| perf/AverageReturn             | 2267.2778  |
| perf/NormalizedReturn          | 0.494      |
| Q-avg                          | 192.58786  |
| Q-std                          | 103.876755 |
| Q_loss                         | 134.77486  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 218        |
| times/epoch_after_hook         | 2.06e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000764   |
| times/evaluation_paths         | 18.3       |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 219000     |
| train-steps                    | 219000     |
| training/Q/q1_loss             | 122.79565  |
| training/sac_pi/alpha          | 0.16568606 |
| training/sac_pi/alpha_loss     | 0.29737163 |
| training/sac_pi/logp_pi        | 5.0691004  |
| training/sac_pi/pi_entropy     | 3.489212   |
| training/sac_pi/pi_global_norm | 1.782048   |
| training/sac_pi/policy_loss    | -205.44266 |
| training/sac_pi/std            | 0.51648784 |
| training/sac_pi/valid_num      | 4911.0     |
| training/sac_Q/q1              | 193.50386  |
| training/sac_Q/q2              | 190.85905  |
| training/sac_Q/q2_loss         | 122.04542  |
| training/sac_Q/q_global_norm   | 278.82935  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16847412  |
| epoch                          | 219         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5005.8975   |
| evaluation/return-max          | 5094.9263   |
| evaluation/return-min          | 4898.562    |
| evaluation/return-std          | 59.307533   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46180       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5005.8975   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 202.06354   |
| Q-std                          | 92.22515    |
| Q_loss                         | 115.00261   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 219         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000394    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000641    |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 220000      |
| train-steps                    | 220000      |
| training/Q/q1_loss             | 82.0353     |
| training/sac_pi/alpha          | 0.16850951  |
| training/sac_pi/alpha_loss     | -0.46991053 |
| training/sac_pi/logp_pi        | 4.4044933   |
| training/sac_pi/pi_entropy     | 3.6042085   |
| training/sac_pi/pi_global_norm | 1.9067065   |
| training/sac_pi/policy_loss    | -210.92955  |
| training/sac_pi/std            | 0.52268225  |
| training/sac_pi/valid_num      | 4922.0      |
| training/sac_Q/q1              | 201.68732   |
| training/sac_Q/q2              | 200.6672    |
| training/sac_Q/q2_loss         | 81.057465   |
| training/sac_Q/q_global_norm   | 257.30466   |
---------------------------------------------------------------------------------
[WARN] 220 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.17216633  |
| epoch                          | 220         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4459.532    |
| evaluation/return-max          | 4527.3267   |
| evaluation/return-min          | 4296.949    |
| evaluation/return-std          | 65.71537    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46015       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4459.532    |
| perf/NormalizedReturn          | 0.971       |
| Q-avg                          | 189.69226   |
| Q-std                          | 118.29609   |
| Q_loss                         | 101.88215   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 220         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000607    |
| times/evaluation_paths         | 35.4        |
| times/timestep_after_hook      | 0.00387     |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 60.2        |
| timestep                       | 1000        |
| timesteps_total                | 221000      |
| train-steps                    | 221000      |
| training/Q/q1_loss             | 73.93033    |
| training/sac_pi/alpha          | 0.17215678  |
| training/sac_pi/alpha_loss     | -0.18997735 |
| training/sac_pi/logp_pi        | 4.1795816   |
| training/sac_pi/pi_entropy     | 3.5051856   |
| training/sac_pi/pi_global_norm | 1.4996736   |
| training/sac_pi/policy_loss    | -215.12532  |
| training/sac_pi/std            | 0.5064005   |
| training/sac_pi/valid_num      | 4991.0      |
| training/sac_Q/q1              | 207.27974   |
| training/sac_Q/q2              | 205.74358   |
| training/sac_Q/q2_loss         | 74.738655   |
| training/sac_Q/q_global_norm   | 316.05478   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17272623  |
| epoch                          | 221         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4625.345    |
| evaluation/return-max          | 4719.9688   |
| evaluation/return-min          | 4515.559    |
| evaluation/return-std          | 55.456516   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 83.5        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46026       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4625.345    |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 201.63905   |
| Q-std                          | 97.92854    |
| Q_loss                         | 99.86181    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 221         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000261    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000638    |
| times/evaluation_paths         | 34.1        |
| times/timestep_after_hook      | 0.00387     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 222000      |
| train-steps                    | 222000      |
| training/Q/q1_loss             | 88.03715    |
| training/sac_pi/alpha          | 0.17274897  |
| training/sac_pi/alpha_loss     | -0.42116365 |
| training/sac_pi/logp_pi        | 4.1662154   |
| training/sac_pi/pi_entropy     | 3.4235878   |
| training/sac_pi/pi_global_norm | 1.5592742   |
| training/sac_pi/policy_loss    | -215.02217  |
| training/sac_pi/std            | 0.49506032  |
| training/sac_pi/valid_num      | 4962.0      |
| training/sac_Q/q1              | 208.07495   |
| training/sac_Q/q2              | 207.00082   |
| training/sac_Q/q2_loss         | 87.59117    |
| training/sac_Q/q_global_norm   | 268.11035   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17438145  |
| epoch                          | 222         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4681.744    |
| evaluation/return-max          | 4764.6484   |
| evaluation/return-min          | 4552.6045   |
| evaluation/return-std          | 63.724457   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46043       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4681.744    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 200.74782   |
| Q-std                          | 104.46486   |
| Q_loss                         | 101.5289    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 222         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000821    |
| times/evaluation_paths         | 34.9        |
| times/timestep_after_hook      | 0.00648     |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 223000      |
| train-steps                    | 223000      |
| training/Q/q1_loss             | 85.57894    |
| training/sac_pi/alpha          | 0.17439316  |
| training/sac_pi/alpha_loss     | -0.20299546 |
| training/sac_pi/logp_pi        | 4.2018523   |
| training/sac_pi/pi_entropy     | 3.4982975   |
| training/sac_pi/pi_global_norm | 1.8715253   |
| training/sac_pi/policy_loss    | -212.81041  |
| training/sac_pi/std            | 0.49644297  |
| training/sac_pi/valid_num      | 4975.0      |
| training/sac_Q/q1              | 205.93057   |
| training/sac_Q/q2              | 204.15543   |
| training/sac_Q/q2_loss         | 84.85746    |
| training/sac_Q/q_global_norm   | 250.90417   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17419598 |
| epoch                          | 223        |
| evaluation/episode-length-avg  | 677        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 151        |
| evaluation/episode-length-std  | 367        |
| evaluation/return-average      | 3332.7573  |
| evaluation/return-max          | 5189.3823  |
| evaluation/return-min          | 426.8694   |
| evaluation/return-std          | 2046.6042  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46076      |
| perf/AverageLength             | 677        |
| perf/AverageReturn             | 3332.7573  |
| perf/NormalizedReturn          | 0.726      |
| Q-avg                          | 197.60971  |
| Q-std                          | 107.28224  |
| Q_loss                         | 116.1411   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 223        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000148   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000477   |
| times/evaluation_paths         | 23.1       |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 224000     |
| train-steps                    | 224000     |
| training/Q/q1_loss             | 97.0522    |
| training/sac_pi/alpha          | 0.17419612 |
| training/sac_pi/alpha_loss     | 0.07242674 |
| training/sac_pi/logp_pi        | 4.399926   |
| training/sac_pi/pi_entropy     | 3.7757385  |
| training/sac_pi/pi_global_norm | 1.857085   |
| training/sac_pi/policy_loss    | -210.66821 |
| training/sac_pi/std            | 0.5297787  |
| training/sac_pi/valid_num      | 5001.0     |
| training/sac_Q/q1              | 204.80473  |
| training/sac_Q/q2              | 202.85764  |
| training/sac_Q/q2_loss         | 96.251205  |
| training/sac_Q/q_global_norm   | 267.21173  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16881439  |
| epoch                          | 224         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4470.542    |
| evaluation/return-max          | 4594.082    |
| evaluation/return-min          | 4380.6255   |
| evaluation/return-std          | 75.704445   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46123       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4470.542    |
| perf/NormalizedReturn          | 0.973       |
| Q-avg                          | 204.63873   |
| Q-std                          | 94.2659     |
| Q_loss                         | 89.57659    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 224         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000142    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000654    |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.0081      |
| times/train                    | 62.3        |
| timestep                       | 1000        |
| timesteps_total                | 225000      |
| train-steps                    | 225000      |
| training/Q/q1_loss             | 114.44296   |
| training/sac_pi/alpha          | 0.16879666  |
| training/sac_pi/alpha_loss     | -0.07206665 |
| training/sac_pi/logp_pi        | 4.0580473   |
| training/sac_pi/pi_entropy     | 3.5907867   |
| training/sac_pi/pi_global_norm | 1.5283284   |
| training/sac_pi/policy_loss    | -207.1582   |
| training/sac_pi/std            | 0.49925825  |
| training/sac_pi/valid_num      | 4999.0      |
| training/sac_Q/q1              | 200.97746   |
| training/sac_Q/q2              | 200.21523   |
| training/sac_Q/q2_loss         | 113.60572   |
| training/sac_Q/q_global_norm   | 265.60056   |
---------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.16963492    |
| epoch                          | 225           |
| evaluation/episode-length-avg  | 1e+03         |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 1000          |
| evaluation/episode-length-std  | 0             |
| evaluation/return-average      | 4460.4946     |
| evaluation/return-max          | 4539.738      |
| evaluation/return-min          | 4385.634      |
| evaluation/return-std          | 42.49962      |
| model/max_penalty              | 7.27          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 3.01          |
| model/origin_ret               | 85.3          |
| model/penalty_ret              | 82.3          |
| model/val_loss                 | 0.39125705    |
| model/valid_num                | 46116         |
| perf/AverageLength             | 1e+03         |
| perf/AverageReturn             | 4460.4946     |
| perf/NormalizedReturn          | 0.971         |
| Q-avg                          | 195.57217     |
| Q-std                          | 96.83373      |
| Q_loss                         | 96.77857      |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 225           |
| times/epoch_after_hook         | 1.97e-06      |
| times/epoch_before_hook        | 0.000304      |
| times/epoch_rollout_model      | 489           |
| times/evaluation_metrics       | 0.000565      |
| times/evaluation_paths         | 34.5          |
| times/timestep_after_hook      | 0.00407       |
| times/timestep_before_hook     | 0.00824       |
| times/train                    | 59.5          |
| timestep                       | 1000          |
| timesteps_total                | 226000        |
| train-steps                    | 226000        |
| training/Q/q1_loss             | 101.589195    |
| training/sac_pi/alpha          | 0.16966477    |
| training/sac_pi/alpha_loss     | -0.0154130105 |
| training/sac_pi/logp_pi        | 4.22347       |
| training/sac_pi/pi_entropy     | 3.4531407     |
| training/sac_pi/pi_global_norm | 1.4041167     |
| training/sac_pi/policy_loss    | -205.84924    |
| training/sac_pi/std            | 0.49477154    |
| training/sac_pi/valid_num      | 4964.0        |
| training/sac_Q/q1              | 199.37906     |
| training/sac_Q/q2              | 197.53703     |
| training/sac_Q/q2_loss         | 101.75587     |
| training/sac_Q/q_global_norm   | 250.17903     |
-----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16952553  |
| epoch                          | 226         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4667.939    |
| evaluation/return-max          | 4712.858    |
| evaluation/return-min          | 4617.852    |
| evaluation/return-std          | 28.718786   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46203       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4667.939    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 197.97612   |
| Q-std                          | 106.78997   |
| Q_loss                         | 113.764275  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 226         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000592    |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.00407     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 227000      |
| train-steps                    | 227000      |
| training/Q/q1_loss             | 81.36785    |
| training/sac_pi/alpha          | 0.16953233  |
| training/sac_pi/alpha_loss     | -0.40252092 |
| training/sac_pi/logp_pi        | 4.035187    |
| training/sac_pi/pi_entropy     | 3.6443257   |
| training/sac_pi/pi_global_norm | 1.3889463   |
| training/sac_pi/policy_loss    | -210.06114  |
| training/sac_pi/std            | 0.51837677  |
| training/sac_pi/valid_num      | 4956.0      |
| training/sac_Q/q1              | 201.16617   |
| training/sac_Q/q2              | 199.81111   |
| training/sac_Q/q2_loss         | 81.712105   |
| training/sac_Q/q_global_norm   | 205.50047   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16835427 |
| epoch                          | 227        |
| evaluation/episode-length-avg  | 934        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 719        |
| evaluation/episode-length-std  | 107        |
| evaluation/return-average      | 4476.499   |
| evaluation/return-max          | 4868.332   |
| evaluation/return-min          | 3278.9456  |
| evaluation/return-std          | 595.41797  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 82.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46004      |
| perf/AverageLength             | 934        |
| perf/AverageReturn             | 4476.499   |
| perf/NormalizedReturn          | 0.975      |
| Q-avg                          | 208.04565  |
| Q-std                          | 96.25771   |
| Q_loss                         | 100.53755  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 227        |
| times/epoch_after_hook         | 3.39e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000573   |
| times/evaluation_paths         | 32         |
| times/timestep_after_hook      | 0.00412    |
| times/timestep_before_hook     | 0.00802    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 228000     |
| train-steps                    | 228000     |
| training/Q/q1_loss             | 121.8341   |
| training/sac_pi/alpha          | 0.16838396 |
| training/sac_pi/alpha_loss     | -0.5930744 |
| training/sac_pi/logp_pi        | 3.995955   |
| training/sac_pi/pi_entropy     | 3.798841   |
| training/sac_pi/pi_global_norm | 1.8399298  |
| training/sac_pi/policy_loss    | -206.49002 |
| training/sac_pi/std            | 0.53092796 |
| training/sac_pi/valid_num      | 4934.0     |
| training/sac_Q/q1              | 196.77243  |
| training/sac_Q/q2              | 195.05956  |
| training/sac_Q/q2_loss         | 120.38103  |
| training/sac_Q/q_global_norm   | 287.6184   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17562833 |
| epoch                          | 228        |
| evaluation/episode-length-avg  | 946        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 458        |
| evaluation/episode-length-std  | 163        |
| evaluation/return-average      | 4254.386   |
| evaluation/return-max          | 4803.741   |
| evaluation/return-min          | 1806.9708  |
| evaluation/return-std          | 829.2726   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46102      |
| perf/AverageLength             | 946        |
| perf/AverageReturn             | 4254.386   |
| perf/NormalizedReturn          | 0.926      |
| Q-avg                          | 201.03651  |
| Q-std                          | 109.72755  |
| Q_loss                         | 110.3699   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 228        |
| times/epoch_after_hook         | 2.16e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000657   |
| times/evaluation_paths         | 32.7       |
| times/timestep_after_hook      | 0.00411    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 229000     |
| train-steps                    | 229000     |
| training/Q/q1_loss             | 99.50035   |
| training/sac_pi/alpha          | 0.17569391 |
| training/sac_pi/alpha_loss     | -0.3878633 |
| training/sac_pi/logp_pi        | 4.16272    |
| training/sac_pi/pi_entropy     | 3.6188512  |
| training/sac_pi/pi_global_norm | 1.4160478  |
| training/sac_pi/policy_loss    | -216.91612 |
| training/sac_pi/std            | 0.5216854  |
| training/sac_pi/valid_num      | 4949.0     |
| training/sac_Q/q1              | 208.55952  |
| training/sac_Q/q2              | 206.3909   |
| training/sac_Q/q2_loss         | 99.05999   |
| training/sac_Q/q_global_norm   | 272.42514  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1745644  |
| epoch                          | 229        |
| evaluation/episode-length-avg  | 412        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 157        |
| evaluation/episode-length-std  | 385        |
| evaluation/return-average      | 1855.0469  |
| evaluation/return-max          | 4987.339   |
| evaluation/return-min          | 511.5869   |
| evaluation/return-std          | 2041.6844  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 83.5       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45907      |
| perf/AverageLength             | 412        |
| perf/AverageReturn             | 1855.0469  |
| perf/NormalizedReturn          | 0.404      |
| Q-avg                          | 208.18845  |
| Q-std                          | 101.157265 |
| Q_loss                         | 116.2187   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 229        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.000314   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000894   |
| times/evaluation_paths         | 14.4       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 230000     |
| train-steps                    | 230000     |
| training/Q/q1_loss             | 80.09835   |
| training/sac_pi/alpha          | 0.1745912  |
| training/sac_pi/alpha_loss     | -0.5283574 |
| training/sac_pi/logp_pi        | 3.6342578  |
| training/sac_pi/pi_entropy     | 3.6864753  |
| training/sac_pi/pi_global_norm | 1.4964926  |
| training/sac_pi/policy_loss    | -212.62277 |
| training/sac_pi/std            | 0.5033223  |
| training/sac_pi/valid_num      | 5007.0     |
| training/sac_Q/q1              | 207.98254  |
| training/sac_Q/q2              | 207.2675   |
| training/sac_Q/q2_loss         | 79.94574   |
| training/sac_Q/q_global_norm   | 253.34143  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17676136  |
| epoch                          | 230         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4319.7314   |
| evaluation/return-max          | 4440.499    |
| evaluation/return-min          | 4232.714    |
| evaluation/return-std          | 66.71669    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46063       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4319.7314   |
| perf/NormalizedReturn          | 0.941       |
| Q-avg                          | 194.48796   |
| Q-std                          | 106.731735  |
| Q_loss                         | 105.52156   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 230         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000171    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000576    |
| times/evaluation_paths         | 36.1        |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 60.5        |
| timestep                       | 1000        |
| timesteps_total                | 231000      |
| train-steps                    | 231000      |
| training/Q/q1_loss             | 104.47219   |
| training/sac_pi/alpha          | 0.17673966  |
| training/sac_pi/alpha_loss     | -0.06466999 |
| training/sac_pi/logp_pi        | 3.707315    |
| training/sac_pi/pi_entropy     | 3.5505967   |
| training/sac_pi/pi_global_norm | 1.8891277   |
| training/sac_pi/policy_loss    | -204.65842  |
| training/sac_pi/std            | 0.4881405   |
| training/sac_pi/valid_num      | 4945.0      |
| training/sac_Q/q1              | 196.46306   |
| training/sac_Q/q2              | 195.73654   |
| training/sac_Q/q2_loss         | 104.83259   |
| training/sac_Q/q_global_norm   | 272.72113   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17285858 |
| epoch                          | 231        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4404.0586  |
| evaluation/return-max          | 4522.471   |
| evaluation/return-min          | 4265.124   |
| evaluation/return-std          | 72.0645    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46035      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4404.0586  |
| perf/NormalizedReturn          | 0.959      |
| Q-avg                          | 209.7485   |
| Q-std                          | 95.47069   |
| Q_loss                         | 95.887634  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 231        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000699   |
| times/evaluation_paths         | 33.4       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.0102     |
| times/train                    | 60         |
| timestep                       | 1000       |
| timesteps_total                | 232000     |
| train-steps                    | 232000     |
| training/Q/q1_loss             | 102.825554 |
| training/sac_pi/alpha          | 0.17290209 |
| training/sac_pi/alpha_loss     | -0.2761691 |
| training/sac_pi/logp_pi        | 3.6916356  |
| training/sac_pi/pi_entropy     | 3.4179497  |
| training/sac_pi/pi_global_norm | 2.0086145  |
| training/sac_pi/policy_loss    | -208.94044 |
| training/sac_pi/std            | 0.47583956 |
| training/sac_pi/valid_num      | 4998.0     |
| training/sac_Q/q1              | 203.3957   |
| training/sac_Q/q2              | 202.7583   |
| training/sac_Q/q2_loss         | 102.437    |
| training/sac_Q/q_global_norm   | 226.61446  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17321779 |
| epoch                          | 232        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4670.141   |
| evaluation/return-max          | 4852.0     |
| evaluation/return-min          | 4556.2744  |
| evaluation/return-std          | 101.35836  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 83.5       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45991      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4670.141   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 201.31204  |
| Q-std                          | 118.07011  |
| Q_loss                         | 84.379     |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 232        |
| times/epoch_after_hook         | 2.04e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000554   |
| times/evaluation_paths         | 33.7       |
| times/timestep_after_hook      | 0.00409    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 233000     |
| train-steps                    | 233000     |
| training/Q/q1_loss             | 95.91137   |
| training/sac_pi/alpha          | 0.17317109 |
| training/sac_pi/alpha_loss     | 0.05971484 |
| training/sac_pi/logp_pi        | 4.294973   |
| training/sac_pi/pi_entropy     | 3.5229306  |
| training/sac_pi/pi_global_norm | 1.7547733  |
| training/sac_pi/policy_loss    | -218.35674 |
| training/sac_pi/std            | 0.51162505 |
| training/sac_pi/valid_num      | 5001.0     |
| training/sac_Q/q1              | 211.70952  |
| training/sac_Q/q2              | 210.4185   |
| training/sac_Q/q2_loss         | 94.41642   |
| training/sac_Q/q_global_norm   | 224.66757  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16793709 |
| epoch                          | 233        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4839.0654  |
| evaluation/return-max          | 4897.561   |
| evaluation/return-min          | 4744.5186  |
| evaluation/return-std          | 48.10255   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46084      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4839.0654  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 200.62408  |
| Q-std                          | 116.79522  |
| Q_loss                         | 95.66228   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 233        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000335   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000677   |
| times/evaluation_paths         | 33.8       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 234000     |
| train-steps                    | 234000     |
| training/Q/q1_loss             | 92.35453   |
| training/sac_pi/alpha          | 0.16794379 |
| training/sac_pi/alpha_loss     | 0.09812817 |
| training/sac_pi/logp_pi        | 4.6230516  |
| training/sac_pi/pi_entropy     | 3.3810182  |
| training/sac_pi/pi_global_norm | 1.3323352  |
| training/sac_pi/policy_loss    | -217.8174  |
| training/sac_pi/std            | 0.49140263 |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 209.75879  |
| training/sac_Q/q2              | 207.83809  |
| training/sac_Q/q2_loss         | 91.50627   |
| training/sac_Q/q_global_norm   | 189.45844  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16883373  |
| epoch                          | 234         |
| evaluation/episode-length-avg  | 481         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 407         |
| evaluation/episode-length-std  | 173         |
| evaluation/return-average      | 1709.4675   |
| evaluation/return-max          | 4650.837    |
| evaluation/return-min          | 1355.4167   |
| evaluation/return-std          | 980.91113   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46109       |
| perf/AverageLength             | 481         |
| perf/AverageReturn             | 1709.4675   |
| perf/NormalizedReturn          | 0.372       |
| Q-avg                          | 201.96667   |
| Q-std                          | 97.11407    |
| Q_loss                         | 91.04601    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 234         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000231    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000663    |
| times/evaluation_paths         | 16.6        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.0081      |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 235000      |
| train-steps                    | 235000      |
| training/Q/q1_loss             | 85.05478    |
| training/sac_pi/alpha          | 0.16885762  |
| training/sac_pi/alpha_loss     | -0.21317679 |
| training/sac_pi/logp_pi        | 4.2843885   |
| training/sac_pi/pi_entropy     | 3.496057    |
| training/sac_pi/pi_global_norm | 1.9265308   |
| training/sac_pi/policy_loss    | -216.10887  |
| training/sac_pi/std            | 0.50622684  |
| training/sac_pi/valid_num      | 4944.0      |
| training/sac_Q/q1              | 206.28873   |
| training/sac_Q/q2              | 204.77493   |
| training/sac_Q/q2_loss         | 84.2762     |
| training/sac_Q/q_global_norm   | 251.62714   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17189494  |
| epoch                          | 235         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4750.1353   |
| evaluation/return-max          | 4889.7085   |
| evaluation/return-min          | 4677.8887   |
| evaluation/return-std          | 63.67625    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46137       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4750.1353   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 203.45024   |
| Q-std                          | 97.29043    |
| Q_loss                         | 102.99421   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 235         |
| times/epoch_after_hook         | 1.6e-06     |
| times/epoch_before_hook        | 0.000151    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000538    |
| times/evaluation_paths         | 35.8        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 236000      |
| train-steps                    | 236000      |
| training/Q/q1_loss             | 95.64171    |
| training/sac_pi/alpha          | 0.17192492  |
| training/sac_pi/alpha_loss     | -0.59403396 |
| training/sac_pi/logp_pi        | 3.9139137   |
| training/sac_pi/pi_entropy     | 3.4938025   |
| training/sac_pi/pi_global_norm | 1.8593069   |
| training/sac_pi/policy_loss    | -203.038    |
| training/sac_pi/std            | 0.5002103   |
| training/sac_pi/valid_num      | 4952.0      |
| training/sac_Q/q1              | 195.483     |
| training/sac_Q/q2              | 194.27812   |
| training/sac_Q/q2_loss         | 94.56113    |
| training/sac_Q/q_global_norm   | 207.0079    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17082413 |
| epoch                          | 236        |
| evaluation/episode-length-avg  | 914        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 136        |
| evaluation/episode-length-std  | 259        |
| evaluation/return-average      | 4235.1284  |
| evaluation/return-max          | 4758.196   |
| evaluation/return-min          | 362.93762  |
| evaluation/return-std          | 1291.6954  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45972      |
| perf/AverageLength             | 914        |
| perf/AverageReturn             | 4235.1284  |
| perf/NormalizedReturn          | 0.922      |
| Q-avg                          | 193.01651  |
| Q-std                          | 121.13714  |
| Q_loss                         | 88.85461   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 236        |
| times/epoch_after_hook         | 2.07e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000627   |
| times/evaluation_paths         | 32.8       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 237000     |
| train-steps                    | 237000     |
| training/Q/q1_loss             | 99.94517   |
| training/sac_pi/alpha          | 0.17079914 |
| training/sac_pi/alpha_loss     | 0.81386226 |
| training/sac_pi/logp_pi        | 4.932205   |
| training/sac_pi/pi_entropy     | 3.442618   |
| training/sac_pi/pi_global_norm | 1.4793063  |
| training/sac_pi/policy_loss    | -206.30754 |
| training/sac_pi/std            | 0.49919397 |
| training/sac_pi/valid_num      | 4940.0     |
| training/sac_Q/q1              | 195.06863  |
| training/sac_Q/q2              | 194.13695  |
| training/sac_Q/q2_loss         | 99.70328   |
| training/sac_Q/q_global_norm   | 254.52197  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16703302 |
| epoch                          | 237        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4922.73    |
| evaluation/return-max          | 4958.8564  |
| evaluation/return-min          | 4874.6763  |
| evaluation/return-std          | 25.431145  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46054      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4922.73    |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 206.60173  |
| Q-std                          | 116.9103   |
| Q_loss                         | 108.71782  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 237        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000298   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000533   |
| times/evaluation_paths         | 33.2       |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 238000     |
| train-steps                    | 238000     |
| training/Q/q1_loss             | 99.44516   |
| training/sac_pi/alpha          | 0.16703886 |
| training/sac_pi/alpha_loss     | 0.14626513 |
| training/sac_pi/logp_pi        | 4.0575194  |
| training/sac_pi/pi_entropy     | 3.595532   |
| training/sac_pi/pi_global_norm | 1.4300482  |
| training/sac_pi/policy_loss    | -213.41678 |
| training/sac_pi/std            | 0.49346498 |
| training/sac_pi/valid_num      | 4987.0     |
| training/sac_Q/q1              | 207.7032   |
| training/sac_Q/q2              | 206.94492  |
| training/sac_Q/q2_loss         | 99.09818   |
| training/sac_Q/q_global_norm   | 201.13062  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16465779  |
| epoch                          | 238         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4766.344    |
| evaluation/return-max          | 4865.0845   |
| evaluation/return-min          | 4637.5293   |
| evaluation/return-std          | 62.211895   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46151       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4766.344    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 202.9       |
| Q-std                          | 115.387276  |
| Q_loss                         | 94.72609    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 238         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000604    |
| times/evaluation_paths         | 34.1        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 239000      |
| train-steps                    | 239000      |
| training/Q/q1_loss             | 101.8861    |
| training/sac_pi/alpha          | 0.1646783   |
| training/sac_pi/alpha_loss     | 0.105879955 |
| training/sac_pi/logp_pi        | 4.8599734   |
| training/sac_pi/pi_entropy     | 3.4089463   |
| training/sac_pi/pi_global_norm | 1.6062045   |
| training/sac_pi/policy_loss    | -217.26492  |
| training/sac_pi/std            | 0.52723783  |
| training/sac_pi/valid_num      | 4942.0      |
| training/sac_Q/q1              | 208.10605   |
| training/sac_Q/q2              | 207.7291    |
| training/sac_Q/q2_loss         | 101.06136   |
| training/sac_Q/q_global_norm   | 315.08356   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16943425  |
| epoch                          | 239         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4709.2964   |
| evaluation/return-max          | 4839.2207   |
| evaluation/return-min          | 4470.6016   |
| evaluation/return-std          | 130.77896   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46183       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4709.2964   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 196.61084   |
| Q-std                          | 118.936775  |
| Q_loss                         | 102.313354  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 239         |
| times/epoch_after_hook         | 2e-06       |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000563    |
| times/evaluation_paths         | 35.1        |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 240000      |
| train-steps                    | 240000      |
| training/Q/q1_loss             | 101.1562    |
| training/sac_pi/alpha          | 0.16943868  |
| training/sac_pi/alpha_loss     | -0.32679033 |
| training/sac_pi/logp_pi        | 4.2389417   |
| training/sac_pi/pi_entropy     | 3.6293807   |
| training/sac_pi/pi_global_norm | 1.5495417   |
| training/sac_pi/policy_loss    | -204.19698  |
| training/sac_pi/std            | 0.52719015  |
| training/sac_pi/valid_num      | 4960.0      |
| training/sac_Q/q1              | 195.02998   |
| training/sac_Q/q2              | 194.65723   |
| training/sac_Q/q2_loss         | 99.37738    |
| training/sac_Q/q_global_norm   | 230.34433   |
---------------------------------------------------------------------------------
[WARN] 240 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.17257401  |
| epoch                          | 240         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4720.956    |
| evaluation/return-max          | 4746.218    |
| evaluation/return-min          | 4661.9126   |
| evaluation/return-std          | 24.246439   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45998       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4720.956    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 204.83456   |
| Q-std                          | 116.09189   |
| Q_loss                         | 94.958755   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 240         |
| times/epoch_after_hook         | 1.99e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000599    |
| times/evaluation_paths         | 33.8        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 241000      |
| train-steps                    | 241000      |
| training/Q/q1_loss             | 86.42415    |
| training/sac_pi/alpha          | 0.17258582  |
| training/sac_pi/alpha_loss     | -0.17120484 |
| training/sac_pi/logp_pi        | 3.87518     |
| training/sac_pi/pi_entropy     | 3.5726337   |
| training/sac_pi/pi_global_norm | 1.5651444   |
| training/sac_pi/policy_loss    | -214.74977  |
| training/sac_pi/std            | 0.49804428  |
| training/sac_pi/valid_num      | 4997.0      |
| training/sac_Q/q1              | 208.13293   |
| training/sac_Q/q2              | 208.87357   |
| training/sac_Q/q2_loss         | 87.58016    |
| training/sac_Q/q_global_norm   | 308.28696   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16773684  |
| epoch                          | 241         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4797.967    |
| evaluation/return-max          | 4830.368    |
| evaluation/return-min          | 4759.6787   |
| evaluation/return-std          | 21.045662   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 82.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46078       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4797.967    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 202.46782   |
| Q-std                          | 97.35513    |
| Q_loss                         | 97.23654    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 241         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000266    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000578    |
| times/evaluation_paths         | 34.3        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00809     |
| times/train                    | 61.9        |
| timestep                       | 1000        |
| timesteps_total                | 242000      |
| train-steps                    | 242000      |
| training/Q/q1_loss             | 91.33378    |
| training/sac_pi/alpha          | 0.16775917  |
| training/sac_pi/alpha_loss     | -0.12518817 |
| training/sac_pi/logp_pi        | 4.4421897   |
| training/sac_pi/pi_entropy     | 3.5249877   |
| training/sac_pi/pi_global_norm | 1.670855    |
| training/sac_pi/policy_loss    | -215.18945  |
| training/sac_pi/std            | 0.52186376  |
| training/sac_pi/valid_num      | 4957.0      |
| training/sac_Q/q1              | 206.16501   |
| training/sac_Q/q2              | 205.10356   |
| training/sac_Q/q2_loss         | 91.95833    |
| training/sac_Q/q_global_norm   | 262.09763   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16771165  |
| epoch                          | 242         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4788.477    |
| evaluation/return-max          | 4833.8105   |
| evaluation/return-min          | 4737.824    |
| evaluation/return-std          | 26.084816   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46007       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4788.477    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 196.18674   |
| Q-std                          | 108.83494   |
| Q_loss                         | 106.72893   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 242         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000748    |
| times/evaluation_paths         | 34.1        |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 62          |
| timestep                       | 1000        |
| timesteps_total                | 243000      |
| train-steps                    | 243000      |
| training/Q/q1_loss             | 81.00557    |
| training/sac_pi/alpha          | 0.16772659  |
| training/sac_pi/alpha_loss     | -0.24311444 |
| training/sac_pi/logp_pi        | 3.643488    |
| training/sac_pi/pi_entropy     | 3.5367534   |
| training/sac_pi/pi_global_norm | 1.422261    |
| training/sac_pi/policy_loss    | -204.99985  |
| training/sac_pi/std            | 0.48690224  |
| training/sac_pi/valid_num      | 4959.0      |
| training/sac_Q/q1              | 198.1846    |
| training/sac_Q/q2              | 197.44217   |
| training/sac_Q/q2_loss         | 80.871      |
| training/sac_Q/q_global_norm   | 247.2286    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1705828   |
| epoch                          | 243         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4771.2725   |
| evaluation/return-max          | 4841.723    |
| evaluation/return-min          | 4587.3623   |
| evaluation/return-std          | 70.814186   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46135       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4771.2725   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 208.38399   |
| Q-std                          | 96.94748    |
| Q_loss                         | 101.21614   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 243         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.000149    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000555    |
| times/evaluation_paths         | 33.8        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 62.3        |
| timestep                       | 1000        |
| timesteps_total                | 244000      |
| train-steps                    | 244000      |
| training/Q/q1_loss             | 110.91871   |
| training/sac_pi/alpha          | 0.17058402  |
| training/sac_pi/alpha_loss     | -0.24695143 |
| training/sac_pi/logp_pi        | 3.8167336   |
| training/sac_pi/pi_entropy     | 3.6398125   |
| training/sac_pi/pi_global_norm | 1.6370114   |
| training/sac_pi/policy_loss    | -206.58789  |
| training/sac_pi/std            | 0.503007    |
| training/sac_pi/valid_num      | 4986.0      |
| training/sac_Q/q1              | 199.76733   |
| training/sac_Q/q2              | 198.35252   |
| training/sac_Q/q2_loss         | 111.61732   |
| training/sac_Q/q_global_norm   | 399.74072   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1700777   |
| epoch                          | 244         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4907.6655   |
| evaluation/return-max          | 5027.811    |
| evaluation/return-min          | 4836.538    |
| evaluation/return-std          | 58.87229    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46022       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4907.6655   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 217.48193   |
| Q-std                          | 92.64336    |
| Q_loss                         | 100.96928   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 244         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000136    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000604    |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 62.4        |
| timestep                       | 1000        |
| timesteps_total                | 245000      |
| train-steps                    | 245000      |
| training/Q/q1_loss             | 98.875694   |
| training/sac_pi/alpha          | 0.17008586  |
| training/sac_pi/alpha_loss     | -0.15811001 |
| training/sac_pi/logp_pi        | 4.6454573   |
| training/sac_pi/pi_entropy     | 3.7115645   |
| training/sac_pi/pi_global_norm | 1.46137     |
| training/sac_pi/policy_loss    | -205.84131  |
| training/sac_pi/std            | 0.54501086  |
| training/sac_pi/valid_num      | 4976.0      |
| training/sac_Q/q1              | 197.92763   |
| training/sac_Q/q2              | 196.87904   |
| training/sac_Q/q2_loss         | 98.62765    |
| training/sac_Q/q_global_norm   | 291.6533    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17166206  |
| epoch                          | 245         |
| evaluation/episode-length-avg  | 916         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 165         |
| evaluation/episode-length-std  | 250         |
| evaluation/return-average      | 4188.794    |
| evaluation/return-max          | 4781.9673   |
| evaluation/return-min          | 354.98132   |
| evaluation/return-std          | 1281.3838   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46116       |
| perf/AverageLength             | 916         |
| perf/AverageReturn             | 4188.794    |
| perf/NormalizedReturn          | 0.912       |
| Q-avg                          | 210.98694   |
| Q-std                          | 110.2082    |
| Q_loss                         | 108.66508   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 245         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000333    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000604    |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 246000      |
| train-steps                    | 246000      |
| training/Q/q1_loss             | 80.76719    |
| training/sac_pi/alpha          | 0.17167746  |
| training/sac_pi/alpha_loss     | 0.098675705 |
| training/sac_pi/logp_pi        | 3.8776195   |
| training/sac_pi/pi_entropy     | 3.5732124   |
| training/sac_pi/pi_global_norm | 1.5126935   |
| training/sac_pi/policy_loss    | -211.54634  |
| training/sac_pi/std            | 0.5020873   |
| training/sac_pi/valid_num      | 5017.0      |
| training/sac_Q/q1              | 203.64218   |
| training/sac_Q/q2              | 202.82857   |
| training/sac_Q/q2_loss         | 81.30795    |
| training/sac_Q/q_global_norm   | 288.9554    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17800985 |
| epoch                          | 246        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4811.4985  |
| evaluation/return-max          | 4865.994   |
| evaluation/return-min          | 4698.9536  |
| evaluation/return-std          | 53.68599   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46243      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4811.4985  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 206.68477  |
| Q-std                          | 96.943855  |
| Q_loss                         | 95.694786  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 246        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000601   |
| times/evaluation_paths         | 34.8       |
| times/timestep_after_hook      | 0.00417    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 247000     |
| train-steps                    | 247000     |
| training/Q/q1_loss             | 101.92943  |
| training/sac_pi/alpha          | 0.17797261 |
| training/sac_pi/alpha_loss     | 0.1340248  |
| training/sac_pi/logp_pi        | 4.4391236  |
| training/sac_pi/pi_entropy     | 3.518746   |
| training/sac_pi/pi_global_norm | 2.0215065  |
| training/sac_pi/policy_loss    | -207.86406 |
| training/sac_pi/std            | 0.49163333 |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 200.84612  |
| training/sac_Q/q2              | 199.84042  |
| training/sac_Q/q2_loss         | 102.47856  |
| training/sac_Q/q_global_norm   | 273.0239   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16880308 |
| epoch                          | 247        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4532.5083  |
| evaluation/return-max          | 4591.455   |
| evaluation/return-min          | 4466.337   |
| evaluation/return-std          | 35.975643  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46226      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4532.5083  |
| perf/NormalizedReturn          | 0.987      |
| Q-avg                          | 202.64453  |
| Q-std                          | 103.541336 |
| Q_loss                         | 100.53975  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 247        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000144   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000587   |
| times/evaluation_paths         | 34         |
| times/timestep_after_hook      | 0.00403    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 62.1       |
| timestep                       | 1000       |
| timesteps_total                | 248000     |
| train-steps                    | 248000     |
| training/Q/q1_loss             | 102.48538  |
| training/sac_pi/alpha          | 0.1688468  |
| training/sac_pi/alpha_loss     | 0.15420544 |
| training/sac_pi/logp_pi        | 4.5358496  |
| training/sac_pi/pi_entropy     | 3.4117026  |
| training/sac_pi/pi_global_norm | 1.6624897  |
| training/sac_pi/policy_loss    | -209.93497 |
| training/sac_pi/std            | 0.49792942 |
| training/sac_pi/valid_num      | 4997.0     |
| training/sac_Q/q1              | 205.05342  |
| training/sac_Q/q2              | 203.35275  |
| training/sac_Q/q2_loss         | 102.671074 |
| training/sac_Q/q_global_norm   | 281.7546   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16799574  |
| epoch                          | 248         |
| evaluation/episode-length-avg  | 329         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 154         |
| evaluation/episode-length-std  | 336         |
| evaluation/return-average      | 1387.3114   |
| evaluation/return-max          | 4954.5596   |
| evaluation/return-min          | 480.72076   |
| evaluation/return-std          | 1769.4489   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 83.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46099       |
| perf/AverageLength             | 329         |
| perf/AverageReturn             | 1387.3114   |
| perf/NormalizedReturn          | 0.302       |
| Q-avg                          | 195.05739   |
| Q-std                          | 105.622246  |
| Q_loss                         | 115.906075  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 248         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000478    |
| times/evaluation_paths         | 12.5        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.00809     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 249000      |
| train-steps                    | 249000      |
| training/Q/q1_loss             | 96.22689    |
| training/sac_pi/alpha          | 0.16795726  |
| training/sac_pi/alpha_loss     | 0.036349848 |
| training/sac_pi/logp_pi        | 4.3572183   |
| training/sac_pi/pi_entropy     | 3.5784626   |
| training/sac_pi/pi_global_norm | 1.3565519   |
| training/sac_pi/policy_loss    | -214.50562  |
| training/sac_pi/std            | 0.5197512   |
| training/sac_pi/valid_num      | 4966.0      |
| training/sac_Q/q1              | 206.69121   |
| training/sac_Q/q2              | 205.7808    |
| training/sac_Q/q2_loss         | 95.2125     |
| training/sac_Q/q_global_norm   | 318.7282    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17010853 |
| epoch                          | 249        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5024.661   |
| evaluation/return-max          | 5087.6187  |
| evaluation/return-min          | 4983.413   |
| evaluation/return-std          | 25.309397  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45937      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5024.661   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 200.5603   |
| Q-std                          | 103.27974  |
| Q_loss                         | 111.754684 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 249        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.000513   |
| times/epoch_rollout_model      | 521        |
| times/evaluation_metrics       | 0.00057    |
| times/evaluation_paths         | 32.7       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 62.6       |
| timestep                       | 1000       |
| timesteps_total                | 250000     |
| train-steps                    | 250000     |
| training/Q/q1_loss             | 85.85884   |
| training/sac_pi/alpha          | 0.17011192 |
| training/sac_pi/alpha_loss     | 0.2032768  |
| training/sac_pi/logp_pi        | 3.8886383  |
| training/sac_pi/pi_entropy     | 3.441763   |
| training/sac_pi/pi_global_norm | 1.4834371  |
| training/sac_pi/policy_loss    | -208.5316  |
| training/sac_pi/std            | 0.47382292 |
| training/sac_pi/valid_num      | 5018.0     |
| training/sac_Q/q1              | 203.20691  |
| training/sac_Q/q2              | 202.57703  |
| training/sac_Q/q2_loss         | 86.59669   |
| training/sac_Q/q_global_norm   | 251.5133   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17110096  |
| epoch                          | 250         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4831.284    |
| evaluation/return-max          | 4906.5996   |
| evaluation/return-min          | 4732.859    |
| evaluation/return-std          | 47.71044    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46104       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4831.284    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 201.47887   |
| Q-std                          | 94.78558    |
| Q_loss                         | 109.07885   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 250         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000715    |
| times/evaluation_paths         | 36.4        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 251000      |
| train-steps                    | 251000      |
| training/Q/q1_loss             | 85.54699    |
| training/sac_pi/alpha          | 0.17110834  |
| training/sac_pi/alpha_loss     | -0.08377553 |
| training/sac_pi/logp_pi        | 4.1268525   |
| training/sac_pi/pi_entropy     | 3.4847808   |
| training/sac_pi/pi_global_norm | 1.488127    |
| training/sac_pi/policy_loss    | -211.7843   |
| training/sac_pi/std            | 0.5051312   |
| training/sac_pi/valid_num      | 4993.0      |
| training/sac_Q/q1              | 204.7685    |
| training/sac_Q/q2              | 203.83115   |
| training/sac_Q/q2_loss         | 85.917816   |
| training/sac_Q/q_global_norm   | 342.88177   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1758377    |
| epoch                          | 251          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4851.5605    |
| evaluation/return-max          | 4889.6885    |
| evaluation/return-min          | 4797.255     |
| evaluation/return-std          | 32.051292    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.89         |
| model/origin_ret               | 83.4         |
| model/penalty_ret              | 81.4         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45959        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4851.5605    |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 195.32239    |
| Q-std                          | 112.397064   |
| Q_loss                         | 107.50261    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 251          |
| times/epoch_after_hook         | 3.33e-06     |
| times/epoch_before_hook        | 0.00017      |
| times/epoch_rollout_model      | 497          |
| times/evaluation_metrics       | 0.000537     |
| times/evaluation_paths         | 36           |
| times/timestep_after_hook      | 0.00402      |
| times/timestep_before_hook     | 0.00824      |
| times/train                    | 60.9         |
| timestep                       | 1000         |
| timesteps_total                | 252000       |
| train-steps                    | 252000       |
| training/Q/q1_loss             | 108.68769    |
| training/sac_pi/alpha          | 0.17584285   |
| training/sac_pi/alpha_loss     | -0.053164706 |
| training/sac_pi/logp_pi        | 4.466405     |
| training/sac_pi/pi_entropy     | 3.5231712    |
| training/sac_pi/pi_global_norm | 1.3349147    |
| training/sac_pi/policy_loss    | -210.75002   |
| training/sac_pi/std            | 0.50992686   |
| training/sac_pi/valid_num      | 4966.0       |
| training/sac_Q/q1              | 201.37851    |
| training/sac_Q/q2              | 200.88712    |
| training/sac_Q/q2_loss         | 108.88162    |
| training/sac_Q/q_global_norm   | 261.68628    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1742931  |
| epoch                          | 252        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4858.072   |
| evaluation/return-max          | 4921.99    |
| evaluation/return-min          | 4802.292   |
| evaluation/return-std          | 33.260067  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45982      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4858.072   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 205.60469  |
| Q-std                          | 94.698204  |
| Q_loss                         | 94.3688    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 252        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000587   |
| times/evaluation_paths         | 33.6       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 253000     |
| train-steps                    | 253000     |
| training/Q/q1_loss             | 84.175     |
| training/sac_pi/alpha          | 0.17425753 |
| training/sac_pi/alpha_loss     | 0.37306032 |
| training/sac_pi/logp_pi        | 3.897852   |
| training/sac_pi/pi_entropy     | 3.4379764  |
| training/sac_pi/pi_global_norm | 1.5066622  |
| training/sac_pi/policy_loss    | -214.58635 |
| training/sac_pi/std            | 0.47628695 |
| training/sac_pi/valid_num      | 4993.0     |
| training/sac_Q/q1              | 208.71973  |
| training/sac_Q/q2              | 209.18867  |
| training/sac_Q/q2_loss         | 83.404655  |
| training/sac_Q/q_global_norm   | 294.77945  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1718284  |
| epoch                          | 253        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4444.488   |
| evaluation/return-max          | 4542.838   |
| evaluation/return-min          | 4264.377   |
| evaluation/return-std          | 74.98081   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46057      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4444.488   |
| perf/NormalizedReturn          | 0.968      |
| Q-avg                          | 200.87912  |
| Q-std                          | 103.585785 |
| Q_loss                         | 94.52562   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 253        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000388   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000536   |
| times/evaluation_paths         | 33.7       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 62.2       |
| timestep                       | 1000       |
| timesteps_total                | 254000     |
| train-steps                    | 254000     |
| training/Q/q1_loss             | 87.53934   |
| training/sac_pi/alpha          | 0.17183208 |
| training/sac_pi/alpha_loss     | 0.16761017 |
| training/sac_pi/logp_pi        | 4.207835   |
| training/sac_pi/pi_entropy     | 3.5727265  |
| training/sac_pi/pi_global_norm | 1.6784356  |
| training/sac_pi/policy_loss    | -208.20726 |
| training/sac_pi/std            | 0.49569747 |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 202.11317  |
| training/sac_Q/q2              | 202.11655  |
| training/sac_Q/q2_loss         | 86.88367   |
| training/sac_Q/q_global_norm   | 235.07515  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17680834  |
| epoch                          | 254         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4800.587    |
| evaluation/return-max          | 4886.3086   |
| evaluation/return-min          | 4729.318    |
| evaluation/return-std          | 56.03722    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45821       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4800.587    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 193.93599   |
| Q-std                          | 120.30538   |
| Q_loss                         | 108.547714  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 254         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000141    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000609    |
| times/evaluation_paths         | 35.5        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 60.5        |
| timestep                       | 1000        |
| timesteps_total                | 255000      |
| train-steps                    | 255000      |
| training/Q/q1_loss             | 99.82229    |
| training/sac_pi/alpha          | 0.17684299  |
| training/sac_pi/alpha_loss     | 0.037017796 |
| training/sac_pi/logp_pi        | 4.9012766   |
| training/sac_pi/pi_entropy     | 3.8680282   |
| training/sac_pi/pi_global_norm | 1.6046724   |
| training/sac_pi/policy_loss    | -205.93887  |
| training/sac_pi/std            | 0.55919546  |
| training/sac_pi/valid_num      | 4894.0      |
| training/sac_Q/q1              | 195.79425   |
| training/sac_Q/q2              | 194.42291   |
| training/sac_Q/q2_loss         | 101.18117   |
| training/sac_Q/q_global_norm   | 304.47144   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.18095407 |
| epoch                          | 255        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4927.2803  |
| evaluation/return-max          | 4948.6523  |
| evaluation/return-min          | 4889.376   |
| evaluation/return-std          | 19.216103  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45952      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4927.2803  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 204.59798  |
| Q-std                          | 112.39875  |
| Q_loss                         | 102.91643  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 255        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000566   |
| times/evaluation_paths         | 35.2       |
| times/timestep_after_hook      | 0.00406    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 256000     |
| train-steps                    | 256000     |
| training/Q/q1_loss             | 89.04498   |
| training/sac_pi/alpha          | 0.18099077 |
| training/sac_pi/alpha_loss     | -0.4564312 |
| training/sac_pi/logp_pi        | 4.275855   |
| training/sac_pi/pi_entropy     | 3.8713276  |
| training/sac_pi/pi_global_norm | 1.5380118  |
| training/sac_pi/policy_loss    | -206.59753 |
| training/sac_pi/std            | 0.5595709  |
| training/sac_pi/valid_num      | 4937.0     |
| training/sac_Q/q1              | 194.78806  |
| training/sac_Q/q2              | 192.97177  |
| training/sac_Q/q2_loss         | 88.956154  |
| training/sac_Q/q_global_norm   | 231.4625   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17389683 |
| epoch                          | 256        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5116.667   |
| evaluation/return-max          | 5189.1484  |
| evaluation/return-min          | 5055.873   |
| evaluation/return-std          | 41.48992   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46050      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5116.667   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 207.54941  |
| Q-std                          | 93.27418   |
| Q_loss                         | 88.060936  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 256        |
| times/epoch_after_hook         | 2.09e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000563   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 257000     |
| train-steps                    | 257000     |
| training/Q/q1_loss             | 86.2741    |
| training/sac_pi/alpha          | 0.17389598 |
| training/sac_pi/alpha_loss     | 0.18614297 |
| training/sac_pi/logp_pi        | 4.6945596  |
| training/sac_pi/pi_entropy     | 3.6207614  |
| training/sac_pi/pi_global_norm | 1.5687596  |
| training/sac_pi/policy_loss    | -208.72923 |
| training/sac_pi/std            | 0.53131986 |
| training/sac_pi/valid_num      | 4939.0     |
| training/sac_Q/q1              | 199.92557  |
| training/sac_Q/q2              | 197.52051  |
| training/sac_Q/q2_loss         | 85.328     |
| training/sac_Q/q_global_norm   | 292.3748   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17873651 |
| epoch                          | 257        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4980.7495  |
| evaluation/return-max          | 5057.593   |
| evaluation/return-min          | 4906.0396  |
| evaluation/return-std          | 49.840385  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46002      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4980.7495  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 200.42986  |
| Q-std                          | 104.617485 |
| Q_loss                         | 102.805786 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 257        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000307   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.00064    |
| times/evaluation_paths         | 33.8       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 62.4       |
| timestep                       | 1000       |
| timesteps_total                | 258000     |
| train-steps                    | 258000     |
| training/Q/q1_loss             | 82.1415    |
| training/sac_pi/alpha          | 0.17874432 |
| training/sac_pi/alpha_loss     | 0.16544214 |
| training/sac_pi/logp_pi        | 4.7188406  |
| training/sac_pi/pi_entropy     | 3.6226945  |
| training/sac_pi/pi_global_norm | 1.5524051  |
| training/sac_pi/policy_loss    | -214.13191 |
| training/sac_pi/std            | 0.53747153 |
| training/sac_pi/valid_num      | 4940.0     |
| training/sac_Q/q1              | 205.52844  |
| training/sac_Q/q2              | 201.8923   |
| training/sac_Q/q2_loss         | 82.56354   |
| training/sac_Q/q_global_norm   | 318.05447  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17576693 |
| epoch                          | 258        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4731.276   |
| evaluation/return-max          | 4757.1685  |
| evaluation/return-min          | 4698.126   |
| evaluation/return-std          | 18.680866  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45958      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4731.276   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 209.87984  |
| Q-std                          | 97.24983   |
| Q_loss                         | 110.12723  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 258        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000643   |
| times/evaluation_paths         | 35.7       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00806    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 259000     |
| train-steps                    | 259000     |
| training/Q/q1_loss             | 97.35787   |
| training/sac_pi/alpha          | 0.17581062 |
| training/sac_pi/alpha_loss     | -0.3467989 |
| training/sac_pi/logp_pi        | 4.3588343  |
| training/sac_pi/pi_entropy     | 3.4729095  |
| training/sac_pi/pi_global_norm | 1.921046   |
| training/sac_pi/policy_loss    | -214.7662  |
| training/sac_pi/std            | 0.49777594 |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 206.91142  |
| training/sac_Q/q2              | 205.194    |
| training/sac_Q/q2_loss         | 97.78706   |
| training/sac_Q/q_global_norm   | 193.10591  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17440467 |
| epoch                          | 259        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4560.661   |
| evaluation/return-max          | 4623.5205  |
| evaluation/return-min          | 4497.0024  |
| evaluation/return-std          | 34.408604  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45960      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4560.661   |
| perf/NormalizedReturn          | 0.993      |
| Q-avg                          | 198.92032  |
| Q-std                          | 106.07763  |
| Q_loss                         | 103.503876 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 259        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000742   |
| times/evaluation_paths         | 33.6       |
| times/timestep_after_hook      | 0.00398    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 260000     |
| train-steps                    | 260000     |
| training/Q/q1_loss             | 91.62106   |
| training/sac_pi/alpha          | 0.17440502 |
| training/sac_pi/alpha_loss     | 0.14520529 |
| training/sac_pi/logp_pi        | 4.7397075  |
| training/sac_pi/pi_entropy     | 3.5942597  |
| training/sac_pi/pi_global_norm | 1.5784127  |
| training/sac_pi/policy_loss    | -204.2424  |
| training/sac_pi/std            | 0.52395815 |
| training/sac_pi/valid_num      | 4906.0     |
| training/sac_Q/q1              | 193.49005  |
| training/sac_Q/q2              | 191.27171  |
| training/sac_Q/q2_loss         | 90.376945  |
| training/sac_Q/q_global_norm   | 195.97672  |
--------------------------------------------------------------------------------
[WARN] 260 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.17647372 |
| epoch                          | 260        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4826.7314  |
| evaluation/return-max          | 4871.35    |
| evaluation/return-min          | 4782.9014  |
| evaluation/return-std          | 27.012321  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45928      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4826.7314  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 193.56787  |
| Q-std                          | 120.55849  |
| Q_loss                         | 106.068665 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 260        |
| times/epoch_after_hook         | 2e-06      |
| times/epoch_before_hook        | 0.000346   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000647   |
| times/evaluation_paths         | 35.5       |
| times/timestep_after_hook      | 0.00398    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 261000     |
| train-steps                    | 261000     |
| training/Q/q1_loss             | 113.208015 |
| training/sac_pi/alpha          | 0.17643768 |
| training/sac_pi/alpha_loss     | 0.1676171  |
| training/sac_pi/logp_pi        | 4.6252074  |
| training/sac_pi/pi_entropy     | 3.724847   |
| training/sac_pi/pi_global_norm | 1.7891077  |
| training/sac_pi/policy_loss    | -201.0701  |
| training/sac_pi/std            | 0.5339425  |
| training/sac_pi/valid_num      | 4933.0     |
| training/sac_Q/q1              | 190.745    |
| training/sac_Q/q2              | 188.65051  |
| training/sac_Q/q2_loss         | 112.17037  |
| training/sac_Q/q_global_norm   | 334.9174   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17511946  |
| epoch                          | 261         |
| evaluation/episode-length-avg  | 727         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 420         |
| evaluation/episode-length-std  | 235         |
| evaluation/return-average      | 3415.5312   |
| evaluation/return-max          | 4918.9746   |
| evaluation/return-min          | 1798.5211   |
| evaluation/return-std          | 1222.7808   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45939       |
| perf/AverageLength             | 727         |
| perf/AverageReturn             | 3415.5312   |
| perf/NormalizedReturn          | 0.744       |
| Q-avg                          | 195.02231   |
| Q-std                          | 138.93906   |
| Q_loss                         | 115.741714  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 261         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.00026     |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000685    |
| times/evaluation_paths         | 25.3        |
| times/timestep_after_hook      | 0.00385     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 60.1        |
| timestep                       | 1000        |
| timesteps_total                | 262000      |
| train-steps                    | 262000      |
| training/Q/q1_loss             | 97.14087    |
| training/sac_pi/alpha          | 0.17516793  |
| training/sac_pi/alpha_loss     | -0.33232826 |
| training/sac_pi/logp_pi        | 3.5392852   |
| training/sac_pi/pi_entropy     | 3.4999108   |
| training/sac_pi/pi_global_norm | 2.113379    |
| training/sac_pi/policy_loss    | -211.78835  |
| training/sac_pi/std            | 0.47906834  |
| training/sac_pi/valid_num      | 5007.0      |
| training/sac_Q/q1              | 206.26433   |
| training/sac_Q/q2              | 204.92924   |
| training/sac_Q/q2_loss         | 96.80416    |
| training/sac_Q/q_global_norm   | 247.46906   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1766991   |
| epoch                          | 262         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4867.236    |
| evaluation/return-max          | 4920.737    |
| evaluation/return-min          | 4818.596    |
| evaluation/return-std          | 37.435272   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46025       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4867.236    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 206.30884   |
| Q-std                          | 102.434685  |
| Q_loss                         | 105.21032   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 262         |
| times/epoch_after_hook         | 2.03e-06    |
| times/epoch_before_hook        | 0.000152    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000786    |
| times/evaluation_paths         | 35.4        |
| times/timestep_after_hook      | 0.00423     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 62.3        |
| timestep                       | 1000        |
| timesteps_total                | 263000      |
| train-steps                    | 263000      |
| training/Q/q1_loss             | 106.207924  |
| training/sac_pi/alpha          | 0.17669402  |
| training/sac_pi/alpha_loss     | 0.007021247 |
| training/sac_pi/logp_pi        | 3.726099    |
| training/sac_pi/pi_entropy     | 3.5362535   |
| training/sac_pi/pi_global_norm | 2.4499602   |
| training/sac_pi/policy_loss    | -209.6016   |
| training/sac_pi/std            | 0.48433283  |
| training/sac_pi/valid_num      | 5019.0      |
| training/sac_Q/q1              | 204.81685   |
| training/sac_Q/q2              | 204.28531   |
| training/sac_Q/q2_loss         | 105.86797   |
| training/sac_Q/q_global_norm   | 275.6516    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17306493 |
| epoch                          | 263        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4876.175   |
| evaluation/return-max          | 4935.8027  |
| evaluation/return-min          | 4792.7783  |
| evaluation/return-std          | 44.774807  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46006      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4876.175   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 198.74266  |
| Q-std                          | 105.563126 |
| Q_loss                         | 101.784386 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 263        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000729   |
| times/evaluation_paths         | 38.1       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 264000     |
| train-steps                    | 264000     |
| training/Q/q1_loss             | 100.29164  |
| training/sac_pi/alpha          | 0.17306149 |
| training/sac_pi/alpha_loss     | 0.19128223 |
| training/sac_pi/logp_pi        | 5.235362   |
| training/sac_pi/pi_entropy     | 3.6735244  |
| training/sac_pi/pi_global_norm | 1.9760643  |
| training/sac_pi/policy_loss    | -211.96016 |
| training/sac_pi/std            | 0.5608771  |
| training/sac_pi/valid_num      | 4923.0     |
| training/sac_Q/q1              | 199.02211  |
| training/sac_Q/q2              | 196.35507  |
| training/sac_Q/q2_loss         | 99.554184  |
| training/sac_Q/q_global_norm   | 302.494    |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17394514 |
| epoch                          | 264        |
| evaluation/episode-length-avg  | 800        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 328        |
| evaluation/episode-length-std  | 306        |
| evaluation/return-average      | 3816.1738  |
| evaluation/return-max          | 5108.956   |
| evaluation/return-min          | 1123.1477  |
| evaluation/return-std          | 1755.491   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45957      |
| perf/AverageLength             | 800        |
| perf/AverageReturn             | 3816.1738  |
| perf/NormalizedReturn          | 0.831      |
| Q-avg                          | 198.38864  |
| Q-std                          | 105.02339  |
| Q_loss                         | 95.22318   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 264        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000144   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000628   |
| times/evaluation_paths         | 26.8       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 62.8       |
| timestep                       | 1000       |
| timesteps_total                | 265000     |
| train-steps                    | 265000     |
| training/Q/q1_loss             | 88.65145   |
| training/sac_pi/alpha          | 0.1739163  |
| training/sac_pi/alpha_loss     | 0.21629691 |
| training/sac_pi/logp_pi        | 3.792134   |
| training/sac_pi/pi_entropy     | 3.5555382  |
| training/sac_pi/pi_global_norm | 2.0325313  |
| training/sac_pi/policy_loss    | -213.1784  |
| training/sac_pi/std            | 0.4867192  |
| training/sac_pi/valid_num      | 4992.0     |
| training/sac_Q/q1              | 206.53967  |
| training/sac_Q/q2              | 206.12683  |
| training/sac_Q/q2_loss         | 88.77348   |
| training/sac_Q/q_global_norm   | 218.77156  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17784621  |
| epoch                          | 265         |
| evaluation/episode-length-avg  | 797         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 323         |
| evaluation/episode-length-std  | 310         |
| evaluation/return-average      | 3653.6628   |
| evaluation/return-max          | 4797.5806   |
| evaluation/return-min          | 1178.2854   |
| evaluation/return-std          | 1603.5519   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46094       |
| perf/AverageLength             | 797         |
| perf/AverageReturn             | 3653.6628   |
| perf/NormalizedReturn          | 0.796       |
| Q-avg                          | 205.64294   |
| Q-std                          | 102.520096  |
| Q_loss                         | 87.09659    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 265         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000256    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000603    |
| times/evaluation_paths         | 27.1        |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 60.5        |
| timestep                       | 1000        |
| timesteps_total                | 266000      |
| train-steps                    | 266000      |
| training/Q/q1_loss             | 110.813446  |
| training/sac_pi/alpha          | 0.17783903  |
| training/sac_pi/alpha_loss     | -0.10952878 |
| training/sac_pi/logp_pi        | 3.7637875   |
| training/sac_pi/pi_entropy     | 3.3370247   |
| training/sac_pi/pi_global_norm | 1.6278428   |
| training/sac_pi/policy_loss    | -212.75421  |
| training/sac_pi/std            | 0.46153292  |
| training/sac_pi/valid_num      | 5039.0      |
| training/sac_Q/q1              | 207.08572   |
| training/sac_Q/q2              | 206.4006    |
| training/sac_Q/q2_loss         | 110.2138    |
| training/sac_Q/q_global_norm   | 213.29456   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.18261836 |
| epoch                          | 266        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4983.096   |
| evaluation/return-max          | 5021.981   |
| evaluation/return-min          | 4951.1387  |
| evaluation/return-std          | 23.507782  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46149      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4983.096   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 197.33093  |
| Q-std                          | 104.658195 |
| Q_loss                         | 84.3382    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 266        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000575   |
| times/evaluation_paths         | 34.7       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 62.7       |
| timestep                       | 1000       |
| timesteps_total                | 267000     |
| train-steps                    | 267000     |
| training/Q/q1_loss             | 81.040306  |
| training/sac_pi/alpha          | 0.18261836 |
| training/sac_pi/alpha_loss     | 0.01928105 |
| training/sac_pi/logp_pi        | 3.6988435  |
| training/sac_pi/pi_entropy     | 3.5180733  |
| training/sac_pi/pi_global_norm | 1.4219395  |
| training/sac_pi/policy_loss    | -218.80907 |
| training/sac_pi/std            | 0.47747615 |
| training/sac_pi/valid_num      | 5026.0     |
| training/sac_Q/q1              | 214.22775  |
| training/sac_Q/q2              | 213.5053   |
| training/sac_Q/q2_loss         | 80.533585  |
| training/sac_Q/q_global_norm   | 244.78697  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1774837   |
| epoch                          | 267         |
| evaluation/episode-length-avg  | 912         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 124         |
| evaluation/episode-length-std  | 263         |
| evaluation/return-average      | 4361.868    |
| evaluation/return-max          | 4861.381    |
| evaluation/return-min          | 290.19333   |
| evaluation/return-std          | 1357.6143   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46150       |
| perf/AverageLength             | 912         |
| perf/AverageReturn             | 4361.868    |
| perf/NormalizedReturn          | 0.95        |
| Q-avg                          | 214.39877   |
| Q-std                          | 102.26944   |
| Q_loss                         | 84.4384     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 267         |
| times/epoch_after_hook         | 2.03e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000799    |
| times/evaluation_paths         | 32.2        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 60.2        |
| timestep                       | 1000        |
| timesteps_total                | 268000      |
| train-steps                    | 268000      |
| training/Q/q1_loss             | 95.27895    |
| training/sac_pi/alpha          | 0.17747188  |
| training/sac_pi/alpha_loss     | 0.046866126 |
| training/sac_pi/logp_pi        | 4.5287857   |
| training/sac_pi/pi_entropy     | 3.3094108   |
| training/sac_pi/pi_global_norm | 1.5230983   |
| training/sac_pi/policy_loss    | -210.02289  |
| training/sac_pi/std            | 0.47116414  |
| training/sac_pi/valid_num      | 4937.0      |
| training/sac_Q/q1              | 201.40793   |
| training/sac_Q/q2              | 201.18054   |
| training/sac_Q/q2_loss         | 95.48798    |
| training/sac_Q/q_global_norm   | 225.37975   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17867023 |
| epoch                          | 268        |
| evaluation/episode-length-avg  | 635        |
| evaluation/episode-length-max  | 987        |
| evaluation/episode-length-min  | 520        |
| evaluation/episode-length-std  | 124        |
| evaluation/return-average      | 2996.0637  |
| evaluation/return-max          | 4904.934   |
| evaluation/return-min          | 2401.3828  |
| evaluation/return-std          | 670.4098   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45980      |
| perf/AverageLength             | 635        |
| perf/AverageReturn             | 2996.0637  |
| perf/NormalizedReturn          | 0.652      |
| Q-avg                          | 207.58012  |
| Q-std                          | 103.518    |
| Q_loss                         | 100.68183  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 268        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000143   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000595   |
| times/evaluation_paths         | 22.7       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 61.5       |
| timestep                       | 1000       |
| timesteps_total                | 269000     |
| train-steps                    | 269000     |
| training/Q/q1_loss             | 110.58224  |
| training/sac_pi/alpha          | 0.17866938 |
| training/sac_pi/alpha_loss     | 0.20966436 |
| training/sac_pi/logp_pi        | 4.08105    |
| training/sac_pi/pi_entropy     | 3.651366   |
| training/sac_pi/pi_global_norm | 1.6935688  |
| training/sac_pi/policy_loss    | -205.42831 |
| training/sac_pi/std            | 0.49954045 |
| training/sac_pi/valid_num      | 5038.0     |
| training/sac_Q/q1              | 199.65532  |
| training/sac_Q/q2              | 197.60852  |
| training/sac_Q/q2_loss         | 111.26946  |
| training/sac_Q/q_global_norm   | 384.08978  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16823587 |
| epoch                          | 269        |
| evaluation/episode-length-avg  | 996        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 961        |
| evaluation/episode-length-std  | 11.7       |
| evaluation/return-average      | 4607.7607  |
| evaluation/return-max          | 4796.567   |
| evaluation/return-min          | 4423.2856  |
| evaluation/return-std          | 119.56508  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45871      |
| perf/AverageLength             | 996        |
| perf/AverageReturn             | 4607.7607  |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 202.83316  |
| Q-std                          | 97.09688   |
| Q_loss                         | 102.11166  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 269        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.00039    |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000634   |
| times/evaluation_paths         | 35.4       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 270000     |
| train-steps                    | 270000     |
| training/Q/q1_loss             | 103.02244  |
| training/sac_pi/alpha          | 0.16821899 |
| training/sac_pi/alpha_loss     | 0.21428886 |
| training/sac_pi/logp_pi        | 4.0047083  |
| training/sac_pi/pi_entropy     | 3.3899376  |
| training/sac_pi/pi_global_norm | 1.6061959  |
| training/sac_pi/policy_loss    | -205.48508 |
| training/sac_pi/std            | 0.47737712 |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 198.4005   |
| training/sac_Q/q2              | 197.48828  |
| training/sac_Q/q2_loss         | 102.33617  |
| training/sac_Q/q_global_norm   | 262.5862   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17176732 |
| epoch                          | 270        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4598.2256  |
| evaluation/return-max          | 4655.415   |
| evaluation/return-min          | 4544.872   |
| evaluation/return-std          | 35.84956   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46175      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4598.2256  |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 197.50003  |
| Q-std                          | 95.83417   |
| Q_loss                         | 107.59977  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 270        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000267   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000824   |
| times/evaluation_paths         | 33.7       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 62.5       |
| timestep                       | 1000       |
| timesteps_total                | 271000     |
| train-steps                    | 271000     |
| training/Q/q1_loss             | 111.101974 |
| training/sac_pi/alpha          | 0.17179397 |
| training/sac_pi/alpha_loss     | 0.18903758 |
| training/sac_pi/logp_pi        | 4.6534643  |
| training/sac_pi/pi_entropy     | 3.3505752  |
| training/sac_pi/pi_global_norm | 1.3762699  |
| training/sac_pi/policy_loss    | -212.18831 |
| training/sac_pi/std            | 0.489504   |
| training/sac_pi/valid_num      | 4948.0     |
| training/sac_Q/q1              | 204.24261  |
| training/sac_Q/q2              | 202.16162  |
| training/sac_Q/q2_loss         | 110.610344 |
| training/sac_Q/q_global_norm   | 212.73543  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17359176  |
| epoch                          | 271         |
| evaluation/episode-length-avg  | 945         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 454         |
| evaluation/episode-length-std  | 164         |
| evaluation/return-average      | 4089.6562   |
| evaluation/return-max          | 4620.7744   |
| evaluation/return-min          | 1565.3732   |
| evaluation/return-std          | 852.4022    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 82.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46251       |
| perf/AverageLength             | 945         |
| perf/AverageReturn             | 4089.6562   |
| perf/NormalizedReturn          | 0.891       |
| Q-avg                          | 209.54692   |
| Q-std                          | 112.46351   |
| Q_loss                         | 95.096565   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 271         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000173    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.00068     |
| times/evaluation_paths         | 32.8        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 272000      |
| train-steps                    | 272000      |
| training/Q/q1_loss             | 91.93995    |
| training/sac_pi/alpha          | 0.17359924  |
| training/sac_pi/alpha_loss     | 0.113644175 |
| training/sac_pi/logp_pi        | 4.7253613   |
| training/sac_pi/pi_entropy     | 3.5209122   |
| training/sac_pi/pi_global_norm | 1.8123158   |
| training/sac_pi/policy_loss    | -207.545    |
| training/sac_pi/std            | 0.5098358   |
| training/sac_pi/valid_num      | 4927.0      |
| training/sac_Q/q1              | 195.00119   |
| training/sac_Q/q2              | 194.45898   |
| training/sac_Q/q2_loss         | 91.57887    |
| training/sac_Q/q_global_norm   | 229.00441   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17646676 |
| epoch                          | 272        |
| evaluation/episode-length-avg  | 746        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 153        |
| evaluation/episode-length-std  | 387        |
| evaluation/return-average      | 3363.105   |
| evaluation/return-max          | 4797.1597  |
| evaluation/return-min          | 323.1015   |
| evaluation/return-std          | 1989.9717  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 83.5       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46216      |
| perf/AverageLength             | 746        |
| perf/AverageReturn             | 3363.105   |
| perf/NormalizedReturn          | 0.732      |
| Q-avg                          | 191.51486  |
| Q-std                          | 126.41033  |
| Q_loss                         | 91.34111   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 272        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000682   |
| times/evaluation_paths         | 26         |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 273000     |
| train-steps                    | 273000     |
| training/Q/q1_loss             | 100.01287  |
| training/sac_pi/alpha          | 0.17644371 |
| training/sac_pi/alpha_loss     | 0.05011819 |
| training/sac_pi/logp_pi        | 3.7249367  |
| training/sac_pi/pi_entropy     | 3.4673836  |
| training/sac_pi/pi_global_norm | 1.509112   |
| training/sac_pi/policy_loss    | -215.47726 |
| training/sac_pi/std            | 0.46772823 |
| training/sac_pi/valid_num      | 5020.0     |
| training/sac_Q/q1              | 210.27966  |
| training/sac_Q/q2              | 210.04489  |
| training/sac_Q/q2_loss         | 99.61279   |
| training/sac_Q/q_global_norm   | 227.22676  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17655797 |
| epoch                          | 273        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4691.349   |
| evaluation/return-max          | 4719.6836  |
| evaluation/return-min          | 4668.621   |
| evaluation/return-std          | 17.163275  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46133      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4691.349   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 203.24655  |
| Q-std                          | 97.03511   |
| Q_loss                         | 102.32221  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 273        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000256   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000613   |
| times/evaluation_paths         | 33.6       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00794    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 274000     |
| train-steps                    | 274000     |
| training/Q/q1_loss             | 112.563805 |
| training/sac_pi/alpha          | 0.17649548 |
| training/sac_pi/alpha_loss     | 0.0361853  |
| training/sac_pi/logp_pi        | 4.642776   |
| training/sac_pi/pi_entropy     | 3.4917817  |
| training/sac_pi/pi_global_norm | 1.6004195  |
| training/sac_pi/policy_loss    | -207.21184 |
| training/sac_pi/std            | 0.49771434 |
| training/sac_pi/valid_num      | 4924.0     |
| training/sac_Q/q1              | 198.45468  |
| training/sac_Q/q2              | 198.56488  |
| training/sac_Q/q2_loss         | 112.38097  |
| training/sac_Q/q_global_norm   | 363.44507  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.18226226   |
| epoch                          | 274          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4807.067     |
| evaluation/return-max          | 4851.67      |
| evaluation/return-min          | 4762.3604    |
| evaluation/return-std          | 26.524286    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.98         |
| model/origin_ret               | 86.4         |
| model/penalty_ret              | 82.2         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46070        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4807.067     |
| perf/NormalizedReturn          | 1.05         |
| Q-avg                          | 199.56267    |
| Q-std                          | 106.238945   |
| Q_loss                         | 100.83312    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 274          |
| times/epoch_after_hook         | 1.86e-06     |
| times/epoch_before_hook        | 0.000132     |
| times/epoch_rollout_model      | 505          |
| times/evaluation_metrics       | 0.000639     |
| times/evaluation_paths         | 34.3         |
| times/timestep_after_hook      | 0.00391      |
| times/timestep_before_hook     | 0.00795      |
| times/train                    | 60.4         |
| timestep                       | 1000         |
| timesteps_total                | 275000       |
| train-steps                    | 275000       |
| training/Q/q1_loss             | 79.2337      |
| training/sac_pi/alpha          | 0.1822946    |
| training/sac_pi/alpha_loss     | -0.109267004 |
| training/sac_pi/logp_pi        | 3.7532897    |
| training/sac_pi/pi_entropy     | 3.6658604    |
| training/sac_pi/pi_global_norm | 1.9579616    |
| training/sac_pi/policy_loss    | -214.79294   |
| training/sac_pi/std            | 0.4871032    |
| training/sac_pi/valid_num      | 4986.0       |
| training/sac_Q/q1              | 209.56197    |
| training/sac_Q/q2              | 208.79428    |
| training/sac_Q/q2_loss         | 78.79223     |
| training/sac_Q/q_global_norm   | 234.28044    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17326643  |
| epoch                          | 275         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4990.547    |
| evaluation/return-max          | 5056.967    |
| evaluation/return-min          | 4850.205    |
| evaluation/return-std          | 54.369858   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46432       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4990.547    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 203.03108   |
| Q-std                          | 121.89205   |
| Q_loss                         | 100.78262   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 275         |
| times/epoch_after_hook         | 2.14e-06    |
| times/epoch_before_hook        | 0.000202    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000746    |
| times/evaluation_paths         | 34.9        |
| times/timestep_after_hook      | 0.00397     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 276000      |
| train-steps                    | 276000      |
| training/Q/q1_loss             | 85.40818    |
| training/sac_pi/alpha          | 0.17326762  |
| training/sac_pi/alpha_loss     | 0.021330014 |
| training/sac_pi/logp_pi        | 4.1643953   |
| training/sac_pi/pi_entropy     | 3.4527187   |
| training/sac_pi/pi_global_norm | 1.5874108   |
| training/sac_pi/policy_loss    | -205.97624  |
| training/sac_pi/std            | 0.47431818  |
| training/sac_pi/valid_num      | 4992.0      |
| training/sac_Q/q1              | 200.47586   |
| training/sac_Q/q2              | 199.17146   |
| training/sac_Q/q2_loss         | 85.127205   |
| training/sac_Q/q_global_norm   | 250.7209    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17058048 |
| epoch                          | 276        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5106.5806  |
| evaluation/return-max          | 5138.74    |
| evaluation/return-min          | 5055.6616  |
| evaluation/return-std          | 23.893066  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46189      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5106.5806  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 200.98317  |
| Q-std                          | 121.86039  |
| Q_loss                         | 97.273766  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 276        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000186   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000558   |
| times/evaluation_paths         | 35.8       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 277000     |
| train-steps                    | 277000     |
| training/Q/q1_loss             | 101.59203  |
| training/sac_pi/alpha          | 0.17053014 |
| training/sac_pi/alpha_loss     | 0.48240337 |
| training/sac_pi/logp_pi        | 4.0892777  |
| training/sac_pi/pi_entropy     | 3.5024133  |
| training/sac_pi/pi_global_norm | 1.5140023  |
| training/sac_pi/policy_loss    | -208.55118 |
| training/sac_pi/std            | 0.47294846 |
| training/sac_pi/valid_num      | 4996.0     |
| training/sac_Q/q1              | 203.74588  |
| training/sac_Q/q2              | 202.41272  |
| training/sac_Q/q2_loss         | 100.23375  |
| training/sac_Q/q_global_norm   | 193.27881  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16607387 |
| epoch                          | 277        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4822.406   |
| evaluation/return-max          | 5014.4316  |
| evaluation/return-min          | 4675.255   |
| evaluation/return-std          | 109.62266  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46115      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4822.406   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 199.80937  |
| Q-std                          | 108.97167  |
| Q_loss                         | 89.898315  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 277        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000426   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000633   |
| times/evaluation_paths         | 35.6       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00804    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 278000     |
| train-steps                    | 278000     |
| training/Q/q1_loss             | 98.13191   |
| training/sac_pi/alpha          | 0.16605699 |
| training/sac_pi/alpha_loss     | 0.52059335 |
| training/sac_pi/logp_pi        | 4.0953803  |
| training/sac_pi/pi_entropy     | 3.3668523  |
| training/sac_pi/pi_global_norm | 2.2402363  |
| training/sac_pi/policy_loss    | -212.98584 |
| training/sac_pi/std            | 0.46433988 |
| training/sac_pi/valid_num      | 5005.0     |
| training/sac_Q/q1              | 206.58508  |
| training/sac_Q/q2              | 204.65076  |
| training/sac_Q/q2_loss         | 98.633194  |
| training/sac_Q/q_global_norm   | 184.81018  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16949518 |
| epoch                          | 278        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4591.96    |
| evaluation/return-max          | 4766.661   |
| evaluation/return-min          | 4358.0796  |
| evaluation/return-std          | 111.76088  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46221      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4591.96    |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 195.29286  |
| Q-std                          | 109.87947  |
| Q_loss                         | 112.7307   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 278        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000162   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000595   |
| times/evaluation_paths         | 34.3       |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 60.2       |
| timestep                       | 1000       |
| timesteps_total                | 279000     |
| train-steps                    | 279000     |
| training/Q/q1_loss             | 82.87876   |
| training/sac_pi/alpha          | 0.16947551 |
| training/sac_pi/alpha_loss     | -0.2082334 |
| training/sac_pi/logp_pi        | 4.6247454  |
| training/sac_pi/pi_entropy     | 3.398394   |
| training/sac_pi/pi_global_norm | 1.8850611  |
| training/sac_pi/policy_loss    | -223.32416 |
| training/sac_pi/std            | 0.5055334  |
| training/sac_pi/valid_num      | 4973.0     |
| training/sac_Q/q1              | 214.82596  |
| training/sac_Q/q2              | 212.8792   |
| training/sac_Q/q2_loss         | 83.7699    |
| training/sac_Q/q_global_norm   | 241.91801  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17370939  |
| epoch                          | 279         |
| evaluation/episode-length-avg  | 844         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 646         |
| evaluation/episode-length-std  | 157         |
| evaluation/return-average      | 4065.9172   |
| evaluation/return-max          | 4978.8486   |
| evaluation/return-min          | 3000.875    |
| evaluation/return-std          | 885.91833   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46170       |
| perf/AverageLength             | 844         |
| perf/AverageReturn             | 4065.9172   |
| perf/NormalizedReturn          | 0.885       |
| Q-avg                          | 200.82303   |
| Q-std                          | 118.66534   |
| Q_loss                         | 104.35519   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 279         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000612    |
| times/evaluation_paths         | 33.2        |
| times/timestep_after_hook      | 0.0042      |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 62.9        |
| timestep                       | 1000        |
| timesteps_total                | 280000      |
| train-steps                    | 280000      |
| training/Q/q1_loss             | 88.04287    |
| training/sac_pi/alpha          | 0.17367187  |
| training/sac_pi/alpha_loss     | -0.14891472 |
| training/sac_pi/logp_pi        | 4.080213    |
| training/sac_pi/pi_entropy     | 3.7079082   |
| training/sac_pi/pi_global_norm | 1.5857211   |
| training/sac_pi/policy_loss    | -209.28908  |
| training/sac_pi/std            | 0.52086574  |
| training/sac_pi/valid_num      | 4969.0      |
| training/sac_Q/q1              | 201.7637    |
| training/sac_Q/q2              | 199.77222   |
| training/sac_Q/q2_loss         | 88.42862    |
| training/sac_Q/q_global_norm   | 286.11017   |
---------------------------------------------------------------------------------
[WARN] 280 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.17557676 |
| epoch                          | 280        |
| evaluation/episode-length-avg  | 831        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 154        |
| evaluation/episode-length-std  | 338        |
| evaluation/return-average      | 3938.7466  |
| evaluation/return-max          | 4918.5063  |
| evaluation/return-min          | 371.9668   |
| evaluation/return-std          | 1782.9188  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46101      |
| perf/AverageLength             | 831        |
| perf/AverageReturn             | 3938.7466  |
| perf/NormalizedReturn          | 0.858      |
| Q-avg                          | 214.38562  |
| Q-std                          | 95.7514    |
| Q_loss                         | 100.92143  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 280        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000596   |
| times/evaluation_paths         | 28.8       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 60         |
| timestep                       | 1000       |
| timesteps_total                | 281000     |
| train-steps                    | 281000     |
| training/Q/q1_loss             | 99.8366    |
| training/sac_pi/alpha          | 0.17553265 |
| training/sac_pi/alpha_loss     | 0.5139161  |
| training/sac_pi/logp_pi        | 4.7601013  |
| training/sac_pi/pi_entropy     | 3.6861293  |
| training/sac_pi/pi_global_norm | 1.3814151  |
| training/sac_pi/policy_loss    | -210.12872 |
| training/sac_pi/std            | 0.5130023  |
| training/sac_pi/valid_num      | 4906.0     |
| training/sac_Q/q1              | 200.53305  |
| training/sac_Q/q2              | 198.91457  |
| training/sac_Q/q2_loss         | 100.03171  |
| training/sac_Q/q_global_norm   | 293.16168  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17202802 |
| epoch                          | 281        |
| evaluation/episode-length-avg  | 912        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 125        |
| evaluation/episode-length-std  | 262        |
| evaluation/return-average      | 4416.0293  |
| evaluation/return-max          | 5021.9688  |
| evaluation/return-min          | 289.31845  |
| evaluation/return-std          | 1379.7012  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45950      |
| perf/AverageLength             | 912        |
| perf/AverageReturn             | 4416.0293  |
| perf/NormalizedReturn          | 0.962      |
| Q-avg                          | 199.67119  |
| Q-std                          | 103.28415  |
| Q_loss                         | 121.3335   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 281        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000309   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000523   |
| times/evaluation_paths         | 35.2       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00791    |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 282000     |
| train-steps                    | 282000     |
| training/Q/q1_loss             | 92.27307   |
| training/sac_pi/alpha          | 0.17203324 |
| training/sac_pi/alpha_loss     | 0.1161541  |
| training/sac_pi/logp_pi        | 4.7143598  |
| training/sac_pi/pi_entropy     | 3.529902   |
| training/sac_pi/pi_global_norm | 1.7737212  |
| training/sac_pi/policy_loss    | -215.06229 |
| training/sac_pi/std            | 0.51547176 |
| training/sac_pi/valid_num      | 4901.0     |
| training/sac_Q/q1              | 203.66151  |
| training/sac_Q/q2              | 200.72586  |
| training/sac_Q/q2_loss         | 91.7762    |
| training/sac_Q/q_global_norm   | 273.12112  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1756105  |
| epoch                          | 282        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4580.6646  |
| evaluation/return-max          | 4639.9375  |
| evaluation/return-min          | 4542.748   |
| evaluation/return-std          | 31.763847  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 83.5       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46221      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4580.6646  |
| perf/NormalizedReturn          | 0.997      |
| Q-avg                          | 195.48354  |
| Q-std                          | 102.69983  |
| Q_loss                         | 102.162025 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 282        |
| times/epoch_after_hook         | 3.3e-06    |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000648   |
| times/evaluation_paths         | 41.7       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 283000     |
| train-steps                    | 283000     |
| training/Q/q1_loss             | 110.40029  |
| training/sac_pi/alpha          | 0.17562939 |
| training/sac_pi/alpha_loss     | 0.5292098  |
| training/sac_pi/logp_pi        | 4.3018823  |
| training/sac_pi/pi_entropy     | 3.5964828  |
| training/sac_pi/pi_global_norm | 1.5917722  |
| training/sac_pi/policy_loss    | -206.09325 |
| training/sac_pi/std            | 0.49895197 |
| training/sac_pi/valid_num      | 4984.0     |
| training/sac_Q/q1              | 199.92514  |
| training/sac_Q/q2              | 198.48573  |
| training/sac_Q/q2_loss         | 110.18652  |
| training/sac_Q/q_global_norm   | 262.8047   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17481321  |
| epoch                          | 283         |
| evaluation/episode-length-avg  | 914         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 138         |
| evaluation/episode-length-std  | 259         |
| evaluation/return-average      | 4184.142    |
| evaluation/return-max          | 4641.8276   |
| evaluation/return-min          | 364.01816   |
| evaluation/return-std          | 1273.5231   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46045       |
| perf/AverageLength             | 914         |
| perf/AverageReturn             | 4184.142    |
| perf/NormalizedReturn          | 0.911       |
| Q-avg                          | 204.41663   |
| Q-std                          | 112.38083   |
| Q_loss                         | 164.77277   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 283         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000138    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000675    |
| times/evaluation_paths         | 40.7        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 63.3        |
| timestep                       | 1000        |
| timesteps_total                | 284000      |
| train-steps                    | 284000      |
| training/Q/q1_loss             | 79.35677    |
| training/sac_pi/alpha          | 0.17479488  |
| training/sac_pi/alpha_loss     | -0.24540356 |
| training/sac_pi/logp_pi        | 3.797573    |
| training/sac_pi/pi_entropy     | 3.475228    |
| training/sac_pi/pi_global_norm | 1.7266502   |
| training/sac_pi/policy_loss    | -219.73633  |
| training/sac_pi/std            | 0.48718992  |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 214.57564   |
| training/sac_Q/q2              | 213.56425   |
| training/sac_Q/q2_loss         | 80.51821    |
| training/sac_Q/q_global_norm   | 324.70096   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17492527  |
| epoch                          | 284         |
| evaluation/episode-length-avg  | 227         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 33          |
| evaluation/episode-length-std  | 387         |
| evaluation/return-average      | 948.5459    |
| evaluation/return-max          | 4715.4727   |
| evaluation/return-min          | 38.806915   |
| evaluation/return-std          | 1815.5819   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46096       |
| perf/AverageLength             | 227         |
| perf/AverageReturn             | 948.5459    |
| perf/NormalizedReturn          | 0.206       |
| Q-avg                          | 201.06311   |
| Q-std                          | 105.55903   |
| Q_loss                         | 87.052605   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 284         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000155    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000599    |
| times/evaluation_paths         | 8.95        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 285000      |
| train-steps                    | 285000      |
| training/Q/q1_loss             | 123.7576    |
| training/sac_pi/alpha          | 0.17496648  |
| training/sac_pi/alpha_loss     | -0.50880176 |
| training/sac_pi/logp_pi        | 4.267071    |
| training/sac_pi/pi_entropy     | 3.6704202   |
| training/sac_pi/pi_global_norm | 1.6703867   |
| training/sac_pi/policy_loss    | -199.93388  |
| training/sac_pi/std            | 0.51666814  |
| training/sac_pi/valid_num      | 4933.0      |
| training/sac_Q/q1              | 190.1673    |
| training/sac_Q/q2              | 188.48871   |
| training/sac_Q/q2_loss         | 123.12789   |
| training/sac_Q/q_global_norm   | 277.59897   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.18090819 |
| epoch                          | 285        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4429.219   |
| evaluation/return-max          | 4475.951   |
| evaluation/return-min          | 4377.7007  |
| evaluation/return-std          | 31.961847  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 83.1       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46104      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4429.219   |
| perf/NormalizedReturn          | 0.964      |
| Q-avg                          | 213.19797  |
| Q-std                          | 97.89221   |
| Q_loss                         | 86.22655   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 285        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000262   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000586   |
| times/evaluation_paths         | 42.1       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00809    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 286000     |
| train-steps                    | 286000     |
| training/Q/q1_loss             | 94.636765  |
| training/sac_pi/alpha          | 0.18089528 |
| training/sac_pi/alpha_loss     | 0.45130453 |
| training/sac_pi/logp_pi        | 4.1432395  |
| training/sac_pi/pi_entropy     | 3.649936   |
| training/sac_pi/pi_global_norm | 1.5773387  |
| training/sac_pi/policy_loss    | -212.13458 |
| training/sac_pi/std            | 0.49705255 |
| training/sac_pi/valid_num      | 4999.0     |
| training/sac_Q/q1              | 206.60686  |
| training/sac_Q/q2              | 205.67525  |
| training/sac_Q/q2_loss         | 93.91402   |
| training/sac_Q/q_global_norm   | 236.58977  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1762752  |
| epoch                          | 286        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4979.0654  |
| evaluation/return-max          | 5076.9404  |
| evaluation/return-min          | 4898.8125  |
| evaluation/return-std          | 50.282963  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46157      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4979.0654  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 203.01863  |
| Q-std                          | 123.66856  |
| Q_loss                         | 100.91706  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 286        |
| times/epoch_after_hook         | 2.03e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000558   |
| times/evaluation_paths         | 45.2       |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 64.1       |
| timestep                       | 1000       |
| timesteps_total                | 287000     |
| train-steps                    | 287000     |
| training/Q/q1_loss             | 97.69918   |
| training/sac_pi/alpha          | 0.17624696 |
| training/sac_pi/alpha_loss     | 0.21772394 |
| training/sac_pi/logp_pi        | 4.250766   |
| training/sac_pi/pi_entropy     | 3.6555524  |
| training/sac_pi/pi_global_norm | 1.8702888  |
| training/sac_pi/policy_loss    | -222.6333  |
| training/sac_pi/std            | 0.50018054 |
| training/sac_pi/valid_num      | 4967.0     |
| training/sac_Q/q1              | 213.80864  |
| training/sac_Q/q2              | 213.0061   |
| training/sac_Q/q2_loss         | 98.08021   |
| training/sac_Q/q_global_norm   | 230.8122   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17023453 |
| epoch                          | 287        |
| evaluation/episode-length-avg  | 537        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 309        |
| evaluation/episode-length-std  | 307        |
| evaluation/return-average      | 2341.3003  |
| evaluation/return-max          | 4796.5186  |
| evaluation/return-min          | 1136.842   |
| evaluation/return-std          | 1607.2689  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46050      |
| perf/AverageLength             | 537        |
| perf/AverageReturn             | 2341.3003  |
| perf/NormalizedReturn          | 0.51       |
| Q-avg                          | 202.3403   |
| Q-std                          | 95.21098   |
| Q_loss                         | 111.08969  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 287        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000562   |
| times/evaluation_paths         | 23.9       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 64.3       |
| timestep                       | 1000       |
| timesteps_total                | 288000     |
| train-steps                    | 288000     |
| training/Q/q1_loss             | 104.776695 |
| training/sac_pi/alpha          | 0.17025305 |
| training/sac_pi/alpha_loss     | 0.24576695 |
| training/sac_pi/logp_pi        | 4.129518   |
| training/sac_pi/pi_entropy     | 3.5050514  |
| training/sac_pi/pi_global_norm | 1.8071133  |
| training/sac_pi/policy_loss    | -211.67178 |
| training/sac_pi/std            | 0.48898506 |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 205.4625   |
| training/sac_Q/q2              | 205.17119  |
| training/sac_Q/q2_loss         | 105.6477   |
| training/sac_Q/q_global_norm   | 319.36682  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16996916 |
| epoch                          | 288        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4749.659   |
| evaluation/return-max          | 4799.7437  |
| evaluation/return-min          | 4706.665   |
| evaluation/return-std          | 27.354445  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46310      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4749.659   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 208.80344  |
| Q-std                          | 87.603195  |
| Q_loss                         | 94.558784  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 288        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.00059    |
| times/evaluation_paths         | 35         |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 289000     |
| train-steps                    | 289000     |
| training/Q/q1_loss             | 102.72843  |
| training/sac_pi/alpha          | 0.16998294 |
| training/sac_pi/alpha_loss     | -0.2291396 |
| training/sac_pi/logp_pi        | 4.947316   |
| training/sac_pi/pi_entropy     | 3.4910865  |
| training/sac_pi/pi_global_norm | 1.728486   |
| training/sac_pi/policy_loss    | -203.35542 |
| training/sac_pi/std            | 0.52588874 |
| training/sac_pi/valid_num      | 4877.0     |
| training/sac_Q/q1              | 190.72998  |
| training/sac_Q/q2              | 187.85883  |
| training/sac_Q/q2_loss         | 102.010124 |
| training/sac_Q/q_global_norm   | 233.11838  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1715162   |
| epoch                          | 289         |
| evaluation/episode-length-avg  | 912         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 124         |
| evaluation/episode-length-std  | 263         |
| evaluation/return-average      | 4299.2207   |
| evaluation/return-max          | 4788.6636   |
| evaluation/return-min          | 305.97955   |
| evaluation/return-std          | 1331.2432   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 83.3        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46247       |
| perf/AverageLength             | 912         |
| perf/AverageReturn             | 4299.2207   |
| perf/NormalizedReturn          | 0.936       |
| Q-avg                          | 202.953     |
| Q-std                          | 99.00921    |
| Q_loss                         | 109.44823   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 289         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000253    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000537    |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 62.4        |
| timestep                       | 1000        |
| timesteps_total                | 290000      |
| train-steps                    | 290000      |
| training/Q/q1_loss             | 111.113014  |
| training/sac_pi/alpha          | 0.1715003   |
| training/sac_pi/alpha_loss     | -0.04400846 |
| training/sac_pi/logp_pi        | 4.425361    |
| training/sac_pi/pi_entropy     | 3.5034313   |
| training/sac_pi/pi_global_norm | 1.9277719   |
| training/sac_pi/policy_loss    | -201.73288  |
| training/sac_pi/std            | 0.51324004  |
| training/sac_pi/valid_num      | 4908.0      |
| training/sac_Q/q1              | 189.08954   |
| training/sac_Q/q2              | 186.86975   |
| training/sac_Q/q2_loss         | 112.84668   |
| training/sac_Q/q_global_norm   | 260.82953   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16993558  |
| epoch                          | 290         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5001.931    |
| evaluation/return-max          | 5185.5356   |
| evaluation/return-min          | 4821.6016   |
| evaluation/return-std          | 114.45488   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46145       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5001.931    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 199.63179   |
| Q-std                          | 106.971504  |
| Q_loss                         | 77.22403    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 290         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000514    |
| times/evaluation_paths         | 44.8        |
| times/timestep_after_hook      | 0.004       |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 63.6        |
| timestep                       | 1000        |
| timesteps_total                | 291000      |
| train-steps                    | 291000      |
| training/Q/q1_loss             | 104.64545   |
| training/sac_pi/alpha          | 0.16996032  |
| training/sac_pi/alpha_loss     | -0.26052833 |
| training/sac_pi/logp_pi        | 3.9748046   |
| training/sac_pi/pi_entropy     | 3.3999736   |
| training/sac_pi/pi_global_norm | 1.6990988   |
| training/sac_pi/policy_loss    | -213.48477  |
| training/sac_pi/std            | 0.47427112  |
| training/sac_pi/valid_num      | 4942.0      |
| training/sac_Q/q1              | 205.46463   |
| training/sac_Q/q2              | 204.09883   |
| training/sac_Q/q2_loss         | 104.94865   |
| training/sac_Q/q_global_norm   | 212.35988   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17590666  |
| epoch                          | 291         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4634.426    |
| evaluation/return-max          | 4765.8535   |
| evaluation/return-min          | 4489.662    |
| evaluation/return-std          | 99.449165   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46104       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4634.426    |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 190.14268   |
| Q-std                          | 133.82501   |
| Q_loss                         | 113.54742   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 291         |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 0.000143    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000652    |
| times/evaluation_paths         | 42.4        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 67.9        |
| timestep                       | 1000        |
| timesteps_total                | 292000      |
| train-steps                    | 292000      |
| training/Q/q1_loss             | 111.97697   |
| training/sac_pi/alpha          | 0.1759176   |
| training/sac_pi/alpha_loss     | -0.11870272 |
| training/sac_pi/logp_pi        | 4.90903     |
| training/sac_pi/pi_entropy     | 3.4524143   |
| training/sac_pi/pi_global_norm | 1.744187    |
| training/sac_pi/policy_loss    | -206.69243  |
| training/sac_pi/std            | 0.5148686   |
| training/sac_pi/valid_num      | 4946.0      |
| training/sac_Q/q1              | 199.51674   |
| training/sac_Q/q2              | 196.25493   |
| training/sac_Q/q2_loss         | 111.108986  |
| training/sac_Q/q_global_norm   | 296.35327   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17730404 |
| epoch                          | 292        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5001.021   |
| evaluation/return-max          | 5043.706   |
| evaluation/return-min          | 4950.4814  |
| evaluation/return-std          | 22.23389   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 82.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46153      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5001.021   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 195.93735  |
| Q-std                          | 123.25039  |
| Q_loss                         | 105.10124  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 292        |
| times/epoch_after_hook         | 3.84e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000662   |
| times/evaluation_paths         | 33.4       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 293000     |
| train-steps                    | 293000     |
| training/Q/q1_loss             | 95.613014  |
| training/sac_pi/alpha          | 0.1772855  |
| training/sac_pi/alpha_loss     | 0.12738113 |
| training/sac_pi/logp_pi        | 4.0654993  |
| training/sac_pi/pi_entropy     | 3.4512439  |
| training/sac_pi/pi_global_norm | 1.6778854  |
| training/sac_pi/policy_loss    | -219.65977 |
| training/sac_pi/std            | 0.492691   |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 208.28589  |
| training/sac_Q/q2              | 205.48882  |
| training/sac_Q/q2_loss         | 94.57774   |
| training/sac_Q/q_global_norm   | 252.48103  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17592773 |
| epoch                          | 293        |
| evaluation/episode-length-avg  | 543        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 122        |
| evaluation/episode-length-std  | 424        |
| evaluation/return-average      | 2554.9365  |
| evaluation/return-max          | 5054.0117  |
| evaluation/return-min          | 310.86575  |
| evaluation/return-std          | 2261.5293  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46080      |
| perf/AverageLength             | 543        |
| perf/AverageReturn             | 2554.9365  |
| perf/NormalizedReturn          | 0.556      |
| Q-avg                          | 197.90872  |
| Q-std                          | 123.07883  |
| Q_loss                         | 95.24548   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 293        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000264   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000748   |
| times/evaluation_paths         | 24.3       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 294000     |
| train-steps                    | 294000     |
| training/Q/q1_loss             | 88.72254   |
| training/sac_pi/alpha          | 0.17593703 |
| training/sac_pi/alpha_loss     | -0.4060923 |
| training/sac_pi/logp_pi        | 3.7912915  |
| training/sac_pi/pi_entropy     | 3.6275356  |
| training/sac_pi/pi_global_norm | 1.6786109  |
| training/sac_pi/policy_loss    | -212.06201 |
| training/sac_pi/std            | 0.49041224 |
| training/sac_pi/valid_num      | 4940.0     |
| training/sac_Q/q1              | 203.51619  |
| training/sac_Q/q2              | 202.68222  |
| training/sac_Q/q2_loss         | 89.27139   |
| training/sac_Q/q_global_norm   | 238.24466  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17222904 |
| epoch                          | 294        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4929.3877  |
| evaluation/return-max          | 4959.675   |
| evaluation/return-min          | 4895.784   |
| evaluation/return-std          | 20.315208  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45994      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4929.3877  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 207.10747  |
| Q-std                          | 104.53683  |
| Q_loss                         | 98.48566   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 294        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000589   |
| times/evaluation_paths         | 40.9       |
| times/timestep_after_hook      | 0.00408    |
| times/timestep_before_hook     | 0.00797    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 295000     |
| train-steps                    | 295000     |
| training/Q/q1_loss             | 100.32502  |
| training/sac_pi/alpha          | 0.17219487 |
| training/sac_pi/alpha_loss     | 0.47738975 |
| training/sac_pi/logp_pi        | 4.605934   |
| training/sac_pi/pi_entropy     | 3.5674062  |
| training/sac_pi/pi_global_norm | 1.4588486  |
| training/sac_pi/policy_loss    | -214.4449  |
| training/sac_pi/std            | 0.5039642  |
| training/sac_pi/valid_num      | 4961.0     |
| training/sac_Q/q1              | 206.19917  |
| training/sac_Q/q2              | 203.01411  |
| training/sac_Q/q2_loss         | 100.536736 |
| training/sac_Q/q_global_norm   | 312.49603  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16856723   |
| epoch                          | 295          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4694.644     |
| evaluation/return-max          | 4720.644     |
| evaluation/return-min          | 4660.8125    |
| evaluation/return-std          | 17.919926    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.03         |
| model/origin_ret               | 86.6         |
| model/penalty_ret              | 81.4         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46117        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4694.644     |
| perf/NormalizedReturn          | 1.02         |
| Q-avg                          | 212.78671    |
| Q-std                          | 95.583275    |
| Q_loss                         | 107.31382    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 295          |
| times/epoch_after_hook         | 1.94e-06     |
| times/epoch_before_hook        | 0.000146     |
| times/epoch_rollout_model      | 485          |
| times/evaluation_metrics       | 0.000527     |
| times/evaluation_paths         | 42.6         |
| times/timestep_after_hook      | 0.00408      |
| times/timestep_before_hook     | 0.00813      |
| times/train                    | 60.8         |
| timestep                       | 1000         |
| timesteps_total                | 296000       |
| train-steps                    | 296000       |
| training/Q/q1_loss             | 100.77129    |
| training/sac_pi/alpha          | 0.16857432   |
| training/sac_pi/alpha_loss     | -0.117680386 |
| training/sac_pi/logp_pi        | 4.3752136    |
| training/sac_pi/pi_entropy     | 3.4881454    |
| training/sac_pi/pi_global_norm | 2.0049226    |
| training/sac_pi/policy_loss    | -220.57803   |
| training/sac_pi/std            | 0.50448793   |
| training/sac_pi/valid_num      | 4943.0       |
| training/sac_Q/q1              | 211.88895    |
| training/sac_Q/q2              | 210.30576    |
| training/sac_Q/q2_loss         | 101.02653    |
| training/sac_Q/q_global_norm   | 260.9677     |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1730181   |
| epoch                          | 296         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5000.833    |
| evaluation/return-max          | 5130.3574   |
| evaluation/return-min          | 4870.9844   |
| evaluation/return-std          | 66.50847    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46164       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5000.833    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 202.71843   |
| Q-std                          | 113.6489    |
| Q_loss                         | 92.55555    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 296         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000139    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000641    |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 62.7        |
| timestep                       | 1000        |
| timesteps_total                | 297000      |
| train-steps                    | 297000      |
| training/Q/q1_loss             | 99.01053    |
| training/sac_pi/alpha          | 0.17299993  |
| training/sac_pi/alpha_loss     | -0.15153384 |
| training/sac_pi/logp_pi        | 3.8825722   |
| training/sac_pi/pi_entropy     | 3.367267    |
| training/sac_pi/pi_global_norm | 1.7999548   |
| training/sac_pi/policy_loss    | -218.96883  |
| training/sac_pi/std            | 0.47724771  |
| training/sac_pi/valid_num      | 4992.0      |
| training/sac_Q/q1              | 212.83646   |
| training/sac_Q/q2              | 211.97574   |
| training/sac_Q/q2_loss         | 97.82828    |
| training/sac_Q/q_global_norm   | 249.96263   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1722819  |
| epoch                          | 297        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5220.624   |
| evaluation/return-max          | 5278.077   |
| evaluation/return-min          | 5154.7812  |
| evaluation/return-std          | 30.84412   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46151      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5220.624   |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 210.96089  |
| Q-std                          | 101.28232  |
| Q_loss                         | 95.007065  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 297        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000272   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000576   |
| times/evaluation_paths         | 44.8       |
| times/timestep_after_hook      | 0.00424    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 298000     |
| train-steps                    | 298000     |
| training/Q/q1_loss             | 91.12735   |
| training/sac_pi/alpha          | 0.17225417 |
| training/sac_pi/alpha_loss     | 0.1458291  |
| training/sac_pi/logp_pi        | 3.741649   |
| training/sac_pi/pi_entropy     | 3.5116234  |
| training/sac_pi/pi_global_norm | 1.4856946  |
| training/sac_pi/policy_loss    | -209.40485 |
| training/sac_pi/std            | 0.46901277 |
| training/sac_pi/valid_num      | 5013.0     |
| training/sac_Q/q1              | 205.73528  |
| training/sac_Q/q2              | 205.48662  |
| training/sac_Q/q2_loss         | 90.99348   |
| training/sac_Q/q_global_norm   | 254.71342  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1673538    |
| epoch                          | 298          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4879.8076    |
| evaluation/return-max          | 4979.541     |
| evaluation/return-min          | 4773.1763    |
| evaluation/return-std          | 71.99875     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.04         |
| model/origin_ret               | 84.9         |
| model/penalty_ret              | 80.1         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46139        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4879.8076    |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 196.3383     |
| Q-std                          | 108.78448    |
| Q_loss                         | 102.737724   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 298          |
| times/epoch_after_hook         | 1.83e-06     |
| times/epoch_before_hook        | 0.000136     |
| times/epoch_rollout_model      | 512          |
| times/evaluation_metrics       | 0.000686     |
| times/evaluation_paths         | 43.5         |
| times/timestep_after_hook      | 0.00411      |
| times/timestep_before_hook     | 0.00826      |
| times/train                    | 65.7         |
| timestep                       | 1000         |
| timesteps_total                | 299000       |
| train-steps                    | 299000       |
| training/Q/q1_loss             | 102.15263    |
| training/sac_pi/alpha          | 0.16734281   |
| training/sac_pi/alpha_loss     | -0.093090124 |
| training/sac_pi/logp_pi        | 4.4459486    |
| training/sac_pi/pi_entropy     | 3.3870482    |
| training/sac_pi/pi_global_norm | 1.5719407    |
| training/sac_pi/policy_loss    | -212.19717   |
| training/sac_pi/std            | 0.48859438   |
| training/sac_pi/valid_num      | 4938.0       |
| training/sac_Q/q1              | 203.17682    |
| training/sac_Q/q2              | 201.81879    |
| training/sac_Q/q2_loss         | 103.52464    |
| training/sac_Q/q_global_norm   | 315.09824    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1731265  |
| epoch                          | 299        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5095.7783  |
| evaluation/return-max          | 5229.201   |
| evaluation/return-min          | 5024.165   |
| evaluation/return-std          | 64.93314   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46118      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5095.7783  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 217.30412  |
| Q-std                          | 89.68827   |
| Q_loss                         | 93.483055  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 299        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000145   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000518   |
| times/evaluation_paths         | 39.7       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00806    |
| times/train                    | 67.6       |
| timestep                       | 1000       |
| timesteps_total                | 300000     |
| train-steps                    | 300000     |
| training/Q/q1_loss             | 100.40442  |
| training/sac_pi/alpha          | 0.17311037 |
| training/sac_pi/alpha_loss     | 0.10845659 |
| training/sac_pi/logp_pi        | 4.2865343  |
| training/sac_pi/pi_entropy     | 3.5800242  |
| training/sac_pi/pi_global_norm | 1.6444901  |
| training/sac_pi/policy_loss    | -212.40662 |
| training/sac_pi/std            | 0.5057996  |
| training/sac_pi/valid_num      | 4973.0     |
| training/sac_Q/q1              | 204.4882   |
| training/sac_Q/q2              | 203.1796   |
| training/sac_Q/q2_loss         | 100.700195 |
| training/sac_Q/q_global_norm   | 252.80484  |
--------------------------------------------------------------------------------
[WARN] 300 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.17435332   |
| epoch                          | 300          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4913.4287    |
| evaluation/return-max          | 5051.4043    |
| evaluation/return-min          | 4775.0645    |
| evaluation/return-std          | 93.87322     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.01         |
| model/origin_ret               | 86.7         |
| model/penalty_ret              | 82.3         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 45901        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4913.4287    |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 192.90475    |
| Q-std                          | 112.022224   |
| Q_loss                         | 115.93764    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 300          |
| times/epoch_after_hook         | 1.8e-06      |
| times/epoch_before_hook        | 0.000132     |
| times/epoch_rollout_model      | 496          |
| times/evaluation_metrics       | 0.000663     |
| times/evaluation_paths         | 44.6         |
| times/timestep_after_hook      | 0.00399      |
| times/timestep_before_hook     | 0.00801      |
| times/train                    | 61.1         |
| timestep                       | 1000         |
| timesteps_total                | 301000       |
| train-steps                    | 301000       |
| training/Q/q1_loss             | 117.53399    |
| training/sac_pi/alpha          | 0.17438138   |
| training/sac_pi/alpha_loss     | -0.055401806 |
| training/sac_pi/logp_pi        | 3.9566712    |
| training/sac_pi/pi_entropy     | 3.467607     |
| training/sac_pi/pi_global_norm | 1.5724456    |
| training/sac_pi/policy_loss    | -214.8908    |
| training/sac_pi/std            | 0.48322752   |
| training/sac_pi/valid_num      | 4939.0       |
| training/sac_Q/q1              | 207.89375    |
| training/sac_Q/q2              | 206.74191    |
| training/sac_Q/q2_loss         | 118.1372     |
| training/sac_Q/q_global_norm   | 270.03293    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17494893  |
| epoch                          | 301         |
| evaluation/episode-length-avg  | 928         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 277         |
| evaluation/episode-length-std  | 217         |
| evaluation/return-average      | 4669.5693   |
| evaluation/return-max          | 5171.5225   |
| evaluation/return-min          | 1037.1465   |
| evaluation/return-std          | 1212.7942   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46163       |
| perf/AverageLength             | 928         |
| perf/AverageReturn             | 4669.5693   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 202.98958   |
| Q-std                          | 104.54412   |
| Q_loss                         | 102.98749   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 301         |
| times/epoch_after_hook         | 3.45e-06    |
| times/epoch_before_hook        | 0.000316    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000571    |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00409     |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 65.2        |
| timestep                       | 1000        |
| timesteps_total                | 302000      |
| train-steps                    | 302000      |
| training/Q/q1_loss             | 99.31902    |
| training/sac_pi/alpha          | 0.17497487  |
| training/sac_pi/alpha_loss     | -0.09051598 |
| training/sac_pi/logp_pi        | 4.1634316   |
| training/sac_pi/pi_entropy     | 3.4104538   |
| training/sac_pi/pi_global_norm | 1.4692153   |
| training/sac_pi/policy_loss    | -220.18922  |
| training/sac_pi/std            | 0.48850992  |
| training/sac_pi/valid_num      | 4965.0      |
| training/sac_Q/q1              | 212.30212   |
| training/sac_Q/q2              | 211.23843   |
| training/sac_Q/q2_loss         | 97.68723    |
| training/sac_Q/q_global_norm   | 238.7925    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.174047    |
| epoch                          | 302         |
| evaluation/episode-length-avg  | 958         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 582         |
| evaluation/episode-length-std  | 125         |
| evaluation/return-average      | 4624.38     |
| evaluation/return-max          | 4892.5938   |
| evaluation/return-min          | 2406.3374   |
| evaluation/return-std          | 739.5246    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 80.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46215       |
| perf/AverageLength             | 958         |
| perf/AverageReturn             | 4624.38     |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 201.92455   |
| Q-std                          | 119.16594   |
| Q_loss                         | 111.87754   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 302         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000153    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000528    |
| times/evaluation_paths         | 33.8        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 64.4        |
| timestep                       | 1000        |
| timesteps_total                | 303000      |
| train-steps                    | 303000      |
| training/Q/q1_loss             | 91.29948    |
| training/sac_pi/alpha          | 0.17406751  |
| training/sac_pi/alpha_loss     | -0.21225868 |
| training/sac_pi/logp_pi        | 3.8927197   |
| training/sac_pi/pi_entropy     | 3.345366    |
| training/sac_pi/pi_global_norm | 1.551892    |
| training/sac_pi/policy_loss    | -212.08524  |
| training/sac_pi/std            | 0.4755026   |
| training/sac_pi/valid_num      | 4964.0      |
| training/sac_Q/q1              | 206.24472   |
| training/sac_Q/q2              | 205.14348   |
| training/sac_Q/q2_loss         | 91.269135   |
| training/sac_Q/q_global_norm   | 300.13278   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16894177  |
| epoch                          | 303         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5025.702    |
| evaluation/return-max          | 5069.2236   |
| evaluation/return-min          | 4932.815    |
| evaluation/return-std          | 36.49956    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46127       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5025.702    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 201.4169    |
| Q-std                          | 116.4793    |
| Q_loss                         | 95.81187    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 303         |
| times/epoch_after_hook         | 1.93e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 504         |
| times/evaluation_metrics       | 0.000689    |
| times/evaluation_paths         | 37.8        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 60.1        |
| timestep                       | 1000        |
| timesteps_total                | 304000      |
| train-steps                    | 304000      |
| training/Q/q1_loss             | 88.85648    |
| training/sac_pi/alpha          | 0.16898134  |
| training/sac_pi/alpha_loss     | -0.38158157 |
| training/sac_pi/logp_pi        | 4.4541597   |
| training/sac_pi/pi_entropy     | 3.3810134   |
| training/sac_pi/pi_global_norm | 1.6405332   |
| training/sac_pi/policy_loss    | -215.058    |
| training/sac_pi/std            | 0.502897    |
| training/sac_pi/valid_num      | 4950.0      |
| training/sac_Q/q1              | 207.30347   |
| training/sac_Q/q2              | 204.86626   |
| training/sac_Q/q2_loss         | 89.30414    |
| training/sac_Q/q_global_norm   | 235.25859   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1731379    |
| epoch                          | 304          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4956.9985    |
| evaluation/return-max          | 5043.824     |
| evaluation/return-min          | 4831.3945    |
| evaluation/return-std          | 63.839714    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.99         |
| model/origin_ret               | 85.1         |
| model/penalty_ret              | 81.4         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46180        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4956.9985    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 209.43904    |
| Q-std                          | 101.365524   |
| Q_loss                         | 94.513916    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 304          |
| times/epoch_after_hook         | 1.75e-06     |
| times/epoch_before_hook        | 0.000155     |
| times/epoch_rollout_model      | 510          |
| times/evaluation_metrics       | 0.000649     |
| times/evaluation_paths         | 35.8         |
| times/timestep_after_hook      | 0.00402      |
| times/timestep_before_hook     | 0.0083       |
| times/train                    | 68.7         |
| timestep                       | 1000         |
| timesteps_total                | 305000       |
| train-steps                    | 305000       |
| training/Q/q1_loss             | 107.445724   |
| training/sac_pi/alpha          | 0.1731528    |
| training/sac_pi/alpha_loss     | -0.011715338 |
| training/sac_pi/logp_pi        | 4.258168     |
| training/sac_pi/pi_entropy     | 3.4574218    |
| training/sac_pi/pi_global_norm | 1.6081213    |
| training/sac_pi/policy_loss    | -213.53033   |
| training/sac_pi/std            | 0.49587125   |
| training/sac_pi/valid_num      | 4991.0       |
| training/sac_Q/q1              | 209.63577    |
| training/sac_Q/q2              | 207.93509    |
| training/sac_Q/q2_loss         | 106.81364    |
| training/sac_Q/q_global_norm   | 293.47806    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17585309 |
| epoch                          | 305        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5178.4834  |
| evaluation/return-max          | 5233.1714  |
| evaluation/return-min          | 5116.3984  |
| evaluation/return-std          | 34.88979   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45897      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5178.4834  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 202.80876  |
| Q-std                          | 93.50613   |
| Q_loss                         | 100.73185  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 305        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000313   |
| times/epoch_rollout_model      | 506        |
| times/evaluation_metrics       | 0.000689   |
| times/evaluation_paths         | 35.9       |
| times/timestep_after_hook      | 0.00411    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 306000     |
| train-steps                    | 306000     |
| training/Q/q1_loss             | 113.66966  |
| training/sac_pi/alpha          | 0.1758269  |
| training/sac_pi/alpha_loss     | 0.08246195 |
| training/sac_pi/logp_pi        | 5.2534547  |
| training/sac_pi/pi_entropy     | 3.5459049  |
| training/sac_pi/pi_global_norm | 1.7758121  |
| training/sac_pi/policy_loss    | -212.1562  |
| training/sac_pi/std            | 0.5236589  |
| training/sac_pi/valid_num      | 4912.0     |
| training/sac_Q/q1              | 206.02544  |
| training/sac_Q/q2              | 202.72307  |
| training/sac_Q/q2_loss         | 113.1802   |
| training/sac_Q/q_global_norm   | 245.46194  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17491123  |
| epoch                          | 306         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5014.462    |
| evaluation/return-max          | 5193.2764   |
| evaluation/return-min          | 4680.896    |
| evaluation/return-std          | 150.17342   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45807       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5014.462    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 196.85843   |
| Q-std                          | 137.52213   |
| Q_loss                         | 106.804855  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 306         |
| times/epoch_after_hook         | 2.03e-06    |
| times/epoch_before_hook        | 0.000145    |
| times/epoch_rollout_model      | 520         |
| times/evaluation_metrics       | 0.000761    |
| times/evaluation_paths         | 35.5        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.00838     |
| times/train                    | 60.5        |
| timestep                       | 1000        |
| timesteps_total                | 307000      |
| train-steps                    | 307000      |
| training/Q/q1_loss             | 110.45253   |
| training/sac_pi/alpha          | 0.17489244  |
| training/sac_pi/alpha_loss     | -0.20455094 |
| training/sac_pi/logp_pi        | 4.465788    |
| training/sac_pi/pi_entropy     | 3.600141    |
| training/sac_pi/pi_global_norm | 2.0323794   |
| training/sac_pi/policy_loss    | -203.03766  |
| training/sac_pi/std            | 0.51409507  |
| training/sac_pi/valid_num      | 4941.0      |
| training/sac_Q/q1              | 195.1154    |
| training/sac_Q/q2              | 194.267     |
| training/sac_Q/q2_loss         | 111.507385  |
| training/sac_Q/q_global_norm   | 332.00375   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17424251 |
| epoch                          | 307        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4445.4346  |
| evaluation/return-max          | 4665.0166  |
| evaluation/return-min          | 4240.023   |
| evaluation/return-std          | 120.96728  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46022      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4445.4346  |
| perf/NormalizedReturn          | 0.968      |
| Q-avg                          | 208.1659   |
| Q-std                          | 109.339676 |
| Q_loss                         | 87.42249   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 307        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 518        |
| times/evaluation_metrics       | 0.000614   |
| times/evaluation_paths         | 33.6       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 62.1       |
| timestep                       | 1000       |
| timesteps_total                | 308000     |
| train-steps                    | 308000     |
| training/Q/q1_loss             | 99.930756  |
| training/sac_pi/alpha          | 0.17425846 |
| training/sac_pi/alpha_loss     | 0.28370064 |
| training/sac_pi/logp_pi        | 4.2271395  |
| training/sac_pi/pi_entropy     | 3.3907585  |
| training/sac_pi/pi_global_norm | 2.0384617  |
| training/sac_pi/policy_loss    | -212.11919 |
| training/sac_pi/std            | 0.47744447 |
| training/sac_pi/valid_num      | 4984.0     |
| training/sac_Q/q1              | 205.93721  |
| training/sac_Q/q2              | 205.72441  |
| training/sac_Q/q2_loss         | 99.684074  |
| training/sac_Q/q_global_norm   | 283.18167  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17777121  |
| epoch                          | 308         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4680.411    |
| evaluation/return-max          | 4820.1006   |
| evaluation/return-min          | 4468.509    |
| evaluation/return-std          | 110.80283   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46159       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4680.411    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 203.89151   |
| Q-std                          | 103.23402   |
| Q_loss                         | 110.199585  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 308         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000154    |
| times/epoch_rollout_model      | 528         |
| times/evaluation_metrics       | 0.000755    |
| times/evaluation_paths         | 34          |
| times/timestep_after_hook      | 0.00408     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 65.1        |
| timestep                       | 1000        |
| timesteps_total                | 309000      |
| train-steps                    | 309000      |
| training/Q/q1_loss             | 101.55929   |
| training/sac_pi/alpha          | 0.17777707  |
| training/sac_pi/alpha_loss     | -0.31514746 |
| training/sac_pi/logp_pi        | 4.42167     |
| training/sac_pi/pi_entropy     | 3.5159478   |
| training/sac_pi/pi_global_norm | 1.5085595   |
| training/sac_pi/policy_loss    | -207.67522  |
| training/sac_pi/std            | 0.51004076  |
| training/sac_pi/valid_num      | 4964.0      |
| training/sac_Q/q1              | 199.16806   |
| training/sac_Q/q2              | 198.07559   |
| training/sac_Q/q2_loss         | 101.07335   |
| training/sac_Q/q_global_norm   | 293.31546   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17623323   |
| epoch                          | 309          |
| evaluation/episode-length-avg  | 735          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 113          |
| evaluation/episode-length-std  | 405          |
| evaluation/return-average      | 3356.0386    |
| evaluation/return-max          | 4714.1787    |
| evaluation/return-min          | 254.86342    |
| evaluation/return-std          | 2021.2291    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.96         |
| model/origin_ret               | 84.5         |
| model/penalty_ret              | 80.9         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46199        |
| perf/AverageLength             | 735          |
| perf/AverageReturn             | 3356.0386    |
| perf/NormalizedReturn          | 0.731        |
| Q-avg                          | 200.18478    |
| Q-std                          | 116.217476   |
| Q_loss                         | 108.79487    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 309          |
| times/epoch_after_hook         | 3.58e-06     |
| times/epoch_before_hook        | 0.000342     |
| times/epoch_rollout_model      | 504          |
| times/evaluation_metrics       | 0.000657     |
| times/evaluation_paths         | 25.6         |
| times/timestep_after_hook      | 0.00407      |
| times/timestep_before_hook     | 0.00835      |
| times/train                    | 64.1         |
| timestep                       | 1000         |
| timesteps_total                | 310000       |
| train-steps                    | 310000       |
| training/Q/q1_loss             | 110.843636   |
| training/sac_pi/alpha          | 0.17622901   |
| training/sac_pi/alpha_loss     | -0.071291454 |
| training/sac_pi/logp_pi        | 3.698756     |
| training/sac_pi/pi_entropy     | 3.4309468    |
| training/sac_pi/pi_global_norm | 1.9730954    |
| training/sac_pi/policy_loss    | -211.95901   |
| training/sac_pi/std            | 0.4686532    |
| training/sac_pi/valid_num      | 4980.0       |
| training/sac_Q/q1              | 204.48433    |
| training/sac_Q/q2              | 203.18884    |
| training/sac_Q/q2_loss         | 110.06291    |
| training/sac_Q/q_global_norm   | 247.42914    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17624101   |
| epoch                          | 310          |
| evaluation/episode-length-avg  | 827          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 128          |
| evaluation/episode-length-std  | 346          |
| evaluation/return-average      | 4075.7493    |
| evaluation/return-max          | 5063.627     |
| evaluation/return-min          | 309.2041     |
| evaluation/return-std          | 1872.5537    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.98         |
| model/origin_ret               | 85.1         |
| model/penalty_ret              | 81.7         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46203        |
| perf/AverageLength             | 827          |
| perf/AverageReturn             | 4075.7493    |
| perf/NormalizedReturn          | 0.887        |
| Q-avg                          | 205.75198    |
| Q-std                          | 115.96563    |
| Q_loss                         | 89.00999     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 310          |
| times/epoch_after_hook         | 3.07e-06     |
| times/epoch_before_hook        | 0.000281     |
| times/epoch_rollout_model      | 499          |
| times/evaluation_metrics       | 0.000476     |
| times/evaluation_paths         | 28.9         |
| times/timestep_after_hook      | 0.00424      |
| times/timestep_before_hook     | 0.00845      |
| times/train                    | 61.8         |
| timestep                       | 1000         |
| timesteps_total                | 311000       |
| train-steps                    | 311000       |
| training/Q/q1_loss             | 86.74497     |
| training/sac_pi/alpha          | 0.17622578   |
| training/sac_pi/alpha_loss     | -0.026013788 |
| training/sac_pi/logp_pi        | 5.0421767    |
| training/sac_pi/pi_entropy     | 3.4599404    |
| training/sac_pi/pi_global_norm | 2.2871652    |
| training/sac_pi/policy_loss    | -214.21361   |
| training/sac_pi/std            | 0.5016957    |
| training/sac_pi/valid_num      | 4926.0       |
| training/sac_Q/q1              | 202.56447    |
| training/sac_Q/q2              | 201.52383    |
| training/sac_Q/q2_loss         | 87.86404     |
| training/sac_Q/q_global_norm   | 227.27606    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17578961  |
| epoch                          | 311         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5178.9985   |
| evaluation/return-max          | 5329.4375   |
| evaluation/return-min          | 5083.8145   |
| evaluation/return-std          | 68.76791    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46226       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5178.9985   |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 209.13138   |
| Q-std                          | 99.15678    |
| Q_loss                         | 104.24957   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 311         |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000605    |
| times/evaluation_paths         | 35.7        |
| times/timestep_after_hook      | 0.00423     |
| times/timestep_before_hook     | 0.00878     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 312000      |
| train-steps                    | 312000      |
| training/Q/q1_loss             | 90.28584    |
| training/sac_pi/alpha          | 0.17584021  |
| training/sac_pi/alpha_loss     | -0.26407155 |
| training/sac_pi/logp_pi        | 4.287118    |
| training/sac_pi/pi_entropy     | 3.5266488   |
| training/sac_pi/pi_global_norm | 1.7831634   |
| training/sac_pi/policy_loss    | -215.84848  |
| training/sac_pi/std            | 0.50794876  |
| training/sac_pi/valid_num      | 4940.0      |
| training/sac_Q/q1              | 205.80757   |
| training/sac_Q/q2              | 203.7928    |
| training/sac_Q/q2_loss         | 90.64822    |
| training/sac_Q/q_global_norm   | 255.95726   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1750157  |
| epoch                          | 312        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4557.5483  |
| evaluation/return-max          | 4646.9688  |
| evaluation/return-min          | 4517.9688  |
| evaluation/return-std          | 37.85274   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46121      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4557.5483  |
| perf/NormalizedReturn          | 0.992      |
| Q-avg                          | 200.07687  |
| Q-std                          | 126.266594 |
| Q_loss                         | 119.87149  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 312        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000664   |
| times/evaluation_paths         | 34         |
| times/timestep_after_hook      | 0.00416    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 313000     |
| train-steps                    | 313000     |
| training/Q/q1_loss             | 104.289764 |
| training/sac_pi/alpha          | 0.17501889 |
| training/sac_pi/alpha_loss     | 0.2138469  |
| training/sac_pi/logp_pi        | 3.5994554  |
| training/sac_pi/pi_entropy     | 3.5426114  |
| training/sac_pi/pi_global_norm | 1.7249656  |
| training/sac_pi/policy_loss    | -215.61044 |
| training/sac_pi/std            | 0.47276556 |
| training/sac_pi/valid_num      | 4961.0     |
| training/sac_Q/q1              | 209.32193  |
| training/sac_Q/q2              | 208.87573  |
| training/sac_Q/q2_loss         | 106.29552  |
| training/sac_Q/q_global_norm   | 270.26718  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17299008  |
| epoch                          | 313         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4867.5938   |
| evaluation/return-max          | 4891.323    |
| evaluation/return-min          | 4856.195    |
| evaluation/return-std          | 9.995428    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 82.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46116       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4867.5938   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 210.22806   |
| Q-std                          | 98.84094    |
| Q_loss                         | 94.75535    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 313         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.00026     |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000553    |
| times/evaluation_paths         | 33.6        |
| times/timestep_after_hook      | 0.00423     |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 314000      |
| train-steps                    | 314000      |
| training/Q/q1_loss             | 105.47517   |
| training/sac_pi/alpha          | 0.17298284  |
| training/sac_pi/alpha_loss     | -0.12726639 |
| training/sac_pi/logp_pi        | 4.171458    |
| training/sac_pi/pi_entropy     | 3.5184574   |
| training/sac_pi/pi_global_norm | 1.6866305   |
| training/sac_pi/policy_loss    | -210.92163  |
| training/sac_pi/std            | 0.5111481   |
| training/sac_pi/valid_num      | 4965.0      |
| training/sac_Q/q1              | 202.3276    |
| training/sac_Q/q2              | 201.48782   |
| training/sac_Q/q2_loss         | 105.29896   |
| training/sac_Q/q_global_norm   | 256.77216   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17187057 |
| epoch                          | 314        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4997.7754  |
| evaluation/return-max          | 5042.667   |
| evaluation/return-min          | 4960.012   |
| evaluation/return-std          | 26.23345   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46170      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4997.7754  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 208.78333  |
| Q-std                          | 99.0774    |
| Q_loss                         | 100.68025  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 314        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000161   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000585   |
| times/evaluation_paths         | 33.9       |
| times/timestep_after_hook      | 0.00422    |
| times/timestep_before_hook     | 0.00955    |
| times/train                    | 62.5       |
| timestep                       | 1000       |
| timesteps_total                | 315000     |
| train-steps                    | 315000     |
| training/Q/q1_loss             | 82.92796   |
| training/sac_pi/alpha          | 0.17187552 |
| training/sac_pi/alpha_loss     | 0.13396141 |
| training/sac_pi/logp_pi        | 4.150425   |
| training/sac_pi/pi_entropy     | 3.4374995  |
| training/sac_pi/pi_global_norm | 1.4768906  |
| training/sac_pi/policy_loss    | -212.21693 |
| training/sac_pi/std            | 0.48951796 |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 203.55626  |
| training/sac_Q/q2              | 203.71542  |
| training/sac_Q/q2_loss         | 82.903465  |
| training/sac_Q/q_global_norm   | 439.2306   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17316279  |
| epoch                          | 315         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5192.314    |
| evaluation/return-max          | 5295.554    |
| evaluation/return-min          | 5151.7354   |
| evaluation/return-std          | 39.493195   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46292       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5192.314    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 205.67241   |
| Q-std                          | 98.594635   |
| Q_loss                         | 89.36781    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 315         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000635    |
| times/evaluation_paths         | 34.4        |
| times/timestep_after_hook      | 0.00413     |
| times/timestep_before_hook     | 0.00859     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 316000      |
| train-steps                    | 316000      |
| training/Q/q1_loss             | 93.45337    |
| training/sac_pi/alpha          | 0.17316122  |
| training/sac_pi/alpha_loss     | -0.05678685 |
| training/sac_pi/logp_pi        | 4.0443025   |
| training/sac_pi/pi_entropy     | 3.1861808   |
| training/sac_pi/pi_global_norm | 1.5268738   |
| training/sac_pi/policy_loss    | -217.4982   |
| training/sac_pi/std            | 0.45259723  |
| training/sac_pi/valid_num      | 5006.0      |
| training/sac_Q/q1              | 209.76865   |
| training/sac_Q/q2              | 209.00298   |
| training/sac_Q/q2_loss         | 93.675255   |
| training/sac_Q/q_global_norm   | 254.63513   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17241998  |
| epoch                          | 316         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4880.0884   |
| evaluation/return-max          | 4941.4893   |
| evaluation/return-min          | 4836.5776   |
| evaluation/return-std          | 32.077312   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45955       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4880.0884   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 208.01859   |
| Q-std                          | 100.32435   |
| Q_loss                         | 82.04411    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 316         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.000136    |
| times/epoch_rollout_model      | 514         |
| times/evaluation_metrics       | 0.000668    |
| times/evaluation_paths         | 34.8        |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 317000      |
| train-steps                    | 317000      |
| training/Q/q1_loss             | 97.293175   |
| training/sac_pi/alpha          | 0.17243603  |
| training/sac_pi/alpha_loss     | 0.101547964 |
| training/sac_pi/logp_pi        | 4.3153315   |
| training/sac_pi/pi_entropy     | 3.6821945   |
| training/sac_pi/pi_global_norm | 2.065801    |
| training/sac_pi/policy_loss    | -210.90804  |
| training/sac_pi/std            | 0.51762694  |
| training/sac_pi/valid_num      | 4967.0      |
| training/sac_Q/q1              | 205.11191   |
| training/sac_Q/q2              | 204.20755   |
| training/sac_Q/q2_loss         | 98.019554   |
| training/sac_Q/q_global_norm   | 241.17068   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16997486 |
| epoch                          | 317        |
| evaluation/episode-length-avg  | 828        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 134        |
| evaluation/episode-length-std  | 344        |
| evaluation/return-average      | 3963.599   |
| evaluation/return-max          | 4981.073   |
| evaluation/return-min          | 260.8448   |
| evaluation/return-std          | 1840.1556  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46124      |
| perf/AverageLength             | 828        |
| perf/AverageReturn             | 3963.599   |
| perf/NormalizedReturn          | 0.863      |
| Q-avg                          | 206.07854  |
| Q-std                          | 114.47819  |
| Q_loss                         | 96.84355   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 317        |
| times/epoch_after_hook         | 3.61e-06   |
| times/epoch_before_hook        | 0.000309   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000545   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.0043     |
| times/timestep_before_hook     | 0.00854    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 318000     |
| train-steps                    | 318000     |
| training/Q/q1_loss             | 101.18064  |
| training/sac_pi/alpha          | 0.16994469 |
| training/sac_pi/alpha_loss     | 0.4027641  |
| training/sac_pi/logp_pi        | 5.024739   |
| training/sac_pi/pi_entropy     | 3.500164   |
| training/sac_pi/pi_global_norm | 1.572954   |
| training/sac_pi/policy_loss    | -214.55014 |
| training/sac_pi/std            | 0.5189221  |
| training/sac_pi/valid_num      | 4959.0     |
| training/sac_Q/q1              | 207.17184  |
| training/sac_Q/q2              | 202.16054  |
| training/sac_Q/q2_loss         | 100.829414 |
| training/sac_Q/q_global_norm   | 253.92282  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17187591  |
| epoch                          | 318         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4949.382    |
| evaluation/return-max          | 4980.782    |
| evaluation/return-min          | 4901.919    |
| evaluation/return-std          | 21.184582   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46275       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4949.382    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 204.98584   |
| Q-std                          | 108.07969   |
| Q_loss                         | 112.40378   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 318         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000668    |
| times/evaluation_paths         | 34.3        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 60.3        |
| timestep                       | 1000        |
| timesteps_total                | 319000      |
| train-steps                    | 319000      |
| training/Q/q1_loss             | 80.35006    |
| training/sac_pi/alpha          | 0.17182823  |
| training/sac_pi/alpha_loss     | -0.07220366 |
| training/sac_pi/logp_pi        | 5.183013    |
| training/sac_pi/pi_entropy     | 3.2830079   |
| training/sac_pi/pi_global_norm | 1.3619034   |
| training/sac_pi/policy_loss    | -210.73978  |
| training/sac_pi/std            | 0.49272448  |
| training/sac_pi/valid_num      | 4888.0      |
| training/sac_Q/q1              | 199.04507   |
| training/sac_Q/q2              | 195.2552    |
| training/sac_Q/q2_loss         | 80.36094    |
| training/sac_Q/q_global_norm   | 218.31662   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17289142 |
| epoch                          | 319        |
| evaluation/episode-length-avg  | 929        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 293        |
| evaluation/episode-length-std  | 212        |
| evaluation/return-average      | 4341.729   |
| evaluation/return-max          | 5014.2217  |
| evaluation/return-min          | 955.781    |
| evaluation/return-std          | 1137.3744  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46049      |
| perf/AverageLength             | 929        |
| perf/AverageReturn             | 4341.729   |
| perf/NormalizedReturn          | 0.945      |
| Q-avg                          | 198.84758  |
| Q-std                          | 130.18138  |
| Q_loss                         | 104.152534 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 319        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000607   |
| times/evaluation_paths         | 33.7       |
| times/timestep_after_hook      | 0.00415    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 320000     |
| train-steps                    | 320000     |
| training/Q/q1_loss             | 94.33659   |
| training/sac_pi/alpha          | 0.17288114 |
| training/sac_pi/alpha_loss     | 0.5078601  |
| training/sac_pi/logp_pi        | 4.1762824  |
| training/sac_pi/pi_entropy     | 3.4727435  |
| training/sac_pi/pi_global_norm | 1.5878214  |
| training/sac_pi/policy_loss    | -221.55922 |
| training/sac_pi/std            | 0.48287392 |
| training/sac_pi/valid_num      | 5037.0     |
| training/sac_Q/q1              | 215.92627  |
| training/sac_Q/q2              | 214.85669  |
| training/sac_Q/q2_loss         | 94.97346   |
| training/sac_Q/q_global_norm   | 252.13359  |
--------------------------------------------------------------------------------
[WARN] 320 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.17511277  |
| epoch                          | 320         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4833.953    |
| evaluation/return-max          | 4959.7915   |
| evaluation/return-min          | 4632.0273   |
| evaluation/return-std          | 94.086426   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46085       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4833.953    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 207.68018   |
| Q-std                          | 104.21589   |
| Q_loss                         | 96.27844    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 320         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.000145    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000608    |
| times/evaluation_paths         | 35.4        |
| times/timestep_after_hook      | 0.00413     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 60.4        |
| timestep                       | 1000        |
| timesteps_total                | 321000      |
| train-steps                    | 321000      |
| training/Q/q1_loss             | 131.25882   |
| training/sac_pi/alpha          | 0.17511539  |
| training/sac_pi/alpha_loss     | -0.01947265 |
| training/sac_pi/logp_pi        | 5.56474     |
| training/sac_pi/pi_entropy     | 3.2322338   |
| training/sac_pi/pi_global_norm | 1.5916789   |
| training/sac_pi/policy_loss    | -206.97813  |
| training/sac_pi/std            | 0.50856787  |
| training/sac_pi/valid_num      | 4865.0      |
| training/sac_Q/q1              | 192.3976    |
| training/sac_Q/q2              | 188.80888   |
| training/sac_Q/q2_loss         | 131.71881   |
| training/sac_Q/q_global_norm   | 239.12457   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17478788 |
| epoch                          | 321        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4920.7944  |
| evaluation/return-max          | 4981.533   |
| evaluation/return-min          | 4835.155   |
| evaluation/return-std          | 42.111565  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46071      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4920.7944  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 205.22844  |
| Q-std                          | 105.973175 |
| Q_loss                         | 122.0631   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 321        |
| times/epoch_after_hook         | 2.01e-06   |
| times/epoch_before_hook        | 0.000283   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000568   |
| times/evaluation_paths         | 33.1       |
| times/timestep_after_hook      | 0.00403    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 59.5       |
| timestep                       | 1000       |
| timesteps_total                | 322000     |
| train-steps                    | 322000     |
| training/Q/q1_loss             | 81.322624  |
| training/sac_pi/alpha          | 0.1747884  |
| training/sac_pi/alpha_loss     | 0.20949784 |
| training/sac_pi/logp_pi        | 4.3430905  |
| training/sac_pi/pi_entropy     | 3.507584   |
| training/sac_pi/pi_global_norm | 1.7719918  |
| training/sac_pi/policy_loss    | -217.99223 |
| training/sac_pi/std            | 0.49517372 |
| training/sac_pi/valid_num      | 4989.0     |
| training/sac_Q/q1              | 210.67183  |
| training/sac_Q/q2              | 209.06572  |
| training/sac_Q/q2_loss         | 81.088936  |
| training/sac_Q/q_global_norm   | 178.07848  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17245889 |
| epoch                          | 322        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4749.831   |
| evaluation/return-max          | 4849.254   |
| evaluation/return-min          | 4625.7144  |
| evaluation/return-std          | 68.04838   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46028      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4749.831   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 207.45316  |
| Q-std                          | 115.01423  |
| Q_loss                         | 109.92179  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 322        |
| times/epoch_after_hook         | 2.2e-06    |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000552   |
| times/evaluation_paths         | 34.4       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 323000     |
| train-steps                    | 323000     |
| training/Q/q1_loss             | 127.25302  |
| training/sac_pi/alpha          | 0.17240731 |
| training/sac_pi/alpha_loss     | 0.20411816 |
| training/sac_pi/logp_pi        | 4.8625917  |
| training/sac_pi/pi_entropy     | 3.5794563  |
| training/sac_pi/pi_global_norm | 1.4730532  |
| training/sac_pi/policy_loss    | -204.62796 |
| training/sac_pi/std            | 0.52993554 |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 195.60397  |
| training/sac_Q/q2              | 193.13359  |
| training/sac_Q/q2_loss         | 128.09052  |
| training/sac_Q/q_global_norm   | 219.23827  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16961579   |
| epoch                          | 323          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4800.9287    |
| evaluation/return-max          | 4846.484     |
| evaluation/return-min          | 4764.1226    |
| evaluation/return-std          | 26.448175    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.03         |
| model/origin_ret               | 86.7         |
| model/penalty_ret              | 82.8         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46128        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4800.9287    |
| perf/NormalizedReturn          | 1.05         |
| Q-avg                          | 200.57808    |
| Q-std                          | 104.55322    |
| Q_loss                         | 101.52878    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 323          |
| times/epoch_after_hook         | 1.89e-06     |
| times/epoch_before_hook        | 0.000154     |
| times/epoch_rollout_model      | 497          |
| times/evaluation_metrics       | 0.000554     |
| times/evaluation_paths         | 35.7         |
| times/timestep_after_hook      | 0.00413      |
| times/timestep_before_hook     | 0.00841      |
| times/train                    | 60           |
| timestep                       | 1000         |
| timesteps_total                | 324000       |
| train-steps                    | 324000       |
| training/Q/q1_loss             | 117.157196   |
| training/sac_pi/alpha          | 0.1696304    |
| training/sac_pi/alpha_loss     | -0.090792626 |
| training/sac_pi/logp_pi        | 3.2378736    |
| training/sac_pi/pi_entropy     | 3.4105377    |
| training/sac_pi/pi_global_norm | 1.8910093    |
| training/sac_pi/policy_loss    | -213.77425   |
| training/sac_pi/std            | 0.4538025    |
| training/sac_pi/valid_num      | 4974.0       |
| training/sac_Q/q1              | 208.70659    |
| training/sac_Q/q2              | 208.18523    |
| training/sac_Q/q2_loss         | 117.21896    |
| training/sac_Q/q_global_norm   | 318.24194    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1685658   |
| epoch                          | 324         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5205.7793   |
| evaluation/return-max          | 5345.4346   |
| evaluation/return-min          | 5143.3936   |
| evaluation/return-std          | 64.864136   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46295       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5205.7793   |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 215.75188   |
| Q-std                          | 121.18291   |
| Q_loss                         | 93.561      |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 324         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000143    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000711    |
| times/evaluation_paths         | 33          |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00834     |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 325000      |
| train-steps                    | 325000      |
| training/Q/q1_loss             | 102.44808   |
| training/sac_pi/alpha          | 0.16860197  |
| training/sac_pi/alpha_loss     | -0.23180015 |
| training/sac_pi/logp_pi        | 3.566915    |
| training/sac_pi/pi_entropy     | 3.4094956   |
| training/sac_pi/pi_global_norm | 1.599378    |
| training/sac_pi/policy_loss    | -226.86038  |
| training/sac_pi/std            | 0.46532968  |
| training/sac_pi/valid_num      | 5013.0      |
| training/sac_Q/q1              | 221.68462   |
| training/sac_Q/q2              | 221.13858   |
| training/sac_Q/q2_loss         | 101.902016  |
| training/sac_Q/q_global_norm   | 307.74545   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17880154 |
| epoch                          | 325        |
| evaluation/episode-length-avg  | 942        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 829        |
| evaluation/episode-length-std  | 55.4       |
| evaluation/return-average      | 4757.0728  |
| evaluation/return-max          | 5120.6934  |
| evaluation/return-min          | 4061.5073  |
| evaluation/return-std          | 330.6839   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46231      |
| perf/AverageLength             | 942        |
| perf/AverageReturn             | 4757.0728  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 214.21481  |
| Q-std                          | 88.95779   |
| Q_loss                         | 102.37683  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 325        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000284   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000644   |
| times/evaluation_paths         | 31.7       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 59.2       |
| timestep                       | 1000       |
| timesteps_total                | 326000     |
| train-steps                    | 326000     |
| training/Q/q1_loss             | 91.83255   |
| training/sac_pi/alpha          | 0.17879422 |
| training/sac_pi/alpha_loss     | 0.03224843 |
| training/sac_pi/logp_pi        | 4.957174   |
| training/sac_pi/pi_entropy     | 3.563809   |
| training/sac_pi/pi_global_norm | 1.7308612  |
| training/sac_pi/policy_loss    | -204.46896 |
| training/sac_pi/std            | 0.51371044 |
| training/sac_pi/valid_num      | 4926.0     |
| training/sac_Q/q1              | 195.43877  |
| training/sac_Q/q2              | 195.34477  |
| training/sac_Q/q2_loss         | 91.74056   |
| training/sac_Q/q_global_norm   | 238.78079  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17013414   |
| epoch                          | 326          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5056.8022    |
| evaluation/return-max          | 5105.0327    |
| evaluation/return-min          | 5012.5645    |
| evaluation/return-std          | 26.84412     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.03         |
| model/origin_ret               | 85.9         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46165        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5056.8022    |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 215.5291     |
| Q-std                          | 112.912865   |
| Q_loss                         | 78.79592     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 326          |
| times/epoch_after_hook         | 1.8e-06      |
| times/epoch_before_hook        | 0.000155     |
| times/epoch_rollout_model      | 497          |
| times/evaluation_metrics       | 0.000587     |
| times/evaluation_paths         | 33.2         |
| times/timestep_after_hook      | 0.00419      |
| times/timestep_before_hook     | 0.00851      |
| times/train                    | 60.8         |
| timestep                       | 1000         |
| timesteps_total                | 327000       |
| train-steps                    | 327000       |
| training/Q/q1_loss             | 95.559784    |
| training/sac_pi/alpha          | 0.17016691   |
| training/sac_pi/alpha_loss     | -0.049896833 |
| training/sac_pi/logp_pi        | 4.5165586    |
| training/sac_pi/pi_entropy     | 3.4220505    |
| training/sac_pi/pi_global_norm | 1.5272435    |
| training/sac_pi/policy_loss    | -212.05984   |
| training/sac_pi/std            | 0.4859396    |
| training/sac_pi/valid_num      | 4931.0       |
| training/sac_Q/q1              | 203.35844    |
| training/sac_Q/q2              | 203.56145    |
| training/sac_Q/q2_loss         | 96.08268     |
| training/sac_Q/q_global_norm   | 207.95003    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17622145 |
| epoch                          | 327        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5129.411   |
| evaluation/return-max          | 5221.315   |
| evaluation/return-min          | 5003.335   |
| evaluation/return-std          | 63.519955  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46160      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5129.411   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 204.2912   |
| Q-std                          | 95.145706  |
| Q_loss                         | 86.55134   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 327        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000141   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000701   |
| times/evaluation_paths         | 34         |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 59.7       |
| timestep                       | 1000       |
| timesteps_total                | 328000     |
| train-steps                    | 328000     |
| training/Q/q1_loss             | 93.595146  |
| training/sac_pi/alpha          | 0.17619607 |
| training/sac_pi/alpha_loss     | 0.10289186 |
| training/sac_pi/logp_pi        | 4.6891603  |
| training/sac_pi/pi_entropy     | 3.7081323  |
| training/sac_pi/pi_global_norm | 1.6027898  |
| training/sac_pi/policy_loss    | -207.60637 |
| training/sac_pi/std            | 0.54579645 |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 198.70145  |
| training/sac_Q/q2              | 196.3912   |
| training/sac_Q/q2_loss         | 93.938614  |
| training/sac_Q/q_global_norm   | 313.97314  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17525586 |
| epoch                          | 328        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4525.072   |
| evaluation/return-max          | 4771.6934  |
| evaluation/return-min          | 4338.407   |
| evaluation/return-std          | 116.32955  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46099      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4525.072   |
| perf/NormalizedReturn          | 0.985      |
| Q-avg                          | 195.23006  |
| Q-std                          | 120.31435  |
| Q_loss                         | 122.25357  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 328        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000535   |
| times/evaluation_paths         | 33.3       |
| times/timestep_after_hook      | 0.00417    |
| times/timestep_before_hook     | 0.00861    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 329000     |
| train-steps                    | 329000     |
| training/Q/q1_loss             | 106.35163  |
| training/sac_pi/alpha          | 0.17523636 |
| training/sac_pi/alpha_loss     | 0.37957326 |
| training/sac_pi/logp_pi        | 4.2924814  |
| training/sac_pi/pi_entropy     | 3.4975045  |
| training/sac_pi/pi_global_norm | 2.102367   |
| training/sac_pi/policy_loss    | -217.86115 |
| training/sac_pi/std            | 0.49316674 |
| training/sac_pi/valid_num      | 4927.0     |
| training/sac_Q/q1              | 207.18997  |
| training/sac_Q/q2              | 207.70512  |
| training/sac_Q/q2_loss         | 107.27797  |
| training/sac_Q/q_global_norm   | 271.6688   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17022316 |
| epoch                          | 329        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5012.171   |
| evaluation/return-max          | 5065.519   |
| evaluation/return-min          | 4972.1006  |
| evaluation/return-std          | 28.336296  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46151      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5012.171   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 203.38376  |
| Q-std                          | 116.121185 |
| Q_loss                         | 85.04011   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 329        |
| times/epoch_after_hook         | 1.98e-06   |
| times/epoch_before_hook        | 0.000311   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000774   |
| times/evaluation_paths         | 33.2       |
| times/timestep_after_hook      | 0.00415    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 330000     |
| train-steps                    | 330000     |
| training/Q/q1_loss             | 133.65344  |
| training/sac_pi/alpha          | 0.1702158  |
| training/sac_pi/alpha_loss     | 0.26514745 |
| training/sac_pi/logp_pi        | 4.5186186  |
| training/sac_pi/pi_entropy     | 3.4870257  |
| training/sac_pi/pi_global_norm | 1.4395803  |
| training/sac_pi/policy_loss    | -208.82065 |
| training/sac_pi/std            | 0.5010005  |
| training/sac_pi/valid_num      | 4983.0     |
| training/sac_Q/q1              | 202.86035  |
| training/sac_Q/q2              | 200.76254  |
| training/sac_Q/q2_loss         | 133.31104  |
| training/sac_Q/q_global_norm   | 288.16562  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17224592  |
| epoch                          | 330         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4678.9585   |
| evaluation/return-max          | 4722.2207   |
| evaluation/return-min          | 4632.84     |
| evaluation/return-std          | 33.991333   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46026       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4678.9585   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 204.5312    |
| Q-std                          | 118.105896  |
| Q_loss                         | 109.22203   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 330         |
| times/epoch_after_hook         | 2.07e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000817    |
| times/evaluation_paths         | 35.3        |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 59.8        |
| timestep                       | 1000        |
| timesteps_total                | 331000      |
| train-steps                    | 331000      |
| training/Q/q1_loss             | 106.02584   |
| training/sac_pi/alpha          | 0.17222334  |
| training/sac_pi/alpha_loss     | -0.05786643 |
| training/sac_pi/logp_pi        | 4.991279    |
| training/sac_pi/pi_entropy     | 3.6024444   |
| training/sac_pi/pi_global_norm | 2.091483    |
| training/sac_pi/policy_loss    | -212.7772   |
| training/sac_pi/std            | 0.54688823  |
| training/sac_pi/valid_num      | 4922.0      |
| training/sac_Q/q1              | 200.85075   |
| training/sac_Q/q2              | 199.50075   |
| training/sac_Q/q2_loss         | 106.04722   |
| training/sac_Q/q_global_norm   | 247.35822   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1698409  |
| epoch                          | 331        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5013.726   |
| evaluation/return-max          | 5084.4014  |
| evaluation/return-min          | 4927.458   |
| evaluation/return-std          | 46.591568  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 87.2       |
| model/penalty_ret              | 82.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46072      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5013.726   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 204.64401  |
| Q-std                          | 107.48404  |
| Q_loss                         | 100.83307  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 331        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000626   |
| times/evaluation_paths         | 33.8       |
| times/timestep_after_hook      | 0.00428    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 332000     |
| train-steps                    | 332000     |
| training/Q/q1_loss             | 99.71981   |
| training/sac_pi/alpha          | 0.16976523 |
| training/sac_pi/alpha_loss     | 0.13855325 |
| training/sac_pi/logp_pi        | 3.7505424  |
| training/sac_pi/pi_entropy     | 3.3835258  |
| training/sac_pi/pi_global_norm | 1.7588751  |
| training/sac_pi/policy_loss    | -212.85014 |
| training/sac_pi/std            | 0.47601098 |
| training/sac_pi/valid_num      | 5025.0     |
| training/sac_Q/q1              | 208.81413  |
| training/sac_Q/q2              | 207.6116   |
| training/sac_Q/q2_loss         | 98.70751   |
| training/sac_Q/q_global_norm   | 245.84424  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17019163 |
| epoch                          | 332        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4750.5767  |
| evaluation/return-max          | 4782.048   |
| evaluation/return-min          | 4732.157   |
| evaluation/return-std          | 19.422333  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46042      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4750.5767  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 197.67278  |
| Q-std                          | 106.585625 |
| Q_loss                         | 132.81145  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 332        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000657   |
| times/evaluation_paths         | 33.6       |
| times/timestep_after_hook      | 0.00409    |
| times/timestep_before_hook     | 0.00856    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 333000     |
| train-steps                    | 333000     |
| training/Q/q1_loss             | 80.11842   |
| training/sac_pi/alpha          | 0.17016098 |
| training/sac_pi/alpha_loss     | 0.1996851  |
| training/sac_pi/logp_pi        | 4.61926    |
| training/sac_pi/pi_entropy     | 3.2307465  |
| training/sac_pi/pi_global_norm | 1.7360443  |
| training/sac_pi/policy_loss    | -216.86763 |
| training/sac_pi/std            | 0.46363002 |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 209.06314  |
| training/sac_Q/q2              | 207.6315   |
| training/sac_Q/q2_loss         | 80.23553   |
| training/sac_Q/q_global_norm   | 223.17426  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17131107 |
| epoch                          | 333        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4971.673   |
| evaluation/return-max          | 5076.295   |
| evaluation/return-min          | 4902.2646  |
| evaluation/return-std          | 54.63876   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46175      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4971.673   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 201.18198  |
| Q-std                          | 100.02445  |
| Q_loss                         | 84.386566  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 333        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.00026    |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.00064    |
| times/evaluation_paths         | 33         |
| times/timestep_after_hook      | 0.0041     |
| times/timestep_before_hook     | 0.00853    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 334000     |
| train-steps                    | 334000     |
| training/Q/q1_loss             | 106.56158  |
| training/sac_pi/alpha          | 0.17132595 |
| training/sac_pi/alpha_loss     | 0.24909887 |
| training/sac_pi/logp_pi        | 5.048579   |
| training/sac_pi/pi_entropy     | 3.4289696  |
| training/sac_pi/pi_global_norm | 2.355793   |
| training/sac_pi/policy_loss    | -216.27612 |
| training/sac_pi/std            | 0.51981336 |
| training/sac_pi/valid_num      | 4929.0     |
| training/sac_Q/q1              | 205.02336  |
| training/sac_Q/q2              | 202.91264  |
| training/sac_Q/q2_loss         | 107.22853  |
| training/sac_Q/q_global_norm   | 307.97766  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17639787 |
| epoch                          | 334        |
| evaluation/episode-length-avg  | 576        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 150        |
| evaluation/episode-length-std  | 424        |
| evaluation/return-average      | 2545.027   |
| evaluation/return-max          | 4755.2007  |
| evaluation/return-min          | 392.4984   |
| evaluation/return-std          | 2148.812   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46102      |
| perf/AverageLength             | 576        |
| perf/AverageReturn             | 2545.027   |
| perf/NormalizedReturn          | 0.554      |
| Q-avg                          | 202.8365   |
| Q-std                          | 114.472275 |
| Q_loss                         | 94.974594  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 334        |
| times/epoch_after_hook         | 2e-06      |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000657   |
| times/evaluation_paths         | 20         |
| times/timestep_after_hook      | 0.00406    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 335000     |
| train-steps                    | 335000     |
| training/Q/q1_loss             | 89.782036  |
| training/sac_pi/alpha          | 0.17643145 |
| training/sac_pi/alpha_loss     | -0.3660881 |
| training/sac_pi/logp_pi        | 4.1176214  |
| training/sac_pi/pi_entropy     | 3.6531098  |
| training/sac_pi/pi_global_norm | 1.8498921  |
| training/sac_pi/policy_loss    | -223.42136 |
| training/sac_pi/std            | 0.53166497 |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 211.01218  |
| training/sac_Q/q2              | 209.66318  |
| training/sac_Q/q2_loss         | 89.19999   |
| training/sac_Q/q_global_norm   | 245.49178  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17322461   |
| epoch                          | 335          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4908.487     |
| evaluation/return-max          | 4955.541     |
| evaluation/return-min          | 4861.8525    |
| evaluation/return-std          | 28.19428     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3            |
| model/origin_ret               | 85.7         |
| model/penalty_ret              | 81.4         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46261        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4908.487     |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 215.76517    |
| Q-std                          | 104.17447    |
| Q_loss                         | 96.15803     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 335          |
| times/epoch_after_hook         | 1.95e-06     |
| times/epoch_before_hook        | 0.000144     |
| times/epoch_rollout_model      | 491          |
| times/evaluation_metrics       | 0.000629     |
| times/evaluation_paths         | 33.2         |
| times/timestep_after_hook      | 0.00414      |
| times/timestep_before_hook     | 0.0084       |
| times/train                    | 60.8         |
| timestep                       | 1000         |
| timesteps_total                | 336000       |
| train-steps                    | 336000       |
| training/Q/q1_loss             | 102.04639    |
| training/sac_pi/alpha          | 0.17318022   |
| training/sac_pi/alpha_loss     | -0.030810751 |
| training/sac_pi/logp_pi        | 4.695887     |
| training/sac_pi/pi_entropy     | 3.7243073    |
| training/sac_pi/pi_global_norm | 1.6224725    |
| training/sac_pi/policy_loss    | -211.27884   |
| training/sac_pi/std            | 0.53709686   |
| training/sac_pi/valid_num      | 4920.0       |
| training/sac_Q/q1              | 197.3104     |
| training/sac_Q/q2              | 194.96309    |
| training/sac_Q/q2_loss         | 101.186745   |
| training/sac_Q/q_global_norm   | 219.33014    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.18112686  |
| epoch                          | 336         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4800.8164   |
| evaluation/return-max          | 4837.89     |
| evaluation/return-min          | 4752.6084   |
| evaluation/return-std          | 24.219086   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46083       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4800.8164   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 212.79556   |
| Q-std                          | 110.64904   |
| Q_loss                         | 88.97537    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 336         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000221    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000558    |
| times/evaluation_paths         | 34.9        |
| times/timestep_after_hook      | 0.00407     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 337000      |
| train-steps                    | 337000      |
| training/Q/q1_loss             | 122.668365  |
| training/sac_pi/alpha          | 0.18114212  |
| training/sac_pi/alpha_loss     | 0.014911576 |
| training/sac_pi/logp_pi        | 4.7610536   |
| training/sac_pi/pi_entropy     | 3.636108    |
| training/sac_pi/pi_global_norm | 1.7323552   |
| training/sac_pi/policy_loss    | -202.79532  |
| training/sac_pi/std            | 0.5377655   |
| training/sac_pi/valid_num      | 4952.0      |
| training/sac_Q/q1              | 188.67046   |
| training/sac_Q/q2              | 187.88078   |
| training/sac_Q/q2_loss         | 124.92755   |
| training/sac_Q/q_global_norm   | 274.65146   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16835347  |
| epoch                          | 337         |
| evaluation/episode-length-avg  | 820         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 397         |
| evaluation/episode-length-std  | 275         |
| evaluation/return-average      | 3933.8325   |
| evaluation/return-max          | 4986.669    |
| evaluation/return-min          | 1627.8064   |
| evaluation/return-std          | 1490.9927   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46184       |
| perf/AverageLength             | 820         |
| perf/AverageReturn             | 3933.8325   |
| perf/NormalizedReturn          | 0.857       |
| Q-avg                          | 199.05266   |
| Q-std                          | 107.81031   |
| Q_loss                         | 134.73572   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 337         |
| times/epoch_after_hook         | 2.02e-06    |
| times/epoch_before_hook        | 0.000313    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000695    |
| times/evaluation_paths         | 27.6        |
| times/timestep_after_hook      | 0.00415     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 338000      |
| train-steps                    | 338000      |
| training/Q/q1_loss             | 97.965294   |
| training/sac_pi/alpha          | 0.1683451   |
| training/sac_pi/alpha_loss     | 0.011337378 |
| training/sac_pi/logp_pi        | 3.5692813   |
| training/sac_pi/pi_entropy     | 3.5247421   |
| training/sac_pi/pi_global_norm | 1.5105711   |
| training/sac_pi/policy_loss    | -211.74976  |
| training/sac_pi/std            | 0.48465163  |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 206.00693   |
| training/sac_Q/q2              | 205.61551   |
| training/sac_Q/q2_loss         | 97.920944   |
| training/sac_Q/q_global_norm   | 269.41367   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17405808  |
| epoch                          | 338         |
| evaluation/episode-length-avg  | 735         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 117         |
| evaluation/episode-length-std  | 404         |
| evaluation/return-average      | 3583.2905   |
| evaluation/return-max          | 5027.5474   |
| evaluation/return-min          | 298.9847    |
| evaluation/return-std          | 2144.921    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 82.8        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46140       |
| perf/AverageLength             | 735         |
| perf/AverageReturn             | 3583.2905   |
| perf/NormalizedReturn          | 0.78        |
| Q-avg                          | 204.10318   |
| Q-std                          | 115.589836  |
| Q_loss                         | 82.325966   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 338         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000591    |
| times/evaluation_paths         | 26.3        |
| times/timestep_after_hook      | 0.00409     |
| times/timestep_before_hook     | 0.00869     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 339000      |
| train-steps                    | 339000      |
| training/Q/q1_loss             | 91.2743     |
| training/sac_pi/alpha          | 0.17409849  |
| training/sac_pi/alpha_loss     | -0.24320997 |
| training/sac_pi/logp_pi        | 3.4906185   |
| training/sac_pi/pi_entropy     | 3.5450797   |
| training/sac_pi/pi_global_norm | 1.4842126   |
| training/sac_pi/policy_loss    | -210.5099   |
| training/sac_pi/std            | 0.47865167  |
| training/sac_pi/valid_num      | 5026.0      |
| training/sac_Q/q1              | 206.77676   |
| training/sac_Q/q2              | 207.03682   |
| training/sac_Q/q2_loss         | 90.993126   |
| training/sac_Q/q_global_norm   | 217.20866   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17262714  |
| epoch                          | 339         |
| evaluation/episode-length-avg  | 913         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 129         |
| evaluation/episode-length-std  | 261         |
| evaluation/return-average      | 4459.376    |
| evaluation/return-max          | 5000.4966   |
| evaluation/return-min          | 308.05423   |
| evaluation/return-std          | 1384.1461   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46141       |
| perf/AverageLength             | 913         |
| perf/AverageReturn             | 4459.376    |
| perf/NormalizedReturn          | 0.971       |
| Q-avg                          | 208.24104   |
| Q-std                          | 100.84257   |
| Q_loss                         | 95.995544   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 339         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.00052     |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00424     |
| times/timestep_before_hook     | 0.00846     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 340000      |
| train-steps                    | 340000      |
| training/Q/q1_loss             | 90.386734   |
| training/sac_pi/alpha          | 0.17264016  |
| training/sac_pi/alpha_loss     | -0.22224054 |
| training/sac_pi/logp_pi        | 3.539       |
| training/sac_pi/pi_entropy     | 3.5151691   |
| training/sac_pi/pi_global_norm | 1.3157588   |
| training/sac_pi/policy_loss    | -208.3544   |
| training/sac_pi/std            | 0.48032534  |
| training/sac_pi/valid_num      | 5036.0      |
| training/sac_Q/q1              | 204.80307   |
| training/sac_Q/q2              | 204.91147   |
| training/sac_Q/q2_loss         | 89.60508    |
| training/sac_Q/q_global_norm   | 221.33385   |
---------------------------------------------------------------------------------
[WARN] 340 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16859506 |
| epoch                          | 340        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4824.915   |
| evaluation/return-max          | 4865.068   |
| evaluation/return-min          | 4785.1924  |
| evaluation/return-std          | 22.890844  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46354      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4824.915   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 198.03008  |
| Q-std                          | 149.66637  |
| Q_loss                         | 102.90647  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 340        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000595   |
| times/evaluation_paths         | 33.6       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 341000     |
| train-steps                    | 341000     |
| training/Q/q1_loss             | 83.63137   |
| training/sac_pi/alpha          | 0.16857295 |
| training/sac_pi/alpha_loss     | 0.1045931  |
| training/sac_pi/logp_pi        | 4.2427526  |
| training/sac_pi/pi_entropy     | 3.3268943  |
| training/sac_pi/pi_global_norm | 1.9357096  |
| training/sac_pi/policy_loss    | -217.60002 |
| training/sac_pi/std            | 0.4767075  |
| training/sac_pi/valid_num      | 5014.0     |
| training/sac_Q/q1              | 208.26297  |
| training/sac_Q/q2              | 206.53658  |
| training/sac_Q/q2_loss         | 84.892494  |
| training/sac_Q/q_global_norm   | 253.46446  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1709367   |
| epoch                          | 341         |
| evaluation/episode-length-avg  | 988         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 882         |
| evaluation/episode-length-std  | 35.4        |
| evaluation/return-average      | 4860.138    |
| evaluation/return-max          | 4989.983    |
| evaluation/return-min          | 4288.978    |
| evaluation/return-std          | 194.76022   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46108       |
| perf/AverageLength             | 988         |
| perf/AverageReturn             | 4860.138    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 194.12497   |
| Q-std                          | 107.98909   |
| Q_loss                         | 90.532265   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 341         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000266    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000575    |
| times/evaluation_paths         | 34.6        |
| times/timestep_after_hook      | 0.00407     |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 59.9        |
| timestep                       | 1000        |
| timesteps_total                | 342000      |
| train-steps                    | 342000      |
| training/Q/q1_loss             | 107.81904   |
| training/sac_pi/alpha          | 0.17097293  |
| training/sac_pi/alpha_loss     | -0.26697132 |
| training/sac_pi/logp_pi        | 4.558814    |
| training/sac_pi/pi_entropy     | 3.6617115   |
| training/sac_pi/pi_global_norm | 1.5411227   |
| training/sac_pi/policy_loss    | -211.0268   |
| training/sac_pi/std            | 0.52807844  |
| training/sac_pi/valid_num      | 4950.0      |
| training/sac_Q/q1              | 200.11526   |
| training/sac_Q/q2              | 197.97731   |
| training/sac_Q/q2_loss         | 106.7495    |
| training/sac_Q/q_global_norm   | 224.71751   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17099462 |
| epoch                          | 342        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5205.2744  |
| evaluation/return-max          | 5258.6543  |
| evaluation/return-min          | 5113.939   |
| evaluation/return-std          | 49.495663  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46064      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5205.2744  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 200.53069  |
| Q-std                          | 108.337326 |
| Q_loss                         | 121.28386  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 342        |
| times/epoch_after_hook         | 2e-06      |
| times/epoch_before_hook        | 0.00014    |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000628   |
| times/evaluation_paths         | 33.4       |
| times/timestep_after_hook      | 0.0041     |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 60.2       |
| timestep                       | 1000       |
| timesteps_total                | 343000     |
| train-steps                    | 343000     |
| training/Q/q1_loss             | 100.94719  |
| training/sac_pi/alpha          | 0.17095898 |
| training/sac_pi/alpha_loss     | 0.10398498 |
| training/sac_pi/logp_pi        | 4.816072   |
| training/sac_pi/pi_entropy     | 3.4433231  |
| training/sac_pi/pi_global_norm | 1.3571029  |
| training/sac_pi/policy_loss    | -211.99384 |
| training/sac_pi/std            | 0.49918348 |
| training/sac_pi/valid_num      | 4974.0     |
| training/sac_Q/q1              | 204.6555   |
| training/sac_Q/q2              | 203.87375  |
| training/sac_Q/q2_loss         | 99.92508   |
| training/sac_Q/q_global_norm   | 226.60063  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16788174 |
| epoch                          | 343        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5173.878   |
| evaluation/return-max          | 5195.3857  |
| evaluation/return-min          | 5147.3145  |
| evaluation/return-std          | 17.68997   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45999      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5173.878   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 207.64189  |
| Q-std                          | 98.353745  |
| Q_loss                         | 89.39428   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 343        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000604   |
| times/evaluation_paths         | 33.1       |
| times/timestep_after_hook      | 0.00419    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 344000     |
| train-steps                    | 344000     |
| training/Q/q1_loss             | 95.38714   |
| training/sac_pi/alpha          | 0.1679221  |
| training/sac_pi/alpha_loss     | -0.139492  |
| training/sac_pi/logp_pi        | 4.297423   |
| training/sac_pi/pi_entropy     | 3.5000198  |
| training/sac_pi/pi_global_norm | 1.5536398  |
| training/sac_pi/policy_loss    | -217.40453 |
| training/sac_pi/std            | 0.5147921  |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 210.44478  |
| training/sac_Q/q2              | 209.66983  |
| training/sac_Q/q2_loss         | 95.2594    |
| training/sac_Q/q_global_norm   | 211.47656  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16983128   |
| epoch                          | 344          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5084.154     |
| evaluation/return-max          | 5120.0015    |
| evaluation/return-min          | 5012.882     |
| evaluation/return-std          | 31.384813    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.02         |
| model/origin_ret               | 86.1         |
| model/penalty_ret              | 82.4         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46043        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5084.154     |
| perf/NormalizedReturn          | 1.11         |
| Q-avg                          | 210.92773    |
| Q-std                          | 89.78958     |
| Q_loss                         | 108.57749    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 344          |
| times/epoch_after_hook         | 2.1e-06      |
| times/epoch_before_hook        | 0.000132     |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.000627     |
| times/evaluation_paths         | 35.3         |
| times/timestep_after_hook      | 0.00407      |
| times/timestep_before_hook     | 0.00863      |
| times/train                    | 60.7         |
| timestep                       | 1000         |
| timesteps_total                | 345000       |
| train-steps                    | 345000       |
| training/Q/q1_loss             | 117.037796   |
| training/sac_pi/alpha          | 0.16985038   |
| training/sac_pi/alpha_loss     | -0.039452378 |
| training/sac_pi/logp_pi        | 4.6836424    |
| training/sac_pi/pi_entropy     | 3.5676665    |
| training/sac_pi/pi_global_norm | 2.0026448    |
| training/sac_pi/policy_loss    | -216.38766   |
| training/sac_pi/std            | 0.5381721    |
| training/sac_pi/valid_num      | 4924.0       |
| training/sac_Q/q1              | 204.14871    |
| training/sac_Q/q2              | 203.76453    |
| training/sac_Q/q2_loss         | 115.752464   |
| training/sac_Q/q_global_norm   | 236.70203    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16857108 |
| epoch                          | 345        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5132.8613  |
| evaluation/return-max          | 5198.3647  |
| evaluation/return-min          | 5087.841   |
| evaluation/return-std          | 29.181965  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46231      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5132.8613  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 205.5192   |
| Q-std                          | 103.68521  |
| Q_loss                         | 99.736984  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 345        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000264   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000666   |
| times/evaluation_paths         | 33.4       |
| times/timestep_after_hook      | 0.00421    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 346000     |
| train-steps                    | 346000     |
| training/Q/q1_loss             | 90.98069   |
| training/sac_pi/alpha          | 0.16855747 |
| training/sac_pi/alpha_loss     | 0.15186334 |
| training/sac_pi/logp_pi        | 4.187616   |
| training/sac_pi/pi_entropy     | 3.4010582  |
| training/sac_pi/pi_global_norm | 1.5500927  |
| training/sac_pi/policy_loss    | -217.86687 |
| training/sac_pi/std            | 0.4799005  |
| training/sac_pi/valid_num      | 5014.0     |
| training/sac_Q/q1              | 212.26257  |
| training/sac_Q/q2              | 212.00162  |
| training/sac_Q/q2_loss         | 90.49663   |
| training/sac_Q/q_global_norm   | 263.1102   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17452897  |
| epoch                          | 346         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4659.3247   |
| evaluation/return-max          | 4748.272    |
| evaluation/return-min          | 4522.732    |
| evaluation/return-std          | 63.045963   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46295       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4659.3247   |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 204.36443   |
| Q-std                          | 113.29645   |
| Q_loss                         | 109.0415    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 346         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000143    |
| times/epoch_rollout_model      | 503         |
| times/evaluation_metrics       | 0.00056     |
| times/evaluation_paths         | 36.4        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 347000      |
| train-steps                    | 347000      |
| training/Q/q1_loss             | 101.03243   |
| training/sac_pi/alpha          | 0.17453969  |
| training/sac_pi/alpha_loss     | 0.058004893 |
| training/sac_pi/logp_pi        | 4.4351907   |
| training/sac_pi/pi_entropy     | 3.5814552   |
| training/sac_pi/pi_global_norm | 1.5404496   |
| training/sac_pi/policy_loss    | -209.98245  |
| training/sac_pi/std            | 0.52343297  |
| training/sac_pi/valid_num      | 4907.0      |
| training/sac_Q/q1              | 199.29509   |
| training/sac_Q/q2              | 197.74777   |
| training/sac_Q/q2_loss         | 100.48209   |
| training/sac_Q/q_global_norm   | 289.04584   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1782609   |
| epoch                          | 347         |
| evaluation/episode-length-avg  | 731         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 422         |
| evaluation/episode-length-std  | 233         |
| evaluation/return-average      | 3542.2664   |
| evaluation/return-max          | 5068.8984   |
| evaluation/return-min          | 1810.9712   |
| evaluation/return-std          | 1291.2031   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46265       |
| perf/AverageLength             | 731         |
| perf/AverageReturn             | 3542.2664   |
| perf/NormalizedReturn          | 0.771       |
| Q-avg                          | 209.471     |
| Q-std                          | 92.21095    |
| Q_loss                         | 90.46956    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 347         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000729    |
| times/evaluation_paths         | 25.1        |
| times/timestep_after_hook      | 0.00414     |
| times/timestep_before_hook     | 0.0087      |
| times/train                    | 60          |
| timestep                       | 1000        |
| timesteps_total                | 348000      |
| train-steps                    | 348000      |
| training/Q/q1_loss             | 94.8973     |
| training/sac_pi/alpha          | 0.17827676  |
| training/sac_pi/alpha_loss     | -0.24297257 |
| training/sac_pi/logp_pi        | 4.5803704   |
| training/sac_pi/pi_entropy     | 3.6288986   |
| training/sac_pi/pi_global_norm | 1.4132526   |
| training/sac_pi/policy_loss    | -216.06067  |
| training/sac_pi/std            | 0.5262883   |
| training/sac_pi/valid_num      | 4953.0      |
| training/sac_Q/q1              | 204.63814   |
| training/sac_Q/q2              | 202.91435   |
| training/sac_Q/q2_loss         | 95.07357    |
| training/sac_Q/q_global_norm   | 234.53125   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17602052  |
| epoch                          | 348         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4696.159    |
| evaluation/return-max          | 4757.0874   |
| evaluation/return-min          | 4607.132    |
| evaluation/return-std          | 49.909195   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46179       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4696.159    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 208.34018   |
| Q-std                          | 108.682045  |
| Q_loss                         | 81.01214    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 348         |
| times/epoch_after_hook         | 1.99e-06    |
| times/epoch_before_hook        | 0.000136    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000563    |
| times/evaluation_paths         | 33.6        |
| times/timestep_after_hook      | 0.00407     |
| times/timestep_before_hook     | 0.00855     |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 349000      |
| train-steps                    | 349000      |
| training/Q/q1_loss             | 69.42936    |
| training/sac_pi/alpha          | 0.17604925  |
| training/sac_pi/alpha_loss     | -0.27945906 |
| training/sac_pi/logp_pi        | 3.6894882   |
| training/sac_pi/pi_entropy     | 3.3772247   |
| training/sac_pi/pi_global_norm | 1.376239    |
| training/sac_pi/policy_loss    | -221.78578  |
| training/sac_pi/std            | 0.4755207   |
| training/sac_pi/valid_num      | 4989.0      |
| training/sac_Q/q1              | 216.1453    |
| training/sac_Q/q2              | 215.80093   |
| training/sac_Q/q2_loss         | 69.85463    |
| training/sac_Q/q_global_norm   | 191.16881   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16852257 |
| epoch                          | 349        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4608.048   |
| evaluation/return-max          | 4887.302   |
| evaluation/return-min          | 4339.0063  |
| evaluation/return-std          | 151.38171  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46211      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4608.048   |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 207.0542   |
| Q-std                          | 103.398186 |
| Q_loss                         | 89.17829   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 349        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000283   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000601   |
| times/evaluation_paths         | 34         |
| times/timestep_after_hook      | 0.00408    |
| times/timestep_before_hook     | 0.0108     |
| times/train                    | 61.5       |
| timestep                       | 1000       |
| timesteps_total                | 350000     |
| train-steps                    | 350000     |
| training/Q/q1_loss             | 94.645355  |
| training/sac_pi/alpha          | 0.16850261 |
| training/sac_pi/alpha_loss     | 0.56498843 |
| training/sac_pi/logp_pi        | 4.2015576  |
| training/sac_pi/pi_entropy     | 3.3465202  |
| training/sac_pi/pi_global_norm | 1.7319013  |
| training/sac_pi/policy_loss    | -213.77094 |
| training/sac_pi/std            | 0.47038758 |
| training/sac_pi/valid_num      | 5029.0     |
| training/sac_Q/q1              | 208.60689  |
| training/sac_Q/q2              | 208.56778  |
| training/sac_Q/q2_loss         | 94.45728   |
| training/sac_Q/q_global_norm   | 183.52286  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16708206 |
| epoch                          | 350        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4977.05    |
| evaluation/return-max          | 5029.358   |
| evaluation/return-min          | 4940.499   |
| evaluation/return-std          | 22.218424  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 83.4       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46206      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4977.05    |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 207.32822  |
| Q-std                          | 105.08253  |
| Q_loss                         | 91.35561   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 350        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000591   |
| times/evaluation_paths         | 33.6       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 351000     |
| train-steps                    | 351000     |
| training/Q/q1_loss             | 112.92385  |
| training/sac_pi/alpha          | 0.16708304 |
| training/sac_pi/alpha_loss     | -0.4079433 |
| training/sac_pi/logp_pi        | 5.0609937  |
| training/sac_pi/pi_entropy     | 3.3960845  |
| training/sac_pi/pi_global_norm | 1.6252568  |
| training/sac_pi/policy_loss    | -217.58292 |
| training/sac_pi/std            | 0.52143794 |
| training/sac_pi/valid_num      | 4949.0     |
| training/sac_Q/q1              | 208.78516  |
| training/sac_Q/q2              | 208.226    |
| training/sac_Q/q2_loss         | 112.48971  |
| training/sac_Q/q_global_norm   | 256.4977   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.169219   |
| epoch                          | 351        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4485.7295  |
| evaluation/return-max          | 4527.8916  |
| evaluation/return-min          | 4438.3013  |
| evaluation/return-std          | 24.87255   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46060      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4485.7295  |
| perf/NormalizedReturn          | 0.977      |
| Q-avg                          | 206.53764  |
| Q-std                          | 117.69399  |
| Q_loss                         | 106.44832  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 351        |
| times/epoch_after_hook         | 2e-06      |
| times/epoch_before_hook        | 0.000155   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000544   |
| times/evaluation_paths         | 33.6       |
| times/timestep_after_hook      | 0.00468    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 63.5       |
| timestep                       | 1000       |
| timesteps_total                | 352000     |
| train-steps                    | 352000     |
| training/Q/q1_loss             | 94.44739   |
| training/sac_pi/alpha          | 0.16918723 |
| training/sac_pi/alpha_loss     | 0.54835856 |
| training/sac_pi/logp_pi        | 4.0564384  |
| training/sac_pi/pi_entropy     | 3.3881142  |
| training/sac_pi/pi_global_norm | 1.5879743  |
| training/sac_pi/policy_loss    | -210.0821  |
| training/sac_pi/std            | 0.4693925  |
| training/sac_pi/valid_num      | 5050.0     |
| training/sac_Q/q1              | 207.78532  |
| training/sac_Q/q2              | 207.39932  |
| training/sac_Q/q2_loss         | 95.22578   |
| training/sac_Q/q_global_norm   | 283.47165  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17061247  |
| epoch                          | 352         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4960.4497   |
| evaluation/return-max          | 5012.802    |
| evaluation/return-min          | 4913.428    |
| evaluation/return-std          | 25.993555   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46145       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4960.4497   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 205.8864    |
| Q-std                          | 107.48182   |
| Q_loss                         | 105.09974   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 352         |
| times/epoch_after_hook         | 1.93e-06    |
| times/epoch_before_hook        | 0.00016     |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000578    |
| times/evaluation_paths         | 37          |
| times/timestep_after_hook      | 0.00408     |
| times/timestep_before_hook     | 0.0086      |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 353000      |
| train-steps                    | 353000      |
| training/Q/q1_loss             | 99.50627    |
| training/sac_pi/alpha          | 0.1706063   |
| training/sac_pi/alpha_loss     | -0.16144852 |
| training/sac_pi/logp_pi        | 4.3579035   |
| training/sac_pi/pi_entropy     | 3.353625    |
| training/sac_pi/pi_global_norm | 1.6126682   |
| training/sac_pi/policy_loss    | -215.15283  |
| training/sac_pi/std            | 0.48062623  |
| training/sac_pi/valid_num      | 4950.0      |
| training/sac_Q/q1              | 204.31815   |
| training/sac_Q/q2              | 204.07137   |
| training/sac_Q/q2_loss         | 99.678925   |
| training/sac_Q/q_global_norm   | 300.28134   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17225036 |
| epoch                          | 353        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5074.677   |
| evaluation/return-max          | 5143.4985  |
| evaluation/return-min          | 5028.424   |
| evaluation/return-std          | 39.3746    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46063      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5074.677   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 196.52151  |
| Q-std                          | 112.04359  |
| Q_loss                         | 98.91985   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 353        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000271   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000633   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.0042     |
| times/timestep_before_hook     | 0.00852    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 354000     |
| train-steps                    | 354000     |
| training/Q/q1_loss             | 110.39426  |
| training/sac_pi/alpha          | 0.17223682 |
| training/sac_pi/alpha_loss     | 0.12181855 |
| training/sac_pi/logp_pi        | 4.0906067  |
| training/sac_pi/pi_entropy     | 3.496589   |
| training/sac_pi/pi_global_norm | 1.6939495  |
| training/sac_pi/policy_loss    | -209.89363 |
| training/sac_pi/std            | 0.4992066  |
| training/sac_pi/valid_num      | 4998.0     |
| training/sac_Q/q1              | 204.52676  |
| training/sac_Q/q2              | 203.20676  |
| training/sac_Q/q2_loss         | 110.95501  |
| training/sac_Q/q_global_norm   | 308.3682   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17266324  |
| epoch                          | 354         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4767.2725   |
| evaluation/return-max          | 4926.6064   |
| evaluation/return-min          | 4703.782    |
| evaluation/return-std          | 71.159386   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46185       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4767.2725   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 209.51831   |
| Q-std                          | 117.7104    |
| Q_loss                         | 100.78606   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 354         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000641    |
| times/evaluation_paths         | 33.8        |
| times/timestep_after_hook      | 0.00426     |
| times/timestep_before_hook     | 0.00867     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 355000      |
| train-steps                    | 355000      |
| training/Q/q1_loss             | 103.050896  |
| training/sac_pi/alpha          | 0.17266454  |
| training/sac_pi/alpha_loss     | -0.04325084 |
| training/sac_pi/logp_pi        | 4.423142    |
| training/sac_pi/pi_entropy     | 3.6849575   |
| training/sac_pi/pi_global_norm | 2.1041453   |
| training/sac_pi/policy_loss    | -210.06152  |
| training/sac_pi/std            | 0.5152989   |
| training/sac_pi/valid_num      | 4865.0      |
| training/sac_Q/q1              | 198.86794   |
| training/sac_Q/q2              | 197.59921   |
| training/sac_Q/q2_loss         | 104.03556   |
| training/sac_Q/q_global_norm   | 269.03955   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17536362 |
| epoch                          | 355        |
| evaluation/episode-length-avg  | 479        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 122        |
| evaluation/episode-length-std  | 426        |
| evaluation/return-average      | 2084.899   |
| evaluation/return-max          | 4814.99    |
| evaluation/return-min          | 310.6875   |
| evaluation/return-std          | 2136.8433  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46190      |
| perf/AverageLength             | 479        |
| perf/AverageReturn             | 2084.899   |
| perf/NormalizedReturn          | 0.454      |
| Q-avg                          | 206.5876   |
| Q-std                          | 115.51277  |
| Q_loss                         | 101.66163  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 355        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000224   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000501   |
| times/evaluation_paths         | 16.6       |
| times/timestep_after_hook      | 0.00417    |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 356000     |
| train-steps                    | 356000     |
| training/Q/q1_loss             | 102.70005  |
| training/sac_pi/alpha          | 0.17530337 |
| training/sac_pi/alpha_loss     | 0.33634233 |
| training/sac_pi/logp_pi        | 4.2767344  |
| training/sac_pi/pi_entropy     | 3.5008202  |
| training/sac_pi/pi_global_norm | 1.8422388  |
| training/sac_pi/policy_loss    | -211.49367 |
| training/sac_pi/std            | 0.49415043 |
| training/sac_pi/valid_num      | 4976.0     |
| training/sac_Q/q1              | 201.56763  |
| training/sac_Q/q2              | 199.33102  |
| training/sac_Q/q2_loss         | 103.351776 |
| training/sac_Q/q_global_norm   | 247.3992   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16850632  |
| epoch                          | 356         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4861.986    |
| evaluation/return-max          | 4946.434    |
| evaluation/return-min          | 4792.3096   |
| evaluation/return-std          | 45.740704   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46107       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4861.986    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 204.42041   |
| Q-std                          | 107.23895   |
| Q_loss                         | 101.74095   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 356         |
| times/epoch_after_hook         | 2.16e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000764    |
| times/evaluation_paths         | 33.6        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.00865     |
| times/train                    | 59.8        |
| timestep                       | 1000        |
| timesteps_total                | 357000      |
| train-steps                    | 357000      |
| training/Q/q1_loss             | 80.5542     |
| training/sac_pi/alpha          | 0.16848955  |
| training/sac_pi/alpha_loss     | 0.027673973 |
| training/sac_pi/logp_pi        | 4.427673    |
| training/sac_pi/pi_entropy     | 3.4731154   |
| training/sac_pi/pi_global_norm | 1.8453138   |
| training/sac_pi/policy_loss    | -208.40164  |
| training/sac_pi/std            | 0.50426084  |
| training/sac_pi/valid_num      | 4979.0      |
| training/sac_Q/q1              | 199.63263   |
| training/sac_Q/q2              | 199.69324   |
| training/sac_Q/q2_loss         | 80.433655   |
| training/sac_Q/q_global_norm   | 250.924     |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16807802 |
| epoch                          | 357        |
| evaluation/episode-length-avg  | 647        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 116        |
| evaluation/episode-length-std  | 432        |
| evaluation/return-average      | 3106.4617  |
| evaluation/return-max          | 5119.0273  |
| evaluation/return-min          | 298.59125  |
| evaluation/return-std          | 2290.3428  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46167      |
| perf/AverageLength             | 647        |
| perf/AverageReturn             | 3106.4617  |
| perf/NormalizedReturn          | 0.676      |
| Q-avg                          | 199.37431  |
| Q-std                          | 104.58937  |
| Q_loss                         | 110.68444  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 357        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000382   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000562   |
| times/evaluation_paths         | 22.2       |
| times/timestep_after_hook      | 0.0042     |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 358000     |
| train-steps                    | 358000     |
| training/Q/q1_loss             | 91.43431   |
| training/sac_pi/alpha          | 0.16801843 |
| training/sac_pi/alpha_loss     | 0.536652   |
| training/sac_pi/logp_pi        | 4.9287696  |
| training/sac_pi/pi_entropy     | 3.3850334  |
| training/sac_pi/pi_global_norm | 1.7030545  |
| training/sac_pi/policy_loss    | -214.93431 |
| training/sac_pi/std            | 0.51012063 |
| training/sac_pi/valid_num      | 4944.0     |
| training/sac_Q/q1              | 206.28671  |
| training/sac_Q/q2              | 206.41537  |
| training/sac_Q/q2_loss         | 91.45333   |
| training/sac_Q/q_global_norm   | 233.5003   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16692653 |
| epoch                          | 358        |
| evaluation/episode-length-avg  | 237        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 143        |
| evaluation/episode-length-std  | 254        |
| evaluation/return-average      | 910.58923  |
| evaluation/return-max          | 5330.95    |
| evaluation/return-min          | 376.29266  |
| evaluation/return-std          | 1473.7136  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46078      |
| perf/AverageLength             | 237        |
| perf/AverageReturn             | 910.58923  |
| perf/NormalizedReturn          | 0.198      |
| Q-avg                          | 195.07579  |
| Q-std                          | 158.5641   |
| Q_loss                         | 113.4466   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 358        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000144   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000736   |
| times/evaluation_paths         | 8.55       |
| times/timestep_after_hook      | 0.0041     |
| times/timestep_before_hook     | 0.00851    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 359000     |
| train-steps                    | 359000     |
| training/Q/q1_loss             | 114.20804  |
| training/sac_pi/alpha          | 0.16691785 |
| training/sac_pi/alpha_loss     | 0.34314665 |
| training/sac_pi/logp_pi        | 4.4395766  |
| training/sac_pi/pi_entropy     | 3.5062516  |
| training/sac_pi/pi_global_norm | 1.4656961  |
| training/sac_pi/policy_loss    | -212.14699 |
| training/sac_pi/std            | 0.5079926  |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 203.24826  |
| training/sac_Q/q2              | 203.63684  |
| training/sac_Q/q2_loss         | 114.25513  |
| training/sac_Q/q_global_norm   | 271.65723  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1700734  |
| epoch                          | 359        |
| evaluation/episode-length-avg  | 491        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 151        |
| evaluation/episode-length-std  | 416        |
| evaluation/return-average      | 2063.4688  |
| evaluation/return-max          | 4730.6113  |
| evaluation/return-min          | 350.80054  |
| evaluation/return-std          | 2090.8298  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46154      |
| perf/AverageLength             | 491        |
| perf/AverageReturn             | 2063.4688  |
| perf/NormalizedReturn          | 0.449      |
| Q-avg                          | 211.1694   |
| Q-std                          | 90.969765  |
| Q_loss                         | 91.007095  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 359        |
| times/epoch_after_hook         | 8.21e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000617   |
| times/evaluation_paths         | 17.4       |
| times/timestep_after_hook      | 0.00422    |
| times/timestep_before_hook     | 0.00871    |
| times/train                    | 62.9       |
| timestep                       | 1000       |
| timesteps_total                | 360000     |
| train-steps                    | 360000     |
| training/Q/q1_loss             | 83.01747   |
| training/sac_pi/alpha          | 0.1700534  |
| training/sac_pi/alpha_loss     | 0.19572231 |
| training/sac_pi/logp_pi        | 4.5420027  |
| training/sac_pi/pi_entropy     | 3.3616066  |
| training/sac_pi/pi_global_norm | 1.9317608  |
| training/sac_pi/policy_loss    | -212.77917 |
| training/sac_pi/std            | 0.48411098 |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 203.46957  |
| training/sac_Q/q2              | 201.1666   |
| training/sac_Q/q2_loss         | 83.66783   |
| training/sac_Q/q_global_norm   | 254.74785  |
--------------------------------------------------------------------------------
[WARN] 360 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.17108421 |
| epoch                          | 360        |
| evaluation/episode-length-avg  | 862        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 311        |
| evaluation/episode-length-std  | 275        |
| evaluation/return-average      | 4212.96    |
| evaluation/return-max          | 5170.5     |
| evaluation/return-min          | 1209.6185  |
| evaluation/return-std          | 1500.379   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46206      |
| perf/AverageLength             | 862        |
| perf/AverageReturn             | 4212.96    |
| perf/NormalizedReturn          | 0.917      |
| Q-avg                          | 219.35873  |
| Q-std                          | 89.1759    |
| Q_loss                         | 90.39043   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 360        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000141   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000522   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.00423    |
| times/timestep_before_hook     | 0.00866    |
| times/train                    | 71.1       |
| timestep                       | 1000       |
| timesteps_total                | 361000     |
| train-steps                    | 361000     |
| training/Q/q1_loss             | 129.93568  |
| training/sac_pi/alpha          | 0.17109393 |
| training/sac_pi/alpha_loss     | -0.4378438 |
| training/sac_pi/logp_pi        | 4.0809326  |
| training/sac_pi/pi_entropy     | 3.5572648  |
| training/sac_pi/pi_global_norm | 1.7676927  |
| training/sac_pi/policy_loss    | -210.35764 |
| training/sac_pi/std            | 0.5052029  |
| training/sac_pi/valid_num      | 4976.0     |
| training/sac_Q/q1              | 203.59355  |
| training/sac_Q/q2              | 200.90938  |
| training/sac_Q/q2_loss         | 130.5458   |
| training/sac_Q/q_global_norm   | 240.1349   |
--------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.17452669    |
| epoch                          | 361           |
| evaluation/episode-length-avg  | 185           |
| evaluation/episode-length-max  | 367           |
| evaluation/episode-length-min  | 161           |
| evaluation/episode-length-std  | 60.8          |
| evaluation/return-average      | 458.58072     |
| evaluation/return-max          | 1158.237      |
| evaluation/return-min          | 374.38336     |
| evaluation/return-std          | 233.27322     |
| model/max_penalty              | 7.27          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 2.98          |
| model/origin_ret               | 84.5          |
| model/penalty_ret              | 81.7          |
| model/val_loss                 | 0.39125705    |
| model/valid_num                | 46167         |
| perf/AverageLength             | 185           |
| perf/AverageReturn             | 458.58072     |
| perf/NormalizedReturn          | 0.0995        |
| Q-avg                          | 203.33614     |
| Q-std                          | 131.52997     |
| Q_loss                         | 93.89045      |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 361           |
| times/epoch_after_hook         | 1.94e-06      |
| times/epoch_before_hook        | 0.000258      |
| times/epoch_rollout_model      | 491           |
| times/evaluation_metrics       | 0.000643      |
| times/evaluation_paths         | 6.12          |
| times/timestep_after_hook      | 0.00415       |
| times/timestep_before_hook     | 0.00846       |
| times/train                    | 60.5          |
| timestep                       | 1000          |
| timesteps_total                | 362000        |
| train-steps                    | 362000        |
| training/Q/q1_loss             | 118.00166     |
| training/sac_pi/alpha          | 0.17449708    |
| training/sac_pi/alpha_loss     | 0.00016644705 |
| training/sac_pi/logp_pi        | 4.5791903     |
| training/sac_pi/pi_entropy     | 3.5317261     |
| training/sac_pi/pi_global_norm | 1.7452357     |
| training/sac_pi/policy_loss    | -209.60399    |
| training/sac_pi/std            | 0.5095559     |
| training/sac_pi/valid_num      | 4895.0        |
| training/sac_Q/q1              | 198.05933     |
| training/sac_Q/q2              | 195.41495     |
| training/sac_Q/q2_loss         | 116.78933     |
| training/sac_Q/q_global_norm   | 247.9649      |
-----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1727391  |
| epoch                          | 362        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4755.3145  |
| evaluation/return-max          | 4839.0225  |
| evaluation/return-min          | 4612.3486  |
| evaluation/return-std          | 62.91742   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46156      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4755.3145  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 212.78006  |
| Q-std                          | 111.07647  |
| Q_loss                         | 84.19118   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 362        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000619   |
| times/evaluation_paths         | 35.4       |
| times/timestep_after_hook      | 0.00421    |
| times/timestep_before_hook     | 0.00856    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 363000     |
| train-steps                    | 363000     |
| training/Q/q1_loss             | 95.605064  |
| training/sac_pi/alpha          | 0.17275496 |
| training/sac_pi/alpha_loss     | -0.1461254 |
| training/sac_pi/logp_pi        | 3.8525577  |
| training/sac_pi/pi_entropy     | 3.440761   |
| training/sac_pi/pi_global_norm | 1.4312841  |
| training/sac_pi/policy_loss    | -219.5895  |
| training/sac_pi/std            | 0.4713859  |
| training/sac_pi/valid_num      | 4960.0     |
| training/sac_Q/q1              | 210.53743  |
| training/sac_Q/q2              | 210.21619  |
| training/sac_Q/q2_loss         | 96.62075   |
| training/sac_Q/q_global_norm   | 246.76102  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17743471  |
| epoch                          | 363         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4916.546    |
| evaluation/return-max          | 5002.893    |
| evaluation/return-min          | 4867.755    |
| evaluation/return-std          | 43.33949    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45982       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4916.546    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 205.01065   |
| Q-std                          | 117.60429   |
| Q_loss                         | 97.06359    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 363         |
| times/epoch_after_hook         | 3.27e-06    |
| times/epoch_before_hook        | 0.000141    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000585    |
| times/evaluation_paths         | 37          |
| times/timestep_after_hook      | 0.00413     |
| times/timestep_before_hook     | 0.00848     |
| times/train                    | 59.4        |
| timestep                       | 1000        |
| timesteps_total                | 364000      |
| train-steps                    | 364000      |
| training/Q/q1_loss             | 118.55583   |
| training/sac_pi/alpha          | 0.17742358  |
| training/sac_pi/alpha_loss     | -0.14728653 |
| training/sac_pi/logp_pi        | 3.6181214   |
| training/sac_pi/pi_entropy     | 3.4387298   |
| training/sac_pi/pi_global_norm | 1.5828959   |
| training/sac_pi/policy_loss    | -220.61772  |
| training/sac_pi/std            | 0.4701132   |
| training/sac_pi/valid_num      | 4996.0      |
| training/sac_Q/q1              | 215.5229    |
| training/sac_Q/q2              | 215.30185   |
| training/sac_Q/q2_loss         | 118.65432   |
| training/sac_Q/q_global_norm   | 218.62396   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16899163 |
| epoch                          | 364        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4930.216   |
| evaluation/return-max          | 5014.33    |
| evaluation/return-min          | 4864.0073  |
| evaluation/return-std          | 55.688663  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46020      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4930.216   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 213.41751  |
| Q-std                          | 130.11174  |
| Q_loss                         | 77.05329   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 364        |
| times/epoch_after_hook         | 2e-06      |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000541   |
| times/evaluation_paths         | 40.4       |
| times/timestep_after_hook      | 0.00438    |
| times/timestep_before_hook     | 0.00872    |
| times/train                    | 71.1       |
| timestep                       | 1000       |
| timesteps_total                | 365000     |
| train-steps                    | 365000     |
| training/Q/q1_loss             | 92.71791   |
| training/sac_pi/alpha          | 0.16899459 |
| training/sac_pi/alpha_loss     | 0.14330539 |
| training/sac_pi/logp_pi        | 4.346787   |
| training/sac_pi/pi_entropy     | 3.398428   |
| training/sac_pi/pi_global_norm | 1.7047976  |
| training/sac_pi/policy_loss    | -216.936   |
| training/sac_pi/std            | 0.501906   |
| training/sac_pi/valid_num      | 4977.0     |
| training/sac_Q/q1              | 211.76831  |
| training/sac_Q/q2              | 209.92618  |
| training/sac_Q/q2_loss         | 92.382256  |
| training/sac_Q/q_global_norm   | 233.163    |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1766646  |
| epoch                          | 365        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5025.7085  |
| evaluation/return-max          | 5087.525   |
| evaluation/return-min          | 4983.5566  |
| evaluation/return-std          | 33.722836  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46180      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5025.7085  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 202.0156   |
| Q-std                          | 100.59301  |
| Q_loss                         | 117.58957  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 365        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.000312   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.00069    |
| times/evaluation_paths         | 32.9       |
| times/timestep_after_hook      | 0.00432    |
| times/timestep_before_hook     | 0.00863    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 366000     |
| train-steps                    | 366000     |
| training/Q/q1_loss             | 97.64837   |
| training/sac_pi/alpha          | 0.176617   |
| training/sac_pi/alpha_loss     | 0.13144562 |
| training/sac_pi/logp_pi        | 4.1264176  |
| training/sac_pi/pi_entropy     | 3.2752957  |
| training/sac_pi/pi_global_norm | 1.6480981  |
| training/sac_pi/policy_loss    | -209.99586 |
| training/sac_pi/std            | 0.46346542 |
| training/sac_pi/valid_num      | 5019.0     |
| training/sac_Q/q1              | 205.404    |
| training/sac_Q/q2              | 203.98264  |
| training/sac_Q/q2_loss         | 97.04831   |
| training/sac_Q/q_global_norm   | 215.63602  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16886963  |
| epoch                          | 366         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5099.4463   |
| evaluation/return-max          | 5213.4336   |
| evaluation/return-min          | 4984.051    |
| evaluation/return-std          | 76.82205    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46028       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5099.4463   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 206.47055   |
| Q-std                          | 123.667     |
| Q_loss                         | 99.26921    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 366         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000553    |
| times/evaluation_paths         | 33.3        |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 63.2        |
| timestep                       | 1000        |
| timesteps_total                | 367000      |
| train-steps                    | 367000      |
| training/Q/q1_loss             | 95.02279    |
| training/sac_pi/alpha          | 0.16882835  |
| training/sac_pi/alpha_loss     | 0.029856712 |
| training/sac_pi/logp_pi        | 3.6413891   |
| training/sac_pi/pi_entropy     | 3.4006977   |
| training/sac_pi/pi_global_norm | 1.5973786   |
| training/sac_pi/policy_loss    | -208.8892   |
| training/sac_pi/std            | 0.46318066  |
| training/sac_pi/valid_num      | 5059.0      |
| training/sac_Q/q1              | 206.99487   |
| training/sac_Q/q2              | 206.80391   |
| training/sac_Q/q2_loss         | 95.03988    |
| training/sac_Q/q_global_norm   | 205.32455   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16776335  |
| epoch                          | 367         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5246.7437   |
| evaluation/return-max          | 5340.967    |
| evaluation/return-min          | 5109.71     |
| evaluation/return-std          | 59.00915    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46145       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5246.7437   |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 206.48918   |
| Q-std                          | 139.2971    |
| Q_loss                         | 103.24242   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 367         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000538    |
| times/evaluation_paths         | 32.7        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.0086      |
| times/train                    | 65.2        |
| timestep                       | 1000        |
| timesteps_total                | 368000      |
| train-steps                    | 368000      |
| training/Q/q1_loss             | 105.71714   |
| training/sac_pi/alpha          | 0.16773622  |
| training/sac_pi/alpha_loss     | -0.13125323 |
| training/sac_pi/logp_pi        | 5.1435213   |
| training/sac_pi/pi_entropy     | 3.5719314   |
| training/sac_pi/pi_global_norm | 1.9234089   |
| training/sac_pi/policy_loss    | -209.30719  |
| training/sac_pi/std            | 0.5520703   |
| training/sac_pi/valid_num      | 4924.0      |
| training/sac_Q/q1              | 201.01462   |
| training/sac_Q/q2              | 198.22998   |
| training/sac_Q/q2_loss         | 105.99896   |
| training/sac_Q/q_global_norm   | 253.76254   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17461759 |
| epoch                          | 368        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4952.6787  |
| evaluation/return-max          | 4993.911   |
| evaluation/return-min          | 4919.1475  |
| evaluation/return-std          | 22.878082  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46074      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4952.6787  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 204.6987   |
| Q-std                          | 102.43443  |
| Q_loss                         | 94.8175    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 368        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000561   |
| times/evaluation_paths         | 47.9       |
| times/timestep_after_hook      | 0.00415    |
| times/timestep_before_hook     | 0.00857    |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 369000     |
| train-steps                    | 369000     |
| training/Q/q1_loss             | 108.07396  |
| training/sac_pi/alpha          | 0.17461112 |
| training/sac_pi/alpha_loss     | 0.29951784 |
| training/sac_pi/logp_pi        | 4.739353   |
| training/sac_pi/pi_entropy     | 3.1288323  |
| training/sac_pi/pi_global_norm | 1.6833272  |
| training/sac_pi/policy_loss    | -220.77534 |
| training/sac_pi/std            | 0.45989296 |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 212.57608  |
| training/sac_Q/q2              | 211.83035  |
| training/sac_Q/q2_loss         | 105.86553  |
| training/sac_Q/q_global_norm   | 300.53638  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17582007 |
| epoch                          | 369        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5240.7207  |
| evaluation/return-max          | 5346.708   |
| evaluation/return-min          | 5099.042   |
| evaluation/return-std          | 69.22652   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46176      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5240.7207  |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 210.05888  |
| Q-std                          | 123.42128  |
| Q_loss                         | 89.543915  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 369        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000308   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000581   |
| times/evaluation_paths         | 35.4       |
| times/timestep_after_hook      | 0.0042     |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 68.6       |
| timestep                       | 1000       |
| timesteps_total                | 370000     |
| train-steps                    | 370000     |
| training/Q/q1_loss             | 103.7304   |
| training/sac_pi/alpha          | 0.17577474 |
| training/sac_pi/alpha_loss     | 0.22035767 |
| training/sac_pi/logp_pi        | 5.021636   |
| training/sac_pi/pi_entropy     | 3.5460148  |
| training/sac_pi/pi_global_norm | 1.7140409  |
| training/sac_pi/policy_loss    | -208.79977 |
| training/sac_pi/std            | 0.5167284  |
| training/sac_pi/valid_num      | 4917.0     |
| training/sac_Q/q1              | 195.29797  |
| training/sac_Q/q2              | 190.15775  |
| training/sac_Q/q2_loss         | 103.01863  |
| training/sac_Q/q_global_norm   | 283.97208  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16631536 |
| epoch                          | 370        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4924.2544  |
| evaluation/return-max          | 4965.265   |
| evaluation/return-min          | 4864.9346  |
| evaluation/return-std          | 30.742033  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46007      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4924.2544  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 217.73233  |
| Q-std                          | 90.69914   |
| Q_loss                         | 98.10839   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 370        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000144   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000559   |
| times/evaluation_paths         | 37         |
| times/timestep_after_hook      | 0.00425    |
| times/timestep_before_hook     | 0.00869    |
| times/train                    | 70.2       |
| timestep                       | 1000       |
| timesteps_total                | 371000     |
| train-steps                    | 371000     |
| training/Q/q1_loss             | 105.87079  |
| training/sac_pi/alpha          | 0.16633457 |
| training/sac_pi/alpha_loss     | 0.0895716  |
| training/sac_pi/logp_pi        | 4.806192   |
| training/sac_pi/pi_entropy     | 3.590838   |
| training/sac_pi/pi_global_norm | 1.6721098  |
| training/sac_pi/policy_loss    | -207.77348 |
| training/sac_pi/std            | 0.53353906 |
| training/sac_pi/valid_num      | 4916.0     |
| training/sac_Q/q1              | 194.89417  |
| training/sac_Q/q2              | 192.6631   |
| training/sac_Q/q2_loss         | 105.67311  |
| training/sac_Q/q_global_norm   | 180.59431  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17388056 |
| epoch                          | 371        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5010.3745  |
| evaluation/return-max          | 5048.601   |
| evaluation/return-min          | 4957.375   |
| evaluation/return-std          | 27.070107  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46150      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5010.3745  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 217.08455  |
| Q-std                          | 94.178375  |
| Q_loss                         | 85.44317   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 371        |
| times/epoch_after_hook         | 1.6e-06    |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000548   |
| times/evaluation_paths         | 35.2       |
| times/timestep_after_hook      | 0.00426    |
| times/timestep_before_hook     | 0.00884    |
| times/train                    | 70.8       |
| timestep                       | 1000       |
| timesteps_total                | 372000     |
| train-steps                    | 372000     |
| training/Q/q1_loss             | 87.2262    |
| training/sac_pi/alpha          | 0.1738115  |
| training/sac_pi/alpha_loss     | 0.3071622  |
| training/sac_pi/logp_pi        | 4.8613214  |
| training/sac_pi/pi_entropy     | 3.402823   |
| training/sac_pi/pi_global_norm | 1.8588803  |
| training/sac_pi/policy_loss    | -216.26793 |
| training/sac_pi/std            | 0.49265954 |
| training/sac_pi/valid_num      | 4971.0     |
| training/sac_Q/q1              | 204.4753   |
| training/sac_Q/q2              | 204.69818  |
| training/sac_Q/q2_loss         | 87.43363   |
| training/sac_Q/q_global_norm   | 324.59882  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17318752  |
| epoch                          | 372         |
| evaluation/episode-length-avg  | 826         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 302         |
| evaluation/episode-length-std  | 240         |
| evaluation/return-average      | 3978.6946   |
| evaluation/return-max          | 5094.451    |
| evaluation/return-min          | 1102.0182   |
| evaluation/return-std          | 1344.9973   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 80.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46241       |
| perf/AverageLength             | 826         |
| perf/AverageReturn             | 3978.6946   |
| perf/NormalizedReturn          | 0.866       |
| Q-avg                          | 203.63414   |
| Q-std                          | 129.8723    |
| Q_loss                         | 109.50325   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 372         |
| times/epoch_after_hook         | 2e-06       |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000636    |
| times/evaluation_paths         | 37.9        |
| times/timestep_after_hook      | 0.00413     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 373000      |
| train-steps                    | 373000      |
| training/Q/q1_loss             | 95.407684   |
| training/sac_pi/alpha          | 0.1731751   |
| training/sac_pi/alpha_loss     | 0.005727071 |
| training/sac_pi/logp_pi        | 4.2409863   |
| training/sac_pi/pi_entropy     | 3.3861542   |
| training/sac_pi/pi_global_norm | 1.6270444   |
| training/sac_pi/policy_loss    | -207.00851  |
| training/sac_pi/std            | 0.4761707   |
| training/sac_pi/valid_num      | 4962.0      |
| training/sac_Q/q1              | 195.79282   |
| training/sac_Q/q2              | 196.21298   |
| training/sac_Q/q2_loss         | 95.39131    |
| training/sac_Q/q_global_norm   | 211.30986   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17485829 |
| epoch                          | 373        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4967.4443  |
| evaluation/return-max          | 5034.6416  |
| evaluation/return-min          | 4892.714   |
| evaluation/return-std          | 39.564598  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46325      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4967.4443  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 210.27742  |
| Q-std                          | 121.97302  |
| Q_loss                         | 101.86335  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 373        |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.000268   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000679   |
| times/evaluation_paths         | 35.7       |
| times/timestep_after_hook      | 0.00423    |
| times/timestep_before_hook     | 0.00859    |
| times/train                    | 72.9       |
| timestep                       | 1000       |
| timesteps_total                | 374000     |
| train-steps                    | 374000     |
| training/Q/q1_loss             | 105.53751  |
| training/sac_pi/alpha          | 0.17480944 |
| training/sac_pi/alpha_loss     | 0.33078608 |
| training/sac_pi/logp_pi        | 4.164996   |
| training/sac_pi/pi_entropy     | 3.3640199  |
| training/sac_pi/pi_global_norm | 1.5857383  |
| training/sac_pi/policy_loss    | -219.38855 |
| training/sac_pi/std            | 0.46846542 |
| training/sac_pi/valid_num      | 5001.0     |
| training/sac_Q/q1              | 212.9124   |
| training/sac_Q/q2              | 211.71443  |
| training/sac_Q/q2_loss         | 104.723915 |
| training/sac_Q/q_global_norm   | 271.49683  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17623024  |
| epoch                          | 374         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4633.95     |
| evaluation/return-max          | 4839.5776   |
| evaluation/return-min          | 4548.275    |
| evaluation/return-std          | 80.891174   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 82.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46215       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4633.95     |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 201.29118   |
| Q-std                          | 103.16608   |
| Q_loss                         | 96.901375   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 374         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000592    |
| times/evaluation_paths         | 33.2        |
| times/timestep_after_hook      | 0.00429     |
| times/timestep_before_hook     | 0.00846     |
| times/train                    | 68.3        |
| timestep                       | 1000        |
| timesteps_total                | 375000      |
| train-steps                    | 375000      |
| training/Q/q1_loss             | 83.92027    |
| training/sac_pi/alpha          | 0.17625016  |
| training/sac_pi/alpha_loss     | -0.23171154 |
| training/sac_pi/logp_pi        | 4.278348    |
| training/sac_pi/pi_entropy     | 3.2577481   |
| training/sac_pi/pi_global_norm | 1.8819667   |
| training/sac_pi/policy_loss    | -216.27629  |
| training/sac_pi/std            | 0.47640783  |
| training/sac_pi/valid_num      | 4954.0      |
| training/sac_Q/q1              | 209.52567   |
| training/sac_Q/q2              | 208.00766   |
| training/sac_Q/q2_loss         | 84.60826    |
| training/sac_Q/q_global_norm   | 207.39372   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17446373 |
| epoch                          | 375        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4941.986   |
| evaluation/return-max          | 4982.0586  |
| evaluation/return-min          | 4863.0674  |
| evaluation/return-std          | 31.554852  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46187      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4941.986   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 216.09814  |
| Q-std                          | 90.855255  |
| Q_loss                         | 88.4341    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 375        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000668   |
| times/evaluation_paths         | 37.7       |
| times/timestep_after_hook      | 0.00412    |
| times/timestep_before_hook     | 0.00864    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 376000     |
| train-steps                    | 376000     |
| training/Q/q1_loss             | 97.4087    |
| training/sac_pi/alpha          | 0.17441624 |
| training/sac_pi/alpha_loss     | 0.46439004 |
| training/sac_pi/logp_pi        | 4.302671   |
| training/sac_pi/pi_entropy     | 3.463108   |
| training/sac_pi/pi_global_norm | 1.5097079  |
| training/sac_pi/policy_loss    | -216.3106  |
| training/sac_pi/std            | 0.4831961  |
| training/sac_pi/valid_num      | 4935.0     |
| training/sac_Q/q1              | 207.42468  |
| training/sac_Q/q2              | 205.64157  |
| training/sac_Q/q2_loss         | 97.54218   |
| training/sac_Q/q_global_norm   | 218.33238  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17507212 |
| epoch                          | 376        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4980.7344  |
| evaluation/return-max          | 5013.7773  |
| evaluation/return-min          | 4937.9346  |
| evaluation/return-std          | 24.448557  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46075      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4980.7344  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 202.66919  |
| Q-std                          | 98.92224   |
| Q_loss                         | 92.6595    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 376        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000571   |
| times/evaluation_paths         | 40.3       |
| times/timestep_after_hook      | 0.0042     |
| times/timestep_before_hook     | 0.00872    |
| times/train                    | 71.6       |
| timestep                       | 1000       |
| timesteps_total                | 377000     |
| train-steps                    | 377000     |
| training/Q/q1_loss             | 115.13691  |
| training/sac_pi/alpha          | 0.17499556 |
| training/sac_pi/alpha_loss     | 0.5680496  |
| training/sac_pi/logp_pi        | 4.4074707  |
| training/sac_pi/pi_entropy     | 3.40569    |
| training/sac_pi/pi_global_norm | 1.7408152  |
| training/sac_pi/policy_loss    | -211.1397  |
| training/sac_pi/std            | 0.4833783  |
| training/sac_pi/valid_num      | 4953.0     |
| training/sac_Q/q1              | 203.16736  |
| training/sac_Q/q2              | 201.40298  |
| training/sac_Q/q2_loss         | 115.4813   |
| training/sac_Q/q_global_norm   | 257.9717   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17236291 |
| epoch                          | 377        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4773.867   |
| evaluation/return-max          | 4826.9956  |
| evaluation/return-min          | 4734.375   |
| evaluation/return-std          | 25.618683  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46109      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4773.867   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 193.20715  |
| Q-std                          | 113.32335  |
| Q_loss                         | 90.8415    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 377        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000265   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000644   |
| times/evaluation_paths         | 33.8       |
| times/timestep_after_hook      | 0.00431    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 62.6       |
| timestep                       | 1000       |
| timesteps_total                | 378000     |
| train-steps                    | 378000     |
| training/Q/q1_loss             | 95.28351   |
| training/sac_pi/alpha          | 0.17233282 |
| training/sac_pi/alpha_loss     | 0.09469565 |
| training/sac_pi/logp_pi        | 4.393181   |
| training/sac_pi/pi_entropy     | 3.303048   |
| training/sac_pi/pi_global_norm | 1.7042073  |
| training/sac_pi/policy_loss    | -211.97855 |
| training/sac_pi/std            | 0.4908982  |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 199.1374   |
| training/sac_Q/q2              | 198.82793  |
| training/sac_Q/q2_loss         | 95.37316   |
| training/sac_Q/q_global_norm   | 198.44077  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17112619 |
| epoch                          | 378        |
| evaluation/episode-length-avg  | 566        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 130        |
| evaluation/episode-length-std  | 434        |
| evaluation/return-average      | 2499.1553  |
| evaluation/return-max          | 4744.056   |
| evaluation/return-min          | 329.31445  |
| evaluation/return-std          | 2159.743   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 82.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46153      |
| perf/AverageLength             | 566        |
| perf/AverageReturn             | 2499.1553  |
| perf/NormalizedReturn          | 0.544      |
| Q-avg                          | 216.26009  |
| Q-std                          | 108.44756  |
| Q_loss                         | 81.498825  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 378        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000559   |
| times/evaluation_paths         | 19.4       |
| times/timestep_after_hook      | 0.00416    |
| times/timestep_before_hook     | 0.00861    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 379000     |
| train-steps                    | 379000     |
| training/Q/q1_loss             | 105.333855 |
| training/sac_pi/alpha          | 0.17112914 |
| training/sac_pi/alpha_loss     | 0.08359518 |
| training/sac_pi/logp_pi        | 5.028239   |
| training/sac_pi/pi_entropy     | 3.56383    |
| training/sac_pi/pi_global_norm | 1.7784762  |
| training/sac_pi/policy_loss    | -209.90302 |
| training/sac_pi/std            | 0.531413   |
| training/sac_pi/valid_num      | 4914.0     |
| training/sac_Q/q1              | 197.00139  |
| training/sac_Q/q2              | 196.2196   |
| training/sac_Q/q2_loss         | 105.21109  |
| training/sac_Q/q_global_norm   | 256.12036  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1752049   |
| epoch                          | 379         |
| evaluation/episode-length-avg  | 164         |
| evaluation/episode-length-max  | 317         |
| evaluation/episode-length-min  | 144         |
| evaluation/episode-length-std  | 51.1        |
| evaluation/return-average      | 485.41513   |
| evaluation/return-max          | 1131.1753   |
| evaluation/return-min          | 399.88525   |
| evaluation/return-std          | 215.53433   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46326       |
| perf/AverageLength             | 164         |
| perf/AverageReturn             | 485.41513   |
| perf/NormalizedReturn          | 0.105       |
| Q-avg                          | 197.91914   |
| Q-std                          | 136.0036    |
| Q_loss                         | 113.43916   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 379         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000465    |
| times/evaluation_paths         | 5.27        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 59.3        |
| timestep                       | 1000        |
| timesteps_total                | 380000      |
| train-steps                    | 380000      |
| training/Q/q1_loss             | 93.44373    |
| training/sac_pi/alpha          | 0.17522076  |
| training/sac_pi/alpha_loss     | -0.44384894 |
| training/sac_pi/logp_pi        | 4.415261    |
| training/sac_pi/pi_entropy     | 3.5441163   |
| training/sac_pi/pi_global_norm | 1.5860064   |
| training/sac_pi/policy_loss    | -211.01244  |
| training/sac_pi/std            | 0.51515675  |
| training/sac_pi/valid_num      | 4924.0      |
| training/sac_Q/q1              | 198.29227   |
| training/sac_Q/q2              | 197.87523   |
| training/sac_Q/q2_loss         | 94.404305   |
| training/sac_Q/q_global_norm   | 255.46706   |
---------------------------------------------------------------------------------
[WARN] 380 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16779584  |
| epoch                          | 380         |
| evaluation/episode-length-avg  | 943         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 427         |
| evaluation/episode-length-std  | 172         |
| evaluation/return-average      | 4513.542    |
| evaluation/return-max          | 4892.1787   |
| evaluation/return-min          | 1733.3601   |
| evaluation/return-std          | 928.26086   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46071       |
| perf/AverageLength             | 943         |
| perf/AverageReturn             | 4513.542    |
| perf/NormalizedReturn          | 0.983       |
| Q-avg                          | 201.68881   |
| Q-std                          | 116.22476   |
| Q_loss                         | 104.60026   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 380         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.00058     |
| times/evaluation_paths         | 44.2        |
| times/timestep_after_hook      | 0.00415     |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 62.6        |
| timestep                       | 1000        |
| timesteps_total                | 381000      |
| train-steps                    | 381000      |
| training/Q/q1_loss             | 75.45099    |
| training/sac_pi/alpha          | 0.16776507  |
| training/sac_pi/alpha_loss     | -0.29360846 |
| training/sac_pi/logp_pi        | 4.323911    |
| training/sac_pi/pi_entropy     | 3.2256176   |
| training/sac_pi/pi_global_norm | 1.9704739   |
| training/sac_pi/policy_loss    | -221.31863  |
| training/sac_pi/std            | 0.47914502  |
| training/sac_pi/valid_num      | 4959.0      |
| training/sac_Q/q1              | 213.45224   |
| training/sac_Q/q2              | 211.80954   |
| training/sac_Q/q2_loss         | 75.3174     |
| training/sac_Q/q_global_norm   | 198.21008   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16555676 |
| epoch                          | 381        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5128.0205  |
| evaluation/return-max          | 5198.754   |
| evaluation/return-min          | 5083.9595  |
| evaluation/return-std          | 35.10031   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 83.4       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46130      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5128.0205  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 204.63889  |
| Q-std                          | 122.08025  |
| Q_loss                         | 102.63401  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 381        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000264   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000593   |
| times/evaluation_paths         | 37.3       |
| times/timestep_after_hook      | 0.00416    |
| times/timestep_before_hook     | 0.00872    |
| times/train                    | 70.1       |
| timestep                       | 1000       |
| timesteps_total                | 382000     |
| train-steps                    | 382000     |
| training/Q/q1_loss             | 103.049324 |
| training/sac_pi/alpha          | 0.1655873  |
| training/sac_pi/alpha_loss     | 0.18511555 |
| training/sac_pi/logp_pi        | 4.2225757  |
| training/sac_pi/pi_entropy     | 3.4249892  |
| training/sac_pi/pi_global_norm | 1.8315299  |
| training/sac_pi/policy_loss    | -208.38716 |
| training/sac_pi/std            | 0.48527035 |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 198.32352  |
| training/sac_Q/q2              | 197.47249  |
| training/sac_Q/q2_loss         | 103.85859  |
| training/sac_Q/q_global_norm   | 369.64725  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17086914  |
| epoch                          | 382         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4746.9165   |
| evaluation/return-max          | 4852.33     |
| evaluation/return-min          | 4640.307    |
| evaluation/return-std          | 53.128956   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46120       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4746.9165   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 198.94476   |
| Q-std                          | 104.73626   |
| Q_loss                         | 112.71059   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 382         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000553    |
| times/evaluation_paths         | 41.2        |
| times/timestep_after_hook      | 0.00418     |
| times/timestep_before_hook     | 0.00866     |
| times/train                    | 70.3        |
| timestep                       | 1000        |
| timesteps_total                | 383000      |
| train-steps                    | 383000      |
| training/Q/q1_loss             | 91.75983    |
| training/sac_pi/alpha          | 0.17088751  |
| training/sac_pi/alpha_loss     | -0.21947394 |
| training/sac_pi/logp_pi        | 3.7044914   |
| training/sac_pi/pi_entropy     | 3.4208286   |
| training/sac_pi/pi_global_norm | 2.509661    |
| training/sac_pi/policy_loss    | -214.27449  |
| training/sac_pi/std            | 0.4743063   |
| training/sac_pi/valid_num      | 4950.0      |
| training/sac_Q/q1              | 206.6768    |
| training/sac_Q/q2              | 206.20601   |
| training/sac_Q/q2_loss         | 91.54144    |
| training/sac_Q/q_global_norm   | 316.5522    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16860883 |
| epoch                          | 383        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5038.4556  |
| evaluation/return-max          | 5078.7246  |
| evaluation/return-min          | 4987.544   |
| evaluation/return-std          | 30.717009  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46147      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5038.4556  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 207.76482  |
| Q-std                          | 90.74765   |
| Q_loss                         | 105.475494 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 383        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000154   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000538   |
| times/evaluation_paths         | 41.6       |
| times/timestep_after_hook      | 0.00419    |
| times/timestep_before_hook     | 0.00878    |
| times/train                    | 70.4       |
| timestep                       | 1000       |
| timesteps_total                | 384000     |
| train-steps                    | 384000     |
| training/Q/q1_loss             | 98.515884  |
| training/sac_pi/alpha          | 0.16859528 |
| training/sac_pi/alpha_loss     | 0.21576923 |
| training/sac_pi/logp_pi        | 4.9855285  |
| training/sac_pi/pi_entropy     | 3.4542496  |
| training/sac_pi/pi_global_norm | 1.5933992  |
| training/sac_pi/policy_loss    | -209.36894 |
| training/sac_pi/std            | 0.53291446 |
| training/sac_pi/valid_num      | 4865.0     |
| training/sac_Q/q1              | 198.30449  |
| training/sac_Q/q2              | 197.45523  |
| training/sac_Q/q2_loss         | 98.33536   |
| training/sac_Q/q_global_norm   | 366.58325  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17053314 |
| epoch                          | 384        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4676.225   |
| evaluation/return-max          | 4726.2603  |
| evaluation/return-min          | 4629.245   |
| evaluation/return-std          | 27.583008  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46161      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4676.225   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 213.29631  |
| Q-std                          | 101.90248  |
| Q_loss                         | 90.26984   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 384        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 40.9       |
| times/timestep_after_hook      | 0.00427    |
| times/timestep_before_hook     | 0.0106     |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 385000     |
| train-steps                    | 385000     |
| training/Q/q1_loss             | 87.2585    |
| training/sac_pi/alpha          | 0.17052302 |
| training/sac_pi/alpha_loss     | 0.22593363 |
| training/sac_pi/logp_pi        | 3.9708915  |
| training/sac_pi/pi_entropy     | 3.248001   |
| training/sac_pi/pi_global_norm | 1.5978534  |
| training/sac_pi/policy_loss    | -220.17635 |
| training/sac_pi/std            | 0.46969888 |
| training/sac_pi/valid_num      | 5001.0     |
| training/sac_Q/q1              | 213.43095  |
| training/sac_Q/q2              | 211.89108  |
| training/sac_Q/q2_loss         | 86.71744   |
| training/sac_Q/q_global_norm   | 200.64668  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17067212 |
| epoch                          | 385        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4467.366   |
| evaluation/return-max          | 4900.844   |
| evaluation/return-min          | 4068.0928  |
| evaluation/return-std          | 214.07018  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46212      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4467.366   |
| perf/NormalizedReturn          | 0.973      |
| Q-avg                          | 208.35005  |
| Q-std                          | 117.74635  |
| Q_loss                         | 108.2266   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 385        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000311   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 40.5       |
| times/timestep_after_hook      | 0.00438    |
| times/timestep_before_hook     | 0.00867    |
| times/train                    | 73.9       |
| timestep                       | 1000       |
| timesteps_total                | 386000     |
| train-steps                    | 386000     |
| training/Q/q1_loss             | 125.41054  |
| training/sac_pi/alpha          | 0.17068271 |
| training/sac_pi/alpha_loss     | -0.2432738 |
| training/sac_pi/logp_pi        | 4.330725   |
| training/sac_pi/pi_entropy     | 3.2969985  |
| training/sac_pi/pi_global_norm | 1.7251524  |
| training/sac_pi/policy_loss    | -216.52211 |
| training/sac_pi/std            | 0.48680666 |
| training/sac_pi/valid_num      | 4947.0     |
| training/sac_Q/q1              | 206.38652  |
| training/sac_Q/q2              | 204.0757   |
| training/sac_Q/q2_loss         | 125.16204  |
| training/sac_Q/q_global_norm   | 238.74988  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17238384 |
| epoch                          | 386        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4957.712   |
| evaluation/return-max          | 5002.175   |
| evaluation/return-min          | 4857.957   |
| evaluation/return-std          | 45.630512  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46187      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4957.712   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 205.07483  |
| Q-std                          | 110.60987  |
| Q_loss                         | 90.667175  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 386        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000517   |
| times/evaluation_paths         | 46.1       |
| times/timestep_after_hook      | 0.00423    |
| times/timestep_before_hook     | 0.00901    |
| times/train                    | 77.3       |
| timestep                       | 1000       |
| timesteps_total                | 387000     |
| train-steps                    | 387000     |
| training/Q/q1_loss             | 91.221016  |
| training/sac_pi/alpha          | 0.17239165 |
| training/sac_pi/alpha_loss     | -0.3105803 |
| training/sac_pi/logp_pi        | 3.8063102  |
| training/sac_pi/pi_entropy     | 3.339761   |
| training/sac_pi/pi_global_norm | 1.4790328  |
| training/sac_pi/policy_loss    | -219.68718 |
| training/sac_pi/std            | 0.47603652 |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 211.92697  |
| training/sac_Q/q2              | 209.71724  |
| training/sac_Q/q2_loss         | 91.38847   |
| training/sac_Q/q_global_norm   | 173.55151  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17003475  |
| epoch                          | 387         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5087.771    |
| evaluation/return-max          | 5125.772    |
| evaluation/return-min          | 5008.788    |
| evaluation/return-std          | 33.032253   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85          |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46198       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5087.771    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 199.45341   |
| Q-std                          | 117.613815  |
| Q_loss                         | 109.9858    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 387         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000606    |
| times/evaluation_paths         | 38.4        |
| times/timestep_after_hook      | 0.00419     |
| times/timestep_before_hook     | 0.00896     |
| times/train                    | 72.7        |
| timestep                       | 1000        |
| timesteps_total                | 388000      |
| train-steps                    | 388000      |
| training/Q/q1_loss             | 93.93805    |
| training/sac_pi/alpha          | 0.17002462  |
| training/sac_pi/alpha_loss     | 0.014088778 |
| training/sac_pi/logp_pi        | 4.3655763   |
| training/sac_pi/pi_entropy     | 3.3795745   |
| training/sac_pi/pi_global_norm | 1.9492196   |
| training/sac_pi/policy_loss    | -204.74382  |
| training/sac_pi/std            | 0.48359853  |
| training/sac_pi/valid_num      | 4923.0      |
| training/sac_Q/q1              | 192.79948   |
| training/sac_Q/q2              | 191.63094   |
| training/sac_Q/q2_loss         | 93.999825   |
| training/sac_Q/q_global_norm   | 227.75555   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17155436 |
| epoch                          | 388        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5072.573   |
| evaluation/return-max          | 5131.6943  |
| evaluation/return-min          | 4921.9507  |
| evaluation/return-std          | 62.104774  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45969      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5072.573   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 204.2048   |
| Q-std                          | 110.53659  |
| Q_loss                         | 83.54498   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 388        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000627   |
| times/evaluation_paths         | 57.3       |
| times/timestep_after_hook      | 0.00455    |
| times/timestep_before_hook     | 0.00876    |
| times/train                    | 80.3       |
| timestep                       | 1000       |
| timesteps_total                | 389000     |
| train-steps                    | 389000     |
| training/Q/q1_loss             | 102.062126 |
| training/sac_pi/alpha          | 0.17153612 |
| training/sac_pi/alpha_loss     | 0.29602477 |
| training/sac_pi/logp_pi        | 4.653347   |
| training/sac_pi/pi_entropy     | 3.2930481  |
| training/sac_pi/pi_global_norm | 1.4846369  |
| training/sac_pi/policy_loss    | -213.31325 |
| training/sac_pi/std            | 0.48241785 |
| training/sac_pi/valid_num      | 4988.0     |
| training/sac_Q/q1              | 205.40251  |
| training/sac_Q/q2              | 203.71968  |
| training/sac_Q/q2_loss         | 102.30829  |
| training/sac_Q/q_global_norm   | 372.19128  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17150944  |
| epoch                          | 389         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4969.2075   |
| evaluation/return-max          | 5045.1357   |
| evaluation/return-min          | 4886.216    |
| evaluation/return-std          | 48.493282   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46249       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4969.2075   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 206.35396   |
| Q-std                          | 106.386925  |
| Q_loss                         | 91.14553    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 389         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000369    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000636    |
| times/evaluation_paths         | 50.9        |
| times/timestep_after_hook      | 0.00415     |
| times/timestep_before_hook     | 0.00904     |
| times/train                    | 84.8        |
| timestep                       | 1000        |
| timesteps_total                | 390000      |
| train-steps                    | 390000      |
| training/Q/q1_loss             | 114.0812    |
| training/sac_pi/alpha          | 0.17153755  |
| training/sac_pi/alpha_loss     | 0.030452285 |
| training/sac_pi/logp_pi        | 4.496644    |
| training/sac_pi/pi_entropy     | 3.6428185   |
| training/sac_pi/pi_global_norm | 1.7783121   |
| training/sac_pi/policy_loss    | -205.54073  |
| training/sac_pi/std            | 0.5318006   |
| training/sac_pi/valid_num      | 4959.0      |
| training/sac_Q/q1              | 194.0053    |
| training/sac_Q/q2              | 194.64154   |
| training/sac_Q/q2_loss         | 113.40595   |
| training/sac_Q/q_global_norm   | 284.30435   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17472847  |
| epoch                          | 390         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4808.195    |
| evaluation/return-max          | 4841.933    |
| evaluation/return-min          | 4769.568    |
| evaluation/return-std          | 23.568811   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46088       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4808.195    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 209.71443   |
| Q-std                          | 97.06273    |
| Q_loss                         | 83.83678    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 390         |
| times/epoch_after_hook         | 1.95e-06    |
| times/epoch_before_hook        | 0.00015     |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000789    |
| times/evaluation_paths         | 52.1        |
| times/timestep_after_hook      | 0.00847     |
| times/timestep_before_hook     | 0.00876     |
| times/train                    | 81.5        |
| timestep                       | 1000        |
| timesteps_total                | 391000      |
| train-steps                    | 391000      |
| training/Q/q1_loss             | 96.67527    |
| training/sac_pi/alpha          | 0.17476313  |
| training/sac_pi/alpha_loss     | -0.19362688 |
| training/sac_pi/logp_pi        | 4.2044854   |
| training/sac_pi/pi_entropy     | 3.453155    |
| training/sac_pi/pi_global_norm | 1.6094551   |
| training/sac_pi/policy_loss    | -216.70525  |
| training/sac_pi/std            | 0.4872104   |
| training/sac_pi/valid_num      | 4985.0      |
| training/sac_Q/q1              | 209.16519   |
| training/sac_Q/q2              | 208.88286   |
| training/sac_Q/q2_loss         | 96.192184   |
| training/sac_Q/q_global_norm   | 227.31364   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16951758 |
| epoch                          | 391        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4881.4297  |
| evaluation/return-max          | 5118.9175  |
| evaluation/return-min          | 4554.024   |
| evaluation/return-std          | 138.01164  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45920      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4881.4297  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 196.23898  |
| Q-std                          | 150.96654  |
| Q_loss                         | 86.077065  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 391        |
| times/epoch_after_hook         | 3.25e-06   |
| times/epoch_before_hook        | 0.000333   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000592   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00427    |
| times/timestep_before_hook     | 0.00854    |
| times/train                    | 71.1       |
| timestep                       | 1000       |
| timesteps_total                | 392000     |
| train-steps                    | 392000     |
| training/Q/q1_loss             | 109.36355  |
| training/sac_pi/alpha          | 0.16949399 |
| training/sac_pi/alpha_loss     | 0.50332487 |
| training/sac_pi/logp_pi        | 4.8959017  |
| training/sac_pi/pi_entropy     | 3.4414964  |
| training/sac_pi/pi_global_norm | 1.5369251  |
| training/sac_pi/policy_loss    | -219.96063 |
| training/sac_pi/std            | 0.5023362  |
| training/sac_pi/valid_num      | 4922.0     |
| training/sac_Q/q1              | 205.81357  |
| training/sac_Q/q2              | 203.962    |
| training/sac_Q/q2_loss         | 109.62299  |
| training/sac_Q/q_global_norm   | 360.80896  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1673456   |
| epoch                          | 392         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5291.0806   |
| evaluation/return-max          | 5335.8657   |
| evaluation/return-min          | 5218.757    |
| evaluation/return-std          | 33.950203   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46297       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5291.0806   |
| perf/NormalizedReturn          | 1.15        |
| Q-avg                          | 209.27786   |
| Q-std                          | 110.390396  |
| Q_loss                         | 97.43052    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 392         |
| times/epoch_after_hook         | 1.95e-06    |
| times/epoch_before_hook        | 0.000138    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000667    |
| times/evaluation_paths         | 36.4        |
| times/timestep_after_hook      | 0.00421     |
| times/timestep_before_hook     | 0.00855     |
| times/train                    | 63.4        |
| timestep                       | 1000        |
| timesteps_total                | 393000      |
| train-steps                    | 393000      |
| training/Q/q1_loss             | 120.02646   |
| training/sac_pi/alpha          | 0.16735983  |
| training/sac_pi/alpha_loss     | -0.29234892 |
| training/sac_pi/logp_pi        | 4.259761    |
| training/sac_pi/pi_entropy     | 3.51323     |
| training/sac_pi/pi_global_norm | 1.5246565   |
| training/sac_pi/policy_loss    | -218.47987  |
| training/sac_pi/std            | 0.5163604   |
| training/sac_pi/valid_num      | 4961.0      |
| training/sac_Q/q1              | 209.55717   |
| training/sac_Q/q2              | 208.14966   |
| training/sac_Q/q2_loss         | 120.538284  |
| training/sac_Q/q_global_norm   | 239.87733   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16646063  |
| epoch                          | 393         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4835.456    |
| evaluation/return-max          | 4884.5186   |
| evaluation/return-min          | 4769.4844   |
| evaluation/return-std          | 35.57104    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46077       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4835.456    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 203.24954   |
| Q-std                          | 116.534325  |
| Q_loss                         | 101.716545  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 393         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000286    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000528    |
| times/evaluation_paths         | 39.9        |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.00881     |
| times/train                    | 72.9        |
| timestep                       | 1000        |
| timesteps_total                | 394000      |
| train-steps                    | 394000      |
| training/Q/q1_loss             | 84.33221    |
| training/sac_pi/alpha          | 0.16643518  |
| training/sac_pi/alpha_loss     | -0.11073307 |
| training/sac_pi/logp_pi        | 3.8197281   |
| training/sac_pi/pi_entropy     | 3.496048    |
| training/sac_pi/pi_global_norm | 1.558428    |
| training/sac_pi/policy_loss    | -219.02458  |
| training/sac_pi/std            | 0.4896602   |
| training/sac_pi/valid_num      | 4999.0      |
| training/sac_Q/q1              | 212.07845   |
| training/sac_Q/q2              | 211.4008    |
| training/sac_Q/q2_loss         | 83.32006    |
| training/sac_Q/q_global_norm   | 216.49208   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17201193   |
| epoch                          | 394          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4791.1494    |
| evaluation/return-max          | 5061.4307    |
| evaluation/return-min          | 4547.62      |
| evaluation/return-std          | 156.8606     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.03         |
| model/origin_ret               | 86.6         |
| model/penalty_ret              | 82.4         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46275        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4791.1494    |
| perf/NormalizedReturn          | 1.04         |
| Q-avg                          | 220.03775    |
| Q-std                          | 91.8462      |
| Q_loss                         | 93.34257     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 394          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.000173     |
| times/epoch_rollout_model      | 489          |
| times/evaluation_metrics       | 0.000502     |
| times/evaluation_paths         | 41.2         |
| times/timestep_after_hook      | 0.00411      |
| times/timestep_before_hook     | 0.00875      |
| times/train                    | 71.3         |
| timestep                       | 1000         |
| timesteps_total                | 395000       |
| train-steps                    | 395000       |
| training/Q/q1_loss             | 75.397865    |
| training/sac_pi/alpha          | 0.17201772   |
| training/sac_pi/alpha_loss     | -0.096011885 |
| training/sac_pi/logp_pi        | 3.6454291    |
| training/sac_pi/pi_entropy     | 3.4250329    |
| training/sac_pi/pi_global_norm | 1.6446351    |
| training/sac_pi/policy_loss    | -223.12602   |
| training/sac_pi/std            | 0.47560993   |
| training/sac_pi/valid_num      | 5037.0       |
| training/sac_Q/q1              | 218.50537    |
| training/sac_Q/q2              | 218.58125    |
| training/sac_Q/q2_loss         | 76.35047     |
| training/sac_Q/q_global_norm   | 188.59152    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16888678 |
| epoch                          | 395        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5066.9346  |
| evaluation/return-max          | 5107.6025  |
| evaluation/return-min          | 5019.0273  |
| evaluation/return-std          | 29.057117  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46232      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5066.9346  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 201.64967  |
| Q-std                          | 100.98311  |
| Q_loss                         | 137.07869  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 395        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.00014    |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000569   |
| times/evaluation_paths         | 38.6       |
| times/timestep_after_hook      | 0.00418    |
| times/timestep_before_hook     | 0.0086     |
| times/train                    | 72.8       |
| timestep                       | 1000       |
| timesteps_total                | 396000     |
| train-steps                    | 396000     |
| training/Q/q1_loss             | 82.34739   |
| training/sac_pi/alpha          | 0.16889319 |
| training/sac_pi/alpha_loss     | -0.5365624 |
| training/sac_pi/logp_pi        | 3.1873488  |
| training/sac_pi/pi_entropy     | 3.3063455  |
| training/sac_pi/pi_global_norm | 1.7370209  |
| training/sac_pi/policy_loss    | -227.91792 |
| training/sac_pi/std            | 0.4570773  |
| training/sac_pi/valid_num      | 5027.0     |
| training/sac_Q/q1              | 223.51314  |
| training/sac_Q/q2              | 222.5393   |
| training/sac_Q/q2_loss         | 82.77875   |
| training/sac_Q/q_global_norm   | 209.58832  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17195764 |
| epoch                          | 396        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4863.7627  |
| evaluation/return-max          | 4928.753   |
| evaluation/return-min          | 4754.2266  |
| evaluation/return-std          | 51.319378  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46034      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4863.7627  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 197.37175  |
| Q-std                          | 123.733406 |
| Q_loss                         | 100.4309   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 396        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000142   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.00051    |
| times/evaluation_paths         | 47.7       |
| times/timestep_after_hook      | 0.00413    |
| times/timestep_before_hook     | 0.00861    |
| times/train                    | 64.1       |
| timestep                       | 1000       |
| timesteps_total                | 397000     |
| train-steps                    | 397000     |
| training/Q/q1_loss             | 87.05195   |
| training/sac_pi/alpha          | 0.17194586 |
| training/sac_pi/alpha_loss     | 0.02785599 |
| training/sac_pi/logp_pi        | 3.9566224  |
| training/sac_pi/pi_entropy     | 3.361779   |
| training/sac_pi/pi_global_norm | 1.8711653  |
| training/sac_pi/policy_loss    | -217.45312 |
| training/sac_pi/std            | 0.4632217  |
| training/sac_pi/valid_num      | 4963.0     |
| training/sac_Q/q1              | 209.486    |
| training/sac_Q/q2              | 207.76631  |
| training/sac_Q/q2_loss         | 85.85718   |
| training/sac_Q/q_global_norm   | 183.61307  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1689232  |
| epoch                          | 397        |
| evaluation/episode-length-avg  | 296        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 113        |
| evaluation/episode-length-std  | 352        |
| evaluation/return-average      | 1249.7207  |
| evaluation/return-max          | 4859.6885  |
| evaluation/return-min          | 325.2374   |
| evaluation/return-std          | 1796.1873  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46180      |
| perf/AverageLength             | 296        |
| perf/AverageReturn             | 1249.7207  |
| perf/NormalizedReturn          | 0.272      |
| Q-avg                          | 213.97551  |
| Q-std                          | 93.25446   |
| Q_loss                         | 108.35864  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 397        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000312   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000517   |
| times/evaluation_paths         | 11.7       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00876    |
| times/train                    | 64.1       |
| timestep                       | 1000       |
| timesteps_total                | 398000     |
| train-steps                    | 398000     |
| training/Q/q1_loss             | 94.66552   |
| training/sac_pi/alpha          | 0.1689344  |
| training/sac_pi/alpha_loss     | -0.3479186 |
| training/sac_pi/logp_pi        | 4.075039   |
| training/sac_pi/pi_entropy     | 3.4139583  |
| training/sac_pi/pi_global_norm | 1.6641906  |
| training/sac_pi/policy_loss    | -217.26431 |
| training/sac_pi/std            | 0.5010998  |
| training/sac_pi/valid_num      | 4893.0     |
| training/sac_Q/q1              | 205.5975   |
| training/sac_Q/q2              | 205.0085   |
| training/sac_Q/q2_loss         | 95.778435  |
| training/sac_Q/q_global_norm   | 323.56598  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16769096 |
| epoch                          | 398        |
| evaluation/episode-length-avg  | 940        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 405        |
| evaluation/episode-length-std  | 178        |
| evaluation/return-average      | 4531.92    |
| evaluation/return-max          | 4955.1436  |
| evaluation/return-min          | 1633.0793  |
| evaluation/return-std          | 969.91016  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46199      |
| perf/AverageLength             | 940        |
| perf/AverageReturn             | 4531.92    |
| perf/NormalizedReturn          | 0.987      |
| Q-avg                          | 204.00232  |
| Q-std                          | 105.525475 |
| Q_loss                         | 101.85968  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 398        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000139   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000569   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00417    |
| times/timestep_before_hook     | 0.0086     |
| times/train                    | 73.9       |
| timestep                       | 1000       |
| timesteps_total                | 399000     |
| train-steps                    | 399000     |
| training/Q/q1_loss             | 100.227585 |
| training/sac_pi/alpha          | 0.16767457 |
| training/sac_pi/alpha_loss     | 0.3894969  |
| training/sac_pi/logp_pi        | 4.387925   |
| training/sac_pi/pi_entropy     | 3.212761   |
| training/sac_pi/pi_global_norm | 1.7653763  |
| training/sac_pi/policy_loss    | -213.96025 |
| training/sac_pi/std            | 0.46820372 |
| training/sac_pi/valid_num      | 4994.0     |
| training/sac_Q/q1              | 207.89238  |
| training/sac_Q/q2              | 206.92978  |
| training/sac_Q/q2_loss         | 100.06196  |
| training/sac_Q/q_global_norm   | 228.78598  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17284599  |
| epoch                          | 399         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4757.4585   |
| evaluation/return-max          | 4826.996    |
| evaluation/return-min          | 4690.0234   |
| evaluation/return-std          | 41.054813   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46140       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4757.4585   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 206.35164   |
| Q-std                          | 103.15139   |
| Q_loss                         | 98.998116   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 399         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000675    |
| times/evaluation_paths         | 37.6        |
| times/timestep_after_hook      | 0.00407     |
| times/timestep_before_hook     | 0.00852     |
| times/train                    | 70          |
| timestep                       | 1000        |
| timesteps_total                | 400000      |
| train-steps                    | 400000      |
| training/Q/q1_loss             | 113.55146   |
| training/sac_pi/alpha          | 0.17287344  |
| training/sac_pi/alpha_loss     | -0.06643375 |
| training/sac_pi/logp_pi        | 3.9601135   |
| training/sac_pi/pi_entropy     | 3.4000516   |
| training/sac_pi/pi_global_norm | 1.5459864   |
| training/sac_pi/policy_loss    | -210.59056  |
| training/sac_pi/std            | 0.47044772  |
| training/sac_pi/valid_num      | 4988.0      |
| training/sac_Q/q1              | 203.51987   |
| training/sac_Q/q2              | 202.90155   |
| training/sac_Q/q2_loss         | 112.73048   |
| training/sac_Q/q_global_norm   | 260.1679    |
---------------------------------------------------------------------------------
[WARN] 400 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.1766813  |
| epoch                          | 400        |
| evaluation/episode-length-avg  | 922        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 224        |
| evaluation/episode-length-std  | 233        |
| evaluation/return-average      | 4470.4595  |
| evaluation/return-max          | 4969.477   |
| evaluation/return-min          | 808.5194   |
| evaluation/return-std          | 1223.364   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46046      |
| perf/AverageLength             | 922        |
| perf/AverageReturn             | 4470.4595  |
| perf/NormalizedReturn          | 0.973      |
| Q-avg                          | 210.73648  |
| Q-std                          | 113.44959  |
| Q_loss                         | 95.61852   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 400        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000144   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000525   |
| times/evaluation_paths         | 37.9       |
| times/timestep_after_hook      | 0.00412    |
| times/timestep_before_hook     | 0.00856    |
| times/train                    | 73.5       |
| timestep                       | 1000       |
| timesteps_total                | 401000     |
| train-steps                    | 401000     |
| training/Q/q1_loss             | 93.08581   |
| training/sac_pi/alpha          | 0.17665419 |
| training/sac_pi/alpha_loss     | 0.24938355 |
| training/sac_pi/logp_pi        | 4.192123   |
| training/sac_pi/pi_entropy     | 3.5059848  |
| training/sac_pi/pi_global_norm | 1.6632688  |
| training/sac_pi/policy_loss    | -216.6544  |
| training/sac_pi/std            | 0.4986963  |
| training/sac_pi/valid_num      | 5007.0     |
| training/sac_Q/q1              | 208.05624  |
| training/sac_Q/q2              | 206.66037  |
| training/sac_Q/q2_loss         | 93.410835  |
| training/sac_Q/q_global_norm   | 280.83987  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17488293 |
| epoch                          | 401        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4856.819   |
| evaluation/return-max          | 4916.217   |
| evaluation/return-min          | 4785.55    |
| evaluation/return-std          | 40.646343  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45980      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4856.819   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 214.89229  |
| Q-std                          | 90.32457   |
| Q_loss                         | 75.193886  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 401        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000312   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.00108    |
| times/evaluation_paths         | 33.7       |
| times/timestep_after_hook      | 0.00406    |
| times/timestep_before_hook     | 0.00868    |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 402000     |
| train-steps                    | 402000     |
| training/Q/q1_loss             | 114.2591   |
| training/sac_pi/alpha          | 0.17489207 |
| training/sac_pi/alpha_loss     | -0.3893788 |
| training/sac_pi/logp_pi        | 3.9953856  |
| training/sac_pi/pi_entropy     | 3.5275636  |
| training/sac_pi/pi_global_norm | 2.1184523  |
| training/sac_pi/policy_loss    | -211.3042  |
| training/sac_pi/std            | 0.50039357 |
| training/sac_pi/valid_num      | 4951.0     |
| training/sac_Q/q1              | 201.21335  |
| training/sac_Q/q2              | 200.2913   |
| training/sac_Q/q2_loss         | 114.03045  |
| training/sac_Q/q_global_norm   | 338.53323  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17469773 |
| epoch                          | 402        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4878.7256  |
| evaluation/return-max          | 4903.2344  |
| evaluation/return-min          | 4862.7227  |
| evaluation/return-std          | 11.2762375 |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46040      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4878.7256  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 209.01938  |
| Q-std                          | 105.784615 |
| Q_loss                         | 120.86152  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 402        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000546   |
| times/evaluation_paths         | 35.1       |
| times/timestep_after_hook      | 0.00417    |
| times/timestep_before_hook     | 0.00865    |
| times/train                    | 67.6       |
| timestep                       | 1000       |
| timesteps_total                | 403000     |
| train-steps                    | 403000     |
| training/Q/q1_loss             | 110.204895 |
| training/sac_pi/alpha          | 0.17471859 |
| training/sac_pi/alpha_loss     | -0.2001794 |
| training/sac_pi/logp_pi        | 4.8470783  |
| training/sac_pi/pi_entropy     | 3.4824474  |
| training/sac_pi/pi_global_norm | 2.1141121  |
| training/sac_pi/policy_loss    | -212.33456 |
| training/sac_pi/std            | 0.50789267 |
| training/sac_pi/valid_num      | 4930.0     |
| training/sac_Q/q1              | 198.8259   |
| training/sac_Q/q2              | 195.37036  |
| training/sac_Q/q2_loss         | 111.04516  |
| training/sac_Q/q_global_norm   | 262.9727   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17264634  |
| epoch                          | 403         |
| evaluation/episode-length-avg  | 400         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 134         |
| evaluation/episode-length-std  | 393         |
| evaluation/return-average      | 1638.9817   |
| evaluation/return-max          | 4762.124    |
| evaluation/return-min          | 363.3933    |
| evaluation/return-std          | 1927.8933   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46051       |
| perf/AverageLength             | 400         |
| perf/AverageReturn             | 1638.9817   |
| perf/NormalizedReturn          | 0.357       |
| Q-avg                          | 209.63211   |
| Q-std                          | 102.62424   |
| Q_loss                         | 81.26999    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 403         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000143    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000593    |
| times/evaluation_paths         | 15.1        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.00861     |
| times/train                    | 69.4        |
| timestep                       | 1000        |
| timesteps_total                | 404000      |
| train-steps                    | 404000      |
| training/Q/q1_loss             | 83.321754   |
| training/sac_pi/alpha          | 0.1726703   |
| training/sac_pi/alpha_loss     | 0.042061817 |
| training/sac_pi/logp_pi        | 3.526174    |
| training/sac_pi/pi_entropy     | 3.3822758   |
| training/sac_pi/pi_global_norm | 1.9748249   |
| training/sac_pi/policy_loss    | -220.39264  |
| training/sac_pi/std            | 0.45966846  |
| training/sac_pi/valid_num      | 4997.0      |
| training/sac_Q/q1              | 215.18747   |
| training/sac_Q/q2              | 214.73193   |
| training/sac_Q/q2_loss         | 83.696396   |
| training/sac_Q/q_global_norm   | 287.04276   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17384541 |
| epoch                          | 404        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5158.972   |
| evaluation/return-max          | 5204.2266  |
| evaluation/return-min          | 5107.4453  |
| evaluation/return-std          | 29.080969  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46212      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5158.972   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 194.32553  |
| Q-std                          | 141.5816   |
| Q_loss                         | 103.85388  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 404        |
| times/epoch_after_hook         | 1.98e-06   |
| times/epoch_before_hook        | 0.000143   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.00065    |
| times/evaluation_paths         | 41.5       |
| times/timestep_after_hook      | 0.0041     |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 62.4       |
| timestep                       | 1000       |
| timesteps_total                | 405000     |
| train-steps                    | 405000     |
| training/Q/q1_loss             | 103.36434  |
| training/sac_pi/alpha          | 0.17384566 |
| training/sac_pi/alpha_loss     | 0.15877122 |
| training/sac_pi/logp_pi        | 4.859693   |
| training/sac_pi/pi_entropy     | 3.4209294  |
| training/sac_pi/pi_global_norm | 1.7219899  |
| training/sac_pi/policy_loss    | -214.10648 |
| training/sac_pi/std            | 0.50195104 |
| training/sac_pi/valid_num      | 4919.0     |
| training/sac_Q/q1              | 202.84554  |
| training/sac_Q/q2              | 202.439    |
| training/sac_Q/q2_loss         | 103.78871  |
| training/sac_Q/q_global_norm   | 246.08905  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1696247   |
| epoch                          | 405         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4733.952    |
| evaluation/return-max          | 4796.9004   |
| evaluation/return-min          | 4666.037    |
| evaluation/return-std          | 44.783527   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46064       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4733.952    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 196.0474    |
| Q-std                          | 143.59015   |
| Q_loss                         | 98.94348    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 405         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000273    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000532    |
| times/evaluation_paths         | 42.8        |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 69.4        |
| timestep                       | 1000        |
| timesteps_total                | 406000      |
| train-steps                    | 406000      |
| training/Q/q1_loss             | 102.13303   |
| training/sac_pi/alpha          | 0.16963787  |
| training/sac_pi/alpha_loss     | 0.053557146 |
| training/sac_pi/logp_pi        | 4.840804    |
| training/sac_pi/pi_entropy     | 3.355267    |
| training/sac_pi/pi_global_norm | 2.1238809   |
| training/sac_pi/policy_loss    | -212.36798  |
| training/sac_pi/std            | 0.5049385   |
| training/sac_pi/valid_num      | 4953.0      |
| training/sac_Q/q1              | 200.52576   |
| training/sac_Q/q2              | 198.72397   |
| training/sac_Q/q2_loss         | 102.98248   |
| training/sac_Q/q_global_norm   | 232.02275   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17005146   |
| epoch                          | 406          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4726.7666    |
| evaluation/return-max          | 4821.0415    |
| evaluation/return-min          | 4601.58      |
| evaluation/return-std          | 60.442093    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.01         |
| model/origin_ret               | 85.3         |
| model/penalty_ret              | 81.5         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46264        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4726.7666    |
| perf/NormalizedReturn          | 1.03         |
| Q-avg                          | 200.98251    |
| Q-std                          | 145.79515    |
| Q_loss                         | 103.90805    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 406          |
| times/epoch_after_hook         | 1.83e-06     |
| times/epoch_before_hook        | 0.000261     |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.000546     |
| times/evaluation_paths         | 43.5         |
| times/timestep_after_hook      | 0.00404      |
| times/timestep_before_hook     | 0.00849      |
| times/train                    | 67.8         |
| timestep                       | 1000         |
| timesteps_total                | 407000       |
| train-steps                    | 407000       |
| training/Q/q1_loss             | 109.56903    |
| training/sac_pi/alpha          | 0.17006393   |
| training/sac_pi/alpha_loss     | -0.036183745 |
| training/sac_pi/logp_pi        | 4.100134     |
| training/sac_pi/pi_entropy     | 3.6125932    |
| training/sac_pi/pi_global_norm | 1.6361558    |
| training/sac_pi/policy_loss    | -218.70401   |
| training/sac_pi/std            | 0.50247836   |
| training/sac_pi/valid_num      | 4957.0       |
| training/sac_Q/q1              | 210.32785    |
| training/sac_Q/q2              | 208.45381    |
| training/sac_Q/q2_loss         | 110.02612    |
| training/sac_Q/q_global_norm   | 297.92444    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17526993 |
| epoch                          | 407        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4340.3076  |
| evaluation/return-max          | 4565.3086  |
| evaluation/return-min          | 4097.6997  |
| evaluation/return-std          | 192.57559  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46128      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4340.3076  |
| perf/NormalizedReturn          | 0.945      |
| Q-avg                          | 213.01094  |
| Q-std                          | 89.74801   |
| Q_loss                         | 95.4893    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 407        |
| times/epoch_after_hook         | 3.16e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000533   |
| times/evaluation_paths         | 44.2       |
| times/timestep_after_hook      | 0.00436    |
| times/timestep_before_hook     | 0.00874    |
| times/train                    | 71.6       |
| timestep                       | 1000       |
| timesteps_total                | 408000     |
| train-steps                    | 408000     |
| training/Q/q1_loss             | 104.866844 |
| training/sac_pi/alpha          | 0.17523837 |
| training/sac_pi/alpha_loss     | 0.11948507 |
| training/sac_pi/logp_pi        | 4.2583933  |
| training/sac_pi/pi_entropy     | 3.4585106  |
| training/sac_pi/pi_global_norm | 1.8214496  |
| training/sac_pi/policy_loss    | -207.0218  |
| training/sac_pi/std            | 0.4936747  |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 199.02628  |
| training/sac_Q/q2              | 198.19395  |
| training/sac_Q/q2_loss         | 104.33237  |
| training/sac_Q/q_global_norm   | 258.07266  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16907074  |
| epoch                          | 408         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4991.6675   |
| evaluation/return-max          | 5029.5312   |
| evaluation/return-min          | 4908.589    |
| evaluation/return-std          | 34.85224    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46279       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4991.6675   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 212.60959   |
| Q-std                          | 99.48482    |
| Q_loss                         | 105.577194  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 408         |
| times/epoch_after_hook         | 1.95e-06    |
| times/epoch_before_hook        | 0.000202    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000545    |
| times/evaluation_paths         | 38.2        |
| times/timestep_after_hook      | 0.00416     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 409000      |
| train-steps                    | 409000      |
| training/Q/q1_loss             | 101.379944  |
| training/sac_pi/alpha          | 0.16907744  |
| training/sac_pi/alpha_loss     | -0.15139413 |
| training/sac_pi/logp_pi        | 4.2139916   |
| training/sac_pi/pi_entropy     | 3.5630288   |
| training/sac_pi/pi_global_norm | 1.7971936   |
| training/sac_pi/policy_loss    | -212.34917  |
| training/sac_pi/std            | 0.5127868   |
| training/sac_pi/valid_num      | 4940.0      |
| training/sac_Q/q1              | 202.54982   |
| training/sac_Q/q2              | 202.10794   |
| training/sac_Q/q2_loss         | 101.91842   |
| training/sac_Q/q_global_norm   | 248.68068   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16758853   |
| epoch                          | 409          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4608.573     |
| evaluation/return-max          | 4725.348     |
| evaluation/return-min          | 4467.7       |
| evaluation/return-std          | 85.981094    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.01         |
| model/origin_ret               | 86           |
| model/penalty_ret              | 81.5         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46080        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4608.573     |
| perf/NormalizedReturn          | 1            |
| Q-avg                          | 196.64745    |
| Q-std                          | 128.05884    |
| Q_loss                         | 113.74609    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 409          |
| times/epoch_after_hook         | 3.32e-06     |
| times/epoch_before_hook        | 0.000317     |
| times/epoch_rollout_model      | 486          |
| times/evaluation_metrics       | 0.000575     |
| times/evaluation_paths         | 36.2         |
| times/timestep_after_hook      | 0.00404      |
| times/timestep_before_hook     | 0.00843      |
| times/train                    | 71.1         |
| timestep                       | 1000         |
| timesteps_total                | 410000       |
| train-steps                    | 410000       |
| training/Q/q1_loss             | 95.62178     |
| training/sac_pi/alpha          | 0.16761446   |
| training/sac_pi/alpha_loss     | -0.079261936 |
| training/sac_pi/logp_pi        | 3.989846     |
| training/sac_pi/pi_entropy     | 3.3115342    |
| training/sac_pi/pi_global_norm | 1.6112461    |
| training/sac_pi/policy_loss    | -218.71803   |
| training/sac_pi/std            | 0.48120192   |
| training/sac_pi/valid_num      | 4997.0       |
| training/sac_Q/q1              | 213.76616    |
| training/sac_Q/q2              | 211.6665     |
| training/sac_Q/q2_loss         | 95.64122     |
| training/sac_Q/q_global_norm   | 222.85954    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17317164   |
| epoch                          | 410          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4840.5327    |
| evaluation/return-max          | 4902.751     |
| evaluation/return-min          | 4745.905     |
| evaluation/return-std          | 50.226673    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3            |
| model/origin_ret               | 85           |
| model/penalty_ret              | 81           |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46208        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4840.5327    |
| perf/NormalizedReturn          | 1.05         |
| Q-avg                          | 199.66347    |
| Q-std                          | 124.718216   |
| Q_loss                         | 115.01935    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 410          |
| times/epoch_after_hook         | 2.05e-06     |
| times/epoch_before_hook        | 0.000132     |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.000814     |
| times/evaluation_paths         | 37.8         |
| times/timestep_after_hook      | 0.00404      |
| times/timestep_before_hook     | 0.00854      |
| times/train                    | 65.9         |
| timestep                       | 1000         |
| timesteps_total                | 411000       |
| train-steps                    | 411000       |
| training/Q/q1_loss             | 83.42595     |
| training/sac_pi/alpha          | 0.1731533    |
| training/sac_pi/alpha_loss     | -0.039981306 |
| training/sac_pi/logp_pi        | 4.9630723    |
| training/sac_pi/pi_entropy     | 3.159536     |
| training/sac_pi/pi_global_norm | 1.5649722    |
| training/sac_pi/policy_loss    | -218.59154   |
| training/sac_pi/std            | 0.4763523    |
| training/sac_pi/valid_num      | 4980.0       |
| training/sac_Q/q1              | 210.0752     |
| training/sac_Q/q2              | 210.05258    |
| training/sac_Q/q2_loss         | 83.937904    |
| training/sac_Q/q_global_norm   | 223.33194    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16635835   |
| epoch                          | 411          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5055.6587    |
| evaluation/return-max          | 5179.499     |
| evaluation/return-min          | 4909.214     |
| evaluation/return-std          | 89.197876    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.03         |
| model/origin_ret               | 85.2         |
| model/penalty_ret              | 81           |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46214        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5055.6587    |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 204.07065    |
| Q-std                          | 116.42815    |
| Q_loss                         | 86.260994    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 411          |
| times/epoch_after_hook         | 1.84e-06     |
| times/epoch_before_hook        | 0.000145     |
| times/epoch_rollout_model      | 494          |
| times/evaluation_metrics       | 0.000545     |
| times/evaluation_paths         | 34.9         |
| times/timestep_after_hook      | 0.00396      |
| times/timestep_before_hook     | 0.00844      |
| times/train                    | 66.1         |
| timestep                       | 1000         |
| timesteps_total                | 412000       |
| train-steps                    | 412000       |
| training/Q/q1_loss             | 78.8135      |
| training/sac_pi/alpha          | 0.1663742    |
| training/sac_pi/alpha_loss     | -0.048516594 |
| training/sac_pi/logp_pi        | 3.7751572    |
| training/sac_pi/pi_entropy     | 3.390946     |
| training/sac_pi/pi_global_norm | 1.7773399    |
| training/sac_pi/policy_loss    | -208.97206   |
| training/sac_pi/std            | 0.4710441    |
| training/sac_pi/valid_num      | 4956.0       |
| training/sac_Q/q1              | 201.38484    |
| training/sac_Q/q2              | 201.50395    |
| training/sac_Q/q2_loss         | 79.11266     |
| training/sac_Q/q_global_norm   | 261.2867     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1692826  |
| epoch                          | 412        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5084.1636  |
| evaluation/return-max          | 5157.2163  |
| evaluation/return-min          | 5029.7373  |
| evaluation/return-std          | 46.5938    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46254      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5084.1636  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 211.12798  |
| Q-std                          | 119.74701  |
| Q_loss                         | 123.85412  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 412        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 518        |
| times/evaluation_metrics       | 0.000686   |
| times/evaluation_paths         | 47.5       |
| times/timestep_after_hook      | 0.00409    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 64.4       |
| timestep                       | 1000       |
| timesteps_total                | 413000     |
| train-steps                    | 413000     |
| training/Q/q1_loss             | 124.26991  |
| training/sac_pi/alpha          | 0.16923825 |
| training/sac_pi/alpha_loss     | 0.5016678  |
| training/sac_pi/logp_pi        | 3.9693809  |
| training/sac_pi/pi_entropy     | 3.4020524  |
| training/sac_pi/pi_global_norm | 1.5916046  |
| training/sac_pi/policy_loss    | -213.99834 |
| training/sac_pi/std            | 0.46981984 |
| training/sac_pi/valid_num      | 4972.0     |
| training/sac_Q/q1              | 208.28299  |
| training/sac_Q/q2              | 208.10385  |
| training/sac_Q/q2_loss         | 124.12083  |
| training/sac_Q/q_global_norm   | 299.28952  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17058279  |
| epoch                          | 413         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5057.782    |
| evaluation/return-max          | 5110.9053   |
| evaluation/return-min          | 5018.3135   |
| evaluation/return-std          | 27.867544   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46228       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5057.782    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 205.90427   |
| Q-std                          | 99.391785   |
| Q_loss                         | 94.51442    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 413         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000305    |
| times/epoch_rollout_model      | 501         |
| times/evaluation_metrics       | 0.000583    |
| times/evaluation_paths         | 34.3        |
| times/timestep_after_hook      | 0.004       |
| times/timestep_before_hook     | 0.00847     |
| times/train                    | 67.9        |
| timestep                       | 1000        |
| timesteps_total                | 414000      |
| train-steps                    | 414000      |
| training/Q/q1_loss             | 104.26512   |
| training/sac_pi/alpha          | 0.17061     |
| training/sac_pi/alpha_loss     | -0.12627359 |
| training/sac_pi/logp_pi        | 4.7670846   |
| training/sac_pi/pi_entropy     | 3.3912215   |
| training/sac_pi/pi_global_norm | 1.6940683   |
| training/sac_pi/policy_loss    | -209.91493  |
| training/sac_pi/std            | 0.50312084  |
| training/sac_pi/valid_num      | 4961.0      |
| training/sac_Q/q1              | 198.75993   |
| training/sac_Q/q2              | 198.20317   |
| training/sac_Q/q2_loss         | 105.06786   |
| training/sac_Q/q_global_norm   | 194.25066   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17095417 |
| epoch                          | 414        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4914.454   |
| evaluation/return-max          | 4930.655   |
| evaluation/return-min          | 4885.388   |
| evaluation/return-std          | 13.56252   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46188      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4914.454   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 217.76518  |
| Q-std                          | 88.42723   |
| Q_loss                         | 83.352295  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 414        |
| times/epoch_after_hook         | 1.65e-06   |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000571   |
| times/evaluation_paths         | 36.5       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 62.1       |
| timestep                       | 1000       |
| timesteps_total                | 415000     |
| train-steps                    | 415000     |
| training/Q/q1_loss             | 99.938194  |
| training/sac_pi/alpha          | 0.17097254 |
| training/sac_pi/alpha_loss     | 0.05352424 |
| training/sac_pi/logp_pi        | 3.749665   |
| training/sac_pi/pi_entropy     | 3.5756555  |
| training/sac_pi/pi_global_norm | 1.4947401  |
| training/sac_pi/policy_loss    | -208.14821 |
| training/sac_pi/std            | 0.4788636  |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 202.15637  |
| training/sac_Q/q2              | 201.88383  |
| training/sac_Q/q2_loss         | 99.488235  |
| training/sac_Q/q_global_norm   | 231.90103  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16875131 |
| epoch                          | 415        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4783.046   |
| evaluation/return-max          | 4805.7617  |
| evaluation/return-min          | 4748.109   |
| evaluation/return-std          | 18.767576  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46187      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4783.046   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 213.89494  |
| Q-std                          | 103.842    |
| Q_loss                         | 123.430305 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 415        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000575   |
| times/evaluation_paths         | 35.9       |
| times/timestep_after_hook      | 0.00418    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 63.2       |
| timestep                       | 1000       |
| timesteps_total                | 416000     |
| train-steps                    | 416000     |
| training/Q/q1_loss             | 108.36963  |
| training/sac_pi/alpha          | 0.16875671 |
| training/sac_pi/alpha_loss     | -0.185335  |
| training/sac_pi/logp_pi        | 4.283826   |
| training/sac_pi/pi_entropy     | 3.5360222  |
| training/sac_pi/pi_global_norm | 1.4496846  |
| training/sac_pi/policy_loss    | -219.21303 |
| training/sac_pi/std            | 0.5235469  |
| training/sac_pi/valid_num      | 4956.0     |
| training/sac_Q/q1              | 209.57198  |
| training/sac_Q/q2              | 208.5959   |
| training/sac_Q/q2_loss         | 108.05798  |
| training/sac_Q/q_global_norm   | 283.59482  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1698635  |
| epoch                          | 416        |
| evaluation/episode-length-avg  | 925        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 253        |
| evaluation/episode-length-std  | 224        |
| evaluation/return-average      | 4431.2896  |
| evaluation/return-max          | 4936.716   |
| evaluation/return-min          | 894.2363   |
| evaluation/return-std          | 1181.1375  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46153      |
| perf/AverageLength             | 925        |
| perf/AverageReturn             | 4431.2896  |
| perf/NormalizedReturn          | 0.965      |
| Q-avg                          | 213.44846  |
| Q-std                          | 101.77286  |
| Q_loss                         | 111.76574  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 416        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000661   |
| times/evaluation_paths         | 32.1       |
| times/timestep_after_hook      | 0.00422    |
| times/timestep_before_hook     | 0.0087     |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 417000     |
| train-steps                    | 417000     |
| training/Q/q1_loss             | 87.61179   |
| training/sac_pi/alpha          | 0.16984671 |
| training/sac_pi/alpha_loss     | 0.0793248  |
| training/sac_pi/logp_pi        | 3.5836558  |
| training/sac_pi/pi_entropy     | 3.352941   |
| training/sac_pi/pi_global_norm | 1.6201798  |
| training/sac_pi/policy_loss    | -220.3255  |
| training/sac_pi/std            | 0.4587847  |
| training/sac_pi/valid_num      | 5025.0     |
| training/sac_Q/q1              | 214.983    |
| training/sac_Q/q2              | 215.998    |
| training/sac_Q/q2_loss         | 87.951454  |
| training/sac_Q/q_global_norm   | 187.29955  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1694918  |
| epoch                          | 417        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4798.87    |
| evaluation/return-max          | 4824.2188  |
| evaluation/return-min          | 4756.0005  |
| evaluation/return-std          | 20.935678  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85         |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46195      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4798.87    |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 217.85027  |
| Q-std                          | 93.01223   |
| Q_loss                         | 101.57696  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 417        |
| times/epoch_after_hook         | 3.37e-06   |
| times/epoch_before_hook        | 0.000261   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000523   |
| times/evaluation_paths         | 34.1       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 418000     |
| train-steps                    | 418000     |
| training/Q/q1_loss             | 113.39765  |
| training/sac_pi/alpha          | 0.16949779 |
| training/sac_pi/alpha_loss     | 0.13481465 |
| training/sac_pi/logp_pi        | 4.614051   |
| training/sac_pi/pi_entropy     | 3.524849   |
| training/sac_pi/pi_global_norm | 1.5810796  |
| training/sac_pi/policy_loss    | -206.56967 |
| training/sac_pi/std            | 0.5055558  |
| training/sac_pi/valid_num      | 4917.0     |
| training/sac_Q/q1              | 195.68047  |
| training/sac_Q/q2              | 194.9625   |
| training/sac_Q/q2_loss         | 113.52145  |
| training/sac_Q/q_global_norm   | 236.40134  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16626573 |
| epoch                          | 418        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4857.3984  |
| evaluation/return-max          | 4939.3877  |
| evaluation/return-min          | 4821.1763  |
| evaluation/return-std          | 34.317795  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46210      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4857.3984  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 212.95084  |
| Q-std                          | 128.09785  |
| Q_loss                         | 122.4461   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 418        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 37.5       |
| times/timestep_after_hook      | 0.00423    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 419000     |
| train-steps                    | 419000     |
| training/Q/q1_loss             | 117.26265  |
| training/sac_pi/alpha          | 0.16625842 |
| training/sac_pi/alpha_loss     | 0.32073525 |
| training/sac_pi/logp_pi        | 4.7104216  |
| training/sac_pi/pi_entropy     | 3.4021087  |
| training/sac_pi/pi_global_norm | 2.072226   |
| training/sac_pi/policy_loss    | -216.57521 |
| training/sac_pi/std            | 0.4992908  |
| training/sac_pi/valid_num      | 4926.0     |
| training/sac_Q/q1              | 206.43413  |
| training/sac_Q/q2              | 204.92935  |
| training/sac_Q/q2_loss         | 118.079765 |
| training/sac_Q/q_global_norm   | 272.76187  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17218585 |
| epoch                          | 419        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5253.8584  |
| evaluation/return-max          | 5280.051   |
| evaluation/return-min          | 5210.4316  |
| evaluation/return-std          | 21.501162  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46338      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5253.8584  |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 206.38826  |
| Q-std                          | 127.05968  |
| Q_loss                         | 119.31635  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 419        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000543   |
| times/evaluation_paths         | 34         |
| times/timestep_after_hook      | 0.00408    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 420000     |
| train-steps                    | 420000     |
| training/Q/q1_loss             | 86.736176  |
| training/sac_pi/alpha          | 0.17216994 |
| training/sac_pi/alpha_loss     | 0.02170027 |
| training/sac_pi/logp_pi        | 3.9903252  |
| training/sac_pi/pi_entropy     | 3.4478905  |
| training/sac_pi/pi_global_norm | 1.3672973  |
| training/sac_pi/policy_loss    | -213.64757 |
| training/sac_pi/std            | 0.48312342 |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 204.55737  |
| training/sac_Q/q2              | 204.78838  |
| training/sac_Q/q2_loss         | 86.78012   |
| training/sac_Q/q_global_norm   | 223.86833  |
--------------------------------------------------------------------------------
[WARN] 420 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.17050138 |
| epoch                          | 420        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5126.642   |
| evaluation/return-max          | 5218.1807  |
| evaluation/return-min          | 4985.998   |
| evaluation/return-std          | 68.82901   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 87.2       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46148      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5126.642   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 207.70651  |
| Q-std                          | 106.39164  |
| Q_loss                         | 88.37182   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 420        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000602   |
| times/evaluation_paths         | 37         |
| times/timestep_after_hook      | 0.00418    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 67.8       |
| timestep                       | 1000       |
| timesteps_total                | 421000     |
| train-steps                    | 421000     |
| training/Q/q1_loss             | 90.1058    |
| training/sac_pi/alpha          | 0.17054151 |
| training/sac_pi/alpha_loss     | 0.15691021 |
| training/sac_pi/logp_pi        | 4.455246   |
| training/sac_pi/pi_entropy     | 3.5016313  |
| training/sac_pi/pi_global_norm | 1.6206298  |
| training/sac_pi/policy_loss    | -222.38121 |
| training/sac_pi/std            | 0.50827384 |
| training/sac_pi/valid_num      | 4973.0     |
| training/sac_Q/q1              | 213.80566  |
| training/sac_Q/q2              | 212.43484  |
| training/sac_Q/q2_loss         | 88.86856   |
| training/sac_Q/q_global_norm   | 215.47273  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16949837 |
| epoch                          | 421        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5005.373   |
| evaluation/return-max          | 5134.801   |
| evaluation/return-min          | 4962.3125  |
| evaluation/return-std          | 47.29216   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 45893      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5005.373   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 213.33139  |
| Q-std                          | 116.1132   |
| Q_loss                         | 106.42288  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 421        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000264   |
| times/epoch_rollout_model      | 506        |
| times/evaluation_metrics       | 0.000557   |
| times/evaluation_paths         | 35.9       |
| times/timestep_after_hook      | 0.00449    |
| times/timestep_before_hook     | 0.00877    |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 422000     |
| train-steps                    | 422000     |
| training/Q/q1_loss             | 107.99047  |
| training/sac_pi/alpha          | 0.16951166 |
| training/sac_pi/alpha_loss     | -0.1498471 |
| training/sac_pi/logp_pi        | 3.6778598  |
| training/sac_pi/pi_entropy     | 3.4092476  |
| training/sac_pi/pi_global_norm | 1.8099539  |
| training/sac_pi/policy_loss    | -217.33987 |
| training/sac_pi/std            | 0.4655421  |
| training/sac_pi/valid_num      | 4992.0     |
| training/sac_Q/q1              | 212.22432  |
| training/sac_Q/q2              | 211.37439  |
| training/sac_Q/q2_loss         | 109.67447  |
| training/sac_Q/q_global_norm   | 252.71999  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17535384 |
| epoch                          | 422        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4864.118   |
| evaluation/return-max          | 4920.74    |
| evaluation/return-min          | 4806.2383  |
| evaluation/return-std          | 38.679123  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46255      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4864.118   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 202.51413  |
| Q-std                          | 129.91635  |
| Q_loss                         | 111.57205  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 422        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 514        |
| times/evaluation_metrics       | 0.000568   |
| times/evaluation_paths         | 36.8       |
| times/timestep_after_hook      | 0.00406    |
| times/timestep_before_hook     | 0.00862    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 423000     |
| train-steps                    | 423000     |
| training/Q/q1_loss             | 96.9297    |
| training/sac_pi/alpha          | 0.17534052 |
| training/sac_pi/alpha_loss     | 0.31727868 |
| training/sac_pi/logp_pi        | 4.877514   |
| training/sac_pi/pi_entropy     | 3.4640136  |
| training/sac_pi/pi_global_norm | 1.5082753  |
| training/sac_pi/policy_loss    | -221.31104 |
| training/sac_pi/std            | 0.51413494 |
| training/sac_pi/valid_num      | 4929.0     |
| training/sac_Q/q1              | 206.79858  |
| training/sac_Q/q2              | 203.37622  |
| training/sac_Q/q2_loss         | 97.71404   |
| training/sac_Q/q_global_norm   | 280.18542  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17712386  |
| epoch                          | 423         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4950.793    |
| evaluation/return-max          | 5059.5703   |
| evaluation/return-min          | 4852.949    |
| evaluation/return-std          | 64.99195    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46148       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4950.793    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 219.02017   |
| Q-std                          | 98.32701    |
| Q_loss                         | 78.686295   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 423         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 507         |
| times/evaluation_metrics       | 0.000554    |
| times/evaluation_paths         | 35.4        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00863     |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 424000      |
| train-steps                    | 424000      |
| training/Q/q1_loss             | 103.025444  |
| training/sac_pi/alpha          | 0.17710635  |
| training/sac_pi/alpha_loss     | -0.21540397 |
| training/sac_pi/logp_pi        | 4.9255104   |
| training/sac_pi/pi_entropy     | 3.4729028   |
| training/sac_pi/pi_global_norm | 1.9512465   |
| training/sac_pi/policy_loss    | -217.84587  |
| training/sac_pi/std            | 0.51918703  |
| training/sac_pi/valid_num      | 4938.0      |
| training/sac_Q/q1              | 205.53305   |
| training/sac_Q/q2              | 202.84671   |
| training/sac_Q/q2_loss         | 103.08104   |
| training/sac_Q/q_global_norm   | 285.24713   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17417584 |
| epoch                          | 424        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 3997.4148  |
| evaluation/return-max          | 4168.5146  |
| evaluation/return-min          | 3851.0667  |
| evaluation/return-std          | 100.03225  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46246      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 3997.4148  |
| perf/NormalizedReturn          | 0.87       |
| Q-avg                          | 212.07626  |
| Q-std                          | 112.05826  |
| Q_loss                         | 103.7001   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 424        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 511        |
| times/evaluation_metrics       | 0.000669   |
| times/evaluation_paths         | 36.6       |
| times/timestep_after_hook      | 0.00425    |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 67.1       |
| timestep                       | 1000       |
| timesteps_total                | 425000     |
| train-steps                    | 425000     |
| training/Q/q1_loss             | 93.643074  |
| training/sac_pi/alpha          | 0.1741778  |
| training/sac_pi/alpha_loss     | 0.15777907 |
| training/sac_pi/logp_pi        | 4.645214   |
| training/sac_pi/pi_entropy     | 3.4877827  |
| training/sac_pi/pi_global_norm | 1.82447    |
| training/sac_pi/policy_loss    | -214.26237 |
| training/sac_pi/std            | 0.50739986 |
| training/sac_pi/valid_num      | 4879.0     |
| training/sac_Q/q1              | 198.4934   |
| training/sac_Q/q2              | 196.38818  |
| training/sac_Q/q2_loss         | 94.05457   |
| training/sac_Q/q_global_norm   | 263.3538   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17528695  |
| epoch                          | 425         |
| evaluation/episode-length-avg  | 225         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 128         |
| evaluation/episode-length-std  | 259         |
| evaluation/return-average      | 783.4321    |
| evaluation/return-max          | 4746.8765   |
| evaluation/return-min          | 315.79807   |
| evaluation/return-std          | 1321.2198   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46315       |
| perf/AverageLength             | 225         |
| perf/AverageReturn             | 783.4321    |
| perf/NormalizedReturn          | 0.17        |
| Q-avg                          | 203.48843   |
| Q-std                          | 114.65286   |
| Q_loss                         | 104.72008   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 425         |
| times/epoch_after_hook         | 1.99e-06    |
| times/epoch_before_hook        | 0.000288    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000534    |
| times/evaluation_paths         | 9.55        |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.00853     |
| times/train                    | 65.3        |
| timestep                       | 1000        |
| timesteps_total                | 426000      |
| train-steps                    | 426000      |
| training/Q/q1_loss             | 104.96086   |
| training/sac_pi/alpha          | 0.17531331  |
| training/sac_pi/alpha_loss     | -0.21067962 |
| training/sac_pi/logp_pi        | 3.9140415   |
| training/sac_pi/pi_entropy     | 3.381782    |
| training/sac_pi/pi_global_norm | 2.5586581   |
| training/sac_pi/policy_loss    | -221.45796  |
| training/sac_pi/std            | 0.48614806  |
| training/sac_pi/valid_num      | 4957.0      |
| training/sac_Q/q1              | 213.00911   |
| training/sac_Q/q2              | 211.92252   |
| training/sac_Q/q2_loss         | 104.86733   |
| training/sac_Q/q_global_norm   | 238.0164    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1762601   |
| epoch                          | 426         |
| evaluation/episode-length-avg  | 885         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 709         |
| evaluation/episode-length-std  | 101         |
| evaluation/return-average      | 4275.5117   |
| evaluation/return-max          | 5013.0757   |
| evaluation/return-min          | 3308.9119   |
| evaluation/return-std          | 578.0237    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46378       |
| perf/AverageLength             | 885         |
| perf/AverageReturn             | 4275.5117   |
| perf/NormalizedReturn          | 0.931       |
| Q-avg                          | 215.84248   |
| Q-std                          | 93.567604   |
| Q_loss                         | 91.47634    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 426         |
| times/epoch_after_hook         | 1.93e-06    |
| times/epoch_before_hook        | 8.01e-05    |
| times/epoch_rollout_model      | 517         |
| times/evaluation_metrics       | 0.0006      |
| times/evaluation_paths         | 33.2        |
| times/timestep_after_hook      | 0.00415     |
| times/timestep_before_hook     | 0.0088      |
| times/train                    | 65          |
| timestep                       | 1000        |
| timesteps_total                | 427000      |
| train-steps                    | 427000      |
| training/Q/q1_loss             | 95.38897    |
| training/sac_pi/alpha          | 0.17631522  |
| training/sac_pi/alpha_loss     | -0.35528368 |
| training/sac_pi/logp_pi        | 3.9694386   |
| training/sac_pi/pi_entropy     | 3.5232918   |
| training/sac_pi/pi_global_norm | 1.6562023   |
| training/sac_pi/policy_loss    | -220.95581  |
| training/sac_pi/std            | 0.49884757  |
| training/sac_pi/valid_num      | 4996.0      |
| training/sac_Q/q1              | 212.108     |
| training/sac_Q/q2              | 210.95447   |
| training/sac_Q/q2_loss         | 94.80481    |
| training/sac_Q/q_global_norm   | 231.51608   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17018352  |
| epoch                          | 427         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5037.0005   |
| evaluation/return-max          | 5086.963    |
| evaluation/return-min          | 4998.128    |
| evaluation/return-std          | 28.302734   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46163       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5037.0005   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 206.868     |
| Q-std                          | 99.509514   |
| Q_loss                         | 105.40372   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 427         |
| times/epoch_after_hook         | 1.99e-06    |
| times/epoch_before_hook        | 0.000155    |
| times/epoch_rollout_model      | 506         |
| times/evaluation_metrics       | 0.000573    |
| times/evaluation_paths         | 34          |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.00864     |
| times/train                    | 65.5        |
| timestep                       | 1000        |
| timesteps_total                | 428000      |
| train-steps                    | 428000      |
| training/Q/q1_loss             | 110.502594  |
| training/sac_pi/alpha          | 0.17020012  |
| training/sac_pi/alpha_loss     | -0.02646709 |
| training/sac_pi/logp_pi        | 4.629181    |
| training/sac_pi/pi_entropy     | 3.2628136   |
| training/sac_pi/pi_global_norm | 1.68646     |
| training/sac_pi/policy_loss    | -206.8848   |
| training/sac_pi/std            | 0.47665104  |
| training/sac_pi/valid_num      | 4969.0      |
| training/sac_Q/q1              | 198.92519   |
| training/sac_Q/q2              | 197.74615   |
| training/sac_Q/q2_loss         | 109.51098   |
| training/sac_Q/q_global_norm   | 262.55646   |
---------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.17074054    |
| epoch                          | 428           |
| evaluation/episode-length-avg  | 560           |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 94            |
| evaluation/episode-length-std  | 441           |
| evaluation/return-average      | 2569.4478     |
| evaluation/return-max          | 4834.454      |
| evaluation/return-min          | 210.08641     |
| evaluation/return-std          | 2257.1658     |
| model/max_penalty              | 7.27          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 3.01          |
| model/origin_ret               | 85.7          |
| model/penalty_ret              | 82.2          |
| model/val_loss                 | 0.39125705    |
| model/valid_num                | 46116         |
| perf/AverageLength             | 560           |
| perf/AverageReturn             | 2569.4478     |
| perf/NormalizedReturn          | 0.559         |
| Q-avg                          | 217.21062     |
| Q-std                          | 121.64268     |
| Q_loss                         | 87.046776     |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 428           |
| times/epoch_after_hook         | 2.03e-06      |
| times/epoch_before_hook        | 0.000139      |
| times/epoch_rollout_model      | 497           |
| times/evaluation_metrics       | 0.000588      |
| times/evaluation_paths         | 19.1          |
| times/timestep_after_hook      | 0.0041        |
| times/timestep_before_hook     | 0.00837       |
| times/train                    | 60            |
| timestep                       | 1000          |
| timesteps_total                | 429000        |
| train-steps                    | 429000        |
| training/Q/q1_loss             | 93.4814       |
| training/sac_pi/alpha          | 0.17073822    |
| training/sac_pi/alpha_loss     | -0.0077184197 |
| training/sac_pi/logp_pi        | 4.775111      |
| training/sac_pi/pi_entropy     | 3.6656837     |
| training/sac_pi/pi_global_norm | 2.0624206     |
| training/sac_pi/policy_loss    | -217.41312    |
| training/sac_pi/std            | 0.55547535    |
| training/sac_pi/valid_num      | 4926.0        |
| training/sac_Q/q1              | 205.37822     |
| training/sac_Q/q2              | 202.81258     |
| training/sac_Q/q2_loss         | 94.43103      |
| training/sac_Q/q_global_norm   | 290.7415      |
-----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16594712 |
| epoch                          | 429        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4834.2646  |
| evaluation/return-max          | 4873.101   |
| evaluation/return-min          | 4762.663   |
| evaluation/return-std          | 33.723755  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46291      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4834.2646  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 209.3239   |
| Q-std                          | 113.21204  |
| Q_loss                         | 70.05589   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 429        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000309   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000661   |
| times/evaluation_paths         | 44.6       |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 61.5       |
| timestep                       | 1000       |
| timesteps_total                | 430000     |
| train-steps                    | 430000     |
| training/Q/q1_loss             | 115.68542  |
| training/sac_pi/alpha          | 0.16594861 |
| training/sac_pi/alpha_loss     | 0.16010618 |
| training/sac_pi/logp_pi        | 4.942612   |
| training/sac_pi/pi_entropy     | 3.3245323  |
| training/sac_pi/pi_global_norm | 1.4617122  |
| training/sac_pi/policy_loss    | -213.60936 |
| training/sac_pi/std            | 0.49573377 |
| training/sac_pi/valid_num      | 4930.0     |
| training/sac_Q/q1              | 201.86559  |
| training/sac_Q/q2              | 200.36197  |
| training/sac_Q/q2_loss         | 114.99745  |
| training/sac_Q/q_global_norm   | 268.76596  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17087711  |
| epoch                          | 430         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4851.1655   |
| evaluation/return-max          | 4909.8438   |
| evaluation/return-min          | 4774.661    |
| evaluation/return-std          | 38.171135   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46120       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4851.1655   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 196.11832   |
| Q-std                          | 161.31747   |
| Q_loss                         | 115.86581   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 430         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000555    |
| times/evaluation_paths         | 33.9        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 59.3        |
| timestep                       | 1000        |
| timesteps_total                | 431000      |
| train-steps                    | 431000      |
| training/Q/q1_loss             | 100.003235  |
| training/sac_pi/alpha          | 0.17090015  |
| training/sac_pi/alpha_loss     | -0.12229246 |
| training/sac_pi/logp_pi        | 3.8326087   |
| training/sac_pi/pi_entropy     | 3.4757698   |
| training/sac_pi/pi_global_norm | 1.7017555   |
| training/sac_pi/policy_loss    | -215.23161  |
| training/sac_pi/std            | 0.49494058  |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 209.05905   |
| training/sac_Q/q2              | 208.07663   |
| training/sac_Q/q2_loss         | 98.996254   |
| training/sac_Q/q_global_norm   | 231.01747   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16936514  |
| epoch                          | 431         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4963.12     |
| evaluation/return-max          | 5014.0127   |
| evaluation/return-min          | 4914.0244   |
| evaluation/return-std          | 32.957165   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46219       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4963.12     |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 219.53543   |
| Q-std                          | 93.51352    |
| Q_loss                         | 83.49727    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 431         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 501         |
| times/evaluation_metrics       | 0.00052     |
| times/evaluation_paths         | 33.4        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00846     |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 432000      |
| train-steps                    | 432000      |
| training/Q/q1_loss             | 89.61322    |
| training/sac_pi/alpha          | 0.16936997  |
| training/sac_pi/alpha_loss     | 0.015370058 |
| training/sac_pi/logp_pi        | 4.5358996   |
| training/sac_pi/pi_entropy     | 3.2444224   |
| training/sac_pi/pi_global_norm | 2.0448189   |
| training/sac_pi/policy_loss    | -218.50938  |
| training/sac_pi/std            | 0.48342708  |
| training/sac_pi/valid_num      | 4972.0      |
| training/sac_Q/q1              | 208.74643   |
| training/sac_Q/q2              | 209.02039   |
| training/sac_Q/q2_loss         | 89.35717    |
| training/sac_Q/q_global_norm   | 269.44      |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1724166  |
| epoch                          | 432        |
| evaluation/episode-length-avg  | 727        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 589        |
| evaluation/episode-length-std  | 137        |
| evaluation/return-average      | 3341.664   |
| evaluation/return-max          | 4933.9326  |
| evaluation/return-min          | 2629.7388  |
| evaluation/return-std          | 732.06995  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46348      |
| perf/AverageLength             | 727        |
| perf/AverageReturn             | 3341.664   |
| perf/NormalizedReturn          | 0.728      |
| Q-avg                          | 212.46774  |
| Q-std                          | 117.229996 |
| Q_loss                         | 81.90278   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 432        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000527   |
| times/evaluation_paths         | 27.5       |
| times/timestep_after_hook      | 0.00412    |
| times/timestep_before_hook     | 0.00857    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 433000     |
| train-steps                    | 433000     |
| training/Q/q1_loss             | 84.27225   |
| training/sac_pi/alpha          | 0.17237712 |
| training/sac_pi/alpha_loss     | 0.36054242 |
| training/sac_pi/logp_pi        | 3.903458   |
| training/sac_pi/pi_entropy     | 3.3700728  |
| training/sac_pi/pi_global_norm | 2.0495515  |
| training/sac_pi/policy_loss    | -223.91777 |
| training/sac_pi/std            | 0.45776856 |
| training/sac_pi/valid_num      | 5035.0     |
| training/sac_Q/q1              | 220.30222  |
| training/sac_Q/q2              | 219.28474  |
| training/sac_Q/q2_loss         | 83.23632   |
| training/sac_Q/q_global_norm   | 192.89226  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16790232 |
| epoch                          | 433        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4890.724   |
| evaluation/return-max          | 4940.702   |
| evaluation/return-min          | 4843.4595  |
| evaluation/return-std          | 29.938938  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46241      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4890.724   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 204.24251  |
| Q-std                          | 101.954926 |
| Q_loss                         | 81.90069   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 433        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.00031    |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000516   |
| times/evaluation_paths         | 36.1       |
| times/timestep_after_hook      | 0.00409    |
| times/timestep_before_hook     | 0.00842    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 434000     |
| train-steps                    | 434000     |
| training/Q/q1_loss             | 96.5286    |
| training/sac_pi/alpha          | 0.16792051 |
| training/sac_pi/alpha_loss     | 0.17354995 |
| training/sac_pi/logp_pi        | 4.3596525  |
| training/sac_pi/pi_entropy     | 3.3744576  |
| training/sac_pi/pi_global_norm | 2.0079677  |
| training/sac_pi/policy_loss    | -215.20857 |
| training/sac_pi/std            | 0.4889072  |
| training/sac_pi/valid_num      | 4972.0     |
| training/sac_Q/q1              | 204.17758  |
| training/sac_Q/q2              | 203.10635  |
| training/sac_Q/q2_loss         | 95.43131   |
| training/sac_Q/q_global_norm   | 216.15952  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16840544  |
| epoch                          | 434         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4849.045    |
| evaluation/return-max          | 4921.27     |
| evaluation/return-min          | 4801.8013   |
| evaluation/return-std          | 32.31933    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46446       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4849.045    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 203.103     |
| Q-std                          | 151.38622   |
| Q_loss                         | 96.45275    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 434         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.0005      |
| times/evaluation_paths         | 36.4        |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 435000      |
| train-steps                    | 435000      |
| training/Q/q1_loss             | 92.11842    |
| training/sac_pi/alpha          | 0.1684368   |
| training/sac_pi/alpha_loss     | -0.21980888 |
| training/sac_pi/logp_pi        | 4.6141777   |
| training/sac_pi/pi_entropy     | 3.3995805   |
| training/sac_pi/pi_global_norm | 1.4221337   |
| training/sac_pi/policy_loss    | -221.98265  |
| training/sac_pi/std            | 0.49141514  |
| training/sac_pi/valid_num      | 4894.0      |
| training/sac_Q/q1              | 208.78792   |
| training/sac_Q/q2              | 206.47934   |
| training/sac_Q/q2_loss         | 91.31837    |
| training/sac_Q/q_global_norm   | 359.56226   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16444805   |
| epoch                          | 435          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4817.1685    |
| evaluation/return-max          | 4900.485     |
| evaluation/return-min          | 4750.0713    |
| evaluation/return-std          | 46.041595    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.95         |
| model/origin_ret               | 84.5         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46203        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4817.1685    |
| perf/NormalizedReturn          | 1.05         |
| Q-avg                          | 207.83383    |
| Q-std                          | 136.72603    |
| Q_loss                         | 90.28257     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 435          |
| times/epoch_after_hook         | 2.06e-06     |
| times/epoch_before_hook        | 0.00017      |
| times/epoch_rollout_model      | 502          |
| times/evaluation_metrics       | 0.0008       |
| times/evaluation_paths         | 35.8         |
| times/timestep_after_hook      | 0.00411      |
| times/timestep_before_hook     | 0.00844      |
| times/train                    | 59.6         |
| timestep                       | 1000         |
| timesteps_total                | 436000       |
| train-steps                    | 436000       |
| training/Q/q1_loss             | 82.283905    |
| training/sac_pi/alpha          | 0.16444765   |
| training/sac_pi/alpha_loss     | -0.034556687 |
| training/sac_pi/logp_pi        | 3.9772537    |
| training/sac_pi/pi_entropy     | 3.5237331    |
| training/sac_pi/pi_global_norm | 1.9928707    |
| training/sac_pi/policy_loss    | -216.02744   |
| training/sac_pi/std            | 0.49246708   |
| training/sac_pi/valid_num      | 4990.0       |
| training/sac_Q/q1              | 209.01787    |
| training/sac_Q/q2              | 207.28067    |
| training/sac_Q/q2_loss         | 82.32095     |
| training/sac_Q/q_global_norm   | 263.04095    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1633211    |
| epoch                          | 436          |
| evaluation/episode-length-avg  | 659          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 145          |
| evaluation/episode-length-std  | 418          |
| evaluation/return-average      | 3021.1743    |
| evaluation/return-max          | 4894.0264    |
| evaluation/return-min          | 369.4344     |
| evaluation/return-std          | 2160.1233    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.96         |
| model/origin_ret               | 84.4         |
| model/penalty_ret              | 80.9         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46305        |
| perf/AverageLength             | 659          |
| perf/AverageReturn             | 3021.1743    |
| perf/NormalizedReturn          | 0.658        |
| Q-avg                          | 218.19943    |
| Q-std                          | 100.12028    |
| Q_loss                         | 83.409546    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 436          |
| times/epoch_after_hook         | 1.86e-06     |
| times/epoch_before_hook        | 0.000199     |
| times/epoch_rollout_model      | 500          |
| times/evaluation_metrics       | 0.000842     |
| times/evaluation_paths         | 23.3         |
| times/timestep_after_hook      | 0.00417      |
| times/timestep_before_hook     | 0.00862      |
| times/train                    | 61.4         |
| timestep                       | 1000         |
| timesteps_total                | 437000       |
| train-steps                    | 437000       |
| training/Q/q1_loss             | 103.6418     |
| training/sac_pi/alpha          | 0.1633482    |
| training/sac_pi/alpha_loss     | -0.061101206 |
| training/sac_pi/logp_pi        | 3.9247432    |
| training/sac_pi/pi_entropy     | 3.4589856    |
| training/sac_pi/pi_global_norm | 1.8038025    |
| training/sac_pi/policy_loss    | -213.2143    |
| training/sac_pi/std            | 0.48295316   |
| training/sac_pi/valid_num      | 4923.0       |
| training/sac_Q/q1              | 203.77763    |
| training/sac_Q/q2              | 202.9161     |
| training/sac_Q/q2_loss         | 103.86325    |
| training/sac_Q/q_global_norm   | 234.20576    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17099006 |
| epoch                          | 437        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4914.7812  |
| evaluation/return-max          | 4951.7573  |
| evaluation/return-min          | 4882.674   |
| evaluation/return-std          | 21.21821   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46282      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4914.7812  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 202.81088  |
| Q-std                          | 109.19315  |
| Q_loss                         | 108.963875 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 437        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000333   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000513   |
| times/evaluation_paths         | 34.8       |
| times/timestep_after_hook      | 0.00417    |
| times/timestep_before_hook     | 0.00858    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 438000     |
| train-steps                    | 438000     |
| training/Q/q1_loss             | 98.975975  |
| training/sac_pi/alpha          | 0.17100094 |
| training/sac_pi/alpha_loss     | 0.11229142 |
| training/sac_pi/logp_pi        | 4.0666704  |
| training/sac_pi/pi_entropy     | 3.4340851  |
| training/sac_pi/pi_global_norm | 1.7562548  |
| training/sac_pi/policy_loss    | -217.76736 |
| training/sac_pi/std            | 0.4664577  |
| training/sac_pi/valid_num      | 4994.0     |
| training/sac_Q/q1              | 210.7725   |
| training/sac_Q/q2              | 208.86014  |
| training/sac_Q/q2_loss         | 100.16312  |
| training/sac_Q/q_global_norm   | 242.9767   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17569007   |
| epoch                          | 438          |
| evaluation/episode-length-avg  | 552          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 244          |
| evaluation/episode-length-std  | 365          |
| evaluation/return-average      | 2517.548     |
| evaluation/return-max          | 4925.756     |
| evaluation/return-min          | 907.7133     |
| evaluation/return-std          | 1918.6235    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.01         |
| model/origin_ret               | 85.2         |
| model/penalty_ret              | 81.4         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46232        |
| perf/AverageLength             | 552          |
| perf/AverageReturn             | 2517.548     |
| perf/NormalizedReturn          | 0.548        |
| Q-avg                          | 209.46057    |
| Q-std                          | 107.303505   |
| Q_loss                         | 89.89317     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 438          |
| times/epoch_after_hook         | 1.76e-06     |
| times/epoch_before_hook        | 0.000162     |
| times/epoch_rollout_model      | 508          |
| times/evaluation_metrics       | 0.000708     |
| times/evaluation_paths         | 19           |
| times/timestep_after_hook      | 0.00425      |
| times/timestep_before_hook     | 0.00844      |
| times/train                    | 60.9         |
| timestep                       | 1000         |
| timesteps_total                | 439000       |
| train-steps                    | 439000       |
| training/Q/q1_loss             | 104.84438    |
| training/sac_pi/alpha          | 0.17567517   |
| training/sac_pi/alpha_loss     | -0.009458812 |
| training/sac_pi/logp_pi        | 4.0877333    |
| training/sac_pi/pi_entropy     | 3.3177419    |
| training/sac_pi/pi_global_norm | 1.7707688    |
| training/sac_pi/policy_loss    | -221.74883   |
| training/sac_pi/std            | 0.46927708   |
| training/sac_pi/valid_num      | 5032.0       |
| training/sac_Q/q1              | 216.19438    |
| training/sac_Q/q2              | 214.72746    |
| training/sac_Q/q2_loss         | 104.12918    |
| training/sac_Q/q_global_norm   | 232.4766     |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17139144  |
| epoch                          | 439         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4814.0435   |
| evaluation/return-max          | 4914.5547   |
| evaluation/return-min          | 4704.8135   |
| evaluation/return-std          | 78.02996    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46124       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4814.0435   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 218.7749    |
| Q-std                          | 89.89       |
| Q_loss                         | 100.654625  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 439         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000516    |
| times/evaluation_paths         | 45.2        |
| times/timestep_after_hook      | 0.00415     |
| times/timestep_before_hook     | 0.00862     |
| times/train                    | 62.6        |
| timestep                       | 1000        |
| timesteps_total                | 440000      |
| train-steps                    | 440000      |
| training/Q/q1_loss             | 96.07324    |
| training/sac_pi/alpha          | 0.17136258  |
| training/sac_pi/alpha_loss     | -0.11523256 |
| training/sac_pi/logp_pi        | 4.1864066   |
| training/sac_pi/pi_entropy     | 3.4532368   |
| training/sac_pi/pi_global_norm | 1.4610156   |
| training/sac_pi/policy_loss    | -224.42265  |
| training/sac_pi/std            | 0.48617274  |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 210.5606    |
| training/sac_Q/q2              | 210.39404   |
| training/sac_Q/q2_loss         | 95.99866    |
| training/sac_Q/q_global_norm   | 227.22838   |
---------------------------------------------------------------------------------
[WARN] 440 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.17573805 |
| epoch                          | 440        |
| evaluation/episode-length-avg  | 877        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 396        |
| evaluation/episode-length-std  | 212        |
| evaluation/return-average      | 3836.7852  |
| evaluation/return-max          | 4443.615   |
| evaluation/return-min          | 1551.2231  |
| evaluation/return-std          | 1009.5972  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46224      |
| perf/AverageLength             | 877        |
| perf/AverageReturn             | 3836.7852  |
| perf/NormalizedReturn          | 0.835      |
| Q-avg                          | 216.28789  |
| Q-std                          | 99.74231   |
| Q_loss                         | 87.08337   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 440        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.000589   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 441000     |
| train-steps                    | 441000     |
| training/Q/q1_loss             | 98.51457   |
| training/sac_pi/alpha          | 0.17573299 |
| training/sac_pi/alpha_loss     | 0.19581993 |
| training/sac_pi/logp_pi        | 4.604516   |
| training/sac_pi/pi_entropy     | 3.5029685  |
| training/sac_pi/pi_global_norm | 1.531055   |
| training/sac_pi/policy_loss    | -220.94977 |
| training/sac_pi/std            | 0.50457543 |
| training/sac_pi/valid_num      | 4915.0     |
| training/sac_Q/q1              | 212.63223  |
| training/sac_Q/q2              | 209.58672  |
| training/sac_Q/q2_loss         | 99.50811   |
| training/sac_Q/q_global_norm   | 266.0673   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1717706    |
| epoch                          | 441          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4697.395     |
| evaluation/return-max          | 4894.453     |
| evaluation/return-min          | 4462.4204    |
| evaluation/return-std          | 152.92978    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.96         |
| model/origin_ret               | 84.5         |
| model/penalty_ret              | 81.6         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46270        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4697.395     |
| perf/NormalizedReturn          | 1.02         |
| Q-avg                          | 212.65776    |
| Q-std                          | 108.664314   |
| Q_loss                         | 90.73851     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 441          |
| times/epoch_after_hook         | 2.08e-06     |
| times/epoch_before_hook        | 0.000311     |
| times/epoch_rollout_model      | 496          |
| times/evaluation_metrics       | 0.00112      |
| times/evaluation_paths         | 42.5         |
| times/timestep_after_hook      | 0.00409      |
| times/timestep_before_hook     | 0.00849      |
| times/train                    | 67.5         |
| timestep                       | 1000         |
| timesteps_total                | 442000       |
| train-steps                    | 442000       |
| training/Q/q1_loss             | 89.51504     |
| training/sac_pi/alpha          | 0.1717988    |
| training/sac_pi/alpha_loss     | -0.022928175 |
| training/sac_pi/logp_pi        | 3.572647     |
| training/sac_pi/pi_entropy     | 3.4585814    |
| training/sac_pi/pi_global_norm | 1.8359116    |
| training/sac_pi/policy_loss    | -219.04971   |
| training/sac_pi/std            | 0.46633893   |
| training/sac_pi/valid_num      | 4993.0       |
| training/sac_Q/q1              | 214.19405    |
| training/sac_Q/q2              | 213.41467    |
| training/sac_Q/q2_loss         | 89.58913     |
| training/sac_Q/q_global_norm   | 239.17973    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17210983 |
| epoch                          | 442        |
| evaluation/episode-length-avg  | 914        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 141        |
| evaluation/episode-length-std  | 258        |
| evaluation/return-average      | 4243.6357  |
| evaluation/return-max          | 4807.005   |
| evaluation/return-min          | 323.40723  |
| evaluation/return-std          | 1308.916   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46202      |
| perf/AverageLength             | 914        |
| perf/AverageReturn             | 4243.6357  |
| perf/NormalizedReturn          | 0.924      |
| Q-avg                          | 196.9288   |
| Q-std                          | 121.4023   |
| Q_loss                         | 115.71398  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 442        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000513   |
| times/evaluation_paths         | 36.5       |
| times/timestep_after_hook      | 0.00422    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 70.5       |
| timestep                       | 1000       |
| timesteps_total                | 443000     |
| train-steps                    | 443000     |
| training/Q/q1_loss             | 100.975044 |
| training/sac_pi/alpha          | 0.17212017 |
| training/sac_pi/alpha_loss     | 0.02943546 |
| training/sac_pi/logp_pi        | 4.177293   |
| training/sac_pi/pi_entropy     | 3.41124    |
| training/sac_pi/pi_global_norm | 1.7753055  |
| training/sac_pi/policy_loss    | -213.53392 |
| training/sac_pi/std            | 0.48229516 |
| training/sac_pi/valid_num      | 5004.0     |
| training/sac_Q/q1              | 206.47324  |
| training/sac_Q/q2              | 207.26968  |
| training/sac_Q/q2_loss         | 100.78299  |
| training/sac_Q/q_global_norm   | 244.22427  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17590159 |
| epoch                          | 443        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4962.4253  |
| evaluation/return-max          | 5038.4893  |
| evaluation/return-min          | 4882.1265  |
| evaluation/return-std          | 53.711945  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46243      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4962.4253  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 214.3425   |
| Q-std                          | 117.076485 |
| Q_loss                         | 103.03617  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 443        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000206   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000564   |
| times/evaluation_paths         | 37.3       |
| times/timestep_after_hook      | 0.00408    |
| times/timestep_before_hook     | 0.00851    |
| times/train                    | 72.3       |
| timestep                       | 1000       |
| timesteps_total                | 444000     |
| train-steps                    | 444000     |
| training/Q/q1_loss             | 107.80826  |
| training/sac_pi/alpha          | 0.1759112  |
| training/sac_pi/alpha_loss     | 0.13712484 |
| training/sac_pi/logp_pi        | 4.587202   |
| training/sac_pi/pi_entropy     | 3.7143073  |
| training/sac_pi/pi_global_norm | 1.5895072  |
| training/sac_pi/policy_loss    | -217.4227  |
| training/sac_pi/std            | 0.5325388  |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 205.70102  |
| training/sac_Q/q2              | 204.76097  |
| training/sac_Q/q2_loss         | 106.902855 |
| training/sac_Q/q_global_norm   | 248.86475  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17581479  |
| epoch                          | 444         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4813.7314   |
| evaluation/return-max          | 4879.7705   |
| evaluation/return-min          | 4622.3604   |
| evaluation/return-std          | 69.17885    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46230       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4813.7314   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 209.97864   |
| Q-std                          | 121.52735   |
| Q_loss                         | 110.58305   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 444         |
| times/epoch_after_hook         | 3.23e-06    |
| times/epoch_before_hook        | 0.000144    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000531    |
| times/evaluation_paths         | 45.7        |
| times/timestep_after_hook      | 0.00416     |
| times/timestep_before_hook     | 0.00859     |
| times/train                    | 63.2        |
| timestep                       | 1000        |
| timesteps_total                | 445000      |
| train-steps                    | 445000      |
| training/Q/q1_loss             | 108.0767    |
| training/sac_pi/alpha          | 0.17583095  |
| training/sac_pi/alpha_loss     | -0.08270938 |
| training/sac_pi/logp_pi        | 4.5122504   |
| training/sac_pi/pi_entropy     | 3.5040329   |
| training/sac_pi/pi_global_norm | 1.8587817   |
| training/sac_pi/policy_loss    | -212.14957  |
| training/sac_pi/std            | 0.50102127  |
| training/sac_pi/valid_num      | 4961.0      |
| training/sac_Q/q1              | 204.20609   |
| training/sac_Q/q2              | 202.98251   |
| training/sac_Q/q2_loss         | 106.78586   |
| training/sac_Q/q_global_norm   | 260.26517   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17324984  |
| epoch                          | 445         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4669.905    |
| evaluation/return-max          | 4697.3135   |
| evaluation/return-min          | 4643.294    |
| evaluation/return-std          | 16.410744   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46310       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4669.905    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 202.94008   |
| Q-std                          | 115.42742   |
| Q_loss                         | 119.77315   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 445         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000267    |
| times/epoch_rollout_model      | 501         |
| times/evaluation_metrics       | 0.000538    |
| times/evaluation_paths         | 35.8        |
| times/timestep_after_hook      | 0.00407     |
| times/timestep_before_hook     | 0.00857     |
| times/train                    | 63.9        |
| timestep                       | 1000        |
| timesteps_total                | 446000      |
| train-steps                    | 446000      |
| training/Q/q1_loss             | 76.43599    |
| training/sac_pi/alpha          | 0.17322476  |
| training/sac_pi/alpha_loss     | -0.08358011 |
| training/sac_pi/logp_pi        | 4.8858438   |
| training/sac_pi/pi_entropy     | 3.5218093   |
| training/sac_pi/pi_global_norm | 1.4564984   |
| training/sac_pi/policy_loss    | -212.33328  |
| training/sac_pi/std            | 0.51226145  |
| training/sac_pi/valid_num      | 4930.0      |
| training/sac_Q/q1              | 203.41592   |
| training/sac_Q/q2              | 201.44063   |
| training/sac_Q/q2_loss         | 77.31441    |
| training/sac_Q/q_global_norm   | 169.53474   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1769872  |
| epoch                          | 446        |
| evaluation/episode-length-avg  | 147        |
| evaluation/episode-length-max  | 149        |
| evaluation/episode-length-min  | 141        |
| evaluation/episode-length-std  | 2.39       |
| evaluation/return-average      | 347.3881   |
| evaluation/return-max          | 352.47055  |
| evaluation/return-min          | 333.29288  |
| evaluation/return-std          | 5.394974   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46185      |
| perf/AverageLength             | 147        |
| perf/AverageReturn             | 347.3881   |
| perf/NormalizedReturn          | 0.0753     |
| Q-avg                          | 212.8606   |
| Q-std                          | 107.3359   |
| Q_loss                         | 98.2766    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 446        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.000166   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000471   |
| times/evaluation_paths         | 4.76       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 447000     |
| train-steps                    | 447000     |
| training/Q/q1_loss             | 95.321655  |
| training/sac_pi/alpha          | 0.1769686  |
| training/sac_pi/alpha_loss     | 0.02605324 |
| training/sac_pi/logp_pi        | 4.4345713  |
| training/sac_pi/pi_entropy     | 3.4703383  |
| training/sac_pi/pi_global_norm | 1.5450083  |
| training/sac_pi/policy_loss    | -214.8603  |
| training/sac_pi/std            | 0.49392876 |
| training/sac_pi/valid_num      | 4958.0     |
| training/sac_Q/q1              | 206.76762  |
| training/sac_Q/q2              | 203.74075  |
| training/sac_Q/q2_loss         | 95.194756  |
| training/sac_Q/q_global_norm   | 202.07924  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1680606   |
| epoch                          | 447         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5088.638    |
| evaluation/return-max          | 5263.6235   |
| evaluation/return-min          | 5022.7275   |
| evaluation/return-std          | 65.33902    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46193       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5088.638    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 199.57161   |
| Q-std                          | 133.82777   |
| Q_loss                         | 118.98654   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 447         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000596    |
| times/evaluation_paths         | 32.6        |
| times/timestep_after_hook      | 0.00416     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 67          |
| timestep                       | 1000        |
| timesteps_total                | 448000      |
| train-steps                    | 448000      |
| training/Q/q1_loss             | 97.60389    |
| training/sac_pi/alpha          | 0.1680686   |
| training/sac_pi/alpha_loss     | -0.40886962 |
| training/sac_pi/logp_pi        | 4.760186    |
| training/sac_pi/pi_entropy     | 3.4406433   |
| training/sac_pi/pi_global_norm | 1.9021206   |
| training/sac_pi/policy_loss    | -223.34166  |
| training/sac_pi/std            | 0.51482326  |
| training/sac_pi/valid_num      | 4935.0      |
| training/sac_Q/q1              | 210.67818   |
| training/sac_Q/q2              | 209.78853   |
| training/sac_Q/q2_loss         | 97.33862    |
| training/sac_Q/q_global_norm   | 212.01106   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17019878 |
| epoch                          | 448        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4944.4473  |
| evaluation/return-max          | 4970.7866  |
| evaluation/return-min          | 4918.059   |
| evaluation/return-std          | 13.36473   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46099      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4944.4473  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 209.4415   |
| Q-std                          | 116.40899  |
| Q_loss                         | 99.52015   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 448        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000565   |
| times/evaluation_paths         | 42.3       |
| times/timestep_after_hook      | 0.0043     |
| times/timestep_before_hook     | 0.00855    |
| times/train                    | 67.2       |
| timestep                       | 1000       |
| timesteps_total                | 449000     |
| train-steps                    | 449000     |
| training/Q/q1_loss             | 99.792076  |
| training/sac_pi/alpha          | 0.17015217 |
| training/sac_pi/alpha_loss     | 0.41606158 |
| training/sac_pi/logp_pi        | 4.818141   |
| training/sac_pi/pi_entropy     | 3.1919374  |
| training/sac_pi/pi_global_norm | 1.6439294  |
| training/sac_pi/policy_loss    | -210.93874 |
| training/sac_pi/std            | 0.45997652 |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 197.78941  |
| training/sac_Q/q2              | 198.70773  |
| training/sac_Q/q2_loss         | 98.988556  |
| training/sac_Q/q_global_norm   | 170.85594  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17551292  |
| epoch                          | 449         |
| evaluation/episode-length-avg  | 236         |
| evaluation/episode-length-max  | 758         |
| evaluation/episode-length-min  | 165         |
| evaluation/episode-length-std  | 174         |
| evaluation/return-average      | 713.6318    |
| evaluation/return-max          | 3404.9424   |
| evaluation/return-min          | 389.86285   |
| evaluation/return-std          | 897.18677   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46213       |
| perf/AverageLength             | 236         |
| perf/AverageReturn             | 713.6318    |
| perf/NormalizedReturn          | 0.155       |
| Q-avg                          | 210.19756   |
| Q-std                          | 107.6541    |
| Q_loss                         | 92.12358    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 449         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000264    |
| times/epoch_rollout_model      | 506         |
| times/evaluation_metrics       | 0.000436    |
| times/evaluation_paths         | 7.54        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 450000      |
| train-steps                    | 450000      |
| training/Q/q1_loss             | 85.19125    |
| training/sac_pi/alpha          | 0.17554025  |
| training/sac_pi/alpha_loss     | -0.23837687 |
| training/sac_pi/logp_pi        | 3.8025467   |
| training/sac_pi/pi_entropy     | 3.574068    |
| training/sac_pi/pi_global_norm | 1.7490317   |
| training/sac_pi/policy_loss    | -216.31369  |
| training/sac_pi/std            | 0.4994501   |
| training/sac_pi/valid_num      | 4989.0      |
| training/sac_Q/q1              | 210.32605   |
| training/sac_Q/q2              | 209.36551   |
| training/sac_Q/q2_loss         | 84.116486   |
| training/sac_Q/q_global_norm   | 227.18077   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17226371 |
| epoch                          | 450        |
| evaluation/episode-length-avg  | 742        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 127        |
| evaluation/episode-length-std  | 394        |
| evaluation/return-average      | 3466.1     |
| evaluation/return-max          | 4885.801   |
| evaluation/return-min          | 317.11185  |
| evaluation/return-std          | 2039.5073  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46204      |
| perf/AverageLength             | 742        |
| perf/AverageReturn             | 3466.1     |
| perf/NormalizedReturn          | 0.755      |
| Q-avg                          | 200.8234   |
| Q-std                          | 150.49207  |
| Q_loss                         | 101.10192  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 450        |
| times/epoch_after_hook         | 2.13e-06   |
| times/epoch_before_hook        | 8.4e-05    |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000551   |
| times/evaluation_paths         | 27.4       |
| times/timestep_after_hook      | 0.00408    |
| times/timestep_before_hook     | 0.00854    |
| times/train                    | 67.6       |
| timestep                       | 1000       |
| timesteps_total                | 451000     |
| train-steps                    | 451000     |
| training/Q/q1_loss             | 86.93077   |
| training/sac_pi/alpha          | 0.17226884 |
| training/sac_pi/alpha_loss     | 0.20736413 |
| training/sac_pi/logp_pi        | 4.3086753  |
| training/sac_pi/pi_entropy     | 3.386146   |
| training/sac_pi/pi_global_norm | 1.67198    |
| training/sac_pi/policy_loss    | -223.6178  |
| training/sac_pi/std            | 0.49382845 |
| training/sac_pi/valid_num      | 4962.0     |
| training/sac_Q/q1              | 213.7598   |
| training/sac_Q/q2              | 212.50015  |
| training/sac_Q/q2_loss         | 87.4839    |
| training/sac_Q/q_global_norm   | 253.89273  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16871125 |
| epoch                          | 451        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4989.526   |
| evaluation/return-max          | 5054.265   |
| evaluation/return-min          | 4849.258   |
| evaluation/return-std          | 67.29647   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46142      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4989.526   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 206.06088  |
| Q-std                          | 115.969986 |
| Q_loss                         | 97.651985  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 451        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000155   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000574   |
| times/evaluation_paths         | 33         |
| times/timestep_after_hook      | 0.00415    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 68.3       |
| timestep                       | 1000       |
| timesteps_total                | 452000     |
| train-steps                    | 452000     |
| training/Q/q1_loss             | 113.78142  |
| training/sac_pi/alpha          | 0.16868594 |
| training/sac_pi/alpha_loss     | 0.13893327 |
| training/sac_pi/logp_pi        | 5.0264435  |
| training/sac_pi/pi_entropy     | 3.5747368  |
| training/sac_pi/pi_global_norm | 1.7721424  |
| training/sac_pi/policy_loss    | -214.55162 |
| training/sac_pi/std            | 0.53795904 |
| training/sac_pi/valid_num      | 4930.0     |
| training/sac_Q/q1              | 203.14499  |
| training/sac_Q/q2              | 200.75198  |
| training/sac_Q/q2_loss         | 114.370476 |
| training/sac_Q/q_global_norm   | 292.996    |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16827951 |
| epoch                          | 452        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4828.464   |
| evaluation/return-max          | 4901.7334  |
| evaluation/return-min          | 4776.017   |
| evaluation/return-std          | 41.795788  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46172      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4828.464   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 202.45369  |
| Q-std                          | 121.25962  |
| Q_loss                         | 103.13061  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 452        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000591   |
| times/evaluation_paths         | 41.4       |
| times/timestep_after_hook      | 0.0042     |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 69         |
| timestep                       | 1000       |
| timesteps_total                | 453000     |
| train-steps                    | 453000     |
| training/Q/q1_loss             | 112.90247  |
| training/sac_pi/alpha          | 0.16827911 |
| training/sac_pi/alpha_loss     | 0.17321746 |
| training/sac_pi/logp_pi        | 4.789455   |
| training/sac_pi/pi_entropy     | 3.5098896  |
| training/sac_pi/pi_global_norm | 1.6438544  |
| training/sac_pi/policy_loss    | -200.91066 |
| training/sac_pi/std            | 0.50561863 |
| training/sac_pi/valid_num      | 4934.0     |
| training/sac_Q/q1              | 190.44849  |
| training/sac_Q/q2              | 191.19366  |
| training/sac_Q/q2_loss         | 113.8493   |
| training/sac_Q/q_global_norm   | 245.75818  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16844632 |
| epoch                          | 453        |
| evaluation/episode-length-avg  | 830        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 144        |
| evaluation/episode-length-std  | 341        |
| evaluation/return-average      | 3934.5007  |
| evaluation/return-max          | 4895.9927  |
| evaluation/return-min          | 368.2852   |
| evaluation/return-std          | 1779.7997  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46168      |
| perf/AverageLength             | 830        |
| perf/AverageReturn             | 3934.5007  |
| perf/NormalizedReturn          | 0.857      |
| Q-avg                          | 203.90724  |
| Q-std                          | 124.612015 |
| Q_loss                         | 89.63901   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 453        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000322   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000517   |
| times/evaluation_paths         | 27.7       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00868    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 454000     |
| train-steps                    | 454000     |
| training/Q/q1_loss             | 90.28603   |
| training/sac_pi/alpha          | 0.16846052 |
| training/sac_pi/alpha_loss     | -0.5013598 |
| training/sac_pi/logp_pi        | 4.9913282  |
| training/sac_pi/pi_entropy     | 3.4280257  |
| training/sac_pi/pi_global_norm | 1.807826   |
| training/sac_pi/policy_loss    | -216.24437 |
| training/sac_pi/std            | 0.52245617 |
| training/sac_pi/valid_num      | 4932.0     |
| training/sac_Q/q1              | 202.52307  |
| training/sac_Q/q2              | 200.43323  |
| training/sac_Q/q2_loss         | 89.81456   |
| training/sac_Q/q_global_norm   | 250.8716   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16881856 |
| epoch                          | 454        |
| evaluation/episode-length-avg  | 397        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 134        |
| evaluation/episode-length-std  | 395        |
| evaluation/return-average      | 1699.575   |
| evaluation/return-max          | 5007.0215  |
| evaluation/return-min          | 313.89093  |
| evaluation/return-std          | 2089.7595  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46216      |
| perf/AverageLength             | 397        |
| perf/AverageReturn             | 1699.575   |
| perf/NormalizedReturn          | 0.37       |
| Q-avg                          | 189.33438  |
| Q-std                          | 113.71874  |
| Q_loss                         | 93.73439   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 454        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000618   |
| times/evaluation_paths         | 12.7       |
| times/timestep_after_hook      | 0.00424    |
| times/timestep_before_hook     | 0.00855    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 455000     |
| train-steps                    | 455000     |
| training/Q/q1_loss             | 100.643654 |
| training/sac_pi/alpha          | 0.16882412 |
| training/sac_pi/alpha_loss     | 0.04469522 |
| training/sac_pi/logp_pi        | 4.5581355  |
| training/sac_pi/pi_entropy     | 3.3074462  |
| training/sac_pi/pi_global_norm | 1.5210733  |
| training/sac_pi/policy_loss    | -202.00989 |
| training/sac_pi/std            | 0.47539002 |
| training/sac_pi/valid_num      | 4879.0     |
| training/sac_Q/q1              | 191.70656  |
| training/sac_Q/q2              | 190.08203  |
| training/sac_Q/q2_loss         | 99.07612   |
| training/sac_Q/q_global_norm   | 262.3335   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16697213  |
| epoch                          | 455         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4720.479    |
| evaluation/return-max          | 4850.422    |
| evaluation/return-min          | 4423.4414   |
| evaluation/return-std          | 129.48564   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46134       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4720.479    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 202.90485   |
| Q-std                          | 130.7898    |
| Q_loss                         | 89.356415   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 455         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000561    |
| times/evaluation_paths         | 34.5        |
| times/timestep_after_hook      | 0.00412     |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 456000      |
| train-steps                    | 456000      |
| training/Q/q1_loss             | 108.00297   |
| training/sac_pi/alpha          | 0.16697823  |
| training/sac_pi/alpha_loss     | -0.17471462 |
| training/sac_pi/logp_pi        | 4.3790007   |
| training/sac_pi/pi_entropy     | 3.3248162   |
| training/sac_pi/pi_global_norm | 2.150895    |
| training/sac_pi/policy_loss    | -212.31     |
| training/sac_pi/std            | 0.4904389   |
| training/sac_pi/valid_num      | 4934.0      |
| training/sac_Q/q1              | 200.2009    |
| training/sac_Q/q2              | 200.78491   |
| training/sac_Q/q2_loss         | 108.60714   |
| training/sac_Q/q_global_norm   | 327.91867   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16712348 |
| epoch                          | 456        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5045.18    |
| evaluation/return-max          | 5085.5967  |
| evaluation/return-min          | 4920.1885  |
| evaluation/return-std          | 46.391556  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46117      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5045.18    |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 196.36928  |
| Q-std                          | 147.0906   |
| Q_loss                         | 102.93764  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 456        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000636   |
| times/evaluation_paths         | 34.7       |
| times/timestep_after_hook      | 0.00411    |
| times/timestep_before_hook     | 0.00852    |
| times/train                    | 65.4       |
| timestep                       | 1000       |
| timesteps_total                | 457000     |
| train-steps                    | 457000     |
| training/Q/q1_loss             | 97.90824   |
| training/sac_pi/alpha          | 0.16706784 |
| training/sac_pi/alpha_loss     | 0.59950083 |
| training/sac_pi/logp_pi        | 4.6906176  |
| training/sac_pi/pi_entropy     | 3.3191845  |
| training/sac_pi/pi_global_norm | 1.491727   |
| training/sac_pi/policy_loss    | -214.66382 |
| training/sac_pi/std            | 0.48114207 |
| training/sac_pi/valid_num      | 4985.0     |
| training/sac_Q/q1              | 205.60068  |
| training/sac_Q/q2              | 205.29239  |
| training/sac_Q/q2_loss         | 98.07366   |
| training/sac_Q/q_global_norm   | 255.35971  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16964625  |
| epoch                          | 457         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5072.957    |
| evaluation/return-max          | 5105.076    |
| evaluation/return-min          | 5026.955    |
| evaluation/return-std          | 27.997847   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46281       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5072.957    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 214.02054   |
| Q-std                          | 96.111374   |
| Q_loss                         | 122.4511    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 457         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.00026     |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 32.8        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 458000      |
| train-steps                    | 458000      |
| training/Q/q1_loss             | 120.82352   |
| training/sac_pi/alpha          | 0.16967495  |
| training/sac_pi/alpha_loss     | -0.08277874 |
| training/sac_pi/logp_pi        | 4.7788644   |
| training/sac_pi/pi_entropy     | 3.6741128   |
| training/sac_pi/pi_global_norm | 1.579382    |
| training/sac_pi/policy_loss    | -212.16437  |
| training/sac_pi/std            | 0.5476325   |
| training/sac_pi/valid_num      | 4863.0      |
| training/sac_Q/q1              | 197.50838   |
| training/sac_Q/q2              | 194.95169   |
| training/sac_Q/q2_loss         | 121.5384    |
| training/sac_Q/q_global_norm   | 278.85983   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17343248  |
| epoch                          | 458         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4897.667    |
| evaluation/return-max          | 4948.866    |
| evaluation/return-min          | 4846.035    |
| evaluation/return-std          | 32.37232    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46172       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4897.667    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 200.27814   |
| Q-std                          | 143.78189   |
| Q_loss                         | 109.53361   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 458         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000151    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000548    |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00839     |
| times/train                    | 59.2        |
| timestep                       | 1000        |
| timesteps_total                | 459000      |
| train-steps                    | 459000      |
| training/Q/q1_loss             | 90.97897    |
| training/sac_pi/alpha          | 0.17342718  |
| training/sac_pi/alpha_loss     | 0.110704295 |
| training/sac_pi/logp_pi        | 4.360053    |
| training/sac_pi/pi_entropy     | 3.7027116   |
| training/sac_pi/pi_global_norm | 1.6187351   |
| training/sac_pi/policy_loss    | -210.69513  |
| training/sac_pi/std            | 0.52423185  |
| training/sac_pi/valid_num      | 4944.0      |
| training/sac_Q/q1              | 200.43283   |
| training/sac_Q/q2              | 200.89665   |
| training/sac_Q/q2_loss         | 92.10016    |
| training/sac_Q/q_global_norm   | 175.90234   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17299347  |
| epoch                          | 459         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4899.202    |
| evaluation/return-max          | 4912.625    |
| evaluation/return-min          | 4883.5176   |
| evaluation/return-std          | 10.907956   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46053       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4899.202    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 209.14717   |
| Q-std                          | 99.20156    |
| Q_loss                         | 98.71827    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 459         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000142    |
| times/epoch_rollout_model      | 501         |
| times/evaluation_metrics       | 0.000525    |
| times/evaluation_paths         | 34.8        |
| times/timestep_after_hook      | 0.0045      |
| times/timestep_before_hook     | 0.00884     |
| times/train                    | 60.5        |
| timestep                       | 1000        |
| timesteps_total                | 460000      |
| train-steps                    | 460000      |
| training/Q/q1_loss             | 100.509     |
| training/sac_pi/alpha          | 0.17302857  |
| training/sac_pi/alpha_loss     | -0.25791055 |
| training/sac_pi/logp_pi        | 4.363218    |
| training/sac_pi/pi_entropy     | 3.431228    |
| training/sac_pi/pi_global_norm | 1.672212    |
| training/sac_pi/policy_loss    | -219.20953  |
| training/sac_pi/std            | 0.5048635   |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 208.75186   |
| training/sac_Q/q2              | 206.8627    |
| training/sac_Q/q2_loss         | 101.42525   |
| training/sac_Q/q_global_norm   | 278.2       |
---------------------------------------------------------------------------------
[WARN] 460 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.169873    |
| epoch                          | 460         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4935.964    |
| evaluation/return-max          | 5014.0737   |
| evaluation/return-min          | 4749.432    |
| evaluation/return-std          | 72.92895    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85          |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46287       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4935.964    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 210.09209   |
| Q-std                          | 100.291374  |
| Q_loss                         | 102.25813   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 460         |
| times/epoch_after_hook         | 2.04e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 507         |
| times/evaluation_metrics       | 0.000532    |
| times/evaluation_paths         | 33          |
| times/timestep_after_hook      | 0.00425     |
| times/timestep_before_hook     | 0.00855     |
| times/train                    | 62.4        |
| timestep                       | 1000        |
| timesteps_total                | 461000      |
| train-steps                    | 461000      |
| training/Q/q1_loss             | 86.23043    |
| training/sac_pi/alpha          | 0.16987932  |
| training/sac_pi/alpha_loss     | 0.022159625 |
| training/sac_pi/logp_pi        | 4.5379114   |
| training/sac_pi/pi_entropy     | 3.3874803   |
| training/sac_pi/pi_global_norm | 1.4542972   |
| training/sac_pi/policy_loss    | -211.4531   |
| training/sac_pi/std            | 0.5026439   |
| training/sac_pi/valid_num      | 4937.0      |
| training/sac_Q/q1              | 200.97357   |
| training/sac_Q/q2              | 199.71056   |
| training/sac_Q/q2_loss         | 86.16784    |
| training/sac_Q/q_global_norm   | 234.98534   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16919623  |
| epoch                          | 461         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5058.552    |
| evaluation/return-max          | 5118.6855   |
| evaluation/return-min          | 4957.9375   |
| evaluation/return-std          | 43.716015   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46347       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5058.552    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 189.99173   |
| Q-std                          | 122.59637   |
| Q_loss                         | 96.22174    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 461         |
| times/epoch_after_hook         | 1.98e-06    |
| times/epoch_before_hook        | 0.000272    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000513    |
| times/evaluation_paths         | 33.2        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00838     |
| times/train                    | 61.5        |
| timestep                       | 1000        |
| timesteps_total                | 462000      |
| train-steps                    | 462000      |
| training/Q/q1_loss             | 111.21186   |
| training/sac_pi/alpha          | 0.16917631  |
| training/sac_pi/alpha_loss     | 0.026020812 |
| training/sac_pi/logp_pi        | 3.935889    |
| training/sac_pi/pi_entropy     | 3.5047314   |
| training/sac_pi/pi_global_norm | 1.6907191   |
| training/sac_pi/policy_loss    | -216.37956  |
| training/sac_pi/std            | 0.48383346  |
| training/sac_pi/valid_num      | 4985.0      |
| training/sac_Q/q1              | 207.62949   |
| training/sac_Q/q2              | 207.70772   |
| training/sac_Q/q2_loss         | 110.479614  |
| training/sac_Q/q_global_norm   | 250.28651   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17319706 |
| epoch                          | 462        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4881.168   |
| evaluation/return-max          | 4991.3877  |
| evaluation/return-min          | 4742.786   |
| evaluation/return-std          | 86.00034   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46240      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4881.168   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 204.57086  |
| Q-std                          | 130.49933  |
| Q_loss                         | 113.570145 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 462        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000625   |
| times/evaluation_paths         | 33.5       |
| times/timestep_after_hook      | 0.0042     |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 59.3       |
| timestep                       | 1000       |
| timesteps_total                | 463000     |
| train-steps                    | 463000     |
| training/Q/q1_loss             | 108.6311   |
| training/sac_pi/alpha          | 0.1732331  |
| training/sac_pi/alpha_loss     | -0.510761  |
| training/sac_pi/logp_pi        | 4.537916   |
| training/sac_pi/pi_entropy     | 3.5015023  |
| training/sac_pi/pi_global_norm | 1.5408021  |
| training/sac_pi/policy_loss    | -213.46208 |
| training/sac_pi/std            | 0.51785946 |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 202.05234  |
| training/sac_Q/q2              | 202.04327  |
| training/sac_Q/q2_loss         | 107.89284  |
| training/sac_Q/q_global_norm   | 252.82628  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17034896 |
| epoch                          | 463        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4885.3486  |
| evaluation/return-max          | 4920.176   |
| evaluation/return-min          | 4801.917   |
| evaluation/return-std          | 35.348965  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46264      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4885.3486  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 211.25742  |
| Q-std                          | 140.1606   |
| Q_loss                         | 98.20282   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 463        |
| times/epoch_after_hook         | 3.67e-06   |
| times/epoch_before_hook        | 0.000242   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000608   |
| times/evaluation_paths         | 33.1       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 464000     |
| train-steps                    | 464000     |
| training/Q/q1_loss             | 83.73828   |
| training/sac_pi/alpha          | 0.17032334 |
| training/sac_pi/alpha_loss     | 0.13437954 |
| training/sac_pi/logp_pi        | 4.473501   |
| training/sac_pi/pi_entropy     | 3.3051848  |
| training/sac_pi/pi_global_norm | 1.8079038  |
| training/sac_pi/policy_loss    | -214.69086 |
| training/sac_pi/std            | 0.48253182 |
| training/sac_pi/valid_num      | 4958.0     |
| training/sac_Q/q1              | 204.40286  |
| training/sac_Q/q2              | 201.59914  |
| training/sac_Q/q2_loss         | 83.31253   |
| training/sac_Q/q_global_norm   | 202.09201  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16776933   |
| epoch                          | 464          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5034.764     |
| evaluation/return-max          | 5084.62      |
| evaluation/return-min          | 4987.1416    |
| evaluation/return-std          | 28.783258    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.02         |
| model/origin_ret               | 86.5         |
| model/penalty_ret              | 82.3         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46238        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5034.764     |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 197.47423    |
| Q-std                          | 149.32889    |
| Q_loss                         | 90.275795    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 464          |
| times/epoch_after_hook         | 1.74e-06     |
| times/epoch_before_hook        | 0.00011      |
| times/epoch_rollout_model      | 501          |
| times/evaluation_metrics       | 0.000623     |
| times/evaluation_paths         | 33.4         |
| times/timestep_after_hook      | 0.00413      |
| times/timestep_before_hook     | 0.00849      |
| times/train                    | 59.2         |
| timestep                       | 1000         |
| timesteps_total                | 465000       |
| train-steps                    | 465000       |
| training/Q/q1_loss             | 119.33226    |
| training/sac_pi/alpha          | 0.16775058   |
| training/sac_pi/alpha_loss     | -0.037980463 |
| training/sac_pi/logp_pi        | 4.8736596    |
| training/sac_pi/pi_entropy     | 3.586509     |
| training/sac_pi/pi_global_norm | 1.5778893    |
| training/sac_pi/policy_loss    | -213.18799   |
| training/sac_pi/std            | 0.5370032    |
| training/sac_pi/valid_num      | 4928.0       |
| training/sac_Q/q1              | 202.16182    |
| training/sac_Q/q2              | 199.86493    |
| training/sac_Q/q2_loss         | 118.552795   |
| training/sac_Q/q_global_norm   | 306.11996    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1668154  |
| epoch                          | 465        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5113.634   |
| evaluation/return-max          | 5138.4253  |
| evaluation/return-min          | 5084.448   |
| evaluation/return-std          | 18.087864  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46253      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5113.634   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 220.11055  |
| Q-std                          | 103.95293  |
| Q_loss                         | 70.48609   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 465        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.00026    |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000527   |
| times/evaluation_paths         | 32.8       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 466000     |
| train-steps                    | 466000     |
| training/Q/q1_loss             | 110.49278  |
| training/sac_pi/alpha          | 0.16679719 |
| training/sac_pi/alpha_loss     | 0.06814297 |
| training/sac_pi/logp_pi        | 3.7235513  |
| training/sac_pi/pi_entropy     | 3.3688455  |
| training/sac_pi/pi_global_norm | 1.9871706  |
| training/sac_pi/policy_loss    | -219.8454  |
| training/sac_pi/std            | 0.46825567 |
| training/sac_pi/valid_num      | 4936.0     |
| training/sac_Q/q1              | 209.36311  |
| training/sac_Q/q2              | 209.07031  |
| training/sac_Q/q2_loss         | 110.1328   |
| training/sac_Q/q_global_norm   | 333.6933   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17144166 |
| epoch                          | 466        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4541.0576  |
| evaluation/return-max          | 4678.0376  |
| evaluation/return-min          | 4350.749   |
| evaluation/return-std          | 92.61125   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46332      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4541.0576  |
| perf/NormalizedReturn          | 0.989      |
| Q-avg                          | 207.872    |
| Q-std                          | 107.65132  |
| Q_loss                         | 102.040764 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 466        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000533   |
| times/evaluation_paths         | 33.1       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 467000     |
| train-steps                    | 467000     |
| training/Q/q1_loss             | 101.68296  |
| training/sac_pi/alpha          | 0.17143667 |
| training/sac_pi/alpha_loss     | 0.15450852 |
| training/sac_pi/logp_pi        | 3.6562629  |
| training/sac_pi/pi_entropy     | 3.420639   |
| training/sac_pi/pi_global_norm | 1.6871341  |
| training/sac_pi/policy_loss    | -211.29315 |
| training/sac_pi/std            | 0.46873716 |
| training/sac_pi/valid_num      | 5002.0     |
| training/sac_Q/q1              | 205.90483  |
| training/sac_Q/q2              | 205.89883  |
| training/sac_Q/q2_loss         | 101.24521  |
| training/sac_Q/q_global_norm   | 232.94664  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16906147   |
| epoch                          | 467          |
| evaluation/episode-length-avg  | 744          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 146          |
| evaluation/episode-length-std  | 391          |
| evaluation/return-average      | 3242.1184    |
| evaluation/return-max          | 4495.298     |
| evaluation/return-min          | 352.90485    |
| evaluation/return-std          | 1889.9275    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.96         |
| model/origin_ret               | 84.5         |
| model/penalty_ret              | 80.8         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46156        |
| perf/AverageLength             | 744          |
| perf/AverageReturn             | 3242.1184    |
| perf/NormalizedReturn          | 0.706        |
| Q-avg                          | 208.76535    |
| Q-std                          | 110.99828    |
| Q_loss                         | 81.72928     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 467          |
| times/epoch_after_hook         | 1.81e-06     |
| times/epoch_before_hook        | 0.000119     |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.000511     |
| times/evaluation_paths         | 25.4         |
| times/timestep_after_hook      | 0.00392      |
| times/timestep_before_hook     | 0.00826      |
| times/train                    | 60.5         |
| timestep                       | 1000         |
| timesteps_total                | 468000       |
| train-steps                    | 468000       |
| training/Q/q1_loss             | 103.72803    |
| training/sac_pi/alpha          | 0.16907184   |
| training/sac_pi/alpha_loss     | -0.013691159 |
| training/sac_pi/logp_pi        | 4.4296503    |
| training/sac_pi/pi_entropy     | 3.3311665    |
| training/sac_pi/pi_global_norm | 2.0629132    |
| training/sac_pi/policy_loss    | -222.31056   |
| training/sac_pi/std            | 0.49022418   |
| training/sac_pi/valid_num      | 4974.0       |
| training/sac_Q/q1              | 213.54533    |
| training/sac_Q/q2              | 211.09819    |
| training/sac_Q/q2_loss         | 104.92222    |
| training/sac_Q/q_global_norm   | 201.40247    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1712905   |
| epoch                          | 468         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5118.333    |
| evaluation/return-max          | 5159.7275   |
| evaluation/return-min          | 5087.243    |
| evaluation/return-std          | 22.380085   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46440       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5118.333    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 206.99336   |
| Q-std                          | 152.89015   |
| Q_loss                         | 82.84336    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 468         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000509    |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00385     |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 469000      |
| train-steps                    | 469000      |
| training/Q/q1_loss             | 102.89677   |
| training/sac_pi/alpha          | 0.17133114  |
| training/sac_pi/alpha_loss     | -0.38808456 |
| training/sac_pi/logp_pi        | 4.1123066   |
| training/sac_pi/pi_entropy     | 3.3790164   |
| training/sac_pi/pi_global_norm | 1.5434381   |
| training/sac_pi/policy_loss    | -227.76688  |
| training/sac_pi/std            | 0.49181435  |
| training/sac_pi/valid_num      | 4994.0      |
| training/sac_Q/q1              | 220.47368   |
| training/sac_Q/q2              | 218.87378   |
| training/sac_Q/q2_loss         | 102.14356   |
| training/sac_Q/q_global_norm   | 215.22458   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16918379  |
| epoch                          | 469         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4678.496    |
| evaluation/return-max          | 4875.245    |
| evaluation/return-min          | 4479.5063   |
| evaluation/return-std          | 101.440125  |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46119       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4678.496    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 209.40237   |
| Q-std                          | 104.19591   |
| Q_loss                         | 99.49123    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 469         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000276    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.00052     |
| times/evaluation_paths         | 32.7        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 59.7        |
| timestep                       | 1000        |
| timesteps_total                | 470000      |
| train-steps                    | 470000      |
| training/Q/q1_loss             | 82.59998    |
| training/sac_pi/alpha          | 0.16918014  |
| training/sac_pi/alpha_loss     | 0.063750245 |
| training/sac_pi/logp_pi        | 4.9211783   |
| training/sac_pi/pi_entropy     | 3.1489599   |
| training/sac_pi/pi_global_norm | 1.7588767   |
| training/sac_pi/policy_loss    | -222.44324  |
| training/sac_pi/std            | 0.48335737  |
| training/sac_pi/valid_num      | 4955.0      |
| training/sac_Q/q1              | 213.83696   |
| training/sac_Q/q2              | 213.50644   |
| training/sac_Q/q2_loss         | 83.042404   |
| training/sac_Q/q_global_norm   | 199.86603   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16970302   |
| epoch                          | 470          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5051.2705    |
| evaluation/return-max          | 5105.4946    |
| evaluation/return-min          | 5013.7593    |
| evaluation/return-std          | 27.8846      |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.06         |
| model/origin_ret               | 85.6         |
| model/penalty_ret              | 81.8         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46361        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5051.2705    |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 215.01697    |
| Q-std                          | 92.655014    |
| Q_loss                         | 82.286064    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 470          |
| times/epoch_after_hook         | 1.67e-06     |
| times/epoch_before_hook        | 0.000107     |
| times/epoch_rollout_model      | 511          |
| times/evaluation_metrics       | 0.000657     |
| times/evaluation_paths         | 33.9         |
| times/timestep_after_hook      | 0.00412      |
| times/timestep_before_hook     | 0.00848      |
| times/train                    | 62.4         |
| timestep                       | 1000         |
| timesteps_total                | 471000       |
| train-steps                    | 471000       |
| training/Q/q1_loss             | 96.56687     |
| training/sac_pi/alpha          | 0.16972937   |
| training/sac_pi/alpha_loss     | -0.018786699 |
| training/sac_pi/logp_pi        | 3.8237464    |
| training/sac_pi/pi_entropy     | 3.5515466    |
| training/sac_pi/pi_global_norm | 1.6902505    |
| training/sac_pi/policy_loss    | -215.71783   |
| training/sac_pi/std            | 0.4883066    |
| training/sac_pi/valid_num      | 4983.0       |
| training/sac_Q/q1              | 209.49252    |
| training/sac_Q/q2              | 209.42476    |
| training/sac_Q/q2_loss         | 96.93316     |
| training/sac_Q/q_global_norm   | 266.8034     |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1672163    |
| epoch                          | 471          |
| evaluation/episode-length-avg  | 931          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 314          |
| evaluation/episode-length-std  | 206          |
| evaluation/return-average      | 4356.554     |
| evaluation/return-max          | 4995.63      |
| evaluation/return-min          | 990.1587     |
| evaluation/return-std          | 1128.9869    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.03         |
| model/origin_ret               | 86.2         |
| model/penalty_ret              | 82.2         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46111        |
| perf/AverageLength             | 931          |
| perf/AverageReturn             | 4356.554     |
| perf/NormalizedReturn          | 0.949        |
| Q-avg                          | 204.91939    |
| Q-std                          | 132.59114    |
| Q_loss                         | 115.83143    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 471          |
| times/epoch_after_hook         | 1.82e-06     |
| times/epoch_before_hook        | 0.000155     |
| times/epoch_rollout_model      | 506          |
| times/evaluation_metrics       | 0.00105      |
| times/evaluation_paths         | 32.8         |
| times/timestep_after_hook      | 0.00408      |
| times/timestep_before_hook     | 0.00839      |
| times/train                    | 61.8         |
| timestep                       | 1000         |
| timesteps_total                | 472000       |
| train-steps                    | 472000       |
| training/Q/q1_loss             | 104.3884     |
| training/sac_pi/alpha          | 0.16722326   |
| training/sac_pi/alpha_loss     | -0.117716536 |
| training/sac_pi/logp_pi        | 3.712583     |
| training/sac_pi/pi_entropy     | 3.3302147    |
| training/sac_pi/pi_global_norm | 1.6033832    |
| training/sac_pi/policy_loss    | -226.25374   |
| training/sac_pi/std            | 0.4690305    |
| training/sac_pi/valid_num      | 5047.0       |
| training/sac_Q/q1              | 220.54663    |
| training/sac_Q/q2              | 219.64238    |
| training/sac_Q/q2_loss         | 104.01273    |
| training/sac_Q/q_global_norm   | 221.24283    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17178205  |
| epoch                          | 472         |
| evaluation/episode-length-avg  | 660         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 147         |
| evaluation/episode-length-std  | 417         |
| evaluation/return-average      | 2998.1875   |
| evaluation/return-max          | 4848.6104   |
| evaluation/return-min          | 367.95746   |
| evaluation/return-std          | 2146.425    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46348       |
| perf/AverageLength             | 660         |
| perf/AverageReturn             | 2998.1875   |
| perf/NormalizedReturn          | 0.653       |
| Q-avg                          | 206.03482   |
| Q-std                          | 112.54762   |
| Q_loss                         | 88.95034    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 472         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000149    |
| times/epoch_rollout_model      | 506         |
| times/evaluation_metrics       | 0.000486    |
| times/evaluation_paths         | 23.1        |
| times/timestep_after_hook      | 0.00437     |
| times/timestep_before_hook     | 0.00882     |
| times/train                    | 62.1        |
| timestep                       | 1000        |
| timesteps_total                | 473000      |
| train-steps                    | 473000      |
| training/Q/q1_loss             | 112.237564  |
| training/sac_pi/alpha          | 0.17178172  |
| training/sac_pi/alpha_loss     | -0.28603426 |
| training/sac_pi/logp_pi        | 4.3043528   |
| training/sac_pi/pi_entropy     | 3.4916031   |
| training/sac_pi/pi_global_norm | 1.778006    |
| training/sac_pi/policy_loss    | -214.03644  |
| training/sac_pi/std            | 0.5011161   |
| training/sac_pi/valid_num      | 4889.0      |
| training/sac_Q/q1              | 201.1995    |
| training/sac_Q/q2              | 199.87466   |
| training/sac_Q/q2_loss         | 111.058075  |
| training/sac_Q/q_global_norm   | 220.76534   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17267863  |
| epoch                          | 473         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4495.0366   |
| evaluation/return-max          | 4693.084    |
| evaluation/return-min          | 4319.789    |
| evaluation/return-std          | 142.25363   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46232       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4495.0366   |
| perf/NormalizedReturn          | 0.979       |
| Q-avg                          | 199.15671   |
| Q-std                          | 127.193054  |
| Q_loss                         | 101.59072   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 473         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.00027     |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000657    |
| times/evaluation_paths         | 33          |
| times/timestep_after_hook      | 0.00681     |
| times/timestep_before_hook     | 0.00839     |
| times/train                    | 62.9        |
| timestep                       | 1000        |
| timesteps_total                | 474000      |
| train-steps                    | 474000      |
| training/Q/q1_loss             | 108.70346   |
| training/sac_pi/alpha          | 0.17267016  |
| training/sac_pi/alpha_loss     | -0.27058288 |
| training/sac_pi/logp_pi        | 4.331794    |
| training/sac_pi/pi_entropy     | 3.5096161   |
| training/sac_pi/pi_global_norm | 2.4571407   |
| training/sac_pi/policy_loss    | -216.54495  |
| training/sac_pi/std            | 0.50468314  |
| training/sac_pi/valid_num      | 4939.0      |
| training/sac_Q/q1              | 205.43002   |
| training/sac_Q/q2              | 204.55814   |
| training/sac_Q/q2_loss         | 108.2764    |
| training/sac_Q/q_global_norm   | 208.48291   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17541355  |
| epoch                          | 474         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4483.628    |
| evaluation/return-max          | 4552.6      |
| evaluation/return-min          | 4420.1353   |
| evaluation/return-std          | 39.870155   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46295       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4483.628    |
| perf/NormalizedReturn          | 0.976       |
| Q-avg                          | 198.86145   |
| Q-std                          | 119.35975   |
| Q_loss                         | 94.20626    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 474         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000544    |
| times/evaluation_paths         | 33.5        |
| times/timestep_after_hook      | 0.00397     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 475000      |
| train-steps                    | 475000      |
| training/Q/q1_loss             | 98.81801    |
| training/sac_pi/alpha          | 0.1754065   |
| training/sac_pi/alpha_loss     | -0.19977169 |
| training/sac_pi/logp_pi        | 3.5350158   |
| training/sac_pi/pi_entropy     | 3.6692688   |
| training/sac_pi/pi_global_norm | 1.7642894   |
| training/sac_pi/policy_loss    | -211.29091  |
| training/sac_pi/std            | 0.49936455  |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 202.0736    |
| training/sac_Q/q2              | 201.79816   |
| training/sac_Q/q2_loss         | 98.11376    |
| training/sac_Q/q_global_norm   | 190.24019   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17187655 |
| epoch                          | 475        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5067.409   |
| evaluation/return-max          | 5170.1885  |
| evaluation/return-min          | 4849.911   |
| evaluation/return-std          | 97.447556  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46227      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5067.409   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 207.64114  |
| Q-std                          | 103.954185 |
| Q_loss                         | 99.79581   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 475        |
| times/epoch_after_hook         | 2.04e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000524   |
| times/evaluation_paths         | 32.9       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 58.9       |
| timestep                       | 1000       |
| timesteps_total                | 476000     |
| train-steps                    | 476000     |
| training/Q/q1_loss             | 96.04369   |
| training/sac_pi/alpha          | 0.17187893 |
| training/sac_pi/alpha_loss     | -0.3414626 |
| training/sac_pi/logp_pi        | 3.524798   |
| training/sac_pi/pi_entropy     | 3.4970756  |
| training/sac_pi/pi_global_norm | 1.6747733  |
| training/sac_pi/policy_loss    | -220.06947 |
| training/sac_pi/std            | 0.48394826 |
| training/sac_pi/valid_num      | 4955.0     |
| training/sac_Q/q1              | 212.63928  |
| training/sac_Q/q2              | 212.67021  |
| training/sac_Q/q2_loss         | 95.366234  |
| training/sac_Q/q_global_norm   | 193.06456  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17060418 |
| epoch                          | 476        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5155.495   |
| evaluation/return-max          | 5189.962   |
| evaluation/return-min          | 5081.702   |
| evaluation/return-std          | 28.970507  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46287      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5155.495   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 205.70036  |
| Q-std                          | 117.240654 |
| Q_loss                         | 105.114136 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 476        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000593   |
| times/evaluation_paths         | 33.4       |
| times/timestep_after_hook      | 0.00409    |
| times/timestep_before_hook     | 0.00869    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 477000     |
| train-steps                    | 477000     |
| training/Q/q1_loss             | 92.280556  |
| training/sac_pi/alpha          | 0.17057534 |
| training/sac_pi/alpha_loss     | 0.3184096  |
| training/sac_pi/logp_pi        | 4.515859   |
| training/sac_pi/pi_entropy     | 3.468881   |
| training/sac_pi/pi_global_norm | 1.8684016  |
| training/sac_pi/policy_loss    | -208.9757  |
| training/sac_pi/std            | 0.50038815 |
| training/sac_pi/valid_num      | 4974.0     |
| training/sac_Q/q1              | 200.84969  |
| training/sac_Q/q2              | 200.7349   |
| training/sac_Q/q2_loss         | 93.5238    |
| training/sac_Q/q_global_norm   | 254.29543  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16490024  |
| epoch                          | 477         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5052.501    |
| evaluation/return-max          | 5090.4487   |
| evaluation/return-min          | 5000.777    |
| evaluation/return-std          | 25.810328   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46394       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5052.501    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 205.6879    |
| Q-std                          | 122.415985  |
| Q_loss                         | 88.70402    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 477         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000262    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000513    |
| times/evaluation_paths         | 34.6        |
| times/timestep_after_hook      | 0.00396     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 59.4        |
| timestep                       | 1000        |
| timesteps_total                | 478000      |
| train-steps                    | 478000      |
| training/Q/q1_loss             | 88.45033    |
| training/sac_pi/alpha          | 0.16491     |
| training/sac_pi/alpha_loss     | 0.055745654 |
| training/sac_pi/logp_pi        | 5.0864954   |
| training/sac_pi/pi_entropy     | 3.4837883   |
| training/sac_pi/pi_global_norm | 1.9168411   |
| training/sac_pi/policy_loss    | -216.40038  |
| training/sac_pi/std            | 0.5292271   |
| training/sac_pi/valid_num      | 4905.0      |
| training/sac_Q/q1              | 199.89963   |
| training/sac_Q/q2              | 199.24637   |
| training/sac_Q/q2_loss         | 89.70393    |
| training/sac_Q/q_global_norm   | 277.64288   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1681564  |
| epoch                          | 478        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5018.5786  |
| evaluation/return-max          | 5078.925   |
| evaluation/return-min          | 4982.7544  |
| evaluation/return-std          | 27.787977  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46253      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5018.5786  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 204.89424  |
| Q-std                          | 115.03791  |
| Q_loss                         | 104.41116  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 478        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.00011    |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000569   |
| times/evaluation_paths         | 33.2       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00806    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 479000     |
| train-steps                    | 479000     |
| training/Q/q1_loss             | 83.13357   |
| training/sac_pi/alpha          | 0.1681649  |
| training/sac_pi/alpha_loss     | -0.1940519 |
| training/sac_pi/logp_pi        | 4.495342   |
| training/sac_pi/pi_entropy     | 3.591095   |
| training/sac_pi/pi_global_norm | 1.8178008  |
| training/sac_pi/policy_loss    | -215.19789 |
| training/sac_pi/std            | 0.5127292  |
| training/sac_pi/valid_num      | 4970.0     |
| training/sac_Q/q1              | 202.87259  |
| training/sac_Q/q2              | 200.61221  |
| training/sac_Q/q2_loss         | 83.41486   |
| training/sac_Q/q_global_norm   | 179.40344  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16920733 |
| epoch                          | 479        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5059.993   |
| evaluation/return-max          | 5078.5234  |
| evaluation/return-min          | 5018.327   |
| evaluation/return-std          | 16.982838  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46281      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5059.993   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 204.85176  |
| Q-std                          | 133.71222  |
| Q_loss                         | 107.19404  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 479        |
| times/epoch_after_hook         | 3.63e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000564   |
| times/evaluation_paths         | 33         |
| times/timestep_after_hook      | 0.00398    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 480000     |
| train-steps                    | 480000     |
| training/Q/q1_loss             | 100.33973  |
| training/sac_pi/alpha          | 0.16919877 |
| training/sac_pi/alpha_loss     | 0.29936582 |
| training/sac_pi/logp_pi        | 4.269677   |
| training/sac_pi/pi_entropy     | 3.3774734  |
| training/sac_pi/pi_global_norm | 1.4698132  |
| training/sac_pi/policy_loss    | -217.88083 |
| training/sac_pi/std            | 0.4680925  |
| training/sac_pi/valid_num      | 4953.0     |
| training/sac_Q/q1              | 212.01025  |
| training/sac_Q/q2              | 209.21758  |
| training/sac_Q/q2_loss         | 100.00297  |
| training/sac_Q/q_global_norm   | 234.03748  |
--------------------------------------------------------------------------------
[WARN] 480 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.17209333 |
| epoch                          | 480        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4749.857   |
| evaluation/return-max          | 4824.967   |
| evaluation/return-min          | 4506.2695  |
| evaluation/return-std          | 105.47195  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46321      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4749.857   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 210.38467  |
| Q-std                          | 111.06825  |
| Q_loss                         | 107.927315 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 480        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000119   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000514   |
| times/evaluation_paths         | 33.2       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 58.7       |
| timestep                       | 1000       |
| timesteps_total                | 481000     |
| train-steps                    | 481000     |
| training/Q/q1_loss             | 77.27364   |
| training/sac_pi/alpha          | 0.17205247 |
| training/sac_pi/alpha_loss     | 0.28759667 |
| training/sac_pi/logp_pi        | 3.58293    |
| training/sac_pi/pi_entropy     | 3.408711   |
| training/sac_pi/pi_global_norm | 2.1351206  |
| training/sac_pi/policy_loss    | -217.22348 |
| training/sac_pi/std            | 0.45985827 |
| training/sac_pi/valid_num      | 4992.0     |
| training/sac_Q/q1              | 211.85307  |
| training/sac_Q/q2              | 210.48433  |
| training/sac_Q/q2_loss         | 76.17067   |
| training/sac_Q/q_global_norm   | 264.77414  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1696904   |
| epoch                          | 481         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5070.068    |
| evaluation/return-max          | 5167.584    |
| evaluation/return-min          | 5011.613    |
| evaluation/return-std          | 46.005177   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46317       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5070.068    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 201.69489   |
| Q-std                          | 110.955086  |
| Q_loss                         | 109.22256   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 481         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000324    |
| times/epoch_rollout_model      | 510         |
| times/evaluation_metrics       | 0.000519    |
| times/evaluation_paths         | 33          |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.00827     |
| times/train                    | 58.8        |
| timestep                       | 1000        |
| timesteps_total                | 482000      |
| train-steps                    | 482000      |
| training/Q/q1_loss             | 93.04272    |
| training/sac_pi/alpha          | 0.16966286  |
| training/sac_pi/alpha_loss     | -0.18059394 |
| training/sac_pi/logp_pi        | 4.032097    |
| training/sac_pi/pi_entropy     | 3.4466195   |
| training/sac_pi/pi_global_norm | 1.6188366   |
| training/sac_pi/policy_loss    | -222.4973   |
| training/sac_pi/std            | 0.4944498   |
| training/sac_pi/valid_num      | 4996.0      |
| training/sac_Q/q1              | 216.48145   |
| training/sac_Q/q2              | 215.7607    |
| training/sac_Q/q2_loss         | 92.40975    |
| training/sac_Q/q_global_norm   | 238.47005   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1681085   |
| epoch                          | 482         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5119.124    |
| evaluation/return-max          | 5203.5933   |
| evaluation/return-min          | 4930.536    |
| evaluation/return-std          | 78.80502    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46253       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5119.124    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 196.81543   |
| Q-std                          | 139.42851   |
| Q_loss                         | 107.3628    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 482         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 509         |
| times/evaluation_metrics       | 0.000523    |
| times/evaluation_paths         | 33.1        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00833     |
| times/train                    | 58.8        |
| timestep                       | 1000        |
| timesteps_total                | 483000      |
| train-steps                    | 483000      |
| training/Q/q1_loss             | 83.41395    |
| training/sac_pi/alpha          | 0.16812724  |
| training/sac_pi/alpha_loss     | -0.28205144 |
| training/sac_pi/logp_pi        | 3.5696921   |
| training/sac_pi/pi_entropy     | 3.2999644   |
| training/sac_pi/pi_global_norm | 1.7056751   |
| training/sac_pi/policy_loss    | -220.77087  |
| training/sac_pi/std            | 0.4703741   |
| training/sac_pi/valid_num      | 4996.0      |
| training/sac_Q/q1              | 215.10092   |
| training/sac_Q/q2              | 213.91153   |
| training/sac_Q/q2_loss         | 82.83154    |
| training/sac_Q/q_global_norm   | 220.98634   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1691371  |
| epoch                          | 483        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4913.121   |
| evaluation/return-max          | 4968.3066  |
| evaluation/return-min          | 4862.0137  |
| evaluation/return-std          | 32.250103  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46374      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4913.121   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 204.33435  |
| Q-std                          | 114.51293  |
| Q_loss                         | 111.1249   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 483        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000504   |
| times/evaluation_paths         | 33.2       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 60.2       |
| timestep                       | 1000       |
| timesteps_total                | 484000     |
| train-steps                    | 484000     |
| training/Q/q1_loss             | 87.29873   |
| training/sac_pi/alpha          | 0.16908705 |
| training/sac_pi/alpha_loss     | -0.1015605 |
| training/sac_pi/logp_pi        | 4.26052    |
| training/sac_pi/pi_entropy     | 3.3690524  |
| training/sac_pi/pi_global_norm | 1.7725813  |
| training/sac_pi/policy_loss    | -217.54471 |
| training/sac_pi/std            | 0.4941325  |
| training/sac_pi/valid_num      | 4988.0     |
| training/sac_Q/q1              | 211.02681  |
| training/sac_Q/q2              | 210.7164   |
| training/sac_Q/q2_loss         | 89.86191   |
| training/sac_Q/q_global_norm   | 269.85825  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16705973   |
| epoch                          | 484          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5235.8843    |
| evaluation/return-max          | 5275.4966    |
| evaluation/return-min          | 5150.0845    |
| evaluation/return-std          | 33.49622     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3            |
| model/origin_ret               | 85.9         |
| model/penalty_ret              | 81.9         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46112        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5235.8843    |
| perf/NormalizedReturn          | 1.14         |
| Q-avg                          | 211.54463    |
| Q-std                          | 106.21681    |
| Q_loss                         | 89.95485     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 484          |
| times/epoch_after_hook         | 1.73e-06     |
| times/epoch_before_hook        | 0.000104     |
| times/epoch_rollout_model      | 514          |
| times/evaluation_metrics       | 0.000577     |
| times/evaluation_paths         | 34.1         |
| times/timestep_after_hook      | 0.004        |
| times/timestep_before_hook     | 0.00856      |
| times/train                    | 59.6         |
| timestep                       | 1000         |
| timesteps_total                | 485000       |
| train-steps                    | 485000       |
| training/Q/q1_loss             | 85.70274     |
| training/sac_pi/alpha          | 0.16704772   |
| training/sac_pi/alpha_loss     | -0.075785406 |
| training/sac_pi/logp_pi        | 5.1218576    |
| training/sac_pi/pi_entropy     | 3.2717674    |
| training/sac_pi/pi_global_norm | 1.6590708    |
| training/sac_pi/policy_loss    | -228.97714   |
| training/sac_pi/std            | 0.49792615   |
| training/sac_pi/valid_num      | 4939.0       |
| training/sac_Q/q1              | 220.07524    |
| training/sac_Q/q2              | 217.55717    |
| training/sac_Q/q2_loss         | 86.32534     |
| training/sac_Q/q_global_norm   | 180.80997    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16648407   |
| epoch                          | 485          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5077.0063    |
| evaluation/return-max          | 5153.4863    |
| evaluation/return-min          | 4967.7334    |
| evaluation/return-std          | 50.02839     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.07         |
| model/origin_ret               | 86.8         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46223        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5077.0063    |
| perf/NormalizedReturn          | 1.11         |
| Q-avg                          | 212.67642    |
| Q-std                          | 110.22792    |
| Q_loss                         | 83.320496    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 485          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.000282     |
| times/epoch_rollout_model      | 515          |
| times/evaluation_metrics       | 0.000586     |
| times/evaluation_paths         | 34.9         |
| times/timestep_after_hook      | 0.00426      |
| times/timestep_before_hook     | 0.00835      |
| times/train                    | 59.5         |
| timestep                       | 1000         |
| timesteps_total                | 486000       |
| train-steps                    | 486000       |
| training/Q/q1_loss             | 89.006874    |
| training/sac_pi/alpha          | 0.16645661   |
| training/sac_pi/alpha_loss     | -0.015615834 |
| training/sac_pi/logp_pi        | 4.5155888    |
| training/sac_pi/pi_entropy     | 3.4097004    |
| training/sac_pi/pi_global_norm | 1.6332443    |
| training/sac_pi/policy_loss    | -218.36507   |
| training/sac_pi/std            | 0.49058446   |
| training/sac_pi/valid_num      | 4944.0       |
| training/sac_Q/q1              | 210.16959    |
| training/sac_Q/q2              | 208.53023    |
| training/sac_Q/q2_loss         | 86.93221     |
| training/sac_Q/q_global_norm   | 193.1126     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16929957 |
| epoch                          | 486        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5261.801   |
| evaluation/return-max          | 5293.3867  |
| evaluation/return-min          | 5235.7334  |
| evaluation/return-std          | 15.43223   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46358      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5261.801   |
| perf/NormalizedReturn          | 1.15       |
| Q-avg                          | 207.37314  |
| Q-std                          | 116.31146  |
| Q_loss                         | 104.67254  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 486        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000115   |
| times/epoch_rollout_model      | 514        |
| times/evaluation_metrics       | 0.000644   |
| times/evaluation_paths         | 35.1       |
| times/timestep_after_hook      | 0.00447    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 59.7       |
| timestep                       | 1000       |
| timesteps_total                | 487000     |
| train-steps                    | 487000     |
| training/Q/q1_loss             | 100.12406  |
| training/sac_pi/alpha          | 0.16927218 |
| training/sac_pi/alpha_loss     | 0.16983427 |
| training/sac_pi/logp_pi        | 4.631217   |
| training/sac_pi/pi_entropy     | 3.3710113  |
| training/sac_pi/pi_global_norm | 1.7213774  |
| training/sac_pi/policy_loss    | -216.32144 |
| training/sac_pi/std            | 0.49173158 |
| training/sac_pi/valid_num      | 4955.0     |
| training/sac_Q/q1              | 208.7749   |
| training/sac_Q/q2              | 206.80557  |
| training/sac_Q/q2_loss         | 100.2582   |
| training/sac_Q/q_global_norm   | 241.58412  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17655484   |
| epoch                          | 487          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4890.5366    |
| evaluation/return-max          | 4914.211     |
| evaluation/return-min          | 4860.777     |
| evaluation/return-std          | 17.195967    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.05         |
| model/origin_ret               | 86           |
| model/penalty_ret              | 80.9         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46149        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4890.5366    |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 211.06235    |
| Q-std                          | 102.02941    |
| Q_loss                         | 124.53607    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 487          |
| times/epoch_after_hook         | 1.87e-06     |
| times/epoch_before_hook        | 0.00013      |
| times/epoch_rollout_model      | 512          |
| times/evaluation_metrics       | 0.000602     |
| times/evaluation_paths         | 33           |
| times/timestep_after_hook      | 0.00403      |
| times/timestep_before_hook     | 0.00827      |
| times/train                    | 59.5         |
| timestep                       | 1000         |
| timesteps_total                | 488000       |
| train-steps                    | 488000       |
| training/Q/q1_loss             | 93.5916      |
| training/sac_pi/alpha          | 0.17654829   |
| training/sac_pi/alpha_loss     | -0.052639995 |
| training/sac_pi/logp_pi        | 4.1359444    |
| training/sac_pi/pi_entropy     | 3.260743     |
| training/sac_pi/pi_global_norm | 1.5415751    |
| training/sac_pi/policy_loss    | -222.30037   |
| training/sac_pi/std            | 0.46783796   |
| training/sac_pi/valid_num      | 4944.0       |
| training/sac_Q/q1              | 212.18925    |
| training/sac_Q/q2              | 211.23495    |
| training/sac_Q/q2_loss         | 92.80769     |
| training/sac_Q/q_global_norm   | 221.89777    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16904593  |
| epoch                          | 488         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4930.9453   |
| evaluation/return-max          | 4961.488    |
| evaluation/return-min          | 4899.5537   |
| evaluation/return-std          | 16.934393   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46291       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4930.9453   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 200.7464    |
| Q-std                          | 126.66633   |
| Q_loss                         | 117.119064  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 488         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000117    |
| times/epoch_rollout_model      | 503         |
| times/evaluation_metrics       | 0.000652    |
| times/evaluation_paths         | 33          |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.00855     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 489000      |
| train-steps                    | 489000      |
| training/Q/q1_loss             | 96.04129    |
| training/sac_pi/alpha          | 0.16907057  |
| training/sac_pi/alpha_loss     | -0.20562744 |
| training/sac_pi/logp_pi        | 3.9754906   |
| training/sac_pi/pi_entropy     | 3.2379868   |
| training/sac_pi/pi_global_norm | 1.3803223   |
| training/sac_pi/policy_loss    | -222.90543  |
| training/sac_pi/std            | 0.452777    |
| training/sac_pi/valid_num      | 4947.0      |
| training/sac_Q/q1              | 214.93896   |
| training/sac_Q/q2              | 214.02869   |
| training/sac_Q/q2_loss         | 96.23881    |
| training/sac_Q/q_global_norm   | 242.93797   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16762342  |
| epoch                          | 489         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5607.0635   |
| evaluation/return-max          | 5624.732    |
| evaluation/return-min          | 5583.513    |
| evaluation/return-std          | 14.019807   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46123       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5607.0635   |
| perf/NormalizedReturn          | 1.22        |
| Q-avg                          | 207.0935    |
| Q-std                          | 131.90784   |
| Q_loss                         | 107.14465   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 489         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000274    |
| times/epoch_rollout_model      | 508         |
| times/evaluation_metrics       | 0.000517    |
| times/evaluation_paths         | 32.8        |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.00853     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 490000      |
| train-steps                    | 490000      |
| training/Q/q1_loss             | 112.98621   |
| training/sac_pi/alpha          | 0.16767818  |
| training/sac_pi/alpha_loss     | -0.06569158 |
| training/sac_pi/logp_pi        | 3.7374482   |
| training/sac_pi/pi_entropy     | 3.42586     |
| training/sac_pi/pi_global_norm | 1.5728167   |
| training/sac_pi/policy_loss    | -214.42294  |
| training/sac_pi/std            | 0.47262293  |
| training/sac_pi/valid_num      | 4987.0      |
| training/sac_Q/q1              | 209.31099   |
| training/sac_Q/q2              | 207.89034   |
| training/sac_Q/q2_loss         | 111.908134  |
| training/sac_Q/q_global_norm   | 268.997     |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16581358 |
| epoch                          | 490        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5124.057   |
| evaluation/return-max          | 5239.8955  |
| evaluation/return-min          | 5037.1406  |
| evaluation/return-std          | 54.546455  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 82.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46204      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5124.057   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 215.18596  |
| Q-std                          | 100.45833  |
| Q_loss                         | 83.19018   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 490        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 512        |
| times/evaluation_metrics       | 0.000546   |
| times/evaluation_paths         | 34.2       |
| times/timestep_after_hook      | 0.00409    |
| times/timestep_before_hook     | 0.00859    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 491000     |
| train-steps                    | 491000     |
| training/Q/q1_loss             | 109.94477  |
| training/sac_pi/alpha          | 0.16581099 |
| training/sac_pi/alpha_loss     | 0.12687503 |
| training/sac_pi/logp_pi        | 4.2508407  |
| training/sac_pi/pi_entropy     | 3.402811   |
| training/sac_pi/pi_global_norm | 2.073099   |
| training/sac_pi/policy_loss    | -214.04266 |
| training/sac_pi/std            | 0.48052666 |
| training/sac_pi/valid_num      | 4967.0     |
| training/sac_Q/q1              | 205.00252  |
| training/sac_Q/q2              | 205.79118  |
| training/sac_Q/q2_loss         | 110.67103  |
| training/sac_Q/q_global_norm   | 223.97456  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1656409  |
| epoch                          | 491        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4825.6567  |
| evaluation/return-max          | 4943.8047  |
| evaluation/return-min          | 4624.2656  |
| evaluation/return-std          | 83.45456   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46263      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4825.6567  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 202.30145  |
| Q-std                          | 127.2912   |
| Q_loss                         | 100.75105  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 491        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 509        |
| times/evaluation_metrics       | 0.00061    |
| times/evaluation_paths         | 33.2       |
| times/timestep_after_hook      | 0.00426    |
| times/timestep_before_hook     | 0.0086     |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 492000     |
| train-steps                    | 492000     |
| training/Q/q1_loss             | 93.173775  |
| training/sac_pi/alpha          | 0.1656724  |
| training/sac_pi/alpha_loss     | 0.22048303 |
| training/sac_pi/logp_pi        | 4.2685328  |
| training/sac_pi/pi_entropy     | 3.234686   |
| training/sac_pi/pi_global_norm | 1.7601365  |
| training/sac_pi/policy_loss    | -227.3935  |
| training/sac_pi/std            | 0.47352526 |
| training/sac_pi/valid_num      | 4990.0     |
| training/sac_Q/q1              | 222.4602   |
| training/sac_Q/q2              | 220.88748  |
| training/sac_Q/q2_loss         | 92.94805   |
| training/sac_Q/q_global_norm   | 186.71507  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16939637  |
| epoch                          | 492         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5320.3647   |
| evaluation/return-max          | 5340.5586   |
| evaluation/return-min          | 5282.3516   |
| evaluation/return-std          | 18.931341   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46261       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5320.3647   |
| perf/NormalizedReturn          | 1.16        |
| Q-avg                          | 204.72464   |
| Q-std                          | 122.93272   |
| Q_loss                         | 115.45188   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 492         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 511         |
| times/evaluation_metrics       | 0.000549    |
| times/evaluation_paths         | 33.2        |
| times/timestep_after_hook      | 0.00433     |
| times/timestep_before_hook     | 0.00829     |
| times/train                    | 60.1        |
| timestep                       | 1000        |
| timesteps_total                | 493000      |
| train-steps                    | 493000      |
| training/Q/q1_loss             | 74.783035   |
| training/sac_pi/alpha          | 0.16941404  |
| training/sac_pi/alpha_loss     | -0.21563894 |
| training/sac_pi/logp_pi        | 4.214572    |
| training/sac_pi/pi_entropy     | 3.578534    |
| training/sac_pi/pi_global_norm | 1.7853738   |
| training/sac_pi/policy_loss    | -230.29588  |
| training/sac_pi/std            | 0.5061788   |
| training/sac_pi/valid_num      | 4944.0      |
| training/sac_Q/q1              | 216.86836   |
| training/sac_Q/q2              | 216.30074   |
| training/sac_Q/q2_loss         | 74.81232    |
| training/sac_Q/q_global_norm   | 255.70392   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17289561  |
| epoch                          | 493         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5121.247    |
| evaluation/return-max          | 5218.2964   |
| evaluation/return-min          | 4958.1084   |
| evaluation/return-std          | 78.39786    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46130       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5121.247    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 200.4028    |
| Q-std                          | 114.110146  |
| Q_loss                         | 105.65427   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 493         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000308    |
| times/epoch_rollout_model      | 510         |
| times/evaluation_metrics       | 0.000554    |
| times/evaluation_paths         | 32.9        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.0084      |
| times/train                    | 58.7        |
| timestep                       | 1000        |
| timesteps_total                | 494000      |
| train-steps                    | 494000      |
| training/Q/q1_loss             | 87.0427     |
| training/sac_pi/alpha          | 0.17289706  |
| training/sac_pi/alpha_loss     | -0.11421761 |
| training/sac_pi/logp_pi        | 4.7376413   |
| training/sac_pi/pi_entropy     | 3.3598328   |
| training/sac_pi/pi_global_norm | 1.7502582   |
| training/sac_pi/policy_loss    | -216.66313  |
| training/sac_pi/std            | 0.50281936  |
| training/sac_pi/valid_num      | 4904.0      |
| training/sac_Q/q1              | 204.2421    |
| training/sac_Q/q2              | 204.5094    |
| training/sac_Q/q2_loss         | 87.550835   |
| training/sac_Q/q_global_norm   | 214.18738   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16858073   |
| epoch                          | 494          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4959.5044    |
| evaluation/return-max          | 5049.258     |
| evaluation/return-min          | 4864.3784    |
| evaluation/return-std          | 57.867565    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.05         |
| model/origin_ret               | 86.7         |
| model/penalty_ret              | 81.7         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46271        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4959.5044    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 210.81693    |
| Q-std                          | 124.22555    |
| Q_loss                         | 92.727325    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 494          |
| times/epoch_after_hook         | 1.97e-06     |
| times/epoch_before_hook        | 0.000154     |
| times/epoch_rollout_model      | 507          |
| times/evaluation_metrics       | 0.000525     |
| times/evaluation_paths         | 33.3         |
| times/timestep_after_hook      | 0.00404      |
| times/timestep_before_hook     | 0.00851      |
| times/train                    | 59.7         |
| timestep                       | 1000         |
| timesteps_total                | 495000       |
| train-steps                    | 495000       |
| training/Q/q1_loss             | 113.51703    |
| training/sac_pi/alpha          | 0.16860503   |
| training/sac_pi/alpha_loss     | -0.022546437 |
| training/sac_pi/logp_pi        | 3.7876892    |
| training/sac_pi/pi_entropy     | 3.4448586    |
| training/sac_pi/pi_global_norm | 1.8037758    |
| training/sac_pi/policy_loss    | -212.3331    |
| training/sac_pi/std            | 0.47557515   |
| training/sac_pi/valid_num      | 5029.0       |
| training/sac_Q/q1              | 207.6847     |
| training/sac_Q/q2              | 207.75095    |
| training/sac_Q/q2_loss         | 112.90652    |
| training/sac_Q/q_global_norm   | 246.6925     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17307015 |
| epoch                          | 495        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5219.3115  |
| evaluation/return-max          | 5284.664   |
| evaluation/return-min          | 5160.311   |
| evaluation/return-std          | 40.012787  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46319      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5219.3115  |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 205.62334  |
| Q-std                          | 125.95007  |
| Q_loss                         | 113.148926 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 495        |
| times/epoch_after_hook         | 2.06e-06   |
| times/epoch_before_hook        | 0.000102   |
| times/epoch_rollout_model      | 509        |
| times/evaluation_metrics       | 0.000518   |
| times/evaluation_paths         | 32.8       |
| times/timestep_after_hook      | 0.00422    |
| times/timestep_before_hook     | 0.00869    |
| times/train                    | 61.5       |
| timestep                       | 1000       |
| timesteps_total                | 496000     |
| train-steps                    | 496000     |
| training/Q/q1_loss             | 123.86938  |
| training/sac_pi/alpha          | 0.17306615 |
| training/sac_pi/alpha_loss     | 0.5212295  |
| training/sac_pi/logp_pi        | 4.5109572  |
| training/sac_pi/pi_entropy     | 3.4226413  |
| training/sac_pi/pi_global_norm | 1.657653   |
| training/sac_pi/policy_loss    | -218.12624 |
| training/sac_pi/std            | 0.47364396 |
| training/sac_pi/valid_num      | 4981.0     |
| training/sac_Q/q1              | 210.5439   |
| training/sac_Q/q2              | 210.24194  |
| training/sac_Q/q2_loss         | 123.472755 |
| training/sac_Q/q_global_norm   | 265.8115   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16865543 |
| epoch                          | 496        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4993.769   |
| evaluation/return-max          | 5111.8438  |
| evaluation/return-min          | 4885.726   |
| evaluation/return-std          | 61.89114   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 86.8       |
| model/penalty_ret              | 82.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46002      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4993.769   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 198.95071  |
| Q-std                          | 140.25827  |
| Q_loss                         | 134.01797  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 496        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 509        |
| times/evaluation_metrics       | 0.000505   |
| times/evaluation_paths         | 33.1       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00854    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 497000     |
| train-steps                    | 497000     |
| training/Q/q1_loss             | 92.41948   |
| training/sac_pi/alpha          | 0.16863021 |
| training/sac_pi/alpha_loss     | 0.12588163 |
| training/sac_pi/logp_pi        | 3.6511407  |
| training/sac_pi/pi_entropy     | 3.2564273  |
| training/sac_pi/pi_global_norm | 1.7654446  |
| training/sac_pi/policy_loss    | -228.27338 |
| training/sac_pi/std            | 0.44989693 |
| training/sac_pi/valid_num      | 5006.0     |
| training/sac_Q/q1              | 222.64688  |
| training/sac_Q/q2              | 222.51945  |
| training/sac_Q/q2_loss         | 91.024284  |
| training/sac_Q/q_global_norm   | 200.22057  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17175828 |
| epoch                          | 497        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4442.054   |
| evaluation/return-max          | 4673.6924  |
| evaluation/return-min          | 4199.6367  |
| evaluation/return-std          | 200.10338  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46287      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4442.054   |
| perf/NormalizedReturn          | 0.967      |
| Q-avg                          | 205.20073  |
| Q-std                          | 117.23565  |
| Q_loss                         | 118.21928  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 497        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.00026    |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000557   |
| times/evaluation_paths         | 34.9       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00856    |
| times/train                    | 58.8       |
| timestep                       | 1000       |
| timesteps_total                | 498000     |
| train-steps                    | 498000     |
| training/Q/q1_loss             | 107.43644  |
| training/sac_pi/alpha          | 0.17175913 |
| training/sac_pi/alpha_loss     | 0.1487987  |
| training/sac_pi/logp_pi        | 4.0014243  |
| training/sac_pi/pi_entropy     | 3.5332313  |
| training/sac_pi/pi_global_norm | 1.7859634  |
| training/sac_pi/policy_loss    | -207.53244 |
| training/sac_pi/std            | 0.48572937 |
| training/sac_pi/valid_num      | 4903.0     |
| training/sac_Q/q1              | 198.08133  |
| training/sac_Q/q2              | 196.85422  |
| training/sac_Q/q2_loss         | 108.51225  |
| training/sac_Q/q_global_norm   | 249.46901  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1748271  |
| epoch                          | 498        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4792.5903  |
| evaluation/return-max          | 4851.5625  |
| evaluation/return-min          | 4745.212   |
| evaluation/return-std          | 37.70207   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46298      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4792.5903  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 216.54768  |
| Q-std                          | 113.956055 |
| Q_loss                         | 94.077576  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 498        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.00011    |
| times/epoch_rollout_model      | 511        |
| times/evaluation_metrics       | 0.000511   |
| times/evaluation_paths         | 34.8       |
| times/timestep_after_hook      | 0.00408    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 59.9       |
| timestep                       | 1000       |
| timesteps_total                | 499000     |
| train-steps                    | 499000     |
| training/Q/q1_loss             | 107.33713  |
| training/sac_pi/alpha          | 0.17481175 |
| training/sac_pi/alpha_loss     | 0.13965806 |
| training/sac_pi/logp_pi        | 4.241769   |
| training/sac_pi/pi_entropy     | 3.395636   |
| training/sac_pi/pi_global_norm | 1.5450509  |
| training/sac_pi/policy_loss    | -218.81372 |
| training/sac_pi/std            | 0.47200018 |
| training/sac_pi/valid_num      | 4977.0     |
| training/sac_Q/q1              | 212.08023  |
| training/sac_Q/q2              | 210.93442  |
| training/sac_Q/q2_loss         | 107.64102  |
| training/sac_Q/q_global_norm   | 354.84897  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17134193  |
| epoch                          | 499         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5034.554    |
| evaluation/return-max          | 5096.449    |
| evaluation/return-min          | 4901.048    |
| evaluation/return-std          | 59.049854   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46240       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5034.554    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 206.40317   |
| Q-std                          | 105.69515   |
| Q_loss                         | 85.82334    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 499         |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 510         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 35.3        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 59.8        |
| timestep                       | 1000        |
| timesteps_total                | 500000      |
| train-steps                    | 500000      |
| training/Q/q1_loss             | 80.69828    |
| training/sac_pi/alpha          | 0.17138396  |
| training/sac_pi/alpha_loss     | -0.27407682 |
| training/sac_pi/logp_pi        | 4.117293    |
| training/sac_pi/pi_entropy     | 3.527829    |
| training/sac_pi/pi_global_norm | 1.723159    |
| training/sac_pi/policy_loss    | -212.59254  |
| training/sac_pi/std            | 0.50009763  |
| training/sac_pi/valid_num      | 4975.0      |
| training/sac_Q/q1              | 205.05771   |
| training/sac_Q/q2              | 203.3127    |
| training/sac_Q/q2_loss         | 80.87642    |
| training/sac_Q/q_global_norm   | 227.5686    |
---------------------------------------------------------------------------------
[WARN] 500 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.1697451   |
| epoch                          | 500         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5076.0522   |
| evaluation/return-max          | 5167.675    |
| evaluation/return-min          | 4898.376    |
| evaluation/return-std          | 90.17361    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46176       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5076.0522   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 215.10703   |
| Q-std                          | 137.34584   |
| Q_loss                         | 109.01961   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 500         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 525         |
| times/evaluation_metrics       | 0.000559    |
| times/evaluation_paths         | 35.8        |
| times/timestep_after_hook      | 0.00418     |
| times/timestep_before_hook     | 0.00868     |
| times/train                    | 66.7        |
| timestep                       | 1000        |
| timesteps_total                | 501000      |
| train-steps                    | 501000      |
| training/Q/q1_loss             | 102.50329   |
| training/sac_pi/alpha          | 0.16977255  |
| training/sac_pi/alpha_loss     | -0.30710495 |
| training/sac_pi/logp_pi        | 4.558255    |
| training/sac_pi/pi_entropy     | 3.2534766   |
| training/sac_pi/pi_global_norm | 1.7008835   |
| training/sac_pi/policy_loss    | -216.92426  |
| training/sac_pi/std            | 0.48293164  |
| training/sac_pi/valid_num      | 4971.0      |
| training/sac_Q/q1              | 206.57016   |
| training/sac_Q/q2              | 205.48096   |
| training/sac_Q/q2_loss         | 102.67602   |
| training/sac_Q/q_global_norm   | 223.11679   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16803652  |
| epoch                          | 501         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4896.616    |
| evaluation/return-max          | 4957.964    |
| evaluation/return-min          | 4802.509    |
| evaluation/return-std          | 48.86936    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46190       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4896.616    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 207.80803   |
| Q-std                          | 136.39638   |
| Q_loss                         | 111.306595  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 501         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.0189      |
| times/epoch_rollout_model      | 518         |
| times/evaluation_metrics       | 0.000523    |
| times/evaluation_paths         | 33.3        |
| times/timestep_after_hook      | 0.00422     |
| times/timestep_before_hook     | 0.0087      |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 502000      |
| train-steps                    | 502000      |
| training/Q/q1_loss             | 92.9865     |
| training/sac_pi/alpha          | 0.16804288  |
| training/sac_pi/alpha_loss     | -0.24803744 |
| training/sac_pi/logp_pi        | 3.821305    |
| training/sac_pi/pi_entropy     | 3.212789    |
| training/sac_pi/pi_global_norm | 1.5980564   |
| training/sac_pi/policy_loss    | -217.81685  |
| training/sac_pi/std            | 0.46307582  |
| training/sac_pi/valid_num      | 5011.0      |
| training/sac_Q/q1              | 211.22623   |
| training/sac_Q/q2              | 210.07385   |
| training/sac_Q/q2_loss         | 93.75903    |
| training/sac_Q/q_global_norm   | 242.37218   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16690892 |
| epoch                          | 502        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5048.62    |
| evaluation/return-max          | 5214.946   |
| evaluation/return-min          | 4873.9233  |
| evaluation/return-std          | 108.398254 |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46314      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5048.62    |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 218.99312  |
| Q-std                          | 102.65262  |
| Q_loss                         | 95.17415   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 502        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000207   |
| times/epoch_rollout_model      | 537        |
| times/evaluation_metrics       | 0.000524   |
| times/evaluation_paths         | 33.6       |
| times/timestep_after_hook      | 0.00408    |
| times/timestep_before_hook     | 0.00846    |
| times/train                    | 59.2       |
| timestep                       | 1000       |
| timesteps_total                | 503000     |
| train-steps                    | 503000     |
| training/Q/q1_loss             | 109.1438   |
| training/sac_pi/alpha          | 0.16686058 |
| training/sac_pi/alpha_loss     | 0.27540416 |
| training/sac_pi/logp_pi        | 5.178088   |
| training/sac_pi/pi_entropy     | 3.5659637  |
| training/sac_pi/pi_global_norm | 1.4780828  |
| training/sac_pi/policy_loss    | -212.39445 |
| training/sac_pi/std            | 0.5440238  |
| training/sac_pi/valid_num      | 4921.0     |
| training/sac_Q/q1              | 199.12436  |
| training/sac_Q/q2              | 198.92593  |
| training/sac_Q/q2_loss         | 107.77771  |
| training/sac_Q/q_global_norm   | 281.75845  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17120606  |
| epoch                          | 503         |
| evaluation/episode-length-avg  | 782         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 572         |
| evaluation/episode-length-std  | 152         |
| evaluation/return-average      | 3864.1824   |
| evaluation/return-max          | 5114.835    |
| evaluation/return-min          | 2694.9946   |
| evaluation/return-std          | 849.65753   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46404       |
| perf/AverageLength             | 782         |
| perf/AverageReturn             | 3864.1824   |
| perf/NormalizedReturn          | 0.841       |
| Q-avg                          | 209.95393   |
| Q-std                          | 131.53517   |
| Q_loss                         | 107.87687   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 503         |
| times/epoch_after_hook         | 1.93e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 513         |
| times/evaluation_metrics       | 0.000628    |
| times/evaluation_paths         | 26.3        |
| times/timestep_after_hook      | 0.00423     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 62.8        |
| timestep                       | 1000        |
| timesteps_total                | 504000      |
| train-steps                    | 504000      |
| training/Q/q1_loss             | 96.305786   |
| training/sac_pi/alpha          | 0.17123716  |
| training/sac_pi/alpha_loss     | -0.04269557 |
| training/sac_pi/logp_pi        | 3.235601    |
| training/sac_pi/pi_entropy     | 3.3380268   |
| training/sac_pi/pi_global_norm | 1.6325033   |
| training/sac_pi/policy_loss    | -221.69044  |
| training/sac_pi/std            | 0.44761258  |
| training/sac_pi/valid_num      | 4999.0      |
| training/sac_Q/q1              | 217.53833   |
| training/sac_Q/q2              | 217.17358   |
| training/sac_Q/q2_loss         | 94.91599    |
| training/sac_Q/q_global_norm   | 211.8495    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16929424 |
| epoch                          | 504        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4761.3813  |
| evaluation/return-max          | 4930.211   |
| evaluation/return-min          | 4622.4053  |
| evaluation/return-std          | 77.31287   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46355      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4761.3813  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 209.91838  |
| Q-std                          | 124.89075  |
| Q_loss                         | 99.42293   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 504        |
| times/epoch_after_hook         | 2.17e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 505        |
| times/evaluation_metrics       | 0.00062    |
| times/evaluation_paths         | 35.5       |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 67.5       |
| timestep                       | 1000       |
| timesteps_total                | 505000     |
| train-steps                    | 505000     |
| training/Q/q1_loss             | 94.47111   |
| training/sac_pi/alpha          | 0.16927342 |
| training/sac_pi/alpha_loss     | 0.25750813 |
| training/sac_pi/logp_pi        | 4.348298   |
| training/sac_pi/pi_entropy     | 3.4527988  |
| training/sac_pi/pi_global_norm | 1.4324644  |
| training/sac_pi/policy_loss    | -216.2688  |
| training/sac_pi/std            | 0.49203598 |
| training/sac_pi/valid_num      | 5001.0     |
| training/sac_Q/q1              | 208.46567  |
| training/sac_Q/q2              | 206.4524   |
| training/sac_Q/q2_loss         | 95.02219   |
| training/sac_Q/q_global_norm   | 159.87865  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16913997  |
| epoch                          | 505         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4657.4697   |
| evaluation/return-max          | 4745.96     |
| evaluation/return-min          | 4528.7695   |
| evaluation/return-std          | 63.278717   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46316       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4657.4697   |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 203.04337   |
| Q-std                          | 141.30667   |
| Q_loss                         | 94.46257    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 505         |
| times/epoch_after_hook         | 3.67e-06    |
| times/epoch_before_hook        | 0.000329    |
| times/epoch_rollout_model      | 519         |
| times/evaluation_metrics       | 0.000656    |
| times/evaluation_paths         | 34.9        |
| times/timestep_after_hook      | 0.00435     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 59.8        |
| timestep                       | 1000        |
| timesteps_total                | 506000      |
| train-steps                    | 506000      |
| training/Q/q1_loss             | 77.07535    |
| training/sac_pi/alpha          | 0.16911295  |
| training/sac_pi/alpha_loss     | -0.15703134 |
| training/sac_pi/logp_pi        | 3.5028145   |
| training/sac_pi/pi_entropy     | 3.3143468   |
| training/sac_pi/pi_global_norm | 1.496274    |
| training/sac_pi/policy_loss    | -223.81375  |
| training/sac_pi/std            | 0.45835698  |
| training/sac_pi/valid_num      | 5031.0      |
| training/sac_Q/q1              | 220.37471   |
| training/sac_Q/q2              | 219.59448   |
| training/sac_Q/q2_loss         | 76.880486   |
| training/sac_Q/q_global_norm   | 203.39029   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17319648 |
| epoch                          | 506        |
| evaluation/episode-length-avg  | 720        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 298        |
| evaluation/episode-length-std  | 343        |
| evaluation/return-average      | 3510.9617  |
| evaluation/return-max          | 5146.0864  |
| evaluation/return-min          | 1114.3777  |
| evaluation/return-std          | 1944.908   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46178      |
| perf/AverageLength             | 720        |
| perf/AverageReturn             | 3510.9617  |
| perf/NormalizedReturn          | 0.764      |
| Q-avg                          | 212.10689  |
| Q-std                          | 125.34774  |
| Q_loss                         | 100.59607  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 506        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.00016    |
| times/epoch_rollout_model      | 512        |
| times/evaluation_metrics       | 0.000471   |
| times/evaluation_paths         | 24.6       |
| times/timestep_after_hook      | 0.00422    |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 507000     |
| train-steps                    | 507000     |
| training/Q/q1_loss             | 75.926     |
| training/sac_pi/alpha          | 0.17318533 |
| training/sac_pi/alpha_loss     | -0.4069622 |
| training/sac_pi/logp_pi        | 4.686976   |
| training/sac_pi/pi_entropy     | 3.549358   |
| training/sac_pi/pi_global_norm | 2.3760383  |
| training/sac_pi/policy_loss    | -216.57585 |
| training/sac_pi/std            | 0.5264739  |
| training/sac_pi/valid_num      | 4919.0     |
| training/sac_Q/q1              | 197.8256   |
| training/sac_Q/q2              | 198.21161  |
| training/sac_Q/q2_loss         | 77.421814  |
| training/sac_Q/q_global_norm   | 200.97302  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16669124 |
| epoch                          | 507        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5074.158   |
| evaluation/return-max          | 5196.1533  |
| evaluation/return-min          | 4986.242   |
| evaluation/return-std          | 53.871677  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46189      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5074.158   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 210.32016  |
| Q-std                          | 111.15552  |
| Q_loss                         | 91.70271   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 507        |
| times/epoch_after_hook         | 1.97e-06   |
| times/epoch_before_hook        | 0.000116   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000633   |
| times/evaluation_paths         | 32.2       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 508000     |
| train-steps                    | 508000     |
| training/Q/q1_loss             | 104.66582  |
| training/sac_pi/alpha          | 0.16667177 |
| training/sac_pi/alpha_loss     | 0.24974006 |
| training/sac_pi/logp_pi        | 4.664838   |
| training/sac_pi/pi_entropy     | 3.2996507  |
| training/sac_pi/pi_global_norm | 1.65869    |
| training/sac_pi/policy_loss    | -221.45636 |
| training/sac_pi/std            | 0.4842692  |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 211.50317  |
| training/sac_Q/q2              | 210.49248  |
| training/sac_Q/q2_loss         | 103.46948  |
| training/sac_Q/q_global_norm   | 264.7923   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16696292 |
| epoch                          | 508        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5304.2783  |
| evaluation/return-max          | 5377.2734  |
| evaluation/return-min          | 5142.672   |
| evaluation/return-std          | 63.968952  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46150      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5304.2783  |
| perf/NormalizedReturn          | 1.16       |
| Q-avg                          | 213.55537  |
| Q-std                          | 104.60931  |
| Q_loss                         | 110.69182  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 508        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000506   |
| times/evaluation_paths         | 39         |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 73.5       |
| timestep                       | 1000       |
| timesteps_total                | 509000     |
| train-steps                    | 509000     |
| training/Q/q1_loss             | 95.37071   |
| training/sac_pi/alpha          | 0.16695598 |
| training/sac_pi/alpha_loss     | 0.12491566 |
| training/sac_pi/logp_pi        | 4.5656238  |
| training/sac_pi/pi_entropy     | 3.5800884  |
| training/sac_pi/pi_global_norm | 1.6377625  |
| training/sac_pi/policy_loss    | -221.13025 |
| training/sac_pi/std            | 0.53017116 |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 212.88358  |
| training/sac_Q/q2              | 211.65149  |
| training/sac_Q/q2_loss         | 95.11577   |
| training/sac_Q/q_global_norm   | 193.92647  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16993116 |
| epoch                          | 509        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4986.3145  |
| evaluation/return-max          | 5087.196   |
| evaluation/return-min          | 4879.5215  |
| evaluation/return-std          | 74.06573   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46208      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4986.3145  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 223.24234  |
| Q-std                          | 104.18674  |
| Q_loss                         | 102.88386  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 509        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000316   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000571   |
| times/evaluation_paths         | 33.4       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 510000     |
| train-steps                    | 510000     |
| training/Q/q1_loss             | 103.88833  |
| training/sac_pi/alpha          | 0.1698969  |
| training/sac_pi/alpha_loss     | 0.34232035 |
| training/sac_pi/logp_pi        | 3.9152503  |
| training/sac_pi/pi_entropy     | 3.5411096  |
| training/sac_pi/pi_global_norm | 2.4230533  |
| training/sac_pi/policy_loss    | -219.58032 |
| training/sac_pi/std            | 0.4824608  |
| training/sac_pi/valid_num      | 5019.0     |
| training/sac_Q/q1              | 215.87125  |
| training/sac_Q/q2              | 215.30586  |
| training/sac_Q/q2_loss         | 104.0255   |
| training/sac_Q/q_global_norm   | 309.78036  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17225218  |
| epoch                          | 510         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4888.8433   |
| evaluation/return-max          | 5003.46     |
| evaluation/return-min          | 4689.323    |
| evaluation/return-std          | 87.34065    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46227       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4888.8433   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 209.34094   |
| Q-std                          | 117.76255   |
| Q_loss                         | 90.38144    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 510         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000139    |
| times/epoch_rollout_model      | 511         |
| times/evaluation_metrics       | 0.000503    |
| times/evaluation_paths         | 32.5        |
| times/timestep_after_hook      | 0.00397     |
| times/timestep_before_hook     | 0.00833     |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 511000      |
| train-steps                    | 511000      |
| training/Q/q1_loss             | 85.12484    |
| training/sac_pi/alpha          | 0.17227758  |
| training/sac_pi/alpha_loss     | -0.29497188 |
| training/sac_pi/logp_pi        | 3.9101615   |
| training/sac_pi/pi_entropy     | 3.3498015   |
| training/sac_pi/pi_global_norm | 1.7379143   |
| training/sac_pi/policy_loss    | -224.30547  |
| training/sac_pi/std            | 0.48246688  |
| training/sac_pi/valid_num      | 4971.0      |
| training/sac_Q/q1              | 215.12878   |
| training/sac_Q/q2              | 213.5363    |
| training/sac_Q/q2_loss         | 85.37476    |
| training/sac_Q/q_global_norm   | 220.45045   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17210047 |
| epoch                          | 511        |
| evaluation/episode-length-avg  | 585        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 302        |
| evaluation/episode-length-std  | 339        |
| evaluation/return-average      | 2667.237   |
| evaluation/return-max          | 5189.178   |
| evaluation/return-min          | 1173.1766  |
| evaluation/return-std          | 1791.2761  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46403      |
| perf/AverageLength             | 585        |
| perf/AverageReturn             | 2667.237   |
| perf/NormalizedReturn          | 0.581      |
| Q-avg                          | 220.01273  |
| Q-std                          | 94.77968   |
| Q_loss                         | 130.36064  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 511        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 510        |
| times/evaluation_metrics       | 0.000515   |
| times/evaluation_paths         | 19.2       |
| times/timestep_after_hook      | 0.00408    |
| times/timestep_before_hook     | 0.00863    |
| times/train                    | 63.7       |
| timestep                       | 1000       |
| timesteps_total                | 512000     |
| train-steps                    | 512000     |
| training/Q/q1_loss             | 95.09701   |
| training/sac_pi/alpha          | 0.17208864 |
| training/sac_pi/alpha_loss     | 0.29570693 |
| training/sac_pi/logp_pi        | 4.309863   |
| training/sac_pi/pi_entropy     | 3.4511108  |
| training/sac_pi/pi_global_norm | 2.0673234  |
| training/sac_pi/policy_loss    | -222.00511 |
| training/sac_pi/std            | 0.49432808 |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 213.56404  |
| training/sac_Q/q2              | 211.94914  |
| training/sac_Q/q2_loss         | 94.36836   |
| training/sac_Q/q_global_norm   | 273.23282  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17661884  |
| epoch                          | 512         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5091.551    |
| evaluation/return-max          | 5133.4614   |
| evaluation/return-min          | 4993.5566   |
| evaluation/return-std          | 38.474102   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46258       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5091.551    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 213.21753   |
| Q-std                          | 101.2343    |
| Q_loss                         | 104.343056  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 512         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 507         |
| times/evaluation_metrics       | 0.000529    |
| times/evaluation_paths         | 45.9        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 59.4        |
| timestep                       | 1000        |
| timesteps_total                | 513000      |
| train-steps                    | 513000      |
| training/Q/q1_loss             | 107.33295   |
| training/sac_pi/alpha          | 0.17661862  |
| training/sac_pi/alpha_loss     | 0.122560084 |
| training/sac_pi/logp_pi        | 3.937022    |
| training/sac_pi/pi_entropy     | 3.5293803   |
| training/sac_pi/pi_global_norm | 1.5364864   |
| training/sac_pi/policy_loss    | -213.51646  |
| training/sac_pi/std            | 0.48941475  |
| training/sac_pi/valid_num      | 4989.0      |
| training/sac_Q/q1              | 207.64478   |
| training/sac_Q/q2              | 207.5312    |
| training/sac_Q/q2_loss         | 107.112144  |
| training/sac_Q/q_global_norm   | 268.80197   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17761345 |
| epoch                          | 513        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5024.505   |
| evaluation/return-max          | 5128.041   |
| evaluation/return-min          | 4931.908   |
| evaluation/return-std          | 59.701717  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46233      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5024.505   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 209.92595  |
| Q-std                          | 114.9977   |
| Q_loss                         | 89.159706  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 513        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000343   |
| times/epoch_rollout_model      | 514        |
| times/evaluation_metrics       | 0.000561   |
| times/evaluation_paths         | 37         |
| times/timestep_after_hook      | 0.0041     |
| times/timestep_before_hook     | 0.00866    |
| times/train                    | 70.8       |
| timestep                       | 1000       |
| timesteps_total                | 514000     |
| train-steps                    | 514000     |
| training/Q/q1_loss             | 91.52106   |
| training/sac_pi/alpha          | 0.17763539 |
| training/sac_pi/alpha_loss     | 0.12078399 |
| training/sac_pi/logp_pi        | 4.528206   |
| training/sac_pi/pi_entropy     | 3.2673893  |
| training/sac_pi/pi_global_norm | 1.7313577  |
| training/sac_pi/policy_loss    | -222.6476  |
| training/sac_pi/std            | 0.48682353 |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 210.58574  |
| training/sac_Q/q2              | 210.75009  |
| training/sac_Q/q2_loss         | 91.96084   |
| training/sac_Q/q_global_norm   | 249.16338  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17454083  |
| epoch                          | 514         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4178.1377   |
| evaluation/return-max          | 4332.1543   |
| evaluation/return-min          | 3874.0295   |
| evaluation/return-std          | 160.26254   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46271       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4178.1377   |
| perf/NormalizedReturn          | 0.91        |
| Q-avg                          | 198.55685   |
| Q-std                          | 109.48988   |
| Q_loss                         | 97.59136    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 514         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 534         |
| times/evaluation_metrics       | 0.000577    |
| times/evaluation_paths         | 35.7        |
| times/timestep_after_hook      | 0.00408     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 66.5        |
| timestep                       | 1000        |
| timesteps_total                | 515000      |
| train-steps                    | 515000      |
| training/Q/q1_loss             | 107.78068   |
| training/sac_pi/alpha          | 0.17454423  |
| training/sac_pi/alpha_loss     | 0.085307345 |
| training/sac_pi/logp_pi        | 4.1751075   |
| training/sac_pi/pi_entropy     | 3.3576355   |
| training/sac_pi/pi_global_norm | 1.8560326   |
| training/sac_pi/policy_loss    | -223.44518  |
| training/sac_pi/std            | 0.48647532  |
| training/sac_pi/valid_num      | 4938.0      |
| training/sac_Q/q1              | 214.8274    |
| training/sac_Q/q2              | 212.49199   |
| training/sac_Q/q2_loss         | 108.12625   |
| training/sac_Q/q_global_norm   | 277.13165   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17236832 |
| epoch                          | 515        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4855.6914  |
| evaluation/return-max          | 4911.484   |
| evaluation/return-min          | 4750.176   |
| evaluation/return-std          | 48.786232  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46243      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4855.6914  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 206.49731  |
| Q-std                          | 129.35074  |
| Q_loss                         | 76.72311   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 515        |
| times/epoch_after_hook         | 3.24e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.000542   |
| times/evaluation_paths         | 36.8       |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.00851    |
| times/train                    | 71.8       |
| timestep                       | 1000       |
| timesteps_total                | 516000     |
| train-steps                    | 516000     |
| training/Q/q1_loss             | 104.60597  |
| training/sac_pi/alpha          | 0.17232367 |
| training/sac_pi/alpha_loss     | 0.23233894 |
| training/sac_pi/logp_pi        | 3.7516277  |
| training/sac_pi/pi_entropy     | 3.2749474  |
| training/sac_pi/pi_global_norm | 1.585543   |
| training/sac_pi/policy_loss    | -222.99597 |
| training/sac_pi/std            | 0.4520372  |
| training/sac_pi/valid_num      | 5019.0     |
| training/sac_Q/q1              | 218.07681  |
| training/sac_Q/q2              | 216.77034  |
| training/sac_Q/q2_loss         | 104.561005 |
| training/sac_Q/q_global_norm   | 271.51868  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16521332 |
| epoch                          | 516        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5167.908   |
| evaluation/return-max          | 5230.329   |
| evaluation/return-min          | 5050.639   |
| evaluation/return-std          | 54.262466  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46207      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5167.908   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 213.89417  |
| Q-std                          | 131.56491  |
| Q_loss                         | 109.31931  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 516        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000201   |
| times/epoch_rollout_model      | 508        |
| times/evaluation_metrics       | 0.000646   |
| times/evaluation_paths         | 46.3       |
| times/timestep_after_hook      | 0.00408    |
| times/timestep_before_hook     | 0.00879    |
| times/train                    | 60.2       |
| timestep                       | 1000       |
| timesteps_total                | 517000     |
| train-steps                    | 517000     |
| training/Q/q1_loss             | 85.58731   |
| training/sac_pi/alpha          | 0.16516864 |
| training/sac_pi/alpha_loss     | 0.29291412 |
| training/sac_pi/logp_pi        | 4.084417   |
| training/sac_pi/pi_entropy     | 3.3054175  |
| training/sac_pi/pi_global_norm | 1.4661064  |
| training/sac_pi/policy_loss    | -226.1827  |
| training/sac_pi/std            | 0.46193632 |
| training/sac_pi/valid_num      | 5003.0     |
| training/sac_Q/q1              | 215.88277  |
| training/sac_Q/q2              | 215.5214   |
| training/sac_Q/q2_loss         | 83.16071   |
| training/sac_Q/q_global_norm   | 270.9272   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16961986 |
| epoch                          | 517        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4980.6733  |
| evaluation/return-max          | 5055.837   |
| evaluation/return-min          | 4858.419   |
| evaluation/return-std          | 53.982033  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46240      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4980.6733  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 207.86919  |
| Q-std                          | 133.08208  |
| Q_loss                         | 97.90531   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 517        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000316   |
| times/epoch_rollout_model      | 512        |
| times/evaluation_metrics       | 0.000607   |
| times/evaluation_paths         | 33.4       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 71.4       |
| timestep                       | 1000       |
| timesteps_total                | 518000     |
| train-steps                    | 518000     |
| training/Q/q1_loss             | 92.306885  |
| training/sac_pi/alpha          | 0.16961527 |
| training/sac_pi/alpha_loss     | -0.1708865 |
| training/sac_pi/logp_pi        | 3.3910508  |
| training/sac_pi/pi_entropy     | 3.250958   |
| training/sac_pi/pi_global_norm | 1.5770262  |
| training/sac_pi/policy_loss    | -222.2845  |
| training/sac_pi/std            | 0.45669737 |
| training/sac_pi/valid_num      | 5044.0     |
| training/sac_Q/q1              | 219.45639  |
| training/sac_Q/q2              | 219.01083  |
| training/sac_Q/q2_loss         | 92.39785   |
| training/sac_Q/q_global_norm   | 222.39113  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16862105  |
| epoch                          | 518         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4964.1387   |
| evaluation/return-max          | 5056.409    |
| evaluation/return-min          | 4728.484    |
| evaluation/return-std          | 83.23902    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46261       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4964.1387   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 214.46538   |
| Q-std                          | 100.94627   |
| Q_loss                         | 103.22279   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 518         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 503         |
| times/evaluation_metrics       | 0.000603    |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 64.6        |
| timestep                       | 1000        |
| timesteps_total                | 519000      |
| train-steps                    | 519000      |
| training/Q/q1_loss             | 88.469444   |
| training/sac_pi/alpha          | 0.16862151  |
| training/sac_pi/alpha_loss     | -0.30199087 |
| training/sac_pi/logp_pi        | 3.665247    |
| training/sac_pi/pi_entropy     | 3.4992993   |
| training/sac_pi/pi_global_norm | 1.3995136   |
| training/sac_pi/policy_loss    | -223.55449  |
| training/sac_pi/std            | 0.47973043  |
| training/sac_pi/valid_num      | 4971.0      |
| training/sac_Q/q1              | 216.43217   |
| training/sac_Q/q2              | 215.61905   |
| training/sac_Q/q2_loss         | 89.03202    |
| training/sac_Q/q_global_norm   | 189.19319   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17112415  |
| epoch                          | 519         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4883.6167   |
| evaluation/return-max          | 4976.032    |
| evaluation/return-min          | 4789.2354   |
| evaluation/return-std          | 51.047886   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46190       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4883.6167   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 205.39336   |
| Q-std                          | 167.2281    |
| Q_loss                         | 110.57154   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 519         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000584    |
| times/evaluation_paths         | 36.3        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 520000      |
| train-steps                    | 520000      |
| training/Q/q1_loss             | 84.41696    |
| training/sac_pi/alpha          | 0.17115495  |
| training/sac_pi/alpha_loss     | -0.33074316 |
| training/sac_pi/logp_pi        | 3.8472772   |
| training/sac_pi/pi_entropy     | 3.3913581   |
| training/sac_pi/pi_global_norm | 1.5487273   |
| training/sac_pi/policy_loss    | -225.77516  |
| training/sac_pi/std            | 0.478833    |
| training/sac_pi/valid_num      | 5017.0      |
| training/sac_Q/q1              | 219.9292    |
| training/sac_Q/q2              | 216.93172   |
| training/sac_Q/q2_loss         | 85.32195    |
| training/sac_Q/q_global_norm   | 188.09789   |
---------------------------------------------------------------------------------
[WARN] 520 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16933471 |
| epoch                          | 520        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4847.54    |
| evaluation/return-max          | 4939.0874  |
| evaluation/return-min          | 4728.742   |
| evaluation/return-std          | 61.219753  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46178      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4847.54    |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 208.08304  |
| Q-std                          | 128.29042  |
| Q_loss                         | 112.58498  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 520        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.000618   |
| times/evaluation_paths         | 35.9       |
| times/timestep_after_hook      | 0.00415    |
| times/timestep_before_hook     | 0.00846    |
| times/train                    | 74.4       |
| timestep                       | 1000       |
| timesteps_total                | 521000     |
| train-steps                    | 521000     |
| training/Q/q1_loss             | 97.89933   |
| training/sac_pi/alpha          | 0.16934681 |
| training/sac_pi/alpha_loss     | -0.1529175 |
| training/sac_pi/logp_pi        | 4.423467   |
| training/sac_pi/pi_entropy     | 3.1933608  |
| training/sac_pi/pi_global_norm | 1.7688692  |
| training/sac_pi/policy_loss    | -223.23907 |
| training/sac_pi/std            | 0.46474832 |
| training/sac_pi/valid_num      | 4907.0     |
| training/sac_Q/q1              | 211.40726  |
| training/sac_Q/q2              | 209.37936  |
| training/sac_Q/q2_loss         | 98.966965  |
| training/sac_Q/q_global_norm   | 286.95746  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.174596   |
| epoch                          | 521        |
| evaluation/episode-length-avg  | 484        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 126        |
| evaluation/episode-length-std  | 422        |
| evaluation/return-average      | 2107.1106  |
| evaluation/return-max          | 4821.5     |
| evaluation/return-min          | 278.40253  |
| evaluation/return-std          | 2193.6401  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46195      |
| perf/AverageLength             | 484        |
| perf/AverageReturn             | 2107.1106  |
| perf/NormalizedReturn          | 0.459      |
| Q-avg                          | 210.0708   |
| Q-std                          | 117.36617  |
| Q_loss                         | 99.198814  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 521        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000324   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.00051    |
| times/evaluation_paths         | 17         |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00853    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 522000     |
| train-steps                    | 522000     |
| training/Q/q1_loss             | 83.36255   |
| training/sac_pi/alpha          | 0.1746001  |
| training/sac_pi/alpha_loss     | -0.3488223 |
| training/sac_pi/logp_pi        | 3.7481983  |
| training/sac_pi/pi_entropy     | 3.3624313  |
| training/sac_pi/pi_global_norm | 1.8408257  |
| training/sac_pi/policy_loss    | -222.88293 |
| training/sac_pi/std            | 0.4729129  |
| training/sac_pi/valid_num      | 4976.0     |
| training/sac_Q/q1              | 212.40388  |
| training/sac_Q/q2              | 212.67093  |
| training/sac_Q/q2_loss         | 83.210045  |
| training/sac_Q/q_global_norm   | 194.66795  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17037383  |
| epoch                          | 522         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4938.9146   |
| evaluation/return-max          | 4963.999    |
| evaluation/return-min          | 4910.252    |
| evaluation/return-std          | 20.34125    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46370       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4938.9146   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 205.25998   |
| Q-std                          | 152.95468   |
| Q_loss                         | 134.32822   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 522         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 503         |
| times/evaluation_metrics       | 0.000513    |
| times/evaluation_paths         | 33.4        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 62.3        |
| timestep                       | 1000        |
| timesteps_total                | 523000      |
| train-steps                    | 523000      |
| training/Q/q1_loss             | 104.81981   |
| training/sac_pi/alpha          | 0.17036262  |
| training/sac_pi/alpha_loss     | -0.09363612 |
| training/sac_pi/logp_pi        | 4.311975    |
| training/sac_pi/pi_entropy     | 3.4193864   |
| training/sac_pi/pi_global_norm | 1.7020609   |
| training/sac_pi/policy_loss    | -223.12465  |
| training/sac_pi/std            | 0.5010895   |
| training/sac_pi/valid_num      | 4950.0      |
| training/sac_Q/q1              | 213.403     |
| training/sac_Q/q2              | 213.18558   |
| training/sac_Q/q2_loss         | 105.225784  |
| training/sac_Q/q_global_norm   | 209.49924   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17218047   |
| epoch                          | 523          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5013.5996    |
| evaluation/return-max          | 5040.468     |
| evaluation/return-min          | 4962.3496    |
| evaluation/return-std          | 23.920721    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.06         |
| model/origin_ret               | 85.5         |
| model/penalty_ret              | 80.9         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46249        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5013.5996    |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 206.73035    |
| Q-std                          | 127.90177    |
| Q_loss                         | 95.563576    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 523          |
| times/epoch_after_hook         | 1.78e-06     |
| times/epoch_before_hook        | 0.000109     |
| times/epoch_rollout_model      | 499          |
| times/evaluation_metrics       | 0.000628     |
| times/evaluation_paths         | 36.1         |
| times/timestep_after_hook      | 0.00408      |
| times/timestep_before_hook     | 0.00844      |
| times/train                    | 68.2         |
| timestep                       | 1000         |
| timesteps_total                | 524000       |
| train-steps                    | 524000       |
| training/Q/q1_loss             | 89.51679     |
| training/sac_pi/alpha          | 0.17217769   |
| training/sac_pi/alpha_loss     | -0.123419225 |
| training/sac_pi/logp_pi        | 4.5519156    |
| training/sac_pi/pi_entropy     | 3.2603219    |
| training/sac_pi/pi_global_norm | 1.6627378    |
| training/sac_pi/policy_loss    | -220.27565   |
| training/sac_pi/std            | 0.4773606    |
| training/sac_pi/valid_num      | 4972.0       |
| training/sac_Q/q1              | 207.13786    |
| training/sac_Q/q2              | 204.68973    |
| training/sac_Q/q2_loss         | 89.9419      |
| training/sac_Q/q_global_norm   | 272.48782    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17064686 |
| epoch                          | 524        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5129.4375  |
| evaluation/return-max          | 5171.912   |
| evaluation/return-min          | 5003.735   |
| evaluation/return-std          | 49.773487  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46307      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5129.4375  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 221.71281  |
| Q-std                          | 115.35852  |
| Q_loss                         | 74.14194   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 524        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000632   |
| times/evaluation_paths         | 48.4       |
| times/timestep_after_hook      | 0.00411    |
| times/timestep_before_hook     | 0.00864    |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 525000     |
| train-steps                    | 525000     |
| training/Q/q1_loss             | 94.65204   |
| training/sac_pi/alpha          | 0.17066531 |
| training/sac_pi/alpha_loss     | -0.1581508 |
| training/sac_pi/logp_pi        | 4.3687778  |
| training/sac_pi/pi_entropy     | 3.3323722  |
| training/sac_pi/pi_global_norm | 1.5368065  |
| training/sac_pi/policy_loss    | -213.92123 |
| training/sac_pi/std            | 0.4796658  |
| training/sac_pi/valid_num      | 4886.0     |
| training/sac_Q/q1              | 205.44376  |
| training/sac_Q/q2              | 203.94492  |
| training/sac_Q/q2_loss         | 94.17374   |
| training/sac_Q/q_global_norm   | 251.98364  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17517246  |
| epoch                          | 525         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5118.533    |
| evaluation/return-max          | 5266.2725   |
| evaluation/return-min          | 5010.3564   |
| evaluation/return-std          | 86.87594    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46292       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5118.533    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 206.65732   |
| Q-std                          | 137.42435   |
| Q_loss                         | 121.5156    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 525         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.00031     |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000767    |
| times/evaluation_paths         | 37.7        |
| times/timestep_after_hook      | 0.00417     |
| times/timestep_before_hook     | 0.00861     |
| times/train                    | 69.3        |
| timestep                       | 1000        |
| timesteps_total                | 526000      |
| train-steps                    | 526000      |
| training/Q/q1_loss             | 108.79646   |
| training/sac_pi/alpha          | 0.17517558  |
| training/sac_pi/alpha_loss     | -0.19486812 |
| training/sac_pi/logp_pi        | 4.54734     |
| training/sac_pi/pi_entropy     | 3.4056892   |
| training/sac_pi/pi_global_norm | 1.6618416   |
| training/sac_pi/policy_loss    | -211.21928  |
| training/sac_pi/std            | 0.48245627  |
| training/sac_pi/valid_num      | 4935.0      |
| training/sac_Q/q1              | 199.11075   |
| training/sac_Q/q2              | 196.16135   |
| training/sac_Q/q2_loss         | 108.49325   |
| training/sac_Q/q_global_norm   | 317.67822   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17095453 |
| epoch                          | 526        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5177.1196  |
| evaluation/return-max          | 5282.1646  |
| evaluation/return-min          | 5136.075   |
| evaluation/return-std          | 42.566757  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46257      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5177.1196  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 199.92159  |
| Q-std                          | 115.702255 |
| Q_loss                         | 119.60646  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 526        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000169   |
| times/epoch_rollout_model      | 514        |
| times/evaluation_metrics       | 0.000541   |
| times/evaluation_paths         | 36.5       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00853    |
| times/train                    | 66.5       |
| timestep                       | 1000       |
| timesteps_total                | 527000     |
| train-steps                    | 527000     |
| training/Q/q1_loss             | 89.28347   |
| training/sac_pi/alpha          | 0.17096147 |
| training/sac_pi/alpha_loss     | -0.2810601 |
| training/sac_pi/logp_pi        | 4.2203307  |
| training/sac_pi/pi_entropy     | 3.4258792  |
| training/sac_pi/pi_global_norm | 1.5359145  |
| training/sac_pi/policy_loss    | -219.24586 |
| training/sac_pi/std            | 0.48957843 |
| training/sac_pi/valid_num      | 4958.0     |
| training/sac_Q/q1              | 206.9489   |
| training/sac_Q/q2              | 205.76958  |
| training/sac_Q/q2_loss         | 90.5653    |
| training/sac_Q/q_global_norm   | 168.76324  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16931331  |
| epoch                          | 527         |
| evaluation/episode-length-avg  | 787         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 150         |
| evaluation/episode-length-std  | 330         |
| evaluation/return-average      | 3789.6719   |
| evaluation/return-max          | 4973.458    |
| evaluation/return-min          | 448.511     |
| evaluation/return-std          | 1780.5054   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46248       |
| perf/AverageLength             | 787         |
| perf/AverageReturn             | 3789.6719   |
| perf/NormalizedReturn          | 0.825       |
| Q-avg                          | 212.72144   |
| Q-std                          | 100.17614   |
| Q_loss                         | 94.74245    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 527         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.00022     |
| times/epoch_rollout_model      | 504         |
| times/evaluation_metrics       | 0.000522    |
| times/evaluation_paths         | 27.5        |
| times/timestep_after_hook      | 0.00396     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 67.3        |
| timestep                       | 1000        |
| timesteps_total                | 528000      |
| train-steps                    | 528000      |
| training/Q/q1_loss             | 104.70114   |
| training/sac_pi/alpha          | 0.1693351   |
| training/sac_pi/alpha_loss     | -0.24208184 |
| training/sac_pi/logp_pi        | 4.3696985   |
| training/sac_pi/pi_entropy     | 3.38452     |
| training/sac_pi/pi_global_norm | 2.1610587   |
| training/sac_pi/policy_loss    | -216.16843  |
| training/sac_pi/std            | 0.51019174  |
| training/sac_pi/valid_num      | 4956.0      |
| training/sac_Q/q1              | 205.93147   |
| training/sac_Q/q2              | 204.64145   |
| training/sac_Q/q2_loss         | 103.62723   |
| training/sac_Q/q_global_norm   | 193.42941   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17624082 |
| epoch                          | 528        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4992.0405  |
| evaluation/return-max          | 5027.5737  |
| evaluation/return-min          | 4937.8726  |
| evaluation/return-std          | 24.860744  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46281      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4992.0405  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 199.13159  |
| Q-std                          | 180.52467  |
| Q_loss                         | 106.68527  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 528        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000539   |
| times/evaluation_paths         | 49.9       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.00856    |
| times/train                    | 65         |
| timestep                       | 1000       |
| timesteps_total                | 529000     |
| train-steps                    | 529000     |
| training/Q/q1_loss             | 102.8208   |
| training/sac_pi/alpha          | 0.17623962 |
| training/sac_pi/alpha_loss     | -0.2495788 |
| training/sac_pi/logp_pi        | 4.0367785  |
| training/sac_pi/pi_entropy     | 3.544292   |
| training/sac_pi/pi_global_norm | 1.7473508  |
| training/sac_pi/policy_loss    | -211.08795 |
| training/sac_pi/std            | 0.5026815  |
| training/sac_pi/valid_num      | 5013.0     |
| training/sac_Q/q1              | 207.81265  |
| training/sac_Q/q2              | 206.09615  |
| training/sac_Q/q2_loss         | 102.7986   |
| training/sac_Q/q_global_norm   | 248.54253  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17260724  |
| epoch                          | 529         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4967.518    |
| evaluation/return-max          | 5065.5684   |
| evaluation/return-min          | 4876.3604   |
| evaluation/return-std          | 68.75542    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46286       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4967.518    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 210.43985   |
| Q-std                          | 156.05136   |
| Q_loss                         | 97.572205   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 529         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000265    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000509    |
| times/evaluation_paths         | 39.6        |
| times/timestep_after_hook      | 0.00413     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 69.6        |
| timestep                       | 1000        |
| timesteps_total                | 530000      |
| train-steps                    | 530000      |
| training/Q/q1_loss             | 89.16929    |
| training/sac_pi/alpha          | 0.17263927  |
| training/sac_pi/alpha_loss     | -0.20496045 |
| training/sac_pi/logp_pi        | 3.2112956   |
| training/sac_pi/pi_entropy     | 3.4730995   |
| training/sac_pi/pi_global_norm | 1.8552877   |
| training/sac_pi/policy_loss    | -216.0037   |
| training/sac_pi/std            | 0.46182758  |
| training/sac_pi/valid_num      | 5080.0      |
| training/sac_Q/q1              | 215.05215   |
| training/sac_Q/q2              | 215.05795   |
| training/sac_Q/q2_loss         | 90.10318    |
| training/sac_Q/q_global_norm   | 245.08183   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16793627 |
| epoch                          | 530        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4898.579   |
| evaluation/return-max          | 4950.9277  |
| evaluation/return-min          | 4845.131   |
| evaluation/return-std          | 29.821228  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46283      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4898.579   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 212.83943  |
| Q-std                          | 95.397156  |
| Q_loss                         | 123.709    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 530        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000596   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 69.8       |
| timestep                       | 1000       |
| timesteps_total                | 531000     |
| train-steps                    | 531000     |
| training/Q/q1_loss             | 106.530556 |
| training/sac_pi/alpha          | 0.1679735  |
| training/sac_pi/alpha_loss     | 0.03675343 |
| training/sac_pi/logp_pi        | 4.0484853  |
| training/sac_pi/pi_entropy     | 3.295858   |
| training/sac_pi/pi_global_norm | 1.9130397  |
| training/sac_pi/policy_loss    | -221.14651 |
| training/sac_pi/std            | 0.4744237  |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 213.45236  |
| training/sac_Q/q2              | 212.71419  |
| training/sac_Q/q2_loss         | 106.178314 |
| training/sac_Q/q_global_norm   | 276.95947  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1728611  |
| epoch                          | 531        |
| evaluation/episode-length-avg  | 932        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 324        |
| evaluation/episode-length-std  | 203        |
| evaluation/return-average      | 4674.573   |
| evaluation/return-max          | 5169.9526  |
| evaluation/return-min          | 1304.8287  |
| evaluation/return-std          | 1126.4606  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46287      |
| perf/AverageLength             | 932        |
| perf/AverageReturn             | 4674.573   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 180.43088  |
| Q-std                          | 151.10777  |
| Q_loss                         | 100.24825  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 531        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000613   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00433    |
| times/timestep_before_hook     | 0.00901    |
| times/train                    | 70.4       |
| timestep                       | 1000       |
| timesteps_total                | 532000     |
| train-steps                    | 532000     |
| training/Q/q1_loss             | 97.01778   |
| training/sac_pi/alpha          | 0.17284602 |
| training/sac_pi/alpha_loss     | 0.26599887 |
| training/sac_pi/logp_pi        | 4.86139    |
| training/sac_pi/pi_entropy     | 3.3359046  |
| training/sac_pi/pi_global_norm | 1.5173234  |
| training/sac_pi/policy_loss    | -211.75137 |
| training/sac_pi/std            | 0.48094776 |
| training/sac_pi/valid_num      | 4916.0     |
| training/sac_Q/q1              | 199.66524  |
| training/sac_Q/q2              | 195.43062  |
| training/sac_Q/q2_loss         | 97.36046   |
| training/sac_Q/q_global_norm   | 209.38481  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17193988 |
| epoch                          | 532        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4895.5396  |
| evaluation/return-max          | 4940.2266  |
| evaluation/return-min          | 4855.1484  |
| evaluation/return-std          | 25.62428   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46364      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4895.5396  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 213.27498  |
| Q-std                          | 100.550896 |
| Q_loss                         | 98.11594   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 532        |
| times/epoch_after_hook         | 3.73e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000578   |
| times/evaluation_paths         | 48.4       |
| times/timestep_after_hook      | 0.00411    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 63.6       |
| timestep                       | 1000       |
| timesteps_total                | 533000     |
| train-steps                    | 533000     |
| training/Q/q1_loss             | 112.71012  |
| training/sac_pi/alpha          | 0.17194821 |
| training/sac_pi/alpha_loss     | 0.09782266 |
| training/sac_pi/logp_pi        | 4.492835   |
| training/sac_pi/pi_entropy     | 3.5226104  |
| training/sac_pi/pi_global_norm | 1.6371052  |
| training/sac_pi/policy_loss    | -218.75908 |
| training/sac_pi/std            | 0.49805158 |
| training/sac_pi/valid_num      | 4959.0     |
| training/sac_Q/q1              | 206.35464  |
| training/sac_Q/q2              | 207.75757  |
| training/sac_Q/q2_loss         | 113.267456 |
| training/sac_Q/q_global_norm   | 216.16202  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16791762 |
| epoch                          | 533        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4905.735   |
| evaluation/return-max          | 4975.285   |
| evaluation/return-min          | 4842.5415  |
| evaluation/return-std          | 43.100807  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46226      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4905.735   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 198.73294  |
| Q-std                          | 143.97409  |
| Q_loss                         | 112.1676   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 533        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000276   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.00052    |
| times/evaluation_paths         | 38         |
| times/timestep_after_hook      | 0.00415    |
| times/timestep_before_hook     | 0.00855    |
| times/train                    | 67         |
| timestep                       | 1000       |
| timesteps_total                | 534000     |
| train-steps                    | 534000     |
| training/Q/q1_loss             | 102.60915  |
| training/sac_pi/alpha          | 0.1679012  |
| training/sac_pi/alpha_loss     | 0.20206836 |
| training/sac_pi/logp_pi        | 3.9613736  |
| training/sac_pi/pi_entropy     | 3.5129535  |
| training/sac_pi/pi_global_norm | 1.798584   |
| training/sac_pi/policy_loss    | -212.04587 |
| training/sac_pi/std            | 0.48366907 |
| training/sac_pi/valid_num      | 5004.0     |
| training/sac_Q/q1              | 204.91924  |
| training/sac_Q/q2              | 204.58159  |
| training/sac_Q/q2_loss         | 102.6557   |
| training/sac_Q/q_global_norm   | 181.13855  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1624919   |
| epoch                          | 534         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4981.474    |
| evaluation/return-max          | 5023.9736   |
| evaluation/return-min          | 4814.9736   |
| evaluation/return-std          | 58.56746    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46279       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4981.474    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 212.72037   |
| Q-std                          | 132.66747   |
| Q_loss                         | 87.53668    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 534         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000119    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000529    |
| times/evaluation_paths         | 36.1        |
| times/timestep_after_hook      | 0.0042      |
| times/timestep_before_hook     | 0.00851     |
| times/train                    | 68.4        |
| timestep                       | 1000        |
| timesteps_total                | 535000      |
| train-steps                    | 535000      |
| training/Q/q1_loss             | 101.28937   |
| training/sac_pi/alpha          | 0.16251649  |
| training/sac_pi/alpha_loss     | -0.23132437 |
| training/sac_pi/logp_pi        | 4.365814    |
| training/sac_pi/pi_entropy     | 3.3230767   |
| training/sac_pi/pi_global_norm | 1.5431867   |
| training/sac_pi/policy_loss    | -227.52477  |
| training/sac_pi/std            | 0.4973212   |
| training/sac_pi/valid_num      | 4937.0      |
| training/sac_Q/q1              | 217.18277   |
| training/sac_Q/q2              | 216.91513   |
| training/sac_Q/q2_loss         | 101.570656  |
| training/sac_Q/q_global_norm   | 253.80685   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1660917   |
| epoch                          | 535         |
| evaluation/episode-length-avg  | 219         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 127         |
| evaluation/episode-length-std  | 260         |
| evaluation/return-average      | 739.5404    |
| evaluation/return-max          | 4623.678    |
| evaluation/return-min          | 290.1916    |
| evaluation/return-std          | 1294.7399   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46269       |
| perf/AverageLength             | 219         |
| perf/AverageReturn             | 739.5404    |
| perf/NormalizedReturn          | 0.161       |
| Q-avg                          | 222.38782   |
| Q-std                          | 96.34485    |
| Q_loss                         | 82.69159    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 535         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000486    |
| times/evaluation_paths         | 8.63        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 62.2        |
| timestep                       | 1000        |
| timesteps_total                | 536000      |
| train-steps                    | 536000      |
| training/Q/q1_loss             | 113.37594   |
| training/sac_pi/alpha          | 0.16607727  |
| training/sac_pi/alpha_loss     | 0.122861974 |
| training/sac_pi/logp_pi        | 4.5393596   |
| training/sac_pi/pi_entropy     | 3.3187199   |
| training/sac_pi/pi_global_norm | 1.6613235   |
| training/sac_pi/policy_loss    | -220.50177  |
| training/sac_pi/std            | 0.4891051   |
| training/sac_pi/valid_num      | 4937.0      |
| training/sac_Q/q1              | 212.06766   |
| training/sac_Q/q2              | 209.99362   |
| training/sac_Q/q2_loss         | 113.820915  |
| training/sac_Q/q_global_norm   | 296.8467    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16817363  |
| epoch                          | 536         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4724.6455   |
| evaluation/return-max          | 4741.4263   |
| evaluation/return-min          | 4708.108    |
| evaluation/return-std          | 11.943981   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46293       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4724.6455   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 209.29195   |
| Q-std                          | 117.279465  |
| Q_loss                         | 89.35567    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 536         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000501    |
| times/evaluation_paths         | 39.6        |
| times/timestep_after_hook      | 0.00429     |
| times/timestep_before_hook     | 0.00863     |
| times/train                    | 74          |
| timestep                       | 1000        |
| timesteps_total                | 537000      |
| train-steps                    | 537000      |
| training/Q/q1_loss             | 107.97796   |
| training/sac_pi/alpha          | 0.16817793  |
| training/sac_pi/alpha_loss     | -0.30776548 |
| training/sac_pi/logp_pi        | 3.9137177   |
| training/sac_pi/pi_entropy     | 3.4639      |
| training/sac_pi/pi_global_norm | 1.9647638   |
| training/sac_pi/policy_loss    | -206.45578  |
| training/sac_pi/std            | 0.48991677  |
| training/sac_pi/valid_num      | 4936.0      |
| training/sac_Q/q1              | 198.9676    |
| training/sac_Q/q2              | 198.05472   |
| training/sac_Q/q2_loss         | 107.63479   |
| training/sac_Q/q_global_norm   | 277.90582   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17124818 |
| epoch                          | 537        |
| evaluation/episode-length-avg  | 603        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 152        |
| evaluation/episode-length-std  | 399        |
| evaluation/return-average      | 2452.9058  |
| evaluation/return-max          | 4558.161   |
| evaluation/return-min          | 350.70877  |
| evaluation/return-std          | 1934.6486  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46159      |
| perf/AverageLength             | 603        |
| perf/AverageReturn             | 2452.9058  |
| perf/NormalizedReturn          | 0.534      |
| Q-avg                          | 213.22781  |
| Q-std                          | 97.182945  |
| Q_loss                         | 112.57819  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 537        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000263   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000579   |
| times/evaluation_paths         | 21.3       |
| times/timestep_after_hook      | 0.00422    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 62.9       |
| timestep                       | 1000       |
| timesteps_total                | 538000     |
| train-steps                    | 538000     |
| training/Q/q1_loss             | 89.00534   |
| training/sac_pi/alpha          | 0.17121606 |
| training/sac_pi/alpha_loss     | 0.26725483 |
| training/sac_pi/logp_pi        | 4.0567927  |
| training/sac_pi/pi_entropy     | 3.286491   |
| training/sac_pi/pi_global_norm | 2.142229   |
| training/sac_pi/policy_loss    | -224.84714 |
| training/sac_pi/std            | 0.46840504 |
| training/sac_pi/valid_num      | 4990.0     |
| training/sac_Q/q1              | 219.18405  |
| training/sac_Q/q2              | 218.54135  |
| training/sac_Q/q2_loss         | 88.02842   |
| training/sac_Q/q_global_norm   | 189.28656  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17242281   |
| epoch                          | 538          |
| evaluation/episode-length-avg  | 738          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 115          |
| evaluation/episode-length-std  | 401          |
| evaluation/return-average      | 3441.9214    |
| evaluation/return-max          | 4891.7354    |
| evaluation/return-min          | 251.78008    |
| evaluation/return-std          | 2068.5596    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.97         |
| model/origin_ret               | 84.6         |
| model/penalty_ret              | 80.9         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46155        |
| perf/AverageLength             | 738          |
| perf/AverageReturn             | 3441.9214    |
| perf/NormalizedReturn          | 0.749        |
| Q-avg                          | 208.62161    |
| Q-std                          | 139.26675    |
| Q_loss                         | 95.45947     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 538          |
| times/epoch_after_hook         | 1.7e-06      |
| times/epoch_before_hook        | 0.000135     |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.000458     |
| times/evaluation_paths         | 26.7         |
| times/timestep_after_hook      | 0.00401      |
| times/timestep_before_hook     | 0.00844      |
| times/train                    | 63.2         |
| timestep                       | 1000         |
| timesteps_total                | 539000       |
| train-steps                    | 539000       |
| training/Q/q1_loss             | 96.57046     |
| training/sac_pi/alpha          | 0.17242892   |
| training/sac_pi/alpha_loss     | -0.022266582 |
| training/sac_pi/logp_pi        | 4.822818     |
| training/sac_pi/pi_entropy     | 3.4345193    |
| training/sac_pi/pi_global_norm | 1.6344082    |
| training/sac_pi/policy_loss    | -211.98692   |
| training/sac_pi/std            | 0.50576234   |
| training/sac_pi/valid_num      | 4942.0       |
| training/sac_Q/q1              | 198.58325    |
| training/sac_Q/q2              | 196.37686    |
| training/sac_Q/q2_loss         | 97.549255    |
| training/sac_Q/q_global_norm   | 248.71605    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16725294 |
| epoch                          | 539        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4796.7676  |
| evaluation/return-max          | 4862.8154  |
| evaluation/return-min          | 4690.7295  |
| evaluation/return-std          | 47.580494  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46291      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4796.7676  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 217.80069  |
| Q-std                          | 110.44071  |
| Q_loss                         | 87.01662   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 539        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000149   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000627   |
| times/evaluation_paths         | 36.8       |
| times/timestep_after_hook      | 0.00409    |
| times/timestep_before_hook     | 0.00857    |
| times/train                    | 63         |
| timestep                       | 1000       |
| timesteps_total                | 540000     |
| train-steps                    | 540000     |
| training/Q/q1_loss             | 114.179085 |
| training/sac_pi/alpha          | 0.16724843 |
| training/sac_pi/alpha_loss     | 0.14155792 |
| training/sac_pi/logp_pi        | 4.126815   |
| training/sac_pi/pi_entropy     | 3.309285   |
| training/sac_pi/pi_global_norm | 1.9020008  |
| training/sac_pi/policy_loss    | -221.31242 |
| training/sac_pi/std            | 0.46596318 |
| training/sac_pi/valid_num      | 4974.0     |
| training/sac_Q/q1              | 214.79468  |
| training/sac_Q/q2              | 213.46407  |
| training/sac_Q/q2_loss         | 114.70533  |
| training/sac_Q/q_global_norm   | 249.91347  |
--------------------------------------------------------------------------------
[WARN] 540 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16919875 |
| epoch                          | 540        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5136.4805  |
| evaluation/return-max          | 5157.042   |
| evaluation/return-min          | 5125.3447  |
| evaluation/return-std          | 10.482014  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46137      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5136.4805  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 205.05457  |
| Q-std                          | 122.01484  |
| Q_loss                         | 112.630714 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 540        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000183   |
| times/epoch_rollout_model      | 518        |
| times/evaluation_metrics       | 0.000855   |
| times/evaluation_paths         | 33.4       |
| times/timestep_after_hook      | 0.00418    |
| times/timestep_before_hook     | 0.00862    |
| times/train                    | 64         |
| timestep                       | 1000       |
| timesteps_total                | 541000     |
| train-steps                    | 541000     |
| training/Q/q1_loss             | 98.30609   |
| training/sac_pi/alpha          | 0.16925682 |
| training/sac_pi/alpha_loss     | -0.6068381 |
| training/sac_pi/logp_pi        | 4.3457556  |
| training/sac_pi/pi_entropy     | 3.2779102  |
| training/sac_pi/pi_global_norm | 1.7249556  |
| training/sac_pi/policy_loss    | -229.05022 |
| training/sac_pi/std            | 0.4866811  |
| training/sac_pi/valid_num      | 4991.0     |
| training/sac_Q/q1              | 217.24658  |
| training/sac_Q/q2              | 216.29263  |
| training/sac_Q/q2_loss         | 97.896805  |
| training/sac_Q/q_global_norm   | 216.22867  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17080167 |
| epoch                          | 541        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4937.278   |
| evaluation/return-max          | 5005.8564  |
| evaluation/return-min          | 4910.176   |
| evaluation/return-std          | 26.212708  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46175      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4937.278   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 206.17354  |
| Q-std                          | 145.02652  |
| Q_loss                         | 113.6793   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 541        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000283   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000539   |
| times/evaluation_paths         | 36.2       |
| times/timestep_after_hook      | 0.00409    |
| times/timestep_before_hook     | 0.00881    |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 542000     |
| train-steps                    | 542000     |
| training/Q/q1_loss             | 99.58389   |
| training/sac_pi/alpha          | 0.1708209  |
| training/sac_pi/alpha_loss     | 0.03512381 |
| training/sac_pi/logp_pi        | 4.3761435  |
| training/sac_pi/pi_entropy     | 3.3276393  |
| training/sac_pi/pi_global_norm | 1.87059    |
| training/sac_pi/policy_loss    | -219.44072 |
| training/sac_pi/std            | 0.48026428 |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 204.7138   |
| training/sac_Q/q2              | 207.43811  |
| training/sac_Q/q2_loss         | 100.84913  |
| training/sac_Q/q_global_norm   | 215.92883  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16968839   |
| epoch                          | 542          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5031.1167    |
| evaluation/return-max          | 5079.125     |
| evaluation/return-min          | 4960.714     |
| evaluation/return-std          | 39.108326    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.09         |
| model/origin_ret               | 85.8         |
| model/penalty_ret              | 81           |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46455        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5031.1167    |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 203.74887    |
| Q-std                          | 131.59946    |
| Q_loss                         | 86.902145    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 542          |
| times/epoch_after_hook         | 1.96e-06     |
| times/epoch_before_hook        | 0.000144     |
| times/epoch_rollout_model      | 499          |
| times/evaluation_metrics       | 0.000611     |
| times/evaluation_paths         | 35.4         |
| times/timestep_after_hook      | 0.00406      |
| times/timestep_before_hook     | 0.00846      |
| times/train                    | 60.5         |
| timestep                       | 1000         |
| timesteps_total                | 543000       |
| train-steps                    | 543000       |
| training/Q/q1_loss             | 81.407166    |
| training/sac_pi/alpha          | 0.16964139   |
| training/sac_pi/alpha_loss     | -0.027753882 |
| training/sac_pi/logp_pi        | 4.286174     |
| training/sac_pi/pi_entropy     | 3.4054081    |
| training/sac_pi/pi_global_norm | 2.020859     |
| training/sac_pi/policy_loss    | -223.7062    |
| training/sac_pi/std            | 0.49319676   |
| training/sac_pi/valid_num      | 4943.0       |
| training/sac_Q/q1              | 212.16731    |
| training/sac_Q/q2              | 211.7522     |
| training/sac_Q/q2_loss         | 81.14866     |
| training/sac_Q/q_global_norm   | 235.95926    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17073928  |
| epoch                          | 543         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4892.8203   |
| evaluation/return-max          | 4905.965    |
| evaluation/return-min          | 4883.8506   |
| evaluation/return-std          | 6.9444065   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46330       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4892.8203   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 209.60689   |
| Q-std                          | 104.73637   |
| Q_loss                         | 103.01364   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 543         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000602    |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.00413     |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 61.5        |
| timestep                       | 1000        |
| timesteps_total                | 544000      |
| train-steps                    | 544000      |
| training/Q/q1_loss             | 86.89123    |
| training/sac_pi/alpha          | 0.17073472  |
| training/sac_pi/alpha_loss     | -0.08689158 |
| training/sac_pi/logp_pi        | 4.1209373   |
| training/sac_pi/pi_entropy     | 3.2623715   |
| training/sac_pi/pi_global_norm | 1.6913782   |
| training/sac_pi/policy_loss    | -227.09802  |
| training/sac_pi/std            | 0.47266847  |
| training/sac_pi/valid_num      | 4999.0      |
| training/sac_Q/q1              | 218.55899   |
| training/sac_Q/q2              | 217.2166    |
| training/sac_Q/q2_loss         | 87.4642     |
| training/sac_Q/q_global_norm   | 179.00267   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1691483  |
| epoch                          | 544        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5012.443   |
| evaluation/return-max          | 5065.758   |
| evaluation/return-min          | 4946.695   |
| evaluation/return-std          | 44.92623   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46162      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5012.443   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 195.09714  |
| Q-std                          | 137.01149  |
| Q_loss                         | 111.94611  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 544        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000139   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000607   |
| times/evaluation_paths         | 37.3       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.00874    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 545000     |
| train-steps                    | 545000     |
| training/Q/q1_loss             | 94.91307   |
| training/sac_pi/alpha          | 0.16912043 |
| training/sac_pi/alpha_loss     | 0.41724148 |
| training/sac_pi/logp_pi        | 4.5266294  |
| training/sac_pi/pi_entropy     | 3.44141    |
| training/sac_pi/pi_global_norm | 1.378206   |
| training/sac_pi/policy_loss    | -214.11761 |
| training/sac_pi/std            | 0.48984006 |
| training/sac_pi/valid_num      | 4927.0     |
| training/sac_Q/q1              | 202.66713  |
| training/sac_Q/q2              | 201.77922  |
| training/sac_Q/q2_loss         | 94.606224  |
| training/sac_Q/q_global_norm   | 213.0096   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17477037  |
| epoch                          | 545         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4917.383    |
| evaluation/return-max          | 4966.96     |
| evaluation/return-min          | 4866.5615   |
| evaluation/return-std          | 32.873615   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46319       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4917.383    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 208.42065   |
| Q-std                          | 130.98317   |
| Q_loss                         | 107.03886   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 545         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000337    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.00054     |
| times/evaluation_paths         | 37.3        |
| times/timestep_after_hook      | 0.00418     |
| times/timestep_before_hook     | 0.00855     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 546000      |
| train-steps                    | 546000      |
| training/Q/q1_loss             | 92.38173    |
| training/sac_pi/alpha          | 0.17476113  |
| training/sac_pi/alpha_loss     | -0.11662542 |
| training/sac_pi/logp_pi        | 3.9079807   |
| training/sac_pi/pi_entropy     | 3.6276023   |
| training/sac_pi/pi_global_norm | 1.8659449   |
| training/sac_pi/policy_loss    | -211.20078  |
| training/sac_pi/std            | 0.5132441   |
| training/sac_pi/valid_num      | 4964.0      |
| training/sac_Q/q1              | 203.65956   |
| training/sac_Q/q2              | 202.95728   |
| training/sac_Q/q2_loss         | 91.751045   |
| training/sac_Q/q_global_norm   | 228.45634   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17353135  |
| epoch                          | 546         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4971.4033   |
| evaluation/return-max          | 5091.059    |
| evaluation/return-min          | 4889.916    |
| evaluation/return-std          | 54.022064   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46236       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4971.4033   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 214.50137   |
| Q-std                          | 117.62648   |
| Q_loss                         | 92.028175   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 546         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 506         |
| times/evaluation_metrics       | 0.000537    |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.00408     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 60.2        |
| timestep                       | 1000        |
| timesteps_total                | 547000      |
| train-steps                    | 547000      |
| training/Q/q1_loss             | 99.73147    |
| training/sac_pi/alpha          | 0.17352082  |
| training/sac_pi/alpha_loss     | -0.08716786 |
| training/sac_pi/logp_pi        | 4.038163    |
| training/sac_pi/pi_entropy     | 3.450695    |
| training/sac_pi/pi_global_norm | 1.9903324   |
| training/sac_pi/policy_loss    | -221.0165   |
| training/sac_pi/std            | 0.4856818   |
| training/sac_pi/valid_num      | 5002.0      |
| training/sac_Q/q1              | 214.37598   |
| training/sac_Q/q2              | 212.43637   |
| training/sac_Q/q2_loss         | 100.85827   |
| training/sac_Q/q_global_norm   | 293.5727    |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17393821   |
| epoch                          | 547          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4832.5244    |
| evaluation/return-max          | 4953.722     |
| evaluation/return-min          | 4726.785     |
| evaluation/return-std          | 55.713524    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.04         |
| model/origin_ret               | 84.9         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46221        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4832.5244    |
| perf/NormalizedReturn          | 1.05         |
| Q-avg                          | 210.60336    |
| Q-std                          | 113.351295   |
| Q_loss                         | 103.27025    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 547          |
| times/epoch_after_hook         | 1.76e-06     |
| times/epoch_before_hook        | 0.000136     |
| times/epoch_rollout_model      | 494          |
| times/evaluation_metrics       | 0.000575     |
| times/evaluation_paths         | 34.7         |
| times/timestep_after_hook      | 0.00405      |
| times/timestep_before_hook     | 0.00839      |
| times/train                    | 61.6         |
| timestep                       | 1000         |
| timesteps_total                | 548000       |
| train-steps                    | 548000       |
| training/Q/q1_loss             | 101.2151     |
| training/sac_pi/alpha          | 0.17396046   |
| training/sac_pi/alpha_loss     | -0.055056576 |
| training/sac_pi/logp_pi        | 4.2186027    |
| training/sac_pi/pi_entropy     | 3.3271098    |
| training/sac_pi/pi_global_norm | 1.8709155    |
| training/sac_pi/policy_loss    | -229.95946   |
| training/sac_pi/std            | 0.48442328   |
| training/sac_pi/valid_num      | 5004.0       |
| training/sac_Q/q1              | 224.00725    |
| training/sac_Q/q2              | 223.71172    |
| training/sac_Q/q2_loss         | 101.80874    |
| training/sac_Q/q_global_norm   | 196.45894    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16805927 |
| epoch                          | 548        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4961.089   |
| evaluation/return-max          | 5031.7285  |
| evaluation/return-min          | 4862.625   |
| evaluation/return-std          | 50.248226  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46309      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4961.089   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 213.36191  |
| Q-std                          | 108.517555 |
| Q_loss                         | 93.80015   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 548        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000639   |
| times/evaluation_paths         | 34.7       |
| times/timestep_after_hook      | 0.00415    |
| times/timestep_before_hook     | 0.00854    |
| times/train                    | 64.2       |
| timestep                       | 1000       |
| timesteps_total                | 549000     |
| train-steps                    | 549000     |
| training/Q/q1_loss             | 124.723434 |
| training/sac_pi/alpha          | 0.16807157 |
| training/sac_pi/alpha_loss     | 0.21110608 |
| training/sac_pi/logp_pi        | 4.476318   |
| training/sac_pi/pi_entropy     | 3.306825   |
| training/sac_pi/pi_global_norm | 1.5155867  |
| training/sac_pi/policy_loss    | -216.89336 |
| training/sac_pi/std            | 0.47837612 |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 209.5601   |
| training/sac_Q/q2              | 209.26724  |
| training/sac_Q/q2_loss         | 123.840256 |
| training/sac_Q/q_global_norm   | 276.35092  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1688209  |
| epoch                          | 549        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5265.2715  |
| evaluation/return-max          | 5303.6553  |
| evaluation/return-min          | 5209.759   |
| evaluation/return-std          | 26.44541   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46285      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5265.2715  |
| perf/NormalizedReturn          | 1.15       |
| Q-avg                          | 221.01285  |
| Q-std                          | 97.2001    |
| Q_loss                         | 94.81266   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 549        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000319   |
| times/epoch_rollout_model      | 511        |
| times/evaluation_metrics       | 0.000627   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00432    |
| times/timestep_before_hook     | 0.00861    |
| times/train                    | 63.2       |
| timestep                       | 1000       |
| timesteps_total                | 550000     |
| train-steps                    | 550000     |
| training/Q/q1_loss             | 120.58016  |
| training/sac_pi/alpha          | 0.16881339 |
| training/sac_pi/alpha_loss     | 0.28586826 |
| training/sac_pi/logp_pi        | 4.8680735  |
| training/sac_pi/pi_entropy     | 3.4791007  |
| training/sac_pi/pi_global_norm | 1.92588    |
| training/sac_pi/policy_loss    | -217.19418 |
| training/sac_pi/std            | 0.5048524  |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 206.24478  |
| training/sac_Q/q2              | 204.37521  |
| training/sac_Q/q2_loss         | 120.04447  |
| training/sac_Q/q_global_norm   | 229.72328  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16079226  |
| epoch                          | 550         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5081.327    |
| evaluation/return-max          | 5128.8174   |
| evaluation/return-min          | 5022.617    |
| evaluation/return-std          | 26.361437   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46090       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5081.327    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 216.90999   |
| Q-std                          | 116.048325  |
| Q_loss                         | 93.28242    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 550         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000114    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000561    |
| times/evaluation_paths         | 35.4        |
| times/timestep_after_hook      | 0.00421     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 60.1        |
| timestep                       | 1000        |
| timesteps_total                | 551000      |
| train-steps                    | 551000      |
| training/Q/q1_loss             | 98.84598    |
| training/sac_pi/alpha          | 0.16082247  |
| training/sac_pi/alpha_loss     | -0.19608489 |
| training/sac_pi/logp_pi        | 4.977412    |
| training/sac_pi/pi_entropy     | 3.113295    |
| training/sac_pi/pi_global_norm | 1.7107253   |
| training/sac_pi/policy_loss    | -211.232    |
| training/sac_pi/std            | 0.4721394   |
| training/sac_pi/valid_num      | 4919.0      |
| training/sac_Q/q1              | 198.58292   |
| training/sac_Q/q2              | 196.63152   |
| training/sac_Q/q2_loss         | 98.123886   |
| training/sac_Q/q_global_norm   | 279.78363   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16714264  |
| epoch                          | 551         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5013.8975   |
| evaluation/return-max          | 5060.5117   |
| evaluation/return-min          | 4952.302    |
| evaluation/return-std          | 39.026722   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46484       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5013.8975   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 223.29553   |
| Q-std                          | 101.767334  |
| Q_loss                         | 94.7695     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 551         |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 0.000142    |
| times/epoch_rollout_model      | 506         |
| times/evaluation_metrics       | 0.000626    |
| times/evaluation_paths         | 34.6        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.00839     |
| times/train                    | 62.1        |
| timestep                       | 1000        |
| timesteps_total                | 552000      |
| train-steps                    | 552000      |
| training/Q/q1_loss             | 90.02409    |
| training/sac_pi/alpha          | 0.16714974  |
| training/sac_pi/alpha_loss     | -0.48045924 |
| training/sac_pi/logp_pi        | 4.021145    |
| training/sac_pi/pi_entropy     | 3.4488564   |
| training/sac_pi/pi_global_norm | 1.5726211   |
| training/sac_pi/policy_loss    | -220.41074  |
| training/sac_pi/std            | 0.5021781   |
| training/sac_pi/valid_num      | 5006.0      |
| training/sac_Q/q1              | 211.74475   |
| training/sac_Q/q2              | 211.48543   |
| training/sac_Q/q2_loss         | 88.65415    |
| training/sac_Q/q_global_norm   | 187.62956   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1704946   |
| epoch                          | 552         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4998.5747   |
| evaluation/return-max          | 5058.5044   |
| evaluation/return-min          | 4951.586    |
| evaluation/return-std          | 36.57463    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46307       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4998.5747   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 208.36792   |
| Q-std                          | 109.238174  |
| Q_loss                         | 106.94451   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 552         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 509         |
| times/evaluation_metrics       | 0.000593    |
| times/evaluation_paths         | 36.1        |
| times/timestep_after_hook      | 0.00422     |
| times/timestep_before_hook     | 0.0087      |
| times/train                    | 63.8        |
| timestep                       | 1000        |
| timesteps_total                | 553000      |
| train-steps                    | 553000      |
| training/Q/q1_loss             | 85.90039    |
| training/sac_pi/alpha          | 0.17052628  |
| training/sac_pi/alpha_loss     | -0.20455901 |
| training/sac_pi/logp_pi        | 4.740131    |
| training/sac_pi/pi_entropy     | 3.3295746   |
| training/sac_pi/pi_global_norm | 1.5988598   |
| training/sac_pi/policy_loss    | -218.02863  |
| training/sac_pi/std            | 0.49024016  |
| training/sac_pi/valid_num      | 4964.0      |
| training/sac_Q/q1              | 208.281     |
| training/sac_Q/q2              | 205.06831   |
| training/sac_Q/q2_loss         | 85.75538    |
| training/sac_Q/q_global_norm   | 250.67157   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17563412 |
| epoch                          | 553        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4372.9854  |
| evaluation/return-max          | 4483.0312  |
| evaluation/return-min          | 4208.5522  |
| evaluation/return-std          | 76.39311   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46212      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4372.9854  |
| perf/NormalizedReturn          | 0.952      |
| Q-avg                          | 214.29306  |
| Q-std                          | 89.370605  |
| Q_loss                         | 104.99672  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 553        |
| times/epoch_after_hook         | 4.38e-06   |
| times/epoch_before_hook        | 0.00029    |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000589   |
| times/evaluation_paths         | 34         |
| times/timestep_after_hook      | 0.00411    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 554000     |
| train-steps                    | 554000     |
| training/Q/q1_loss             | 100.59969  |
| training/sac_pi/alpha          | 0.17560276 |
| training/sac_pi/alpha_loss     | 0.18617992 |
| training/sac_pi/logp_pi        | 4.757451   |
| training/sac_pi/pi_entropy     | 3.3608055  |
| training/sac_pi/pi_global_norm | 1.5914885  |
| training/sac_pi/policy_loss    | -216.17818 |
| training/sac_pi/std            | 0.48851216 |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 203.76492  |
| training/sac_Q/q2              | 202.80672  |
| training/sac_Q/q2_loss         | 99.424194  |
| training/sac_Q/q_global_norm   | 261.99854  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17528982 |
| epoch                          | 554        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5050.5454  |
| evaluation/return-max          | 5109.5728  |
| evaluation/return-min          | 4931.047   |
| evaluation/return-std          | 53.00518   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.92       |
| model/origin_ret               | 83.3       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46120      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5050.5454  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 206.20236  |
| Q-std                          | 124.135345 |
| Q_loss                         | 112.62082  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 554        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000118   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000534   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 555000     |
| train-steps                    | 555000     |
| training/Q/q1_loss             | 123.16658  |
| training/sac_pi/alpha          | 0.17530827 |
| training/sac_pi/alpha_loss     | 0.19828412 |
| training/sac_pi/logp_pi        | 4.218553   |
| training/sac_pi/pi_entropy     | 3.4887886  |
| training/sac_pi/pi_global_norm | 1.6802979  |
| training/sac_pi/policy_loss    | -217.34245 |
| training/sac_pi/std            | 0.49369958 |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 211.06027  |
| training/sac_Q/q2              | 209.9067   |
| training/sac_Q/q2_loss         | 122.12284  |
| training/sac_Q/q_global_norm   | 357.5387   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17641668 |
| epoch                          | 555        |
| evaluation/episode-length-avg  | 939        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 390        |
| evaluation/episode-length-std  | 183        |
| evaluation/return-average      | 4451.111   |
| evaluation/return-max          | 4852.848   |
| evaluation/return-min          | 1424.2869  |
| evaluation/return-std          | 1010.17554 |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46292      |
| perf/AverageLength             | 939        |
| perf/AverageReturn             | 4451.111   |
| perf/NormalizedReturn          | 0.969      |
| Q-avg                          | 216.71753  |
| Q-std                          | 87.4684    |
| Q_loss                         | 94.88515   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 555        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000107   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000569   |
| times/evaluation_paths         | 34.7       |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.00851    |
| times/train                    | 63.4       |
| timestep                       | 1000       |
| timesteps_total                | 556000     |
| train-steps                    | 556000     |
| training/Q/q1_loss             | 114.432365 |
| training/sac_pi/alpha          | 0.1764195  |
| training/sac_pi/alpha_loss     | 0.5130646  |
| training/sac_pi/logp_pi        | 4.3279138  |
| training/sac_pi/pi_entropy     | 3.436103   |
| training/sac_pi/pi_global_norm | 1.711882   |
| training/sac_pi/policy_loss    | -221.43884 |
| training/sac_pi/std            | 0.48447582 |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 211.123    |
| training/sac_Q/q2              | 211.01163  |
| training/sac_Q/q2_loss         | 114.43609  |
| training/sac_Q/q_global_norm   | 307.77444  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17327303 |
| epoch                          | 556        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4770.497   |
| evaluation/return-max          | 4838.8975  |
| evaluation/return-min          | 4674.4907  |
| evaluation/return-std          | 47.146297  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46173      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4770.497   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 203.5457   |
| Q-std                          | 127.414246 |
| Q_loss                         | 103.97039  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 556        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000153   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.00051    |
| times/evaluation_paths         | 34.4       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 557000     |
| train-steps                    | 557000     |
| training/Q/q1_loss             | 117.205376 |
| training/sac_pi/alpha          | 0.17328101 |
| training/sac_pi/alpha_loss     | 0.09752064 |
| training/sac_pi/logp_pi        | 4.3631716  |
| training/sac_pi/pi_entropy     | 3.609084   |
| training/sac_pi/pi_global_norm | 1.7220404  |
| training/sac_pi/policy_loss    | -211.74794 |
| training/sac_pi/std            | 0.5144168  |
| training/sac_pi/valid_num      | 4926.0     |
| training/sac_Q/q1              | 201.48708  |
| training/sac_Q/q2              | 200.08646  |
| training/sac_Q/q2_loss         | 116.6591   |
| training/sac_Q/q_global_norm   | 324.95193  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17222726  |
| epoch                          | 557         |
| evaluation/episode-length-avg  | 874         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 367         |
| evaluation/episode-length-std  | 251         |
| evaluation/return-average      | 4201.3477   |
| evaluation/return-max          | 4981.5923   |
| evaluation/return-min          | 1408.6453   |
| evaluation/return-std          | 1387.4077   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46311       |
| perf/AverageLength             | 874         |
| perf/AverageReturn             | 4201.3477   |
| perf/NormalizedReturn          | 0.915       |
| Q-avg                          | 215.12894   |
| Q-std                          | 96.78691    |
| Q_loss                         | 95.92189    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 557         |
| times/epoch_after_hook         | 2.11e-06    |
| times/epoch_before_hook        | 0.000305    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000524    |
| times/evaluation_paths         | 31.9        |
| times/timestep_after_hook      | 0.00413     |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 558000      |
| train-steps                    | 558000      |
| training/Q/q1_loss             | 111.02503   |
| training/sac_pi/alpha          | 0.17223872  |
| training/sac_pi/alpha_loss     | 0.051881075 |
| training/sac_pi/logp_pi        | 4.1496487   |
| training/sac_pi/pi_entropy     | 3.4637775   |
| training/sac_pi/pi_global_norm | 1.7007406   |
| training/sac_pi/policy_loss    | -220.77673  |
| training/sac_pi/std            | 0.51809186  |
| training/sac_pi/valid_num      | 5013.0      |
| training/sac_Q/q1              | 215.7117    |
| training/sac_Q/q2              | 214.59004   |
| training/sac_Q/q2_loss         | 110.42905   |
| training/sac_Q/q_global_norm   | 359.8358    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16944341  |
| epoch                          | 558         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5008.532    |
| evaluation/return-max          | 5061.9087   |
| evaluation/return-min          | 4973.2188   |
| evaluation/return-std          | 29.370884   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46251       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5008.532    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 212.54016   |
| Q-std                          | 114.19802   |
| Q_loss                         | 90.73025    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 558         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000153    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000574    |
| times/evaluation_paths         | 33.9        |
| times/timestep_after_hook      | 0.00408     |
| times/timestep_before_hook     | 0.00858     |
| times/train                    | 62          |
| timestep                       | 1000        |
| timesteps_total                | 559000      |
| train-steps                    | 559000      |
| training/Q/q1_loss             | 118.23639   |
| training/sac_pi/alpha          | 0.16945589  |
| training/sac_pi/alpha_loss     | -0.15929061 |
| training/sac_pi/logp_pi        | 4.316367    |
| training/sac_pi/pi_entropy     | 3.6081314   |
| training/sac_pi/pi_global_norm | 1.563533    |
| training/sac_pi/policy_loss    | -214.24406  |
| training/sac_pi/std            | 0.51908773  |
| training/sac_pi/valid_num      | 4905.0      |
| training/sac_Q/q1              | 199.14493   |
| training/sac_Q/q2              | 198.45016   |
| training/sac_Q/q2_loss         | 119.18188   |
| training/sac_Q/q_global_norm   | 292.96353   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16992462  |
| epoch                          | 559         |
| evaluation/episode-length-avg  | 922         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 225         |
| evaluation/episode-length-std  | 232         |
| evaluation/return-average      | 4320.0454   |
| evaluation/return-max          | 4789.921    |
| evaluation/return-min          | 651.3583    |
| evaluation/return-std          | 1223.4415   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46321       |
| perf/AverageLength             | 922         |
| perf/AverageReturn             | 4320.0454   |
| perf/NormalizedReturn          | 0.941       |
| Q-avg                          | 212.0104    |
| Q-std                          | 124.71778   |
| Q_loss                         | 112.17425   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 559         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.0005      |
| times/evaluation_paths         | 30.7        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 58.6        |
| timestep                       | 1000        |
| timesteps_total                | 560000      |
| train-steps                    | 560000      |
| training/Q/q1_loss             | 103.55103   |
| training/sac_pi/alpha          | 0.16998751  |
| training/sac_pi/alpha_loss     | -0.17496389 |
| training/sac_pi/logp_pi        | 4.1727085   |
| training/sac_pi/pi_entropy     | 3.4917934   |
| training/sac_pi/pi_global_norm | 1.9321672   |
| training/sac_pi/policy_loss    | -218.63792  |
| training/sac_pi/std            | 0.50989234  |
| training/sac_pi/valid_num      | 4963.0      |
| training/sac_Q/q1              | 207.02975   |
| training/sac_Q/q2              | 205.0207    |
| training/sac_Q/q2_loss         | 102.526146  |
| training/sac_Q/q_global_norm   | 287.95422   |
---------------------------------------------------------------------------------
[WARN] 560 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.17406033 |
| epoch                          | 560        |
| evaluation/episode-length-avg  | 935        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 354        |
| evaluation/episode-length-std  | 194        |
| evaluation/return-average      | 4335.325   |
| evaluation/return-max          | 4853.213   |
| evaluation/return-min          | 1293.3846  |
| evaluation/return-std          | 1035.3978  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46305      |
| perf/AverageLength             | 935        |
| perf/AverageReturn             | 4335.325   |
| perf/NormalizedReturn          | 0.944      |
| Q-avg                          | 212.52475  |
| Q-std                          | 105.69575  |
| Q_loss                         | 95.456665  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 560        |
| times/epoch_after_hook         | 1.99e-06   |
| times/epoch_before_hook        | 0.000145   |
| times/epoch_rollout_model      | 512        |
| times/evaluation_metrics       | 0.000686   |
| times/evaluation_paths         | 33.8       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 561000     |
| train-steps                    | 561000     |
| training/Q/q1_loss             | 104.11373  |
| training/sac_pi/alpha          | 0.17403467 |
| training/sac_pi/alpha_loss     | 0.5150521  |
| training/sac_pi/logp_pi        | 4.200624   |
| training/sac_pi/pi_entropy     | 3.3276992  |
| training/sac_pi/pi_global_norm | 1.7680631  |
| training/sac_pi/policy_loss    | -215.5759  |
| training/sac_pi/std            | 0.46364492 |
| training/sac_pi/valid_num      | 5007.0     |
| training/sac_Q/q1              | 208.90536  |
| training/sac_Q/q2              | 208.49097  |
| training/sac_Q/q2_loss         | 104.05127  |
| training/sac_Q/q_global_norm   | 228.63948  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17214736 |
| epoch                          | 561        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5034.623   |
| evaluation/return-max          | 5061.8555  |
| evaluation/return-min          | 4996.4785  |
| evaluation/return-std          | 19.665384  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46166      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5034.623   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 214.40146  |
| Q-std                          | 115.39328  |
| Q_loss                         | 97.41423   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 561        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000323   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.00052    |
| times/evaluation_paths         | 34.2       |
| times/timestep_after_hook      | 0.00419    |
| times/timestep_before_hook     | 0.00865    |
| times/train                    | 62.8       |
| timestep                       | 1000       |
| timesteps_total                | 562000     |
| train-steps                    | 562000     |
| training/Q/q1_loss             | 99.88401   |
| training/sac_pi/alpha          | 0.17211919 |
| training/sac_pi/alpha_loss     | 0.36571878 |
| training/sac_pi/logp_pi        | 4.1848865  |
| training/sac_pi/pi_entropy     | 3.4499538  |
| training/sac_pi/pi_global_norm | 2.7833173  |
| training/sac_pi/policy_loss    | -224.16571 |
| training/sac_pi/std            | 0.4990778  |
| training/sac_pi/valid_num      | 4913.0     |
| training/sac_Q/q1              | 213.38362  |
| training/sac_Q/q2              | 212.44563  |
| training/sac_Q/q2_loss         | 99.12754   |
| training/sac_Q/q_global_norm   | 200.5819   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16853638   |
| epoch                          | 562          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5077.4814    |
| evaluation/return-max          | 5138.0767    |
| evaluation/return-min          | 5014.7266    |
| evaluation/return-std          | 43.421448    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.05         |
| model/origin_ret               | 86           |
| model/penalty_ret              | 81.7         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46197        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5077.4814    |
| perf/NormalizedReturn          | 1.11         |
| Q-avg                          | 210.54414    |
| Q-std                          | 101.16779    |
| Q_loss                         | 106.655876   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 562          |
| times/epoch_after_hook         | 3.38e-06     |
| times/epoch_before_hook        | 0.000127     |
| times/epoch_rollout_model      | 503          |
| times/evaluation_metrics       | 0.000589     |
| times/evaluation_paths         | 35           |
| times/timestep_after_hook      | 0.00401      |
| times/timestep_before_hook     | 0.00832      |
| times/train                    | 60           |
| timestep                       | 1000         |
| timesteps_total                | 563000       |
| train-steps                    | 563000       |
| training/Q/q1_loss             | 116.49191    |
| training/sac_pi/alpha          | 0.16855267   |
| training/sac_pi/alpha_loss     | -0.025280984 |
| training/sac_pi/logp_pi        | 4.9147387    |
| training/sac_pi/pi_entropy     | 3.235681     |
| training/sac_pi/pi_global_norm | 2.0057645    |
| training/sac_pi/policy_loss    | -215.43765   |
| training/sac_pi/std            | 0.4813743    |
| training/sac_pi/valid_num      | 4940.0       |
| training/sac_Q/q1              | 204.15009    |
| training/sac_Q/q2              | 202.62723    |
| training/sac_Q/q2_loss         | 116.67578    |
| training/sac_Q/q_global_norm   | 339.55243    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1692502  |
| epoch                          | 563        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4902.9     |
| evaluation/return-max          | 4941.554   |
| evaluation/return-min          | 4848.352   |
| evaluation/return-std          | 23.676033  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46166      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4902.9     |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 209.4842   |
| Q-std                          | 106.60375  |
| Q_loss                         | 107.456566 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 563        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000553   |
| times/evaluation_paths         | 35.3       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00859    |
| times/train                    | 63.2       |
| timestep                       | 1000       |
| timesteps_total                | 564000     |
| train-steps                    | 564000     |
| training/Q/q1_loss             | 88.86562   |
| training/sac_pi/alpha          | 0.1692035  |
| training/sac_pi/alpha_loss     | 0.2251037  |
| training/sac_pi/logp_pi        | 3.9823308  |
| training/sac_pi/pi_entropy     | 3.3899179  |
| training/sac_pi/pi_global_norm | 1.9147537  |
| training/sac_pi/policy_loss    | -215.7983  |
| training/sac_pi/std            | 0.4830337  |
| training/sac_pi/valid_num      | 5006.0     |
| training/sac_Q/q1              | 209.90201  |
| training/sac_Q/q2              | 209.18266  |
| training/sac_Q/q2_loss         | 89.1551    |
| training/sac_Q/q_global_norm   | 207.52415  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17022629  |
| epoch                          | 564         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5079.383    |
| evaluation/return-max          | 5155.1807   |
| evaluation/return-min          | 4953.1816   |
| evaluation/return-std          | 59.419403   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46244       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5079.383    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 212.84319   |
| Q-std                          | 106.80691   |
| Q_loss                         | 103.73432   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 564         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000636    |
| times/evaluation_paths         | 36.5        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.0088      |
| times/train                    | 60.3        |
| timestep                       | 1000        |
| timesteps_total                | 565000      |
| train-steps                    | 565000      |
| training/Q/q1_loss             | 108.40553   |
| training/sac_pi/alpha          | 0.17024633  |
| training/sac_pi/alpha_loss     | -0.11446203 |
| training/sac_pi/logp_pi        | 4.538692    |
| training/sac_pi/pi_entropy     | 3.3842773   |
| training/sac_pi/pi_global_norm | 1.5103681   |
| training/sac_pi/policy_loss    | -214.02492  |
| training/sac_pi/std            | 0.5044294   |
| training/sac_pi/valid_num      | 4995.0      |
| training/sac_Q/q1              | 204.19846   |
| training/sac_Q/q2              | 203.43369   |
| training/sac_Q/q2_loss         | 108.20345   |
| training/sac_Q/q_global_norm   | 312.8962    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16761464 |
| epoch                          | 565        |
| evaluation/episode-length-avg  | 890        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 317        |
| evaluation/episode-length-std  | 228        |
| evaluation/return-average      | 4109.1523  |
| evaluation/return-max          | 4817.711   |
| evaluation/return-min          | 1135.9141  |
| evaluation/return-std          | 1191.1047  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46260      |
| perf/AverageLength             | 890        |
| perf/AverageReturn             | 4109.1523  |
| perf/NormalizedReturn          | 0.895      |
| Q-avg                          | 216.91084  |
| Q-std                          | 113.05939  |
| Q_loss                         | 98.35094   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 565        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.00031    |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000504   |
| times/evaluation_paths         | 33.8       |
| times/timestep_after_hook      | 0.00422    |
| times/timestep_before_hook     | 0.00853    |
| times/train                    | 71.9       |
| timestep                       | 1000       |
| timesteps_total                | 566000     |
| train-steps                    | 566000     |
| training/Q/q1_loss             | 98.26456   |
| training/sac_pi/alpha          | 0.167613   |
| training/sac_pi/alpha_loss     | -0.1258649 |
| training/sac_pi/logp_pi        | 3.824648   |
| training/sac_pi/pi_entropy     | 3.1670938  |
| training/sac_pi/pi_global_norm | 1.4657551  |
| training/sac_pi/policy_loss    | -226.53581 |
| training/sac_pi/std            | 0.45180437 |
| training/sac_pi/valid_num      | 5022.0     |
| training/sac_Q/q1              | 220.78647  |
| training/sac_Q/q2              | 220.7476   |
| training/sac_Q/q2_loss         | 97.899956  |
| training/sac_Q/q_global_norm   | 222.37897  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17196192   |
| epoch                          | 566          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4964.9316    |
| evaluation/return-max          | 5002.419     |
| evaluation/return-min          | 4936.504     |
| evaluation/return-std          | 17.794006    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.99         |
| model/origin_ret               | 83.4         |
| model/penalty_ret              | 79.7         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46299        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4964.9316    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 200.59322    |
| Q-std                          | 121.10737    |
| Q_loss                         | 134.84868    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 566          |
| times/epoch_after_hook         | 1.67e-06     |
| times/epoch_before_hook        | 0.000125     |
| times/epoch_rollout_model      | 502          |
| times/evaluation_metrics       | 0.000501     |
| times/evaluation_paths         | 39.4         |
| times/timestep_after_hook      | 0.00421      |
| times/timestep_before_hook     | 0.00885      |
| times/train                    | 71.3         |
| timestep                       | 1000         |
| timesteps_total                | 567000       |
| train-steps                    | 567000       |
| training/Q/q1_loss             | 102.08927    |
| training/sac_pi/alpha          | 0.17193763   |
| training/sac_pi/alpha_loss     | -0.013043691 |
| training/sac_pi/logp_pi        | 3.8686652    |
| training/sac_pi/pi_entropy     | 3.4971695    |
| training/sac_pi/pi_global_norm | 1.5460207    |
| training/sac_pi/policy_loss    | -219.83156   |
| training/sac_pi/std            | 0.472752     |
| training/sac_pi/valid_num      | 4969.0       |
| training/sac_Q/q1              | 212.95552    |
| training/sac_Q/q2              | 212.24442    |
| training/sac_Q/q2_loss         | 101.09866    |
| training/sac_Q/q_global_norm   | 269.2838     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17136534 |
| epoch                          | 567        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5155.6514  |
| evaluation/return-max          | 5200.2656  |
| evaluation/return-min          | 5102.54    |
| evaluation/return-std          | 27.390905  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 87         |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46144      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5155.6514  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 217.65799  |
| Q-std                          | 103.69904  |
| Q_loss                         | 95.484795  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 567        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000119   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000663   |
| times/evaluation_paths         | 44.9       |
| times/timestep_after_hook      | 0.00413    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 66         |
| timestep                       | 1000       |
| timesteps_total                | 568000     |
| train-steps                    | 568000     |
| training/Q/q1_loss             | 107.07895  |
| training/sac_pi/alpha          | 0.17132634 |
| training/sac_pi/alpha_loss     | 0.22958921 |
| training/sac_pi/logp_pi        | 4.8789086  |
| training/sac_pi/pi_entropy     | 3.417724   |
| training/sac_pi/pi_global_norm | 1.6959237  |
| training/sac_pi/policy_loss    | -210.85258 |
| training/sac_pi/std            | 0.5005596  |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 197.42847  |
| training/sac_Q/q2              | 196.4893   |
| training/sac_Q/q2_loss         | 106.66902  |
| training/sac_Q/q_global_norm   | 214.11993  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16706695 |
| epoch                          | 568        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4912.9346  |
| evaluation/return-max          | 4958.6504  |
| evaluation/return-min          | 4843.3027  |
| evaluation/return-std          | 37.905304  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46324      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4912.9346  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 204.91438  |
| Q-std                          | 109.711365 |
| Q_loss                         | 101.68398  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 568        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000542   |
| times/evaluation_paths         | 38.4       |
| times/timestep_after_hook      | 0.00412    |
| times/timestep_before_hook     | 0.0088     |
| times/train                    | 72.9       |
| timestep                       | 1000       |
| timesteps_total                | 569000     |
| train-steps                    | 569000     |
| training/Q/q1_loss             | 94.7727    |
| training/sac_pi/alpha          | 0.1670915  |
| training/sac_pi/alpha_loss     | 0.15852891 |
| training/sac_pi/logp_pi        | 4.872068   |
| training/sac_pi/pi_entropy     | 3.4256158  |
| training/sac_pi/pi_global_norm | 1.5580813  |
| training/sac_pi/policy_loss    | -211.51637 |
| training/sac_pi/std            | 0.5085486  |
| training/sac_pi/valid_num      | 4970.0     |
| training/sac_Q/q1              | 201.04565  |
| training/sac_Q/q2              | 198.93764  |
| training/sac_Q/q2_loss         | 94.83417   |
| training/sac_Q/q_global_norm   | 228.20593  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17027342   |
| epoch                          | 569          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4900.9243    |
| evaluation/return-max          | 4956.3643    |
| evaluation/return-min          | 4835.9385    |
| evaluation/return-std          | 35.835373    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.05         |
| model/origin_ret               | 84.9         |
| model/penalty_ret              | 80.5         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46304        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4900.9243    |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 198.88683    |
| Q-std                          | 165.04192    |
| Q_loss                         | 109.99064    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 569          |
| times/epoch_after_hook         | 1.86e-06     |
| times/epoch_before_hook        | 0.000525     |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.000542     |
| times/evaluation_paths         | 37.3         |
| times/timestep_after_hook      | 0.00402      |
| times/timestep_before_hook     | 0.00871      |
| times/train                    | 59.9         |
| timestep                       | 1000         |
| timesteps_total                | 570000       |
| train-steps                    | 570000       |
| training/Q/q1_loss             | 76.88978     |
| training/sac_pi/alpha          | 0.17022309   |
| training/sac_pi/alpha_loss     | -0.001959225 |
| training/sac_pi/logp_pi        | 3.812764     |
| training/sac_pi/pi_entropy     | 3.46283      |
| training/sac_pi/pi_global_norm | 1.3711829    |
| training/sac_pi/policy_loss    | -221.36127   |
| training/sac_pi/std            | 0.4750209    |
| training/sac_pi/valid_num      | 5008.0       |
| training/sac_Q/q1              | 214.50728    |
| training/sac_Q/q2              | 214.13843    |
| training/sac_Q/q2_loss         | 77.47197     |
| training/sac_Q/q_global_norm   | 229.5621     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16851705 |
| epoch                          | 570        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4946.5903  |
| evaluation/return-max          | 5006.071   |
| evaluation/return-min          | 4912.9106  |
| evaluation/return-std          | 33.718754  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 87.6       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46111      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4946.5903  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 210.57324  |
| Q-std                          | 108.65106  |
| Q_loss                         | 102.99868  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 570        |
| times/epoch_after_hook         | 2.11e-06   |
| times/epoch_before_hook        | 0.000143   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000598   |
| times/evaluation_paths         | 34.9       |
| times/timestep_after_hook      | 0.00421    |
| times/timestep_before_hook     | 0.00855    |
| times/train                    | 65.2       |
| timestep                       | 1000       |
| timesteps_total                | 571000     |
| train-steps                    | 571000     |
| training/Q/q1_loss             | 91.777664  |
| training/sac_pi/alpha          | 0.1685595  |
| training/sac_pi/alpha_loss     | -0.2637432 |
| training/sac_pi/logp_pi        | 3.3686757  |
| training/sac_pi/pi_entropy     | 3.3396313  |
| training/sac_pi/pi_global_norm | 1.8097774  |
| training/sac_pi/policy_loss    | -229.4267  |
| training/sac_pi/std            | 0.45434496 |
| training/sac_pi/valid_num      | 5008.0     |
| training/sac_Q/q1              | 224.37509  |
| training/sac_Q/q2              | 224.29077  |
| training/sac_Q/q2_loss         | 91.224045  |
| training/sac_Q/q_global_norm   | 186.84259  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16842403  |
| epoch                          | 571         |
| evaluation/episode-length-avg  | 873         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 356         |
| evaluation/episode-length-std  | 254         |
| evaluation/return-average      | 4316.641    |
| evaluation/return-max          | 5120.994    |
| evaluation/return-min          | 1425.0493   |
| evaluation/return-std          | 1429.9081   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46385       |
| perf/AverageLength             | 873         |
| perf/AverageReturn             | 4316.641    |
| perf/NormalizedReturn          | 0.94        |
| Q-avg                          | 208.7456    |
| Q-std                          | 110.011696  |
| Q_loss                         | 113.76147   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 571         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000574    |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00869     |
| times/train                    | 64.7        |
| timestep                       | 1000        |
| timesteps_total                | 572000      |
| train-steps                    | 572000      |
| training/Q/q1_loss             | 100.058334  |
| training/sac_pi/alpha          | 0.16844513  |
| training/sac_pi/alpha_loss     | -0.16785872 |
| training/sac_pi/logp_pi        | 4.500015    |
| training/sac_pi/pi_entropy     | 3.365792    |
| training/sac_pi/pi_global_norm | 1.4567701   |
| training/sac_pi/policy_loss    | -222.76773  |
| training/sac_pi/std            | 0.4844247   |
| training/sac_pi/valid_num      | 4965.0      |
| training/sac_Q/q1              | 208.62524   |
| training/sac_Q/q2              | 208.57109   |
| training/sac_Q/q2_loss         | 100.31916   |
| training/sac_Q/q_global_norm   | 302.5335    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16673562  |
| epoch                          | 572         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5088.7915   |
| evaluation/return-max          | 5140.0645   |
| evaluation/return-min          | 4978.506    |
| evaluation/return-std          | 43.32492    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46262       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5088.7915   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 204.00793   |
| Q-std                          | 116.12768   |
| Q_loss                         | 128.37866   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 572         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000115    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.00051     |
| times/evaluation_paths         | 35.2        |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.00868     |
| times/train                    | 65.8        |
| timestep                       | 1000        |
| timesteps_total                | 573000      |
| train-steps                    | 573000      |
| training/Q/q1_loss             | 80.619286   |
| training/sac_pi/alpha          | 0.16673583  |
| training/sac_pi/alpha_loss     | -0.34761044 |
| training/sac_pi/logp_pi        | 4.4180956   |
| training/sac_pi/pi_entropy     | 3.5563354   |
| training/sac_pi/pi_global_norm | 1.851514    |
| training/sac_pi/policy_loss    | -217.31578  |
| training/sac_pi/std            | 0.51115006  |
| training/sac_pi/valid_num      | 4908.0      |
| training/sac_Q/q1              | 204.09341   |
| training/sac_Q/q2              | 200.84392   |
| training/sac_Q/q2_loss         | 81.48706    |
| training/sac_Q/q_global_norm   | 230.93915   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16833206  |
| epoch                          | 573         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4920.8584   |
| evaluation/return-max          | 4994.083    |
| evaluation/return-min          | 4850.945    |
| evaluation/return-std          | 37.906044   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46319       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4920.8584   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 217.92819   |
| Q-std                          | 108.11074   |
| Q_loss                         | 81.17774    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 573         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000258    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000525    |
| times/evaluation_paths         | 36.5        |
| times/timestep_after_hook      | 0.0065      |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 61.5        |
| timestep                       | 1000        |
| timesteps_total                | 574000      |
| train-steps                    | 574000      |
| training/Q/q1_loss             | 104.28372   |
| training/sac_pi/alpha          | 0.16833901  |
| training/sac_pi/alpha_loss     | -0.20608263 |
| training/sac_pi/logp_pi        | 3.755839    |
| training/sac_pi/pi_entropy     | 3.437523    |
| training/sac_pi/pi_global_norm | 1.8778858   |
| training/sac_pi/policy_loss    | -218.21826  |
| training/sac_pi/std            | 0.4758773   |
| training/sac_pi/valid_num      | 4971.0      |
| training/sac_Q/q1              | 211.45695   |
| training/sac_Q/q2              | 210.49556   |
| training/sac_Q/q2_loss         | 105.19466   |
| training/sac_Q/q_global_norm   | 291.82443   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17121303  |
| epoch                          | 574         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5132.6655   |
| evaluation/return-max          | 5223.619    |
| evaluation/return-min          | 4991.4575   |
| evaluation/return-std          | 64.93695    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 82          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46254       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5132.6655   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 210.19455   |
| Q-std                          | 102.831635  |
| Q_loss                         | 85.22006    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 574         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000116    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000597    |
| times/evaluation_paths         | 37.7        |
| times/timestep_after_hook      | 0.00418     |
| times/timestep_before_hook     | 0.00869     |
| times/train                    | 63.4        |
| timestep                       | 1000        |
| timesteps_total                | 575000      |
| train-steps                    | 575000      |
| training/Q/q1_loss             | 112.88978   |
| training/sac_pi/alpha          | 0.17124683  |
| training/sac_pi/alpha_loss     | -0.20404752 |
| training/sac_pi/logp_pi        | 4.47933     |
| training/sac_pi/pi_entropy     | 3.443208    |
| training/sac_pi/pi_global_norm | 1.5368664   |
| training/sac_pi/policy_loss    | -217.31491  |
| training/sac_pi/std            | 0.507194    |
| training/sac_pi/valid_num      | 4947.0      |
| training/sac_Q/q1              | 204.54599   |
| training/sac_Q/q2              | 204.9877    |
| training/sac_Q/q2_loss         | 112.61861   |
| training/sac_Q/q_global_norm   | 246.4566    |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17251152   |
| epoch                          | 575          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5032.6196    |
| evaluation/return-max          | 5081.7197    |
| evaluation/return-min          | 4993.033     |
| evaluation/return-std          | 25.340605    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.03         |
| model/origin_ret               | 84.5         |
| model/penalty_ret              | 80.4         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46275        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5032.6196    |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 211.84929    |
| Q-std                          | 123.70649    |
| Q_loss                         | 98.91215     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 575          |
| times/epoch_after_hook         | 1.71e-06     |
| times/epoch_before_hook        | 0.000135     |
| times/epoch_rollout_model      | 488          |
| times/evaluation_metrics       | 0.000576     |
| times/evaluation_paths         | 36.2         |
| times/timestep_after_hook      | 0.00415      |
| times/timestep_before_hook     | 0.00846      |
| times/train                    | 61.9         |
| timestep                       | 1000         |
| timesteps_total                | 576000       |
| train-steps                    | 576000       |
| training/Q/q1_loss             | 91.60533     |
| training/sac_pi/alpha          | 0.17251058   |
| training/sac_pi/alpha_loss     | -0.034257278 |
| training/sac_pi/logp_pi        | 3.6035683    |
| training/sac_pi/pi_entropy     | 3.4462533    |
| training/sac_pi/pi_global_norm | 2.08749      |
| training/sac_pi/policy_loss    | -223.1372    |
| training/sac_pi/std            | 0.4676227    |
| training/sac_pi/valid_num      | 5008.0       |
| training/sac_Q/q1              | 216.2644     |
| training/sac_Q/q2              | 216.05673    |
| training/sac_Q/q2_loss         | 92.857956    |
| training/sac_Q/q_global_norm   | 219.37221    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17049406 |
| epoch                          | 576        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5102.6167  |
| evaluation/return-max          | 5141.081   |
| evaluation/return-min          | 5044.6724  |
| evaluation/return-std          | 33.21834   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46161      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5102.6167  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 204.79514  |
| Q-std                          | 109.352234 |
| Q_loss                         | 118.12741  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 576        |
| times/epoch_after_hook         | 3.41e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000635   |
| times/evaluation_paths         | 39.5       |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.00891    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 577000     |
| train-steps                    | 577000     |
| training/Q/q1_loss             | 97.13746   |
| training/sac_pi/alpha          | 0.17047474 |
| training/sac_pi/alpha_loss     | 0.14524195 |
| training/sac_pi/logp_pi        | 3.8284066  |
| training/sac_pi/pi_entropy     | 3.426246   |
| training/sac_pi/pi_global_norm | 1.5091414  |
| training/sac_pi/policy_loss    | -219.6851  |
| training/sac_pi/std            | 0.46735984 |
| training/sac_pi/valid_num      | 4985.0     |
| training/sac_Q/q1              | 213.79443  |
| training/sac_Q/q2              | 212.39128  |
| training/sac_Q/q2_loss         | 97.855545  |
| training/sac_Q/q_global_norm   | 215.53342  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17196889 |
| epoch                          | 577        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4794.3623  |
| evaluation/return-max          | 4912.962   |
| evaluation/return-min          | 4621.539   |
| evaluation/return-std          | 88.00661   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46196      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4794.3623  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 218.01266  |
| Q-std                          | 94.91486   |
| Q_loss                         | 93.87474   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 577        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000279   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000551   |
| times/evaluation_paths         | 35.1       |
| times/timestep_after_hook      | 0.00413    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 63.9       |
| timestep                       | 1000       |
| timesteps_total                | 578000     |
| train-steps                    | 578000     |
| training/Q/q1_loss             | 103.79566  |
| training/sac_pi/alpha          | 0.1719878  |
| training/sac_pi/alpha_loss     | -0.0733888 |
| training/sac_pi/logp_pi        | 3.9210262  |
| training/sac_pi/pi_entropy     | 3.443126   |
| training/sac_pi/pi_global_norm | 1.596451   |
| training/sac_pi/policy_loss    | -221.69437 |
| training/sac_pi/std            | 0.4830209  |
| training/sac_pi/valid_num      | 4984.0     |
| training/sac_Q/q1              | 214.26025  |
| training/sac_Q/q2              | 213.3237   |
| training/sac_Q/q2_loss         | 105.247406 |
| training/sac_Q/q_global_norm   | 205.6451   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17442171 |
| epoch                          | 578        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5013.543   |
| evaluation/return-max          | 5056.3535  |
| evaluation/return-min          | 4992.491   |
| evaluation/return-std          | 18.148167  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46257      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5013.543   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 211.53032  |
| Q-std                          | 105.38237  |
| Q_loss                         | 104.097    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 578        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000584   |
| times/evaluation_paths         | 34.2       |
| times/timestep_after_hook      | 0.00406    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 62.9       |
| timestep                       | 1000       |
| timesteps_total                | 579000     |
| train-steps                    | 579000     |
| training/Q/q1_loss             | 105.33058  |
| training/sac_pi/alpha          | 0.17438555 |
| training/sac_pi/alpha_loss     | 0.27544484 |
| training/sac_pi/logp_pi        | 5.0327196  |
| training/sac_pi/pi_entropy     | 3.5281398  |
| training/sac_pi/pi_global_norm | 1.7033277  |
| training/sac_pi/policy_loss    | -212.47696 |
| training/sac_pi/std            | 0.5117902  |
| training/sac_pi/valid_num      | 4841.0     |
| training/sac_Q/q1              | 198.5527   |
| training/sac_Q/q2              | 197.22006  |
| training/sac_Q/q2_loss         | 104.02286  |
| training/sac_Q/q_global_norm   | 230.48671  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17185892 |
| epoch                          | 579        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4980.5186  |
| evaluation/return-max          | 5042.893   |
| evaluation/return-min          | 4903.7783  |
| evaluation/return-std          | 44.7427    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46248      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4980.5186  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 210.76328  |
| Q-std                          | 122.259445 |
| Q_loss                         | 95.60844   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 579        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.0005     |
| times/evaluation_paths         | 36.3       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 64.2       |
| timestep                       | 1000       |
| timesteps_total                | 580000     |
| train-steps                    | 580000     |
| training/Q/q1_loss             | 98.609985  |
| training/sac_pi/alpha          | 0.17187232 |
| training/sac_pi/alpha_loss     | 0.1744205  |
| training/sac_pi/logp_pi        | 4.5832295  |
| training/sac_pi/pi_entropy     | 3.6232445  |
| training/sac_pi/pi_global_norm | 1.5820212  |
| training/sac_pi/policy_loss    | -217.65019 |
| training/sac_pi/std            | 0.52061003 |
| training/sac_pi/valid_num      | 4923.0     |
| training/sac_Q/q1              | 206.6539   |
| training/sac_Q/q2              | 205.24075  |
| training/sac_Q/q2_loss         | 99.135635  |
| training/sac_Q/q_global_norm   | 339.99545  |
--------------------------------------------------------------------------------
[WARN] 580 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.1652111  |
| epoch                          | 580        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4925.5293  |
| evaluation/return-max          | 4984.2725  |
| evaluation/return-min          | 4861.5547  |
| evaluation/return-std          | 36.509342  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46199      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4925.5293  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 205.30408  |
| Q-std                          | 130.5301   |
| Q_loss                         | 105.94419  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 580        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000141   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.00123    |
| times/evaluation_paths         | 35.3       |
| times/timestep_after_hook      | 0.00408    |
| times/timestep_before_hook     | 0.00856    |
| times/train                    | 62.8       |
| timestep                       | 1000       |
| timesteps_total                | 581000     |
| train-steps                    | 581000     |
| training/Q/q1_loss             | 81.56218   |
| training/sac_pi/alpha          | 0.16517109 |
| training/sac_pi/alpha_loss     | 0.28607646 |
| training/sac_pi/logp_pi        | 3.6784472  |
| training/sac_pi/pi_entropy     | 3.3277678  |
| training/sac_pi/pi_global_norm | 1.834851   |
| training/sac_pi/policy_loss    | -222.69449 |
| training/sac_pi/std            | 0.45998776 |
| training/sac_pi/valid_num      | 5055.0     |
| training/sac_Q/q1              | 217.44902  |
| training/sac_Q/q2              | 217.40585  |
| training/sac_Q/q2_loss         | 81.16602   |
| training/sac_Q/q_global_norm   | 282.4353   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17193365   |
| epoch                          | 581          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5011.7812    |
| evaluation/return-max          | 5046.5293    |
| evaluation/return-min          | 4967.7686    |
| evaluation/return-std          | 21.574451    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.99         |
| model/origin_ret               | 84.9         |
| model/penalty_ret              | 81.1         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46239        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5011.7812    |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 206.76086    |
| Q-std                          | 121.05542    |
| Q_loss                         | 104.600685   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 581          |
| times/epoch_after_hook         | 1.82e-06     |
| times/epoch_before_hook        | 0.000258     |
| times/epoch_rollout_model      | 489          |
| times/evaluation_metrics       | 0.000543     |
| times/evaluation_paths         | 35.1         |
| times/timestep_after_hook      | 0.00414      |
| times/timestep_before_hook     | 0.00872      |
| times/train                    | 62.1         |
| timestep                       | 1000         |
| timesteps_total                | 582000       |
| train-steps                    | 582000       |
| training/Q/q1_loss             | 99.021324    |
| training/sac_pi/alpha          | 0.17191027   |
| training/sac_pi/alpha_loss     | 0.0025657495 |
| training/sac_pi/logp_pi        | 4.020427     |
| training/sac_pi/pi_entropy     | 3.4785428    |
| training/sac_pi/pi_global_norm | 1.6808263    |
| training/sac_pi/policy_loss    | -221.05742   |
| training/sac_pi/std            | 0.48563087   |
| training/sac_pi/valid_num      | 4988.0       |
| training/sac_Q/q1              | 212.4773     |
| training/sac_Q/q2              | 211.22888    |
| training/sac_Q/q2_loss         | 99.81291     |
| training/sac_Q/q_global_norm   | 245.11813    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17347683  |
| epoch                          | 582         |
| evaluation/episode-length-avg  | 739         |
| evaluation/episode-length-max  | 858         |
| evaluation/episode-length-min  | 572         |
| evaluation/episode-length-std  | 98.8        |
| evaluation/return-average      | 3610.3867   |
| evaluation/return-max          | 4273.124    |
| evaluation/return-min          | 2637.9136   |
| evaluation/return-std          | 555.4197    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46316       |
| perf/AverageLength             | 739         |
| perf/AverageReturn             | 3610.3867   |
| perf/NormalizedReturn          | 0.786       |
| Q-avg                          | 200.08902   |
| Q-std                          | 152.24371   |
| Q_loss                         | 98.47171    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 582         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000506    |
| times/evaluation_paths         | 27.3        |
| times/timestep_after_hook      | 0.00428     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 62.3        |
| timestep                       | 1000        |
| timesteps_total                | 583000      |
| train-steps                    | 583000      |
| training/Q/q1_loss             | 98.93593    |
| training/sac_pi/alpha          | 0.17349386  |
| training/sac_pi/alpha_loss     | -0.08524711 |
| training/sac_pi/logp_pi        | 3.7247357   |
| training/sac_pi/pi_entropy     | 3.442655    |
| training/sac_pi/pi_global_norm | 1.5960189   |
| training/sac_pi/policy_loss    | -217.7952   |
| training/sac_pi/std            | 0.477399    |
| training/sac_pi/valid_num      | 4995.0      |
| training/sac_Q/q1              | 212.34053   |
| training/sac_Q/q2              | 211.24873   |
| training/sac_Q/q2_loss         | 98.429276   |
| training/sac_Q/q_global_norm   | 245.64134   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17370662  |
| epoch                          | 583         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4904.186    |
| evaluation/return-max          | 4992.7314   |
| evaluation/return-min          | 4810.9385   |
| evaluation/return-std          | 61.028774   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46314       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4904.186    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 197.84512   |
| Q-std                          | 142.02515   |
| Q_loss                         | 127.61168   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 583         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000667    |
| times/evaluation_paths         | 35.2        |
| times/timestep_after_hook      | 0.00425     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 63.3        |
| timestep                       | 1000        |
| timesteps_total                | 584000      |
| train-steps                    | 584000      |
| training/Q/q1_loss             | 86.49293    |
| training/sac_pi/alpha          | 0.17365167  |
| training/sac_pi/alpha_loss     | 0.008072084 |
| training/sac_pi/logp_pi        | 4.116542    |
| training/sac_pi/pi_entropy     | 3.249868    |
| training/sac_pi/pi_global_norm | 1.5796016   |
| training/sac_pi/policy_loss    | -217.80228  |
| training/sac_pi/std            | 0.47134447  |
| training/sac_pi/valid_num      | 4974.0      |
| training/sac_Q/q1              | 211.28438   |
| training/sac_Q/q2              | 209.99283   |
| training/sac_Q/q2_loss         | 85.911865   |
| training/sac_Q/q_global_norm   | 288.90723   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17232065 |
| epoch                          | 584        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4955.9883  |
| evaluation/return-max          | 5077.623   |
| evaluation/return-min          | 4828.846   |
| evaluation/return-std          | 86.94468   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46241      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4955.9883  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 209.56766  |
| Q-std                          | 126.500854 |
| Q_loss                         | 98.91088   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 584        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.00014    |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000539   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00421    |
| times/timestep_before_hook     | 0.00858    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 585000     |
| train-steps                    | 585000     |
| training/Q/q1_loss             | 96.85343   |
| training/sac_pi/alpha          | 0.17236751 |
| training/sac_pi/alpha_loss     | -0.335945  |
| training/sac_pi/logp_pi        | 3.857848   |
| training/sac_pi/pi_entropy     | 3.4495301  |
| training/sac_pi/pi_global_norm | 1.8419211  |
| training/sac_pi/policy_loss    | -215.57793 |
| training/sac_pi/std            | 0.47432968 |
| training/sac_pi/valid_num      | 4977.0     |
| training/sac_Q/q1              | 208.19478  |
| training/sac_Q/q2              | 208.36783  |
| training/sac_Q/q2_loss         | 97.2165    |
| training/sac_Q/q_global_norm   | 231.83522  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17143694 |
| epoch                          | 585        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4865.534   |
| evaluation/return-max          | 4911.6094  |
| evaluation/return-min          | 4824.298   |
| evaluation/return-std          | 24.885365  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46170      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4865.534   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 208.28345  |
| Q-std                          | 124.7462   |
| Q_loss                         | 87.088684  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 585        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000262   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000553   |
| times/evaluation_paths         | 40.2       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00859    |
| times/train                    | 63.5       |
| timestep                       | 1000       |
| timesteps_total                | 586000     |
| train-steps                    | 586000     |
| training/Q/q1_loss             | 109.11743  |
| training/sac_pi/alpha          | 0.17141937 |
| training/sac_pi/alpha_loss     | 0.3290985  |
| training/sac_pi/logp_pi        | 4.8276606  |
| training/sac_pi/pi_entropy     | 3.3780494  |
| training/sac_pi/pi_global_norm | 1.6947247  |
| training/sac_pi/policy_loss    | -217.8723  |
| training/sac_pi/std            | 0.49253407 |
| training/sac_pi/valid_num      | 4945.0     |
| training/sac_Q/q1              | 207.50948  |
| training/sac_Q/q2              | 208.57524  |
| training/sac_Q/q2_loss         | 110.014534 |
| training/sac_Q/q_global_norm   | 231.18869  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16589195 |
| epoch                          | 586        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5082.4766  |
| evaluation/return-max          | 5141.6836  |
| evaluation/return-min          | 5027.7466  |
| evaluation/return-std          | 39.26738   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46208      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5082.4766  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 209.49033  |
| Q-std                          | 133.82692  |
| Q_loss                         | 105.59801  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 586        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000644   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 58.6       |
| timestep                       | 1000       |
| timesteps_total                | 587000     |
| train-steps                    | 587000     |
| training/Q/q1_loss             | 109.80969  |
| training/sac_pi/alpha          | 0.16586876 |
| training/sac_pi/alpha_loss     | 0.24050356 |
| training/sac_pi/logp_pi        | 4.820554   |
| training/sac_pi/pi_entropy     | 3.3201957  |
| training/sac_pi/pi_global_norm | 1.4594079  |
| training/sac_pi/policy_loss    | -222.00182 |
| training/sac_pi/std            | 0.49479666 |
| training/sac_pi/valid_num      | 4942.0     |
| training/sac_Q/q1              | 204.99585  |
| training/sac_Q/q2              | 205.33061  |
| training/sac_Q/q2_loss         | 109.711494 |
| training/sac_Q/q_global_norm   | 288.96405  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16646053  |
| epoch                          | 587         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4903.9595   |
| evaluation/return-max          | 4925.854    |
| evaluation/return-min          | 4873.929    |
| evaluation/return-std          | 13.971      |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46206       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4903.9595   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 200.58029   |
| Q-std                          | 132.6269    |
| Q_loss                         | 95.86717    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 587         |
| times/epoch_after_hook         | 2.04e-06    |
| times/epoch_before_hook        | 0.000148    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000515    |
| times/evaluation_paths         | 33.5        |
| times/timestep_after_hook      | 0.00424     |
| times/timestep_before_hook     | 0.00867     |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 588000      |
| train-steps                    | 588000      |
| training/Q/q1_loss             | 100.71264   |
| training/sac_pi/alpha          | 0.1665004   |
| training/sac_pi/alpha_loss     | -0.08067534 |
| training/sac_pi/logp_pi        | 4.3087244   |
| training/sac_pi/pi_entropy     | 3.447998    |
| training/sac_pi/pi_global_norm | 1.9517226   |
| training/sac_pi/policy_loss    | -213.90422  |
| training/sac_pi/std            | 0.5029364   |
| training/sac_pi/valid_num      | 4976.0      |
| training/sac_Q/q1              | 206.55103   |
| training/sac_Q/q2              | 205.91995   |
| training/sac_Q/q2_loss         | 101.043976  |
| training/sac_Q/q_global_norm   | 228.8312    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16574718 |
| epoch                          | 588        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5171.121   |
| evaluation/return-max          | 5257.4     |
| evaluation/return-min          | 5014.7344  |
| evaluation/return-std          | 72.62069   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46203      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5171.121   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 206.40097  |
| Q-std                          | 131.65994  |
| Q_loss                         | 76.60397   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 588        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 506        |
| times/evaluation_metrics       | 0.000566   |
| times/evaluation_paths         | 36.1       |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 58.5       |
| timestep                       | 1000       |
| timesteps_total                | 589000     |
| train-steps                    | 589000     |
| training/Q/q1_loss             | 98.73885   |
| training/sac_pi/alpha          | 0.16572139 |
| training/sac_pi/alpha_loss     | 0.15182364 |
| training/sac_pi/logp_pi        | 4.154343   |
| training/sac_pi/pi_entropy     | 3.376007   |
| training/sac_pi/pi_global_norm | 1.4602201  |
| training/sac_pi/policy_loss    | -215.48352 |
| training/sac_pi/std            | 0.48243442 |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 203.79677  |
| training/sac_Q/q2              | 203.35739  |
| training/sac_Q/q2_loss         | 98.95374   |
| training/sac_Q/q_global_norm   | 220.90997  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16366139  |
| epoch                          | 589         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4891.7334   |
| evaluation/return-max          | 4925.582    |
| evaluation/return-min          | 4857.3677   |
| evaluation/return-std          | 22.503622   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46227       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4891.7334   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 197.83974   |
| Q-std                          | 132.71558   |
| Q_loss                         | 96.950745   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 589         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000299    |
| times/epoch_rollout_model      | 510         |
| times/evaluation_metrics       | 0.000673    |
| times/evaluation_paths         | 34.3        |
| times/timestep_after_hook      | 0.00412     |
| times/timestep_before_hook     | 0.00856     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 590000      |
| train-steps                    | 590000      |
| training/Q/q1_loss             | 101.27194   |
| training/sac_pi/alpha          | 0.16368529  |
| training/sac_pi/alpha_loss     | -0.25966814 |
| training/sac_pi/logp_pi        | 3.797442    |
| training/sac_pi/pi_entropy     | 3.3959498   |
| training/sac_pi/pi_global_norm | 1.5212647   |
| training/sac_pi/policy_loss    | -210.31776  |
| training/sac_pi/std            | 0.48743686  |
| training/sac_pi/valid_num      | 4962.0      |
| training/sac_Q/q1              | 200.10068   |
| training/sac_Q/q2              | 200.97006   |
| training/sac_Q/q2_loss         | 100.00111   |
| training/sac_Q/q_global_norm   | 183.66559   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17170826   |
| epoch                          | 590          |
| evaluation/episode-length-avg  | 929          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 291          |
| evaluation/episode-length-std  | 213          |
| evaluation/return-average      | 4597.828     |
| evaluation/return-max          | 5029.6484    |
| evaluation/return-min          | 1081.2567    |
| evaluation/return-std          | 1172.7427    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.91         |
| model/origin_ret               | 83.3         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46143        |
| perf/AverageLength             | 929          |
| perf/AverageReturn             | 4597.828     |
| perf/NormalizedReturn          | 1            |
| Q-avg                          | 195.23306    |
| Q-std                          | 174.34723    |
| Q_loss                         | 98.3003      |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 590          |
| times/epoch_after_hook         | 1.82e-06     |
| times/epoch_before_hook        | 0.000121     |
| times/epoch_rollout_model      | 499          |
| times/evaluation_metrics       | 0.000536     |
| times/evaluation_paths         | 33.1         |
| times/timestep_after_hook      | 0.00434      |
| times/timestep_before_hook     | 0.00848      |
| times/train                    | 60.6         |
| timestep                       | 1000         |
| timesteps_total                | 591000       |
| train-steps                    | 591000       |
| training/Q/q1_loss             | 122.59077    |
| training/sac_pi/alpha          | 0.1717127    |
| training/sac_pi/alpha_loss     | -0.026968667 |
| training/sac_pi/logp_pi        | 4.981641     |
| training/sac_pi/pi_entropy     | 3.3916526    |
| training/sac_pi/pi_global_norm | 1.763228     |
| training/sac_pi/policy_loss    | -220.85043   |
| training/sac_pi/std            | 0.5220962    |
| training/sac_pi/valid_num      | 4957.0       |
| training/sac_Q/q1              | 207.25334    |
| training/sac_Q/q2              | 207.79546    |
| training/sac_Q/q2_loss         | 122.43186    |
| training/sac_Q/q_global_norm   | 285.19925    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1710445   |
| epoch                          | 591         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4690.8794   |
| evaluation/return-max          | 4785.299    |
| evaluation/return-min          | 4630.629    |
| evaluation/return-std          | 48.56812    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46151       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4690.8794   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 212.28877   |
| Q-std                          | 103.69533   |
| Q_loss                         | 97.84334    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 591         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000116    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000513    |
| times/evaluation_paths         | 34.4        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 61.5        |
| timestep                       | 1000        |
| timesteps_total                | 592000      |
| train-steps                    | 592000      |
| training/Q/q1_loss             | 115.3446    |
| training/sac_pi/alpha          | 0.1710767   |
| training/sac_pi/alpha_loss     | -0.25814626 |
| training/sac_pi/logp_pi        | 4.112504    |
| training/sac_pi/pi_entropy     | 3.4662952   |
| training/sac_pi/pi_global_norm | 1.6719759   |
| training/sac_pi/policy_loss    | -211.67714  |
| training/sac_pi/std            | 0.5014136   |
| training/sac_pi/valid_num      | 4967.0      |
| training/sac_Q/q1              | 202.71115   |
| training/sac_Q/q2              | 202.03926   |
| training/sac_Q/q2_loss         | 115.6346    |
| training/sac_Q/q_global_norm   | 222.41844   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1699452    |
| epoch                          | 592          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5137.9473    |
| evaluation/return-max          | 5226.3677    |
| evaluation/return-min          | 5054.2075    |
| evaluation/return-std          | 52.609013    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.01         |
| model/origin_ret               | 84.7         |
| model/penalty_ret              | 81.1         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46279        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5137.9473    |
| perf/NormalizedReturn          | 1.12         |
| Q-avg                          | 198.41386    |
| Q-std                          | 122.68445    |
| Q_loss                         | 104.83272    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 592          |
| times/epoch_after_hook         | 1.81e-06     |
| times/epoch_before_hook        | 0.000144     |
| times/epoch_rollout_model      | 512          |
| times/evaluation_metrics       | 0.000537     |
| times/evaluation_paths         | 33.2         |
| times/timestep_after_hook      | 0.00403      |
| times/timestep_before_hook     | 0.00855      |
| times/train                    | 58.3         |
| timestep                       | 1000         |
| timesteps_total                | 593000       |
| train-steps                    | 593000       |
| training/Q/q1_loss             | 89.262695    |
| training/sac_pi/alpha          | 0.1699663    |
| training/sac_pi/alpha_loss     | -0.059423048 |
| training/sac_pi/logp_pi        | 4.0274897    |
| training/sac_pi/pi_entropy     | 3.5004272    |
| training/sac_pi/pi_global_norm | 1.7933117    |
| training/sac_pi/policy_loss    | -223.76932   |
| training/sac_pi/std            | 0.5044182    |
| training/sac_pi/valid_num      | 4943.0       |
| training/sac_Q/q1              | 214.02637    |
| training/sac_Q/q2              | 213.3583     |
| training/sac_Q/q2_loss         | 89.15959     |
| training/sac_Q/q_global_norm   | 231.37953    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1712778  |
| epoch                          | 593        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5016.8916  |
| evaluation/return-max          | 5039.205   |
| evaluation/return-min          | 4963.0576  |
| evaluation/return-std          | 21.403227  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46235      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5016.8916  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 208.01572  |
| Q-std                          | 126.63292  |
| Q_loss                         | 86.58052   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 593        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000339   |
| times/epoch_rollout_model      | 515        |
| times/evaluation_metrics       | 0.000575   |
| times/evaluation_paths         | 35.7       |
| times/timestep_after_hook      | 0.00442    |
| times/timestep_before_hook     | 0.00868    |
| times/train                    | 64.9       |
| timestep                       | 1000       |
| timesteps_total                | 594000     |
| train-steps                    | 594000     |
| training/Q/q1_loss             | 95.732315  |
| training/sac_pi/alpha          | 0.17125714 |
| training/sac_pi/alpha_loss     | 0.06453144 |
| training/sac_pi/logp_pi        | 3.4501526  |
| training/sac_pi/pi_entropy     | 3.4498124  |
| training/sac_pi/pi_global_norm | 1.7991683  |
| training/sac_pi/policy_loss    | -218.46487 |
| training/sac_pi/std            | 0.45668036 |
| training/sac_pi/valid_num      | 4983.0     |
| training/sac_Q/q1              | 213.34306  |
| training/sac_Q/q2              | 213.28809  |
| training/sac_Q/q2_loss         | 96.976326  |
| training/sac_Q/q_global_norm   | 238.00253  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1716861  |
| epoch                          | 594        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4821.991   |
| evaluation/return-max          | 4902.2646  |
| evaluation/return-min          | 4609.142   |
| evaluation/return-std          | 84.694954  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46274      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4821.991   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 204.34122  |
| Q-std                          | 121.87992  |
| Q_loss                         | 96.504234  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 594        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 505        |
| times/evaluation_metrics       | 0.00062    |
| times/evaluation_paths         | 35         |
| times/timestep_after_hook      | 0.00421    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 595000     |
| train-steps                    | 595000     |
| training/Q/q1_loss             | 98.11398   |
| training/sac_pi/alpha          | 0.17164403 |
| training/sac_pi/alpha_loss     | 0.20075901 |
| training/sac_pi/logp_pi        | 4.362132   |
| training/sac_pi/pi_entropy     | 3.2840004  |
| training/sac_pi/pi_global_norm | 2.3813033  |
| training/sac_pi/policy_loss    | -222.33984 |
| training/sac_pi/std            | 0.47638148 |
| training/sac_pi/valid_num      | 4985.0     |
| training/sac_Q/q1              | 214.8896   |
| training/sac_Q/q2              | 214.63766  |
| training/sac_Q/q2_loss         | 97.65377   |
| training/sac_Q/q_global_norm   | 223.24179  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16846663 |
| epoch                          | 595        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5165.3623  |
| evaluation/return-max          | 5211.9556  |
| evaluation/return-min          | 5066.0684  |
| evaluation/return-std          | 39.357315  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46333      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5165.3623  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 213.42395  |
| Q-std                          | 107.004    |
| Q_loss                         | 104.82678  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 595        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 33         |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 60         |
| timestep                       | 1000       |
| timesteps_total                | 596000     |
| train-steps                    | 596000     |
| training/Q/q1_loss             | 101.41719  |
| training/sac_pi/alpha          | 0.16846694 |
| training/sac_pi/alpha_loss     | 0.2863057  |
| training/sac_pi/logp_pi        | 4.2423773  |
| training/sac_pi/pi_entropy     | 3.4216664  |
| training/sac_pi/pi_global_norm | 1.8004243  |
| training/sac_pi/policy_loss    | -212.1418  |
| training/sac_pi/std            | 0.49660188 |
| training/sac_pi/valid_num      | 4931.0     |
| training/sac_Q/q1              | 202.34709  |
| training/sac_Q/q2              | 202.89284  |
| training/sac_Q/q2_loss         | 101.306755 |
| training/sac_Q/q_global_norm   | 285.11038  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16643223  |
| epoch                          | 596         |
| evaluation/episode-length-avg  | 974         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 741         |
| evaluation/episode-length-std  | 77.7        |
| evaluation/return-average      | 5181.28     |
| evaluation/return-max          | 5407.1685   |
| evaluation/return-min          | 3731.1794   |
| evaluation/return-std          | 486.63907   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46221       |
| perf/AverageLength             | 974         |
| perf/AverageReturn             | 5181.28     |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 199.49092   |
| Q-std                          | 140.45782   |
| Q_loss                         | 101.504295  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 596         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000536    |
| times/evaluation_paths         | 33.5        |
| times/timestep_after_hook      | 0.00421     |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 62.3        |
| timestep                       | 1000        |
| timesteps_total                | 597000      |
| train-steps                    | 597000      |
| training/Q/q1_loss             | 101.44147   |
| training/sac_pi/alpha          | 0.16651039  |
| training/sac_pi/alpha_loss     | -0.58550376 |
| training/sac_pi/logp_pi        | 3.7386913   |
| training/sac_pi/pi_entropy     | 3.4695778   |
| training/sac_pi/pi_global_norm | 1.8548478   |
| training/sac_pi/policy_loss    | -219.51021  |
| training/sac_pi/std            | 0.48331675  |
| training/sac_pi/valid_num      | 4960.0      |
| training/sac_Q/q1              | 209.5339    |
| training/sac_Q/q2              | 209.59335   |
| training/sac_Q/q2_loss         | 100.87282   |
| training/sac_Q/q_global_norm   | 233.96533   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17326987  |
| epoch                          | 597         |
| evaluation/episode-length-avg  | 725         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 310         |
| evaluation/episode-length-std  | 337         |
| evaluation/return-average      | 3393.5      |
| evaluation/return-max          | 4877.711    |
| evaluation/return-min          | 1229.1284   |
| evaluation/return-std          | 1758.8739   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46314       |
| perf/AverageLength             | 725         |
| perf/AverageReturn             | 3393.5      |
| perf/NormalizedReturn          | 0.739       |
| Q-avg                          | 197.11179   |
| Q-std                          | 148.70375   |
| Q_loss                         | 116.06687   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 597         |
| times/epoch_after_hook         | 1.62e-06    |
| times/epoch_before_hook        | 0.000318    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000488    |
| times/evaluation_paths         | 24.4        |
| times/timestep_after_hook      | 0.00423     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 58          |
| timestep                       | 1000        |
| timesteps_total                | 598000      |
| train-steps                    | 598000      |
| training/Q/q1_loss             | 105.26272   |
| training/sac_pi/alpha          | 0.17325923  |
| training/sac_pi/alpha_loss     | -0.07980503 |
| training/sac_pi/logp_pi        | 3.8129306   |
| training/sac_pi/pi_entropy     | 3.2594967   |
| training/sac_pi/pi_global_norm | 1.5305096   |
| training/sac_pi/policy_loss    | -221.4055   |
| training/sac_pi/std            | 0.4606571   |
| training/sac_pi/valid_num      | 5017.0      |
| training/sac_Q/q1              | 216.78252   |
| training/sac_Q/q2              | 216.10376   |
| training/sac_Q/q2_loss         | 105.50878   |
| training/sac_Q/q_global_norm   | 244.33739   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17545211 |
| epoch                          | 598        |
| evaluation/episode-length-avg  | 653        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 280        |
| evaluation/episode-length-std  | 348        |
| evaluation/return-average      | 3163.4836  |
| evaluation/return-max          | 5089.45    |
| evaluation/return-min          | 1163.8154  |
| evaluation/return-std          | 1874.4988  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46123      |
| perf/AverageLength             | 653        |
| perf/AverageReturn             | 3163.4836  |
| perf/NormalizedReturn          | 0.689      |
| Q-avg                          | 224.94214  |
| Q-std                          | 96.54087   |
| Q_loss                         | 96.603905  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 598        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 510        |
| times/evaluation_metrics       | 0.000534   |
| times/evaluation_paths         | 22.2       |
| times/timestep_after_hook      | 0.00409    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 599000     |
| train-steps                    | 599000     |
| training/Q/q1_loss             | 83.76949   |
| training/sac_pi/alpha          | 0.17546116 |
| training/sac_pi/alpha_loss     | -0.2845443 |
| training/sac_pi/logp_pi        | 3.5328128  |
| training/sac_pi/pi_entropy     | 3.5788925  |
| training/sac_pi/pi_global_norm | 1.9415889  |
| training/sac_pi/policy_loss    | -215.13545 |
| training/sac_pi/std            | 0.4836226  |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 207.31612  |
| training/sac_Q/q2              | 207.342    |
| training/sac_Q/q2_loss         | 84.81302   |
| training/sac_Q/q_global_norm   | 219.84306  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17698023  |
| epoch                          | 599         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5037.1313   |
| evaluation/return-max          | 5086.169    |
| evaluation/return-min          | 4985.498    |
| evaluation/return-std          | 30.409904   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46296       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5037.1313   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 206.39973   |
| Q-std                          | 129.41777   |
| Q_loss                         | 113.85839   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 599         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000303    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000465    |
| times/evaluation_paths         | 34.5        |
| times/timestep_after_hook      | 0.004       |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 62.3        |
| timestep                       | 1000        |
| timesteps_total                | 600000      |
| train-steps                    | 600000      |
| training/Q/q1_loss             | 106.25341   |
| training/sac_pi/alpha          | 0.17700155  |
| training/sac_pi/alpha_loss     | -0.30369174 |
| training/sac_pi/logp_pi        | 3.994577    |
| training/sac_pi/pi_entropy     | 3.5306573   |
| training/sac_pi/pi_global_norm | 1.9491756   |
| training/sac_pi/policy_loss    | -222.41762  |
| training/sac_pi/std            | 0.50558287  |
| training/sac_pi/valid_num      | 4983.0      |
| training/sac_Q/q1              | 214.94382   |
| training/sac_Q/q2              | 215.5209    |
| training/sac_Q/q2_loss         | 106.611305  |
| training/sac_Q/q_global_norm   | 222.51971   |
---------------------------------------------------------------------------------
[WARN] 600 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16883661  |
| epoch                          | 600         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4998.345    |
| evaluation/return-max          | 5069.333    |
| evaluation/return-min          | 4928.788    |
| evaluation/return-std          | 36.261654   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46183       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4998.345    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 210.50137   |
| Q-std                          | 111.48719   |
| Q_loss                         | 109.50752   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 600         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000114    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000571    |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00417     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 62.4        |
| timestep                       | 1000        |
| timesteps_total                | 601000      |
| train-steps                    | 601000      |
| training/Q/q1_loss             | 114.846275  |
| training/sac_pi/alpha          | 0.16882052  |
| training/sac_pi/alpha_loss     | -0.06299093 |
| training/sac_pi/logp_pi        | 4.3671317   |
| training/sac_pi/pi_entropy     | 3.5887046   |
| training/sac_pi/pi_global_norm | 1.8870655   |
| training/sac_pi/policy_loss    | -217.81096  |
| training/sac_pi/std            | 0.5228893   |
| training/sac_pi/valid_num      | 4930.0      |
| training/sac_Q/q1              | 206.1132    |
| training/sac_Q/q2              | 205.81587   |
| training/sac_Q/q2_loss         | 114.36623   |
| training/sac_Q/q_global_norm   | 269.4924    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16574067 |
| epoch                          | 601        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5063.1567  |
| evaluation/return-max          | 5128.004   |
| evaluation/return-min          | 5027.7354  |
| evaluation/return-std          | 27.152292  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46108      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5063.1567  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 204.77328  |
| Q-std                          | 119.085175 |
| Q_loss                         | 121.971405 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 601        |
| times/epoch_after_hook         | 3.37e-06   |
| times/epoch_before_hook        | 0.000272   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000653   |
| times/evaluation_paths         | 41.7       |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 59.5       |
| timestep                       | 1000       |
| timesteps_total                | 602000     |
| train-steps                    | 602000     |
| training/Q/q1_loss             | 87.295456  |
| training/sac_pi/alpha          | 0.16571718 |
| training/sac_pi/alpha_loss     | -0.1586303 |
| training/sac_pi/logp_pi        | 4.250936   |
| training/sac_pi/pi_entropy     | 3.355165   |
| training/sac_pi/pi_global_norm | 1.3926532  |
| training/sac_pi/policy_loss    | -216.6162  |
| training/sac_pi/std            | 0.48066682 |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 203.67007  |
| training/sac_Q/q2              | 203.35439  |
| training/sac_Q/q2_loss         | 86.482185  |
| training/sac_Q/q_global_norm   | 243.64816  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16401464 |
| epoch                          | 602        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5264.5825  |
| evaluation/return-max          | 5303.255   |
| evaluation/return-min          | 5178.2256  |
| evaluation/return-std          | 37.372787  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46192      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5264.5825  |
| perf/NormalizedReturn          | 1.15       |
| Q-avg                          | 205.22314  |
| Q-std                          | 112.56555  |
| Q_loss                         | 91.50789   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 602        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000149   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.000838   |
| times/evaluation_paths         | 39.7       |
| times/timestep_after_hook      | 0.00422    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 603000     |
| train-steps                    | 603000     |
| training/Q/q1_loss             | 117.48041  |
| training/sac_pi/alpha          | 0.164026   |
| training/sac_pi/alpha_loss     | 0.13422908 |
| training/sac_pi/logp_pi        | 5.098619   |
| training/sac_pi/pi_entropy     | 3.2466881  |
| training/sac_pi/pi_global_norm | 2.221972   |
| training/sac_pi/policy_loss    | -218.6054  |
| training/sac_pi/std            | 0.49477655 |
| training/sac_pi/valid_num      | 4939.0     |
| training/sac_Q/q1              | 205.52092  |
| training/sac_Q/q2              | 205.50388  |
| training/sac_Q/q2_loss         | 116.803024 |
| training/sac_Q/q_global_norm   | 288.06607  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16327716  |
| epoch                          | 603         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5044.8574   |
| evaluation/return-max          | 5125.1514   |
| evaluation/return-min          | 4977.994    |
| evaluation/return-std          | 37.564545   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46323       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5044.8574   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 210.30136   |
| Q-std                          | 116.519646  |
| Q_loss                         | 85.01102    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 603         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000136    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000621    |
| times/evaluation_paths         | 35.1        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.0084      |
| times/train                    | 61.8        |
| timestep                       | 1000        |
| timesteps_total                | 604000      |
| train-steps                    | 604000      |
| training/Q/q1_loss             | 103.623146  |
| training/sac_pi/alpha          | 0.16328594  |
| training/sac_pi/alpha_loss     | -0.26621398 |
| training/sac_pi/logp_pi        | 3.609792    |
| training/sac_pi/pi_entropy     | 3.4162097   |
| training/sac_pi/pi_global_norm | 1.5545343   |
| training/sac_pi/policy_loss    | -219.17659  |
| training/sac_pi/std            | 0.4752426   |
| training/sac_pi/valid_num      | 5013.0      |
| training/sac_Q/q1              | 214.1145    |
| training/sac_Q/q2              | 213.03625   |
| training/sac_Q/q2_loss         | 104.5693    |
| training/sac_Q/q_global_norm   | 237.35684   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16517791  |
| epoch                          | 604         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5273.919    |
| evaluation/return-max          | 5319.0254   |
| evaluation/return-min          | 5236.1025   |
| evaluation/return-std          | 25.807026   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46336       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5273.919    |
| perf/NormalizedReturn          | 1.15        |
| Q-avg                          | 206.63724   |
| Q-std                          | 135.5508    |
| Q_loss                         | 116.78676   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 604         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000549    |
| times/evaluation_paths         | 35.2        |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 60.1        |
| timestep                       | 1000        |
| timesteps_total                | 605000      |
| train-steps                    | 605000      |
| training/Q/q1_loss             | 86.42459    |
| training/sac_pi/alpha          | 0.16518863  |
| training/sac_pi/alpha_loss     | 0.079941235 |
| training/sac_pi/logp_pi        | 5.004858    |
| training/sac_pi/pi_entropy     | 3.2819762   |
| training/sac_pi/pi_global_norm | 1.5558096   |
| training/sac_pi/policy_loss    | -214.41138  |
| training/sac_pi/std            | 0.5034004   |
| training/sac_pi/valid_num      | 4900.0      |
| training/sac_Q/q1              | 199.05113   |
| training/sac_Q/q2              | 199.93106   |
| training/sac_Q/q2_loss         | 85.88121    |
| training/sac_Q/q_global_norm   | 198.75212   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16938452 |
| epoch                          | 605        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5173.79    |
| evaluation/return-max          | 5199.4893  |
| evaluation/return-min          | 5102.753   |
| evaluation/return-std          | 27.385221  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46195      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5173.79    |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 209.30917  |
| Q-std                          | 128.71284  |
| Q_loss                         | 94.277695  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 605        |
| times/epoch_after_hook         | 1.97e-06   |
| times/epoch_before_hook        | 0.000273   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.00052    |
| times/evaluation_paths         | 36.1       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00863    |
| times/train                    | 72.3       |
| timestep                       | 1000       |
| timesteps_total                | 606000     |
| train-steps                    | 606000     |
| training/Q/q1_loss             | 101.00818  |
| training/sac_pi/alpha          | 0.16938052 |
| training/sac_pi/alpha_loss     | 0.10134034 |
| training/sac_pi/logp_pi        | 4.0618243  |
| training/sac_pi/pi_entropy     | 3.4840503  |
| training/sac_pi/pi_global_norm | 1.2650458  |
| training/sac_pi/policy_loss    | -227.99301 |
| training/sac_pi/std            | 0.48321506 |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 220.08086  |
| training/sac_Q/q2              | 220.20792  |
| training/sac_Q/q2_loss         | 100.647766 |
| training/sac_Q/q_global_norm   | 171.5091   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16884957   |
| epoch                          | 606          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4925.184     |
| evaluation/return-max          | 4983.6787    |
| evaluation/return-min          | 4896.245     |
| evaluation/return-std          | 29.55024     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.08         |
| model/origin_ret               | 86.2         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46203        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4925.184     |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 212.39822    |
| Q-std                          | 119.40965    |
| Q_loss                         | 108.69217    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 606          |
| times/epoch_after_hook         | 1.75e-06     |
| times/epoch_before_hook        | 0.000132     |
| times/epoch_rollout_model      | 497          |
| times/evaluation_metrics       | 0.00059      |
| times/evaluation_paths         | 45.3         |
| times/timestep_after_hook      | 0.00414      |
| times/timestep_before_hook     | 0.00838      |
| times/train                    | 64           |
| timestep                       | 1000         |
| timesteps_total                | 607000       |
| train-steps                    | 607000       |
| training/Q/q1_loss             | 106.714714   |
| training/sac_pi/alpha          | 0.16882618   |
| training/sac_pi/alpha_loss     | -0.020779096 |
| training/sac_pi/logp_pi        | 4.222293     |
| training/sac_pi/pi_entropy     | 3.4952035    |
| training/sac_pi/pi_global_norm | 1.4597054    |
| training/sac_pi/policy_loss    | -219.34137   |
| training/sac_pi/std            | 0.51000845   |
| training/sac_pi/valid_num      | 4954.0       |
| training/sac_Q/q1              | 210.96843    |
| training/sac_Q/q2              | 210.38521    |
| training/sac_Q/q2_loss         | 106.39208    |
| training/sac_Q/q_global_norm   | 190.457      |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17115414 |
| epoch                          | 607        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4606.9805  |
| evaluation/return-max          | 4875.375   |
| evaluation/return-min          | 4095.3633  |
| evaluation/return-std          | 328.70544  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46185      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4606.9805  |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 203.09073  |
| Q-std                          | 143.61331  |
| Q_loss                         | 100.740616 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 607        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.000524   |
| times/evaluation_paths         | 42.5       |
| times/timestep_after_hook      | 0.00409    |
| times/timestep_before_hook     | 0.00852    |
| times/train                    | 68.4       |
| timestep                       | 1000       |
| timesteps_total                | 608000     |
| train-steps                    | 608000     |
| training/Q/q1_loss             | 97.31473   |
| training/sac_pi/alpha          | 0.17116721 |
| training/sac_pi/alpha_loss     | -0.2770968 |
| training/sac_pi/logp_pi        | 3.0283046  |
| training/sac_pi/pi_entropy     | 3.3325782  |
| training/sac_pi/pi_global_norm | 1.5675555  |
| training/sac_pi/policy_loss    | -226.11876 |
| training/sac_pi/std            | 0.44634756 |
| training/sac_pi/valid_num      | 5048.0     |
| training/sac_Q/q1              | 223.41716  |
| training/sac_Q/q2              | 223.45056  |
| training/sac_Q/q2_loss         | 96.26403   |
| training/sac_Q/q_global_norm   | 213.335    |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16707772 |
| epoch                          | 608        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4705.7383  |
| evaluation/return-max          | 4792.7324  |
| evaluation/return-min          | 4619.2393  |
| evaluation/return-std          | 52.081062  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46249      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4705.7383  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 211.30766  |
| Q-std                          | 143.99686  |
| Q_loss                         | 90.25512   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 608        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000245   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000521   |
| times/evaluation_paths         | 40.9       |
| times/timestep_after_hook      | 0.0042     |
| times/timestep_before_hook     | 0.00864    |
| times/train                    | 68.8       |
| timestep                       | 1000       |
| timesteps_total                | 609000     |
| train-steps                    | 609000     |
| training/Q/q1_loss             | 113.079956 |
| training/sac_pi/alpha          | 0.16706568 |
| training/sac_pi/alpha_loss     | 0.6373817  |
| training/sac_pi/logp_pi        | 4.975823   |
| training/sac_pi/pi_entropy     | 3.2293708  |
| training/sac_pi/pi_global_norm | 2.2201993  |
| training/sac_pi/policy_loss    | -211.24487 |
| training/sac_pi/std            | 0.4690831  |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 201.1393   |
| training/sac_Q/q2              | 200.83467  |
| training/sac_Q/q2_loss         | 113.07246  |
| training/sac_Q/q_global_norm   | 306.9047   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1677642   |
| epoch                          | 609         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4937.9385   |
| evaluation/return-max          | 4974.6963   |
| evaluation/return-min          | 4877.4824   |
| evaluation/return-std          | 31.230503   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 80.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46119       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4937.9385   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 217.90633   |
| Q-std                          | 138.24919   |
| Q_loss                         | 90.669785   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 609         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000259    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000563    |
| times/evaluation_paths         | 37.8        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 57.1        |
| timestep                       | 1000        |
| timesteps_total                | 610000      |
| train-steps                    | 610000      |
| training/Q/q1_loss             | 113.397736  |
| training/sac_pi/alpha          | 0.16777158  |
| training/sac_pi/alpha_loss     | -0.13584854 |
| training/sac_pi/logp_pi        | 4.5406227   |
| training/sac_pi/pi_entropy     | 3.5778575   |
| training/sac_pi/pi_global_norm | 1.5489324   |
| training/sac_pi/policy_loss    | -219.05011  |
| training/sac_pi/std            | 0.5320086   |
| training/sac_pi/valid_num      | 4964.0      |
| training/sac_Q/q1              | 206.21602   |
| training/sac_Q/q2              | 205.56631   |
| training/sac_Q/q2_loss         | 112.65081   |
| training/sac_Q/q_global_norm   | 213.44543   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17290297 |
| epoch                          | 610        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4984.398   |
| evaluation/return-max          | 5098.3228  |
| evaluation/return-min          | 4891.509   |
| evaluation/return-std          | 65.878105  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46164      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4984.398   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 221.10347  |
| Q-std                          | 131.59477  |
| Q_loss                         | 96.62382   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 610        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000115   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000628   |
| times/evaluation_paths         | 41.5       |
| times/timestep_after_hook      | 0.00409    |
| times/timestep_before_hook     | 0.00859    |
| times/train                    | 72.8       |
| timestep                       | 1000       |
| timesteps_total                | 611000     |
| train-steps                    | 611000     |
| training/Q/q1_loss             | 107.38213  |
| training/sac_pi/alpha          | 0.17288695 |
| training/sac_pi/alpha_loss     | 0.3328182  |
| training/sac_pi/logp_pi        | 5.1402183  |
| training/sac_pi/pi_entropy     | 3.35933    |
| training/sac_pi/pi_global_norm | 1.6747726  |
| training/sac_pi/policy_loss    | -227.85298 |
| training/sac_pi/std            | 0.50537586 |
| training/sac_pi/valid_num      | 4909.0     |
| training/sac_Q/q1              | 212.64034  |
| training/sac_Q/q2              | 210.16467  |
| training/sac_Q/q2_loss         | 107.27386  |
| training/sac_Q/q_global_norm   | 222.47339  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17023036 |
| epoch                          | 611        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4814.2837  |
| evaluation/return-max          | 4848.567   |
| evaluation/return-min          | 4765.2983  |
| evaluation/return-std          | 26.530735  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.8       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46276      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4814.2837  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 207.06812  |
| Q-std                          | 120.774574 |
| Q_loss                         | 83.31172   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 611        |
| times/epoch_after_hook         | 1.99e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.00063    |
| times/evaluation_paths         | 38.4       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00857    |
| times/train                    | 65.8       |
| timestep                       | 1000       |
| timesteps_total                | 612000     |
| train-steps                    | 612000     |
| training/Q/q1_loss             | 105.903336 |
| training/sac_pi/alpha          | 0.1702221  |
| training/sac_pi/alpha_loss     | 0.27796984 |
| training/sac_pi/logp_pi        | 3.9538624  |
| training/sac_pi/pi_entropy     | 3.4006066  |
| training/sac_pi/pi_global_norm | 1.8134937  |
| training/sac_pi/policy_loss    | -218.51854 |
| training/sac_pi/std            | 0.4886754  |
| training/sac_pi/valid_num      | 5018.0     |
| training/sac_Q/q1              | 214.55762  |
| training/sac_Q/q2              | 214.02396  |
| training/sac_Q/q2_loss         | 105.620056 |
| training/sac_Q/q_global_norm   | 234.22856  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16174419   |
| epoch                          | 612          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5188.357     |
| evaluation/return-max          | 5222.5996    |
| evaluation/return-min          | 5114.41      |
| evaluation/return-std          | 31.30963     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.08         |
| model/origin_ret               | 86.4         |
| model/penalty_ret              | 81.8         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46278        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5188.357     |
| perf/NormalizedReturn          | 1.13         |
| Q-avg                          | 206.28427    |
| Q-std                          | 113.84882    |
| Q_loss                         | 105.48134    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 612          |
| times/epoch_after_hook         | 1.79e-06     |
| times/epoch_before_hook        | 0.000123     |
| times/epoch_rollout_model      | 502          |
| times/evaluation_metrics       | 0.000575     |
| times/evaluation_paths         | 34.8         |
| times/timestep_after_hook      | 0.00405      |
| times/timestep_before_hook     | 0.00878      |
| times/train                    | 64.6         |
| timestep                       | 1000         |
| timesteps_total                | 613000       |
| train-steps                    | 613000       |
| training/Q/q1_loss             | 88.026024    |
| training/sac_pi/alpha          | 0.16176748   |
| training/sac_pi/alpha_loss     | -0.060736656 |
| training/sac_pi/logp_pi        | 4.475986     |
| training/sac_pi/pi_entropy     | 3.368611     |
| training/sac_pi/pi_global_norm | 1.5385779    |
| training/sac_pi/policy_loss    | -221.07053   |
| training/sac_pi/std            | 0.51094043   |
| training/sac_pi/valid_num      | 4938.0       |
| training/sac_Q/q1              | 208.90886    |
| training/sac_Q/q2              | 207.49695    |
| training/sac_Q/q2_loss         | 88.3048      |
| training/sac_Q/q_global_norm   | 288.43713    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17011832  |
| epoch                          | 613         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5009.2314   |
| evaluation/return-max          | 5062.7334   |
| evaluation/return-min          | 4961.5728   |
| evaluation/return-std          | 35.567875   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46303       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5009.2314   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 211.45125   |
| Q-std                          | 152.2208    |
| Q_loss                         | 110.74015   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 613         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000317    |
| times/epoch_rollout_model      | 503         |
| times/evaluation_metrics       | 0.00122     |
| times/evaluation_paths         | 36.9        |
| times/timestep_after_hook      | 0.00427     |
| times/timestep_before_hook     | 0.00867     |
| times/train                    | 63          |
| timestep                       | 1000        |
| timesteps_total                | 614000      |
| train-steps                    | 614000      |
| training/Q/q1_loss             | 98.89336    |
| training/sac_pi/alpha          | 0.17015643  |
| training/sac_pi/alpha_loss     | -0.10506644 |
| training/sac_pi/logp_pi        | 3.6010623   |
| training/sac_pi/pi_entropy     | 3.4227417   |
| training/sac_pi/pi_global_norm | 1.5295208   |
| training/sac_pi/policy_loss    | -225.05498  |
| training/sac_pi/std            | 0.467887    |
| training/sac_pi/valid_num      | 5018.0      |
| training/sac_Q/q1              | 216.47241   |
| training/sac_Q/q2              | 216.65536   |
| training/sac_Q/q2_loss         | 99.711464   |
| training/sac_Q/q_global_norm   | 169.69171   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16748196 |
| epoch                          | 614        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4942.218   |
| evaluation/return-max          | 5070.558   |
| evaluation/return-min          | 4713.681   |
| evaluation/return-std          | 92.56936   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46413      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4942.218   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 209.60901  |
| Q-std                          | 151.21466  |
| Q_loss                         | 85.845505  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 614        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000654   |
| times/evaluation_paths         | 34.2       |
| times/timestep_after_hook      | 0.00426    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 615000     |
| train-steps                    | 615000     |
| training/Q/q1_loss             | 77.24669   |
| training/sac_pi/alpha          | 0.16749695 |
| training/sac_pi/alpha_loss     | -0.4964795 |
| training/sac_pi/logp_pi        | 3.7739289  |
| training/sac_pi/pi_entropy     | 3.3336701  |
| training/sac_pi/pi_global_norm | 1.5797797  |
| training/sac_pi/policy_loss    | -222.82294 |
| training/sac_pi/std            | 0.46728268 |
| training/sac_pi/valid_num      | 4980.0     |
| training/sac_Q/q1              | 215.82454  |
| training/sac_Q/q2              | 214.95999  |
| training/sac_Q/q2_loss         | 76.40457   |
| training/sac_Q/q_global_norm   | 198.38261  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17025617  |
| epoch                          | 615         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5118.507    |
| evaluation/return-max          | 5209.511    |
| evaluation/return-min          | 5038.24     |
| evaluation/return-std          | 50.385128   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 83.2        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46315       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5118.507    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 219.09317   |
| Q-std                          | 105.95511   |
| Q_loss                         | 81.088135   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 615         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000151    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000535    |
| times/evaluation_paths         | 36.9        |
| times/timestep_after_hook      | 0.004       |
| times/timestep_before_hook     | 0.00839     |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 616000      |
| train-steps                    | 616000      |
| training/Q/q1_loss             | 95.908554   |
| training/sac_pi/alpha          | 0.17023142  |
| training/sac_pi/alpha_loss     | -0.09096752 |
| training/sac_pi/logp_pi        | 4.431155    |
| training/sac_pi/pi_entropy     | 3.5430436   |
| training/sac_pi/pi_global_norm | 1.7819873   |
| training/sac_pi/policy_loss    | -221.99413  |
| training/sac_pi/std            | 0.5136721   |
| training/sac_pi/valid_num      | 4917.0      |
| training/sac_Q/q1              | 206.81992   |
| training/sac_Q/q2              | 206.3147    |
| training/sac_Q/q2_loss         | 95.797035   |
| training/sac_Q/q_global_norm   | 268.84457   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1707645   |
| epoch                          | 616         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4844.431    |
| evaluation/return-max          | 4902.423    |
| evaluation/return-min          | 4786.4927   |
| evaluation/return-std          | 30.201101   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46144       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4844.431    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 213.11343   |
| Q-std                          | 123.59527   |
| Q_loss                         | 101.330246  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 616         |
| times/epoch_after_hook         | 1.93e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000553    |
| times/evaluation_paths         | 35.4        |
| times/timestep_after_hook      | 0.00408     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 617000      |
| train-steps                    | 617000      |
| training/Q/q1_loss             | 99.52503    |
| training/sac_pi/alpha          | 0.17074896  |
| training/sac_pi/alpha_loss     | -0.13419633 |
| training/sac_pi/logp_pi        | 4.375987    |
| training/sac_pi/pi_entropy     | 3.525065    |
| training/sac_pi/pi_global_norm | 1.9761802   |
| training/sac_pi/policy_loss    | -223.5326   |
| training/sac_pi/std            | 0.50364065  |
| training/sac_pi/valid_num      | 4951.0      |
| training/sac_Q/q1              | 212.47647   |
| training/sac_Q/q2              | 212.22693   |
| training/sac_Q/q2_loss         | 98.13833    |
| training/sac_Q/q_global_norm   | 224.17105   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17097898 |
| epoch                          | 617        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5008.042   |
| evaluation/return-max          | 5077.874   |
| evaluation/return-min          | 4950.9766  |
| evaluation/return-std          | 43.23171   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46325      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5008.042   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 220.14363  |
| Q-std                          | 94.410614  |
| Q_loss                         | 101.28264  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 617        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000278   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000579   |
| times/evaluation_paths         | 34.9       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00855    |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 618000     |
| train-steps                    | 618000     |
| training/Q/q1_loss             | 95.71885   |
| training/sac_pi/alpha          | 0.1709838  |
| training/sac_pi/alpha_loss     | 0.32301795 |
| training/sac_pi/logp_pi        | 5.036934   |
| training/sac_pi/pi_entropy     | 3.374899   |
| training/sac_pi/pi_global_norm | 1.7153234  |
| training/sac_pi/policy_loss    | -219.76962 |
| training/sac_pi/std            | 0.49330953 |
| training/sac_pi/valid_num      | 4904.0     |
| training/sac_Q/q1              | 208.36453  |
| training/sac_Q/q2              | 205.67586  |
| training/sac_Q/q2_loss         | 95.43141   |
| training/sac_Q/q_global_norm   | 227.48012  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17088331 |
| epoch                          | 618        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4977.4683  |
| evaluation/return-max          | 5096.5703  |
| evaluation/return-min          | 4874.832   |
| evaluation/return-std          | 70.54548   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46440      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4977.4683  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 208.0489   |
| Q-std                          | 141.23145  |
| Q_loss                         | 106.70373  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 618        |
| times/epoch_after_hook         | 3.72e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000531   |
| times/evaluation_paths         | 36.2       |
| times/timestep_after_hook      | 0.0044     |
| times/timestep_before_hook     | 0.00858    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 619000     |
| train-steps                    | 619000     |
| training/Q/q1_loss             | 63.572945  |
| training/sac_pi/alpha          | 0.17091434 |
| training/sac_pi/alpha_loss     | -0.5436995 |
| training/sac_pi/logp_pi        | 3.7818189  |
| training/sac_pi/pi_entropy     | 3.5919788  |
| training/sac_pi/pi_global_norm | 1.5211403  |
| training/sac_pi/policy_loss    | -227.88754 |
| training/sac_pi/std            | 0.5016246  |
| training/sac_pi/valid_num      | 4955.0     |
| training/sac_Q/q1              | 217.60576  |
| training/sac_Q/q2              | 217.6495   |
| training/sac_Q/q2_loss         | 63.723083  |
| training/sac_Q/q_global_norm   | 249.28802  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16530088  |
| epoch                          | 619         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4980.63     |
| evaluation/return-max          | 5038.409    |
| evaluation/return-min          | 4922.945    |
| evaluation/return-std          | 38.18226    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46156       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4980.63     |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 205.02739   |
| Q-std                          | 132.09396   |
| Q_loss                         | 108.16723   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 619         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000574    |
| times/evaluation_paths         | 35.6        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 60          |
| timestep                       | 1000        |
| timesteps_total                | 620000      |
| train-steps                    | 620000      |
| training/Q/q1_loss             | 92.2359     |
| training/sac_pi/alpha          | 0.16530788  |
| training/sac_pi/alpha_loss     | -0.23644367 |
| training/sac_pi/logp_pi        | 3.5314934   |
| training/sac_pi/pi_entropy     | 3.4360688   |
| training/sac_pi/pi_global_norm | 1.7168788   |
| training/sac_pi/policy_loss    | -226.29189  |
| training/sac_pi/std            | 0.47680557  |
| training/sac_pi/valid_num      | 4996.0      |
| training/sac_Q/q1              | 220.49692   |
| training/sac_Q/q2              | 220.7415    |
| training/sac_Q/q2_loss         | 92.14806    |
| training/sac_Q/q_global_norm   | 287.4132    |
---------------------------------------------------------------------------------
[WARN] 620 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16840944 |
| epoch                          | 620        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5009.8823  |
| evaluation/return-max          | 5046.989   |
| evaluation/return-min          | 4985.3354  |
| evaluation/return-std          | 18.266756  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46301      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5009.8823  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 206.69295  |
| Q-std                          | 148.29103  |
| Q_loss                         | 104.271454 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 620        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.00014    |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000585   |
| times/evaluation_paths         | 33.9       |
| times/timestep_after_hook      | 0.00428    |
| times/timestep_before_hook     | 0.00864    |
| times/train                    | 71.3       |
| timestep                       | 1000       |
| timesteps_total                | 621000     |
| train-steps                    | 621000     |
| training/Q/q1_loss             | 93.41173   |
| training/sac_pi/alpha          | 0.16839887 |
| training/sac_pi/alpha_loss     | 0.305561   |
| training/sac_pi/logp_pi        | 4.1077433  |
| training/sac_pi/pi_entropy     | 3.619632   |
| training/sac_pi/pi_global_norm | 1.9632742  |
| training/sac_pi/policy_loss    | -215.2567  |
| training/sac_pi/std            | 0.51270646 |
| training/sac_pi/valid_num      | 4959.0     |
| training/sac_Q/q1              | 205.19377  |
| training/sac_Q/q2              | 205.51562  |
| training/sac_Q/q2_loss         | 93.09713   |
| training/sac_Q/q_global_norm   | 177.24483  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1714593   |
| epoch                          | 621         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5097.4395   |
| evaluation/return-max          | 5169.5312   |
| evaluation/return-min          | 5024.033    |
| evaluation/return-std          | 44.037933   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46287       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5097.4395   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 218.54668   |
| Q-std                          | 133.97452   |
| Q_loss                         | 137.05363   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 621         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000262    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000559    |
| times/evaluation_paths         | 33.5        |
| times/timestep_after_hook      | 0.00416     |
| times/timestep_before_hook     | 0.00838     |
| times/train                    | 59.8        |
| timestep                       | 1000        |
| timesteps_total                | 622000      |
| train-steps                    | 622000      |
| training/Q/q1_loss             | 100.30611   |
| training/sac_pi/alpha          | 0.17151722  |
| training/sac_pi/alpha_loss     | -0.27243653 |
| training/sac_pi/logp_pi        | 4.104423    |
| training/sac_pi/pi_entropy     | 3.5881343   |
| training/sac_pi/pi_global_norm | 1.549008    |
| training/sac_pi/policy_loss    | -219.59657  |
| training/sac_pi/std            | 0.51867956  |
| training/sac_pi/valid_num      | 4978.0      |
| training/sac_Q/q1              | 210.7738    |
| training/sac_Q/q2              | 209.38274   |
| training/sac_Q/q2_loss         | 100.1969    |
| training/sac_Q/q_global_norm   | 233.67793   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16985275   |
| epoch                          | 622          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5104.9526    |
| evaluation/return-max          | 5222.955     |
| evaluation/return-min          | 4871.3535    |
| evaluation/return-std          | 95.14721     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3            |
| model/origin_ret               | 84.8         |
| model/penalty_ret              | 81           |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46199        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5104.9526    |
| perf/NormalizedReturn          | 1.11         |
| Q-avg                          | 205.31978    |
| Q-std                          | 126.981544   |
| Q_loss                         | 100.50207    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 622          |
| times/epoch_after_hook         | 1.67e-06     |
| times/epoch_before_hook        | 0.000131     |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.000504     |
| times/evaluation_paths         | 36.8         |
| times/timestep_after_hook      | 0.00408      |
| times/timestep_before_hook     | 0.00846      |
| times/train                    | 61           |
| timestep                       | 1000         |
| timesteps_total                | 623000       |
| train-steps                    | 623000       |
| training/Q/q1_loss             | 95.393974    |
| training/sac_pi/alpha          | 0.1698529    |
| training/sac_pi/alpha_loss     | -0.021304013 |
| training/sac_pi/logp_pi        | 5.012914     |
| training/sac_pi/pi_entropy     | 3.5734131    |
| training/sac_pi/pi_global_norm | 1.3987155    |
| training/sac_pi/policy_loss    | -215.6893    |
| training/sac_pi/std            | 0.54586464   |
| training/sac_pi/valid_num      | 4926.0       |
| training/sac_Q/q1              | 196.79613    |
| training/sac_Q/q2              | 195.25836    |
| training/sac_Q/q2_loss         | 95.82948     |
| training/sac_Q/q_global_norm   | 276.7473     |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17563535  |
| epoch                          | 623         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5225.456    |
| evaluation/return-max          | 5284.9243   |
| evaluation/return-min          | 5191.546    |
| evaluation/return-std          | 24.846643   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46293       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5225.456    |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 209.11154   |
| Q-std                          | 112.055084  |
| Q_loss                         | 124.17228   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 623         |
| times/epoch_after_hook         | 1.66e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000574    |
| times/evaluation_paths         | 32.9        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 624000      |
| train-steps                    | 624000      |
| training/Q/q1_loss             | 107.22762   |
| training/sac_pi/alpha          | 0.17562611  |
| training/sac_pi/alpha_loss     | -0.17596091 |
| training/sac_pi/logp_pi        | 5.456094    |
| training/sac_pi/pi_entropy     | 3.5392716   |
| training/sac_pi/pi_global_norm | 1.8848201   |
| training/sac_pi/policy_loss    | -218.77438  |
| training/sac_pi/std            | 0.5363039   |
| training/sac_pi/valid_num      | 4828.0      |
| training/sac_Q/q1              | 198.12695   |
| training/sac_Q/q2              | 198.45432   |
| training/sac_Q/q2_loss         | 107.42257   |
| training/sac_Q/q_global_norm   | 212.07858   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17042685  |
| epoch                          | 624         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4968.3506   |
| evaluation/return-max          | 5056.3877   |
| evaluation/return-min          | 4906.2236   |
| evaluation/return-std          | 50.828224   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86.9        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46264       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4968.3506   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 208.95364   |
| Q-std                          | 142.52303   |
| Q_loss                         | 86.96456    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 624         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.00012     |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000502    |
| times/evaluation_paths         | 36          |
| times/timestep_after_hook      | 0.00413     |
| times/timestep_before_hook     | 0.00846     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 625000      |
| train-steps                    | 625000      |
| training/Q/q1_loss             | 106.075676  |
| training/sac_pi/alpha          | 0.17042825  |
| training/sac_pi/alpha_loss     | -0.08245963 |
| training/sac_pi/logp_pi        | 4.618502    |
| training/sac_pi/pi_entropy     | 3.4153771   |
| training/sac_pi/pi_global_norm | 1.7917984   |
| training/sac_pi/policy_loss    | -219.79704  |
| training/sac_pi/std            | 0.50039834  |
| training/sac_pi/valid_num      | 4943.0      |
| training/sac_Q/q1              | 209.01611   |
| training/sac_Q/q2              | 207.81477   |
| training/sac_Q/q2_loss         | 106.61019   |
| training/sac_Q/q_global_norm   | 239.18585   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16524878 |
| epoch                          | 625        |
| evaluation/episode-length-avg  | 824        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 397        |
| evaluation/episode-length-std  | 270        |
| evaluation/return-average      | 3766.0867  |
| evaluation/return-max          | 4810.5967  |
| evaluation/return-min          | 1546.2205  |
| evaluation/return-std          | 1427.3188  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86         |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46262      |
| perf/AverageLength             | 824        |
| perf/AverageReturn             | 3766.0867  |
| perf/NormalizedReturn          | 0.82       |
| Q-avg                          | 214.8344   |
| Q-std                          | 133.41034  |
| Q_loss                         | 86.06708   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 625        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000273   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000612   |
| times/evaluation_paths         | 28.9       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.0086     |
| times/train                    | 59.9       |
| timestep                       | 1000       |
| timesteps_total                | 626000     |
| train-steps                    | 626000     |
| training/Q/q1_loss             | 109.98378  |
| training/sac_pi/alpha          | 0.16527168 |
| training/sac_pi/alpha_loss     | 0.12152036 |
| training/sac_pi/logp_pi        | 3.7204757  |
| training/sac_pi/pi_entropy     | 3.2400448  |
| training/sac_pi/pi_global_norm | 1.9772432  |
| training/sac_pi/policy_loss    | -228.76022 |
| training/sac_pi/std            | 0.46017364 |
| training/sac_pi/valid_num      | 4998.0     |
| training/sac_Q/q1              | 223.08096  |
| training/sac_Q/q2              | 222.56938  |
| training/sac_Q/q2_loss         | 109.06944  |
| training/sac_Q/q_global_norm   | 239.2509   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1655637   |
| epoch                          | 626         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5215.9897   |
| evaluation/return-max          | 5301.5547   |
| evaluation/return-min          | 5155.3086   |
| evaluation/return-std          | 56.05226    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46319       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5215.9897   |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 207.91675   |
| Q-std                          | 147.3694    |
| Q_loss                         | 92.09101    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 626         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000138    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.00052     |
| times/evaluation_paths         | 34.4        |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.00848     |
| times/train                    | 61.8        |
| timestep                       | 1000        |
| timesteps_total                | 627000      |
| train-steps                    | 627000      |
| training/Q/q1_loss             | 72.675224   |
| training/sac_pi/alpha          | 0.16557278  |
| training/sac_pi/alpha_loss     | -0.15765482 |
| training/sac_pi/logp_pi        | 3.7702584   |
| training/sac_pi/pi_entropy     | 3.2217574   |
| training/sac_pi/pi_global_norm | 1.738051    |
| training/sac_pi/policy_loss    | -227.20233  |
| training/sac_pi/std            | 0.45214048  |
| training/sac_pi/valid_num      | 4969.0      |
| training/sac_Q/q1              | 218.76253   |
| training/sac_Q/q2              | 218.73347   |
| training/sac_Q/q2_loss         | 73.07226    |
| training/sac_Q/q_global_norm   | 279.38715   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16132364  |
| epoch                          | 627         |
| evaluation/episode-length-avg  | 850         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 251         |
| evaluation/episode-length-std  | 299         |
| evaluation/return-average      | 4196.4004   |
| evaluation/return-max          | 5189.6113   |
| evaluation/return-min          | 970.4553    |
| evaluation/return-std          | 1611.5844   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46257       |
| perf/AverageLength             | 850         |
| perf/AverageReturn             | 4196.4004   |
| perf/NormalizedReturn          | 0.914       |
| Q-avg                          | 210.10478   |
| Q-std                          | 113.09425   |
| Q_loss                         | 108.408325  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 627         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000578    |
| times/evaluation_paths         | 29.2        |
| times/timestep_after_hook      | 0.00422     |
| times/timestep_before_hook     | 0.00855     |
| times/train                    | 60.3        |
| timestep                       | 1000        |
| timesteps_total                | 628000      |
| train-steps                    | 628000      |
| training/Q/q1_loss             | 106.253944  |
| training/sac_pi/alpha          | 0.16131914  |
| training/sac_pi/alpha_loss     | 0.014579318 |
| training/sac_pi/logp_pi        | 4.9425745   |
| training/sac_pi/pi_entropy     | 3.2245889   |
| training/sac_pi/pi_global_norm | 1.4450917   |
| training/sac_pi/policy_loss    | -223.9286   |
| training/sac_pi/std            | 0.5010427   |
| training/sac_pi/valid_num      | 4972.0      |
| training/sac_Q/q1              | 212.5375    |
| training/sac_Q/q2              | 211.01013   |
| training/sac_Q/q2_loss         | 106.46063   |
| training/sac_Q/q_global_norm   | 220.55319   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17101447 |
| epoch                          | 628        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5026.999   |
| evaluation/return-max          | 5099.494   |
| evaluation/return-min          | 4739.1196  |
| evaluation/return-std          | 98.25013   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46314      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5026.999   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 204.64417  |
| Q-std                          | 147.37234  |
| Q_loss                         | 94.93846   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 628        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000851   |
| times/evaluation_paths         | 34.9       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00858    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 629000     |
| train-steps                    | 629000     |
| training/Q/q1_loss             | 109.17399  |
| training/sac_pi/alpha          | 0.17103367 |
| training/sac_pi/alpha_loss     | 0.16120659 |
| training/sac_pi/logp_pi        | 3.9768653  |
| training/sac_pi/pi_entropy     | 3.4269874  |
| training/sac_pi/pi_global_norm | 1.6074681  |
| training/sac_pi/policy_loss    | -219.89441 |
| training/sac_pi/std            | 0.47046357 |
| training/sac_pi/valid_num      | 5004.0     |
| training/sac_Q/q1              | 215.41377  |
| training/sac_Q/q2              | 214.22173  |
| training/sac_Q/q2_loss         | 110.30468  |
| training/sac_Q/q_global_norm   | 200.40132  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17035615 |
| epoch                          | 629        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5067.6133  |
| evaluation/return-max          | 5101.7056  |
| evaluation/return-min          | 5021.0356  |
| evaluation/return-std          | 26.839828  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46173      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5067.6133  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 199.66312  |
| Q-std                          | 147.41222  |
| Q_loss                         | 108.94645  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 629        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000265   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000557   |
| times/evaluation_paths         | 34.7       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00873    |
| times/train                    | 62.5       |
| timestep                       | 1000       |
| timesteps_total                | 630000     |
| train-steps                    | 630000     |
| training/Q/q1_loss             | 112.34456  |
| training/sac_pi/alpha          | 0.1704119  |
| training/sac_pi/alpha_loss     | -0.4099921 |
| training/sac_pi/logp_pi        | 4.161977   |
| training/sac_pi/pi_entropy     | 3.4186637  |
| training/sac_pi/pi_global_norm | 1.5575699  |
| training/sac_pi/policy_loss    | -227.26994 |
| training/sac_pi/std            | 0.49020794 |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 214.6777   |
| training/sac_Q/q2              | 214.91924  |
| training/sac_Q/q2_loss         | 113.412865 |
| training/sac_Q/q_global_norm   | 231.81046  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16623001 |
| epoch                          | 630        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4831.6694  |
| evaluation/return-max          | 4971.145   |
| evaluation/return-min          | 4660.3794  |
| evaluation/return-std          | 98.91718   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46199      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4831.6694  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 210.47722  |
| Q-std                          | 106.84312  |
| Q_loss                         | 99.865036  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 630        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000572   |
| times/evaluation_paths         | 33.9       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00866    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 631000     |
| train-steps                    | 631000     |
| training/Q/q1_loss             | 116.39097  |
| training/sac_pi/alpha          | 0.1662535  |
| training/sac_pi/alpha_loss     | -0.4048604 |
| training/sac_pi/logp_pi        | 3.9330025  |
| training/sac_pi/pi_entropy     | 3.4568229  |
| training/sac_pi/pi_global_norm | 1.4767176  |
| training/sac_pi/policy_loss    | -216.71501 |
| training/sac_pi/std            | 0.4981805  |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 204.1118   |
| training/sac_Q/q2              | 205.4335   |
| training/sac_Q/q2_loss         | 117.99696  |
| training/sac_Q/q_global_norm   | 252.576    |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1706695   |
| epoch                          | 631         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4997.349    |
| evaluation/return-max          | 5084.7764   |
| evaluation/return-min          | 4956.916    |
| evaluation/return-std          | 35.017612   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46337       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4997.349    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 208.89249   |
| Q-std                          | 135.79652   |
| Q_loss                         | 113.10269   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 631         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000117    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000509    |
| times/evaluation_paths         | 36          |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00846     |
| times/train                    | 60.5        |
| timestep                       | 1000        |
| timesteps_total                | 632000      |
| train-steps                    | 632000      |
| training/Q/q1_loss             | 85.57796    |
| training/sac_pi/alpha          | 0.17068136  |
| training/sac_pi/alpha_loss     | -0.05861564 |
| training/sac_pi/logp_pi        | 3.5940347   |
| training/sac_pi/pi_entropy     | 3.3185844   |
| training/sac_pi/pi_global_norm | 1.6941049   |
| training/sac_pi/policy_loss    | -227.02682  |
| training/sac_pi/std            | 0.46026656  |
| training/sac_pi/valid_num      | 5036.0      |
| training/sac_Q/q1              | 219.52055   |
| training/sac_Q/q2              | 219.86047   |
| training/sac_Q/q2_loss         | 84.07252    |
| training/sac_Q/q_global_norm   | 254.52293   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.165881    |
| epoch                          | 632         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4994.9673   |
| evaluation/return-max          | 5017.3223   |
| evaluation/return-min          | 4967.784    |
| evaluation/return-std          | 15.277701   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46242       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4994.9673   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 209.83435   |
| Q-std                          | 127.26084   |
| Q_loss                         | 89.42554    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 632         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000589    |
| times/evaluation_paths         | 34.2        |
| times/timestep_after_hook      | 0.00408     |
| times/timestep_before_hook     | 0.00846     |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 633000      |
| train-steps                    | 633000      |
| training/Q/q1_loss             | 139.27      |
| training/sac_pi/alpha          | 0.165912    |
| training/sac_pi/alpha_loss     | -0.15598862 |
| training/sac_pi/logp_pi        | 4.704705    |
| training/sac_pi/pi_entropy     | 3.5077362   |
| training/sac_pi/pi_global_norm | 1.9887704   |
| training/sac_pi/policy_loss    | -216.96106  |
| training/sac_pi/std            | 0.5348245   |
| training/sac_pi/valid_num      | 4943.0      |
| training/sac_Q/q1              | 203.82832   |
| training/sac_Q/q2              | 204.35835   |
| training/sac_Q/q2_loss         | 137.94125   |
| training/sac_Q/q_global_norm   | 350.9718    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1624024   |
| epoch                          | 633         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5269.504    |
| evaluation/return-max          | 5325.2793   |
| evaluation/return-min          | 5221.1396   |
| evaluation/return-std          | 37.10171    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46541       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5269.504    |
| perf/NormalizedReturn          | 1.15        |
| Q-avg                          | 206.01826   |
| Q-std                          | 114.51799   |
| Q_loss                         | 92.54316    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 633         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000274    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000548    |
| times/evaluation_paths         | 33.9        |
| times/timestep_after_hook      | 0.0042      |
| times/timestep_before_hook     | 0.00855     |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 634000      |
| train-steps                    | 634000      |
| training/Q/q1_loss             | 98.31229    |
| training/sac_pi/alpha          | 0.16238376  |
| training/sac_pi/alpha_loss     | -0.13849935 |
| training/sac_pi/logp_pi        | 3.5003676   |
| training/sac_pi/pi_entropy     | 3.4431129   |
| training/sac_pi/pi_global_norm | 1.5953002   |
| training/sac_pi/policy_loss    | -228.20673  |
| training/sac_pi/std            | 0.46738034  |
| training/sac_pi/valid_num      | 5015.0      |
| training/sac_Q/q1              | 223.36246   |
| training/sac_Q/q2              | 223.11856   |
| training/sac_Q/q2_loss         | 98.45941    |
| training/sac_Q/q_global_norm   | 255.89684   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16245922  |
| epoch                          | 634         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5114.935    |
| evaluation/return-max          | 5165.0366   |
| evaluation/return-min          | 5054.038    |
| evaluation/return-std          | 30.467306   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46335       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5114.935    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 211.21884   |
| Q-std                          | 96.26997    |
| Q_loss                         | 74.87625    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 634         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000521    |
| times/evaluation_paths         | 36          |
| times/timestep_after_hook      | 0.00418     |
| times/timestep_before_hook     | 0.00902     |
| times/train                    | 59.9        |
| timestep                       | 1000        |
| timesteps_total                | 635000      |
| train-steps                    | 635000      |
| training/Q/q1_loss             | 97.03091    |
| training/sac_pi/alpha          | 0.16246486  |
| training/sac_pi/alpha_loss     | -0.10220541 |
| training/sac_pi/logp_pi        | 4.6187143   |
| training/sac_pi/pi_entropy     | 3.236953    |
| training/sac_pi/pi_global_norm | 1.8103336   |
| training/sac_pi/policy_loss    | -222.12697  |
| training/sac_pi/std            | 0.48990032  |
| training/sac_pi/valid_num      | 4964.0      |
| training/sac_Q/q1              | 212.00607   |
| training/sac_Q/q2              | 211.08943   |
| training/sac_Q/q2_loss         | 97.000916   |
| training/sac_Q/q_global_norm   | 181.17088   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1728876  |
| epoch                          | 635        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5010.962   |
| evaluation/return-max          | 5050.038   |
| evaluation/return-min          | 4971.9844  |
| evaluation/return-std          | 20.521708  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46299      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5010.962   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 210.0728   |
| Q-std                          | 104.48553  |
| Q_loss                         | 100.95495  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 635        |
| times/epoch_after_hook         | 3.32e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000653   |
| times/evaluation_paths         | 33.4       |
| times/timestep_after_hook      | 0.00413    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 636000     |
| train-steps                    | 636000     |
| training/Q/q1_loss             | 87.0923    |
| training/sac_pi/alpha          | 0.17288187 |
| training/sac_pi/alpha_loss     | 0.2196027  |
| training/sac_pi/logp_pi        | 4.3693304  |
| training/sac_pi/pi_entropy     | 3.4873466  |
| training/sac_pi/pi_global_norm | 1.7288796  |
| training/sac_pi/policy_loss    | -217.07841 |
| training/sac_pi/std            | 0.4904159  |
| training/sac_pi/valid_num      | 4997.0     |
| training/sac_Q/q1              | 210.1462   |
| training/sac_Q/q2              | 209.42758  |
| training/sac_Q/q2_loss         | 87.03099   |
| training/sac_Q/q_global_norm   | 480.11557  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1697183  |
| epoch                          | 636        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5249.526   |
| evaluation/return-max          | 5276.6367  |
| evaluation/return-min          | 5212.0566  |
| evaluation/return-std          | 22.66292   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46443      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5249.526   |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 219.18193  |
| Q-std                          | 122.34702  |
| Q_loss                         | 91.296715  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 636        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000521   |
| times/evaluation_paths         | 36.5       |
| times/timestep_after_hook      | 0.00419    |
| times/timestep_before_hook     | 0.00867    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 637000     |
| train-steps                    | 637000     |
| training/Q/q1_loss             | 93.23017   |
| training/sac_pi/alpha          | 0.16969424 |
| training/sac_pi/alpha_loss     | 0.16695389 |
| training/sac_pi/logp_pi        | 3.88506    |
| training/sac_pi/pi_entropy     | 3.5301156  |
| training/sac_pi/pi_global_norm | 1.7393197  |
| training/sac_pi/policy_loss    | -223.29701 |
| training/sac_pi/std            | 0.48302618 |
| training/sac_pi/valid_num      | 4994.0     |
| training/sac_Q/q1              | 215.80034  |
| training/sac_Q/q2              | 216.02054  |
| training/sac_Q/q2_loss         | 93.25876   |
| training/sac_Q/q_global_norm   | 243.25363  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16796972  |
| epoch                          | 637         |
| evaluation/episode-length-avg  | 930         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 305         |
| evaluation/episode-length-std  | 208         |
| evaluation/return-average      | 4568.814    |
| evaluation/return-max          | 5013.799    |
| evaluation/return-min          | 1188.453    |
| evaluation/return-std          | 1127.824    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46120       |
| perf/AverageLength             | 930         |
| perf/AverageReturn             | 4568.814    |
| perf/NormalizedReturn          | 0.995       |
| Q-avg                          | 224.41101   |
| Q-std                          | 100.6362    |
| Q_loss                         | 98.01764    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 637         |
| times/epoch_after_hook         | 2.04e-06    |
| times/epoch_before_hook        | 0.000271    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000607    |
| times/evaluation_paths         | 31.9        |
| times/timestep_after_hook      | 0.00415     |
| times/timestep_before_hook     | 0.00854     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 638000      |
| train-steps                    | 638000      |
| training/Q/q1_loss             | 91.51012    |
| training/sac_pi/alpha          | 0.16797775  |
| training/sac_pi/alpha_loss     | -0.13140328 |
| training/sac_pi/logp_pi        | 4.083709    |
| training/sac_pi/pi_entropy     | 3.5847962   |
| training/sac_pi/pi_global_norm | 1.5369627   |
| training/sac_pi/policy_loss    | -224.68294  |
| training/sac_pi/std            | 0.5149631   |
| training/sac_pi/valid_num      | 4951.0      |
| training/sac_Q/q1              | 216.00032   |
| training/sac_Q/q2              | 215.08365   |
| training/sac_Q/q2_loss         | 90.976776   |
| training/sac_Q/q_global_norm   | 234.62103   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16539088   |
| epoch                          | 638          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4956.867     |
| evaluation/return-max          | 5121.5957    |
| evaluation/return-min          | 4845.972     |
| evaluation/return-std          | 97.14743     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.01         |
| model/origin_ret               | 85           |
| model/penalty_ret              | 80.4         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46166        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4956.867     |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 207.86462    |
| Q-std                          | 122.27094    |
| Q_loss                         | 88.601265    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 638          |
| times/epoch_after_hook         | 1.9e-06      |
| times/epoch_before_hook        | 0.000134     |
| times/epoch_rollout_model      | 488          |
| times/evaluation_metrics       | 0.00055      |
| times/evaluation_paths         | 34.4         |
| times/timestep_after_hook      | 0.00399      |
| times/timestep_before_hook     | 0.00827      |
| times/train                    | 62.5         |
| timestep                       | 1000         |
| timesteps_total                | 639000       |
| train-steps                    | 639000       |
| training/Q/q1_loss             | 97.1534      |
| training/sac_pi/alpha          | 0.16538751   |
| training/sac_pi/alpha_loss     | -0.057709437 |
| training/sac_pi/logp_pi        | 4.1966105    |
| training/sac_pi/pi_entropy     | 3.4264598    |
| training/sac_pi/pi_global_norm | 1.6781808    |
| training/sac_pi/policy_loss    | -216.87598   |
| training/sac_pi/std            | 0.4950531    |
| training/sac_pi/valid_num      | 4999.0       |
| training/sac_Q/q1              | 210.8355     |
| training/sac_Q/q2              | 210.70792    |
| training/sac_Q/q2_loss         | 98.137764    |
| training/sac_Q/q_global_norm   | 241.87839    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16803358  |
| epoch                          | 639         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4889.0283   |
| evaluation/return-max          | 4998.4043   |
| evaluation/return-min          | 4791.19     |
| evaluation/return-std          | 59.191      |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46370       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4889.0283   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 210.71347   |
| Q-std                          | 139.08488   |
| Q_loss                         | 84.132034   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 639         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000556    |
| times/evaluation_paths         | 34.7        |
| times/timestep_after_hook      | 0.00421     |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 640000      |
| train-steps                    | 640000      |
| training/Q/q1_loss             | 99.49622    |
| training/sac_pi/alpha          | 0.16805364  |
| training/sac_pi/alpha_loss     | 0.086214304 |
| training/sac_pi/logp_pi        | 3.7875798   |
| training/sac_pi/pi_entropy     | 3.4469674   |
| training/sac_pi/pi_global_norm | 1.8372182   |
| training/sac_pi/policy_loss    | -222.42325  |
| training/sac_pi/std            | 0.4746014   |
| training/sac_pi/valid_num      | 4993.0      |
| training/sac_Q/q1              | 215.20572   |
| training/sac_Q/q2              | 215.53691   |
| training/sac_Q/q2_loss         | 99.63913    |
| training/sac_Q/q_global_norm   | 285.22217   |
---------------------------------------------------------------------------------
[WARN] 640 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16815121 |
| epoch                          | 640        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4855.2515  |
| evaluation/return-max          | 4895.826   |
| evaluation/return-min          | 4781.824   |
| evaluation/return-std          | 30.315773  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46232      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4855.2515  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 211.452    |
| Q-std                          | 93.412384  |
| Q_loss                         | 121.70324  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 640        |
| times/epoch_after_hook         | 2.1e-06    |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000515   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.00864    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 641000     |
| train-steps                    | 641000     |
| training/Q/q1_loss             | 94.39751   |
| training/sac_pi/alpha          | 0.16813608 |
| training/sac_pi/alpha_loss     | 0.18582563 |
| training/sac_pi/logp_pi        | 4.6943183  |
| training/sac_pi/pi_entropy     | 3.56807    |
| training/sac_pi/pi_global_norm | 1.4365886  |
| training/sac_pi/policy_loss    | -222.63718 |
| training/sac_pi/std            | 0.5468056  |
| training/sac_pi/valid_num      | 4959.0     |
| training/sac_Q/q1              | 213.38644  |
| training/sac_Q/q2              | 212.40503  |
| training/sac_Q/q2_loss         | 94.46975   |
| training/sac_Q/q_global_norm   | 218.98848  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1717577  |
| epoch                          | 641        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4790.486   |
| evaluation/return-max          | 4851.1123  |
| evaluation/return-min          | 4727.719   |
| evaluation/return-std          | 40.660072  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46378      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4790.486   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 204.75461  |
| Q-std                          | 133.5929   |
| Q_loss                         | 79.82495   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 641        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000317   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000518   |
| times/evaluation_paths         | 37.1       |
| times/timestep_after_hook      | 0.0043     |
| times/timestep_before_hook     | 0.00842    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 642000     |
| train-steps                    | 642000     |
| training/Q/q1_loss             | 90.878654  |
| training/sac_pi/alpha          | 0.17174855 |
| training/sac_pi/alpha_loss     | 0.20815346 |
| training/sac_pi/logp_pi        | 3.9712384  |
| training/sac_pi/pi_entropy     | 3.403811   |
| training/sac_pi/pi_global_norm | 1.5046952  |
| training/sac_pi/policy_loss    | -218.96078 |
| training/sac_pi/std            | 0.47931612 |
| training/sac_pi/valid_num      | 5024.0     |
| training/sac_Q/q1              | 213.46423  |
| training/sac_Q/q2              | 212.42957  |
| training/sac_Q/q2_loss         | 91.062645  |
| training/sac_Q/q_global_norm   | 256.9809   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16963045 |
| epoch                          | 642        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4991.2363  |
| evaluation/return-max          | 5021.6387  |
| evaluation/return-min          | 4918.227   |
| evaluation/return-std          | 28.63221   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46391      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4991.2363  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 208.95923  |
| Q-std                          | 126.49301  |
| Q_loss                         | 105.056366 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 642        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000683   |
| times/evaluation_paths         | 35.8       |
| times/timestep_after_hook      | 0.00412    |
| times/timestep_before_hook     | 0.00862    |
| times/train                    | 59.9       |
| timestep                       | 1000       |
| timesteps_total                | 643000     |
| train-steps                    | 643000     |
| training/Q/q1_loss             | 123.047646 |
| training/sac_pi/alpha          | 0.16955294 |
| training/sac_pi/alpha_loss     | 0.6005205  |
| training/sac_pi/logp_pi        | 4.0621023  |
| training/sac_pi/pi_entropy     | 3.4534378  |
| training/sac_pi/pi_global_norm | 1.4788206  |
| training/sac_pi/policy_loss    | -217.18712 |
| training/sac_pi/std            | 0.47493184 |
| training/sac_pi/valid_num      | 4928.0     |
| training/sac_Q/q1              | 208.36116  |
| training/sac_Q/q2              | 208.03357  |
| training/sac_Q/q2_loss         | 123.949165 |
| training/sac_Q/q_global_norm   | 242.27565  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16362558 |
| epoch                          | 643        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4907.132   |
| evaluation/return-max          | 4929.375   |
| evaluation/return-min          | 4837.196   |
| evaluation/return-std          | 27.265411  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 87.6       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46208      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4907.132   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 202.31462  |
| Q-std                          | 120.058235 |
| Q_loss                         | 111.8167   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 643        |
| times/epoch_after_hook         | 3.87e-06   |
| times/epoch_before_hook        | 0.000141   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.00059    |
| times/evaluation_paths         | 36.5       |
| times/timestep_after_hook      | 0.00406    |
| times/timestep_before_hook     | 0.00885    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 644000     |
| train-steps                    | 644000     |
| training/Q/q1_loss             | 87.96058   |
| training/sac_pi/alpha          | 0.16360594 |
| training/sac_pi/alpha_loss     | 0.44670054 |
| training/sac_pi/logp_pi        | 4.7730803  |
| training/sac_pi/pi_entropy     | 3.4382248  |
| training/sac_pi/pi_global_norm | 1.7311584  |
| training/sac_pi/policy_loss    | -219.54518 |
| training/sac_pi/std            | 0.52223784 |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 209.80103  |
| training/sac_Q/q2              | 208.33589  |
| training/sac_Q/q2_loss         | 87.69487   |
| training/sac_Q/q_global_norm   | 247.11398  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16288745 |
| epoch                          | 644        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5287.745   |
| evaluation/return-max          | 5360.366   |
| evaluation/return-min          | 5252.786   |
| evaluation/return-std          | 34.835674  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46295      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5287.745   |
| perf/NormalizedReturn          | 1.15       |
| Q-avg                          | 216.33936  |
| Q-std                          | 117.77502  |
| Q_loss                         | 70.773796  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 644        |
| times/epoch_after_hook         | 2.14e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000787   |
| times/evaluation_paths         | 34.7       |
| times/timestep_after_hook      | 0.00419    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 59.5       |
| timestep                       | 1000       |
| timesteps_total                | 645000     |
| train-steps                    | 645000     |
| training/Q/q1_loss             | 91.22745   |
| training/sac_pi/alpha          | 0.16291031 |
| training/sac_pi/alpha_loss     | -0.2078857 |
| training/sac_pi/logp_pi        | 3.8564606  |
| training/sac_pi/pi_entropy     | 3.156797   |
| training/sac_pi/pi_global_norm | 1.8852549  |
| training/sac_pi/policy_loss    | -227.56593 |
| training/sac_pi/std            | 0.46514255 |
| training/sac_pi/valid_num      | 4998.0     |
| training/sac_Q/q1              | 220.58585  |
| training/sac_Q/q2              | 220.0922   |
| training/sac_Q/q2_loss         | 89.54508   |
| training/sac_Q/q_global_norm   | 263.0041   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1654373   |
| epoch                          | 645         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4899.086    |
| evaluation/return-max          | 4946.084    |
| evaluation/return-min          | 4805.4688   |
| evaluation/return-std          | 46.02057    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46251       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4899.086    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 202.12593   |
| Q-std                          | 133.47888   |
| Q_loss                         | 103.168785  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 645         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000268    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.00057     |
| times/evaluation_paths         | 34.7        |
| times/timestep_after_hook      | 0.004       |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 62.9        |
| timestep                       | 1000        |
| timesteps_total                | 646000      |
| train-steps                    | 646000      |
| training/Q/q1_loss             | 95.36663    |
| training/sac_pi/alpha          | 0.16545895  |
| training/sac_pi/alpha_loss     | -0.29965365 |
| training/sac_pi/logp_pi        | 3.6708443   |
| training/sac_pi/pi_entropy     | 3.3781688   |
| training/sac_pi/pi_global_norm | 2.0455546   |
| training/sac_pi/policy_loss    | -225.48357  |
| training/sac_pi/std            | 0.47130325  |
| training/sac_pi/valid_num      | 5012.0      |
| training/sac_Q/q1              | 213.20657   |
| training/sac_Q/q2              | 216.09502   |
| training/sac_Q/q2_loss         | 94.994995   |
| training/sac_Q/q_global_norm   | 215.70876   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16944791 |
| epoch                          | 646        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5042.131   |
| evaluation/return-max          | 5122.6597  |
| evaluation/return-min          | 4937.15    |
| evaluation/return-std          | 57.22397   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46317      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5042.131   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 207.91171  |
| Q-std                          | 118.872856 |
| Q_loss                         | 94.79183   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 646        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000526   |
| times/evaluation_paths         | 35.6       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 647000     |
| train-steps                    | 647000     |
| training/Q/q1_loss             | 103.6987   |
| training/sac_pi/alpha          | 0.16946664 |
| training/sac_pi/alpha_loss     | -0.3497758 |
| training/sac_pi/logp_pi        | 4.5941772  |
| training/sac_pi/pi_entropy     | 3.488723   |
| training/sac_pi/pi_global_norm | 1.5793434  |
| training/sac_pi/policy_loss    | -217.85818 |
| training/sac_pi/std            | 0.5257658  |
| training/sac_pi/valid_num      | 4951.0     |
| training/sac_Q/q1              | 206.70328  |
| training/sac_Q/q2              | 207.03784  |
| training/sac_Q/q2_loss         | 103.288155 |
| training/sac_Q/q_global_norm   | 281.8983   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1705047   |
| epoch                          | 647         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4945.705    |
| evaluation/return-max          | 5050.2153   |
| evaluation/return-min          | 4838.1104   |
| evaluation/return-std          | 69.71335    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 80.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46301       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4945.705    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 204.04948   |
| Q-std                          | 134.22325   |
| Q_loss                         | 125.51097   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 647         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000518    |
| times/evaluation_paths         | 34.6        |
| times/timestep_after_hook      | 0.00386     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 59.1        |
| timestep                       | 1000        |
| timesteps_total                | 648000      |
| train-steps                    | 648000      |
| training/Q/q1_loss             | 89.331795   |
| training/sac_pi/alpha          | 0.17052393  |
| training/sac_pi/alpha_loss     | -0.19794717 |
| training/sac_pi/logp_pi        | 4.367101    |
| training/sac_pi/pi_entropy     | 3.644812    |
| training/sac_pi/pi_global_norm | 1.8056831   |
| training/sac_pi/policy_loss    | -225.80962  |
| training/sac_pi/std            | 0.5205451   |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 214.58115   |
| training/sac_Q/q2              | 216.13992   |
| training/sac_Q/q2_loss         | 90.379196   |
| training/sac_Q/q_global_norm   | 341.47778   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16829264  |
| epoch                          | 648         |
| evaluation/episode-length-avg  | 929         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 291         |
| evaluation/episode-length-std  | 213         |
| evaluation/return-average      | 4522.4424   |
| evaluation/return-max          | 4958.994    |
| evaluation/return-min          | 941.42114   |
| evaluation/return-std          | 1194.116    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46298       |
| perf/AverageLength             | 929         |
| perf/AverageReturn             | 4522.4424   |
| perf/NormalizedReturn          | 0.985       |
| Q-avg                          | 205.13359   |
| Q-std                          | 160.5393    |
| Q_loss                         | 88.034874   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 648         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.00061     |
| times/evaluation_paths         | 32.2        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.00847     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 649000      |
| train-steps                    | 649000      |
| training/Q/q1_loss             | 77.07034    |
| training/sac_pi/alpha          | 0.16831192  |
| training/sac_pi/alpha_loss     | -0.30790058 |
| training/sac_pi/logp_pi        | 4.3685236   |
| training/sac_pi/pi_entropy     | 3.2463136   |
| training/sac_pi/pi_global_norm | 1.9619988   |
| training/sac_pi/policy_loss    | -231.06758  |
| training/sac_pi/std            | 0.48388985  |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 225.72993   |
| training/sac_Q/q2              | 224.94543   |
| training/sac_Q/q2_loss         | 76.63694    |
| training/sac_Q/q_global_norm   | 170.64777   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16911241 |
| epoch                          | 649        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4666.6187  |
| evaluation/return-max          | 4700.5527  |
| evaluation/return-min          | 4621.124   |
| evaluation/return-std          | 25.806667  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46232      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4666.6187  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 205.2081   |
| Q-std                          | 135.03166  |
| Q_loss                         | 90.7563    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 649        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000262   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000515   |
| times/evaluation_paths         | 34.2       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 650000     |
| train-steps                    | 650000     |
| training/Q/q1_loss             | 92.158295  |
| training/sac_pi/alpha          | 0.16910478 |
| training/sac_pi/alpha_loss     | 0.39333266 |
| training/sac_pi/logp_pi        | 4.80461    |
| training/sac_pi/pi_entropy     | 3.25248    |
| training/sac_pi/pi_global_norm | 1.6157907  |
| training/sac_pi/policy_loss    | -226.34871 |
| training/sac_pi/std            | 0.4920525  |
| training/sac_pi/valid_num      | 4993.0     |
| training/sac_Q/q1              | 215.87881  |
| training/sac_Q/q2              | 217.82837  |
| training/sac_Q/q2_loss         | 92.67898   |
| training/sac_Q/q_global_norm   | 225.75372  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17052713  |
| epoch                          | 650         |
| evaluation/episode-length-avg  | 914         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 145         |
| evaluation/episode-length-std  | 256         |
| evaluation/return-average      | 4517.369    |
| evaluation/return-max          | 5029.9883   |
| evaluation/return-min          | 340.12817   |
| evaluation/return-std          | 1393.1013   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46150       |
| perf/AverageLength             | 914         |
| perf/AverageReturn             | 4517.369    |
| perf/NormalizedReturn          | 0.984       |
| Q-avg                          | 204.60834   |
| Q-std                          | 126.61366   |
| Q_loss                         | 103.62665   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 650         |
| times/epoch_after_hook         | 1.95e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000591    |
| times/evaluation_paths         | 33.6        |
| times/timestep_after_hook      | 0.00415     |
| times/timestep_before_hook     | 0.00862     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 651000      |
| train-steps                    | 651000      |
| training/Q/q1_loss             | 83.86064    |
| training/sac_pi/alpha          | 0.17054687  |
| training/sac_pi/alpha_loss     | -0.16945256 |
| training/sac_pi/logp_pi        | 3.7051158   |
| training/sac_pi/pi_entropy     | 3.380581    |
| training/sac_pi/pi_global_norm | 1.8811386   |
| training/sac_pi/policy_loss    | -225.73665  |
| training/sac_pi/std            | 0.4762213   |
| training/sac_pi/valid_num      | 4998.0      |
| training/sac_Q/q1              | 215.34726   |
| training/sac_Q/q2              | 217.71065   |
| training/sac_Q/q2_loss         | 83.66678    |
| training/sac_Q/q_global_norm   | 231.2607    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17208107 |
| epoch                          | 651        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4813.169   |
| evaluation/return-max          | 4925.628   |
| evaluation/return-min          | 4652.365   |
| evaluation/return-std          | 94.50461   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46392      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4813.169   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 207.06259  |
| Q-std                          | 129.47325  |
| Q_loss                         | 119.69723  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 651        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000147   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000597   |
| times/evaluation_paths         | 33.7       |
| times/timestep_after_hook      | 0.00419    |
| times/timestep_before_hook     | 0.00855    |
| times/train                    | 62.8       |
| timestep                       | 1000       |
| timesteps_total                | 652000     |
| train-steps                    | 652000     |
| training/Q/q1_loss             | 104.88697  |
| training/sac_pi/alpha          | 0.17207634 |
| training/sac_pi/alpha_loss     | 0.35784808 |
| training/sac_pi/logp_pi        | 4.397334   |
| training/sac_pi/pi_entropy     | 3.509089   |
| training/sac_pi/pi_global_norm | 2.364676   |
| training/sac_pi/policy_loss    | -214.59541 |
| training/sac_pi/std            | 0.4914971  |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 204.83047  |
| training/sac_Q/q2              | 205.66924  |
| training/sac_Q/q2_loss         | 103.40945  |
| training/sac_Q/q_global_norm   | 335.88315  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16831017  |
| epoch                          | 652         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5023.4194   |
| evaluation/return-max          | 5153.647    |
| evaluation/return-min          | 4756.186    |
| evaluation/return-std          | 121.66843   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46269       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5023.4194   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 213.21594   |
| Q-std                          | 124.1337    |
| Q_loss                         | 110.18873   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 652         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000624    |
| times/evaluation_paths         | 36.6        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.00846     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 653000      |
| train-steps                    | 653000      |
| training/Q/q1_loss             | 68.40207    |
| training/sac_pi/alpha          | 0.16832414  |
| training/sac_pi/alpha_loss     | -0.11214588 |
| training/sac_pi/logp_pi        | 3.6988227   |
| training/sac_pi/pi_entropy     | 3.5171757   |
| training/sac_pi/pi_global_norm | 1.3995559   |
| training/sac_pi/policy_loss    | -220.69524  |
| training/sac_pi/std            | 0.4839026   |
| training/sac_pi/valid_num      | 5019.0      |
| training/sac_Q/q1              | 214.62793   |
| training/sac_Q/q2              | 215.7907    |
| training/sac_Q/q2_loss         | 69.35368    |
| training/sac_Q/q_global_norm   | 179.74043   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16930032   |
| epoch                          | 653          |
| evaluation/episode-length-avg  | 969          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 686          |
| evaluation/episode-length-std  | 94.2         |
| evaluation/return-average      | 4969.715     |
| evaluation/return-max          | 5246.639     |
| evaluation/return-min          | 3352.5347    |
| evaluation/return-std          | 541.992      |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.03         |
| model/origin_ret               | 85           |
| model/penalty_ret              | 81.1         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46357        |
| perf/AverageLength             | 969          |
| perf/AverageReturn             | 4969.715     |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 214.38303    |
| Q-std                          | 127.895874   |
| Q_loss                         | 102.21095    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 653          |
| times/epoch_after_hook         | 1.77e-06     |
| times/epoch_before_hook        | 0.000443     |
| times/epoch_rollout_model      | 494          |
| times/evaluation_metrics       | 0.00053      |
| times/evaluation_paths         | 33.9         |
| times/timestep_after_hook      | 0.004        |
| times/timestep_before_hook     | 0.00852      |
| times/train                    | 61           |
| timestep                       | 1000         |
| timesteps_total                | 654000       |
| train-steps                    | 654000       |
| training/Q/q1_loss             | 109.91962    |
| training/sac_pi/alpha          | 0.169319     |
| training/sac_pi/alpha_loss     | -0.077797934 |
| training/sac_pi/logp_pi        | 4.3386445    |
| training/sac_pi/pi_entropy     | 3.5624542    |
| training/sac_pi/pi_global_norm | 2.162005     |
| training/sac_pi/policy_loss    | -218.0395    |
| training/sac_pi/std            | 0.52025616   |
| training/sac_pi/valid_num      | 4952.0       |
| training/sac_Q/q1              | 205.35176    |
| training/sac_Q/q2              | 206.45786    |
| training/sac_Q/q2_loss         | 110.12215    |
| training/sac_Q/q_global_norm   | 283.39694    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17191042  |
| epoch                          | 654         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4664.8467   |
| evaluation/return-max          | 4730.7534   |
| evaluation/return-min          | 4610.9775   |
| evaluation/return-std          | 35.973446   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46287       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4664.8467   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 214.18413   |
| Q-std                          | 120.8341    |
| Q_loss                         | 112.76422   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 654         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000687    |
| times/evaluation_paths         | 34.4        |
| times/timestep_after_hook      | 0.00416     |
| times/timestep_before_hook     | 0.00841     |
| times/train                    | 61.9        |
| timestep                       | 1000        |
| timesteps_total                | 655000      |
| train-steps                    | 655000      |
| training/Q/q1_loss             | 106.64751   |
| training/sac_pi/alpha          | 0.1719163   |
| training/sac_pi/alpha_loss     | -0.04700718 |
| training/sac_pi/logp_pi        | 4.220439    |
| training/sac_pi/pi_entropy     | 3.3190346   |
| training/sac_pi/pi_global_norm | 1.5054389   |
| training/sac_pi/policy_loss    | -225.53365  |
| training/sac_pi/std            | 0.46735522  |
| training/sac_pi/valid_num      | 4920.0      |
| training/sac_Q/q1              | 214.80472   |
| training/sac_Q/q2              | 214.08505   |
| training/sac_Q/q2_loss         | 106.35724   |
| training/sac_Q/q_global_norm   | 203.19096   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16838387  |
| epoch                          | 655         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4785.0127   |
| evaluation/return-max          | 4847.913    |
| evaluation/return-min          | 4736.154    |
| evaluation/return-std          | 32.683212   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46305       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4785.0127   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 218.03891   |
| Q-std                          | 91.09198    |
| Q_loss                         | 89.34331    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 655         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000147    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000509    |
| times/evaluation_paths         | 37          |
| times/timestep_after_hook      | 0.00415     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 61.5        |
| timestep                       | 1000        |
| timesteps_total                | 656000      |
| train-steps                    | 656000      |
| training/Q/q1_loss             | 92.750786   |
| training/sac_pi/alpha          | 0.16839647  |
| training/sac_pi/alpha_loss     | 0.035701998 |
| training/sac_pi/logp_pi        | 4.165797    |
| training/sac_pi/pi_entropy     | 3.3458924   |
| training/sac_pi/pi_global_norm | 1.7468988   |
| training/sac_pi/policy_loss    | -218.57748  |
| training/sac_pi/std            | 0.48045236  |
| training/sac_pi/valid_num      | 4966.0      |
| training/sac_Q/q1              | 209.63676   |
| training/sac_Q/q2              | 209.19055   |
| training/sac_Q/q2_loss         | 92.418434   |
| training/sac_Q/q_global_norm   | 203.92111   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16580358 |
| epoch                          | 656        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4992.953   |
| evaluation/return-max          | 5042.533   |
| evaluation/return-min          | 4931.4663  |
| evaluation/return-std          | 32.4505    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46320      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4992.953   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 219.20415  |
| Q-std                          | 109.8503   |
| Q_loss                         | 109.47119  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 656        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000587   |
| times/evaluation_paths         | 36.2       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 657000     |
| train-steps                    | 657000     |
| training/Q/q1_loss             | 120.069786 |
| training/sac_pi/alpha          | 0.16582698 |
| training/sac_pi/alpha_loss     | 0.05257446 |
| training/sac_pi/logp_pi        | 4.47111    |
| training/sac_pi/pi_entropy     | 3.398779   |
| training/sac_pi/pi_global_norm | 1.6418732  |
| training/sac_pi/policy_loss    | -219.10112 |
| training/sac_pi/std            | 0.49268925 |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 209.58537  |
| training/sac_Q/q2              | 209.81723  |
| training/sac_Q/q2_loss         | 118.96483  |
| training/sac_Q/q_global_norm   | 212.13715  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1697837   |
| epoch                          | 657         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4896.629    |
| evaluation/return-max          | 4921.01     |
| evaluation/return-min          | 4868.2793   |
| evaluation/return-std          | 17.29437    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46193       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4896.629    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 215.63669   |
| Q-std                          | 110.86886   |
| Q_loss                         | 87.58368    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 657         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.00035     |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000773    |
| times/evaluation_paths         | 38.5        |
| times/timestep_after_hook      | 0.00427     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 64.1        |
| timestep                       | 1000        |
| timesteps_total                | 658000      |
| train-steps                    | 658000      |
| training/Q/q1_loss             | 103.37059   |
| training/sac_pi/alpha          | 0.16977647  |
| training/sac_pi/alpha_loss     | -0.23381121 |
| training/sac_pi/logp_pi        | 5.0652757   |
| training/sac_pi/pi_entropy     | 3.6336524   |
| training/sac_pi/pi_global_norm | 1.65084     |
| training/sac_pi/policy_loss    | -223.73221  |
| training/sac_pi/std            | 0.55923235  |
| training/sac_pi/valid_num      | 4910.0      |
| training/sac_Q/q1              | 207.30415   |
| training/sac_Q/q2              | 202.92722   |
| training/sac_Q/q2_loss         | 104.15038   |
| training/sac_Q/q_global_norm   | 310.2454    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16490006  |
| epoch                          | 658         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5056.5527   |
| evaluation/return-max          | 5096.955    |
| evaluation/return-min          | 5003.9272   |
| evaluation/return-std          | 23.566662   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46186       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5056.5527   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 210.58658   |
| Q-std                          | 154.54959   |
| Q_loss                         | 98.03367    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 658         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000365    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000609    |
| times/evaluation_paths         | 38.3        |
| times/timestep_after_hook      | 0.00416     |
| times/timestep_before_hook     | 0.00859     |
| times/train                    | 62.1        |
| timestep                       | 1000        |
| timesteps_total                | 659000      |
| train-steps                    | 659000      |
| training/Q/q1_loss             | 125.736374  |
| training/sac_pi/alpha          | 0.16489147  |
| training/sac_pi/alpha_loss     | -0.20752488 |
| training/sac_pi/logp_pi        | 4.342941    |
| training/sac_pi/pi_entropy     | 3.554648    |
| training/sac_pi/pi_global_norm | 1.5983949   |
| training/sac_pi/policy_loss    | -222.03516  |
| training/sac_pi/std            | 0.5186732   |
| training/sac_pi/valid_num      | 4843.0      |
| training/sac_Q/q1              | 205.39653   |
| training/sac_Q/q2              | 206.4019    |
| training/sac_Q/q2_loss         | 124.3539    |
| training/sac_Q/q_global_norm   | 319.26645   |
---------------------------------------------------------------------------------
------------------------------------------------------------------------------------
| alpha                          | 0.16557242     |
| epoch                          | 659            |
| evaluation/episode-length-avg  | 1e+03          |
| evaluation/episode-length-max  | 1000           |
| evaluation/episode-length-min  | 1000           |
| evaluation/episode-length-std  | 0              |
| evaluation/return-average      | 4748.9097      |
| evaluation/return-max          | 4819.115       |
| evaluation/return-min          | 4703.431       |
| evaluation/return-std          | 38.872074      |
| model/max_penalty              | 7.27           |
| model/mean_rollout_length      | 20             |
| model/mean_rollout_reward      | 3.05           |
| model/origin_ret               | 85.1           |
| model/penalty_ret              | 80.8           |
| model/val_loss                 | 0.39125705     |
| model/valid_num                | 46299          |
| perf/AverageLength             | 1e+03          |
| perf/AverageReturn             | 4748.9097      |
| perf/NormalizedReturn          | 1.03           |
| Q-avg                          | 216.74527      |
| Q-std                          | 140.93842      |
| Q_loss                         | 109.238525     |
| sampler/episodes               | 0              |
| sampler/last-path-return       | 0              |
| sampler/max-path-return        | -inf           |
| sampler/pool-size              | 1000000        |
| sampler/total-samples          | 0              |
| time-step                      | 659            |
| times/epoch_after_hook         | 2.02e-06       |
| times/epoch_before_hook        | 0.00012        |
| times/epoch_rollout_model      | 509            |
| times/evaluation_metrics       | 0.000698       |
| times/evaluation_paths         | 35.8           |
| times/timestep_after_hook      | 0.004          |
| times/timestep_before_hook     | 0.00856        |
| times/train                    | 60.3           |
| timestep                       | 1000           |
| timesteps_total                | 660000         |
| train-steps                    | 660000         |
| training/Q/q1_loss             | 75.8711        |
| training/sac_pi/alpha          | 0.16554601     |
| training/sac_pi/alpha_loss     | -0.00028001648 |
| training/sac_pi/logp_pi        | 3.90764        |
| training/sac_pi/pi_entropy     | 3.366551       |
| training/sac_pi/pi_global_norm | 1.4244022      |
| training/sac_pi/policy_loss    | -231.9676      |
| training/sac_pi/std            | 0.47950763     |
| training/sac_pi/valid_num      | 4955.0         |
| training/sac_Q/q1              | 223.81474      |
| training/sac_Q/q2              | 222.91301      |
| training/sac_Q/q2_loss         | 76.22844       |
| training/sac_Q/q_global_norm   | 153.93129      |
------------------------------------------------------------------------------------
[WARN] 660 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16551429  |
| epoch                          | 660         |
| evaluation/episode-length-avg  | 979         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 792         |
| evaluation/episode-length-std  | 62.4        |
| evaluation/return-average      | 4605.6904   |
| evaluation/return-max          | 5091.5205   |
| evaluation/return-min          | 3448.8677   |
| evaluation/return-std          | 429.15015   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46426       |
| perf/AverageLength             | 979         |
| perf/AverageReturn             | 4605.6904   |
| perf/NormalizedReturn          | 1           |
| Q-avg                          | 229.15671   |
| Q-std                          | 86.19366    |
| Q_loss                         | 87.19646    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 660         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000171    |
| times/epoch_rollout_model      | 513         |
| times/evaluation_metrics       | 0.000544    |
| times/evaluation_paths         | 34.4        |
| times/timestep_after_hook      | 0.00434     |
| times/timestep_before_hook     | 0.00874     |
| times/train                    | 64.7        |
| timestep                       | 1000        |
| timesteps_total                | 661000      |
| train-steps                    | 661000      |
| training/Q/q1_loss             | 105.51022   |
| training/sac_pi/alpha          | 0.1655596   |
| training/sac_pi/alpha_loss     | -0.34867948 |
| training/sac_pi/logp_pi        | 3.6434486   |
| training/sac_pi/pi_entropy     | 3.3361988   |
| training/sac_pi/pi_global_norm | 1.593518    |
| training/sac_pi/policy_loss    | -226.54115  |
| training/sac_pi/std            | 0.46309078  |
| training/sac_pi/valid_num      | 5018.0      |
| training/sac_Q/q1              | 220.2902    |
| training/sac_Q/q2              | 221.9915    |
| training/sac_Q/q2_loss         | 106.45274   |
| training/sac_Q/q_global_norm   | 203.93404   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17239234  |
| epoch                          | 661         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4939.454    |
| evaluation/return-max          | 5008.5625   |
| evaluation/return-min          | 4897.6797   |
| evaluation/return-std          | 34.089878   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46331       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4939.454    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 222.75371   |
| Q-std                          | 104.30652   |
| Q_loss                         | 100.70381   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 661         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000314    |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000552    |
| times/evaluation_paths         | 35.7        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 662000      |
| train-steps                    | 662000      |
| training/Q/q1_loss             | 96.49355    |
| training/sac_pi/alpha          | 0.17240313  |
| training/sac_pi/alpha_loss     | -0.28931364 |
| training/sac_pi/logp_pi        | 4.262826    |
| training/sac_pi/pi_entropy     | 3.512963    |
| training/sac_pi/pi_global_norm | 1.650804    |
| training/sac_pi/policy_loss    | -212.8089   |
| training/sac_pi/std            | 0.5062147   |
| training/sac_pi/valid_num      | 4964.0      |
| training/sac_Q/q1              | 202.72163   |
| training/sac_Q/q2              | 202.85806   |
| training/sac_Q/q2_loss         | 95.315384   |
| training/sac_Q/q_global_norm   | 200.82327   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17704354 |
| epoch                          | 662        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5108.329   |
| evaluation/return-max          | 5156.401   |
| evaluation/return-min          | 5045.79    |
| evaluation/return-std          | 35.69285   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46260      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5108.329   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 211.3038   |
| Q-std                          | 112.611206 |
| Q_loss                         | 88.475426  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 662        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.00051    |
| times/evaluation_paths         | 38.5       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00851    |
| times/train                    | 62.6       |
| timestep                       | 1000       |
| timesteps_total                | 663000     |
| train-steps                    | 663000     |
| training/Q/q1_loss             | 82.50053   |
| training/sac_pi/alpha          | 0.17701893 |
| training/sac_pi/alpha_loss     | 0.3188587  |
| training/sac_pi/logp_pi        | 4.260894   |
| training/sac_pi/pi_entropy     | 3.504554   |
| training/sac_pi/pi_global_norm | 1.7587798  |
| training/sac_pi/policy_loss    | -215.13019 |
| training/sac_pi/std            | 0.4935966  |
| training/sac_pi/valid_num      | 4970.0     |
| training/sac_Q/q1              | 206.73535  |
| training/sac_Q/q2              | 206.56625  |
| training/sac_Q/q2_loss         | 81.644936  |
| training/sac_Q/q_global_norm   | 174.41441  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17301634 |
| epoch                          | 663        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5099.419   |
| evaluation/return-max          | 5124.6973  |
| evaluation/return-min          | 5068.8154  |
| evaluation/return-std          | 19.519104  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46201      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5099.419   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 207.33035  |
| Q-std                          | 121.89592  |
| Q_loss                         | 92.40654   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 663        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000139   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000615   |
| times/evaluation_paths         | 37.8       |
| times/timestep_after_hook      | 0.0043     |
| times/timestep_before_hook     | 0.00918    |
| times/train                    | 64.6       |
| timestep                       | 1000       |
| timesteps_total                | 664000     |
| train-steps                    | 664000     |
| training/Q/q1_loss             | 96.20938   |
| training/sac_pi/alpha          | 0.17305367 |
| training/sac_pi/alpha_loss     | -0.1343519 |
| training/sac_pi/logp_pi        | 4.159317   |
| training/sac_pi/pi_entropy     | 3.350499   |
| training/sac_pi/pi_global_norm | 1.9521251  |
| training/sac_pi/policy_loss    | -220.53438 |
| training/sac_pi/std            | 0.4781186  |
| training/sac_pi/valid_num      | 4959.0     |
| training/sac_Q/q1              | 213.55867  |
| training/sac_Q/q2              | 212.84268  |
| training/sac_Q/q2_loss         | 96.66547   |
| training/sac_Q/q_global_norm   | 243.32352  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16652526   |
| epoch                          | 664          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4856.721     |
| evaluation/return-max          | 4914.7734    |
| evaluation/return-min          | 4782.5317    |
| evaluation/return-std          | 40.953846    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.03         |
| model/origin_ret               | 85.4         |
| model/penalty_ret              | 81.7         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46245        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4856.721     |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 215.00656    |
| Q-std                          | 121.244804   |
| Q_loss                         | 97.97035     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 664          |
| times/epoch_after_hook         | 1.84e-06     |
| times/epoch_before_hook        | 0.000141     |
| times/epoch_rollout_model      | 530          |
| times/evaluation_metrics       | 0.000591     |
| times/evaluation_paths         | 62.1         |
| times/timestep_after_hook      | 0.0042       |
| times/timestep_before_hook     | 0.0085       |
| times/train                    | 71.5         |
| timestep                       | 1000         |
| timesteps_total                | 665000       |
| train-steps                    | 665000       |
| training/Q/q1_loss             | 96.568695    |
| training/sac_pi/alpha          | 0.16651234   |
| training/sac_pi/alpha_loss     | -0.022113016 |
| training/sac_pi/logp_pi        | 4.318713     |
| training/sac_pi/pi_entropy     | 3.223365     |
| training/sac_pi/pi_global_norm | 1.7857727    |
| training/sac_pi/policy_loss    | -219.50829   |
| training/sac_pi/std            | 0.47059825   |
| training/sac_pi/valid_num      | 4944.0       |
| training/sac_Q/q1              | 207.53374    |
| training/sac_Q/q2              | 209.44629    |
| training/sac_Q/q2_loss         | 96.21406     |
| training/sac_Q/q_global_norm   | 292.01224    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16919488 |
| epoch                          | 665        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5121.702   |
| evaluation/return-max          | 5174.098   |
| evaluation/return-min          | 5053.6426  |
| evaluation/return-std          | 35.109276  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46287      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5121.702   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 220.28723  |
| Q-std                          | 122.17917  |
| Q_loss                         | 114.845665 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 665        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000362   |
| times/epoch_rollout_model      | 514        |
| times/evaluation_metrics       | 0.000527   |
| times/evaluation_paths         | 51.6       |
| times/timestep_after_hook      | 0.00418    |
| times/timestep_before_hook     | 0.0089     |
| times/train                    | 87.2       |
| timestep                       | 1000       |
| timesteps_total                | 666000     |
| train-steps                    | 666000     |
| training/Q/q1_loss             | 91.9976    |
| training/sac_pi/alpha          | 0.16921657 |
| training/sac_pi/alpha_loss     | -0.7405292 |
| training/sac_pi/logp_pi        | 3.6138084  |
| training/sac_pi/pi_entropy     | 3.2964458  |
| training/sac_pi/pi_global_norm | 1.6957241  |
| training/sac_pi/policy_loss    | -227.2116  |
| training/sac_pi/std            | 0.47133034 |
| training/sac_pi/valid_num      | 4935.0     |
| training/sac_Q/q1              | 219.45044  |
| training/sac_Q/q2              | 219.5395   |
| training/sac_Q/q2_loss         | 93.15986   |
| training/sac_Q/q_global_norm   | 305.13345  |
--------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.17248969    |
| epoch                          | 666           |
| evaluation/episode-length-avg  | 1e+03         |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 1000          |
| evaluation/episode-length-std  | 0             |
| evaluation/return-average      | 4864.5034     |
| evaluation/return-max          | 4934.5938     |
| evaluation/return-min          | 4824.7397     |
| evaluation/return-std          | 30.051764     |
| model/max_penalty              | 7.27          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 3.09          |
| model/origin_ret               | 86.4          |
| model/penalty_ret              | 81.3          |
| model/val_loss                 | 0.39125705    |
| model/valid_num                | 46312         |
| perf/AverageLength             | 1e+03         |
| perf/AverageReturn             | 4864.5034     |
| perf/NormalizedReturn          | 1.06          |
| Q-avg                          | 218.73262     |
| Q-std                          | 110.6829      |
| Q_loss                         | 77.86402      |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 666           |
| times/epoch_after_hook         | 1.86e-06      |
| times/epoch_before_hook        | 0.000133      |
| times/epoch_rollout_model      | 506           |
| times/evaluation_metrics       | 0.000565      |
| times/evaluation_paths         | 47.2          |
| times/timestep_after_hook      | 0.00414       |
| times/timestep_before_hook     | 0.00869       |
| times/train                    | 81.8          |
| timestep                       | 1000          |
| timesteps_total                | 667000        |
| train-steps                    | 667000        |
| training/Q/q1_loss             | 106.1753      |
| training/sac_pi/alpha          | 0.17249927    |
| training/sac_pi/alpha_loss     | -0.0024591428 |
| training/sac_pi/logp_pi        | 4.347398      |
| training/sac_pi/pi_entropy     | 3.4412434     |
| training/sac_pi/pi_global_norm | 1.7689822     |
| training/sac_pi/policy_loss    | -224.07156    |
| training/sac_pi/std            | 0.5023973     |
| training/sac_pi/valid_num      | 4976.0        |
| training/sac_Q/q1              | 214.66882     |
| training/sac_Q/q2              | 214.8376      |
| training/sac_Q/q2_loss         | 105.36678     |
| training/sac_Q/q_global_norm   | 251.68983     |
-----------------------------------------------------------------------------------
------------------------------------------------------------------------------------
| alpha                          | 0.16910417     |
| epoch                          | 667            |
| evaluation/episode-length-avg  | 1e+03          |
| evaluation/episode-length-max  | 1000           |
| evaluation/episode-length-min  | 1000           |
| evaluation/episode-length-std  | 0              |
| evaluation/return-average      | 4930.898       |
| evaluation/return-max          | 5000.324       |
| evaluation/return-min          | 4776.736       |
| evaluation/return-std          | 71.080376      |
| model/max_penalty              | 7.27           |
| model/mean_rollout_length      | 20             |
| model/mean_rollout_reward      | 3.01           |
| model/origin_ret               | 85.3           |
| model/penalty_ret              | 80.5           |
| model/val_loss                 | 0.39125705     |
| model/valid_num                | 46239          |
| perf/AverageLength             | 1e+03          |
| perf/AverageReturn             | 4930.898       |
| perf/NormalizedReturn          | 1.07           |
| Q-avg                          | 208.92867      |
| Q-std                          | 121.44799      |
| Q_loss                         | 103.283554     |
| sampler/episodes               | 0              |
| sampler/last-path-return       | 0              |
| sampler/max-path-return        | -inf           |
| sampler/pool-size              | 1000000        |
| sampler/total-samples          | 0              |
| time-step                      | 667            |
| times/epoch_after_hook         | 1.89e-06       |
| times/epoch_before_hook        | 0.000138       |
| times/epoch_rollout_model      | 512            |
| times/evaluation_metrics       | 0.00077        |
| times/evaluation_paths         | 48.2           |
| times/timestep_after_hook      | 0.00403        |
| times/timestep_before_hook     | 0.0085         |
| times/train                    | 75.9           |
| timestep                       | 1000           |
| timesteps_total                | 668000         |
| train-steps                    | 668000         |
| training/Q/q1_loss             | 98.12836       |
| training/sac_pi/alpha          | 0.16906856     |
| training/sac_pi/alpha_loss     | -0.00065242103 |
| training/sac_pi/logp_pi        | 4.3325944      |
| training/sac_pi/pi_entropy     | 3.3748727      |
| training/sac_pi/pi_global_norm | 2.3488433      |
| training/sac_pi/policy_loss    | -222.58734     |
| training/sac_pi/std            | 0.5005576      |
| training/sac_pi/valid_num      | 4919.0         |
| training/sac_Q/q1              | 210.74239      |
| training/sac_Q/q2              | 210.08199      |
| training/sac_Q/q2_loss         | 99.44459       |
| training/sac_Q/q_global_norm   | 201.26578      |
------------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17245634  |
| epoch                          | 668         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5128.258    |
| evaluation/return-max          | 5162.225    |
| evaluation/return-min          | 5107.6797   |
| evaluation/return-std          | 17.176619   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46243       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5128.258    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 206.12886   |
| Q-std                          | 151.4296    |
| Q_loss                         | 109.99548   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 668         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000315    |
| times/epoch_rollout_model      | 503         |
| times/evaluation_metrics       | 0.000533    |
| times/evaluation_paths         | 51.6        |
| times/timestep_after_hook      | 0.00432     |
| times/timestep_before_hook     | 0.00877     |
| times/train                    | 76.6        |
| timestep                       | 1000        |
| timesteps_total                | 669000      |
| train-steps                    | 669000      |
| training/Q/q1_loss             | 107.5627    |
| training/sac_pi/alpha          | 0.17242445  |
| training/sac_pi/alpha_loss     | 0.058309674 |
| training/sac_pi/logp_pi        | 4.0768585   |
| training/sac_pi/pi_entropy     | 3.5151436   |
| training/sac_pi/pi_global_norm | 1.6101017   |
| training/sac_pi/policy_loss    | -224.01265  |
| training/sac_pi/std            | 0.48693976  |
| training/sac_pi/valid_num      | 4958.0      |
| training/sac_Q/q1              | 216.6228    |
| training/sac_Q/q2              | 217.08955   |
| training/sac_Q/q2_loss         | 108.16114   |
| training/sac_Q/q_global_norm   | 322.08896   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16877243  |
| epoch                          | 669         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4905.7246   |
| evaluation/return-max          | 4940.965    |
| evaluation/return-min          | 4844.6436   |
| evaluation/return-std          | 31.454391   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 45958       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4905.7246   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 212.51436   |
| Q-std                          | 116.165436  |
| Q_loss                         | 93.84132    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 669         |
| times/epoch_after_hook         | 2.07e-06    |
| times/epoch_before_hook        | 0.00026     |
| times/epoch_rollout_model      | 506         |
| times/evaluation_metrics       | 0.00076     |
| times/evaluation_paths         | 36.2        |
| times/timestep_after_hook      | 0.00417     |
| times/timestep_before_hook     | 0.00853     |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 670000      |
| train-steps                    | 670000      |
| training/Q/q1_loss             | 96.64743    |
| training/sac_pi/alpha          | 0.16880226  |
| training/sac_pi/alpha_loss     | -0.12919632 |
| training/sac_pi/logp_pi        | 4.4354844   |
| training/sac_pi/pi_entropy     | 3.3831496   |
| training/sac_pi/pi_global_norm | 1.4534938   |
| training/sac_pi/policy_loss    | -222.24055  |
| training/sac_pi/std            | 0.49906784  |
| training/sac_pi/valid_num      | 4962.0      |
| training/sac_Q/q1              | 211.02591   |
| training/sac_Q/q2              | 211.0824    |
| training/sac_Q/q2_loss         | 95.736664   |
| training/sac_Q/q_global_norm   | 183.89703   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16970341  |
| epoch                          | 670         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5029.2603   |
| evaluation/return-max          | 5118.09     |
| evaluation/return-min          | 4967.713    |
| evaluation/return-std          | 39.61432    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46215       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5029.2603   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 199.48451   |
| Q-std                          | 131.23521   |
| Q_loss                         | 115.512375  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 670         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000156    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000572    |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.00869     |
| times/train                    | 62.4        |
| timestep                       | 1000        |
| timesteps_total                | 671000      |
| train-steps                    | 671000      |
| training/Q/q1_loss             | 89.91318    |
| training/sac_pi/alpha          | 0.16971402  |
| training/sac_pi/alpha_loss     | 0.022821754 |
| training/sac_pi/logp_pi        | 3.9526935   |
| training/sac_pi/pi_entropy     | 3.4415653   |
| training/sac_pi/pi_global_norm | 1.4866574   |
| training/sac_pi/policy_loss    | -225.17783  |
| training/sac_pi/std            | 0.49048552  |
| training/sac_pi/valid_num      | 5023.0      |
| training/sac_Q/q1              | 217.21622   |
| training/sac_Q/q2              | 217.72519   |
| training/sac_Q/q2_loss         | 89.22854    |
| training/sac_Q/q_global_norm   | 223.08292   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1660629  |
| epoch                          | 671        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4959.62    |
| evaluation/return-max          | 5132.4805  |
| evaluation/return-min          | 4510.5215  |
| evaluation/return-std          | 183.06294  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46202      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4959.62    |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 213.24336  |
| Q-std                          | 112.64528  |
| Q_loss                         | 88.792175  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 671        |
| times/epoch_after_hook         | 2.21e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.00121    |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00415    |
| times/timestep_before_hook     | 0.00882    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 672000     |
| train-steps                    | 672000     |
| training/Q/q1_loss             | 106.53457  |
| training/sac_pi/alpha          | 0.166057   |
| training/sac_pi/alpha_loss     | 0.18591343 |
| training/sac_pi/logp_pi        | 4.305757   |
| training/sac_pi/pi_entropy     | 3.4260707  |
| training/sac_pi/pi_global_norm | 1.7649062  |
| training/sac_pi/policy_loss    | -220.31526 |
| training/sac_pi/std            | 0.49352428 |
| training/sac_pi/valid_num      | 4873.0     |
| training/sac_Q/q1              | 206.71347  |
| training/sac_Q/q2              | 206.56772  |
| training/sac_Q/q2_loss         | 105.92983  |
| training/sac_Q/q_global_norm   | 243.16867  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16533569  |
| epoch                          | 672         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4890.22     |
| evaluation/return-max          | 4953.744    |
| evaluation/return-min          | 4798.4434   |
| evaluation/return-std          | 49.160038   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46307       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4890.22     |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 210.11368   |
| Q-std                          | 108.066956  |
| Q_loss                         | 106.89151   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 672         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000138    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000578    |
| times/evaluation_paths         | 37.2        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.00866     |
| times/train                    | 63.5        |
| timestep                       | 1000        |
| timesteps_total                | 673000      |
| train-steps                    | 673000      |
| training/Q/q1_loss             | 94.31354    |
| training/sac_pi/alpha          | 0.16534455  |
| training/sac_pi/alpha_loss     | -0.38478053 |
| training/sac_pi/logp_pi        | 4.174217    |
| training/sac_pi/pi_entropy     | 3.3702683   |
| training/sac_pi/pi_global_norm | 1.57063     |
| training/sac_pi/policy_loss    | -228.30975  |
| training/sac_pi/std            | 0.5003207   |
| training/sac_pi/valid_num      | 4985.0      |
| training/sac_Q/q1              | 220.47066   |
| training/sac_Q/q2              | 219.94145   |
| training/sac_Q/q2_loss         | 93.125565   |
| training/sac_Q/q_global_norm   | 198.77318   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17195882 |
| epoch                          | 673        |
| evaluation/episode-length-avg  | 966        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 662        |
| evaluation/episode-length-std  | 101        |
| evaluation/return-average      | 4585.205   |
| evaluation/return-max          | 4842.917   |
| evaluation/return-min          | 2988.3735  |
| evaluation/return-std          | 533.87115  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46326      |
| perf/AverageLength             | 966        |
| perf/AverageReturn             | 4585.205   |
| perf/NormalizedReturn          | 0.998      |
| Q-avg                          | 212.43985  |
| Q-std                          | 131.07076  |
| Q_loss                         | 110.64155  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 673        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000269   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000534   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.0042     |
| times/timestep_before_hook     | 0.00864    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 674000     |
| train-steps                    | 674000     |
| training/Q/q1_loss             | 117.286446 |
| training/sac_pi/alpha          | 0.17194256 |
| training/sac_pi/alpha_loss     | 0.07406029 |
| training/sac_pi/logp_pi        | 4.1061354  |
| training/sac_pi/pi_entropy     | 3.4937356  |
| training/sac_pi/pi_global_norm | 1.4339621  |
| training/sac_pi/policy_loss    | -213.87006 |
| training/sac_pi/std            | 0.49682733 |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 208.61836  |
| training/sac_Q/q2              | 206.49716  |
| training/sac_Q/q2_loss         | 118.07882  |
| training/sac_Q/q_global_norm   | 211.74937  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16639292  |
| epoch                          | 674         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4932.136    |
| evaluation/return-max          | 4953.118    |
| evaluation/return-min          | 4914.292    |
| evaluation/return-std          | 13.162991   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46316       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4932.136    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 216.50699   |
| Q-std                          | 102.728775  |
| Q_loss                         | 115.10016   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 674         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.00062     |
| times/evaluation_paths         | 35.4        |
| times/timestep_after_hook      | 0.00412     |
| times/timestep_before_hook     | 0.00856     |
| times/train                    | 63.8        |
| timestep                       | 1000        |
| timesteps_total                | 675000      |
| train-steps                    | 675000      |
| training/Q/q1_loss             | 88.043655   |
| training/sac_pi/alpha          | 0.16637993  |
| training/sac_pi/alpha_loss     | 0.068547875 |
| training/sac_pi/logp_pi        | 3.6046357   |
| training/sac_pi/pi_entropy     | 3.339641    |
| training/sac_pi/pi_global_norm | 1.7663915   |
| training/sac_pi/policy_loss    | -222.73608  |
| training/sac_pi/std            | 0.46823218  |
| training/sac_pi/valid_num      | 4984.0      |
| training/sac_Q/q1              | 216.03056   |
| training/sac_Q/q2              | 215.34464   |
| training/sac_Q/q2_loss         | 88.91564    |
| training/sac_Q/q_global_norm   | 181.94304   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1686982  |
| epoch                          | 675        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4936.767   |
| evaluation/return-max          | 5119.7686  |
| evaluation/return-min          | 4752.278   |
| evaluation/return-std          | 107.30838  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46183      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4936.767   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 198.02751  |
| Q-std                          | 142.08727  |
| Q_loss                         | 118.005585 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 675        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000153   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000639   |
| times/evaluation_paths         | 37.1       |
| times/timestep_after_hook      | 0.00424    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 676000     |
| train-steps                    | 676000     |
| training/Q/q1_loss             | 100.900185 |
| training/sac_pi/alpha          | 0.16871291 |
| training/sac_pi/alpha_loss     | 0.16844301 |
| training/sac_pi/logp_pi        | 4.422979   |
| training/sac_pi/pi_entropy     | 3.639075   |
| training/sac_pi/pi_global_norm | 1.7612509  |
| training/sac_pi/policy_loss    | -218.41425 |
| training/sac_pi/std            | 0.52367103 |
| training/sac_pi/valid_num      | 4953.0     |
| training/sac_Q/q1              | 206.98286  |
| training/sac_Q/q2              | 206.25801  |
| training/sac_Q/q2_loss         | 101.39423  |
| training/sac_Q/q_global_norm   | 240.44638  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1670602   |
| epoch                          | 676         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4905.785    |
| evaluation/return-max          | 5007.5366   |
| evaluation/return-min          | 4746.2373   |
| evaluation/return-std          | 93.84319    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46002       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4905.785    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 210.80746   |
| Q-std                          | 126.69418   |
| Q_loss                         | 83.85701    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 676         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000652    |
| times/evaluation_paths         | 34.6        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 677000      |
| train-steps                    | 677000      |
| training/Q/q1_loss             | 92.79595    |
| training/sac_pi/alpha          | 0.1671116   |
| training/sac_pi/alpha_loss     | -0.27599272 |
| training/sac_pi/logp_pi        | 4.7743483   |
| training/sac_pi/pi_entropy     | 3.4952683   |
| training/sac_pi/pi_global_norm | 1.7245325   |
| training/sac_pi/policy_loss    | -222.16641  |
| training/sac_pi/std            | 0.5232343   |
| training/sac_pi/valid_num      | 4872.0      |
| training/sac_Q/q1              | 206.91093   |
| training/sac_Q/q2              | 208.35544   |
| training/sac_Q/q2_loss         | 92.11133    |
| training/sac_Q/q_global_norm   | 264.24265   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16811904  |
| epoch                          | 677         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5096.913    |
| evaluation/return-max          | 5218.4985   |
| evaluation/return-min          | 4971.0757   |
| evaluation/return-std          | 84.94479    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46209       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5096.913    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 204.51929   |
| Q-std                          | 116.41051   |
| Q_loss                         | 93.425865   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 677         |
| times/epoch_after_hook         | 2.13e-06    |
| times/epoch_before_hook        | 0.000259    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000539    |
| times/evaluation_paths         | 37.2        |
| times/timestep_after_hook      | 0.00412     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 62.1        |
| timestep                       | 1000        |
| timesteps_total                | 678000      |
| train-steps                    | 678000      |
| training/Q/q1_loss             | 94.51241    |
| training/sac_pi/alpha          | 0.16812582  |
| training/sac_pi/alpha_loss     | -0.21980992 |
| training/sac_pi/logp_pi        | 3.6669755   |
| training/sac_pi/pi_entropy     | 3.4630089   |
| training/sac_pi/pi_global_norm | 1.6151739   |
| training/sac_pi/policy_loss    | -224.17296  |
| training/sac_pi/std            | 0.48919284  |
| training/sac_pi/valid_num      | 4976.0      |
| training/sac_Q/q1              | 215.71729   |
| training/sac_Q/q2              | 216.83536   |
| training/sac_Q/q2_loss         | 94.66177    |
| training/sac_Q/q_global_norm   | 287.36707   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16079092   |
| epoch                          | 678          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5048.4062    |
| evaluation/return-max          | 5070.4985    |
| evaluation/return-min          | 5006.879     |
| evaluation/return-std          | 19.770761    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.02         |
| model/origin_ret               | 85.8         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46200        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5048.4062    |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 209.17618    |
| Q-std                          | 140.3475     |
| Q_loss                         | 117.75952    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 678          |
| times/epoch_after_hook         | 2.96e-06     |
| times/epoch_before_hook        | 0.00014      |
| times/epoch_rollout_model      | 496          |
| times/evaluation_metrics       | 0.00055      |
| times/evaluation_paths         | 34           |
| times/timestep_after_hook      | 0.00428      |
| times/timestep_before_hook     | 0.00833      |
| times/train                    | 62.1         |
| timestep                       | 1000         |
| timesteps_total                | 679000       |
| train-steps                    | 679000       |
| training/Q/q1_loss             | 89.11022     |
| training/sac_pi/alpha          | 0.16079332   |
| training/sac_pi/alpha_loss     | -0.060391687 |
| training/sac_pi/logp_pi        | 4.0557976    |
| training/sac_pi/pi_entropy     | 3.400106     |
| training/sac_pi/pi_global_norm | 1.4070522    |
| training/sac_pi/policy_loss    | -222.62048   |
| training/sac_pi/std            | 0.4877502    |
| training/sac_pi/valid_num      | 4974.0       |
| training/sac_Q/q1              | 216.19519    |
| training/sac_Q/q2              | 214.51836    |
| training/sac_Q/q2_loss         | 88.29791     |
| training/sac_Q/q_global_norm   | 208.91713    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16578504  |
| epoch                          | 679         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5063.7407   |
| evaluation/return-max          | 5095.9746   |
| evaluation/return-min          | 5020.374    |
| evaluation/return-std          | 21.676409   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46227       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5063.7407   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 202.2679    |
| Q-std                          | 128.63232   |
| Q_loss                         | 95.639946   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 679         |
| times/epoch_after_hook         | 1.93e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000525    |
| times/evaluation_paths         | 35.1        |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.00864     |
| times/train                    | 62.4        |
| timestep                       | 1000        |
| timesteps_total                | 680000      |
| train-steps                    | 680000      |
| training/Q/q1_loss             | 90.37159    |
| training/sac_pi/alpha          | 0.16574688  |
| training/sac_pi/alpha_loss     | -0.09648966 |
| training/sac_pi/logp_pi        | 4.0747967   |
| training/sac_pi/pi_entropy     | 3.5645595   |
| training/sac_pi/pi_global_norm | 1.4634149   |
| training/sac_pi/policy_loss    | -223.87553  |
| training/sac_pi/std            | 0.51533663  |
| training/sac_pi/valid_num      | 4970.0      |
| training/sac_Q/q1              | 216.56836   |
| training/sac_Q/q2              | 215.23885   |
| training/sac_Q/q2_loss         | 89.5385     |
| training/sac_Q/q_global_norm   | 202.79648   |
---------------------------------------------------------------------------------
[WARN] 680 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.1677672   |
| epoch                          | 680         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4972.0654   |
| evaluation/return-max          | 4992.0596   |
| evaluation/return-min          | 4950.0776   |
| evaluation/return-std          | 13.429237   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46271       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4972.0654   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 213.0981    |
| Q-std                          | 95.947      |
| Q_loss                         | 97.4592     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 680         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000247    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000558    |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.00858     |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 681000      |
| train-steps                    | 681000      |
| training/Q/q1_loss             | 100.692894  |
| training/sac_pi/alpha          | 0.16777614  |
| training/sac_pi/alpha_loss     | -0.17010692 |
| training/sac_pi/logp_pi        | 3.7172675   |
| training/sac_pi/pi_entropy     | 3.3898692   |
| training/sac_pi/pi_global_norm | 1.811633    |
| training/sac_pi/policy_loss    | -219.71376  |
| training/sac_pi/std            | 0.47042343  |
| training/sac_pi/valid_num      | 4992.0      |
| training/sac_Q/q1              | 213.75725   |
| training/sac_Q/q2              | 213.79224   |
| training/sac_Q/q2_loss         | 99.02593    |
| training/sac_Q/q_global_norm   | 220.4492    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1614489  |
| epoch                          | 681        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4875.2393  |
| evaluation/return-max          | 4906.29    |
| evaluation/return-min          | 4822.846   |
| evaluation/return-std          | 25.778715  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46251      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4875.2393  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 200.64204  |
| Q-std                          | 119.403465 |
| Q_loss                         | 105.28112  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 681        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000266   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000514   |
| times/evaluation_paths         | 35.6       |
| times/timestep_after_hook      | 0.00413    |
| times/timestep_before_hook     | 0.00866    |
| times/train                    | 63.3       |
| timestep                       | 1000       |
| timesteps_total                | 682000     |
| train-steps                    | 682000     |
| training/Q/q1_loss             | 103.91685  |
| training/sac_pi/alpha          | 0.16143386 |
| training/sac_pi/alpha_loss     | 0.2513137  |
| training/sac_pi/logp_pi        | 3.8726773  |
| training/sac_pi/pi_entropy     | 3.3208542  |
| training/sac_pi/pi_global_norm | 1.8431532  |
| training/sac_pi/policy_loss    | -215.25407 |
| training/sac_pi/std            | 0.46501502 |
| training/sac_pi/valid_num      | 4996.0     |
| training/sac_Q/q1              | 210.87814  |
| training/sac_Q/q2              | 209.64035  |
| training/sac_Q/q2_loss         | 104.06196  |
| training/sac_Q/q_global_norm   | 269.2481   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16153173 |
| epoch                          | 682        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4815.0693  |
| evaluation/return-max          | 4925.9453  |
| evaluation/return-min          | 4711.8296  |
| evaluation/return-std          | 55.911522  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46194      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4815.0693  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 209.88309  |
| Q-std                          | 109.55695  |
| Q_loss                         | 97.161705  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 682        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 505        |
| times/evaluation_metrics       | 0.000583   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.00424    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 62.2       |
| timestep                       | 1000       |
| timesteps_total                | 683000     |
| train-steps                    | 683000     |
| training/Q/q1_loss             | 85.82665   |
| training/sac_pi/alpha          | 0.16150828 |
| training/sac_pi/alpha_loss     | 0.31287006 |
| training/sac_pi/logp_pi        | 4.330489   |
| training/sac_pi/pi_entropy     | 3.423706   |
| training/sac_pi/pi_global_norm | 1.5973303  |
| training/sac_pi/policy_loss    | -222.08363 |
| training/sac_pi/std            | 0.49057138 |
| training/sac_pi/valid_num      | 4977.0     |
| training/sac_Q/q1              | 210.91292  |
| training/sac_Q/q2              | 212.27475  |
| training/sac_Q/q2_loss         | 85.48392   |
| training/sac_Q/q_global_norm   | 303.44373  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16662939  |
| epoch                          | 683         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5131.634    |
| evaluation/return-max          | 5197.126    |
| evaluation/return-min          | 5065.704    |
| evaluation/return-std          | 40.718784   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 83.1        |
| model/penalty_ret              | 80.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46318       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5131.634    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 211.62405   |
| Q-std                          | 175.73213   |
| Q_loss                         | 106.90674   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 683         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.00014     |
| times/epoch_rollout_model      | 504         |
| times/evaluation_metrics       | 0.000605    |
| times/evaluation_paths         | 36.2        |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.00862     |
| times/train                    | 64.4        |
| timestep                       | 1000        |
| timesteps_total                | 684000      |
| train-steps                    | 684000      |
| training/Q/q1_loss             | 94.961876   |
| training/sac_pi/alpha          | 0.1666382   |
| training/sac_pi/alpha_loss     | -0.14847939 |
| training/sac_pi/logp_pi        | 3.3387647   |
| training/sac_pi/pi_entropy     | 3.3886497   |
| training/sac_pi/pi_global_norm | 1.4887648   |
| training/sac_pi/policy_loss    | -222.61366  |
| training/sac_pi/std            | 0.4628584   |
| training/sac_pi/valid_num      | 5041.0      |
| training/sac_Q/q1              | 219.14163   |
| training/sac_Q/q2              | 219.26135   |
| training/sac_Q/q2_loss         | 95.39535    |
| training/sac_Q/q_global_norm   | 276.20502   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16760063 |
| epoch                          | 684        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5183.075   |
| evaluation/return-max          | 5206.9346  |
| evaluation/return-min          | 5143.2207  |
| evaluation/return-std          | 20.32165   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46154      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5183.075   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 211.49393  |
| Q-std                          | 115.93683  |
| Q_loss                         | 94.38253   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 684        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 514        |
| times/evaluation_metrics       | 0.000544   |
| times/evaluation_paths         | 39.8       |
| times/timestep_after_hook      | 0.00418    |
| times/timestep_before_hook     | 0.00855    |
| times/train                    | 65.5       |
| timestep                       | 1000       |
| timesteps_total                | 685000     |
| train-steps                    | 685000     |
| training/Q/q1_loss             | 95.04585   |
| training/sac_pi/alpha          | 0.16757491 |
| training/sac_pi/alpha_loss     | 0.4019964  |
| training/sac_pi/logp_pi        | 4.507663   |
| training/sac_pi/pi_entropy     | 3.3061142  |
| training/sac_pi/pi_global_norm | 1.6282222  |
| training/sac_pi/policy_loss    | -225.10556 |
| training/sac_pi/std            | 0.48498142 |
| training/sac_pi/valid_num      | 4995.0     |
| training/sac_Q/q1              | 218.3274   |
| training/sac_Q/q2              | 217.05586  |
| training/sac_Q/q2_loss         | 95.06627   |
| training/sac_Q/q_global_norm   | 257.0941   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15998887 |
| epoch                          | 685        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4741.4805  |
| evaluation/return-max          | 4833.301   |
| evaluation/return-min          | 4651.538   |
| evaluation/return-std          | 44.74685   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46149      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4741.4805  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 220.29599  |
| Q-std                          | 107.657906 |
| Q_loss                         | 92.878296  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 685        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000308   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.00069    |
| times/evaluation_paths         | 39.4       |
| times/timestep_after_hook      | 0.00422    |
| times/timestep_before_hook     | 0.00862    |
| times/train                    | 70         |
| timestep                       | 1000       |
| timesteps_total                | 686000     |
| train-steps                    | 686000     |
| training/Q/q1_loss             | 113.76237  |
| training/sac_pi/alpha          | 0.1599577  |
| training/sac_pi/alpha_loss     | 0.15592574 |
| training/sac_pi/logp_pi        | 4.6011434  |
| training/sac_pi/pi_entropy     | 3.6121883  |
| training/sac_pi/pi_global_norm | 3.1410992  |
| training/sac_pi/policy_loss    | -208.0186  |
| training/sac_pi/std            | 0.5358225  |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 198.18149  |
| training/sac_Q/q2              | 197.1055   |
| training/sac_Q/q2_loss         | 114.26545  |
| training/sac_Q/q_global_norm   | 227.1271   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16895556 |
| epoch                          | 686        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4788.1353  |
| evaluation/return-max          | 4860.957   |
| evaluation/return-min          | 4691.9404  |
| evaluation/return-std          | 43.58036   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46228      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4788.1353  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 204.97017  |
| Q-std                          | 147.58267  |
| Q_loss                         | 107.61906  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 686        |
| times/epoch_after_hook         | 3.44e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000594   |
| times/evaluation_paths         | 41.5       |
| times/timestep_after_hook      | 0.00432    |
| times/timestep_before_hook     | 0.0086     |
| times/train                    | 67.6       |
| timestep                       | 1000       |
| timesteps_total                | 687000     |
| train-steps                    | 687000     |
| training/Q/q1_loss             | 109.14207  |
| training/sac_pi/alpha          | 0.1689569  |
| training/sac_pi/alpha_loss     | 0.33864677 |
| training/sac_pi/logp_pi        | 3.5481286  |
| training/sac_pi/pi_entropy     | 3.341987   |
| training/sac_pi/pi_global_norm | 1.5577582  |
| training/sac_pi/policy_loss    | -219.52663 |
| training/sac_pi/std            | 0.45374662 |
| training/sac_pi/valid_num      | 5027.0     |
| training/sac_Q/q1              | 211.07935  |
| training/sac_Q/q2              | 211.85127  |
| training/sac_Q/q2_loss         | 108.13734  |
| training/sac_Q/q_global_norm   | 239.10413  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16352752  |
| epoch                          | 687         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4889.65     |
| evaluation/return-max          | 4962.629    |
| evaluation/return-min          | 4817.422    |
| evaluation/return-std          | 41.08882    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46218       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4889.65     |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 205.08232   |
| Q-std                          | 132.5064    |
| Q_loss                         | 83.15488    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 687         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 511         |
| times/evaluation_metrics       | 0.00077     |
| times/evaluation_paths         | 38          |
| times/timestep_after_hook      | 0.0042      |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 64.6        |
| timestep                       | 1000        |
| timesteps_total                | 688000      |
| train-steps                    | 688000      |
| training/Q/q1_loss             | 80.77714    |
| training/sac_pi/alpha          | 0.16353358  |
| training/sac_pi/alpha_loss     | -0.46975058 |
| training/sac_pi/logp_pi        | 3.950251    |
| training/sac_pi/pi_entropy     | 3.4245408   |
| training/sac_pi/pi_global_norm | 1.3923237   |
| training/sac_pi/policy_loss    | -224.18954  |
| training/sac_pi/std            | 0.5028004   |
| training/sac_pi/valid_num      | 4989.0      |
| training/sac_Q/q1              | 215.12259   |
| training/sac_Q/q2              | 216.46915   |
| training/sac_Q/q2_loss         | 81.55431    |
| training/sac_Q/q_global_norm   | 235.38264   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16544178 |
| epoch                          | 688        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4907.5205  |
| evaluation/return-max          | 4951.4814  |
| evaluation/return-min          | 4837.98    |
| evaluation/return-std          | 35.814236  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46343      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4907.5205  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 217.54155  |
| Q-std                          | 136.64326  |
| Q_loss                         | 83.34182   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 688        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000143   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000579   |
| times/evaluation_paths         | 40.4       |
| times/timestep_after_hook      | 0.00451    |
| times/timestep_before_hook     | 0.00892    |
| times/train                    | 66         |
| timestep                       | 1000       |
| timesteps_total                | 689000     |
| train-steps                    | 689000     |
| training/Q/q1_loss             | 108.53342  |
| training/sac_pi/alpha          | 0.16538428 |
| training/sac_pi/alpha_loss     | 0.45507184 |
| training/sac_pi/logp_pi        | 4.2170434  |
| training/sac_pi/pi_entropy     | 3.4465287  |
| training/sac_pi/pi_global_norm | 1.6013955  |
| training/sac_pi/policy_loss    | -216.56683 |
| training/sac_pi/std            | 0.48192278 |
| training/sac_pi/valid_num      | 5013.0     |
| training/sac_Q/q1              | 211.53198  |
| training/sac_Q/q2              | 210.79512  |
| training/sac_Q/q2_loss         | 107.69818  |
| training/sac_Q/q_global_norm   | 200.57303  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16441303   |
| epoch                          | 689          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5126.092     |
| evaluation/return-max          | 5197.247     |
| evaluation/return-min          | 5016.32      |
| evaluation/return-std          | 48.346886    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.1          |
| model/origin_ret               | 85.5         |
| model/penalty_ret              | 80.5         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46392        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5126.092     |
| perf/NormalizedReturn          | 1.12         |
| Q-avg                          | 217.78055    |
| Q-std                          | 102.69241    |
| Q_loss                         | 103.41848    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 689          |
| times/epoch_after_hook         | 1.93e-06     |
| times/epoch_before_hook        | 0.000263     |
| times/epoch_rollout_model      | 493          |
| times/evaluation_metrics       | 0.000622     |
| times/evaluation_paths         | 37.7         |
| times/timestep_after_hook      | 0.00418      |
| times/timestep_before_hook     | 0.00879      |
| times/train                    | 66.9         |
| timestep                       | 1000         |
| timesteps_total                | 690000       |
| train-steps                    | 690000       |
| training/Q/q1_loss             | 94.53668     |
| training/sac_pi/alpha          | 0.16440259   |
| training/sac_pi/alpha_loss     | -0.019791042 |
| training/sac_pi/logp_pi        | 4.042408     |
| training/sac_pi/pi_entropy     | 3.2897408    |
| training/sac_pi/pi_global_norm | 1.6241264    |
| training/sac_pi/policy_loss    | -225.88303   |
| training/sac_pi/std            | 0.47383907   |
| training/sac_pi/valid_num      | 5013.0       |
| training/sac_Q/q1              | 221.86816    |
| training/sac_Q/q2              | 220.07834    |
| training/sac_Q/q2_loss         | 94.06956     |
| training/sac_Q/q_global_norm   | 207.18144    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16356355 |
| epoch                          | 690        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4863.6396  |
| evaluation/return-max          | 4909.383   |
| evaluation/return-min          | 4798.396   |
| evaluation/return-std          | 37.365864  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46291      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4863.6396  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 207.8979   |
| Q-std                          | 122.066025 |
| Q_loss                         | 105.94298  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 690        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000151   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000645   |
| times/evaluation_paths         | 39.2       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00879    |
| times/train                    | 65.4       |
| timestep                       | 1000       |
| timesteps_total                | 691000     |
| train-steps                    | 691000     |
| training/Q/q1_loss             | 92.326454  |
| training/sac_pi/alpha          | 0.16353826 |
| training/sac_pi/alpha_loss     | 0.21961068 |
| training/sac_pi/logp_pi        | 4.7565794  |
| training/sac_pi/pi_entropy     | 3.3877327  |
| training/sac_pi/pi_global_norm | 1.6849335  |
| training/sac_pi/policy_loss    | -218.10518 |
| training/sac_pi/std            | 0.5070211  |
| training/sac_pi/valid_num      | 4919.0     |
| training/sac_Q/q1              | 206.73495  |
| training/sac_Q/q2              | 207.29675  |
| training/sac_Q/q2_loss         | 92.24907   |
| training/sac_Q/q_global_norm   | 167.16266  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16743973 |
| epoch                          | 691        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5176.3193  |
| evaluation/return-max          | 5200.6504  |
| evaluation/return-min          | 5146.0776  |
| evaluation/return-std          | 15.962717  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46067      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5176.3193  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 207.75346  |
| Q-std                          | 166.20288  |
| Q_loss                         | 121.256966 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 691        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000569   |
| times/evaluation_paths         | 36.3       |
| times/timestep_after_hook      | 0.00425    |
| times/timestep_before_hook     | 0.00865    |
| times/train                    | 65.4       |
| timestep                       | 1000       |
| timesteps_total                | 692000     |
| train-steps                    | 692000     |
| training/Q/q1_loss             | 105.37862  |
| training/sac_pi/alpha          | 0.16739477 |
| training/sac_pi/alpha_loss     | 0.32391158 |
| training/sac_pi/logp_pi        | 3.7592895  |
| training/sac_pi/pi_entropy     | 3.4553814  |
| training/sac_pi/pi_global_norm | 2.0036695  |
| training/sac_pi/policy_loss    | -218.65282 |
| training/sac_pi/std            | 0.46891874 |
| training/sac_pi/valid_num      | 5007.0     |
| training/sac_Q/q1              | 211.23477  |
| training/sac_Q/q2              | 212.29309  |
| training/sac_Q/q2_loss         | 105.5987   |
| training/sac_Q/q_global_norm   | 217.7658   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16958955 |
| epoch                          | 692        |
| evaluation/episode-length-avg  | 916        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 156        |
| evaluation/episode-length-std  | 253        |
| evaluation/return-average      | 4218.9893  |
| evaluation/return-max          | 4847.288   |
| evaluation/return-min          | 349.97495  |
| evaluation/return-std          | 1293.1857  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46192      |
| perf/AverageLength             | 916        |
| perf/AverageReturn             | 4218.9893  |
| perf/NormalizedReturn          | 0.919      |
| Q-avg                          | 208.93906  |
| Q-std                          | 112.74874  |
| Q_loss                         | 103.7703   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 692        |
| times/epoch_after_hook         | 2.05e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 508        |
| times/evaluation_metrics       | 0.000689   |
| times/evaluation_paths         | 31.6       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 693000     |
| train-steps                    | 693000     |
| training/Q/q1_loss             | 68.97116   |
| training/sac_pi/alpha          | 0.16956949 |
| training/sac_pi/alpha_loss     | 0.19937453 |
| training/sac_pi/logp_pi        | 3.9304097  |
| training/sac_pi/pi_entropy     | 3.2831504  |
| training/sac_pi/pi_global_norm | 1.6280724  |
| training/sac_pi/policy_loss    | -224.27892 |
| training/sac_pi/std            | 0.46623263 |
| training/sac_pi/valid_num      | 5002.0     |
| training/sac_Q/q1              | 217.8678   |
| training/sac_Q/q2              | 217.5603   |
| training/sac_Q/q2_loss         | 68.68037   |
| training/sac_Q/q_global_norm   | 128.65863  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16441125 |
| epoch                          | 693        |
| evaluation/episode-length-avg  | 877        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 315        |
| evaluation/episode-length-std  | 247        |
| evaluation/return-average      | 4121.9375  |
| evaluation/return-max          | 4874.06    |
| evaluation/return-min          | 1109.483   |
| evaluation/return-std          | 1331.1038  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46326      |
| perf/AverageLength             | 877        |
| perf/AverageReturn             | 4121.9375  |
| perf/NormalizedReturn          | 0.898      |
| Q-avg                          | 193.60922  |
| Q-std                          | 144.19585  |
| Q_loss                         | 99.05403   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 693        |
| times/epoch_after_hook         | 3.37e-06   |
| times/epoch_before_hook        | 0.000321   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000588   |
| times/evaluation_paths         | 33.1       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00842    |
| times/train                    | 64.8       |
| timestep                       | 1000       |
| timesteps_total                | 694000     |
| train-steps                    | 694000     |
| training/Q/q1_loss             | 114.44004  |
| training/sac_pi/alpha          | 0.16438873 |
| training/sac_pi/alpha_loss     | 0.24769023 |
| training/sac_pi/logp_pi        | 4.2543063  |
| training/sac_pi/pi_entropy     | 3.5043495  |
| training/sac_pi/pi_global_norm | 1.8019611  |
| training/sac_pi/policy_loss    | -220.33972 |
| training/sac_pi/std            | 0.5150016  |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 208.65791  |
| training/sac_Q/q2              | 208.59055  |
| training/sac_Q/q2_loss         | 114.91629  |
| training/sac_Q/q_global_norm   | 235.45976  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16814475   |
| epoch                          | 694          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4936.764     |
| evaluation/return-max          | 4988.5654    |
| evaluation/return-min          | 4863.1523    |
| evaluation/return-std          | 35.68146     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.02         |
| model/origin_ret               | 85.4         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46259        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4936.764     |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 216.69942    |
| Q-std                          | 137.9274     |
| Q_loss                         | 90.274666    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 694          |
| times/epoch_after_hook         | 1.81e-06     |
| times/epoch_before_hook        | 0.000133     |
| times/epoch_rollout_model      | 511          |
| times/evaluation_metrics       | 0.000619     |
| times/evaluation_paths         | 41.7         |
| times/timestep_after_hook      | 0.00411      |
| times/timestep_before_hook     | 0.00852      |
| times/train                    | 65.9         |
| timestep                       | 1000         |
| timesteps_total                | 695000       |
| train-steps                    | 695000       |
| training/Q/q1_loss             | 86.5563      |
| training/sac_pi/alpha          | 0.16813722   |
| training/sac_pi/alpha_loss     | -0.019953681 |
| training/sac_pi/logp_pi        | 4.7293963    |
| training/sac_pi/pi_entropy     | 3.6915126    |
| training/sac_pi/pi_global_norm | 1.4598355    |
| training/sac_pi/policy_loss    | -215.01248   |
| training/sac_pi/std            | 0.54293054   |
| training/sac_pi/valid_num      | 4950.0       |
| training/sac_Q/q1              | 206.82439    |
| training/sac_Q/q2              | 203.92355    |
| training/sac_Q/q2_loss         | 86.937996    |
| training/sac_Q/q_global_norm   | 281.57425    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16916479 |
| epoch                          | 695        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4991.258   |
| evaluation/return-max          | 5062.001   |
| evaluation/return-min          | 4830.3057  |
| evaluation/return-std          | 64.50373   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46290      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4991.258   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 218.12515  |
| Q-std                          | 121.15551  |
| Q_loss                         | 136.53275  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 695        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000507   |
| times/evaluation_paths         | 39.1       |
| times/timestep_after_hook      | 0.00438    |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 66.8       |
| timestep                       | 1000       |
| timesteps_total                | 696000     |
| train-steps                    | 696000     |
| training/Q/q1_loss             | 98.87443   |
| training/sac_pi/alpha          | 0.16917102 |
| training/sac_pi/alpha_loss     | 0.06760834 |
| training/sac_pi/logp_pi        | 4.242677   |
| training/sac_pi/pi_entropy     | 3.39634    |
| training/sac_pi/pi_global_norm | 1.5904553  |
| training/sac_pi/policy_loss    | -214.85988 |
| training/sac_pi/std            | 0.4868419  |
| training/sac_pi/valid_num      | 5003.0     |
| training/sac_Q/q1              | 208.77084  |
| training/sac_Q/q2              | 208.83987  |
| training/sac_Q/q2_loss         | 98.65771   |
| training/sac_Q/q_global_norm   | 254.04277  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16341865  |
| epoch                          | 696         |
| evaluation/episode-length-avg  | 884         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 681         |
| evaluation/episode-length-std  | 112         |
| evaluation/return-average      | 4287.949    |
| evaluation/return-max          | 5063.127    |
| evaluation/return-min          | 3061.7615   |
| evaluation/return-std          | 674.25793   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46154       |
| perf/AverageLength             | 884         |
| perf/AverageReturn             | 4287.949    |
| perf/NormalizedReturn          | 0.934       |
| Q-avg                          | 216.22197   |
| Q-std                          | 122.332794  |
| Q_loss                         | 76.44308    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 696         |
| times/epoch_after_hook         | 2.11e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000793    |
| times/evaluation_paths         | 34.6        |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.0087      |
| times/train                    | 64.6        |
| timestep                       | 1000        |
| timesteps_total                | 697000      |
| train-steps                    | 697000      |
| training/Q/q1_loss             | 95.38711    |
| training/sac_pi/alpha          | 0.16338356  |
| training/sac_pi/alpha_loss     | -0.02483958 |
| training/sac_pi/logp_pi        | 4.4417734   |
| training/sac_pi/pi_entropy     | 3.347477    |
| training/sac_pi/pi_global_norm | 1.6301997   |
| training/sac_pi/policy_loss    | -209.83037  |
| training/sac_pi/std            | 0.49369955  |
| training/sac_pi/valid_num      | 4988.0      |
| training/sac_Q/q1              | 200.71855   |
| training/sac_Q/q2              | 200.35359   |
| training/sac_Q/q2_loss         | 95.89005    |
| training/sac_Q/q_global_norm   | 190.15984   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16325729  |
| epoch                          | 697         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4995.987    |
| evaluation/return-max          | 5040.0776   |
| evaluation/return-min          | 4952.5303   |
| evaluation/return-std          | 32.89829    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46237       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4995.987    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 206.24387   |
| Q-std                          | 124.43215   |
| Q_loss                         | 107.39346   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 697         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000272    |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000814    |
| times/evaluation_paths         | 38.3        |
| times/timestep_after_hook      | 0.00428     |
| times/timestep_before_hook     | 0.00866     |
| times/train                    | 67.6        |
| timestep                       | 1000        |
| timesteps_total                | 698000      |
| train-steps                    | 698000      |
| training/Q/q1_loss             | 108.22639   |
| training/sac_pi/alpha          | 0.16326155  |
| training/sac_pi/alpha_loss     | -0.07403763 |
| training/sac_pi/logp_pi        | 3.8824627   |
| training/sac_pi/pi_entropy     | 3.2558162   |
| training/sac_pi/pi_global_norm | 1.4765177   |
| training/sac_pi/policy_loss    | -220.211    |
| training/sac_pi/std            | 0.4638595   |
| training/sac_pi/valid_num      | 5016.0      |
| training/sac_Q/q1              | 215.10852   |
| training/sac_Q/q2              | 215.48209   |
| training/sac_Q/q2_loss         | 109.74227   |
| training/sac_Q/q_global_norm   | 219.20143   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15982798  |
| epoch                          | 698         |
| evaluation/episode-length-avg  | 930         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 296         |
| evaluation/episode-length-std  | 211         |
| evaluation/return-average      | 4467.883    |
| evaluation/return-max          | 4988.414    |
| evaluation/return-min          | 1084.7012   |
| evaluation/return-std          | 1129.6094   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46398       |
| perf/AverageLength             | 930         |
| perf/AverageReturn             | 4467.883    |
| perf/NormalizedReturn          | 0.973       |
| Q-avg                          | 204.06595   |
| Q-std                          | 119.13548   |
| Q_loss                         | 86.977776   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 698         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000139    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000616    |
| times/evaluation_paths         | 41.6        |
| times/timestep_after_hook      | 0.00628     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 70.4        |
| timestep                       | 1000        |
| timesteps_total                | 699000      |
| train-steps                    | 699000      |
| training/Q/q1_loss             | 93.71392    |
| training/sac_pi/alpha          | 0.15984133  |
| training/sac_pi/alpha_loss     | -0.21841732 |
| training/sac_pi/logp_pi        | 4.6414375   |
| training/sac_pi/pi_entropy     | 3.1167865   |
| training/sac_pi/pi_global_norm | 1.953646    |
| training/sac_pi/policy_loss    | -224.57303  |
| training/sac_pi/std            | 0.47159925  |
| training/sac_pi/valid_num      | 4947.0      |
| training/sac_Q/q1              | 212.80025   |
| training/sac_Q/q2              | 212.15536   |
| training/sac_Q/q2_loss         | 91.728386   |
| training/sac_Q/q_global_norm   | 283.7076    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17019905 |
| epoch                          | 699        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5051.191   |
| evaluation/return-max          | 5083.849   |
| evaluation/return-min          | 5016.8223  |
| evaluation/return-std          | 20.859228  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46297      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5051.191   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 216.33484  |
| Q-std                          | 115.372314 |
| Q_loss                         | 97.18419   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 699        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000675   |
| times/evaluation_paths         | 38.9       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00855    |
| times/train                    | 66.1       |
| timestep                       | 1000       |
| timesteps_total                | 700000     |
| train-steps                    | 700000     |
| training/Q/q1_loss             | 110.67998  |
| training/sac_pi/alpha          | 0.17023991 |
| training/sac_pi/alpha_loss     | 0.09612863 |
| training/sac_pi/logp_pi        | 4.2756433  |
| training/sac_pi/pi_entropy     | 3.504947   |
| training/sac_pi/pi_global_norm | 2.456117   |
| training/sac_pi/policy_loss    | -213.90053 |
| training/sac_pi/std            | 0.49591193 |
| training/sac_pi/valid_num      | 4984.0     |
| training/sac_Q/q1              | 199.9527   |
| training/sac_Q/q2              | 201.97818  |
| training/sac_Q/q2_loss         | 110.33111  |
| training/sac_Q/q_global_norm   | 208.00043  |
--------------------------------------------------------------------------------
[WARN] 700 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.17530864 |
| epoch                          | 700        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4931.917   |
| evaluation/return-max          | 4977.098   |
| evaluation/return-min          | 4804.91    |
| evaluation/return-std          | 47.902496  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46335      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4931.917   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 215.70297  |
| Q-std                          | 130.62476  |
| Q_loss                         | 94.494514  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 700        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.00014    |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000582   |
| times/evaluation_paths         | 42         |
| times/timestep_after_hook      | 0.0041     |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 70.7       |
| timestep                       | 1000       |
| timesteps_total                | 701000     |
| train-steps                    | 701000     |
| training/Q/q1_loss             | 71.16487   |
| training/sac_pi/alpha          | 0.17531914 |
| training/sac_pi/alpha_loss     | 0.2404087  |
| training/sac_pi/logp_pi        | 4.446044   |
| training/sac_pi/pi_entropy     | 3.4171262  |
| training/sac_pi/pi_global_norm | 1.6709623  |
| training/sac_pi/policy_loss    | -223.70242 |
| training/sac_pi/std            | 0.49038202 |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 215.92505  |
| training/sac_Q/q2              | 216.04495  |
| training/sac_Q/q2_loss         | 70.579     |
| training/sac_Q/q_global_norm   | 193.02426  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16945899  |
| epoch                          | 701         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4824.421    |
| evaluation/return-max          | 4958.991    |
| evaluation/return-min          | 4676.103    |
| evaluation/return-std          | 86.91208    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46238       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4824.421    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 219.0787    |
| Q-std                          | 124.210976  |
| Q_loss                         | 97.90326    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 701         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000261    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000585    |
| times/evaluation_paths         | 38          |
| times/timestep_after_hook      | 0.00416     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 65          |
| timestep                       | 1000        |
| timesteps_total                | 702000      |
| train-steps                    | 702000      |
| training/Q/q1_loss             | 85.50321    |
| training/sac_pi/alpha          | 0.16946486  |
| training/sac_pi/alpha_loss     | -0.09066543 |
| training/sac_pi/logp_pi        | 4.371455    |
| training/sac_pi/pi_entropy     | 3.4588656   |
| training/sac_pi/pi_global_norm | 1.792416    |
| training/sac_pi/policy_loss    | -222.37346  |
| training/sac_pi/std            | 0.49182802  |
| training/sac_pi/valid_num      | 4961.0      |
| training/sac_Q/q1              | 217.34717   |
| training/sac_Q/q2              | 216.0079    |
| training/sac_Q/q2_loss         | 85.55516    |
| training/sac_Q/q_global_norm   | 197.27843   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17368487 |
| epoch                          | 702        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5112.3413  |
| evaluation/return-max          | 5289.039   |
| evaluation/return-min          | 4949.9272  |
| evaluation/return-std          | 104.20628  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46316      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5112.3413  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 206.55473  |
| Q-std                          | 144.1388   |
| Q_loss                         | 99.334366  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 702        |
| times/epoch_after_hook         | 3.23e-06   |
| times/epoch_before_hook        | 0.000156   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000527   |
| times/evaluation_paths         | 37.4       |
| times/timestep_after_hook      | 0.00454    |
| times/timestep_before_hook     | 0.00859    |
| times/train                    | 67.2       |
| timestep                       | 1000       |
| timesteps_total                | 703000     |
| train-steps                    | 703000     |
| training/Q/q1_loss             | 88.64991   |
| training/sac_pi/alpha          | 0.1736613  |
| training/sac_pi/alpha_loss     | 0.1632137  |
| training/sac_pi/logp_pi        | 4.293943   |
| training/sac_pi/pi_entropy     | 3.5319297  |
| training/sac_pi/pi_global_norm | 1.4752011  |
| training/sac_pi/policy_loss    | -217.56001 |
| training/sac_pi/std            | 0.49733165 |
| training/sac_pi/valid_num      | 5013.0     |
| training/sac_Q/q1              | 210.52097  |
| training/sac_Q/q2              | 210.80513  |
| training/sac_Q/q2_loss         | 88.67182   |
| training/sac_Q/q_global_norm   | 205.37634  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17088023  |
| epoch                          | 703         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4887.7905   |
| evaluation/return-max          | 4972.7065   |
| evaluation/return-min          | 4823.6343   |
| evaluation/return-std          | 50.202938   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46258       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4887.7905   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 216.34201   |
| Q-std                          | 123.64286   |
| Q_loss                         | 107.54734   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 703         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000138    |
| times/epoch_rollout_model      | 503         |
| times/evaluation_metrics       | 0.000532    |
| times/evaluation_paths         | 41.1        |
| times/timestep_after_hook      | 0.00415     |
| times/timestep_before_hook     | 0.00866     |
| times/train                    | 69.8        |
| timestep                       | 1000        |
| timesteps_total                | 704000      |
| train-steps                    | 704000      |
| training/Q/q1_loss             | 101.941414  |
| training/sac_pi/alpha          | 0.17088117  |
| training/sac_pi/alpha_loss     | 0.089968465 |
| training/sac_pi/logp_pi        | 4.060756    |
| training/sac_pi/pi_entropy     | 3.4118118   |
| training/sac_pi/pi_global_norm | 1.6863021   |
| training/sac_pi/policy_loss    | -221.90094  |
| training/sac_pi/std            | 0.476117    |
| training/sac_pi/valid_num      | 4991.0      |
| training/sac_Q/q1              | 214.23624   |
| training/sac_Q/q2              | 214.11406   |
| training/sac_Q/q2_loss         | 101.25898   |
| training/sac_Q/q_global_norm   | 230.87802   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15972248 |
| epoch                          | 704        |
| evaluation/episode-length-avg  | 954        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 539        |
| evaluation/episode-length-std  | 138        |
| evaluation/return-average      | 4660.0635  |
| evaluation/return-max          | 4991.398   |
| evaluation/return-min          | 2388.1865  |
| evaluation/return-std          | 759.7457   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46284      |
| perf/AverageLength             | 954        |
| perf/AverageReturn             | 4660.0635  |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 203.44232  |
| Q-std                          | 120.0866   |
| Q_loss                         | 127.75133  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 704        |
| times/epoch_after_hook         | 2.02e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.00087    |
| times/evaluation_paths         | 37.1       |
| times/timestep_after_hook      | 0.00411    |
| times/timestep_before_hook     | 0.00842    |
| times/train                    | 64.7       |
| timestep                       | 1000       |
| timesteps_total                | 705000     |
| train-steps                    | 705000     |
| training/Q/q1_loss             | 112.05537  |
| training/sac_pi/alpha          | 0.1597512  |
| training/sac_pi/alpha_loss     | 0.17176622 |
| training/sac_pi/logp_pi        | 3.79987    |
| training/sac_pi/pi_entropy     | 3.1936257  |
| training/sac_pi/pi_global_norm | 1.7982635  |
| training/sac_pi/policy_loss    | -229.2999  |
| training/sac_pi/std            | 0.45329052 |
| training/sac_pi/valid_num      | 5040.0     |
| training/sac_Q/q1              | 226.53325  |
| training/sac_Q/q2              | 225.57964  |
| training/sac_Q/q2_loss         | 112.266655 |
| training/sac_Q/q_global_norm   | 273.17322  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17084886  |
| epoch                          | 705         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4880.8896   |
| evaluation/return-max          | 4938.8623   |
| evaluation/return-min          | 4792.075    |
| evaluation/return-std          | 47.87486    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46261       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4880.8896   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 206.45541   |
| Q-std                          | 122.67794   |
| Q_loss                         | 104.37146   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 705         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000305    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000557    |
| times/evaluation_paths         | 38.6        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.00866     |
| times/train                    | 66          |
| timestep                       | 1000        |
| timesteps_total                | 706000      |
| train-steps                    | 706000      |
| training/Q/q1_loss             | 115.46094   |
| training/sac_pi/alpha          | 0.17087537  |
| training/sac_pi/alpha_loss     | -0.14117295 |
| training/sac_pi/logp_pi        | 4.244897    |
| training/sac_pi/pi_entropy     | 3.449021    |
| training/sac_pi/pi_global_norm | 1.4756178   |
| training/sac_pi/policy_loss    | -219.45367  |
| training/sac_pi/std            | 0.5037477   |
| training/sac_pi/valid_num      | 5002.0      |
| training/sac_Q/q1              | 213.39287   |
| training/sac_Q/q2              | 211.92667   |
| training/sac_Q/q2_loss         | 115.3249    |
| training/sac_Q/q_global_norm   | 219.58871   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16726995  |
| epoch                          | 706         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4918.4014   |
| evaluation/return-max          | 5009.9873   |
| evaluation/return-min          | 4851.5728   |
| evaluation/return-std          | 45.32464    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46314       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4918.4014   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 207.85464   |
| Q-std                          | 129.91061   |
| Q_loss                         | 121.98768   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 706         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000509    |
| times/evaluation_paths         | 42.8        |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.00868     |
| times/train                    | 67          |
| timestep                       | 1000        |
| timesteps_total                | 707000      |
| train-steps                    | 707000      |
| training/Q/q1_loss             | 102.06934   |
| training/sac_pi/alpha          | 0.16728793  |
| training/sac_pi/alpha_loss     | -0.09098831 |
| training/sac_pi/logp_pi        | 4.1053977   |
| training/sac_pi/pi_entropy     | 3.4006934   |
| training/sac_pi/pi_global_norm | 1.5183035   |
| training/sac_pi/policy_loss    | -222.02014  |
| training/sac_pi/std            | 0.48508662  |
| training/sac_pi/valid_num      | 4983.0      |
| training/sac_Q/q1              | 212.68098   |
| training/sac_Q/q2              | 212.53084   |
| training/sac_Q/q2_loss         | 101.64093   |
| training/sac_Q/q_global_norm   | 188.5766    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17053305 |
| epoch                          | 707        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5062.659   |
| evaluation/return-max          | 5114.132   |
| evaluation/return-min          | 5027.755   |
| evaluation/return-std          | 30.422535  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46436      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5062.659   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 219.57556  |
| Q-std                          | 123.2547   |
| Q_loss                         | 91.25442   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 707        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000888   |
| times/evaluation_paths         | 40.4       |
| times/timestep_after_hook      | 0.00411    |
| times/timestep_before_hook     | 0.00861    |
| times/train                    | 64.7       |
| timestep                       | 1000       |
| timesteps_total                | 708000     |
| train-steps                    | 708000     |
| training/Q/q1_loss             | 102.60099  |
| training/sac_pi/alpha          | 0.17054975 |
| training/sac_pi/alpha_loss     | 0.18208368 |
| training/sac_pi/logp_pi        | 4.427096   |
| training/sac_pi/pi_entropy     | 3.5661156  |
| training/sac_pi/pi_global_norm | 1.8632206  |
| training/sac_pi/policy_loss    | -223.43552 |
| training/sac_pi/std            | 0.5013708  |
| training/sac_pi/valid_num      | 4974.0     |
| training/sac_Q/q1              | 211.6597   |
| training/sac_Q/q2              | 212.12617  |
| training/sac_Q/q2_loss         | 102.48709  |
| training/sac_Q/q_global_norm   | 177.84322  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16617282 |
| epoch                          | 708        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4849.1904  |
| evaluation/return-max          | 4909.287   |
| evaluation/return-min          | 4809.322   |
| evaluation/return-std          | 29.907654  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46337      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4849.1904  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 219.76086  |
| Q-std                          | 102.46988  |
| Q_loss                         | 84.05567   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 708        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000517   |
| times/evaluation_paths         | 39.2       |
| times/timestep_after_hook      | 0.00421    |
| times/timestep_before_hook     | 0.0087     |
| times/train                    | 67.9       |
| timestep                       | 1000       |
| timesteps_total                | 709000     |
| train-steps                    | 709000     |
| training/Q/q1_loss             | 99.63316   |
| training/sac_pi/alpha          | 0.16617005 |
| training/sac_pi/alpha_loss     | 0.28071064 |
| training/sac_pi/logp_pi        | 3.9196663  |
| training/sac_pi/pi_entropy     | 3.4907317  |
| training/sac_pi/pi_global_norm | 1.5893538  |
| training/sac_pi/policy_loss    | -220.43243 |
| training/sac_pi/std            | 0.47923318 |
| training/sac_pi/valid_num      | 5001.0     |
| training/sac_Q/q1              | 211.17818  |
| training/sac_Q/q2              | 212.5826   |
| training/sac_Q/q2_loss         | 100.789154 |
| training/sac_Q/q_global_norm   | 294.12173  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16590384 |
| epoch                          | 709        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4503.959   |
| evaluation/return-max          | 4661.119   |
| evaluation/return-min          | 4341.119   |
| evaluation/return-std          | 85.47267   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46308      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4503.959   |
| perf/NormalizedReturn          | 0.981      |
| Q-avg                          | 215.99951  |
| Q-std                          | 121.74242  |
| Q_loss                         | 71.247765  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 709        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000311   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.00056    |
| times/evaluation_paths         | 44.4       |
| times/timestep_after_hook      | 0.00449    |
| times/timestep_before_hook     | 0.00852    |
| times/train                    | 69.8       |
| timestep                       | 1000       |
| timesteps_total                | 710000     |
| train-steps                    | 710000     |
| training/Q/q1_loss             | 110.09154  |
| training/sac_pi/alpha          | 0.16590641 |
| training/sac_pi/alpha_loss     | 0.21430379 |
| training/sac_pi/logp_pi        | 4.058287   |
| training/sac_pi/pi_entropy     | 3.3087547  |
| training/sac_pi/pi_global_norm | 1.7262692  |
| training/sac_pi/policy_loss    | -230.81854 |
| training/sac_pi/std            | 0.4797559  |
| training/sac_pi/valid_num      | 5008.0     |
| training/sac_Q/q1              | 222.99399  |
| training/sac_Q/q2              | 223.8726   |
| training/sac_Q/q2_loss         | 109.98524  |
| training/sac_Q/q_global_norm   | 192.4828   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16109456 |
| epoch                          | 710        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5123.1655  |
| evaluation/return-max          | 5226.3525  |
| evaluation/return-min          | 5041.334   |
| evaluation/return-std          | 50.131756  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46400      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5123.1655  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 205.4194   |
| Q-std                          | 158.23434  |
| Q_loss                         | 117.50213  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 710        |
| times/epoch_after_hook         | 3.71e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000665   |
| times/evaluation_paths         | 43         |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 69.4       |
| timestep                       | 1000       |
| timesteps_total                | 711000     |
| train-steps                    | 711000     |
| training/Q/q1_loss             | 94.474976  |
| training/sac_pi/alpha          | 0.16109753 |
| training/sac_pi/alpha_loss     | 0.06266822 |
| training/sac_pi/logp_pi        | 3.8468833  |
| training/sac_pi/pi_entropy     | 3.301349   |
| training/sac_pi/pi_global_norm | 1.6247824  |
| training/sac_pi/policy_loss    | -222.71835 |
| training/sac_pi/std            | 0.4689022  |
| training/sac_pi/valid_num      | 4956.0     |
| training/sac_Q/q1              | 214.6318   |
| training/sac_Q/q2              | 214.5457   |
| training/sac_Q/q2_loss         | 92.9664    |
| training/sac_Q/q_global_norm   | 237.07143  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16223614 |
| epoch                          | 711        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5003.6313  |
| evaluation/return-max          | 5063.6763  |
| evaluation/return-min          | 4939.9316  |
| evaluation/return-std          | 37.210384  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46340      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5003.6313  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 207.05392  |
| Q-std                          | 128.29105  |
| Q_loss                         | 91.93288   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 711        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000156   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.00051    |
| times/evaluation_paths         | 42.5       |
| times/timestep_after_hook      | 0.00439    |
| times/timestep_before_hook     | 0.00873    |
| times/train                    | 71.7       |
| timestep                       | 1000       |
| timesteps_total                | 712000     |
| train-steps                    | 712000     |
| training/Q/q1_loss             | 93.765564  |
| training/sac_pi/alpha          | 0.16224745 |
| training/sac_pi/alpha_loss     | 0.12857936 |
| training/sac_pi/logp_pi        | 3.8238678  |
| training/sac_pi/pi_entropy     | 3.200786   |
| training/sac_pi/pi_global_norm | 1.6120832  |
| training/sac_pi/policy_loss    | -222.73073 |
| training/sac_pi/std            | 0.45393008 |
| training/sac_pi/valid_num      | 5007.0     |
| training/sac_Q/q1              | 215.6355   |
| training/sac_Q/q2              | 216.27681  |
| training/sac_Q/q2_loss         | 93.72658   |
| training/sac_Q/q_global_norm   | 196.20183  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16627145 |
| epoch                          | 712        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5068.9077  |
| evaluation/return-max          | 5146.795   |
| evaluation/return-min          | 4990.5547  |
| evaluation/return-std          | 51.917175  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46312      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5068.9077  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 217.55379  |
| Q-std                          | 108.12493  |
| Q_loss                         | 94.11183   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 712        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000519   |
| times/evaluation_paths         | 35.9       |
| times/timestep_after_hook      | 0.00406    |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 68.2       |
| timestep                       | 1000       |
| timesteps_total                | 713000     |
| train-steps                    | 713000     |
| training/Q/q1_loss             | 98.808716  |
| training/sac_pi/alpha          | 0.16625598 |
| training/sac_pi/alpha_loss     | 0.12001425 |
| training/sac_pi/logp_pi        | 4.2583895  |
| training/sac_pi/pi_entropy     | 3.6042316  |
| training/sac_pi/pi_global_norm | 1.4637545  |
| training/sac_pi/policy_loss    | -221.30452 |
| training/sac_pi/std            | 0.51519805 |
| training/sac_pi/valid_num      | 4938.0     |
| training/sac_Q/q1              | 210.48242  |
| training/sac_Q/q2              | 210.97058  |
| training/sac_Q/q2_loss         | 98.62719   |
| training/sac_Q/q_global_norm   | 276.42883  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16458239  |
| epoch                          | 713         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5145.4966   |
| evaluation/return-max          | 5199.518    |
| evaluation/return-min          | 5078.867    |
| evaluation/return-std          | 37.68534    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46163       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5145.4966   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 214.52888   |
| Q-std                          | 106.61008   |
| Q_loss                         | 118.73723   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 713         |
| times/epoch_after_hook         | 2.05e-06    |
| times/epoch_before_hook        | 0.000261    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000552    |
| times/evaluation_paths         | 36.6        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00855     |
| times/train                    | 64.4        |
| timestep                       | 1000        |
| timesteps_total                | 714000      |
| train-steps                    | 714000      |
| training/Q/q1_loss             | 93.947205   |
| training/sac_pi/alpha          | 0.1646154   |
| training/sac_pi/alpha_loss     | -0.31732634 |
| training/sac_pi/logp_pi        | 4.6120048   |
| training/sac_pi/pi_entropy     | 3.140838    |
| training/sac_pi/pi_global_norm | 1.6808158   |
| training/sac_pi/policy_loss    | -225.29329  |
| training/sac_pi/std            | 0.47577637  |
| training/sac_pi/valid_num      | 4955.0      |
| training/sac_Q/q1              | 212.26633   |
| training/sac_Q/q2              | 212.79875   |
| training/sac_Q/q2_loss         | 94.19717    |
| training/sac_Q/q_global_norm   | 227.94452   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16715674 |
| epoch                          | 714        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5100.1367  |
| evaluation/return-max          | 5150.798   |
| evaluation/return-min          | 5013.03    |
| evaluation/return-std          | 42.921307  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46286      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5100.1367  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 206.9884   |
| Q-std                          | 104.72921  |
| Q_loss                         | 127.36804  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 714        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000558   |
| times/evaluation_paths         | 46         |
| times/timestep_after_hook      | 0.00426    |
| times/timestep_before_hook     | 0.009      |
| times/train                    | 71.2       |
| timestep                       | 1000       |
| timesteps_total                | 715000     |
| train-steps                    | 715000     |
| training/Q/q1_loss             | 97.70142   |
| training/sac_pi/alpha          | 0.16714631 |
| training/sac_pi/alpha_loss     | 0.1401716  |
| training/sac_pi/logp_pi        | 4.1186776  |
| training/sac_pi/pi_entropy     | 3.4437747  |
| training/sac_pi/pi_global_norm | 1.6402333  |
| training/sac_pi/policy_loss    | -216.4244  |
| training/sac_pi/std            | 0.4863906  |
| training/sac_pi/valid_num      | 4937.0     |
| training/sac_Q/q1              | 206.11316  |
| training/sac_Q/q2              | 206.21216  |
| training/sac_Q/q2_loss         | 97.50224   |
| training/sac_Q/q_global_norm   | 277.6269   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16957872 |
| epoch                          | 715        |
| evaluation/episode-length-avg  | 937        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 374        |
| evaluation/episode-length-std  | 188        |
| evaluation/return-average      | 4627.28    |
| evaluation/return-max          | 5047.6904  |
| evaluation/return-min          | 1398.1605  |
| evaluation/return-std          | 1077.1349  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46048      |
| perf/AverageLength             | 937        |
| perf/AverageReturn             | 4627.28    |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 224.58623  |
| Q-std                          | 88.65975   |
| Q_loss                         | 103.44362  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 715        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000568   |
| times/evaluation_paths         | 35.6       |
| times/timestep_after_hook      | 0.00415    |
| times/timestep_before_hook     | 0.00863    |
| times/train                    | 69.4       |
| timestep                       | 1000       |
| timesteps_total                | 716000     |
| train-steps                    | 716000     |
| training/Q/q1_loss             | 92.0596    |
| training/sac_pi/alpha          | 0.16959567 |
| training/sac_pi/alpha_loss     | -0.3088748 |
| training/sac_pi/logp_pi        | 3.9437554  |
| training/sac_pi/pi_entropy     | 3.2516022  |
| training/sac_pi/pi_global_norm | 1.5799923  |
| training/sac_pi/policy_loss    | -226.69904 |
| training/sac_pi/std            | 0.4716491  |
| training/sac_pi/valid_num      | 4942.0     |
| training/sac_Q/q1              | 217.38965  |
| training/sac_Q/q2              | 215.9415   |
| training/sac_Q/q2_loss         | 92.22326   |
| training/sac_Q/q_global_norm   | 233.7231   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17425579  |
| epoch                          | 716         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5010.631    |
| evaluation/return-max          | 5067.38     |
| evaluation/return-min          | 4899.175    |
| evaluation/return-std          | 45.234818   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46392       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5010.631    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 210.26692   |
| Q-std                          | 108.27611   |
| Q_loss                         | 97.52651    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 716         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000695    |
| times/evaluation_paths         | 42.7        |
| times/timestep_after_hook      | 0.00419     |
| times/timestep_before_hook     | 0.0107      |
| times/train                    | 65.1        |
| timestep                       | 1000        |
| timesteps_total                | 717000      |
| train-steps                    | 717000      |
| training/Q/q1_loss             | 116.47837   |
| training/sac_pi/alpha          | 0.17430924  |
| training/sac_pi/alpha_loss     | -0.28380293 |
| training/sac_pi/logp_pi        | 3.7126815   |
| training/sac_pi/pi_entropy     | 3.451776    |
| training/sac_pi/pi_global_norm | 1.9774259   |
| training/sac_pi/policy_loss    | -213.57843  |
| training/sac_pi/std            | 0.47296137  |
| training/sac_pi/valid_num      | 4982.0      |
| training/sac_Q/q1              | 209.15219   |
| training/sac_Q/q2              | 207.7293    |
| training/sac_Q/q2_loss         | 117.63411   |
| training/sac_Q/q_global_norm   | 303.93756   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16823131 |
| epoch                          | 717        |
| evaluation/episode-length-avg  | 686        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 207        |
| evaluation/episode-length-std  | 384        |
| evaluation/return-average      | 3321.618   |
| evaluation/return-max          | 5132.04    |
| evaluation/return-min          | 740.674    |
| evaluation/return-std          | 2089.1638  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46366      |
| perf/AverageLength             | 686        |
| perf/AverageReturn             | 3321.618   |
| perf/NormalizedReturn          | 0.723      |
| Q-avg                          | 209.62663  |
| Q-std                          | 132.38284  |
| Q_loss                         | 112.76931  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 717        |
| times/epoch_after_hook         | 3.47e-06   |
| times/epoch_before_hook        | 0.000258   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000624   |
| times/evaluation_paths         | 30.9       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00862    |
| times/train                    | 72.3       |
| timestep                       | 1000       |
| timesteps_total                | 718000     |
| train-steps                    | 718000     |
| training/Q/q1_loss             | 96.878265  |
| training/sac_pi/alpha          | 0.16823663 |
| training/sac_pi/alpha_loss     | -0.2993894 |
| training/sac_pi/logp_pi        | 4.9373493  |
| training/sac_pi/pi_entropy     | 3.5048432  |
| training/sac_pi/pi_global_norm | 2.0797043  |
| training/sac_pi/policy_loss    | -216.57283 |
| training/sac_pi/std            | 0.52977264 |
| training/sac_pi/valid_num      | 4838.0     |
| training/sac_Q/q1              | 198.6434   |
| training/sac_Q/q2              | 197.47217  |
| training/sac_Q/q2_loss         | 96.66798   |
| training/sac_Q/q_global_norm   | 282.4583   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16927049   |
| epoch                          | 718          |
| evaluation/episode-length-avg  | 571          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 141          |
| evaluation/episode-length-std  | 429          |
| evaluation/return-average      | 2587.906     |
| evaluation/return-max          | 4898.912     |
| evaluation/return-min          | 352.75644    |
| evaluation/return-std          | 2234.1855    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.04         |
| model/origin_ret               | 85.2         |
| model/penalty_ret              | 80.9         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46400        |
| perf/AverageLength             | 571          |
| perf/AverageReturn             | 2587.906     |
| perf/NormalizedReturn          | 0.563        |
| Q-avg                          | 212.3074     |
| Q-std                          | 103.54117    |
| Q_loss                         | 85.6233      |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 718          |
| times/epoch_after_hook         | 2.12e-06     |
| times/epoch_before_hook        | 0.00013      |
| times/epoch_rollout_model      | 493          |
| times/evaluation_metrics       | 0.000705     |
| times/evaluation_paths         | 20.9         |
| times/timestep_after_hook      | 0.00405      |
| times/timestep_before_hook     | 0.00858      |
| times/train                    | 62.5         |
| timestep                       | 1000         |
| timesteps_total                | 719000       |
| train-steps                    | 719000       |
| training/Q/q1_loss             | 106.57225    |
| training/sac_pi/alpha          | 0.16930641   |
| training/sac_pi/alpha_loss     | -0.066981055 |
| training/sac_pi/logp_pi        | 4.105065     |
| training/sac_pi/pi_entropy     | 3.4717171    |
| training/sac_pi/pi_global_norm | 1.4655601    |
| training/sac_pi/policy_loss    | -221.2078    |
| training/sac_pi/std            | 0.4916025    |
| training/sac_pi/valid_num      | 4954.0       |
| training/sac_Q/q1              | 213.6751     |
| training/sac_Q/q2              | 213.31503    |
| training/sac_Q/q2_loss         | 106.42294    |
| training/sac_Q/q_global_norm   | 187.94882    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17176738  |
| epoch                          | 719         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4714.808    |
| evaluation/return-max          | 4825.5576   |
| evaluation/return-min          | 4592.1436   |
| evaluation/return-std          | 56.649887   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46454       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4714.808    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 216.41397   |
| Q-std                          | 112.69273   |
| Q_loss                         | 94.89781    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 719         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000154    |
| times/epoch_rollout_model      | 518         |
| times/evaluation_metrics       | 0.000731    |
| times/evaluation_paths         | 36.3        |
| times/timestep_after_hook      | 0.00476     |
| times/timestep_before_hook     | 0.0089      |
| times/train                    | 66          |
| timestep                       | 1000        |
| timesteps_total                | 720000      |
| train-steps                    | 720000      |
| training/Q/q1_loss             | 98.17024    |
| training/sac_pi/alpha          | 0.17179696  |
| training/sac_pi/alpha_loss     | -0.10180878 |
| training/sac_pi/logp_pi        | 4.5793633   |
| training/sac_pi/pi_entropy     | 3.6954117   |
| training/sac_pi/pi_global_norm | 1.7335886   |
| training/sac_pi/policy_loss    | -212.98387  |
| training/sac_pi/std            | 0.5335843   |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 202.63248   |
| training/sac_Q/q2              | 203.22835   |
| training/sac_Q/q2_loss         | 97.55474    |
| training/sac_Q/q_global_norm   | 224.09068   |
---------------------------------------------------------------------------------
[WARN] 720 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16684614 |
| epoch                          | 720        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4819.36    |
| evaluation/return-max          | 4957.2734  |
| evaluation/return-min          | 4685.5063  |
| evaluation/return-std          | 70.23881   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46381      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4819.36    |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 215.69577  |
| Q-std                          | 118.41367  |
| Q_loss                         | 83.92168   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 720        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000195   |
| times/epoch_rollout_model      | 531        |
| times/evaluation_metrics       | 0.0012     |
| times/evaluation_paths         | 36.7       |
| times/timestep_after_hook      | 0.0041     |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 63.8       |
| timestep                       | 1000       |
| timesteps_total                | 721000     |
| train-steps                    | 721000     |
| training/Q/q1_loss             | 96.48393   |
| training/sac_pi/alpha          | 0.16681923 |
| training/sac_pi/alpha_loss     | 0.27646145 |
| training/sac_pi/logp_pi        | 3.9014878  |
| training/sac_pi/pi_entropy     | 3.4277472  |
| training/sac_pi/pi_global_norm | 1.8572129  |
| training/sac_pi/policy_loss    | -219.96439 |
| training/sac_pi/std            | 0.47496372 |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 213.25114  |
| training/sac_Q/q2              | 213.28413  |
| training/sac_Q/q2_loss         | 95.54254   |
| training/sac_Q/q_global_norm   | 218.67896  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17003438 |
| epoch                          | 721        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4943.3057  |
| evaluation/return-max          | 5006.6377  |
| evaluation/return-min          | 4873.248   |
| evaluation/return-std          | 40.088177  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46389      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4943.3057  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 222.3977   |
| Q-std                          | 148.72368  |
| Q_loss                         | 84.78722   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 721        |
| times/epoch_after_hook         | 2e-06      |
| times/epoch_before_hook        | 0.000465   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000635   |
| times/evaluation_paths         | 40.5       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.0086     |
| times/train                    | 62.9       |
| timestep                       | 1000       |
| timesteps_total                | 722000     |
| train-steps                    | 722000     |
| training/Q/q1_loss             | 95.970665  |
| training/sac_pi/alpha          | 0.17004436 |
| training/sac_pi/alpha_loss     | 0.11984694 |
| training/sac_pi/logp_pi        | 4.2729597  |
| training/sac_pi/pi_entropy     | 3.403241   |
| training/sac_pi/pi_global_norm | 1.8759823  |
| training/sac_pi/policy_loss    | -220.23561 |
| training/sac_pi/std            | 0.4835517  |
| training/sac_pi/valid_num      | 4987.0     |
| training/sac_Q/q1              | 213.49239  |
| training/sac_Q/q2              | 212.74016  |
| training/sac_Q/q2_loss         | 95.58181   |
| training/sac_Q/q_global_norm   | 217.91609  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16557066 |
| epoch                          | 722        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5015.663   |
| evaluation/return-max          | 5168.6406  |
| evaluation/return-min          | 4806.206   |
| evaluation/return-std          | 105.53283  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46303      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5015.663   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 208.5835   |
| Q-std                          | 122.86436  |
| Q_loss                         | 107.4121   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 722        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000158   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000519   |
| times/evaluation_paths         | 44.3       |
| times/timestep_after_hook      | 0.00426    |
| times/timestep_before_hook     | 0.00877    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 723000     |
| train-steps                    | 723000     |
| training/Q/q1_loss             | 116.4325   |
| training/sac_pi/alpha          | 0.16553551 |
| training/sac_pi/alpha_loss     | 0.2738521  |
| training/sac_pi/logp_pi        | 4.6394496  |
| training/sac_pi/pi_entropy     | 3.3337474  |
| training/sac_pi/pi_global_norm | 1.7017386  |
| training/sac_pi/policy_loss    | -217.76947 |
| training/sac_pi/std            | 0.4799537  |
| training/sac_pi/valid_num      | 4981.0     |
| training/sac_Q/q1              | 210.86435  |
| training/sac_Q/q2              | 210.89949  |
| training/sac_Q/q2_loss         | 115.81534  |
| training/sac_Q/q_global_norm   | 286.9766   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1690468    |
| epoch                          | 723          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5004.84      |
| evaluation/return-max          | 5072.351     |
| evaluation/return-min          | 4919.35      |
| evaluation/return-std          | 51.217487    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.03         |
| model/origin_ret               | 85.5         |
| model/penalty_ret              | 80.7         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46226        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5004.84      |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 220.4251     |
| Q-std                          | 134.2805     |
| Q_loss                         | 87.37765     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 723          |
| times/epoch_after_hook         | 1.94e-06     |
| times/epoch_before_hook        | 0.000133     |
| times/epoch_rollout_model      | 509          |
| times/evaluation_metrics       | 0.000598     |
| times/evaluation_paths         | 44.7         |
| times/timestep_after_hook      | 0.00399      |
| times/timestep_before_hook     | 0.00837      |
| times/train                    | 65.4         |
| timestep                       | 1000         |
| timesteps_total                | 724000       |
| train-steps                    | 724000       |
| training/Q/q1_loss             | 96.32759     |
| training/sac_pi/alpha          | 0.16904852   |
| training/sac_pi/alpha_loss     | -0.043242343 |
| training/sac_pi/logp_pi        | 4.526281     |
| training/sac_pi/pi_entropy     | 3.495938     |
| training/sac_pi/pi_global_norm | 1.7677662    |
| training/sac_pi/policy_loss    | -224.32744   |
| training/sac_pi/std            | 0.5215361    |
| training/sac_pi/valid_num      | 4904.0       |
| training/sac_Q/q1              | 211.39023    |
| training/sac_Q/q2              | 210.05383    |
| training/sac_Q/q2_loss         | 97.035866    |
| training/sac_Q/q_global_norm   | 219.75214    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17123479 |
| epoch                          | 724        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4852.251   |
| evaluation/return-max          | 4943.8066  |
| evaluation/return-min          | 4754.3647  |
| evaluation/return-std          | 58.39505   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46389      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4852.251   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 201.95438  |
| Q-std                          | 142.04982  |
| Q_loss                         | 93.69531   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 724        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000151   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.000817   |
| times/evaluation_paths         | 41.6       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 59.7       |
| timestep                       | 1000       |
| timesteps_total                | 725000     |
| train-steps                    | 725000     |
| training/Q/q1_loss             | 103.354675 |
| training/sac_pi/alpha          | 0.17122276 |
| training/sac_pi/alpha_loss     | 0.08130049 |
| training/sac_pi/logp_pi        | 3.8280272  |
| training/sac_pi/pi_entropy     | 3.4991174  |
| training/sac_pi/pi_global_norm | 1.7641491  |
| training/sac_pi/policy_loss    | -222.83267 |
| training/sac_pi/std            | 0.4888027  |
| training/sac_pi/valid_num      | 4987.0     |
| training/sac_Q/q1              | 212.92392  |
| training/sac_Q/q2              | 214.45926  |
| training/sac_Q/q2_loss         | 103.49368  |
| training/sac_Q/q_global_norm   | 184.38956  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16713947   |
| epoch                          | 725          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4668.7295    |
| evaluation/return-max          | 4714.9443    |
| evaluation/return-min          | 4515.0645    |
| evaluation/return-std          | 54.745125    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.09         |
| model/origin_ret               | 86.5         |
| model/penalty_ret              | 80.5         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46255        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4668.7295    |
| perf/NormalizedReturn          | 1.02         |
| Q-avg                          | 216.83313    |
| Q-std                          | 89.74905     |
| Q_loss                         | 93.6512      |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 725          |
| times/epoch_after_hook         | 1.86e-06     |
| times/epoch_before_hook        | 0.000288     |
| times/epoch_rollout_model      | 512          |
| times/evaluation_metrics       | 0.000606     |
| times/evaluation_paths         | 33.4         |
| times/timestep_after_hook      | 0.00403      |
| times/timestep_before_hook     | 0.00859      |
| times/train                    | 63.1         |
| timestep                       | 1000         |
| timesteps_total                | 726000       |
| train-steps                    | 726000       |
| training/Q/q1_loss             | 94.268845    |
| training/sac_pi/alpha          | 0.16715103   |
| training/sac_pi/alpha_loss     | -0.013486544 |
| training/sac_pi/logp_pi        | 4.228826     |
| training/sac_pi/pi_entropy     | 3.3723457    |
| training/sac_pi/pi_global_norm | 1.6477063    |
| training/sac_pi/policy_loss    | -225.16124   |
| training/sac_pi/std            | 0.50221986   |
| training/sac_pi/valid_num      | 4977.0       |
| training/sac_Q/q1              | 215.97144    |
| training/sac_Q/q2              | 216.95901    |
| training/sac_Q/q2_loss         | 93.7708      |
| training/sac_Q/q_global_norm   | 233.45168    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17310281 |
| epoch                          | 726        |
| evaluation/episode-length-avg  | 764        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 573        |
| evaluation/episode-length-std  | 171        |
| evaluation/return-average      | 3453.7527  |
| evaluation/return-max          | 4747.8916  |
| evaluation/return-min          | 2467.6404  |
| evaluation/return-std          | 888.91724  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46320      |
| perf/AverageLength             | 764        |
| perf/AverageReturn             | 3453.7527  |
| perf/NormalizedReturn          | 0.752      |
| Q-avg                          | 211.72041  |
| Q-std                          | 159.12012  |
| Q_loss                         | 77.845726  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 726        |
| times/epoch_after_hook         | 3.3e-06    |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000668   |
| times/evaluation_paths         | 28.3       |
| times/timestep_after_hook      | 0.00409    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 63.2       |
| timestep                       | 1000       |
| timesteps_total                | 727000     |
| train-steps                    | 727000     |
| training/Q/q1_loss             | 80.52186   |
| training/sac_pi/alpha          | 0.17303771 |
| training/sac_pi/alpha_loss     | 0.10830929 |
| training/sac_pi/logp_pi        | 3.928259   |
| training/sac_pi/pi_entropy     | 3.3567638  |
| training/sac_pi/pi_global_norm | 1.4996645  |
| training/sac_pi/policy_loss    | -227.57314 |
| training/sac_pi/std            | 0.46799463 |
| training/sac_pi/valid_num      | 5013.0     |
| training/sac_Q/q1              | 217.93896  |
| training/sac_Q/q2              | 219.36006  |
| training/sac_Q/q2_loss         | 80.48741   |
| training/sac_Q/q_global_norm   | 180.0833   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17120789   |
| epoch                          | 727          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4847.3076    |
| evaluation/return-max          | 4982.202     |
| evaluation/return-min          | 4731.9014    |
| evaluation/return-std          | 68.41912     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.05         |
| model/origin_ret               | 86.2         |
| model/penalty_ret              | 81.7         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46231        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4847.3076    |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 205.16219    |
| Q-std                          | 115.78738    |
| Q_loss                         | 101.00082    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 727          |
| times/epoch_after_hook         | 1.88e-06     |
| times/epoch_before_hook        | 0.000135     |
| times/epoch_rollout_model      | 510          |
| times/evaluation_metrics       | 0.000552     |
| times/evaluation_paths         | 36.5         |
| times/timestep_after_hook      | 0.00401      |
| times/timestep_before_hook     | 0.00858      |
| times/train                    | 59.2         |
| timestep                       | 1000         |
| timesteps_total                | 728000       |
| train-steps                    | 728000       |
| training/Q/q1_loss             | 93.30354     |
| training/sac_pi/alpha          | 0.17123178   |
| training/sac_pi/alpha_loss     | -0.007435581 |
| training/sac_pi/logp_pi        | 3.7296283    |
| training/sac_pi/pi_entropy     | 3.4395194    |
| training/sac_pi/pi_global_norm | 1.5322078    |
| training/sac_pi/policy_loss    | -216.56981   |
| training/sac_pi/std            | 0.48122507   |
| training/sac_pi/valid_num      | 5016.0       |
| training/sac_Q/q1              | 211.27954    |
| training/sac_Q/q2              | 211.46445    |
| training/sac_Q/q2_loss         | 92.90456     |
| training/sac_Q/q_global_norm   | 218.53618    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15996411  |
| epoch                          | 728         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4819.288    |
| evaluation/return-max          | 4911.6416   |
| evaluation/return-min          | 4715.1934   |
| evaluation/return-std          | 67.02543    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46174       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4819.288    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 210.41434   |
| Q-std                          | 123.72654   |
| Q_loss                         | 109.51614   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 728         |
| times/epoch_after_hook         | 1.93e-06    |
| times/epoch_before_hook        | 0.000138    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000596    |
| times/evaluation_paths         | 37          |
| times/timestep_after_hook      | 0.00413     |
| times/timestep_before_hook     | 0.00881     |
| times/train                    | 70.1        |
| timestep                       | 1000        |
| timesteps_total                | 729000      |
| train-steps                    | 729000      |
| training/Q/q1_loss             | 105.35203   |
| training/sac_pi/alpha          | 0.15997577  |
| training/sac_pi/alpha_loss     | 0.093781926 |
| training/sac_pi/logp_pi        | 4.265929    |
| training/sac_pi/pi_entropy     | 3.244269    |
| training/sac_pi/pi_global_norm | 2.2299297   |
| training/sac_pi/policy_loss    | -225.74112  |
| training/sac_pi/std            | 0.47747836  |
| training/sac_pi/valid_num      | 4971.0      |
| training/sac_Q/q1              | 213.83672   |
| training/sac_Q/q2              | 214.70346   |
| training/sac_Q/q2_loss         | 105.559494  |
| training/sac_Q/q_global_norm   | 236.42525   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15823723 |
| epoch                          | 729        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4965.0127  |
| evaluation/return-max          | 5006.7607  |
| evaluation/return-min          | 4885.803   |
| evaluation/return-std          | 38.412663  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46352      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4965.0127  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 213.80144  |
| Q-std                          | 136.01842  |
| Q_loss                         | 105.71386  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 729        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000317   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000671   |
| times/evaluation_paths         | 36.5       |
| times/timestep_after_hook      | 0.00403    |
| times/timestep_before_hook     | 0.00952    |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 730000     |
| train-steps                    | 730000     |
| training/Q/q1_loss             | 75.30782   |
| training/sac_pi/alpha          | 0.15818581 |
| training/sac_pi/alpha_loss     | 0.1731113  |
| training/sac_pi/logp_pi        | 3.8505225  |
| training/sac_pi/pi_entropy     | 3.108759   |
| training/sac_pi/pi_global_norm | 1.3528885  |
| training/sac_pi/policy_loss    | -230.1625  |
| training/sac_pi/std            | 0.45012915 |
| training/sac_pi/valid_num      | 5025.0     |
| training/sac_Q/q1              | 223.64023  |
| training/sac_Q/q2              | 222.85385  |
| training/sac_Q/q2_loss         | 75.81352   |
| training/sac_Q/q_global_norm   | 242.52283  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15718696  |
| epoch                          | 730         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4853.464    |
| evaluation/return-max          | 4911.037    |
| evaluation/return-min          | 4772.8853   |
| evaluation/return-std          | 37.733196   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46587       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4853.464    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 218.69669   |
| Q-std                          | 115.34023   |
| Q_loss                         | 92.82884    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 730         |
| times/epoch_after_hook         | 2.16e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000539    |
| times/evaluation_paths         | 33.6        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00853     |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 731000      |
| train-steps                    | 731000      |
| training/Q/q1_loss             | 100.62365   |
| training/sac_pi/alpha          | 0.15717053  |
| training/sac_pi/alpha_loss     | -0.14186384 |
| training/sac_pi/logp_pi        | 4.148061    |
| training/sac_pi/pi_entropy     | 3.1494942   |
| training/sac_pi/pi_global_norm | 1.6374153   |
| training/sac_pi/policy_loss    | -224.44041  |
| training/sac_pi/std            | 0.45760778  |
| training/sac_pi/valid_num      | 4942.0      |
| training/sac_Q/q1              | 216.3461    |
| training/sac_Q/q2              | 217.1084    |
| training/sac_Q/q2_loss         | 98.88796    |
| training/sac_Q/q_global_norm   | 227.94072   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15969901  |
| epoch                          | 731         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4686.9287   |
| evaluation/return-max          | 4812.875    |
| evaluation/return-min          | 4579.1475   |
| evaluation/return-std          | 75.293816   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46366       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4686.9287   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 214.55595   |
| Q-std                          | 128.13135   |
| Q_loss                         | 83.397415   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 731         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000525    |
| times/evaluation_paths         | 34.1        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00857     |
| times/train                    | 64.2        |
| timestep                       | 1000        |
| timesteps_total                | 732000      |
| train-steps                    | 732000      |
| training/Q/q1_loss             | 119.35561   |
| training/sac_pi/alpha          | 0.15969445  |
| training/sac_pi/alpha_loss     | 0.013466389 |
| training/sac_pi/logp_pi        | 4.464532    |
| training/sac_pi/pi_entropy     | 3.2662601   |
| training/sac_pi/pi_global_norm | 1.8478633   |
| training/sac_pi/policy_loss    | -213.75774  |
| training/sac_pi/std            | 0.47022817  |
| training/sac_pi/valid_num      | 4977.0      |
| training/sac_Q/q1              | 207.15659   |
| training/sac_Q/q2              | 206.69516   |
| training/sac_Q/q2_loss         | 119.22874   |
| training/sac_Q/q_global_norm   | 247.86958   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16311075  |
| epoch                          | 732         |
| evaluation/episode-length-avg  | 921         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 246         |
| evaluation/episode-length-std  | 225         |
| evaluation/return-average      | 4427.366    |
| evaluation/return-max          | 5034.3857   |
| evaluation/return-min          | 758.04663   |
| evaluation/return-std          | 1231.0703   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46310       |
| perf/AverageLength             | 921         |
| perf/AverageReturn             | 4427.366    |
| perf/NormalizedReturn          | 0.964       |
| Q-avg                          | 225.73367   |
| Q-std                          | 93.35111    |
| Q_loss                         | 95.225685   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 732         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000673    |
| times/evaluation_paths         | 32.1        |
| times/timestep_after_hook      | 0.00412     |
| times/timestep_before_hook     | 0.0084      |
| times/train                    | 63.6        |
| timestep                       | 1000        |
| timesteps_total                | 733000      |
| train-steps                    | 733000      |
| training/Q/q1_loss             | 88.70686    |
| training/sac_pi/alpha          | 0.1631269   |
| training/sac_pi/alpha_loss     | -0.19360241 |
| training/sac_pi/logp_pi        | 3.9133396   |
| training/sac_pi/pi_entropy     | 3.5631588   |
| training/sac_pi/pi_global_norm | 1.7169567   |
| training/sac_pi/policy_loss    | -219.29776  |
| training/sac_pi/std            | 0.49923888  |
| training/sac_pi/valid_num      | 4981.0      |
| training/sac_Q/q1              | 212.48965   |
| training/sac_Q/q2              | 211.91605   |
| training/sac_Q/q2_loss         | 88.841194   |
| training/sac_Q/q_global_norm   | 217.68018   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16103844 |
| epoch                          | 733        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5114.7744  |
| evaluation/return-max          | 5154.081   |
| evaluation/return-min          | 5058.687   |
| evaluation/return-std          | 29.115618  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46203      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5114.7744  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 217.30713  |
| Q-std                          | 107.47014  |
| Q_loss                         | 88.35647   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 733        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000263   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000586   |
| times/evaluation_paths         | 35.2       |
| times/timestep_after_hook      | 0.00408    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 734000     |
| train-steps                    | 734000     |
| training/Q/q1_loss             | 95.26704   |
| training/sac_pi/alpha          | 0.16101533 |
| training/sac_pi/alpha_loss     | -0.1286532 |
| training/sac_pi/logp_pi        | 4.037614   |
| training/sac_pi/pi_entropy     | 3.3818657  |
| training/sac_pi/pi_global_norm | 1.7272924  |
| training/sac_pi/policy_loss    | -224.01021 |
| training/sac_pi/std            | 0.48664883 |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 212.9228   |
| training/sac_Q/q2              | 212.5375   |
| training/sac_Q/q2_loss         | 96.197044  |
| training/sac_Q/q_global_norm   | 186.36009  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15811498  |
| epoch                          | 734         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5137.1787   |
| evaluation/return-max          | 5159.517    |
| evaluation/return-min          | 5120.804    |
| evaluation/return-std          | 11.187458   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46289       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5137.1787   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 204.16898   |
| Q-std                          | 135.13461   |
| Q_loss                         | 95.99745    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 734         |
| times/epoch_after_hook         | 3.09e-06    |
| times/epoch_before_hook        | 0.000114    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.00054     |
| times/evaluation_paths         | 35.4        |
| times/timestep_after_hook      | 0.0043      |
| times/timestep_before_hook     | 0.00858     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 735000      |
| train-steps                    | 735000      |
| training/Q/q1_loss             | 118.65063   |
| training/sac_pi/alpha          | 0.15813074  |
| training/sac_pi/alpha_loss     | -0.14569286 |
| training/sac_pi/logp_pi        | 3.5630074   |
| training/sac_pi/pi_entropy     | 3.3461323   |
| training/sac_pi/pi_global_norm | 1.843464    |
| training/sac_pi/policy_loss    | -220.6075   |
| training/sac_pi/std            | 0.46463028  |
| training/sac_pi/valid_num      | 4994.0      |
| training/sac_Q/q1              | 214.94792   |
| training/sac_Q/q2              | 215.03479   |
| training/sac_Q/q2_loss         | 118.185425  |
| training/sac_Q/q_global_norm   | 295.47687   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16724437  |
| epoch                          | 735         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4975.929    |
| evaluation/return-max          | 5052.374    |
| evaluation/return-min          | 4914.3037   |
| evaluation/return-std          | 45.31046    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46261       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4975.929    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 209.48032   |
| Q-std                          | 132.00899   |
| Q_loss                         | 77.51196    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 735         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 504         |
| times/evaluation_metrics       | 0.000503    |
| times/evaluation_paths         | 34.4        |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 736000      |
| train-steps                    | 736000      |
| training/Q/q1_loss             | 103.4917    |
| training/sac_pi/alpha          | 0.16725725  |
| training/sac_pi/alpha_loss     | -0.11317045 |
| training/sac_pi/logp_pi        | 4.1963754   |
| training/sac_pi/pi_entropy     | 3.454258    |
| training/sac_pi/pi_global_norm | 1.6347008   |
| training/sac_pi/policy_loss    | -216.456    |
| training/sac_pi/std            | 0.49493155  |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 208.53438   |
| training/sac_Q/q2              | 207.36299   |
| training/sac_Q/q2_loss         | 104.32585   |
| training/sac_Q/q_global_norm   | 267.06717   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16646929 |
| epoch                          | 736        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4889.121   |
| evaluation/return-max          | 4964.4453  |
| evaluation/return-min          | 4813.7476  |
| evaluation/return-std          | 59.988434  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46264      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4889.121   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 212.82584  |
| Q-std                          | 114.319534 |
| Q_loss                         | 93.411674  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 736        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 505        |
| times/evaluation_metrics       | 0.000529   |
| times/evaluation_paths         | 34.3       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 57.4       |
| timestep                       | 1000       |
| timesteps_total                | 737000     |
| train-steps                    | 737000     |
| training/Q/q1_loss             | 102.70871  |
| training/sac_pi/alpha          | 0.16646591 |
| training/sac_pi/alpha_loss     | 0.33395195 |
| training/sac_pi/logp_pi        | 4.686504   |
| training/sac_pi/pi_entropy     | 3.0850377  |
| training/sac_pi/pi_global_norm | 1.6298354  |
| training/sac_pi/policy_loss    | -221.22456 |
| training/sac_pi/std            | 0.45652965 |
| training/sac_pi/valid_num      | 4992.0     |
| training/sac_Q/q1              | 211.56644  |
| training/sac_Q/q2              | 211.09464  |
| training/sac_Q/q2_loss         | 100.950195 |
| training/sac_Q/q_global_norm   | 208.63075  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16835846 |
| epoch                          | 737        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5064.757   |
| evaluation/return-max          | 5158.758   |
| evaluation/return-min          | 4938.912   |
| evaluation/return-std          | 59.915035  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46170      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5064.757   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 218.50664  |
| Q-std                          | 137.39922  |
| Q_loss                         | 98.228325  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 737        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000263   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000508   |
| times/evaluation_paths         | 35         |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 738000     |
| train-steps                    | 738000     |
| training/Q/q1_loss             | 96.9384    |
| training/sac_pi/alpha          | 0.16835628 |
| training/sac_pi/alpha_loss     | 0.2013163  |
| training/sac_pi/logp_pi        | 4.025778   |
| training/sac_pi/pi_entropy     | 3.3519485  |
| training/sac_pi/pi_global_norm | 1.8369629  |
| training/sac_pi/policy_loss    | -222.6328  |
| training/sac_pi/std            | 0.47297034 |
| training/sac_pi/valid_num      | 4974.0     |
| training/sac_Q/q1              | 215.272    |
| training/sac_Q/q2              | 216.01035  |
| training/sac_Q/q2_loss         | 96.86811   |
| training/sac_Q/q_global_norm   | 221.52097  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1644966   |
| epoch                          | 738         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4809.638    |
| evaluation/return-max          | 4863.6973   |
| evaluation/return-min          | 4749.924    |
| evaluation/return-std          | 31.572287   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46288       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4809.638    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 208.33093   |
| Q-std                          | 121.875626  |
| Q_loss                         | 105.29332   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 738         |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 0.000105    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000511    |
| times/evaluation_paths         | 33.9        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 739000      |
| train-steps                    | 739000      |
| training/Q/q1_loss             | 100.02541   |
| training/sac_pi/alpha          | 0.16453706  |
| training/sac_pi/alpha_loss     | -0.24113837 |
| training/sac_pi/logp_pi        | 4.6145597   |
| training/sac_pi/pi_entropy     | 3.3618233   |
| training/sac_pi/pi_global_norm | 1.6506572   |
| training/sac_pi/policy_loss    | -220.13823  |
| training/sac_pi/std            | 0.5069486   |
| training/sac_pi/valid_num      | 4831.0      |
| training/sac_Q/q1              | 201.42052   |
| training/sac_Q/q2              | 198.70665   |
| training/sac_Q/q2_loss         | 98.17054    |
| training/sac_Q/q_global_norm   | 312.2143    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16700757  |
| epoch                          | 739         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4733.921    |
| evaluation/return-max          | 4860.3086   |
| evaluation/return-min          | 4641.312    |
| evaluation/return-std          | 58.066414   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46350       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4733.921    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 217.25801   |
| Q-std                          | 102.29019   |
| Q_loss                         | 88.80124    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 739         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000144    |
| times/epoch_rollout_model      | 504         |
| times/evaluation_metrics       | 0.000569    |
| times/evaluation_paths         | 34.7        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 740000      |
| train-steps                    | 740000      |
| training/Q/q1_loss             | 92.68134    |
| training/sac_pi/alpha          | 0.16701822  |
| training/sac_pi/alpha_loss     | -0.09641863 |
| training/sac_pi/logp_pi        | 3.746263    |
| training/sac_pi/pi_entropy     | 3.3752697   |
| training/sac_pi/pi_global_norm | 1.6622992   |
| training/sac_pi/policy_loss    | -225.31458  |
| training/sac_pi/std            | 0.47265726  |
| training/sac_pi/valid_num      | 4979.0      |
| training/sac_Q/q1              | 219.33401   |
| training/sac_Q/q2              | 219.5158    |
| training/sac_Q/q2_loss         | 92.29661    |
| training/sac_Q/q_global_norm   | 218.95514   |
---------------------------------------------------------------------------------
[WARN] 740 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.16554715   |
| epoch                          | 740          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4902.8447    |
| evaluation/return-max          | 4973.4727    |
| evaluation/return-min          | 4814.1143    |
| evaluation/return-std          | 46.734337    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.08         |
| model/origin_ret               | 85.9         |
| model/penalty_ret              | 80.1         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46363        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4902.8447    |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 221.24898    |
| Q-std                          | 99.6516      |
| Q_loss                         | 85.41345     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 740          |
| times/epoch_after_hook         | 1.63e-06     |
| times/epoch_before_hook        | 0.000134     |
| times/epoch_rollout_model      | 508          |
| times/evaluation_metrics       | 0.000524     |
| times/evaluation_paths         | 34.1         |
| times/timestep_after_hook      | 0.00424      |
| times/timestep_before_hook     | 0.00863      |
| times/train                    | 62.5         |
| timestep                       | 1000         |
| timesteps_total                | 741000       |
| train-steps                    | 741000       |
| training/Q/q1_loss             | 91.14615     |
| training/sac_pi/alpha          | 0.1655367    |
| training/sac_pi/alpha_loss     | -0.099515274 |
| training/sac_pi/logp_pi        | 3.8868935    |
| training/sac_pi/pi_entropy     | 3.3150399    |
| training/sac_pi/pi_global_norm | 1.4110268    |
| training/sac_pi/policy_loss    | -230.57986   |
| training/sac_pi/std            | 0.4672484    |
| training/sac_pi/valid_num      | 5010.0       |
| training/sac_Q/q1              | 223.22745    |
| training/sac_Q/q2              | 222.86972    |
| training/sac_Q/q2_loss         | 91.86691     |
| training/sac_Q/q_global_norm   | 288.8698     |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16626868   |
| epoch                          | 741          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5033.3315    |
| evaluation/return-max          | 5123.539     |
| evaluation/return-min          | 4834.241     |
| evaluation/return-std          | 81.41062     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.02         |
| model/origin_ret               | 85.2         |
| model/penalty_ret              | 80.8         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46267        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5033.3315    |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 220.75395    |
| Q-std                          | 92.28535     |
| Q_loss                         | 99.09736     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 741          |
| times/epoch_after_hook         | 1.91e-06     |
| times/epoch_before_hook        | 0.000284     |
| times/epoch_rollout_model      | 501          |
| times/evaluation_metrics       | 0.000572     |
| times/evaluation_paths         | 35.6         |
| times/timestep_after_hook      | 0.00415      |
| times/timestep_before_hook     | 0.00851      |
| times/train                    | 60.3         |
| timestep                       | 1000         |
| timesteps_total                | 742000       |
| train-steps                    | 742000       |
| training/Q/q1_loss             | 93.81681     |
| training/sac_pi/alpha          | 0.16627456   |
| training/sac_pi/alpha_loss     | -0.098471604 |
| training/sac_pi/logp_pi        | 4.045851     |
| training/sac_pi/pi_entropy     | 3.3344414    |
| training/sac_pi/pi_global_norm | 1.5878891    |
| training/sac_pi/policy_loss    | -224.63474   |
| training/sac_pi/std            | 0.4702719    |
| training/sac_pi/valid_num      | 4984.0       |
| training/sac_Q/q1              | 215.08676    |
| training/sac_Q/q2              | 217.10385    |
| training/sac_Q/q2_loss         | 94.39075     |
| training/sac_Q/q_global_norm   | 231.33049    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16246842  |
| epoch                          | 742         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4892.2705   |
| evaluation/return-max          | 5032.0103   |
| evaluation/return-min          | 4773.8936   |
| evaluation/return-std          | 83.13298    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46307       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4892.2705   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 217.16415   |
| Q-std                          | 131.50557   |
| Q_loss                         | 85.50704    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 742         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000147    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000558    |
| times/evaluation_paths         | 34.3        |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00841     |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 743000      |
| train-steps                    | 743000      |
| training/Q/q1_loss             | 103.08914   |
| training/sac_pi/alpha          | 0.16253094  |
| training/sac_pi/alpha_loss     | -0.55083984 |
| training/sac_pi/logp_pi        | 3.9152284   |
| training/sac_pi/pi_entropy     | 3.376004    |
| training/sac_pi/pi_global_norm | 1.6294775   |
| training/sac_pi/policy_loss    | -229.72523  |
| training/sac_pi/std            | 0.49211273  |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 221.6165    |
| training/sac_Q/q2              | 220.78865   |
| training/sac_Q/q2_loss         | 103.78389   |
| training/sac_Q/q_global_norm   | 232.52708   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16594468  |
| epoch                          | 743         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5121.9185   |
| evaluation/return-max          | 5158.3613   |
| evaluation/return-min          | 5075.615    |
| evaluation/return-std          | 23.166468   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46417       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5121.9185   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 210.98674   |
| Q-std                          | 149.44571   |
| Q_loss                         | 99.681175   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 743         |
| times/epoch_after_hook         | 2.02e-06    |
| times/epoch_before_hook        | 0.000111    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000917    |
| times/evaluation_paths         | 35.7        |
| times/timestep_after_hook      | 0.00409     |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 744000      |
| train-steps                    | 744000      |
| training/Q/q1_loss             | 85.293045   |
| training/sac_pi/alpha          | 0.16594829  |
| training/sac_pi/alpha_loss     | -0.28398702 |
| training/sac_pi/logp_pi        | 3.965219    |
| training/sac_pi/pi_entropy     | 3.2745965   |
| training/sac_pi/pi_global_norm | 1.7422261   |
| training/sac_pi/policy_loss    | -224.59776  |
| training/sac_pi/std            | 0.48125017  |
| training/sac_pi/valid_num      | 5022.0      |
| training/sac_Q/q1              | 219.58276   |
| training/sac_Q/q2              | 220.0142    |
| training/sac_Q/q2_loss         | 84.974236   |
| training/sac_Q/q_global_norm   | 225.07529   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16553785 |
| epoch                          | 744        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4890.62    |
| evaluation/return-max          | 4974.947   |
| evaluation/return-min          | 4831.98    |
| evaluation/return-std          | 48.931103  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46240      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4890.62    |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 221.3925   |
| Q-std                          | 105.64839  |
| Q_loss                         | 96.98522   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 744        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.00016    |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000643   |
| times/evaluation_paths         | 35.2       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00842    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 745000     |
| train-steps                    | 745000     |
| training/Q/q1_loss             | 100.18004  |
| training/sac_pi/alpha          | 0.16554715 |
| training/sac_pi/alpha_loss     | 0.22898455 |
| training/sac_pi/logp_pi        | 4.515247   |
| training/sac_pi/pi_entropy     | 3.112411   |
| training/sac_pi/pi_global_norm | 1.9963387  |
| training/sac_pi/policy_loss    | -212.60287 |
| training/sac_pi/std            | 0.45491317 |
| training/sac_pi/valid_num      | 5007.0     |
| training/sac_Q/q1              | 202.5633   |
| training/sac_Q/q2              | 204.33078  |
| training/sac_Q/q2_loss         | 100.5553   |
| training/sac_Q/q_global_norm   | 405.09915  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16779879  |
| epoch                          | 745         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4705.7993   |
| evaluation/return-max          | 4745.2617   |
| evaluation/return-min          | 4640.033    |
| evaluation/return-std          | 29.497652   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46346       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4705.7993   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 217.76132   |
| Q-std                          | 114.511955  |
| Q_loss                         | 102.83957   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 745         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000345    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000679    |
| times/evaluation_paths         | 35.8        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00878     |
| times/train                    | 59.9        |
| timestep                       | 1000        |
| timesteps_total                | 746000      |
| train-steps                    | 746000      |
| training/Q/q1_loss             | 111.252464  |
| training/sac_pi/alpha          | 0.16781138  |
| training/sac_pi/alpha_loss     | -0.10952785 |
| training/sac_pi/logp_pi        | 5.304329    |
| training/sac_pi/pi_entropy     | 3.5502114   |
| training/sac_pi/pi_global_norm | 2.3130558   |
| training/sac_pi/policy_loss    | -217.7408   |
| training/sac_pi/std            | 0.5631834   |
| training/sac_pi/valid_num      | 4867.0      |
| training/sac_Q/q1              | 198.71884   |
| training/sac_Q/q2              | 200.72302   |
| training/sac_Q/q2_loss         | 111.81011   |
| training/sac_Q/q_global_norm   | 214.39473   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16291812  |
| epoch                          | 746         |
| evaluation/episode-length-avg  | 930         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 304         |
| evaluation/episode-length-std  | 209         |
| evaluation/return-average      | 4426.849    |
| evaluation/return-max          | 4981.808    |
| evaluation/return-min          | 1229.61     |
| evaluation/return-std          | 1074.3352   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46256       |
| perf/AverageLength             | 930         |
| perf/AverageReturn             | 4426.849    |
| perf/NormalizedReturn          | 0.964       |
| Q-avg                          | 214.79317   |
| Q-std                          | 118.88033   |
| Q_loss                         | 108.66917   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 746         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000151    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000597    |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00852     |
| times/train                    | 60.2        |
| timestep                       | 1000        |
| timesteps_total                | 747000      |
| train-steps                    | 747000      |
| training/Q/q1_loss             | 96.90803    |
| training/sac_pi/alpha          | 0.16291344  |
| training/sac_pi/alpha_loss     | -0.24326771 |
| training/sac_pi/logp_pi        | 3.443541    |
| training/sac_pi/pi_entropy     | 3.1455321   |
| training/sac_pi/pi_global_norm | 1.4171804   |
| training/sac_pi/policy_loss    | -226.54695  |
| training/sac_pi/std            | 0.4467816   |
| training/sac_pi/valid_num      | 5019.0      |
| training/sac_Q/q1              | 222.7629    |
| training/sac_Q/q2              | 221.61382   |
| training/sac_Q/q2_loss         | 96.45611    |
| training/sac_Q/q_global_norm   | 294.24368   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1698      |
| epoch                          | 747         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5202.892    |
| evaluation/return-max          | 5279.573    |
| evaluation/return-min          | 5070.932    |
| evaluation/return-std          | 71.432396   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46115       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5202.892    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 219.61235   |
| Q-std                          | 93.57014    |
| Q_loss                         | 94.08601    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 747         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000147    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000601    |
| times/evaluation_paths         | 34.2        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 748000      |
| train-steps                    | 748000      |
| training/Q/q1_loss             | 103.528534  |
| training/sac_pi/alpha          | 0.16977493  |
| training/sac_pi/alpha_loss     | -0.19616143 |
| training/sac_pi/logp_pi        | 4.3241663   |
| training/sac_pi/pi_entropy     | 3.2760231   |
| training/sac_pi/pi_global_norm | 1.8141112   |
| training/sac_pi/policy_loss    | -220.78378  |
| training/sac_pi/std            | 0.47819555  |
| training/sac_pi/valid_num      | 4981.0      |
| training/sac_Q/q1              | 212.8107    |
| training/sac_Q/q2              | 212.29605   |
| training/sac_Q/q2_loss         | 103.54291   |
| training/sac_Q/q_global_norm   | 258.12997   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17265633  |
| epoch                          | 748         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4946.3564   |
| evaluation/return-max          | 4996.243    |
| evaluation/return-min          | 4868.324    |
| evaluation/return-std          | 43.706066   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46303       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4946.3564   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 207.682     |
| Q-std                          | 162.39706   |
| Q_loss                         | 95.37331    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 748         |
| times/epoch_after_hook         | 1.95e-06    |
| times/epoch_before_hook        | 0.000156    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 34.7        |
| times/timestep_after_hook      | 0.00417     |
| times/timestep_before_hook     | 0.0087      |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 749000      |
| train-steps                    | 749000      |
| training/Q/q1_loss             | 139.1047    |
| training/sac_pi/alpha          | 0.17270553  |
| training/sac_pi/alpha_loss     | 0.049258098 |
| training/sac_pi/logp_pi        | 4.5193715   |
| training/sac_pi/pi_entropy     | 3.4537094   |
| training/sac_pi/pi_global_norm | 1.6839173   |
| training/sac_pi/policy_loss    | -217.94922  |
| training/sac_pi/std            | 0.5019267   |
| training/sac_pi/valid_num      | 4984.0      |
| training/sac_Q/q1              | 205.43808   |
| training/sac_Q/q2              | 207.02925   |
| training/sac_Q/q2_loss         | 136.95076   |
| training/sac_Q/q_global_norm   | 274.04974   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16834119 |
| epoch                          | 749        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4956.7427  |
| evaluation/return-max          | 5036.6074  |
| evaluation/return-min          | 4885.101   |
| evaluation/return-std          | 46.38229   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46322      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4956.7427  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 209.2188   |
| Q-std                          | 114.930695 |
| Q_loss                         | 116.75371  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 749        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000294   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.00053    |
| times/evaluation_paths         | 35.3       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00865    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 750000     |
| train-steps                    | 750000     |
| training/Q/q1_loss             | 115.92533  |
| training/sac_pi/alpha          | 0.16836286 |
| training/sac_pi/alpha_loss     | 0.07730894 |
| training/sac_pi/logp_pi        | 3.625035   |
| training/sac_pi/pi_entropy     | 3.4354396  |
| training/sac_pi/pi_global_norm | 1.7425258  |
| training/sac_pi/policy_loss    | -213.62054 |
| training/sac_pi/std            | 0.46701673 |
| training/sac_pi/valid_num      | 5022.0     |
| training/sac_Q/q1              | 210.19185  |
| training/sac_Q/q2              | 209.85315  |
| training/sac_Q/q2_loss         | 115.57378  |
| training/sac_Q/q_global_norm   | 180.33592  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16822787 |
| epoch                          | 750        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5067.1963  |
| evaluation/return-max          | 5161.6064  |
| evaluation/return-min          | 4823.402   |
| evaluation/return-std          | 91.01592   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46128      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5067.1963  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 211.66525  |
| Q-std                          | 122.47269  |
| Q_loss                         | 106.04026  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 750        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000802   |
| times/evaluation_paths         | 34         |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00806    |
| times/train                    | 60.2       |
| timestep                       | 1000       |
| timesteps_total                | 751000     |
| train-steps                    | 751000     |
| training/Q/q1_loss             | 96.602104  |
| training/sac_pi/alpha          | 0.16818413 |
| training/sac_pi/alpha_loss     | 0.2568733  |
| training/sac_pi/logp_pi        | 3.8455544  |
| training/sac_pi/pi_entropy     | 3.2904022  |
| training/sac_pi/pi_global_norm | 1.76634    |
| training/sac_pi/policy_loss    | -227.59311 |
| training/sac_pi/std            | 0.45264    |
| training/sac_pi/valid_num      | 4998.0     |
| training/sac_Q/q1              | 221.25967  |
| training/sac_Q/q2              | 220.71313  |
| training/sac_Q/q2_loss         | 97.826706  |
| training/sac_Q/q_global_norm   | 210.45428  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16817464  |
| epoch                          | 751         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4997.393    |
| evaluation/return-max          | 5045.9434   |
| evaluation/return-min          | 4962.0776   |
| evaluation/return-std          | 28.026842   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46348       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4997.393    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 211.76794   |
| Q-std                          | 124.611725  |
| Q_loss                         | 93.74919    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 751         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000359    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000758    |
| times/evaluation_paths         | 34.7        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.0088      |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 752000      |
| train-steps                    | 752000      |
| training/Q/q1_loss             | 103.19394   |
| training/sac_pi/alpha          | 0.16820167  |
| training/sac_pi/alpha_loss     | 0.038829207 |
| training/sac_pi/logp_pi        | 4.524928    |
| training/sac_pi/pi_entropy     | 3.3983886   |
| training/sac_pi/pi_global_norm | 1.5016625   |
| training/sac_pi/policy_loss    | -215.57007  |
| training/sac_pi/std            | 0.49925405  |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 205.78186   |
| training/sac_Q/q2              | 205.46414   |
| training/sac_Q/q2_loss         | 102.68362   |
| training/sac_Q/q_global_norm   | 237.02255   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16887476  |
| epoch                          | 752         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4822.1963   |
| evaluation/return-max          | 4923.7646   |
| evaluation/return-min          | 4791.7935   |
| evaluation/return-std          | 37.71828    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46191       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4822.1963   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 214.6287    |
| Q-std                          | 130.77798   |
| Q_loss                         | 98.514854   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 752         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000187    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000563    |
| times/evaluation_paths         | 35.1        |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 60          |
| timestep                       | 1000        |
| timesteps_total                | 753000      |
| train-steps                    | 753000      |
| training/Q/q1_loss             | 76.43451    |
| training/sac_pi/alpha          | 0.16890551  |
| training/sac_pi/alpha_loss     | -0.27468854 |
| training/sac_pi/logp_pi        | 4.0386496   |
| training/sac_pi/pi_entropy     | 3.3093915   |
| training/sac_pi/pi_global_norm | 1.9845158   |
| training/sac_pi/policy_loss    | -224.8687   |
| training/sac_pi/std            | 0.48032877  |
| training/sac_pi/valid_num      | 4962.0      |
| training/sac_Q/q1              | 215.40251   |
| training/sac_Q/q2              | 214.48015   |
| training/sac_Q/q2_loss         | 75.788994   |
| training/sac_Q/q_global_norm   | 189.07019   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16619146 |
| epoch                          | 753        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4907.304   |
| evaluation/return-max          | 4991.124   |
| evaluation/return-min          | 4816.349   |
| evaluation/return-std          | 52.596214  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46317      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4907.304   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 203.01877  |
| Q-std                          | 157.60878  |
| Q_loss                         | 96.87299   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 753        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000501   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000662   |
| times/evaluation_paths         | 34.1       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 60.2       |
| timestep                       | 1000       |
| timesteps_total                | 754000     |
| train-steps                    | 754000     |
| training/Q/q1_loss             | 89.89195   |
| training/sac_pi/alpha          | 0.16616203 |
| training/sac_pi/alpha_loss     | 0.0440545  |
| training/sac_pi/logp_pi        | 4.787539   |
| training/sac_pi/pi_entropy     | 3.3789449  |
| training/sac_pi/pi_global_norm | 1.7137412  |
| training/sac_pi/policy_loss    | -221.13275 |
| training/sac_pi/std            | 0.50625527 |
| training/sac_pi/valid_num      | 4921.0     |
| training/sac_Q/q1              | 205.3188   |
| training/sac_Q/q2              | 204.23203  |
| training/sac_Q/q2_loss         | 89.91557   |
| training/sac_Q/q_global_norm   | 214.36366  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16332255 |
| epoch                          | 754        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4846.014   |
| evaluation/return-max          | 4924.494   |
| evaluation/return-min          | 4779.674   |
| evaluation/return-std          | 39.782856  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 86.8       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46225      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4846.014   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 213.56079  |
| Q-std                          | 153.8505   |
| Q_loss                         | 91.57926   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 754        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000168   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000545   |
| times/evaluation_paths         | 34.3       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 755000     |
| train-steps                    | 755000     |
| training/Q/q1_loss             | 86.8655    |
| training/sac_pi/alpha          | 0.16330843 |
| training/sac_pi/alpha_loss     | 0.26718137 |
| training/sac_pi/logp_pi        | 5.038749   |
| training/sac_pi/pi_entropy     | 3.0533905  |
| training/sac_pi/pi_global_norm | 1.4651579  |
| training/sac_pi/policy_loss    | -226.12653 |
| training/sac_pi/std            | 0.4754236  |
| training/sac_pi/valid_num      | 4973.0     |
| training/sac_Q/q1              | 214.83139  |
| training/sac_Q/q2              | 215.06967  |
| training/sac_Q/q2_loss         | 86.09615   |
| training/sac_Q/q_global_norm   | 179.97124  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.165189   |
| epoch                          | 755        |
| evaluation/episode-length-avg  | 954        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 543        |
| evaluation/episode-length-std  | 137        |
| evaluation/return-average      | 4562.103   |
| evaluation/return-max          | 4886.331   |
| evaluation/return-min          | 2278.6128  |
| evaluation/return-std          | 762.1291   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46210      |
| perf/AverageLength             | 954        |
| perf/AverageReturn             | 4562.103   |
| perf/NormalizedReturn          | 0.993      |
| Q-avg                          | 208.93607  |
| Q-std                          | 144.65593  |
| Q_loss                         | 117.24433  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 755        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000696   |
| times/evaluation_paths         | 31.9       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 756000     |
| train-steps                    | 756000     |
| training/Q/q1_loss             | 99.039635  |
| training/sac_pi/alpha          | 0.16523209 |
| training/sac_pi/alpha_loss     | -0.510487  |
| training/sac_pi/logp_pi        | 4.239714   |
| training/sac_pi/pi_entropy     | 3.0479043  |
| training/sac_pi/pi_global_norm | 1.643842   |
| training/sac_pi/policy_loss    | -227.26663 |
| training/sac_pi/std            | 0.46892598 |
| training/sac_pi/valid_num      | 4983.0     |
| training/sac_Q/q1              | 214.27927  |
| training/sac_Q/q2              | 216.39713  |
| training/sac_Q/q2_loss         | 99.05044   |
| training/sac_Q/q_global_norm   | 236.83278  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16761836 |
| epoch                          | 756        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5210.257   |
| evaluation/return-max          | 5249.715   |
| evaluation/return-min          | 5174.284   |
| evaluation/return-std          | 24.465458  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46343      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5210.257   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 214.10986  |
| Q-std                          | 116.409386 |
| Q_loss                         | 104.148445 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 756        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000116   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000506   |
| times/evaluation_paths         | 33.7       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00882    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 757000     |
| train-steps                    | 757000     |
| training/Q/q1_loss             | 90.3793    |
| training/sac_pi/alpha          | 0.16765465 |
| training/sac_pi/alpha_loss     | -0.5901253 |
| training/sac_pi/logp_pi        | 3.4922466  |
| training/sac_pi/pi_entropy     | 3.4194322  |
| training/sac_pi/pi_global_norm | 1.7034566  |
| training/sac_pi/policy_loss    | -220.34131 |
| training/sac_pi/std            | 0.47571075 |
| training/sac_pi/valid_num      | 4949.0     |
| training/sac_Q/q1              | 210.34709  |
| training/sac_Q/q2              | 211.09683  |
| training/sac_Q/q2_loss         | 90.467545  |
| training/sac_Q/q_global_norm   | 247.81262  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1701575    |
| epoch                          | 757          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5313.579     |
| evaluation/return-max          | 5338.877     |
| evaluation/return-min          | 5270.261     |
| evaluation/return-std          | 21.035088    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.06         |
| model/origin_ret               | 85.6         |
| model/penalty_ret              | 81           |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46359        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5313.579     |
| perf/NormalizedReturn          | 1.16         |
| Q-avg                          | 218.95537    |
| Q-std                          | 138.40361    |
| Q_loss                         | 67.20695     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 757          |
| times/epoch_after_hook         | 1.78e-06     |
| times/epoch_before_hook        | 0.000311     |
| times/epoch_rollout_model      | 509          |
| times/evaluation_metrics       | 0.000591     |
| times/evaluation_paths         | 46.1         |
| times/timestep_after_hook      | 0.00385      |
| times/timestep_before_hook     | 0.00815      |
| times/train                    | 60.1         |
| timestep                       | 1000         |
| timesteps_total                | 758000       |
| train-steps                    | 758000       |
| training/Q/q1_loss             | 95.16353     |
| training/sac_pi/alpha          | 0.17015265   |
| training/sac_pi/alpha_loss     | -0.060137425 |
| training/sac_pi/logp_pi        | 4.074065     |
| training/sac_pi/pi_entropy     | 3.5104594    |
| training/sac_pi/pi_global_norm | 1.4193417    |
| training/sac_pi/policy_loss    | -227.29037   |
| training/sac_pi/std            | 0.49698687   |
| training/sac_pi/valid_num      | 4935.0       |
| training/sac_Q/q1              | 216.20357    |
| training/sac_Q/q2              | 216.3757     |
| training/sac_Q/q2_loss         | 96.40067     |
| training/sac_Q/q_global_norm   | 248.48117    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16876967  |
| epoch                          | 758         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5122.5454   |
| evaluation/return-max          | 5160.2095   |
| evaluation/return-min          | 5079.996    |
| evaluation/return-std          | 25.869793   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46276       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5122.5454   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 216.20947   |
| Q-std                          | 106.29037   |
| Q_loss                         | 86.09541    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 758         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000136    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000573    |
| times/evaluation_paths         | 43.2        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.00875     |
| times/train                    | 64.5        |
| timestep                       | 1000        |
| timesteps_total                | 759000      |
| train-steps                    | 759000      |
| training/Q/q1_loss             | 91.67727    |
| training/sac_pi/alpha          | 0.1687855   |
| training/sac_pi/alpha_loss     | -0.12033987 |
| training/sac_pi/logp_pi        | 4.444725    |
| training/sac_pi/pi_entropy     | 3.1383758   |
| training/sac_pi/pi_global_norm | 1.6068155   |
| training/sac_pi/policy_loss    | -226.01512  |
| training/sac_pi/std            | 0.4791188   |
| training/sac_pi/valid_num      | 4978.0      |
| training/sac_Q/q1              | 215.38907   |
| training/sac_Q/q2              | 216.16731   |
| training/sac_Q/q2_loss         | 91.61858    |
| training/sac_Q/q_global_norm   | 201.17264   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17301984  |
| epoch                          | 759         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5168.194    |
| evaluation/return-max          | 5231.8994   |
| evaluation/return-min          | 5112.122    |
| evaluation/return-std          | 38.03205    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46252       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5168.194    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 215.56355   |
| Q-std                          | 118.51552   |
| Q_loss                         | 83.29041    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 759         |
| times/epoch_after_hook         | 3.12e-06    |
| times/epoch_before_hook        | 0.000161    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000568    |
| times/evaluation_paths         | 36.8        |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 760000      |
| train-steps                    | 760000      |
| training/Q/q1_loss             | 105.22296   |
| training/sac_pi/alpha          | 0.1730085   |
| training/sac_pi/alpha_loss     | -0.14252563 |
| training/sac_pi/logp_pi        | 3.9976754   |
| training/sac_pi/pi_entropy     | 3.3810005   |
| training/sac_pi/pi_global_norm | 1.6525333   |
| training/sac_pi/policy_loss    | -225.78004  |
| training/sac_pi/std            | 0.47457275  |
| training/sac_pi/valid_num      | 5002.0      |
| training/sac_Q/q1              | 216.66293   |
| training/sac_Q/q2              | 216.5668    |
| training/sac_Q/q2_loss         | 103.83991   |
| training/sac_Q/q_global_norm   | 247.20988   |
---------------------------------------------------------------------------------
[WARN] 760 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16672106  |
| epoch                          | 760         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5068.4272   |
| evaluation/return-max          | 5202.041    |
| evaluation/return-min          | 4989.3945   |
| evaluation/return-std          | 60.712746   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46434       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5068.4272   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 217.09367   |
| Q-std                          | 115.12377   |
| Q_loss                         | 91.7528     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 760         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.00059     |
| times/evaluation_paths         | 44          |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00827     |
| times/train                    | 58.9        |
| timestep                       | 1000        |
| timesteps_total                | 761000      |
| train-steps                    | 761000      |
| training/Q/q1_loss             | 98.66152    |
| training/sac_pi/alpha          | 0.16675462  |
| training/sac_pi/alpha_loss     | -0.52408445 |
| training/sac_pi/logp_pi        | 4.167675    |
| training/sac_pi/pi_entropy     | 3.4949582   |
| training/sac_pi/pi_global_norm | 1.6581298   |
| training/sac_pi/policy_loss    | -221.36812  |
| training/sac_pi/std            | 0.513889    |
| training/sac_pi/valid_num      | 4927.0      |
| training/sac_Q/q1              | 209.53735   |
| training/sac_Q/q2              | 210.17734   |
| training/sac_Q/q2_loss         | 98.84123    |
| training/sac_Q/q_global_norm   | 225.28752   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16769055  |
| epoch                          | 761         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5026.0303   |
| evaluation/return-max          | 5106.857    |
| evaluation/return-min          | 4837.292    |
| evaluation/return-std          | 83.844505   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46330       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5026.0303   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 209.63667   |
| Q-std                          | 142.51999   |
| Q_loss                         | 97.31104    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 761         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000261    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000524    |
| times/evaluation_paths         | 33.6        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00867     |
| times/train                    | 69.4        |
| timestep                       | 1000        |
| timesteps_total                | 762000      |
| train-steps                    | 762000      |
| training/Q/q1_loss             | 95.32757    |
| training/sac_pi/alpha          | 0.16771637  |
| training/sac_pi/alpha_loss     | -0.07410307 |
| training/sac_pi/logp_pi        | 4.10365     |
| training/sac_pi/pi_entropy     | 3.4203186   |
| training/sac_pi/pi_global_norm | 1.5690885   |
| training/sac_pi/policy_loss    | -213.39594  |
| training/sac_pi/std            | 0.48491356  |
| training/sac_pi/valid_num      | 4978.0      |
| training/sac_Q/q1              | 206.12354   |
| training/sac_Q/q2              | 207.69136   |
| training/sac_Q/q2_loss         | 95.395      |
| training/sac_Q/q_global_norm   | 228.43309   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16651498  |
| epoch                          | 762         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4928.212    |
| evaluation/return-max          | 4998.033    |
| evaluation/return-min          | 4848.302    |
| evaluation/return-std          | 51.89879    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46277       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4928.212    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 219.4356    |
| Q-std                          | 145.1818    |
| Q_loss                         | 101.169075  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 762         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000142    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000551    |
| times/evaluation_paths         | 36.6        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 763000      |
| train-steps                    | 763000      |
| training/Q/q1_loss             | 89.63006    |
| training/sac_pi/alpha          | 0.16651727  |
| training/sac_pi/alpha_loss     | -0.23722968 |
| training/sac_pi/logp_pi        | 4.5572166   |
| training/sac_pi/pi_entropy     | 3.268657    |
| training/sac_pi/pi_global_norm | 2.1955202   |
| training/sac_pi/policy_loss    | -222.30165  |
| training/sac_pi/std            | 0.47684702  |
| training/sac_pi/valid_num      | 4932.0      |
| training/sac_Q/q1              | 214.6856    |
| training/sac_Q/q2              | 214.62752   |
| training/sac_Q/q2_loss         | 90.31654    |
| training/sac_Q/q_global_norm   | 222.34001   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16738413   |
| epoch                          | 763          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4943.1787    |
| evaluation/return-max          | 5001.5737    |
| evaluation/return-min          | 4902.1006    |
| evaluation/return-std          | 34.02039     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.07         |
| model/origin_ret               | 86.2         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46379        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4943.1787    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 207.78305    |
| Q-std                          | 115.920456   |
| Q_loss                         | 93.013306    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 763          |
| times/epoch_after_hook         | 1.99e-06     |
| times/epoch_before_hook        | 0.000121     |
| times/epoch_rollout_model      | 501          |
| times/evaluation_metrics       | 0.000537     |
| times/evaluation_paths         | 39.1         |
| times/timestep_after_hook      | 0.00395      |
| times/timestep_before_hook     | 0.00867      |
| times/train                    | 71.9         |
| timestep                       | 1000         |
| timesteps_total                | 764000       |
| train-steps                    | 764000       |
| training/Q/q1_loss             | 97.95199     |
| training/sac_pi/alpha          | 0.16738097   |
| training/sac_pi/alpha_loss     | -0.005117608 |
| training/sac_pi/logp_pi        | 4.5670757    |
| training/sac_pi/pi_entropy     | 3.3044753    |
| training/sac_pi/pi_global_norm | 1.7238415    |
| training/sac_pi/policy_loss    | -223.82701   |
| training/sac_pi/std            | 0.4821603    |
| training/sac_pi/valid_num      | 4882.0       |
| training/sac_Q/q1              | 211.76714    |
| training/sac_Q/q2              | 210.44038    |
| training/sac_Q/q2_loss         | 96.83333     |
| training/sac_Q/q_global_norm   | 223.57582    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16909534  |
| epoch                          | 764         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4948.651    |
| evaluation/return-max          | 4992.7393   |
| evaluation/return-min          | 4892.0913   |
| evaluation/return-std          | 32.292366   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46499       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4948.651    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 209.35515   |
| Q-std                          | 127.98625   |
| Q_loss                         | 110.70875   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 764         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.00043     |
| times/evaluation_paths         | 38.2        |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00841     |
| times/train                    | 69.5        |
| timestep                       | 1000        |
| timesteps_total                | 765000      |
| train-steps                    | 765000      |
| training/Q/q1_loss             | 91.437775   |
| training/sac_pi/alpha          | 0.16905662  |
| training/sac_pi/alpha_loss     | 0.083389565 |
| training/sac_pi/logp_pi        | 3.6742826   |
| training/sac_pi/pi_entropy     | 3.5429788   |
| training/sac_pi/pi_global_norm | 1.5882307   |
| training/sac_pi/policy_loss    | -221.97     |
| training/sac_pi/std            | 0.47974518  |
| training/sac_pi/valid_num      | 4999.0      |
| training/sac_Q/q1              | 214.73697   |
| training/sac_Q/q2              | 215.64175   |
| training/sac_Q/q2_loss         | 91.60587    |
| training/sac_Q/q_global_norm   | 217.28964   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16398472  |
| epoch                          | 765         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4837.922    |
| evaluation/return-max          | 4914.9473   |
| evaluation/return-min          | 4733.8213   |
| evaluation/return-std          | 48.237362   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46290       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4837.922    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 207.8082    |
| Q-std                          | 111.73457   |
| Q_loss                         | 81.742325   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 765         |
| times/epoch_after_hook         | 2e-06       |
| times/epoch_before_hook        | 0.000272    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000662    |
| times/evaluation_paths         | 34          |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00858     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 766000      |
| train-steps                    | 766000      |
| training/Q/q1_loss             | 91.73059    |
| training/sac_pi/alpha          | 0.16401581  |
| training/sac_pi/alpha_loss     | -0.14655782 |
| training/sac_pi/logp_pi        | 3.967771    |
| training/sac_pi/pi_entropy     | 3.3198695   |
| training/sac_pi/pi_global_norm | 1.6053488   |
| training/sac_pi/policy_loss    | -220.75565  |
| training/sac_pi/std            | 0.47387677  |
| training/sac_pi/valid_num      | 4956.0      |
| training/sac_Q/q1              | 213.26501   |
| training/sac_Q/q2              | 212.2419    |
| training/sac_Q/q2_loss         | 91.03391    |
| training/sac_Q/q_global_norm   | 226.48598   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16621216 |
| epoch                          | 766        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4857.087   |
| evaluation/return-max          | 4880.8926  |
| evaluation/return-min          | 4812.04    |
| evaluation/return-std          | 19.939993  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46219      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4857.087   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 211.48544  |
| Q-std                          | 148.69232  |
| Q_loss                         | 82.87945   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 766        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000179   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000651   |
| times/evaluation_paths         | 35.2       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00873    |
| times/train                    | 63.3       |
| timestep                       | 1000       |
| timesteps_total                | 767000     |
| train-steps                    | 767000     |
| training/Q/q1_loss             | 91.36101   |
| training/sac_pi/alpha          | 0.1661711  |
| training/sac_pi/alpha_loss     | 0.14039837 |
| training/sac_pi/logp_pi        | 4.375674   |
| training/sac_pi/pi_entropy     | 3.1435585  |
| training/sac_pi/pi_global_norm | 1.8364604  |
| training/sac_pi/policy_loss    | -219.5815  |
| training/sac_pi/std            | 0.4596525  |
| training/sac_pi/valid_num      | 4999.0     |
| training/sac_Q/q1              | 212.21687  |
| training/sac_Q/q2              | 212.29485  |
| training/sac_Q/q2_loss         | 91.26719   |
| training/sac_Q/q_global_norm   | 293.49374  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16355623 |
| epoch                          | 767        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5059.542   |
| evaluation/return-max          | 5152.3804  |
| evaluation/return-min          | 5000.9746  |
| evaluation/return-std          | 42.203465  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46405      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5059.542   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 216.08635  |
| Q-std                          | 112.15118  |
| Q_loss                         | 85.225044  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 767        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.00018    |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 34.2       |
| times/timestep_after_hook      | 0.00423    |
| times/timestep_before_hook     | 0.00856    |
| times/train                    | 63.5       |
| timestep                       | 1000       |
| timesteps_total                | 768000     |
| train-steps                    | 768000     |
| training/Q/q1_loss             | 111.48009  |
| training/sac_pi/alpha          | 0.16354553 |
| training/sac_pi/alpha_loss     | 0.07707795 |
| training/sac_pi/logp_pi        | 3.5929894  |
| training/sac_pi/pi_entropy     | 3.4357095  |
| training/sac_pi/pi_global_norm | 1.5586096  |
| training/sac_pi/policy_loss    | -214.98517 |
| training/sac_pi/std            | 0.46653202 |
| training/sac_pi/valid_num      | 5041.0     |
| training/sac_Q/q1              | 212.00288  |
| training/sac_Q/q2              | 211.85725  |
| training/sac_Q/q2_loss         | 112.97396  |
| training/sac_Q/q_global_norm   | 187.6882   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16744448  |
| epoch                          | 768         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5154.2656   |
| evaluation/return-max          | 5254.035    |
| evaluation/return-min          | 5079.347    |
| evaluation/return-std          | 54.22404    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46392       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5154.2656   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 207.11836   |
| Q-std                          | 97.90428    |
| Q_loss                         | 106.84912   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 768         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.00014     |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000659    |
| times/evaluation_paths         | 33.8        |
| times/timestep_after_hook      | 0.00408     |
| times/timestep_before_hook     | 0.00854     |
| times/train                    | 62.4        |
| timestep                       | 1000        |
| timesteps_total                | 769000      |
| train-steps                    | 769000      |
| training/Q/q1_loss             | 105.09543   |
| training/sac_pi/alpha          | 0.16746943  |
| training/sac_pi/alpha_loss     | -0.06745094 |
| training/sac_pi/logp_pi        | 4.394999    |
| training/sac_pi/pi_entropy     | 3.4478424   |
| training/sac_pi/pi_global_norm | 1.4504914   |
| training/sac_pi/policy_loss    | -225.06615  |
| training/sac_pi/std            | 0.49551958  |
| training/sac_pi/valid_num      | 4926.0      |
| training/sac_Q/q1              | 211.34229   |
| training/sac_Q/q2              | 215.18474   |
| training/sac_Q/q2_loss         | 104.859955  |
| training/sac_Q/q_global_norm   | 229.46664   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17016326 |
| epoch                          | 769        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5131.6055  |
| evaluation/return-max          | 5180.2485  |
| evaluation/return-min          | 5066.9355  |
| evaluation/return-std          | 34.321526  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46266      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5131.6055  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 220.31284  |
| Q-std                          | 113.52652  |
| Q_loss                         | 93.97237   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 769        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000358   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000532   |
| times/evaluation_paths         | 35.8       |
| times/timestep_after_hook      | 0.00398    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 59.4       |
| timestep                       | 1000       |
| timesteps_total                | 770000     |
| train-steps                    | 770000     |
| training/Q/q1_loss             | 100.18654  |
| training/sac_pi/alpha          | 0.17015567 |
| training/sac_pi/alpha_loss     | 0.29151258 |
| training/sac_pi/logp_pi        | 4.271151   |
| training/sac_pi/pi_entropy     | 3.4539566  |
| training/sac_pi/pi_global_norm | 1.5523564  |
| training/sac_pi/policy_loss    | -221.08006 |
| training/sac_pi/std            | 0.49430314 |
| training/sac_pi/valid_num      | 4959.0     |
| training/sac_Q/q1              | 212.02835  |
| training/sac_Q/q2              | 213.11923  |
| training/sac_Q/q2_loss         | 99.540344  |
| training/sac_Q/q_global_norm   | 246.55043  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16580209  |
| epoch                          | 770         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4825.517    |
| evaluation/return-max          | 4941.5283   |
| evaluation/return-min          | 4746.909    |
| evaluation/return-std          | 46.537476   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46329       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4825.517    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 217.4833    |
| Q-std                          | 116.43395   |
| Q_loss                         | 83.19936    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 770         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000609    |
| times/evaluation_paths         | 35.4        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 771000      |
| train-steps                    | 771000      |
| training/Q/q1_loss             | 105.390686  |
| training/sac_pi/alpha          | 0.165825    |
| training/sac_pi/alpha_loss     | -0.33090955 |
| training/sac_pi/logp_pi        | 4.6818223   |
| training/sac_pi/pi_entropy     | 3.5187461   |
| training/sac_pi/pi_global_norm | 1.9387009   |
| training/sac_pi/policy_loss    | -223.77896  |
| training/sac_pi/std            | 0.52422535  |
| training/sac_pi/valid_num      | 4902.0      |
| training/sac_Q/q1              | 209.47623   |
| training/sac_Q/q2              | 212.7898    |
| training/sac_Q/q2_loss         | 103.7738    |
| training/sac_Q/q_global_norm   | 199.58205   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16593032 |
| epoch                          | 771        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4847.325   |
| evaluation/return-max          | 4874.073   |
| evaluation/return-min          | 4800.5654  |
| evaluation/return-std          | 23.296091  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46339      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4847.325   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 215.3335   |
| Q-std                          | 126.253746 |
| Q_loss                         | 103.59087  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 771        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000115   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000561   |
| times/evaluation_paths         | 34.1       |
| times/timestep_after_hook      | 0.0042     |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 772000     |
| train-steps                    | 772000     |
| training/Q/q1_loss             | 96.87442   |
| training/sac_pi/alpha          | 0.16595778 |
| training/sac_pi/alpha_loss     | 0.3184585  |
| training/sac_pi/logp_pi        | 4.731088   |
| training/sac_pi/pi_entropy     | 3.1823978  |
| training/sac_pi/pi_global_norm | 1.7842624  |
| training/sac_pi/policy_loss    | -227.75046 |
| training/sac_pi/std            | 0.48157322 |
| training/sac_pi/valid_num      | 4951.0     |
| training/sac_Q/q1              | 218.8262   |
| training/sac_Q/q2              | 218.55673  |
| training/sac_Q/q2_loss         | 96.21564   |
| training/sac_Q/q_global_norm   | 200.53065  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16620056 |
| epoch                          | 772        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4711.6045  |
| evaluation/return-max          | 4767.8086  |
| evaluation/return-min          | 4640.259   |
| evaluation/return-std          | 47.19242   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46326      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4711.6045  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 214.24841  |
| Q-std                          | 167.0044   |
| Q_loss                         | 85.550255  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 772        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000489   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000521   |
| times/evaluation_paths         | 35.3       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 59.2       |
| timestep                       | 1000       |
| timesteps_total                | 773000     |
| train-steps                    | 773000     |
| training/Q/q1_loss             | 124.50664  |
| training/sac_pi/alpha          | 0.16616699 |
| training/sac_pi/alpha_loss     | 0.35359955 |
| training/sac_pi/logp_pi        | 5.802926   |
| training/sac_pi/pi_entropy     | 3.2719054  |
| training/sac_pi/pi_global_norm | 1.7370968  |
| training/sac_pi/policy_loss    | -214.20782 |
| training/sac_pi/std            | 0.52880305 |
| training/sac_pi/valid_num      | 4879.0     |
| training/sac_Q/q1              | 187.43837  |
| training/sac_Q/q2              | 193.56052  |
| training/sac_Q/q2_loss         | 124.07433  |
| training/sac_Q/q_global_norm   | 237.49237  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16337083 |
| epoch                          | 773        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4882.089   |
| evaluation/return-max          | 5008.42    |
| evaluation/return-min          | 4676.84    |
| evaluation/return-std          | 102.70331  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46278      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4882.089   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 224.7769   |
| Q-std                          | 112.762825 |
| Q_loss                         | 96.55037   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 773        |
| times/epoch_after_hook         | 1.99e-06   |
| times/epoch_before_hook        | 0.000274   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000705   |
| times/evaluation_paths         | 33.5       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00862    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 774000     |
| train-steps                    | 774000     |
| training/Q/q1_loss             | 91.19234   |
| training/sac_pi/alpha          | 0.16339186 |
| training/sac_pi/alpha_loss     | -0.2760901 |
| training/sac_pi/logp_pi        | 3.3960717  |
| training/sac_pi/pi_entropy     | 3.2896645  |
| training/sac_pi/pi_global_norm | 1.7761257  |
| training/sac_pi/policy_loss    | -227.55661 |
| training/sac_pi/std            | 0.45354712 |
| training/sac_pi/valid_num      | 5013.0     |
| training/sac_Q/q1              | 221.52254  |
| training/sac_Q/q2              | 223.58224  |
| training/sac_Q/q2_loss         | 91.6683    |
| training/sac_Q/q_global_norm   | 187.99875  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16575213 |
| epoch                          | 774        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5173.905   |
| evaluation/return-max          | 5257.8203  |
| evaluation/return-min          | 5076.6597  |
| evaluation/return-std          | 56.340137  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46372      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5173.905   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 208.45671  |
| Q-std                          | 121.38826  |
| Q_loss                         | 110.311584 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 774        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000157   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000737   |
| times/evaluation_paths         | 34.5       |
| times/timestep_after_hook      | 0.00418    |
| times/timestep_before_hook     | 0.00874    |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 775000     |
| train-steps                    | 775000     |
| training/Q/q1_loss             | 85.84389   |
| training/sac_pi/alpha          | 0.16577862 |
| training/sac_pi/alpha_loss     | 0.07760348 |
| training/sac_pi/logp_pi        | 3.9798348  |
| training/sac_pi/pi_entropy     | 3.320851   |
| training/sac_pi/pi_global_norm | 1.9543873  |
| training/sac_pi/policy_loss    | -222.43343 |
| training/sac_pi/std            | 0.46785277 |
| training/sac_pi/valid_num      | 4994.0     |
| training/sac_Q/q1              | 216.08643  |
| training/sac_Q/q2              | 217.03467  |
| training/sac_Q/q2_loss         | 85.602974  |
| training/sac_Q/q_global_norm   | 174.20541  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16575503 |
| epoch                          | 775        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5197.398   |
| evaluation/return-max          | 5263.5444  |
| evaluation/return-min          | 5070.8394  |
| evaluation/return-std          | 56.089394  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46394      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5197.398   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 216.70879  |
| Q-std                          | 124.33491  |
| Q_loss                         | 73.88785   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 775        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000179   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000526   |
| times/evaluation_paths         | 35.9       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00856    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 776000     |
| train-steps                    | 776000     |
| training/Q/q1_loss             | 93.26177   |
| training/sac_pi/alpha          | 0.16571462 |
| training/sac_pi/alpha_loss     | 0.1687207  |
| training/sac_pi/logp_pi        | 5.049222   |
| training/sac_pi/pi_entropy     | 3.2954407  |
| training/sac_pi/pi_global_norm | 1.658852   |
| training/sac_pi/policy_loss    | -223.19778 |
| training/sac_pi/std            | 0.4926929  |
| training/sac_pi/valid_num      | 4931.0     |
| training/sac_Q/q1              | 210.0562   |
| training/sac_Q/q2              | 212.13156  |
| training/sac_Q/q2_loss         | 92.18085   |
| training/sac_Q/q_global_norm   | 234.81282  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16401058  |
| epoch                          | 776         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4987.9316   |
| evaluation/return-max          | 5077.3403   |
| evaluation/return-min          | 4934.6064   |
| evaluation/return-std          | 38.340836   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46235       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4987.9316   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 218.59424   |
| Q-std                          | 116.328     |
| Q_loss                         | 107.46733   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 776         |
| times/epoch_after_hook         | 1.99e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000717    |
| times/evaluation_paths         | 37.5        |
| times/timestep_after_hook      | 0.00397     |
| times/timestep_before_hook     | 0.00839     |
| times/train                    | 60.1        |
| timestep                       | 1000        |
| timesteps_total                | 777000      |
| train-steps                    | 777000      |
| training/Q/q1_loss             | 72.66635    |
| training/sac_pi/alpha          | 0.16406089  |
| training/sac_pi/alpha_loss     | -0.70051277 |
| training/sac_pi/logp_pi        | 3.8344643   |
| training/sac_pi/pi_entropy     | 3.3420205   |
| training/sac_pi/pi_global_norm | 2.1734073   |
| training/sac_pi/policy_loss    | -220.11649  |
| training/sac_pi/std            | 0.5049239   |
| training/sac_pi/valid_num      | 5005.0      |
| training/sac_Q/q1              | 213.32344   |
| training/sac_Q/q2              | 211.87247   |
| training/sac_Q/q2_loss         | 72.22227    |
| training/sac_Q/q_global_norm   | 240.64392   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17152973 |
| epoch                          | 777        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4939.3193  |
| evaluation/return-max          | 5012.324   |
| evaluation/return-min          | 4853.592   |
| evaluation/return-std          | 52.341328  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46473      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4939.3193  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 219.72531  |
| Q-std                          | 108.97309  |
| Q_loss                         | 102.24927  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 777        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000367   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000514   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 778000     |
| train-steps                    | 778000     |
| training/Q/q1_loss             | 109.56707  |
| training/sac_pi/alpha          | 0.17152195 |
| training/sac_pi/alpha_loss     | 0.22880203 |
| training/sac_pi/logp_pi        | 4.637141   |
| training/sac_pi/pi_entropy     | 3.5113697  |
| training/sac_pi/pi_global_norm | 1.634123   |
| training/sac_pi/policy_loss    | -224.98131 |
| training/sac_pi/std            | 0.5070852  |
| training/sac_pi/valid_num      | 4948.0     |
| training/sac_Q/q1              | 215.11739  |
| training/sac_Q/q2              | 216.8187   |
| training/sac_Q/q2_loss         | 109.08448  |
| training/sac_Q/q_global_norm   | 267.76242  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1739001   |
| epoch                          | 778         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5080.4673   |
| evaluation/return-max          | 5159.6396   |
| evaluation/return-min          | 4980.853    |
| evaluation/return-std          | 54.34689    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46398       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5080.4673   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 211.82938   |
| Q-std                          | 119.16334   |
| Q_loss                         | 109.71297   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 778         |
| times/epoch_after_hook         | 1.98e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000884    |
| times/evaluation_paths         | 34.7        |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 779000      |
| train-steps                    | 779000      |
| training/Q/q1_loss             | 102.16963   |
| training/sac_pi/alpha          | 0.17392449  |
| training/sac_pi/alpha_loss     | -0.11975175 |
| training/sac_pi/logp_pi        | 4.385639    |
| training/sac_pi/pi_entropy     | 3.6385179   |
| training/sac_pi/pi_global_norm | 2.0086458   |
| training/sac_pi/policy_loss    | -216.55202  |
| training/sac_pi/std            | 0.5271779   |
| training/sac_pi/valid_num      | 4905.0      |
| training/sac_Q/q1              | 203.8989    |
| training/sac_Q/q2              | 205.16806   |
| training/sac_Q/q2_loss         | 101.047775  |
| training/sac_Q/q_global_norm   | 225.24149   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16671039  |
| epoch                          | 779         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5190.5127   |
| evaluation/return-max          | 5231.497    |
| evaluation/return-min          | 5074.629    |
| evaluation/return-std          | 42.68464    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 86.8        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46309       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5190.5127   |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 215.57141   |
| Q-std                          | 147.5096    |
| Q_loss                         | 87.382835   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 779         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000571    |
| times/evaluation_paths         | 33.5        |
| times/timestep_after_hook      | 0.00412     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 780000      |
| train-steps                    | 780000      |
| training/Q/q1_loss             | 92.401245   |
| training/sac_pi/alpha          | 0.16669425  |
| training/sac_pi/alpha_loss     | -0.06662817 |
| training/sac_pi/logp_pi        | 3.925218    |
| training/sac_pi/pi_entropy     | 3.473079    |
| training/sac_pi/pi_global_norm | 1.5207007   |
| training/sac_pi/policy_loss    | -228.0838   |
| training/sac_pi/std            | 0.49459496  |
| training/sac_pi/valid_num      | 4949.0      |
| training/sac_Q/q1              | 218.7063    |
| training/sac_Q/q2              | 218.37346   |
| training/sac_Q/q2_loss         | 92.81568    |
| training/sac_Q/q_global_norm   | 168.28558   |
---------------------------------------------------------------------------------
[WARN] 780 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16704826 |
| epoch                          | 780        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4414.897   |
| evaluation/return-max          | 4484.2046  |
| evaluation/return-min          | 4325.506   |
| evaluation/return-std          | 44.325924  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46461      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4414.897   |
| perf/NormalizedReturn          | 0.961      |
| Q-avg                          | 205.57095  |
| Q-std                          | 101.35259  |
| Q_loss                         | 89.09605   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 780        |
| times/epoch_after_hook         | 2.26e-06   |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000549   |
| times/evaluation_paths         | 33.9       |
| times/timestep_after_hook      | 0.00421    |
| times/timestep_before_hook     | 0.00864    |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 781000     |
| train-steps                    | 781000     |
| training/Q/q1_loss             | 91.52212   |
| training/sac_pi/alpha          | 0.16702491 |
| training/sac_pi/alpha_loss     | 0.32115823 |
| training/sac_pi/logp_pi        | 4.3721113  |
| training/sac_pi/pi_entropy     | 3.5581899  |
| training/sac_pi/pi_global_norm | 1.5700635  |
| training/sac_pi/policy_loss    | -212.04666 |
| training/sac_pi/std            | 0.51709694 |
| training/sac_pi/valid_num      | 4953.0     |
| training/sac_Q/q1              | 206.9729   |
| training/sac_Q/q2              | 204.73822  |
| training/sac_Q/q2_loss         | 92.10886   |
| training/sac_Q/q_global_norm   | 212.58769  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16996782 |
| epoch                          | 781        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4603.374   |
| evaluation/return-max          | 4775.0986  |
| evaluation/return-min          | 4507.3896  |
| evaluation/return-std          | 75.62942   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46432      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4603.374   |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 214.90982  |
| Q-std                          | 120.50594  |
| Q_loss                         | 117.23732  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 781        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.00026    |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000555   |
| times/evaluation_paths         | 32.3       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 59.3       |
| timestep                       | 1000       |
| timesteps_total                | 782000     |
| train-steps                    | 782000     |
| training/Q/q1_loss             | 118.979385 |
| training/sac_pi/alpha          | 0.16995686 |
| training/sac_pi/alpha_loss     | 0.23477983 |
| training/sac_pi/logp_pi        | 3.593804   |
| training/sac_pi/pi_entropy     | 3.3118203  |
| training/sac_pi/pi_global_norm | 1.4966232  |
| training/sac_pi/policy_loss    | -215.45656 |
| training/sac_pi/std            | 0.4543317  |
| training/sac_pi/valid_num      | 5041.0     |
| training/sac_Q/q1              | 211.83505  |
| training/sac_Q/q2              | 212.4065   |
| training/sac_Q/q2_loss         | 119.63976  |
| training/sac_Q/q_global_norm   | 186.77063  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16812591 |
| epoch                          | 782        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4863.0366  |
| evaluation/return-max          | 4938.1963  |
| evaluation/return-min          | 4647.4434  |
| evaluation/return-std          | 78.0036    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46239      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4863.0366  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 225.56705  |
| Q-std                          | 101.758736 |
| Q_loss                         | 101.29306  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 782        |
| times/epoch_after_hook         | 1.99e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000652   |
| times/evaluation_paths         | 35.1       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00855    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 783000     |
| train-steps                    | 783000     |
| training/Q/q1_loss             | 104.45585  |
| training/sac_pi/alpha          | 0.16812098 |
| training/sac_pi/alpha_loss     | 0.43934745 |
| training/sac_pi/logp_pi        | 4.4786534  |
| training/sac_pi/pi_entropy     | 3.4022152  |
| training/sac_pi/pi_global_norm | 2.21019    |
| training/sac_pi/policy_loss    | -213.34596 |
| training/sac_pi/std            | 0.49372846 |
| training/sac_pi/valid_num      | 4986.0     |
| training/sac_Q/q1              | 206.19792  |
| training/sac_Q/q2              | 207.29643  |
| training/sac_Q/q2_loss         | 103.298965 |
| training/sac_Q/q_global_norm   | 207.74228  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16763088 |
| epoch                          | 783        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5117.88    |
| evaluation/return-max          | 5179.0723  |
| evaluation/return-min          | 5006.2397  |
| evaluation/return-std          | 51.46603   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46338      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5117.88    |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 219.9853   |
| Q-std                          | 122.51096  |
| Q_loss                         | 85.1382    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 783        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000148   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000533   |
| times/evaluation_paths         | 36.6       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00861    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 784000     |
| train-steps                    | 784000     |
| training/Q/q1_loss             | 111.87537  |
| training/sac_pi/alpha          | 0.16758022 |
| training/sac_pi/alpha_loss     | 0.3477503  |
| training/sac_pi/logp_pi        | 4.549778   |
| training/sac_pi/pi_entropy     | 3.5637689  |
| training/sac_pi/pi_global_norm | 1.7949741  |
| training/sac_pi/policy_loss    | -220.6283  |
| training/sac_pi/std            | 0.5147591  |
| training/sac_pi/valid_num      | 4939.0     |
| training/sac_Q/q1              | 208.18282  |
| training/sac_Q/q2              | 209.13676  |
| training/sac_Q/q2_loss         | 111.858475 |
| training/sac_Q/q_global_norm   | 253.90503  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17130494  |
| epoch                          | 784         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5229.5967   |
| evaluation/return-max          | 5256.465    |
| evaluation/return-min          | 5182.795    |
| evaluation/return-std          | 24.907291   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46191       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5229.5967   |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 218.72806   |
| Q-std                          | 119.958015  |
| Q_loss                         | 105.782196  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 784         |
| times/epoch_after_hook         | 3.27e-06    |
| times/epoch_before_hook        | 0.000116    |
| times/epoch_rollout_model      | 503         |
| times/evaluation_metrics       | 0.000583    |
| times/evaluation_paths         | 35.7        |
| times/timestep_after_hook      | 0.00409     |
| times/timestep_before_hook     | 0.00863     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 785000      |
| train-steps                    | 785000      |
| training/Q/q1_loss             | 104.09343   |
| training/sac_pi/alpha          | 0.17130192  |
| training/sac_pi/alpha_loss     | -0.14591393 |
| training/sac_pi/logp_pi        | 4.0234604   |
| training/sac_pi/pi_entropy     | 3.3888855   |
| training/sac_pi/pi_global_norm | 1.7807862   |
| training/sac_pi/policy_loss    | -225.21391  |
| training/sac_pi/std            | 0.48823056  |
| training/sac_pi/valid_num      | 4933.0      |
| training/sac_Q/q1              | 214.84221   |
| training/sac_Q/q2              | 216.87312   |
| training/sac_Q/q2_loss         | 103.7021    |
| training/sac_Q/q_global_norm   | 319.14377   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17022875  |
| epoch                          | 785         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5129.811    |
| evaluation/return-max          | 5163.494    |
| evaluation/return-min          | 5096.7837   |
| evaluation/return-std          | 23.561363   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46294       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5129.811    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 211.23831   |
| Q-std                          | 131.86868   |
| Q_loss                         | 78.28436    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 785         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000265    |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000513    |
| times/evaluation_paths         | 33.9        |
| times/timestep_after_hook      | 0.00421     |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 62.4        |
| timestep                       | 1000        |
| timesteps_total                | 786000      |
| train-steps                    | 786000      |
| training/Q/q1_loss             | 81.45207    |
| training/sac_pi/alpha          | 0.170246    |
| training/sac_pi/alpha_loss     | -0.12247387 |
| training/sac_pi/logp_pi        | 4.7453566   |
| training/sac_pi/pi_entropy     | 3.5742126   |
| training/sac_pi/pi_global_norm | 1.4494468   |
| training/sac_pi/policy_loss    | -217.94664  |
| training/sac_pi/std            | 0.5207643   |
| training/sac_pi/valid_num      | 4950.0      |
| training/sac_Q/q1              | 207.86064   |
| training/sac_Q/q2              | 207.31792   |
| training/sac_Q/q2_loss         | 80.94385    |
| training/sac_Q/q_global_norm   | 258.96912   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16254911 |
| epoch                          | 786        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4758.002   |
| evaluation/return-max          | 4824.3335  |
| evaluation/return-min          | 4714.295   |
| evaluation/return-std          | 36.37186   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 87         |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46257      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4758.002   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 215.13118  |
| Q-std                          | 110.56452  |
| Q_loss                         | 118.98029  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 786        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000203   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000525   |
| times/evaluation_paths         | 34.2       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00855    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 787000     |
| train-steps                    | 787000     |
| training/Q/q1_loss             | 95.11549   |
| training/sac_pi/alpha          | 0.16252635 |
| training/sac_pi/alpha_loss     | 0.29605708 |
| training/sac_pi/logp_pi        | 4.927377   |
| training/sac_pi/pi_entropy     | 3.3352885  |
| training/sac_pi/pi_global_norm | 1.8328129  |
| training/sac_pi/policy_loss    | -223.2047  |
| training/sac_pi/std            | 0.5208161  |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 214.89551  |
| training/sac_Q/q2              | 215.32877  |
| training/sac_Q/q2_loss         | 94.21804   |
| training/sac_Q/q_global_norm   | 326.61218  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16344045 |
| epoch                          | 787        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4774.673   |
| evaluation/return-max          | 4878.957   |
| evaluation/return-min          | 4628.3555  |
| evaluation/return-std          | 82.31626   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46252      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4774.673   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 215.99886  |
| Q-std                          | 106.51792  |
| Q_loss                         | 111.80507  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 787        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000532   |
| times/evaluation_paths         | 34.8       |
| times/timestep_after_hook      | 0.00411    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 788000     |
| train-steps                    | 788000     |
| training/Q/q1_loss             | 117.8686   |
| training/sac_pi/alpha          | 0.16346966 |
| training/sac_pi/alpha_loss     | 0.05708484 |
| training/sac_pi/logp_pi        | 4.291959   |
| training/sac_pi/pi_entropy     | 3.5099807  |
| training/sac_pi/pi_global_norm | 1.676574   |
| training/sac_pi/policy_loss    | -219.52905 |
| training/sac_pi/std            | 0.5155562  |
| training/sac_pi/valid_num      | 4953.0     |
| training/sac_Q/q1              | 212.26958  |
| training/sac_Q/q2              | 211.14636  |
| training/sac_Q/q2_loss         | 117.13843  |
| training/sac_Q/q_global_norm   | 226.92766  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1699708  |
| epoch                          | 788        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4997.514   |
| evaluation/return-max          | 5055.251   |
| evaluation/return-min          | 4861.484   |
| evaluation/return-std          | 54.659973  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46282      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4997.514   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 207.77998  |
| Q-std                          | 120.65957  |
| Q_loss                         | 97.25108   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 788        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000156   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 36.9       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00859    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 789000     |
| train-steps                    | 789000     |
| training/Q/q1_loss             | 109.43972  |
| training/sac_pi/alpha          | 0.1699159  |
| training/sac_pi/alpha_loss     | 0.13592783 |
| training/sac_pi/logp_pi        | 4.13309    |
| training/sac_pi/pi_entropy     | 3.3912437  |
| training/sac_pi/pi_global_norm | 2.3569796  |
| training/sac_pi/policy_loss    | -219.91327 |
| training/sac_pi/std            | 0.4813124  |
| training/sac_pi/valid_num      | 4932.0     |
| training/sac_Q/q1              | 210.53427  |
| training/sac_Q/q2              | 210.41951  |
| training/sac_Q/q2_loss         | 109.04197  |
| training/sac_Q/q_global_norm   | 269.5132   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16518116   |
| epoch                          | 789          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4855.685     |
| evaluation/return-max          | 4963.1025    |
| evaluation/return-min          | 4716.165     |
| evaluation/return-std          | 83.75152     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.13         |
| model/origin_ret               | 86.9         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46402        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4855.685     |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 214.86714    |
| Q-std                          | 112.886284   |
| Q_loss                         | 85.20809     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 789          |
| times/epoch_after_hook         | 1.81e-06     |
| times/epoch_before_hook        | 0.000287     |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.000564     |
| times/evaluation_paths         | 34.2         |
| times/timestep_after_hook      | 0.00405      |
| times/timestep_before_hook     | 0.00842      |
| times/train                    | 61.2         |
| timestep                       | 1000         |
| timesteps_total                | 790000       |
| train-steps                    | 790000       |
| training/Q/q1_loss             | 91.2387      |
| training/sac_pi/alpha          | 0.16515493   |
| training/sac_pi/alpha_loss     | -0.082775004 |
| training/sac_pi/logp_pi        | 3.5498142    |
| training/sac_pi/pi_entropy     | 3.3874688    |
| training/sac_pi/pi_global_norm | 1.6412019    |
| training/sac_pi/policy_loss    | -222.15271   |
| training/sac_pi/std            | 0.47511297   |
| training/sac_pi/valid_num      | 4962.0       |
| training/sac_Q/q1              | 214.4602     |
| training/sac_Q/q2              | 214.15398    |
| training/sac_Q/q2_loss         | 91.61257     |
| training/sac_Q/q_global_norm   | 199.481      |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17086352 |
| epoch                          | 790        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4970.7803  |
| evaluation/return-max          | 5041.359   |
| evaluation/return-min          | 4883.7305  |
| evaluation/return-std          | 41.063484  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46346      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4970.7803  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 207.39091  |
| Q-std                          | 129.09567  |
| Q_loss                         | 107.154564 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 790        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000555   |
| times/evaluation_paths         | 37.1       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 60.2       |
| timestep                       | 1000       |
| timesteps_total                | 791000     |
| train-steps                    | 791000     |
| training/Q/q1_loss             | 84.92615   |
| training/sac_pi/alpha          | 0.17082863 |
| training/sac_pi/alpha_loss     | 0.2119087  |
| training/sac_pi/logp_pi        | 5.060002   |
| training/sac_pi/pi_entropy     | 3.5859559  |
| training/sac_pi/pi_global_norm | 2.3428454  |
| training/sac_pi/policy_loss    | -224.8291  |
| training/sac_pi/std            | 0.54202807 |
| training/sac_pi/valid_num      | 4853.0     |
| training/sac_Q/q1              | 206.23746  |
| training/sac_Q/q2              | 206.11816  |
| training/sac_Q/q2_loss         | 85.39808   |
| training/sac_Q/q_global_norm   | 200.94695  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1769841   |
| epoch                          | 791         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4840.155    |
| evaluation/return-max          | 4900.376    |
| evaluation/return-min          | 4741.4326   |
| evaluation/return-std          | 49.24501    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46330       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4840.155    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 209.02219   |
| Q-std                          | 127.73981   |
| Q_loss                         | 103.87029   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 791         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000506    |
| times/evaluation_paths         | 34          |
| times/timestep_after_hook      | 0.00429     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 60.4        |
| timestep                       | 1000        |
| timesteps_total                | 792000      |
| train-steps                    | 792000      |
| training/Q/q1_loss             | 106.44409   |
| training/sac_pi/alpha          | 0.17700034  |
| training/sac_pi/alpha_loss     | -0.08529145 |
| training/sac_pi/logp_pi        | 3.4258618   |
| training/sac_pi/pi_entropy     | 3.3934054   |
| training/sac_pi/pi_global_norm | 1.499314    |
| training/sac_pi/policy_loss    | -227.71799  |
| training/sac_pi/std            | 0.45930794  |
| training/sac_pi/valid_num      | 5032.0      |
| training/sac_Q/q1              | 223.76228   |
| training/sac_Q/q2              | 224.16434   |
| training/sac_Q/q2_loss         | 106.90024   |
| training/sac_Q/q_global_norm   | 246.06718   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1688982   |
| epoch                          | 792         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4657.547    |
| evaluation/return-max          | 4735.763    |
| evaluation/return-min          | 4515.4126   |
| evaluation/return-std          | 60.52781    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46152       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4657.547    |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 217.52454   |
| Q-std                          | 99.77851    |
| Q_loss                         | 95.46423    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 792         |
| times/epoch_after_hook         | 3.65e-06    |
| times/epoch_before_hook        | 0.00014     |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000593    |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00407     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 793000      |
| train-steps                    | 793000      |
| training/Q/q1_loss             | 122.13977   |
| training/sac_pi/alpha          | 0.16887677  |
| training/sac_pi/alpha_loss     | 0.081156775 |
| training/sac_pi/logp_pi        | 4.8635325   |
| training/sac_pi/pi_entropy     | 3.3114228   |
| training/sac_pi/pi_global_norm | 2.1976316   |
| training/sac_pi/policy_loss    | -217.48602  |
| training/sac_pi/std            | 0.49555436  |
| training/sac_pi/valid_num      | 4952.0      |
| training/sac_Q/q1              | 207.7814    |
| training/sac_Q/q2              | 208.89929   |
| training/sac_Q/q2_loss         | 121.111694  |
| training/sac_Q/q_global_norm   | 238.42853   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1711249  |
| epoch                          | 793        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4852.82    |
| evaluation/return-max          | 4894.169   |
| evaluation/return-min          | 4816.121   |
| evaluation/return-std          | 24.408342  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46233      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4852.82    |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 215.03671  |
| Q-std                          | 152.12431  |
| Q_loss                         | 82.782616  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 793        |
| times/epoch_after_hook         | 1.99e-06   |
| times/epoch_before_hook        | 0.000273   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000658   |
| times/evaluation_paths         | 34.5       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 794000     |
| train-steps                    | 794000     |
| training/Q/q1_loss             | 93.28728   |
| training/sac_pi/alpha          | 0.1710768  |
| training/sac_pi/alpha_loss     | 0.17959423 |
| training/sac_pi/logp_pi        | 4.5812426  |
| training/sac_pi/pi_entropy     | 3.6148255  |
| training/sac_pi/pi_global_norm | 1.9976972  |
| training/sac_pi/policy_loss    | -220.4537  |
| training/sac_pi/std            | 0.524292   |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 209.75058  |
| training/sac_Q/q2              | 208.3416   |
| training/sac_Q/q2_loss         | 93.23972   |
| training/sac_Q/q_global_norm   | 194.34065  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17094661   |
| epoch                          | 794          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4719.2017    |
| evaluation/return-max          | 4818.7827    |
| evaluation/return-min          | 4611.6714    |
| evaluation/return-std          | 60.228386    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.03         |
| model/origin_ret               | 85.5         |
| model/penalty_ret              | 80.4         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46240        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4719.2017    |
| perf/NormalizedReturn          | 1.03         |
| Q-avg                          | 202.34702    |
| Q-std                          | 126.68048    |
| Q_loss                         | 124.43303    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 794          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.00014      |
| times/epoch_rollout_model      | 495          |
| times/evaluation_metrics       | 0.000495     |
| times/evaluation_paths         | 34.8         |
| times/timestep_after_hook      | 0.00391      |
| times/timestep_before_hook     | 0.00849      |
| times/train                    | 60.7         |
| timestep                       | 1000         |
| timesteps_total                | 795000       |
| train-steps                    | 795000       |
| training/Q/q1_loss             | 87.863266    |
| training/sac_pi/alpha          | 0.17097506   |
| training/sac_pi/alpha_loss     | -0.061924588 |
| training/sac_pi/logp_pi        | 3.2869       |
| training/sac_pi/pi_entropy     | 3.283865     |
| training/sac_pi/pi_global_norm | 1.8027877    |
| training/sac_pi/policy_loss    | -223.03325   |
| training/sac_pi/std            | 0.44738623   |
| training/sac_pi/valid_num      | 5067.0       |
| training/sac_Q/q1              | 219.70464    |
| training/sac_Q/q2              | 219.35478    |
| training/sac_Q/q2_loss         | 88.0745      |
| training/sac_Q/q_global_norm   | 178.29163    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16927457 |
| epoch                          | 795        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4969.0337  |
| evaluation/return-max          | 5013.0146  |
| evaluation/return-min          | 4920.1167  |
| evaluation/return-std          | 31.998734  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46254      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4969.0337  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 198.85168  |
| Q-std                          | 114.7236   |
| Q_loss                         | 95.37422   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 795        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000113   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000587   |
| times/evaluation_paths         | 33.9       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 59.4       |
| timestep                       | 1000       |
| timesteps_total                | 796000     |
| train-steps                    | 796000     |
| training/Q/q1_loss             | 100.884514 |
| training/sac_pi/alpha          | 0.16927424 |
| training/sac_pi/alpha_loss     | 0.06919516 |
| training/sac_pi/logp_pi        | 4.295015   |
| training/sac_pi/pi_entropy     | 3.4144263  |
| training/sac_pi/pi_global_norm | 1.5515872  |
| training/sac_pi/policy_loss    | -228.9618  |
| training/sac_pi/std            | 0.4974325  |
| training/sac_pi/valid_num      | 4929.0     |
| training/sac_Q/q1              | 218.42856  |
| training/sac_Q/q2              | 218.67036  |
| training/sac_Q/q2_loss         | 100.25431  |
| training/sac_Q/q_global_norm   | 206.79248  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16228202 |
| epoch                          | 796        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5210.6396  |
| evaluation/return-max          | 5239.627   |
| evaluation/return-min          | 5165.6455  |
| evaluation/return-std          | 21.942335  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46364      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5210.6396  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 214.65926  |
| Q-std                          | 113.62548  |
| Q_loss                         | 101.62729  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 796        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000715   |
| times/evaluation_paths         | 33.2       |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 59         |
| timestep                       | 1000       |
| timesteps_total                | 797000     |
| train-steps                    | 797000     |
| training/Q/q1_loss             | 101.19953  |
| training/sac_pi/alpha          | 0.1623119  |
| training/sac_pi/alpha_loss     | -0.5692162 |
| training/sac_pi/logp_pi        | 4.7284403  |
| training/sac_pi/pi_entropy     | 3.3488307  |
| training/sac_pi/pi_global_norm | 1.8687925  |
| training/sac_pi/policy_loss    | -224.65588 |
| training/sac_pi/std            | 0.51311135 |
| training/sac_pi/valid_num      | 4922.0     |
| training/sac_Q/q1              | 210.47156  |
| training/sac_Q/q2              | 215.30374  |
| training/sac_Q/q2_loss         | 102.39952  |
| training/sac_Q/q_global_norm   | 262.65997  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16981241 |
| epoch                          | 797        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4837.8955  |
| evaluation/return-max          | 4927.9927  |
| evaluation/return-min          | 4685.3413  |
| evaluation/return-std          | 73.12853   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46292      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4837.8955  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 216.36829  |
| Q-std                          | 130.86578  |
| Q_loss                         | 90.9998    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 797        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000288   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000594   |
| times/evaluation_paths         | 35.3       |
| times/timestep_after_hook      | 0.00411    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 798000     |
| train-steps                    | 798000     |
| training/Q/q1_loss             | 97.00955   |
| training/sac_pi/alpha          | 0.16980277 |
| training/sac_pi/alpha_loss     | 0.31038526 |
| training/sac_pi/logp_pi        | 4.6604614  |
| training/sac_pi/pi_entropy     | 3.4388967  |
| training/sac_pi/pi_global_norm | 1.6544322  |
| training/sac_pi/policy_loss    | -214.19305 |
| training/sac_pi/std            | 0.5056576  |
| training/sac_pi/valid_num      | 4974.0     |
| training/sac_Q/q1              | 204.28902  |
| training/sac_Q/q2              | 206.46701  |
| training/sac_Q/q2_loss         | 98.56038   |
| training/sac_Q/q_global_norm   | 238.01486  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1637444  |
| epoch                          | 798        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4938.809   |
| evaluation/return-max          | 4994.4106  |
| evaluation/return-min          | 4872.119   |
| evaluation/return-std          | 46.27964   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46341      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4938.809   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 200.86731  |
| Q-std                          | 127.680916 |
| Q_loss                         | 128.678    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 798        |
| times/epoch_after_hook         | 2.01e-06   |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000729   |
| times/evaluation_paths         | 36.8       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 59.4       |
| timestep                       | 1000       |
| timesteps_total                | 799000     |
| train-steps                    | 799000     |
| training/Q/q1_loss             | 99.09049   |
| training/sac_pi/alpha          | 0.16371988 |
| training/sac_pi/alpha_loss     | 0.11650781 |
| training/sac_pi/logp_pi        | 4.7525077  |
| training/sac_pi/pi_entropy     | 3.4322963  |
| training/sac_pi/pi_global_norm | 1.8312714  |
| training/sac_pi/policy_loss    | -218.29216 |
| training/sac_pi/std            | 0.5152987  |
| training/sac_pi/valid_num      | 4898.0     |
| training/sac_Q/q1              | 208.24374  |
| training/sac_Q/q2              | 210.48515  |
| training/sac_Q/q2_loss         | 98.616295  |
| training/sac_Q/q_global_norm   | 223.06367  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16503945 |
| epoch                          | 799        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4854.9795  |
| evaluation/return-max          | 4992.7197  |
| evaluation/return-min          | 4750.1865  |
| evaluation/return-std          | 64.99409   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46225      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4854.9795  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 206.86043  |
| Q-std                          | 119.30674  |
| Q_loss                         | 95.53116   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 799        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000157   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000531   |
| times/evaluation_paths         | 35.8       |
| times/timestep_after_hook      | 0.00413    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 800000     |
| train-steps                    | 800000     |
| training/Q/q1_loss             | 108.59741  |
| training/sac_pi/alpha          | 0.1650212  |
| training/sac_pi/alpha_loss     | 0.22548078 |
| training/sac_pi/logp_pi        | 4.1895742  |
| training/sac_pi/pi_entropy     | 3.3770852  |
| training/sac_pi/pi_global_norm | 1.4714446  |
| training/sac_pi/policy_loss    | -221.15552 |
| training/sac_pi/std            | 0.47980925 |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 209.9072   |
| training/sac_Q/q2              | 211.38022  |
| training/sac_Q/q2_loss         | 108.19904  |
| training/sac_Q/q_global_norm   | 199.87305  |
--------------------------------------------------------------------------------
[WARN] 800 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16494976  |
| epoch                          | 800         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4925.235    |
| evaluation/return-max          | 5020.641    |
| evaluation/return-min          | 4881.835    |
| evaluation/return-std          | 43.01143    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46194       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4925.235    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 212.9548    |
| Q-std                          | 140.40175   |
| Q_loss                         | 86.8603     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 800         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000683    |
| times/evaluation_paths         | 35.8        |
| times/timestep_after_hook      | 0.00408     |
| times/timestep_before_hook     | 0.00855     |
| times/train                    | 60.3        |
| timestep                       | 1000        |
| timesteps_total                | 801000      |
| train-steps                    | 801000      |
| training/Q/q1_loss             | 112.134865  |
| training/sac_pi/alpha          | 0.16491705  |
| training/sac_pi/alpha_loss     | -0.09263916 |
| training/sac_pi/logp_pi        | 3.9590485   |
| training/sac_pi/pi_entropy     | 3.4562035   |
| training/sac_pi/pi_global_norm | 1.5142049   |
| training/sac_pi/policy_loss    | -217.7014   |
| training/sac_pi/std            | 0.49201438  |
| training/sac_pi/valid_num      | 4969.0      |
| training/sac_Q/q1              | 210.58084   |
| training/sac_Q/q2              | 211.09575   |
| training/sac_Q/q2_loss         | 112.93032   |
| training/sac_Q/q_global_norm   | 286.3253    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16674991  |
| epoch                          | 801         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4807.8193   |
| evaluation/return-max          | 4941.9307   |
| evaluation/return-min          | 4721.3115   |
| evaluation/return-std          | 57.178062   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46215       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4807.8193   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 216.20613   |
| Q-std                          | 123.30084   |
| Q_loss                         | 101.59426   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 801         |
| times/epoch_after_hook         | 3.14e-06    |
| times/epoch_before_hook        | 0.000268    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000515    |
| times/evaluation_paths         | 36.3        |
| times/timestep_after_hook      | 0.00409     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 65          |
| timestep                       | 1000        |
| timesteps_total                | 802000      |
| train-steps                    | 802000      |
| training/Q/q1_loss             | 105.410835  |
| training/sac_pi/alpha          | 0.16675888  |
| training/sac_pi/alpha_loss     | -0.23032121 |
| training/sac_pi/logp_pi        | 4.1291037   |
| training/sac_pi/pi_entropy     | 3.4420357   |
| training/sac_pi/pi_global_norm | 2.2968714   |
| training/sac_pi/policy_loss    | -223.35898  |
| training/sac_pi/std            | 0.5025266   |
| training/sac_pi/valid_num      | 4953.0      |
| training/sac_Q/q1              | 215.59131   |
| training/sac_Q/q2              | 214.34856   |
| training/sac_Q/q2_loss         | 105.72747   |
| training/sac_Q/q_global_norm   | 223.14667   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16534348  |
| epoch                          | 802         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4862.1304   |
| evaluation/return-max          | 5000.656    |
| evaluation/return-min          | 4733.434    |
| evaluation/return-std          | 85.38424    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46221       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4862.1304   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 201.44461   |
| Q-std                          | 129.2877    |
| Q_loss                         | 88.80975    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 802         |
| times/epoch_after_hook         | 2.15e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000581    |
| times/evaluation_paths         | 37.1        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00862     |
| times/train                    | 64.8        |
| timestep                       | 1000        |
| timesteps_total                | 803000      |
| train-steps                    | 803000      |
| training/Q/q1_loss             | 100.61016   |
| training/sac_pi/alpha          | 0.16531107  |
| training/sac_pi/alpha_loss     | 0.052877884 |
| training/sac_pi/logp_pi        | 3.824078    |
| training/sac_pi/pi_entropy     | 3.4158714   |
| training/sac_pi/pi_global_norm | 1.4561197   |
| training/sac_pi/policy_loss    | -227.2752   |
| training/sac_pi/std            | 0.47954795  |
| training/sac_pi/valid_num      | 4975.0      |
| training/sac_Q/q1              | 216.06319   |
| training/sac_Q/q2              | 218.11568   |
| training/sac_Q/q2_loss         | 99.794426   |
| training/sac_Q/q_global_norm   | 206.98807   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16753429  |
| epoch                          | 803         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4608.553    |
| evaluation/return-max          | 4645.2285   |
| evaluation/return-min          | 4537.6475   |
| evaluation/return-std          | 31.329428   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46339       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4608.553    |
| perf/NormalizedReturn          | 1           |
| Q-avg                          | 220.30034   |
| Q-std                          | 127.42334   |
| Q_loss                         | 87.82812    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 803         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000143    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000524    |
| times/evaluation_paths         | 38.6        |
| times/timestep_after_hook      | 0.00697     |
| times/timestep_before_hook     | 0.00871     |
| times/train                    | 72.6        |
| timestep                       | 1000        |
| timesteps_total                | 804000      |
| train-steps                    | 804000      |
| training/Q/q1_loss             | 112.04544   |
| training/sac_pi/alpha          | 0.16755576  |
| training/sac_pi/alpha_loss     | -0.25951275 |
| training/sac_pi/logp_pi        | 4.7761927   |
| training/sac_pi/pi_entropy     | 3.3014846   |
| training/sac_pi/pi_global_norm | 1.6061255   |
| training/sac_pi/policy_loss    | -219.21051  |
| training/sac_pi/std            | 0.48168245  |
| training/sac_pi/valid_num      | 4957.0      |
| training/sac_Q/q1              | 209.568     |
| training/sac_Q/q2              | 211.26376   |
| training/sac_Q/q2_loss         | 109.94438   |
| training/sac_Q/q_global_norm   | 295.39948   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17113702  |
| epoch                          | 804         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4771.802    |
| evaluation/return-max          | 4847.871    |
| evaluation/return-min          | 4738.0615   |
| evaluation/return-std          | 32.63942    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46234       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4771.802    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 209.361     |
| Q-std                          | 156.31433   |
| Q_loss                         | 98.01219    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 804         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000563    |
| times/evaluation_paths         | 40.5        |
| times/timestep_after_hook      | 0.00415     |
| times/timestep_before_hook     | 0.00872     |
| times/train                    | 68          |
| timestep                       | 1000        |
| timesteps_total                | 805000      |
| train-steps                    | 805000      |
| training/Q/q1_loss             | 104.32368   |
| training/sac_pi/alpha          | 0.17114006  |
| training/sac_pi/alpha_loss     | -0.08324398 |
| training/sac_pi/logp_pi        | 3.9157176   |
| training/sac_pi/pi_entropy     | 3.4612224   |
| training/sac_pi/pi_global_norm | 2.1407948   |
| training/sac_pi/policy_loss    | -221.01341  |
| training/sac_pi/std            | 0.47771809  |
| training/sac_pi/valid_num      | 4940.0      |
| training/sac_Q/q1              | 212.35971   |
| training/sac_Q/q2              | 211.3417    |
| training/sac_Q/q2_loss         | 104.12122   |
| training/sac_Q/q_global_norm   | 207.16322   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16250288  |
| epoch                          | 805         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4737.9014   |
| evaluation/return-max          | 4884.5596   |
| evaluation/return-min          | 4604.4814   |
| evaluation/return-std          | 93.55227    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46163       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4737.9014   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 202.6517    |
| Q-std                          | 99.431114   |
| Q_loss                         | 107.37992   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 805         |
| times/epoch_after_hook         | 1.93e-06    |
| times/epoch_before_hook        | 0.000269    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000579    |
| times/evaluation_paths         | 40.1        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 69.6        |
| timestep                       | 1000        |
| timesteps_total                | 806000      |
| train-steps                    | 806000      |
| training/Q/q1_loss             | 87.42708    |
| training/sac_pi/alpha          | 0.16249111  |
| training/sac_pi/alpha_loss     | 0.014508377 |
| training/sac_pi/logp_pi        | 3.9264748   |
| training/sac_pi/pi_entropy     | 3.4806755   |
| training/sac_pi/pi_global_norm | 1.6911887   |
| training/sac_pi/policy_loss    | -224.67987  |
| training/sac_pi/std            | 0.5073641   |
| training/sac_pi/valid_num      | 4977.0      |
| training/sac_Q/q1              | 216.50586   |
| training/sac_Q/q2              | 217.0542    |
| training/sac_Q/q2_loss         | 86.40377    |
| training/sac_Q/q_global_norm   | 246.91986   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17167282  |
| epoch                          | 806         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4917.0674   |
| evaluation/return-max          | 5002.451    |
| evaluation/return-min          | 4825.176    |
| evaluation/return-std          | 48.85322    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46300       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4917.0674   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 217.51724   |
| Q-std                          | 112.76343   |
| Q_loss                         | 99.93364    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 806         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.000143    |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.00048     |
| times/evaluation_paths         | 44.3        |
| times/timestep_after_hook      | 0.00429     |
| times/timestep_before_hook     | 0.00878     |
| times/train                    | 73.9        |
| timestep                       | 1000        |
| timesteps_total                | 807000      |
| train-steps                    | 807000      |
| training/Q/q1_loss             | 88.412384   |
| training/sac_pi/alpha          | 0.17170653  |
| training/sac_pi/alpha_loss     | -0.54517275 |
| training/sac_pi/logp_pi        | 3.4041076   |
| training/sac_pi/pi_entropy     | 3.6792896   |
| training/sac_pi/pi_global_norm | 1.5877136   |
| training/sac_pi/policy_loss    | -221.984    |
| training/sac_pi/std            | 0.50421053  |
| training/sac_pi/valid_num      | 4969.0      |
| training/sac_Q/q1              | 215.02971   |
| training/sac_Q/q2              | 215.78616   |
| training/sac_Q/q2_loss         | 88.326294   |
| training/sac_Q/q_global_norm   | 209.5393    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16632462 |
| epoch                          | 807        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5060.969   |
| evaluation/return-max          | 5108.1333  |
| evaluation/return-min          | 5009.4653  |
| evaluation/return-std          | 27.923029  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46405      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5060.969   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 216.56381  |
| Q-std                          | 146.82057  |
| Q_loss                         | 99.23847   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 807        |
| times/epoch_after_hook         | 1.99e-06   |
| times/epoch_before_hook        | 8.31e-05   |
| times/epoch_rollout_model      | 511        |
| times/evaluation_metrics       | 0.00059    |
| times/evaluation_paths         | 36.9       |
| times/timestep_after_hook      | 0.00463    |
| times/timestep_before_hook     | 0.0087     |
| times/train                    | 64.9       |
| timestep                       | 1000       |
| timesteps_total                | 808000     |
| train-steps                    | 808000     |
| training/Q/q1_loss             | 102.27989  |
| training/sac_pi/alpha          | 0.16629934 |
| training/sac_pi/alpha_loss     | 0.1688435  |
| training/sac_pi/logp_pi        | 4.3710938  |
| training/sac_pi/pi_entropy     | 3.4558835  |
| training/sac_pi/pi_global_norm | 1.4059225  |
| training/sac_pi/policy_loss    | -234.23808 |
| training/sac_pi/std            | 0.49533728 |
| training/sac_pi/valid_num      | 4981.0     |
| training/sac_Q/q1              | 223.15157  |
| training/sac_Q/q2              | 225.40616  |
| training/sac_Q/q2_loss         | 102.297455 |
| training/sac_Q/q_global_norm   | 270.83612  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16442774  |
| epoch                          | 808         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4823.0913   |
| evaluation/return-max          | 4901.4907   |
| evaluation/return-min          | 4702.1553   |
| evaluation/return-std          | 53.934753   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46222       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4823.0913   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 212.62119   |
| Q-std                          | 140.09506   |
| Q_loss                         | 85.55132    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 808         |
| times/epoch_after_hook         | 2.01e-06    |
| times/epoch_before_hook        | 0.000136    |
| times/epoch_rollout_model      | 536         |
| times/evaluation_metrics       | 0.000527    |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.00408     |
| times/timestep_before_hook     | 0.00911     |
| times/train                    | 66.4        |
| timestep                       | 1000        |
| timesteps_total                | 809000      |
| train-steps                    | 809000      |
| training/Q/q1_loss             | 94.176155   |
| training/sac_pi/alpha          | 0.16440932  |
| training/sac_pi/alpha_loss     | -0.08123788 |
| training/sac_pi/logp_pi        | 4.7920146   |
| training/sac_pi/pi_entropy     | 3.18137     |
| training/sac_pi/pi_global_norm | 1.5608268   |
| training/sac_pi/policy_loss    | -227.35905  |
| training/sac_pi/std            | 0.4776343   |
| training/sac_pi/valid_num      | 4923.0      |
| training/sac_Q/q1              | 209.9126    |
| training/sac_Q/q2              | 211.34428   |
| training/sac_Q/q2_loss         | 92.50799    |
| training/sac_Q/q_global_norm   | 206.58214   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16527943  |
| epoch                          | 809         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5120.392    |
| evaluation/return-max          | 5206.9097   |
| evaluation/return-min          | 5058.4565   |
| evaluation/return-std          | 50.144894   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46393       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5120.392    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 214.186     |
| Q-std                          | 140.4819    |
| Q_loss                         | 78.025505   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 809         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000395    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000614    |
| times/evaluation_paths         | 34.9        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 61.8        |
| timestep                       | 1000        |
| timesteps_total                | 810000      |
| train-steps                    | 810000      |
| training/Q/q1_loss             | 118.28892   |
| training/sac_pi/alpha          | 0.16528183  |
| training/sac_pi/alpha_loss     | 0.034463633 |
| training/sac_pi/logp_pi        | 4.4219985   |
| training/sac_pi/pi_entropy     | 3.448547    |
| training/sac_pi/pi_global_norm | 2.2069674   |
| training/sac_pi/policy_loss    | -215.50325  |
| training/sac_pi/std            | 0.50106823  |
| training/sac_pi/valid_num      | 4966.0      |
| training/sac_Q/q1              | 204.55115   |
| training/sac_Q/q2              | 204.59354   |
| training/sac_Q/q2_loss         | 119.41747   |
| training/sac_Q/q_global_norm   | 218.2143    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1653503  |
| epoch                          | 810        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4904.124   |
| evaluation/return-max          | 4964.064   |
| evaluation/return-min          | 4819.781   |
| evaluation/return-std          | 44.7572    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46370      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4904.124   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 208.4801   |
| Q-std                          | 119.37633  |
| Q_loss                         | 98.58249   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 810        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000531   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.00406    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 63.3       |
| timestep                       | 1000       |
| timesteps_total                | 811000     |
| train-steps                    | 811000     |
| training/Q/q1_loss             | 96.04384   |
| training/sac_pi/alpha          | 0.16531736 |
| training/sac_pi/alpha_loss     | 0.10141982 |
| training/sac_pi/logp_pi        | 3.7732456  |
| training/sac_pi/pi_entropy     | 3.3063672  |
| training/sac_pi/pi_global_norm | 1.940435   |
| training/sac_pi/policy_loss    | -227.70718 |
| training/sac_pi/std            | 0.46174127 |
| training/sac_pi/valid_num      | 5022.0     |
| training/sac_Q/q1              | 222.19067  |
| training/sac_Q/q2              | 222.3051   |
| training/sac_Q/q2_loss         | 95.50258   |
| training/sac_Q/q_global_norm   | 287.6556   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17085649  |
| epoch                          | 811         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4780.61     |
| evaluation/return-max          | 4865.543    |
| evaluation/return-min          | 4711.2607   |
| evaluation/return-std          | 42.119347   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46267       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4780.61     |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 208.43086   |
| Q-std                          | 150.42188   |
| Q_loss                         | 114.03743   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 811         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000669    |
| times/evaluation_paths         | 35.6        |
| times/timestep_after_hook      | 0.00408     |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 62.9        |
| timestep                       | 1000        |
| timesteps_total                | 812000      |
| train-steps                    | 812000      |
| training/Q/q1_loss             | 87.464195   |
| training/sac_pi/alpha          | 0.17086875  |
| training/sac_pi/alpha_loss     | -0.61816746 |
| training/sac_pi/logp_pi        | 3.6082063   |
| training/sac_pi/pi_entropy     | 3.5097477   |
| training/sac_pi/pi_global_norm | 1.5833795   |
| training/sac_pi/policy_loss    | -222.96538  |
| training/sac_pi/std            | 0.4891184   |
| training/sac_pi/valid_num      | 4956.0      |
| training/sac_Q/q1              | 215.71855   |
| training/sac_Q/q2              | 215.81625   |
| training/sac_Q/q2_loss         | 86.21227    |
| training/sac_Q/q_global_norm   | 191.78392   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1669989   |
| epoch                          | 812         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4871.8076   |
| evaluation/return-max          | 4957.081    |
| evaluation/return-min          | 4817.9365   |
| evaluation/return-std          | 43.699764   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46515       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4871.8076   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 205.83443   |
| Q-std                          | 99.885      |
| Q_loss                         | 103.48889   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 812         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000624    |
| times/evaluation_paths         | 36.4        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.0087      |
| times/train                    | 62.2        |
| timestep                       | 1000        |
| timesteps_total                | 813000      |
| train-steps                    | 813000      |
| training/Q/q1_loss             | 101.790276  |
| training/sac_pi/alpha          | 0.16699672  |
| training/sac_pi/alpha_loss     | 0.041010473 |
| training/sac_pi/logp_pi        | 4.488701    |
| training/sac_pi/pi_entropy     | 3.4192307   |
| training/sac_pi/pi_global_norm | 1.8225437   |
| training/sac_pi/policy_loss    | -217.97644  |
| training/sac_pi/std            | 0.50330555  |
| training/sac_pi/valid_num      | 4935.0      |
| training/sac_Q/q1              | 206.15396   |
| training/sac_Q/q2              | 207.72836   |
| training/sac_Q/q2_loss         | 102.09639   |
| training/sac_Q/q_global_norm   | 303.9043    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17041272  |
| epoch                          | 813         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4953.379    |
| evaluation/return-max          | 5045.052    |
| evaluation/return-min          | 4880.7124   |
| evaluation/return-std          | 51.810055   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46400       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4953.379    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 220.80746   |
| Q-std                          | 115.076614  |
| Q_loss                         | 72.10363    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 813         |
| times/epoch_after_hook         | 2.08e-06    |
| times/epoch_before_hook        | 0.000287    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000579    |
| times/evaluation_paths         | 37.5        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.00841     |
| times/train                    | 62.7        |
| timestep                       | 1000        |
| timesteps_total                | 814000      |
| train-steps                    | 814000      |
| training/Q/q1_loss             | 86.805115   |
| training/sac_pi/alpha          | 0.1704377   |
| training/sac_pi/alpha_loss     | -0.14190842 |
| training/sac_pi/logp_pi        | 5.0954733   |
| training/sac_pi/pi_entropy     | 3.5700092   |
| training/sac_pi/pi_global_norm | 2.3490884   |
| training/sac_pi/policy_loss    | -222.92206  |
| training/sac_pi/std            | 0.5333634   |
| training/sac_pi/valid_num      | 4867.0      |
| training/sac_Q/q1              | 205.34537   |
| training/sac_Q/q2              | 203.95154   |
| training/sac_Q/q2_loss         | 86.91243    |
| training/sac_Q/q_global_norm   | 212.37833   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16447285 |
| epoch                          | 814        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4960.121   |
| evaluation/return-max          | 5015.32    |
| evaluation/return-min          | 4905.3184  |
| evaluation/return-std          | 35.162243  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46518      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4960.121   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 227.73979  |
| Q-std                          | 100.05334  |
| Q_loss                         | 92.44722   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 814        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000547   |
| times/evaluation_paths         | 36.6       |
| times/timestep_after_hook      | 0.00414    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 815000     |
| train-steps                    | 815000     |
| training/Q/q1_loss             | 100.11161  |
| training/sac_pi/alpha          | 0.16442694 |
| training/sac_pi/alpha_loss     | 0.39365917 |
| training/sac_pi/logp_pi        | 5.0059333  |
| training/sac_pi/pi_entropy     | 3.4853065  |
| training/sac_pi/pi_global_norm | 1.602228   |
| training/sac_pi/policy_loss    | -215.21599 |
| training/sac_pi/std            | 0.5212137  |
| training/sac_pi/valid_num      | 4939.0     |
| training/sac_Q/q1              | 206.14429  |
| training/sac_Q/q2              | 204.577    |
| training/sac_Q/q2_loss         | 99.7784    |
| training/sac_Q/q_global_norm   | 245.1229   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17078115   |
| epoch                          | 815          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4969.1587    |
| evaluation/return-max          | 5052.675     |
| evaluation/return-min          | 4870.3853    |
| evaluation/return-std          | 54.50461     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.07         |
| model/origin_ret               | 85.8         |
| model/penalty_ret              | 81.1         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46377        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4969.1587    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 212.6008     |
| Q-std                          | 115.23172    |
| Q_loss                         | 84.57496     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 815          |
| times/epoch_after_hook         | 1.89e-06     |
| times/epoch_before_hook        | 0.000138     |
| times/epoch_rollout_model      | 512          |
| times/evaluation_metrics       | 0.000661     |
| times/evaluation_paths         | 35.2         |
| times/timestep_after_hook      | 0.00411      |
| times/timestep_before_hook     | 0.00841      |
| times/train                    | 67.2         |
| timestep                       | 1000         |
| timesteps_total                | 816000       |
| train-steps                    | 816000       |
| training/Q/q1_loss             | 103.10168    |
| training/sac_pi/alpha          | 0.17079261   |
| training/sac_pi/alpha_loss     | -0.007773085 |
| training/sac_pi/logp_pi        | 4.0552964    |
| training/sac_pi/pi_entropy     | 3.626011     |
| training/sac_pi/pi_global_norm | 2.2297723    |
| training/sac_pi/policy_loss    | -217.90312   |
| training/sac_pi/std            | 0.49223325   |
| training/sac_pi/valid_num      | 5006.0       |
| training/sac_Q/q1              | 213.56503    |
| training/sac_Q/q2              | 212.95639    |
| training/sac_Q/q2_loss         | 103.8256     |
| training/sac_Q/q_global_norm   | 292.90094    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1692536   |
| epoch                          | 816         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4932.0986   |
| evaluation/return-max          | 5014.026    |
| evaluation/return-min          | 4868.0483   |
| evaluation/return-std          | 47.072826   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46220       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4932.0986   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 210.94585   |
| Q-std                          | 146.83374   |
| Q_loss                         | 89.30953    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 816         |
| times/epoch_after_hook         | 2.03e-06    |
| times/epoch_before_hook        | 0.000169    |
| times/epoch_rollout_model      | 520         |
| times/evaluation_metrics       | 0.000691    |
| times/evaluation_paths         | 38.1        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 817000      |
| train-steps                    | 817000      |
| training/Q/q1_loss             | 80.17038    |
| training/sac_pi/alpha          | 0.16926476  |
| training/sac_pi/alpha_loss     | -0.29321226 |
| training/sac_pi/logp_pi        | 4.648866    |
| training/sac_pi/pi_entropy     | 3.5896602   |
| training/sac_pi/pi_global_norm | 1.6443732   |
| training/sac_pi/policy_loss    | -226.13696  |
| training/sac_pi/std            | 0.5380866   |
| training/sac_pi/valid_num      | 4882.0      |
| training/sac_Q/q1              | 211.88419   |
| training/sac_Q/q2              | 212.03154   |
| training/sac_Q/q2_loss         | 81.60106    |
| training/sac_Q/q_global_norm   | 230.96315   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16879629  |
| epoch                          | 817         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5061.336    |
| evaluation/return-max          | 5139.2114   |
| evaluation/return-min          | 4973.3887   |
| evaluation/return-std          | 52.431488   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46448       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5061.336    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 220.42497   |
| Q-std                          | 95.91383    |
| Q_loss                         | 90.4057     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 817         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000321    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000623    |
| times/evaluation_paths         | 45.3        |
| times/timestep_after_hook      | 0.00408     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 65          |
| timestep                       | 1000        |
| timesteps_total                | 818000      |
| train-steps                    | 818000      |
| training/Q/q1_loss             | 86.73066    |
| training/sac_pi/alpha          | 0.16878939  |
| training/sac_pi/alpha_loss     | -0.21018821 |
| training/sac_pi/logp_pi        | 4.026447    |
| training/sac_pi/pi_entropy     | 3.5885856   |
| training/sac_pi/pi_global_norm | 1.6461147   |
| training/sac_pi/policy_loss    | -220.87492  |
| training/sac_pi/std            | 0.5005905   |
| training/sac_pi/valid_num      | 4937.0      |
| training/sac_Q/q1              | 211.93167   |
| training/sac_Q/q2              | 211.07153   |
| training/sac_Q/q2_loss         | 86.65643    |
| training/sac_Q/q_global_norm   | 284.25458   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17155042  |
| epoch                          | 818         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5033.9814   |
| evaluation/return-max          | 5078.0713   |
| evaluation/return-min          | 4962.9473   |
| evaluation/return-std          | 33.76801    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46336       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5033.9814   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 213.21127   |
| Q-std                          | 143.88774   |
| Q_loss                         | 105.16466   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 818         |
| times/epoch_after_hook         | 3.38e-06    |
| times/epoch_before_hook        | 0.000141    |
| times/epoch_rollout_model      | 515         |
| times/evaluation_metrics       | 0.000625    |
| times/evaluation_paths         | 33.9        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 63.4        |
| timestep                       | 1000        |
| timesteps_total                | 819000      |
| train-steps                    | 819000      |
| training/Q/q1_loss             | 81.51212    |
| training/sac_pi/alpha          | 0.17153172  |
| training/sac_pi/alpha_loss     | -0.28225487 |
| training/sac_pi/logp_pi        | 3.7948754   |
| training/sac_pi/pi_entropy     | 3.5465527   |
| training/sac_pi/pi_global_norm | 1.4921868   |
| training/sac_pi/policy_loss    | -230.68192  |
| training/sac_pi/std            | 0.4987579   |
| training/sac_pi/valid_num      | 5007.0      |
| training/sac_Q/q1              | 222.86777   |
| training/sac_Q/q2              | 223.07309   |
| training/sac_Q/q2_loss         | 80.82845    |
| training/sac_Q/q_global_norm   | 245.16129   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1708883    |
| epoch                          | 819          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5068.074     |
| evaluation/return-max          | 5209.1523    |
| evaluation/return-min          | 4969.1562    |
| evaluation/return-std          | 90.688515    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.08         |
| model/origin_ret               | 85.9         |
| model/penalty_ret              | 80.4         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46283        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5068.074     |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 218.74817    |
| Q-std                          | 115.74488    |
| Q_loss                         | 117.8766     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 819          |
| times/epoch_after_hook         | 1.94e-06     |
| times/epoch_before_hook        | 0.000132     |
| times/epoch_rollout_model      | 486          |
| times/evaluation_metrics       | 0.000639     |
| times/evaluation_paths         | 34.7         |
| times/timestep_after_hook      | 0.00391      |
| times/timestep_before_hook     | 0.00825      |
| times/train                    | 62.7         |
| timestep                       | 1000         |
| timesteps_total                | 820000       |
| train-steps                    | 820000       |
| training/Q/q1_loss             | 116.32025    |
| training/sac_pi/alpha          | 0.17094885   |
| training/sac_pi/alpha_loss     | 0.0041485806 |
| training/sac_pi/logp_pi        | 3.581263     |
| training/sac_pi/pi_entropy     | 3.5237472    |
| training/sac_pi/pi_global_norm | 1.8715912    |
| training/sac_pi/policy_loss    | -213.58444   |
| training/sac_pi/std            | 0.47530672   |
| training/sac_pi/valid_num      | 5024.0       |
| training/sac_Q/q1              | 210.207      |
| training/sac_Q/q2              | 209.91428    |
| training/sac_Q/q2_loss         | 116.38699    |
| training/sac_Q/q_global_norm   | 291.48898    |
----------------------------------------------------------------------------------
[WARN] 820 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.1672686  |
| epoch                          | 820        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4944.1943  |
| evaluation/return-max          | 4992.8154  |
| evaluation/return-min          | 4861.957   |
| evaluation/return-std          | 42.8084    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46302      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4944.1943  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 213.77779  |
| Q-std                          | 147.18124  |
| Q_loss                         | 103.17552  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 820        |
| times/epoch_after_hook         | 2.1e-06    |
| times/epoch_before_hook        | 0.000172   |
| times/epoch_rollout_model      | 509        |
| times/evaluation_metrics       | 0.00071    |
| times/evaluation_paths         | 34         |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 821000     |
| train-steps                    | 821000     |
| training/Q/q1_loss             | 96.56564   |
| training/sac_pi/alpha          | 0.1672596  |
| training/sac_pi/alpha_loss     | 0.2161129  |
| training/sac_pi/logp_pi        | 3.8118567  |
| training/sac_pi/pi_entropy     | 3.315822   |
| training/sac_pi/pi_global_norm | 1.419431   |
| training/sac_pi/policy_loss    | -221.42166 |
| training/sac_pi/std            | 0.46047226 |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 213.98799  |
| training/sac_Q/q2              | 214.3313   |
| training/sac_Q/q2_loss         | 94.96383   |
| training/sac_Q/q_global_norm   | 212.13399  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16883197 |
| epoch                          | 821        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4787.585   |
| evaluation/return-max          | 4824.176   |
| evaluation/return-min          | 4739.7134  |
| evaluation/return-std          | 21.004745  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46356      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4787.585   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 222.24515  |
| Q-std                          | 122.25312  |
| Q_loss                         | 100.062775 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 821        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000299   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000814   |
| times/evaluation_paths         | 45.4       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 68.1       |
| timestep                       | 1000       |
| timesteps_total                | 822000     |
| train-steps                    | 822000     |
| training/Q/q1_loss             | 108.74382  |
| training/sac_pi/alpha          | 0.16884631 |
| training/sac_pi/alpha_loss     | 0.07753258 |
| training/sac_pi/logp_pi        | 5.1852236  |
| training/sac_pi/pi_entropy     | 3.291394   |
| training/sac_pi/pi_global_norm | 1.6313283  |
| training/sac_pi/policy_loss    | -214.46515 |
| training/sac_pi/std            | 0.4984413  |
| training/sac_pi/valid_num      | 4913.0     |
| training/sac_Q/q1              | 199.81833  |
| training/sac_Q/q2              | 202.14796  |
| training/sac_Q/q2_loss         | 108.45508  |
| training/sac_Q/q_global_norm   | 207.09915  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1670326   |
| epoch                          | 822         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4636.364    |
| evaluation/return-max          | 4689.265    |
| evaluation/return-min          | 4569.7188   |
| evaluation/return-std          | 34.4689     |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 81.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46191       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4636.364    |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 212.53413   |
| Q-std                          | 114.53109   |
| Q_loss                         | 121.122795  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 822         |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000532    |
| times/evaluation_paths         | 39.6        |
| times/timestep_after_hook      | 0.00407     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 823000      |
| train-steps                    | 823000      |
| training/Q/q1_loss             | 112.45226   |
| training/sac_pi/alpha          | 0.16705285  |
| training/sac_pi/alpha_loss     | 0.019906368 |
| training/sac_pi/logp_pi        | 5.32306     |
| training/sac_pi/pi_entropy     | 3.4481888   |
| training/sac_pi/pi_global_norm | 1.8669384   |
| training/sac_pi/policy_loss    | -215.69196  |
| training/sac_pi/std            | 0.5316609   |
| training/sac_pi/valid_num      | 4910.0      |
| training/sac_Q/q1              | 197.77405   |
| training/sac_Q/q2              | 202.25473   |
| training/sac_Q/q2_loss         | 113.728096  |
| training/sac_Q/q_global_norm   | 240.82314   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1683328   |
| epoch                          | 823         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5059.1206   |
| evaluation/return-max          | 5157.269    |
| evaluation/return-min          | 4909.7197   |
| evaluation/return-std          | 82.9304     |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46262       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5059.1206   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 218.02237   |
| Q-std                          | 125.96558   |
| Q_loss                         | 90.89436    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 823         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000503    |
| times/evaluation_paths         | 38          |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.00827     |
| times/train                    | 60          |
| timestep                       | 1000        |
| timesteps_total                | 824000      |
| train-steps                    | 824000      |
| training/Q/q1_loss             | 112.03157   |
| training/sac_pi/alpha          | 0.16834141  |
| training/sac_pi/alpha_loss     | 0.024997996 |
| training/sac_pi/logp_pi        | 4.004667    |
| training/sac_pi/pi_entropy     | 3.3073163   |
| training/sac_pi/pi_global_norm | 1.5192006   |
| training/sac_pi/policy_loss    | -222.7587   |
| training/sac_pi/std            | 0.46904004  |
| training/sac_pi/valid_num      | 5033.0      |
| training/sac_Q/q1              | 214.67725   |
| training/sac_Q/q2              | 214.69629   |
| training/sac_Q/q2_loss         | 112.24375   |
| training/sac_Q/q_global_norm   | 206.43822   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16515799  |
| epoch                          | 824         |
| evaluation/episode-length-avg  | 890         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 292         |
| evaluation/episode-length-std  | 232         |
| evaluation/return-average      | 4020.0105   |
| evaluation/return-max          | 4703.583    |
| evaluation/return-min          | 1059.091    |
| evaluation/return-std          | 1186.3964   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46218       |
| perf/AverageLength             | 890         |
| perf/AverageReturn             | 4020.0105   |
| perf/NormalizedReturn          | 0.875       |
| Q-avg                          | 213.20186   |
| Q-std                          | 123.55737   |
| Q_loss                         | 92.738655   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 824         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 9.55e-05    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000561    |
| times/evaluation_paths         | 33.3        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.00802     |
| times/train                    | 62.2        |
| timestep                       | 1000        |
| timesteps_total                | 825000      |
| train-steps                    | 825000      |
| training/Q/q1_loss             | 104.949776  |
| training/sac_pi/alpha          | 0.16516797  |
| training/sac_pi/alpha_loss     | 0.072809994 |
| training/sac_pi/logp_pi        | 3.6979318   |
| training/sac_pi/pi_entropy     | 3.398534    |
| training/sac_pi/pi_global_norm | 1.9739017   |
| training/sac_pi/policy_loss    | -224.61037  |
| training/sac_pi/std            | 0.47622472  |
| training/sac_pi/valid_num      | 4973.0      |
| training/sac_Q/q1              | 218.88562   |
| training/sac_Q/q2              | 219.32393   |
| training/sac_Q/q2_loss         | 104.183105  |
| training/sac_Q/q_global_norm   | 250.6296    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16397808 |
| epoch                          | 825        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4929.4985  |
| evaluation/return-max          | 4988.894   |
| evaluation/return-min          | 4823.382   |
| evaluation/return-std          | 49.055798  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46405      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4929.4985  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 211.40768  |
| Q-std                          | 120.56288  |
| Q_loss                         | 95.8668    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 825        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000324   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000619   |
| times/evaluation_paths         | 39.2       |
| times/timestep_after_hook      | 0.00411    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 72.5       |
| timestep                       | 1000       |
| timesteps_total                | 826000     |
| train-steps                    | 826000     |
| training/Q/q1_loss             | 112.40817  |
| training/sac_pi/alpha          | 0.1640011  |
| training/sac_pi/alpha_loss     | 0.18490013 |
| training/sac_pi/logp_pi        | 4.2573977  |
| training/sac_pi/pi_entropy     | 3.353152   |
| training/sac_pi/pi_global_norm | 1.7398696  |
| training/sac_pi/policy_loss    | -212.74057 |
| training/sac_pi/std            | 0.47425368 |
| training/sac_pi/valid_num      | 4948.0     |
| training/sac_Q/q1              | 204.27528  |
| training/sac_Q/q2              | 203.32962  |
| training/sac_Q/q2_loss         | 113.10283  |
| training/sac_Q/q_global_norm   | 202.43909  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16344349  |
| epoch                          | 826         |
| evaluation/episode-length-avg  | 858         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 286         |
| evaluation/episode-length-std  | 284         |
| evaluation/return-average      | 3987.5      |
| evaluation/return-max          | 4842.6113   |
| evaluation/return-min          | 1008.09375  |
| evaluation/return-std          | 1485.8809   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46366       |
| perf/AverageLength             | 858         |
| perf/AverageReturn             | 3987.5      |
| perf/NormalizedReturn          | 0.868       |
| Q-avg                          | 214.54858   |
| Q-std                          | 107.44107   |
| Q_loss                         | 109.36926   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 826         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000549    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 60.3        |
| timestep                       | 1000        |
| timesteps_total                | 827000      |
| train-steps                    | 827000      |
| training/Q/q1_loss             | 112.1095    |
| training/sac_pi/alpha          | 0.16343762  |
| training/sac_pi/alpha_loss     | -0.11542467 |
| training/sac_pi/logp_pi        | 4.2222357   |
| training/sac_pi/pi_entropy     | 3.3453774   |
| training/sac_pi/pi_global_norm | 1.649228    |
| training/sac_pi/policy_loss    | -218.05469  |
| training/sac_pi/std            | 0.4829691   |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 209.44772   |
| training/sac_Q/q2              | 209.83838   |
| training/sac_Q/q2_loss         | 111.12387   |
| training/sac_Q/q_global_norm   | 292.96152   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17177364   |
| epoch                          | 827          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5237.254     |
| evaluation/return-max          | 5263.339     |
| evaluation/return-min          | 5210.043     |
| evaluation/return-std          | 14.636693    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.04         |
| model/origin_ret               | 84.9         |
| model/penalty_ret              | 80.9         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46250        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5237.254     |
| perf/NormalizedReturn          | 1.14         |
| Q-avg                          | 213.63057    |
| Q-std                          | 112.419304   |
| Q_loss                         | 128.37735    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 827          |
| times/epoch_after_hook         | 1.75e-06     |
| times/epoch_before_hook        | 0.000133     |
| times/epoch_rollout_model      | 510          |
| times/evaluation_metrics       | 0.000554     |
| times/evaluation_paths         | 34.7         |
| times/timestep_after_hook      | 0.00406      |
| times/timestep_before_hook     | 0.0083       |
| times/train                    | 60.1         |
| timestep                       | 1000         |
| timesteps_total                | 828000       |
| train-steps                    | 828000       |
| training/Q/q1_loss             | 100.03746    |
| training/sac_pi/alpha          | 0.17176764   |
| training/sac_pi/alpha_loss     | -0.016291892 |
| training/sac_pi/logp_pi        | 4.804208     |
| training/sac_pi/pi_entropy     | 3.5847938    |
| training/sac_pi/pi_global_norm | 1.9868374    |
| training/sac_pi/policy_loss    | -219.35295   |
| training/sac_pi/std            | 0.54154116   |
| training/sac_pi/valid_num      | 4944.0       |
| training/sac_Q/q1              | 209.00073    |
| training/sac_Q/q2              | 208.8184     |
| training/sac_Q/q2_loss         | 99.041145    |
| training/sac_Q/q_global_norm   | 259.03308    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1686803   |
| epoch                          | 828         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5135.427    |
| evaluation/return-max          | 5221.7393   |
| evaluation/return-min          | 4979.7085   |
| evaluation/return-std          | 69.79964    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46338       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5135.427    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 208.39656   |
| Q-std                          | 164.79536   |
| Q_loss                         | 100.83968   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 828         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 509         |
| times/evaluation_metrics       | 0.00064     |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.00848     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 829000      |
| train-steps                    | 829000      |
| training/Q/q1_loss             | 114.68206   |
| training/sac_pi/alpha          | 0.1686925   |
| training/sac_pi/alpha_loss     | -0.07051994 |
| training/sac_pi/logp_pi        | 5.038058    |
| training/sac_pi/pi_entropy     | 3.4216945   |
| training/sac_pi/pi_global_norm | 1.8871304   |
| training/sac_pi/policy_loss    | -220.82948  |
| training/sac_pi/std            | 0.5115649   |
| training/sac_pi/valid_num      | 4896.0      |
| training/sac_Q/q1              | 198.68332   |
| training/sac_Q/q2              | 200.4816    |
| training/sac_Q/q2_loss         | 113.30376   |
| training/sac_Q/q_global_norm   | 263.57214   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.167606   |
| epoch                          | 829        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5020.6484  |
| evaluation/return-max          | 5109.0566  |
| evaluation/return-min          | 4970.965   |
| evaluation/return-std          | 48.910732  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46312      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5020.6484  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 211.33826  |
| Q-std                          | 108.117584 |
| Q_loss                         | 87.563896  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 829        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000309   |
| times/epoch_rollout_model      | 511        |
| times/evaluation_metrics       | 0.000617   |
| times/evaluation_paths         | 39.9       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 71.5       |
| timestep                       | 1000       |
| timesteps_total                | 830000     |
| train-steps                    | 830000     |
| training/Q/q1_loss             | 86.602615  |
| training/sac_pi/alpha          | 0.16756837 |
| training/sac_pi/alpha_loss     | 0.5758904  |
| training/sac_pi/logp_pi        | 4.6220145  |
| training/sac_pi/pi_entropy     | 3.6240795  |
| training/sac_pi/pi_global_norm | 1.4867445  |
| training/sac_pi/policy_loss    | -220.55534 |
| training/sac_pi/std            | 0.5369397  |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 209.3519   |
| training/sac_Q/q2              | 212.43709  |
| training/sac_Q/q2_loss         | 86.63292   |
| training/sac_Q/q_global_norm   | 226.10887  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16680136 |
| epoch                          | 830        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4919.296   |
| evaluation/return-max          | 5075.114   |
| evaluation/return-min          | 4799.38    |
| evaluation/return-std          | 91.00073   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 87.2       |
| model/penalty_ret              | 82.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46114      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4919.296   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 210.71407  |
| Q-std                          | 106.31872  |
| Q_loss                         | 109.700874 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 830        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 523        |
| times/evaluation_metrics       | 0.000499   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 831000     |
| train-steps                    | 831000     |
| training/Q/q1_loss             | 100.2423   |
| training/sac_pi/alpha          | 0.16680321 |
| training/sac_pi/alpha_loss     | 0.09714748 |
| training/sac_pi/logp_pi        | 4.3496785  |
| training/sac_pi/pi_entropy     | 3.240626   |
| training/sac_pi/pi_global_norm | 1.6927637  |
| training/sac_pi/policy_loss    | -222.72325 |
| training/sac_pi/std            | 0.47252542 |
| training/sac_pi/valid_num      | 4962.0     |
| training/sac_Q/q1              | 211.78113  |
| training/sac_Q/q2              | 215.17534  |
| training/sac_Q/q2_loss         | 100.59236  |
| training/sac_Q/q_global_norm   | 203.35777  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16162562   |
| epoch                          | 831          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4991.2437    |
| evaluation/return-max          | 5130.535     |
| evaluation/return-min          | 4898.7554    |
| evaluation/return-std          | 64.62297     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.01         |
| model/origin_ret               | 84.4         |
| model/penalty_ret              | 80.9         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46280        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4991.2437    |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 214.78293    |
| Q-std                          | 133.04051    |
| Q_loss                         | 114.21459    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 831          |
| times/epoch_after_hook         | 1.74e-06     |
| times/epoch_before_hook        | 0.000128     |
| times/epoch_rollout_model      | 513          |
| times/evaluation_metrics       | 0.000544     |
| times/evaluation_paths         | 35.2         |
| times/timestep_after_hook      | 0.004        |
| times/timestep_before_hook     | 0.00807      |
| times/train                    | 60.2         |
| timestep                       | 1000         |
| timesteps_total                | 832000       |
| train-steps                    | 832000       |
| training/Q/q1_loss             | 89.284       |
| training/sac_pi/alpha          | 0.16164212   |
| training/sac_pi/alpha_loss     | -0.012069375 |
| training/sac_pi/logp_pi        | 4.0083857    |
| training/sac_pi/pi_entropy     | 3.3647346    |
| training/sac_pi/pi_global_norm | 1.7122551    |
| training/sac_pi/policy_loss    | -228.08635   |
| training/sac_pi/std            | 0.48101944   |
| training/sac_pi/valid_num      | 4997.0       |
| training/sac_Q/q1              | 223.05246    |
| training/sac_Q/q2              | 222.31308    |
| training/sac_Q/q2_loss         | 88.38363     |
| training/sac_Q/q_global_norm   | 233.23596    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16638689  |
| epoch                          | 832         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4988.225    |
| evaluation/return-max          | 5098.1094   |
| evaluation/return-min          | 4900.2363   |
| evaluation/return-std          | 62.423286   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46181       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4988.225    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 210.77446   |
| Q-std                          | 133.34303   |
| Q_loss                         | 85.32223    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 832         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 509         |
| times/evaluation_metrics       | 0.000592    |
| times/evaluation_paths         | 37.3        |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 61.5        |
| timestep                       | 1000        |
| timesteps_total                | 833000      |
| train-steps                    | 833000      |
| training/Q/q1_loss             | 101.32725   |
| training/sac_pi/alpha          | 0.16639611  |
| training/sac_pi/alpha_loss     | -0.08164403 |
| training/sac_pi/logp_pi        | 3.9457142   |
| training/sac_pi/pi_entropy     | 3.420562    |
| training/sac_pi/pi_global_norm | 1.7254593   |
| training/sac_pi/policy_loss    | -221.50612  |
| training/sac_pi/std            | 0.4765574   |
| training/sac_pi/valid_num      | 4987.0      |
| training/sac_Q/q1              | 213.31723   |
| training/sac_Q/q2              | 212.78447   |
| training/sac_Q/q2_loss         | 99.94859    |
| training/sac_Q/q_global_norm   | 290.3822    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16836476  |
| epoch                          | 833         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4849.585    |
| evaluation/return-max          | 4967.165    |
| evaluation/return-min          | 4772.026    |
| evaluation/return-std          | 62.651184   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46320       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4849.585    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 202.80478   |
| Q-std                          | 162.81815   |
| Q_loss                         | 111.68713   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 833         |
| times/epoch_after_hook         | 3.46e-06    |
| times/epoch_before_hook        | 0.00025     |
| times/epoch_rollout_model      | 513         |
| times/evaluation_metrics       | 0.000599    |
| times/evaluation_paths         | 41.2        |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 70.4        |
| timestep                       | 1000        |
| timesteps_total                | 834000      |
| train-steps                    | 834000      |
| training/Q/q1_loss             | 96.83297    |
| training/sac_pi/alpha          | 0.16835597  |
| training/sac_pi/alpha_loss     | -0.31505033 |
| training/sac_pi/logp_pi        | 4.2884607   |
| training/sac_pi/pi_entropy     | 3.357387    |
| training/sac_pi/pi_global_norm | 1.6770078   |
| training/sac_pi/policy_loss    | -218.88152  |
| training/sac_pi/std            | 0.49218798  |
| training/sac_pi/valid_num      | 4935.0      |
| training/sac_Q/q1              | 208.98784   |
| training/sac_Q/q2              | 209.68306   |
| training/sac_Q/q2_loss         | 96.731476   |
| training/sac_Q/q_global_norm   | 308.90768   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16991623  |
| epoch                          | 834         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5152.1655   |
| evaluation/return-max          | 5254.709    |
| evaluation/return-min          | 5081.4805   |
| evaluation/return-std          | 47.45298    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46333       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5152.1655   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 213.33939   |
| Q-std                          | 109.66512   |
| Q_loss                         | 91.86837    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 834         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000596    |
| times/evaluation_paths         | 37.1        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 835000      |
| train-steps                    | 835000      |
| training/Q/q1_loss             | 64.948006   |
| training/sac_pi/alpha          | 0.16995142  |
| training/sac_pi/alpha_loss     | -0.27724802 |
| training/sac_pi/logp_pi        | 3.7582862   |
| training/sac_pi/pi_entropy     | 3.3046405   |
| training/sac_pi/pi_global_norm | 1.5932771   |
| training/sac_pi/policy_loss    | -229.92592  |
| training/sac_pi/std            | 0.46837875  |
| training/sac_pi/valid_num      | 4996.0      |
| training/sac_Q/q1              | 225.43784   |
| training/sac_Q/q2              | 226.4065    |
| training/sac_Q/q2_loss         | 65.60637    |
| training/sac_Q/q_global_norm   | 226.27309   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17385057  |
| epoch                          | 835         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5171.747    |
| evaluation/return-max          | 5216.1045   |
| evaluation/return-min          | 5132.1934   |
| evaluation/return-std          | 29.553535   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46260       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5171.747    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 211.44284   |
| Q-std                          | 111.611176  |
| Q_loss                         | 96.07979    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 835         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 508         |
| times/evaluation_metrics       | 0.00062     |
| times/evaluation_paths         | 36.8        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 836000      |
| train-steps                    | 836000      |
| training/Q/q1_loss             | 106.53342   |
| training/sac_pi/alpha          | 0.17383166  |
| training/sac_pi/alpha_loss     | 0.027684674 |
| training/sac_pi/logp_pi        | 4.6382217   |
| training/sac_pi/pi_entropy     | 3.3965733   |
| training/sac_pi/pi_global_norm | 1.8811189   |
| training/sac_pi/policy_loss    | -218.42816  |
| training/sac_pi/std            | 0.49632642  |
| training/sac_pi/valid_num      | 4954.0      |
| training/sac_Q/q1              | 208.26611   |
| training/sac_Q/q2              | 207.32549   |
| training/sac_Q/q2_loss         | 105.27688   |
| training/sac_Q/q_global_norm   | 243.12788   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16718587   |
| epoch                          | 836          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5223.292     |
| evaluation/return-max          | 5299.9277    |
| evaluation/return-min          | 5136.576     |
| evaluation/return-std          | 52.859203    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.11         |
| model/origin_ret               | 86.7         |
| model/penalty_ret              | 80.8         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46274        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5223.292     |
| perf/NormalizedReturn          | 1.14         |
| Q-avg                          | 203.58658    |
| Q-std                          | 110.751015   |
| Q_loss                         | 102.36005    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 836          |
| times/epoch_after_hook         | 1.8e-06      |
| times/epoch_before_hook        | 0.000131     |
| times/epoch_rollout_model      | 517          |
| times/evaluation_metrics       | 0.000645     |
| times/evaluation_paths         | 45.9         |
| times/timestep_after_hook      | 0.00425      |
| times/timestep_before_hook     | 0.00848      |
| times/train                    | 61.8         |
| timestep                       | 1000         |
| timesteps_total                | 837000       |
| train-steps                    | 837000       |
| training/Q/q1_loss             | 115.04994    |
| training/sac_pi/alpha          | 0.16720235   |
| training/sac_pi/alpha_loss     | -0.014760709 |
| training/sac_pi/logp_pi        | 3.979411     |
| training/sac_pi/pi_entropy     | 3.4792438    |
| training/sac_pi/pi_global_norm | 1.593519     |
| training/sac_pi/policy_loss    | -215.49423   |
| training/sac_pi/std            | 0.48958853   |
| training/sac_pi/valid_num      | 4871.0       |
| training/sac_Q/q1              | 204.1371     |
| training/sac_Q/q2              | 205.23096    |
| training/sac_Q/q2_loss         | 115.37301    |
| training/sac_Q/q_global_norm   | 217.43175    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16241264 |
| epoch                          | 837        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5165.926   |
| evaluation/return-max          | 5195.9263  |
| evaluation/return-min          | 5134.797   |
| evaluation/return-std          | 19.581097  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46363      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5165.926   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 206.75081  |
| Q-std                          | 135.11494  |
| Q_loss                         | 90.100494  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 837        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000308   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.00064    |
| times/evaluation_paths         | 33.1       |
| times/timestep_after_hook      | 0.00433    |
| times/timestep_before_hook     | 0.00854    |
| times/train                    | 69.3       |
| timestep                       | 1000       |
| timesteps_total                | 838000     |
| train-steps                    | 838000     |
| training/Q/q1_loss             | 90.63873   |
| training/sac_pi/alpha          | 0.1623828  |
| training/sac_pi/alpha_loss     | 0.09795308 |
| training/sac_pi/logp_pi        | 4.435197   |
| training/sac_pi/pi_entropy     | 3.2442524  |
| training/sac_pi/pi_global_norm | 1.6242743  |
| training/sac_pi/policy_loss    | -222.58028 |
| training/sac_pi/std            | 0.47936022 |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 213.276    |
| training/sac_Q/q2              | 212.9189   |
| training/sac_Q/q2_loss         | 90.43656   |
| training/sac_Q/q_global_norm   | 221.39935  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16507317  |
| epoch                          | 838         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4960.1396   |
| evaluation/return-max          | 4984.4707   |
| evaluation/return-min          | 4933.0      |
| evaluation/return-std          | 18.235264   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46272       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4960.1396   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 207.658     |
| Q-std                          | 133.67685   |
| Q_loss                         | 113.38016   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 838         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 522         |
| times/evaluation_metrics       | 0.000503    |
| times/evaluation_paths         | 43.5        |
| times/timestep_after_hook      | 0.004       |
| times/timestep_before_hook     | 0.00809     |
| times/train                    | 66.5        |
| timestep                       | 1000        |
| timesteps_total                | 839000      |
| train-steps                    | 839000      |
| training/Q/q1_loss             | 86.72091    |
| training/sac_pi/alpha          | 0.16509114  |
| training/sac_pi/alpha_loss     | -0.13652351 |
| training/sac_pi/logp_pi        | 4.082728    |
| training/sac_pi/pi_entropy     | 3.3281639   |
| training/sac_pi/pi_global_norm | 1.6558422   |
| training/sac_pi/policy_loss    | -222.52757  |
| training/sac_pi/std            | 0.47837666  |
| training/sac_pi/valid_num      | 4979.0      |
| training/sac_Q/q1              | 215.33789   |
| training/sac_Q/q2              | 216.6213    |
| training/sac_Q/q2_loss         | 87.71771    |
| training/sac_Q/q_global_norm   | 292.79282   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16485995 |
| epoch                          | 839        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4887.8643  |
| evaluation/return-max          | 4940.225   |
| evaluation/return-min          | 4789.3955  |
| evaluation/return-std          | 43.280315  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46250      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4887.8643  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 218.00513  |
| Q-std                          | 125.51598  |
| Q_loss                         | 101.23485  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 839        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 512        |
| times/evaluation_metrics       | 0.000535   |
| times/evaluation_paths         | 45.1       |
| times/timestep_after_hook      | 0.00398    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 840000     |
| train-steps                    | 840000     |
| training/Q/q1_loss             | 88.17225   |
| training/sac_pi/alpha          | 0.16485906 |
| training/sac_pi/alpha_loss     | 0.10329864 |
| training/sac_pi/logp_pi        | 4.2553735  |
| training/sac_pi/pi_entropy     | 3.3608537  |
| training/sac_pi/pi_global_norm | 1.52144    |
| training/sac_pi/policy_loss    | -221.43619 |
| training/sac_pi/std            | 0.48207694 |
| training/sac_pi/valid_num      | 5007.0     |
| training/sac_Q/q1              | 214.7131   |
| training/sac_Q/q2              | 214.47018  |
| training/sac_Q/q2_loss         | 89.18463   |
| training/sac_Q/q_global_norm   | 249.94617  |
--------------------------------------------------------------------------------
[WARN] 840 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.1707369  |
| epoch                          | 840        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4979.94    |
| evaluation/return-max          | 5142.5605  |
| evaluation/return-min          | 4766.8896  |
| evaluation/return-std          | 114.28686  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46336      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4979.94    |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 223.60608  |
| Q-std                          | 95.08788   |
| Q_loss                         | 78.89542   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 840        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000506   |
| times/evaluation_paths         | 43.7       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00799    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 841000     |
| train-steps                    | 841000     |
| training/Q/q1_loss             | 83.26691   |
| training/sac_pi/alpha          | 0.17073695 |
| training/sac_pi/alpha_loss     | -0.6409611 |
| training/sac_pi/logp_pi        | 4.3297224  |
| training/sac_pi/pi_entropy     | 3.4807518  |
| training/sac_pi/pi_global_norm | 1.6744343  |
| training/sac_pi/policy_loss    | -226.13136 |
| training/sac_pi/std            | 0.52086914 |
| training/sac_pi/valid_num      | 4994.0     |
| training/sac_Q/q1              | 217.83293  |
| training/sac_Q/q2              | 215.78519  |
| training/sac_Q/q2_loss         | 83.17223   |
| training/sac_Q/q_global_norm   | 238.04762  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16650482  |
| epoch                          | 841         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4830.3135   |
| evaluation/return-max          | 4897.588    |
| evaluation/return-min          | 4706.618    |
| evaluation/return-std          | 56.283745   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46303       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4830.3135   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 214.77568   |
| Q-std                          | 101.399445  |
| Q_loss                         | 110.77669   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 841         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000262    |
| times/epoch_rollout_model      | 514         |
| times/evaluation_metrics       | 0.000653    |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 68.4        |
| timestep                       | 1000        |
| timesteps_total                | 842000      |
| train-steps                    | 842000      |
| training/Q/q1_loss             | 71.49426    |
| training/sac_pi/alpha          | 0.16651298  |
| training/sac_pi/alpha_loss     | -0.31162864 |
| training/sac_pi/logp_pi        | 4.068591    |
| training/sac_pi/pi_entropy     | 3.4188156   |
| training/sac_pi/pi_global_norm | 1.5272242   |
| training/sac_pi/policy_loss    | -218.34198  |
| training/sac_pi/std            | 0.49746367  |
| training/sac_pi/valid_num      | 4986.0      |
| training/sac_Q/q1              | 208.88237   |
| training/sac_Q/q2              | 211.00957   |
| training/sac_Q/q2_loss         | 70.69       |
| training/sac_Q/q_global_norm   | 173.53316   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16520342  |
| epoch                          | 842         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5143.1436   |
| evaluation/return-max          | 5262.5767   |
| evaluation/return-min          | 4997.4536   |
| evaluation/return-std          | 80.75086    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46259       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5143.1436   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 218.30002   |
| Q-std                          | 113.36029   |
| Q_loss                         | 105.31919   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 842         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000611    |
| times/evaluation_paths         | 47.8        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 63.4        |
| timestep                       | 1000        |
| timesteps_total                | 843000      |
| train-steps                    | 843000      |
| training/Q/q1_loss             | 89.57797    |
| training/sac_pi/alpha          | 0.16520585  |
| training/sac_pi/alpha_loss     | -0.04767231 |
| training/sac_pi/logp_pi        | 5.0624247   |
| training/sac_pi/pi_entropy     | 3.361077    |
| training/sac_pi/pi_global_norm | 1.640568    |
| training/sac_pi/policy_loss    | -229.58936  |
| training/sac_pi/std            | 0.5130075   |
| training/sac_pi/valid_num      | 4920.0      |
| training/sac_Q/q1              | 214.23125   |
| training/sac_Q/q2              | 214.01753   |
| training/sac_Q/q2_loss         | 89.262215   |
| training/sac_Q/q_global_norm   | 245.13438   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16870265 |
| epoch                          | 843        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4897.1553  |
| evaluation/return-max          | 4941.267   |
| evaluation/return-min          | 4870.1504  |
| evaluation/return-std          | 17.525064  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46363      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4897.1553  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 221.39885  |
| Q-std                          | 101.026405 |
| Q_loss                         | 95.23904   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 843        |
| times/epoch_after_hook         | 3.58e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 511        |
| times/evaluation_metrics       | 0.000759   |
| times/evaluation_paths         | 44.1       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 62.9       |
| timestep                       | 1000       |
| timesteps_total                | 844000     |
| train-steps                    | 844000     |
| training/Q/q1_loss             | 118.366165 |
| training/sac_pi/alpha          | 0.16867697 |
| training/sac_pi/alpha_loss     | 0.11361353 |
| training/sac_pi/logp_pi        | 4.757359   |
| training/sac_pi/pi_entropy     | 3.7067642  |
| training/sac_pi/pi_global_norm | 1.3537594  |
| training/sac_pi/policy_loss    | -214.66544 |
| training/sac_pi/std            | 0.54355913 |
| training/sac_pi/valid_num      | 4896.0     |
| training/sac_Q/q1              | 201.64302  |
| training/sac_Q/q2              | 200.61823  |
| training/sac_Q/q2_loss         | 118.570724 |
| training/sac_Q/q_global_norm   | 299.44974  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16685502  |
| epoch                          | 844         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4774.753    |
| evaluation/return-max          | 4830.6973   |
| evaluation/return-min          | 4732.251    |
| evaluation/return-std          | 34.85867    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46175       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4774.753    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 212.37984   |
| Q-std                          | 105.53753   |
| Q_loss                         | 111.991104  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 844         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.001       |
| times/evaluation_paths         | 45.8        |
| times/timestep_after_hook      | 0.00396     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 845000      |
| train-steps                    | 845000      |
| training/Q/q1_loss             | 75.448074   |
| training/sac_pi/alpha          | 0.1668836   |
| training/sac_pi/alpha_loss     | -0.44728464 |
| training/sac_pi/logp_pi        | 4.216581    |
| training/sac_pi/pi_entropy     | 3.3298829   |
| training/sac_pi/pi_global_norm | 1.4244728   |
| training/sac_pi/policy_loss    | -228.31627  |
| training/sac_pi/std            | 0.49810752  |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 214.49931   |
| training/sac_Q/q2              | 214.3616    |
| training/sac_Q/q2_loss         | 75.24996    |
| training/sac_Q/q_global_norm   | 192.38055   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16851759 |
| epoch                          | 845        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5065.8066  |
| evaluation/return-max          | 5164.9033  |
| evaluation/return-min          | 4984.341   |
| evaluation/return-std          | 55.676052  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46382      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5065.8066  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 220.19673  |
| Q-std                          | 116.02981  |
| Q_loss                         | 108.88472  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 845        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.00026    |
| times/epoch_rollout_model      | 505        |
| times/evaluation_metrics       | 0.000591   |
| times/evaluation_paths         | 32.9       |
| times/timestep_after_hook      | 0.00419    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 64.1       |
| timestep                       | 1000       |
| timesteps_total                | 846000     |
| train-steps                    | 846000     |
| training/Q/q1_loss             | 96.52103   |
| training/sac_pi/alpha          | 0.16853094 |
| training/sac_pi/alpha_loss     | 0.12517723 |
| training/sac_pi/logp_pi        | 4.304636   |
| training/sac_pi/pi_entropy     | 3.3616128  |
| training/sac_pi/pi_global_norm | 1.5716773  |
| training/sac_pi/policy_loss    | -220.57431 |
| training/sac_pi/std            | 0.47622117 |
| training/sac_pi/valid_num      | 5003.0     |
| training/sac_Q/q1              | 209.82788  |
| training/sac_Q/q2              | 210.90154  |
| training/sac_Q/q2_loss         | 97.24792   |
| training/sac_Q/q_global_norm   | 226.98338  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1694396   |
| epoch                          | 846         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4929.436    |
| evaluation/return-max          | 4973.2812   |
| evaluation/return-min          | 4890.26     |
| evaluation/return-std          | 27.521458   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46446       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4929.436    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 211.17123   |
| Q-std                          | 135.04543   |
| Q_loss                         | 114.97722   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 846         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000143    |
| times/epoch_rollout_model      | 517         |
| times/evaluation_metrics       | 0.000574    |
| times/evaluation_paths         | 43.1        |
| times/timestep_after_hook      | 0.00397     |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 65.6        |
| timestep                       | 1000        |
| timesteps_total                | 847000      |
| train-steps                    | 847000      |
| training/Q/q1_loss             | 103.54335   |
| training/sac_pi/alpha          | 0.16948262  |
| training/sac_pi/alpha_loss     | -0.16400766 |
| training/sac_pi/logp_pi        | 4.4102087   |
| training/sac_pi/pi_entropy     | 3.6205087   |
| training/sac_pi/pi_global_norm | 1.4392505   |
| training/sac_pi/policy_loss    | -207.90283  |
| training/sac_pi/std            | 0.53034693  |
| training/sac_pi/valid_num      | 4918.0      |
| training/sac_Q/q1              | 193.1296    |
| training/sac_Q/q2              | 195.36397   |
| training/sac_Q/q2_loss         | 102.53374   |
| training/sac_Q/q_global_norm   | 236.5091    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16380203 |
| epoch                          | 847        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5102.0137  |
| evaluation/return-max          | 5228.2324  |
| evaluation/return-min          | 4995.905   |
| evaluation/return-std          | 58.204216  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46310      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5102.0137  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 211.72485  |
| Q-std                          | 155.92375  |
| Q_loss                         | 101.36609  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 847        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000594   |
| times/evaluation_paths         | 45.1       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 67.7       |
| timestep                       | 1000       |
| timesteps_total                | 848000     |
| train-steps                    | 848000     |
| training/Q/q1_loss             | 99.038666  |
| training/sac_pi/alpha          | 0.16379786 |
| training/sac_pi/alpha_loss     | 0.2423912  |
| training/sac_pi/logp_pi        | 4.696471   |
| training/sac_pi/pi_entropy     | 3.311914   |
| training/sac_pi/pi_global_norm | 2.3805254  |
| training/sac_pi/policy_loss    | -222.27809 |
| training/sac_pi/std            | 0.4876811  |
| training/sac_pi/valid_num      | 4971.0     |
| training/sac_Q/q1              | 209.27934  |
| training/sac_Q/q2              | 212.64499  |
| training/sac_Q/q2_loss         | 101.01823  |
| training/sac_Q/q_global_norm   | 216.98026  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16642682  |
| epoch                          | 848         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4980.991    |
| evaluation/return-max          | 5131.1445   |
| evaluation/return-min          | 4894.644    |
| evaluation/return-std          | 66.309814   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46317       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4980.991    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 212.45842   |
| Q-std                          | 132.13394   |
| Q_loss                         | 125.260445  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 848         |
| times/epoch_after_hook         | 2.01e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000589    |
| times/evaluation_paths         | 42.9        |
| times/timestep_after_hook      | 0.00403     |
| times/timestep_before_hook     | 0.00809     |
| times/train                    | 68.3        |
| timestep                       | 1000        |
| timesteps_total                | 849000      |
| train-steps                    | 849000      |
| training/Q/q1_loss             | 95.02268    |
| training/sac_pi/alpha          | 0.16642407  |
| training/sac_pi/alpha_loss     | -0.39308846 |
| training/sac_pi/logp_pi        | 3.9772441   |
| training/sac_pi/pi_entropy     | 3.2026863   |
| training/sac_pi/pi_global_norm | 1.656308    |
| training/sac_pi/policy_loss    | -231.0765   |
| training/sac_pi/std            | 0.4599102   |
| training/sac_pi/valid_num      | 4995.0      |
| training/sac_Q/q1              | 223.74878   |
| training/sac_Q/q2              | 222.5748    |
| training/sac_Q/q2_loss         | 95.331314   |
| training/sac_Q/q_global_norm   | 209.6193    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16348839 |
| epoch                          | 849        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4865.995   |
| evaluation/return-max          | 4928.569   |
| evaluation/return-min          | 4828.0186  |
| evaluation/return-std          | 32.795578  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46354      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4865.995   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 211.5911   |
| Q-std                          | 121.977646 |
| Q_loss                         | 85.395454  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 849        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000281   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000618   |
| times/evaluation_paths         | 33.3       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 62.9       |
| timestep                       | 1000       |
| timesteps_total                | 850000     |
| train-steps                    | 850000     |
| training/Q/q1_loss             | 78.33947   |
| training/sac_pi/alpha          | 0.16353995 |
| training/sac_pi/alpha_loss     | -0.3467014 |
| training/sac_pi/logp_pi        | 3.1148672  |
| training/sac_pi/pi_entropy     | 3.370524   |
| training/sac_pi/pi_global_norm | 1.6115129  |
| training/sac_pi/policy_loss    | -233.74648 |
| training/sac_pi/std            | 0.45507467 |
| training/sac_pi/valid_num      | 5034.0     |
| training/sac_Q/q1              | 230.79541  |
| training/sac_Q/q2              | 230.28413  |
| training/sac_Q/q2_loss         | 78.70085   |
| training/sac_Q/q_global_norm   | 215.09631  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1664046   |
| epoch                          | 850         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5122.8184   |
| evaluation/return-max          | 5157.275    |
| evaluation/return-min          | 5066.683    |
| evaluation/return-std          | 26.926556   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46176       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5122.8184   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 214.67142   |
| Q-std                          | 130.65764   |
| Q_loss                         | 114.6508    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 850         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000162    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000508    |
| times/evaluation_paths         | 45.6        |
| times/timestep_after_hook      | 0.004       |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 65.9        |
| timestep                       | 1000        |
| timesteps_total                | 851000      |
| train-steps                    | 851000      |
| training/Q/q1_loss             | 101.684296  |
| training/sac_pi/alpha          | 0.16642435  |
| training/sac_pi/alpha_loss     | -0.34749165 |
| training/sac_pi/logp_pi        | 3.723441    |
| training/sac_pi/pi_entropy     | 3.5114117   |
| training/sac_pi/pi_global_norm | 1.9500387   |
| training/sac_pi/policy_loss    | -227.87     |
| training/sac_pi/std            | 0.48802477  |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 217.02237   |
| training/sac_Q/q2              | 219.30869   |
| training/sac_Q/q2_loss         | 102.611145  |
| training/sac_Q/q_global_norm   | 236.1877    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16101784 |
| epoch                          | 851        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5031.7993  |
| evaluation/return-max          | 5103.323   |
| evaluation/return-min          | 4956.595   |
| evaluation/return-std          | 46.595726  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46257      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5031.7993  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 215.81357  |
| Q-std                          | 115.52339  |
| Q_loss                         | 93.29425   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 851        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000109   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000752   |
| times/evaluation_paths         | 43.6       |
| times/timestep_after_hook      | 0.00406    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 67.5       |
| timestep                       | 1000       |
| timesteps_total                | 852000     |
| train-steps                    | 852000     |
| training/Q/q1_loss             | 108.19267  |
| training/sac_pi/alpha          | 0.16105011 |
| training/sac_pi/alpha_loss     | 0.04884468 |
| training/sac_pi/logp_pi        | 4.4767933  |
| training/sac_pi/pi_entropy     | 3.329342   |
| training/sac_pi/pi_global_norm | 1.6326276  |
| training/sac_pi/policy_loss    | -222.96774 |
| training/sac_pi/std            | 0.48753247 |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 214.7552   |
| training/sac_Q/q2              | 216.06058  |
| training/sac_Q/q2_loss         | 107.4158   |
| training/sac_Q/q_global_norm   | 199.29045  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16758749   |
| epoch                          | 852          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5042.326     |
| evaluation/return-max          | 5132.7935    |
| evaluation/return-min          | 4830.3535    |
| evaluation/return-std          | 87.25033     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.03         |
| model/origin_ret               | 85.4         |
| model/penalty_ret              | 80.6         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46253        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5042.326     |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 224.29456    |
| Q-std                          | 106.05089    |
| Q_loss                         | 105.815865   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 852          |
| times/epoch_after_hook         | 1.87e-06     |
| times/epoch_before_hook        | 0.000139     |
| times/epoch_rollout_model      | 501          |
| times/evaluation_metrics       | 0.000533     |
| times/evaluation_paths         | 40.9         |
| times/timestep_after_hook      | 0.00398      |
| times/timestep_before_hook     | 0.00828      |
| times/train                    | 73.3         |
| timestep                       | 1000         |
| timesteps_total                | 853000       |
| train-steps                    | 853000       |
| training/Q/q1_loss             | 104.40091    |
| training/sac_pi/alpha          | 0.16759108   |
| training/sac_pi/alpha_loss     | -0.055198196 |
| training/sac_pi/logp_pi        | 4.9926634    |
| training/sac_pi/pi_entropy     | 3.598441     |
| training/sac_pi/pi_global_norm | 1.5803065    |
| training/sac_pi/policy_loss    | -220.41084   |
| training/sac_pi/std            | 0.5420485    |
| training/sac_pi/valid_num      | 4866.0       |
| training/sac_Q/q1              | 204.9936     |
| training/sac_Q/q2              | 205.3544     |
| training/sac_Q/q2_loss         | 103.84778    |
| training/sac_Q/q_global_norm   | 273.02698    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16716646  |
| epoch                          | 853         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5121.419    |
| evaluation/return-max          | 5188.8457   |
| evaluation/return-min          | 5051.1255   |
| evaluation/return-std          | 41.331043   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46337       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5121.419    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 207.73897   |
| Q-std                          | 139.90782   |
| Q_loss                         | 71.18706    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 853         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000311    |
| times/epoch_rollout_model      | 476         |
| times/evaluation_metrics       | 0.000555    |
| times/evaluation_paths         | 36.1        |
| times/timestep_after_hook      | 0.00396     |
| times/timestep_before_hook     | 0.00833     |
| times/train                    | 58.4        |
| timestep                       | 1000        |
| timesteps_total                | 854000      |
| train-steps                    | 854000      |
| training/Q/q1_loss             | 104.18943   |
| training/sac_pi/alpha          | 0.167168    |
| training/sac_pi/alpha_loss     | -0.10309943 |
| training/sac_pi/logp_pi        | 4.189444    |
| training/sac_pi/pi_entropy     | 3.3992858   |
| training/sac_pi/pi_global_norm | 1.9639649   |
| training/sac_pi/policy_loss    | -224.33237  |
| training/sac_pi/std            | 0.48452908  |
| training/sac_pi/valid_num      | 4934.0      |
| training/sac_Q/q1              | 212.56238   |
| training/sac_Q/q2              | 213.58716   |
| training/sac_Q/q2_loss         | 104.419586  |
| training/sac_Q/q_global_norm   | 196.36938   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16500475 |
| epoch                          | 854        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4708.638   |
| evaluation/return-max          | 4826.188   |
| evaluation/return-min          | 4516.1963  |
| evaluation/return-std          | 86.48128   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46361      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4708.638   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 210.01277  |
| Q-std                          | 126.64068  |
| Q_loss                         | 89.73204   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 854        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000535   |
| times/evaluation_paths         | 45.7       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 64.8       |
| timestep                       | 1000       |
| timesteps_total                | 855000     |
| train-steps                    | 855000     |
| training/Q/q1_loss             | 111.202126 |
| training/sac_pi/alpha          | 0.16502604 |
| training/sac_pi/alpha_loss     | 0.2167788  |
| training/sac_pi/logp_pi        | 4.1784663  |
| training/sac_pi/pi_entropy     | 3.2568786  |
| training/sac_pi/pi_global_norm | 1.6000236  |
| training/sac_pi/policy_loss    | -224.01505 |
| training/sac_pi/std            | 0.46957982 |
| training/sac_pi/valid_num      | 4984.0     |
| training/sac_Q/q1              | 213.94504  |
| training/sac_Q/q2              | 215.92749  |
| training/sac_Q/q2_loss         | 111.64865  |
| training/sac_Q/q_global_norm   | 287.61252  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17217447  |
| epoch                          | 855         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4815.2275   |
| evaluation/return-max          | 4858.2583   |
| evaluation/return-min          | 4774.093    |
| evaluation/return-std          | 27.838566   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46380       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4815.2275   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 211.73799   |
| Q-std                          | 116.46281   |
| Q_loss                         | 91.41534    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 855         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000536    |
| times/evaluation_paths         | 46          |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00822     |
| times/train                    | 64.2        |
| timestep                       | 1000        |
| timesteps_total                | 856000      |
| train-steps                    | 856000      |
| training/Q/q1_loss             | 97.16962    |
| training/sac_pi/alpha          | 0.17215738  |
| training/sac_pi/alpha_loss     | -0.03495906 |
| training/sac_pi/logp_pi        | 4.810382    |
| training/sac_pi/pi_entropy     | 3.5070205   |
| training/sac_pi/pi_global_norm | 1.9812908   |
| training/sac_pi/policy_loss    | -216.99797  |
| training/sac_pi/std            | 0.50586116  |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 206.65445   |
| training/sac_Q/q2              | 204.19315   |
| training/sac_Q/q2_loss         | 96.93383    |
| training/sac_Q/q_global_norm   | 256.5575    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16175336 |
| epoch                          | 856        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4906.5107  |
| evaluation/return-max          | 5094.9883  |
| evaluation/return-min          | 4657.791   |
| evaluation/return-std          | 128.68217  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46058      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4906.5107  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 205.99406  |
| Q-std                          | 131.1552   |
| Q_loss                         | 71.85614   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 856        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000525   |
| times/evaluation_paths         | 42.8       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 65.8       |
| timestep                       | 1000       |
| timesteps_total                | 857000     |
| train-steps                    | 857000     |
| training/Q/q1_loss             | 78.45312   |
| training/sac_pi/alpha          | 0.1617734  |
| training/sac_pi/alpha_loss     | 0.17949592 |
| training/sac_pi/logp_pi        | 4.7433906  |
| training/sac_pi/pi_entropy     | 3.3576713  |
| training/sac_pi/pi_global_norm | 1.643422   |
| training/sac_pi/policy_loss    | -216.70654 |
| training/sac_pi/std            | 0.49229214 |
| training/sac_pi/valid_num      | 4977.0     |
| training/sac_Q/q1              | 209.89307  |
| training/sac_Q/q2              | 208.78181  |
| training/sac_Q/q2_loss         | 79.18157   |
| training/sac_Q/q_global_norm   | 183.57677  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16606995 |
| epoch                          | 857        |
| evaluation/episode-length-avg  | 940        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 402        |
| evaluation/episode-length-std  | 179        |
| evaluation/return-average      | 4650.502   |
| evaluation/return-max          | 5117.606   |
| evaluation/return-min          | 1599.5251  |
| evaluation/return-std          | 1022.44977 |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46420      |
| perf/AverageLength             | 940        |
| perf/AverageReturn             | 4650.502   |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 212.63998  |
| Q-std                          | 112.4325   |
| Q_loss                         | 103.7569   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 857        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000322   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.00053    |
| times/evaluation_paths         | 31.8       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 65.3       |
| timestep                       | 1000       |
| timesteps_total                | 858000     |
| train-steps                    | 858000     |
| training/Q/q1_loss             | 101.81807  |
| training/sac_pi/alpha          | 0.16607994 |
| training/sac_pi/alpha_loss     | 0.07009855 |
| training/sac_pi/logp_pi        | 4.272109   |
| training/sac_pi/pi_entropy     | 3.4465508  |
| training/sac_pi/pi_global_norm | 1.6148322  |
| training/sac_pi/policy_loss    | -217.52335 |
| training/sac_pi/std            | 0.4966998  |
| training/sac_pi/valid_num      | 4925.0     |
| training/sac_Q/q1              | 205.53325  |
| training/sac_Q/q2              | 205.96147  |
| training/sac_Q/q2_loss         | 101.32066  |
| training/sac_Q/q_global_norm   | 164.8212   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16699497 |
| epoch                          | 858        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4988.8545  |
| evaluation/return-max          | 5086.8115  |
| evaluation/return-min          | 4890.379   |
| evaluation/return-std          | 59.26673   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46277      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4988.8545  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 221.36528  |
| Q-std                          | 95.55444   |
| Q_loss                         | 101.12959  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 858        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000521   |
| times/evaluation_paths         | 45         |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00804    |
| times/train                    | 65         |
| timestep                       | 1000       |
| timesteps_total                | 859000     |
| train-steps                    | 859000     |
| training/Q/q1_loss             | 96.42228   |
| training/sac_pi/alpha          | 0.16697185 |
| training/sac_pi/alpha_loss     | 0.3381302  |
| training/sac_pi/logp_pi        | 3.9389198  |
| training/sac_pi/pi_entropy     | 3.3746955  |
| training/sac_pi/pi_global_norm | 1.8722415  |
| training/sac_pi/policy_loss    | -222.91415 |
| training/sac_pi/std            | 0.4683317  |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 214.33536  |
| training/sac_Q/q2              | 215.0116   |
| training/sac_Q/q2_loss         | 95.73008   |
| training/sac_Q/q_global_norm   | 229.20667  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16615053 |
| epoch                          | 859        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4779.3955  |
| evaluation/return-max          | 4826.777   |
| evaluation/return-min          | 4717.289   |
| evaluation/return-std          | 35.417698  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46397      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4779.3955  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 212.04456  |
| Q-std                          | 111.811165 |
| Q_loss                         | 135.62964  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 859        |
| times/epoch_after_hook         | 3.26e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000547   |
| times/evaluation_paths         | 43.6       |
| times/timestep_after_hook      | 0.00398    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 64.9       |
| timestep                       | 1000       |
| timesteps_total                | 860000     |
| train-steps                    | 860000     |
| training/Q/q1_loss             | 98.16601   |
| training/sac_pi/alpha          | 0.1661249  |
| training/sac_pi/alpha_loss     | 0.55257034 |
| training/sac_pi/logp_pi        | 3.8082142  |
| training/sac_pi/pi_entropy     | 3.3399425  |
| training/sac_pi/pi_global_norm | 1.6333567  |
| training/sac_pi/policy_loss    | -218.43452 |
| training/sac_pi/std            | 0.45585638 |
| training/sac_pi/valid_num      | 5017.0     |
| training/sac_Q/q1              | 213.01201  |
| training/sac_Q/q2              | 213.82816  |
| training/sac_Q/q2_loss         | 97.18297   |
| training/sac_Q/q_global_norm   | 212.00478  |
--------------------------------------------------------------------------------
[WARN] 860 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16802408  |
| epoch                          | 860         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4853.713    |
| evaluation/return-max          | 4926.2744   |
| evaluation/return-min          | 4765.3013   |
| evaluation/return-std          | 47.2416     |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46209       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4853.713    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 221.32874   |
| Q-std                          | 98.4675     |
| Q_loss                         | 95.27033    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 860         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 476         |
| times/evaluation_metrics       | 0.00057     |
| times/evaluation_paths         | 46.6        |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 64.8        |
| timestep                       | 1000        |
| timesteps_total                | 861000      |
| train-steps                    | 861000      |
| training/Q/q1_loss             | 98.41126    |
| training/sac_pi/alpha          | 0.16802023  |
| training/sac_pi/alpha_loss     | -0.20561872 |
| training/sac_pi/logp_pi        | 4.26775     |
| training/sac_pi/pi_entropy     | 3.5170364   |
| training/sac_pi/pi_global_norm | 1.6014788   |
| training/sac_pi/policy_loss    | -221.80592  |
| training/sac_pi/std            | 0.5010908   |
| training/sac_pi/valid_num      | 4947.0      |
| training/sac_Q/q1              | 213.15732   |
| training/sac_Q/q2              | 211.80681   |
| training/sac_Q/q2_loss         | 97.187836   |
| training/sac_Q/q_global_norm   | 247.6277    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16866107 |
| epoch                          | 861        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4655.38    |
| evaluation/return-max          | 4698.188   |
| evaluation/return-min          | 4610.3037  |
| evaluation/return-std          | 29.20639   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46375      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4655.38    |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 215.10336  |
| Q-std                          | 111.90225  |
| Q_loss                         | 110.17387  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 861        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000298   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000585   |
| times/evaluation_paths         | 34.2       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 64.8       |
| timestep                       | 1000       |
| timesteps_total                | 862000     |
| train-steps                    | 862000     |
| training/Q/q1_loss             | 96.154686  |
| training/sac_pi/alpha          | 0.16870865 |
| training/sac_pi/alpha_loss     | -0.1553568 |
| training/sac_pi/logp_pi        | 3.9282658  |
| training/sac_pi/pi_entropy     | 3.4393623  |
| training/sac_pi/pi_global_norm | 1.5575805  |
| training/sac_pi/policy_loss    | -221.4909  |
| training/sac_pi/std            | 0.48734552 |
| training/sac_pi/valid_num      | 5000.0     |
| training/sac_Q/q1              | 213.94803  |
| training/sac_Q/q2              | 214.91577  |
| training/sac_Q/q2_loss         | 97.5976    |
| training/sac_Q/q_global_norm   | 176.89828  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16943595  |
| epoch                          | 862         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4670.002    |
| evaluation/return-max          | 4825.12     |
| evaluation/return-min          | 4538.6113   |
| evaluation/return-std          | 91.78841    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46221       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4670.002    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 211.28552   |
| Q-std                          | 142.08421   |
| Q_loss                         | 116.8042    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 862         |
| times/epoch_after_hook         | 2.03e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000518    |
| times/evaluation_paths         | 44.9        |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 66.3        |
| timestep                       | 1000        |
| timesteps_total                | 863000      |
| train-steps                    | 863000      |
| training/Q/q1_loss             | 95.66855    |
| training/sac_pi/alpha          | 0.16942841  |
| training/sac_pi/alpha_loss     | 0.028074443 |
| training/sac_pi/logp_pi        | 4.4168596   |
| training/sac_pi/pi_entropy     | 3.4672189   |
| training/sac_pi/pi_global_norm | 1.6694868   |
| training/sac_pi/policy_loss    | -223.19337  |
| training/sac_pi/std            | 0.5047936   |
| training/sac_pi/valid_num      | 4969.0      |
| training/sac_Q/q1              | 215.8179    |
| training/sac_Q/q2              | 213.07796   |
| training/sac_Q/q2_loss         | 95.09385    |
| training/sac_Q/q_global_norm   | 160.53468   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1649297    |
| epoch                          | 863          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5033.9214    |
| evaluation/return-max          | 5169.78      |
| evaluation/return-min          | 4948.332     |
| evaluation/return-std          | 79.74245     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.06         |
| model/origin_ret               | 85           |
| model/penalty_ret              | 80.2         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46274        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5033.9214    |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 213.4606     |
| Q-std                          | 100.611176   |
| Q_loss                         | 90.401146    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 863          |
| times/epoch_after_hook         | 1.85e-06     |
| times/epoch_before_hook        | 0.000111     |
| times/epoch_rollout_model      | 476          |
| times/evaluation_metrics       | 0.000688     |
| times/evaluation_paths         | 45.5         |
| times/timestep_after_hook      | 0.00416      |
| times/timestep_before_hook     | 0.00814      |
| times/train                    | 65.3         |
| timestep                       | 1000         |
| timesteps_total                | 864000       |
| train-steps                    | 864000       |
| training/Q/q1_loss             | 98.03015     |
| training/sac_pi/alpha          | 0.1649517    |
| training/sac_pi/alpha_loss     | -0.112271145 |
| training/sac_pi/logp_pi        | 4.253318     |
| training/sac_pi/pi_entropy     | 3.4192727    |
| training/sac_pi/pi_global_norm | 1.5473284    |
| training/sac_pi/policy_loss    | -234.68465   |
| training/sac_pi/std            | 0.49475116   |
| training/sac_pi/valid_num      | 4988.0       |
| training/sac_Q/q1              | 216.93279    |
| training/sac_Q/q2              | 220.1846     |
| training/sac_Q/q2_loss         | 98.843475    |
| training/sac_Q/q_global_norm   | 320.7778     |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16978127  |
| epoch                          | 864         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4926.5693   |
| evaluation/return-max          | 5009.55     |
| evaluation/return-min          | 4886.1367   |
| evaluation/return-std          | 35.86929    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46304       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4926.5693   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 215.98003   |
| Q-std                          | 106.94287   |
| Q_loss                         | 84.70019    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 864         |
| times/epoch_after_hook         | 1.98e-06    |
| times/epoch_before_hook        | 0.000156    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.00063     |
| times/evaluation_paths         | 40.2        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 68.6        |
| timestep                       | 1000        |
| timesteps_total                | 865000      |
| train-steps                    | 865000      |
| training/Q/q1_loss             | 118.492065  |
| training/sac_pi/alpha          | 0.16979171  |
| training/sac_pi/alpha_loss     | -0.23457456 |
| training/sac_pi/logp_pi        | 6.2271276   |
| training/sac_pi/pi_entropy     | 3.241922    |
| training/sac_pi/pi_global_norm | 1.7326169   |
| training/sac_pi/policy_loss    | -207.222    |
| training/sac_pi/std            | 0.5244529   |
| training/sac_pi/valid_num      | 4819.0      |
| training/sac_Q/q1              | 187.02805   |
| training/sac_Q/q2              | 184.89987   |
| training/sac_Q/q2_loss         | 118.709564  |
| training/sac_Q/q_global_norm   | 253.57602   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17097712 |
| epoch                          | 865        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4874.9326  |
| evaluation/return-max          | 4934.5527  |
| evaluation/return-min          | 4839.226   |
| evaluation/return-std          | 31.442661  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46291      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4874.9326  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 219.55962  |
| Q-std                          | 117.594154 |
| Q_loss                         | 116.48507  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 865        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000315   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 31.9       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 63.8       |
| timestep                       | 1000       |
| timesteps_total                | 866000     |
| train-steps                    | 866000     |
| training/Q/q1_loss             | 100.43756  |
| training/sac_pi/alpha          | 0.17098066 |
| training/sac_pi/alpha_loss     | -0.2472216 |
| training/sac_pi/logp_pi        | 3.9207988  |
| training/sac_pi/pi_entropy     | 3.4730072  |
| training/sac_pi/pi_global_norm | 1.5153825  |
| training/sac_pi/policy_loss    | -219.3175  |
| training/sac_pi/std            | 0.48287615 |
| training/sac_pi/valid_num      | 4987.0     |
| training/sac_Q/q1              | 212.59705  |
| training/sac_Q/q2              | 213.32315  |
| training/sac_Q/q2_loss         | 100.80599  |
| training/sac_Q/q_global_norm   | 197.01834  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1679717   |
| epoch                          | 866         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5261.5283   |
| evaluation/return-max          | 5321.294    |
| evaluation/return-min          | 5193.4907   |
| evaluation/return-std          | 48.83679    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46234       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5261.5283   |
| perf/NormalizedReturn          | 1.15        |
| Q-avg                          | 217.57698   |
| Q-std                          | 116.2261    |
| Q_loss                         | 103.8333    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 866         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000139    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.00058     |
| times/evaluation_paths         | 45.4        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00799     |
| times/train                    | 64.7        |
| timestep                       | 1000        |
| timesteps_total                | 867000      |
| train-steps                    | 867000      |
| training/Q/q1_loss             | 96.21246    |
| training/sac_pi/alpha          | 0.16800252  |
| training/sac_pi/alpha_loss     | -0.08014677 |
| training/sac_pi/logp_pi        | 4.1968703   |
| training/sac_pi/pi_entropy     | 3.2080255   |
| training/sac_pi/pi_global_norm | 1.6811323   |
| training/sac_pi/policy_loss    | -222.81686  |
| training/sac_pi/std            | 0.45800337  |
| training/sac_pi/valid_num      | 5007.0      |
| training/sac_Q/q1              | 218.23335   |
| training/sac_Q/q2              | 218.83609   |
| training/sac_Q/q2_loss         | 95.058334   |
| training/sac_Q/q_global_norm   | 175.53436   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1706261   |
| epoch                          | 867         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5151.454    |
| evaluation/return-max          | 5211.9873   |
| evaluation/return-min          | 5107.9736   |
| evaluation/return-std          | 29.456139   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46233       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5151.454    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 211.80893   |
| Q-std                          | 121.11994   |
| Q_loss                         | 103.01294   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 867         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000117    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000614    |
| times/evaluation_paths         | 38.6        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 73          |
| timestep                       | 1000        |
| timesteps_total                | 868000      |
| train-steps                    | 868000      |
| training/Q/q1_loss             | 98.01768    |
| training/sac_pi/alpha          | 0.17062783  |
| training/sac_pi/alpha_loss     | -0.11817381 |
| training/sac_pi/logp_pi        | 4.6338706   |
| training/sac_pi/pi_entropy     | 3.3433928   |
| training/sac_pi/pi_global_norm | 1.5312451   |
| training/sac_pi/policy_loss    | -222.84695  |
| training/sac_pi/std            | 0.49658984  |
| training/sac_pi/valid_num      | 4935.0      |
| training/sac_Q/q1              | 210.18393   |
| training/sac_Q/q2              | 210.78467   |
| training/sac_Q/q2_loss         | 98.69075    |
| training/sac_Q/q_global_norm   | 313.4827    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17496406  |
| epoch                          | 868         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4981.662    |
| evaluation/return-max          | 5169.213    |
| evaluation/return-min          | 4878.071    |
| evaluation/return-std          | 93.44567    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46271       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4981.662    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 196.79964   |
| Q-std                          | 122.53669   |
| Q_loss                         | 87.84744    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 868         |
| times/epoch_after_hook         | 3.12e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000633    |
| times/evaluation_paths         | 39.8        |
| times/timestep_after_hook      | 0.004       |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 71.2        |
| timestep                       | 1000        |
| timesteps_total                | 869000      |
| train-steps                    | 869000      |
| training/Q/q1_loss             | 89.94126    |
| training/sac_pi/alpha          | 0.1749655   |
| training/sac_pi/alpha_loss     | 0.049467612 |
| training/sac_pi/logp_pi        | 5.1632376   |
| training/sac_pi/pi_entropy     | 3.3852463   |
| training/sac_pi/pi_global_norm | 1.5664419   |
| training/sac_pi/policy_loss    | -220.6381   |
| training/sac_pi/std            | 0.5098726   |
| training/sac_pi/valid_num      | 4940.0      |
| training/sac_Q/q1              | 207.98038   |
| training/sac_Q/q2              | 209.77654   |
| training/sac_Q/q2_loss         | 88.749504   |
| training/sac_Q/q_global_norm   | 200.12027   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17018768   |
| epoch                          | 869          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4899.628     |
| evaluation/return-max          | 4987.494     |
| evaluation/return-min          | 4789.134     |
| evaluation/return-std          | 55.988937    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.07         |
| model/origin_ret               | 85.4         |
| model/penalty_ret              | 80.2         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46259        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4899.628     |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 215.01753    |
| Q-std                          | 111.70635    |
| Q_loss                         | 92.97471     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 869          |
| times/epoch_after_hook         | 2.05e-06     |
| times/epoch_before_hook        | 0.000255     |
| times/epoch_rollout_model      | 478          |
| times/evaluation_metrics       | 0.000622     |
| times/evaluation_paths         | 35.8         |
| times/timestep_after_hook      | 0.00399      |
| times/timestep_before_hook     | 0.00816      |
| times/train                    | 58.2         |
| timestep                       | 1000         |
| timesteps_total                | 870000       |
| train-steps                    | 870000       |
| training/Q/q1_loss             | 108.10684    |
| training/sac_pi/alpha          | 0.17018582   |
| training/sac_pi/alpha_loss     | -0.045323633 |
| training/sac_pi/logp_pi        | 4.401255     |
| training/sac_pi/pi_entropy     | 3.4391422    |
| training/sac_pi/pi_global_norm | 1.5658643    |
| training/sac_pi/policy_loss    | -220.14783   |
| training/sac_pi/std            | 0.4960584    |
| training/sac_pi/valid_num      | 4956.0       |
| training/sac_Q/q1              | 207.0749     |
| training/sac_Q/q2              | 210.93477    |
| training/sac_Q/q2_loss         | 108.48951    |
| training/sac_Q/q_global_norm   | 225.3202     |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16688794  |
| epoch                          | 870         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5134.6123   |
| evaluation/return-max          | 5187.472    |
| evaluation/return-min          | 5066.5264   |
| evaluation/return-std          | 32.004208   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46301       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5134.6123   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 220.8342    |
| Q-std                          | 103.48293   |
| Q_loss                         | 96.0757     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 870         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.00016     |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000531    |
| times/evaluation_paths         | 40.2        |
| times/timestep_after_hook      | 0.00396     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 69.7        |
| timestep                       | 1000        |
| timesteps_total                | 871000      |
| train-steps                    | 871000      |
| training/Q/q1_loss             | 100.80547   |
| training/sac_pi/alpha          | 0.16690677  |
| training/sac_pi/alpha_loss     | 0.025689393 |
| training/sac_pi/logp_pi        | 4.0732565   |
| training/sac_pi/pi_entropy     | 3.4297516   |
| training/sac_pi/pi_global_norm | 1.3826315   |
| training/sac_pi/policy_loss    | -222.04121  |
| training/sac_pi/std            | 0.48294264  |
| training/sac_pi/valid_num      | 4992.0      |
| training/sac_Q/q1              | 214.79692   |
| training/sac_Q/q2              | 215.96196   |
| training/sac_Q/q2_loss         | 101.76843   |
| training/sac_Q/q_global_norm   | 215.55037   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16614787 |
| epoch                          | 871        |
| evaluation/episode-length-avg  | 915        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 148        |
| evaluation/episode-length-std  | 256        |
| evaluation/return-average      | 4292.048   |
| evaluation/return-max          | 4814.774   |
| evaluation/return-min          | 345.69098  |
| evaluation/return-std          | 1316.981   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46266      |
| perf/AverageLength             | 915        |
| perf/AverageReturn             | 4292.048   |
| perf/NormalizedReturn          | 0.935      |
| Q-avg                          | 205.10811  |
| Q-std                          | 194.31953  |
| Q_loss                         | 114.98564  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 871        |
| times/epoch_after_hook         | 2.02e-06   |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000505   |
| times/evaluation_paths         | 37.4       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 69.7       |
| timestep                       | 1000       |
| timesteps_total                | 872000     |
| train-steps                    | 872000     |
| training/Q/q1_loss             | 86.94217   |
| training/sac_pi/alpha          | 0.16608696 |
| training/sac_pi/alpha_loss     | 0.28465724 |
| training/sac_pi/logp_pi        | 3.8877444  |
| training/sac_pi/pi_entropy     | 3.2881455  |
| training/sac_pi/pi_global_norm | 1.8241155  |
| training/sac_pi/policy_loss    | -226.43607 |
| training/sac_pi/std            | 0.46297497 |
| training/sac_pi/valid_num      | 4995.0     |
| training/sac_Q/q1              | 219.94595  |
| training/sac_Q/q2              | 220.70059  |
| training/sac_Q/q2_loss         | 87.26389   |
| training/sac_Q/q_global_norm   | 221.17462  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16955446  |
| epoch                          | 872         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4864.927    |
| evaluation/return-max          | 4971.401    |
| evaluation/return-min          | 4801.983    |
| evaluation/return-std          | 58.72048    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46277       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4864.927    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 219.11343   |
| Q-std                          | 100.06399   |
| Q_loss                         | 72.98395    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 872         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000513    |
| times/evaluation_paths         | 41.3        |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 69.9        |
| timestep                       | 1000        |
| timesteps_total                | 873000      |
| train-steps                    | 873000      |
| training/Q/q1_loss             | 113.91876   |
| training/sac_pi/alpha          | 0.16959143  |
| training/sac_pi/alpha_loss     | -0.33783725 |
| training/sac_pi/logp_pi        | 4.2608843   |
| training/sac_pi/pi_entropy     | 3.4611862   |
| training/sac_pi/pi_global_norm | 1.5497236   |
| training/sac_pi/policy_loss    | -221.74007  |
| training/sac_pi/std            | 0.48916042  |
| training/sac_pi/valid_num      | 4974.0      |
| training/sac_Q/q1              | 211.53552   |
| training/sac_Q/q2              | 211.62773   |
| training/sac_Q/q2_loss         | 112.66549   |
| training/sac_Q/q_global_norm   | 234.63316   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16845438 |
| epoch                          | 873        |
| evaluation/episode-length-avg  | 861        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 302        |
| evaluation/episode-length-std  | 278        |
| evaluation/return-average      | 3995.7668  |
| evaluation/return-max          | 4798.099   |
| evaluation/return-min          | 1081.9629  |
| evaluation/return-std          | 1457.0358  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46323      |
| perf/AverageLength             | 861        |
| perf/AverageReturn             | 3995.7668  |
| perf/NormalizedReturn          | 0.87       |
| Q-avg                          | 209.19356  |
| Q-std                          | 119.14912  |
| Q_loss                         | 89.57346   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 873        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000311   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000555   |
| times/evaluation_paths         | 30.1       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 60         |
| timestep                       | 1000       |
| timesteps_total                | 874000     |
| train-steps                    | 874000     |
| training/Q/q1_loss             | 107.62964  |
| training/sac_pi/alpha          | 0.16846745 |
| training/sac_pi/alpha_loss     | -0.2926837 |
| training/sac_pi/logp_pi        | 4.1198797  |
| training/sac_pi/pi_entropy     | 3.3468258  |
| training/sac_pi/pi_global_norm | 1.4536214  |
| training/sac_pi/policy_loss    | -220.79549 |
| training/sac_pi/std            | 0.4905916  |
| training/sac_pi/valid_num      | 4985.0     |
| training/sac_Q/q1              | 212.02841  |
| training/sac_Q/q2              | 213.68393  |
| training/sac_Q/q2_loss         | 106.44335  |
| training/sac_Q/q_global_norm   | 241.7272   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16588224 |
| epoch                          | 874        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4712.7944  |
| evaluation/return-max          | 4800.843   |
| evaluation/return-min          | 4621.1543  |
| evaluation/return-std          | 58.255386  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46420      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4712.7944  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 209.78557  |
| Q-std                          | 136.81146  |
| Q_loss                         | 93.86364   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 874        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000105   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000512   |
| times/evaluation_paths         | 43.3       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00801    |
| times/train                    | 67.6       |
| timestep                       | 1000       |
| timesteps_total                | 875000     |
| train-steps                    | 875000     |
| training/Q/q1_loss             | 104.46734  |
| training/sac_pi/alpha          | 0.16588753 |
| training/sac_pi/alpha_loss     | 0.18283191 |
| training/sac_pi/logp_pi        | 4.300878   |
| training/sac_pi/pi_entropy     | 3.1144066  |
| training/sac_pi/pi_global_norm | 1.4719609  |
| training/sac_pi/policy_loss    | -228.09334 |
| training/sac_pi/std            | 0.45957306 |
| training/sac_pi/valid_num      | 5017.0     |
| training/sac_Q/q1              | 215.33804  |
| training/sac_Q/q2              | 217.1999   |
| training/sac_Q/q2_loss         | 103.57347  |
| training/sac_Q/q_global_norm   | 220.82588  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17016461 |
| epoch                          | 875        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5169.4434  |
| evaluation/return-max          | 5238.375   |
| evaluation/return-min          | 5121.9526  |
| evaluation/return-std          | 30.396488  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46392      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5169.4434  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 205.74724  |
| Q-std                          | 130.03069  |
| Q_loss                         | 107.00069  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 875        |
| times/epoch_after_hook         | 1.13e-05   |
| times/epoch_before_hook        | 0.000215   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000526   |
| times/evaluation_paths         | 39.6       |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 69.5       |
| timestep                       | 1000       |
| timesteps_total                | 876000     |
| train-steps                    | 876000     |
| training/Q/q1_loss             | 89.07778   |
| training/sac_pi/alpha          | 0.17015854 |
| training/sac_pi/alpha_loss     | 0.11996044 |
| training/sac_pi/logp_pi        | 4.026421   |
| training/sac_pi/pi_entropy     | 3.6384003  |
| training/sac_pi/pi_global_norm | 1.5324879  |
| training/sac_pi/policy_loss    | -221.79759 |
| training/sac_pi/std            | 0.5062991  |
| training/sac_pi/valid_num      | 5003.0     |
| training/sac_Q/q1              | 216.42802  |
| training/sac_Q/q2              | 216.79639  |
| training/sac_Q/q2_loss         | 88.221146  |
| training/sac_Q/q_global_norm   | 275.76965  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1718379  |
| epoch                          | 876        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5296.5195  |
| evaluation/return-max          | 5323.2744  |
| evaluation/return-min          | 5202.6826  |
| evaluation/return-std          | 33.17269   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46235      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5296.5195  |
| perf/NormalizedReturn          | 1.15       |
| Q-avg                          | 213.36714  |
| Q-std                          | 123.20074  |
| Q_loss                         | 86.41944   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 876        |
| times/epoch_after_hook         | 2.13e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000681   |
| times/evaluation_paths         | 40.4       |
| times/timestep_after_hook      | 0.00408    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 70.7       |
| timestep                       | 1000       |
| timesteps_total                | 877000     |
| train-steps                    | 877000     |
| training/Q/q1_loss             | 79.67643   |
| training/sac_pi/alpha          | 0.17182414 |
| training/sac_pi/alpha_loss     | 0.3089501  |
| training/sac_pi/logp_pi        | 4.415389   |
| training/sac_pi/pi_entropy     | 3.4930916  |
| training/sac_pi/pi_global_norm | 1.6286386  |
| training/sac_pi/policy_loss    | -227.37053 |
| training/sac_pi/std            | 0.49820668 |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 215.62578  |
| training/sac_Q/q2              | 217.43506  |
| training/sac_Q/q2_loss         | 80.4607    |
| training/sac_Q/q_global_norm   | 276.88007  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17035574   |
| epoch                          | 877          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5270.3413    |
| evaluation/return-max          | 5338.3057    |
| evaluation/return-min          | 5220.3887    |
| evaluation/return-std          | 36.374474    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.07         |
| model/origin_ret               | 86           |
| model/penalty_ret              | 80.3         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46316        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5270.3413    |
| perf/NormalizedReturn          | 1.15         |
| Q-avg                          | 205.01132    |
| Q-std                          | 142.0204     |
| Q_loss                         | 108.19694    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 877          |
| times/epoch_after_hook         | 2.16e-06     |
| times/epoch_before_hook        | 0.000265     |
| times/epoch_rollout_model      | 476          |
| times/evaluation_metrics       | 0.000631     |
| times/evaluation_paths         | 33.7         |
| times/timestep_after_hook      | 0.00392      |
| times/timestep_before_hook     | 0.00803      |
| times/train                    | 57.9         |
| timestep                       | 1000         |
| timesteps_total                | 878000       |
| train-steps                    | 878000       |
| training/Q/q1_loss             | 96.24599     |
| training/sac_pi/alpha          | 0.17036259   |
| training/sac_pi/alpha_loss     | -0.032508615 |
| training/sac_pi/logp_pi        | 3.9794624    |
| training/sac_pi/pi_entropy     | 3.6693847    |
| training/sac_pi/pi_global_norm | 1.9142113    |
| training/sac_pi/policy_loss    | -219.25966   |
| training/sac_pi/std            | 0.5119075    |
| training/sac_pi/valid_num      | 4932.0       |
| training/sac_Q/q1              | 206.41133    |
| training/sac_Q/q2              | 207.8505     |
| training/sac_Q/q2_loss         | 94.749794    |
| training/sac_Q/q_global_norm   | 177.78487    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16779472  |
| epoch                          | 878         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5186.953    |
| evaluation/return-max          | 5233.117    |
| evaluation/return-min          | 5087.3955   |
| evaluation/return-std          | 44.00511    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46155       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5186.953    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 217.4095    |
| Q-std                          | 116.98729   |
| Q_loss                         | 117.0419    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 878         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.000152    |
| times/epoch_rollout_model      | 475         |
| times/evaluation_metrics       | 0.000542    |
| times/evaluation_paths         | 42.4        |
| times/timestep_after_hook      | 0.00397     |
| times/timestep_before_hook     | 0.00806     |
| times/train                    | 66.5        |
| timestep                       | 1000        |
| timesteps_total                | 879000      |
| train-steps                    | 879000      |
| training/Q/q1_loss             | 81.56283    |
| training/sac_pi/alpha          | 0.16780066  |
| training/sac_pi/alpha_loss     | 0.020624539 |
| training/sac_pi/logp_pi        | 4.6398225   |
| training/sac_pi/pi_entropy     | 3.3530114   |
| training/sac_pi/pi_global_norm | 1.502053    |
| training/sac_pi/policy_loss    | -216.55428  |
| training/sac_pi/std            | 0.49505407  |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 206.514     |
| training/sac_Q/q2              | 207.3842    |
| training/sac_Q/q2_loss         | 83.547165   |
| training/sac_Q/q_global_norm   | 272.82913   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17325154   |
| epoch                          | 879          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4974.029     |
| evaluation/return-max          | 5084.492     |
| evaluation/return-min          | 4929.493     |
| evaluation/return-std          | 45.223217    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.97         |
| model/origin_ret               | 84.3         |
| model/penalty_ret              | 80.5         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46154        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4974.029     |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 216.1945     |
| Q-std                          | 115.650116   |
| Q_loss                         | 93.88024     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 879          |
| times/epoch_after_hook         | 2.02e-06     |
| times/epoch_before_hook        | 0.000125     |
| times/epoch_rollout_model      | 495          |
| times/evaluation_metrics       | 0.00059      |
| times/evaluation_paths         | 42.4         |
| times/timestep_after_hook      | 0.004        |
| times/timestep_before_hook     | 0.00815      |
| times/train                    | 69           |
| timestep                       | 1000         |
| timesteps_total                | 880000       |
| train-steps                    | 880000       |
| training/Q/q1_loss             | 103.05006    |
| training/sac_pi/alpha          | 0.17326972   |
| training/sac_pi/alpha_loss     | -0.021095932 |
| training/sac_pi/logp_pi        | 4.2830696    |
| training/sac_pi/pi_entropy     | 3.5302906    |
| training/sac_pi/pi_global_norm | 1.5677904    |
| training/sac_pi/policy_loss    | -221.9721    |
| training/sac_pi/std            | 0.495553     |
| training/sac_pi/valid_num      | 4969.0       |
| training/sac_Q/q1              | 214.09131    |
| training/sac_Q/q2              | 214.04044    |
| training/sac_Q/q2_loss         | 104.15649    |
| training/sac_Q/q_global_norm   | 283.22046    |
----------------------------------------------------------------------------------
[WARN] 880 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16907337 |
| epoch                          | 880        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4818.3936  |
| evaluation/return-max          | 4916.7666  |
| evaluation/return-min          | 4726.9277  |
| evaluation/return-std          | 58.05243   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46323      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4818.3936  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 224.68701  |
| Q-std                          | 101.67268  |
| Q_loss                         | 96.73083   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 880        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000619   |
| times/evaluation_paths         | 41.5       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 67.9       |
| timestep                       | 1000       |
| timesteps_total                | 881000     |
| train-steps                    | 881000     |
| training/Q/q1_loss             | 101.2748   |
| training/sac_pi/alpha          | 0.16904132 |
| training/sac_pi/alpha_loss     | 0.26428372 |
| training/sac_pi/logp_pi        | 3.5017216  |
| training/sac_pi/pi_entropy     | 3.4842389  |
| training/sac_pi/pi_global_norm | 1.7385905  |
| training/sac_pi/policy_loss    | -220.12634 |
| training/sac_pi/std            | 0.46399495 |
| training/sac_pi/valid_num      | 5030.0     |
| training/sac_Q/q1              | 215.9794   |
| training/sac_Q/q2              | 216.4584   |
| training/sac_Q/q2_loss         | 101.493835 |
| training/sac_Q/q_global_norm   | 167.89578  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16386043 |
| epoch                          | 881        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5063.214   |
| evaluation/return-max          | 5158.9326  |
| evaluation/return-min          | 4972.218   |
| evaluation/return-std          | 57.28508   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46438      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5063.214   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 218.25308  |
| Q-std                          | 118.98755  |
| Q_loss                         | 103.49721  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 881        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000311   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.0006     |
| times/evaluation_paths         | 32.2       |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 64.1       |
| timestep                       | 1000       |
| timesteps_total                | 882000     |
| train-steps                    | 882000     |
| training/Q/q1_loss             | 98.19993   |
| training/sac_pi/alpha          | 0.16386102 |
| training/sac_pi/alpha_loss     | 0.27992028 |
| training/sac_pi/logp_pi        | 4.514123   |
| training/sac_pi/pi_entropy     | 3.3983712  |
| training/sac_pi/pi_global_norm | 1.5972393  |
| training/sac_pi/policy_loss    | -220.18143 |
| training/sac_pi/std            | 0.49211222 |
| training/sac_pi/valid_num      | 4922.0     |
| training/sac_Q/q1              | 212.275    |
| training/sac_Q/q2              | 211.31845  |
| training/sac_Q/q2_loss         | 99.81943   |
| training/sac_Q/q_global_norm   | 228.45567  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17080387 |
| epoch                          | 882        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5008.988   |
| evaluation/return-max          | 5056.5073  |
| evaluation/return-min          | 4970.9473  |
| evaluation/return-std          | 24.038084  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46346      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5008.988   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 217.34663  |
| Q-std                          | 146.49446  |
| Q_loss                         | 81.30297   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 882        |
| times/epoch_after_hook         | 2.09e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.00106    |
| times/evaluation_paths         | 45.1       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 64.1       |
| timestep                       | 1000       |
| timesteps_total                | 883000     |
| train-steps                    | 883000     |
| training/Q/q1_loss             | 121.282074 |
| training/sac_pi/alpha          | 0.1708111  |
| training/sac_pi/alpha_loss     | -0.4699613 |
| training/sac_pi/logp_pi        | 4.4979434  |
| training/sac_pi/pi_entropy     | 3.4443774  |
| training/sac_pi/pi_global_norm | 1.7260221  |
| training/sac_pi/policy_loss    | -220.25505 |
| training/sac_pi/std            | 0.50222605 |
| training/sac_pi/valid_num      | 4918.0     |
| training/sac_Q/q1              | 210.81523  |
| training/sac_Q/q2              | 212.99484  |
| training/sac_Q/q2_loss         | 121.22124  |
| training/sac_Q/q_global_norm   | 225.77756  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1696126   |
| epoch                          | 883         |
| evaluation/episode-length-avg  | 910         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 694         |
| evaluation/episode-length-std  | 121         |
| evaluation/return-average      | 4682.1807   |
| evaluation/return-max          | 5226.624    |
| evaluation/return-min          | 3439.6519   |
| evaluation/return-std          | 685.65955   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46355       |
| perf/AverageLength             | 910         |
| perf/AverageReturn             | 4682.1807   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 213.25923   |
| Q-std                          | 115.19822   |
| Q_loss                         | 94.5085     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 883         |
| times/epoch_after_hook         | 2.12e-06    |
| times/epoch_before_hook        | 0.00036     |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000565    |
| times/evaluation_paths         | 39.5        |
| times/timestep_after_hook      | 0.00397     |
| times/timestep_before_hook     | 0.00833     |
| times/train                    | 68.3        |
| timestep                       | 1000        |
| timesteps_total                | 884000      |
| train-steps                    | 884000      |
| training/Q/q1_loss             | 98.742805   |
| training/sac_pi/alpha          | 0.16960515  |
| training/sac_pi/alpha_loss     | 0.006985447 |
| training/sac_pi/logp_pi        | 4.8130927   |
| training/sac_pi/pi_entropy     | 3.4234414   |
| training/sac_pi/pi_global_norm | 1.4910119   |
| training/sac_pi/policy_loss    | -226.30951  |
| training/sac_pi/std            | 0.49781275  |
| training/sac_pi/valid_num      | 4917.0      |
| training/sac_Q/q1              | 208.47012   |
| training/sac_Q/q2              | 211.29907   |
| training/sac_Q/q2_loss         | 98.47638    |
| training/sac_Q/q_global_norm   | 221.01086   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1647129  |
| epoch                          | 884        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4958.382   |
| evaluation/return-max          | 5060.087   |
| evaluation/return-min          | 4887.6074  |
| evaluation/return-std          | 47.103924  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 87.3       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46160      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4958.382   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 205.68417  |
| Q-std                          | 118.21358  |
| Q_loss                         | 93.3961    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 884        |
| times/epoch_after_hook         | 3.81e-06   |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.00066    |
| times/evaluation_paths         | 40.5       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 68.6       |
| timestep                       | 1000       |
| timesteps_total                | 885000     |
| train-steps                    | 885000     |
| training/Q/q1_loss             | 101.28062  |
| training/sac_pi/alpha          | 0.16467138 |
| training/sac_pi/alpha_loss     | 0.46451235 |
| training/sac_pi/logp_pi        | 4.0647264  |
| training/sac_pi/pi_entropy     | 3.2275224  |
| training/sac_pi/pi_global_norm | 1.8627099  |
| training/sac_pi/policy_loss    | -230.08852 |
| training/sac_pi/std            | 0.46129832 |
| training/sac_pi/valid_num      | 5022.0     |
| training/sac_Q/q1              | 222.06143  |
| training/sac_Q/q2              | 223.07129  |
| training/sac_Q/q2_loss         | 101.77692  |
| training/sac_Q/q_global_norm   | 156.01123  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16033582 |
| epoch                          | 885        |
| evaluation/episode-length-avg  | 929        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 294        |
| evaluation/episode-length-std  | 212        |
| evaluation/return-average      | 4469.162   |
| evaluation/return-max          | 4973.243   |
| evaluation/return-min          | 1034.0647  |
| evaluation/return-std          | 1149.5623  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46387      |
| perf/AverageLength             | 929        |
| perf/AverageReturn             | 4469.162   |
| perf/NormalizedReturn          | 0.973      |
| Q-avg                          | 212.46797  |
| Q-std                          | 100.935715 |
| Q_loss                         | 87.86872   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 885        |
| times/epoch_after_hook         | 3.41e-06   |
| times/epoch_before_hook        | 0.000275   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000509   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 59.5       |
| timestep                       | 1000       |
| timesteps_total                | 886000     |
| train-steps                    | 886000     |
| training/Q/q1_loss             | 125.36381  |
| training/sac_pi/alpha          | 0.16032703 |
| training/sac_pi/alpha_loss     | 0.38136995 |
| training/sac_pi/logp_pi        | 4.4354644  |
| training/sac_pi/pi_entropy     | 3.4448688  |
| training/sac_pi/pi_global_norm | 1.9910418  |
| training/sac_pi/policy_loss    | -216.0569  |
| training/sac_pi/std            | 0.49003342 |
| training/sac_pi/valid_num      | 4958.0     |
| training/sac_Q/q1              | 208.55376  |
| training/sac_Q/q2              | 208.82646  |
| training/sac_Q/q2_loss         | 123.5619   |
| training/sac_Q/q_global_norm   | 266.80576  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17094415 |
| epoch                          | 886        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5042.337   |
| evaluation/return-max          | 5158.0083  |
| evaluation/return-min          | 4853.3457  |
| evaluation/return-std          | 80.669205  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46344      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5042.337   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 222.8248   |
| Q-std                          | 120.31357  |
| Q_loss                         | 82.552055  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 886        |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 522        |
| times/evaluation_metrics       | 0.000542   |
| times/evaluation_paths         | 51.1       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 68.1       |
| timestep                       | 1000       |
| timesteps_total                | 887000     |
| train-steps                    | 887000     |
| training/Q/q1_loss             | 98.28193   |
| training/sac_pi/alpha          | 0.17092347 |
| training/sac_pi/alpha_loss     | 0.3576647  |
| training/sac_pi/logp_pi        | 4.279469   |
| training/sac_pi/pi_entropy     | 3.3452308  |
| training/sac_pi/pi_global_norm | 1.5783699  |
| training/sac_pi/policy_loss    | -227.54683 |
| training/sac_pi/std            | 0.47765693 |
| training/sac_pi/valid_num      | 5029.0     |
| training/sac_Q/q1              | 222.35538  |
| training/sac_Q/q2              | 223.26472  |
| training/sac_Q/q2_loss         | 97.87806   |
| training/sac_Q/q_global_norm   | 213.24298  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1621131  |
| epoch                          | 887        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4859.669   |
| evaluation/return-max          | 4913.0     |
| evaluation/return-min          | 4803.0513  |
| evaluation/return-std          | 31.883434  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46124      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4859.669   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 204.94328  |
| Q-std                          | 143.2901   |
| Q_loss                         | 96.04869   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 887        |
| times/epoch_after_hook         | 2.09e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000548   |
| times/evaluation_paths         | 43.6       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 63.4       |
| timestep                       | 1000       |
| timesteps_total                | 888000     |
| train-steps                    | 888000     |
| training/Q/q1_loss             | 98.19542   |
| training/sac_pi/alpha          | 0.16213527 |
| training/sac_pi/alpha_loss     | 0.09642876 |
| training/sac_pi/logp_pi        | 3.873623   |
| training/sac_pi/pi_entropy     | 3.3942032  |
| training/sac_pi/pi_global_norm | 1.8799684  |
| training/sac_pi/policy_loss    | -218.31546 |
| training/sac_pi/std            | 0.48470926 |
| training/sac_pi/valid_num      | 4997.0     |
| training/sac_Q/q1              | 208.535    |
| training/sac_Q/q2              | 210.16422  |
| training/sac_Q/q2_loss         | 98.36289   |
| training/sac_Q/q_global_norm   | 273.1902   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16626221  |
| epoch                          | 888         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4912.64     |
| evaluation/return-max          | 4992.836    |
| evaluation/return-min          | 4820.161    |
| evaluation/return-std          | 62.135887   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46442       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4912.64     |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 211.60608   |
| Q-std                          | 119.13998   |
| Q_loss                         | 92.55654    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 888         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000541    |
| times/evaluation_paths         | 46.6        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.0102      |
| times/train                    | 62.9        |
| timestep                       | 1000        |
| timesteps_total                | 889000      |
| train-steps                    | 889000      |
| training/Q/q1_loss             | 91.37002    |
| training/sac_pi/alpha          | 0.16625074  |
| training/sac_pi/alpha_loss     | -0.23977704 |
| training/sac_pi/logp_pi        | 4.2741404   |
| training/sac_pi/pi_entropy     | 3.156757    |
| training/sac_pi/pi_global_norm | 1.4385626   |
| training/sac_pi/policy_loss    | -226.49574  |
| training/sac_pi/std            | 0.4590694   |
| training/sac_pi/valid_num      | 4994.0      |
| training/sac_Q/q1              | 218.8479    |
| training/sac_Q/q2              | 219.3219    |
| training/sac_Q/q2_loss         | 90.90463    |
| training/sac_Q/q_global_norm   | 162.36385   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16245091  |
| epoch                          | 889         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5054.245    |
| evaluation/return-max          | 5167.7295   |
| evaluation/return-min          | 4918.4214   |
| evaluation/return-std          | 75.33738    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46353       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5054.245    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 202.95882   |
| Q-std                          | 186.09866   |
| Q_loss                         | 137.15578   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 889         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.00026     |
| times/epoch_rollout_model      | 504         |
| times/evaluation_metrics       | 0.000591    |
| times/evaluation_paths         | 37.1        |
| times/timestep_after_hook      | 0.0042      |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 73.7        |
| timestep                       | 1000        |
| timesteps_total                | 890000      |
| train-steps                    | 890000      |
| training/Q/q1_loss             | 112.49811   |
| training/sac_pi/alpha          | 0.16243796  |
| training/sac_pi/alpha_loss     | -0.15245993 |
| training/sac_pi/logp_pi        | 3.544609    |
| training/sac_pi/pi_entropy     | 3.478918    |
| training/sac_pi/pi_global_norm | 1.4768652   |
| training/sac_pi/policy_loss    | -220.28499  |
| training/sac_pi/std            | 0.48003772  |
| training/sac_pi/valid_num      | 4991.0      |
| training/sac_Q/q1              | 213.6932    |
| training/sac_Q/q2              | 214.09673   |
| training/sac_Q/q2_loss         | 111.519936  |
| training/sac_Q/q_global_norm   | 278.0633    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17191815  |
| epoch                          | 890         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5052.8984   |
| evaluation/return-max          | 5101.3203   |
| evaluation/return-min          | 4988.9165   |
| evaluation/return-std          | 39.921375   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46250       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5052.8984   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 211.43167   |
| Q-std                          | 131.45802   |
| Q_loss                         | 112.751526  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 890         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 546         |
| times/evaluation_metrics       | 0.000601    |
| times/evaluation_paths         | 36          |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 73.7        |
| timestep                       | 1000        |
| timesteps_total                | 891000      |
| train-steps                    | 891000      |
| training/Q/q1_loss             | 101.50382   |
| training/sac_pi/alpha          | 0.1719458   |
| training/sac_pi/alpha_loss     | 0.038114276 |
| training/sac_pi/logp_pi        | 4.568003    |
| training/sac_pi/pi_entropy     | 3.7232132   |
| training/sac_pi/pi_global_norm | 1.3932139   |
| training/sac_pi/policy_loss    | -215.19217  |
| training/sac_pi/std            | 0.5450868   |
| training/sac_pi/valid_num      | 4918.0      |
| training/sac_Q/q1              | 201.40266   |
| training/sac_Q/q2              | 203.8863    |
| training/sac_Q/q2_loss         | 100.89199   |
| training/sac_Q/q_global_norm   | 193.4661    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16932875  |
| epoch                          | 891         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4784.856    |
| evaluation/return-max          | 4806.9385   |
| evaluation/return-min          | 4764.6924   |
| evaluation/return-std          | 10.571082   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46329       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4784.856    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 211.15959   |
| Q-std                          | 107.771324  |
| Q_loss                         | 112.11426   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 891         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000154    |
| times/epoch_rollout_model      | 535         |
| times/evaluation_metrics       | 0.000525    |
| times/evaluation_paths         | 37.1        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 67.4        |
| timestep                       | 1000        |
| timesteps_total                | 892000      |
| train-steps                    | 892000      |
| training/Q/q1_loss             | 109.16144   |
| training/sac_pi/alpha          | 0.16933104  |
| training/sac_pi/alpha_loss     | -0.03511469 |
| training/sac_pi/logp_pi        | 4.0850883   |
| training/sac_pi/pi_entropy     | 3.5651283   |
| training/sac_pi/pi_global_norm | 1.6508578   |
| training/sac_pi/policy_loss    | -213.6685   |
| training/sac_pi/std            | 0.51412874  |
| training/sac_pi/valid_num      | 4936.0      |
| training/sac_Q/q1              | 203.16545   |
| training/sac_Q/q2              | 203.75623   |
| training/sac_Q/q2_loss         | 109.68094   |
| training/sac_Q/q_global_norm   | 254.54332   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17314355  |
| epoch                          | 892         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5153.337    |
| evaluation/return-max          | 5225.8457   |
| evaluation/return-min          | 5057.701    |
| evaluation/return-std          | 46.32305    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46416       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5153.337    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 215.08133   |
| Q-std                          | 117.50793   |
| Q_loss                         | 72.20218    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 892         |
| times/epoch_after_hook         | 3.3e-06     |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 549         |
| times/evaluation_metrics       | 0.000637    |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 60          |
| timestep                       | 1000        |
| timesteps_total                | 893000      |
| train-steps                    | 893000      |
| training/Q/q1_loss             | 108.86081   |
| training/sac_pi/alpha          | 0.1731693   |
| training/sac_pi/alpha_loss     | -0.21723878 |
| training/sac_pi/logp_pi        | 4.983595    |
| training/sac_pi/pi_entropy     | 3.616518    |
| training/sac_pi/pi_global_norm | 1.5106643   |
| training/sac_pi/policy_loss    | -214.63101  |
| training/sac_pi/std            | 0.5349798   |
| training/sac_pi/valid_num      | 4933.0      |
| training/sac_Q/q1              | 198.08266   |
| training/sac_Q/q2              | 199.95682   |
| training/sac_Q/q2_loss         | 109.94728   |
| training/sac_Q/q_global_norm   | 217.82312   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1712968  |
| epoch                          | 893        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5067.078   |
| evaluation/return-max          | 5133.398   |
| evaluation/return-min          | 5004.916   |
| evaluation/return-std          | 40.93851   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46262      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5067.078   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 203.55681  |
| Q-std                          | 123.6574   |
| Q_loss                         | 99.06675   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 893        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000583   |
| times/epoch_rollout_model      | 532        |
| times/evaluation_metrics       | 0.000538   |
| times/evaluation_paths         | 32.4       |
| times/timestep_after_hook      | 0.00417    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 894000     |
| train-steps                    | 894000     |
| training/Q/q1_loss             | 117.13924  |
| training/sac_pi/alpha          | 0.17129242 |
| training/sac_pi/alpha_loss     | 0.14271833 |
| training/sac_pi/logp_pi        | 5.5417037  |
| training/sac_pi/pi_entropy     | 3.3083863  |
| training/sac_pi/pi_global_norm | 1.5335823  |
| training/sac_pi/policy_loss    | -220.74016 |
| training/sac_pi/std            | 0.5127971  |
| training/sac_pi/valid_num      | 4905.0     |
| training/sac_Q/q1              | 204.28812  |
| training/sac_Q/q2              | 203.05537  |
| training/sac_Q/q2_loss         | 117.51791  |
| training/sac_Q/q_global_norm   | 320.4138   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1649638   |
| epoch                          | 894         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5129.343    |
| evaluation/return-max          | 5219.01     |
| evaluation/return-min          | 5019.9355   |
| evaluation/return-std          | 64.41853    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46206       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5129.343    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 217.05807   |
| Q-std                          | 99.79448    |
| Q_loss                         | 113.37573   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 894         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 514         |
| times/evaluation_metrics       | 0.000559    |
| times/evaluation_paths         | 34          |
| times/timestep_after_hook      | 0.00421     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 63          |
| timestep                       | 1000        |
| timesteps_total                | 895000      |
| train-steps                    | 895000      |
| training/Q/q1_loss             | 95.677124   |
| training/sac_pi/alpha          | 0.16497263  |
| training/sac_pi/alpha_loss     | -0.30226657 |
| training/sac_pi/logp_pi        | 4.1732283   |
| training/sac_pi/pi_entropy     | 3.4449306   |
| training/sac_pi/pi_global_norm | 2.0091023   |
| training/sac_pi/policy_loss    | -220.96765  |
| training/sac_pi/std            | 0.50542897  |
| training/sac_pi/valid_num      | 4977.0      |
| training/sac_Q/q1              | 211.91719   |
| training/sac_Q/q2              | 211.8741    |
| training/sac_Q/q2_loss         | 95.13944    |
| training/sac_Q/q_global_norm   | 202.12918   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1707279  |
| epoch                          | 895        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4857.6353  |
| evaluation/return-max          | 5021.92    |
| evaluation/return-min          | 4671.6357  |
| evaluation/return-std          | 113.15363  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46420      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4857.6353  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 206.84412  |
| Q-std                          | 127.02263  |
| Q_loss                         | 105.31748  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 895        |
| times/epoch_after_hook         | 1.97e-06   |
| times/epoch_before_hook        | 0.000145   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.00064    |
| times/evaluation_paths         | 33.4       |
| times/timestep_after_hook      | 0.00431    |
| times/timestep_before_hook     | 0.00867    |
| times/train                    | 63.6       |
| timestep                       | 1000       |
| timesteps_total                | 896000     |
| train-steps                    | 896000     |
| training/Q/q1_loss             | 101.101776 |
| training/sac_pi/alpha          | 0.17071454 |
| training/sac_pi/alpha_loss     | 0.2984582  |
| training/sac_pi/logp_pi        | 5.0297937  |
| training/sac_pi/pi_entropy     | 3.3384337  |
| training/sac_pi/pi_global_norm | 1.7411852  |
| training/sac_pi/policy_loss    | -223.09192 |
| training/sac_pi/std            | 0.50620914 |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 204.67133  |
| training/sac_Q/q2              | 208.46298  |
| training/sac_Q/q2_loss         | 100.6982   |
| training/sac_Q/q_global_norm   | 188.6005   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1644392  |
| epoch                          | 896        |
| evaluation/episode-length-avg  | 765        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 214        |
| evaluation/episode-length-std  | 359        |
| evaluation/return-average      | 3660.4395  |
| evaluation/return-max          | 5078.8013  |
| evaluation/return-min          | 777.7374   |
| evaluation/return-std          | 1886.3223  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46383      |
| perf/AverageLength             | 765        |
| perf/AverageReturn             | 3660.4395  |
| perf/NormalizedReturn          | 0.797      |
| Q-avg                          | 203.73676  |
| Q-std                          | 117.03832  |
| Q_loss                         | 92.00212   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 896        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.00014    |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000515   |
| times/evaluation_paths         | 25         |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 62.4       |
| timestep                       | 1000       |
| timesteps_total                | 897000     |
| train-steps                    | 897000     |
| training/Q/q1_loss             | 110.251396 |
| training/sac_pi/alpha          | 0.16443256 |
| training/sac_pi/alpha_loss     | 0.22873037 |
| training/sac_pi/logp_pi        | 4.1746993  |
| training/sac_pi/pi_entropy     | 3.3221436  |
| training/sac_pi/pi_global_norm | 2.3865278  |
| training/sac_pi/policy_loss    | -219.44147 |
| training/sac_pi/std            | 0.46544364 |
| training/sac_pi/valid_num      | 5023.0     |
| training/sac_Q/q1              | 214.68127  |
| training/sac_Q/q2              | 216.15352  |
| training/sac_Q/q2_loss         | 110.491486 |
| training/sac_Q/q_global_norm   | 263.74222  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16912039 |
| epoch                          | 897        |
| evaluation/episode-length-avg  | 576        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 283        |
| evaluation/episode-length-std  | 346        |
| evaluation/return-average      | 2509.993   |
| evaluation/return-max          | 4839.2275  |
| evaluation/return-min          | 953.036    |
| evaluation/return-std          | 1847.9684  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46173      |
| perf/AverageLength             | 576        |
| perf/AverageReturn             | 2509.993   |
| perf/NormalizedReturn          | 0.546      |
| Q-avg                          | 210.22334  |
| Q-std                          | 117.51822  |
| Q_loss                         | 90.8942    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 897        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.00026    |
| times/epoch_rollout_model      | 532        |
| times/evaluation_metrics       | 0.000633   |
| times/evaluation_paths         | 19.2       |
| times/timestep_after_hook      | 0.00443    |
| times/timestep_before_hook     | 0.00859    |
| times/train                    | 62.8       |
| timestep                       | 1000       |
| timesteps_total                | 898000     |
| train-steps                    | 898000     |
| training/Q/q1_loss             | 107.60439  |
| training/sac_pi/alpha          | 0.16910566 |
| training/sac_pi/alpha_loss     | 0.28349158 |
| training/sac_pi/logp_pi        | 3.7064424  |
| training/sac_pi/pi_entropy     | 3.4645348  |
| training/sac_pi/pi_global_norm | 1.8090705  |
| training/sac_pi/policy_loss    | -220.15279 |
| training/sac_pi/std            | 0.4685908  |
| training/sac_pi/valid_num      | 5034.0     |
| training/sac_Q/q1              | 217.10596  |
| training/sac_Q/q2              | 216.4998   |
| training/sac_Q/q2_loss         | 107.10476  |
| training/sac_Q/q_global_norm   | 277.98633  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17138585 |
| epoch                          | 898        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4456.8687  |
| evaluation/return-max          | 4513.581   |
| evaluation/return-min          | 4375.146   |
| evaluation/return-std          | 42.966347  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46336      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4456.8687  |
| perf/NormalizedReturn          | 0.97       |
| Q-avg                          | 201.77365  |
| Q-std                          | 135.91306  |
| Q_loss                         | 116.60565  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 898        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000152   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000502   |
| times/evaluation_paths         | 33.7       |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 899000     |
| train-steps                    | 899000     |
| training/Q/q1_loss             | 90.26516   |
| training/sac_pi/alpha          | 0.1713668  |
| training/sac_pi/alpha_loss     | 0.37709942 |
| training/sac_pi/logp_pi        | 3.862075   |
| training/sac_pi/pi_entropy     | 3.4330704  |
| training/sac_pi/pi_global_norm | 1.7577298  |
| training/sac_pi/policy_loss    | -214.93259 |
| training/sac_pi/std            | 0.46688652 |
| training/sac_pi/valid_num      | 5036.0     |
| training/sac_Q/q1              | 210.68628  |
| training/sac_Q/q2              | 211.9792   |
| training/sac_Q/q2_loss         | 90.41757   |
| training/sac_Q/q_global_norm   | 284.0959   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17496757 |
| epoch                          | 899        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4729.0454  |
| evaluation/return-max          | 4778.1562  |
| evaluation/return-min          | 4616.8486  |
| evaluation/return-std          | 47.7197    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46258      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4729.0454  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 215.18924  |
| Q-std                          | 115.04661  |
| Q_loss                         | 87.40268   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 899        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 513        |
| times/evaluation_metrics       | 0.000502   |
| times/evaluation_paths         | 33.3       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 59.5       |
| timestep                       | 1000       |
| timesteps_total                | 900000     |
| train-steps                    | 900000     |
| training/Q/q1_loss             | 99.21058   |
| training/sac_pi/alpha          | 0.17494671 |
| training/sac_pi/alpha_loss     | 0.28064066 |
| training/sac_pi/logp_pi        | 4.364087   |
| training/sac_pi/pi_entropy     | 3.400022   |
| training/sac_pi/pi_global_norm | 1.8280615  |
| training/sac_pi/policy_loss    | -224.2338  |
| training/sac_pi/std            | 0.48537832 |
| training/sac_pi/valid_num      | 4999.0     |
| training/sac_Q/q1              | 214.37077  |
| training/sac_Q/q2              | 215.13936  |
| training/sac_Q/q2_loss         | 99.41806   |
| training/sac_Q/q_global_norm   | 250.11325  |
--------------------------------------------------------------------------------
[WARN] 900 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.17460346  |
| epoch                          | 900         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5056.375    |
| evaluation/return-max          | 5159.0815   |
| evaluation/return-min          | 4987.3154   |
| evaluation/return-std          | 55.169502   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46439       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5056.375    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 208.69705   |
| Q-std                          | 147.14389   |
| Q_loss                         | 100.26968   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 900         |
| times/epoch_after_hook         | 1.95e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 510         |
| times/evaluation_metrics       | 0.000555    |
| times/evaluation_paths         | 31.7        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00797     |
| times/train                    | 62          |
| timestep                       | 1000        |
| timesteps_total                | 901000      |
| train-steps                    | 901000      |
| training/Q/q1_loss             | 86.29734    |
| training/sac_pi/alpha          | 0.17457198  |
| training/sac_pi/alpha_loss     | -0.17900234 |
| training/sac_pi/logp_pi        | 5.308321    |
| training/sac_pi/pi_entropy     | 3.328183    |
| training/sac_pi/pi_global_norm | 1.6592615   |
| training/sac_pi/policy_loss    | -222.57202  |
| training/sac_pi/std            | 0.50955653  |
| training/sac_pi/valid_num      | 4905.0      |
| training/sac_Q/q1              | 208.44882   |
| training/sac_Q/q2              | 211.10269   |
| training/sac_Q/q2_loss         | 86.12552    |
| training/sac_Q/q_global_norm   | 182.98094   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16968414 |
| epoch                          | 901        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5177.6436  |
| evaluation/return-max          | 5269.0166  |
| evaluation/return-min          | 5024.023   |
| evaluation/return-std          | 75.9856    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46362      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5177.6436  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 211.15508  |
| Q-std                          | 129.2209   |
| Q_loss                         | 80.69713   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 901        |
| times/epoch_after_hook         | 4.09e-06   |
| times/epoch_before_hook        | 0.000291   |
| times/epoch_rollout_model      | 508        |
| times/evaluation_metrics       | 0.000603   |
| times/evaluation_paths         | 32.2       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 902000     |
| train-steps                    | 902000     |
| training/Q/q1_loss             | 98.77855   |
| training/sac_pi/alpha          | 0.16965239 |
| training/sac_pi/alpha_loss     | 0.21621701 |
| training/sac_pi/logp_pi        | 4.3620477  |
| training/sac_pi/pi_entropy     | 3.415205   |
| training/sac_pi/pi_global_norm | 1.538653   |
| training/sac_pi/policy_loss    | -229.22572 |
| training/sac_pi/std            | 0.49695864 |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 218.23955  |
| training/sac_Q/q2              | 218.60808  |
| training/sac_Q/q2_loss         | 98.68491   |
| training/sac_Q/q_global_norm   | 191.80615  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16424236 |
| epoch                          | 902        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4996.941   |
| evaluation/return-max          | 5082.6294  |
| evaluation/return-min          | 4841.4194  |
| evaluation/return-std          | 87.802895  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46327      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4996.941   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 214.11118  |
| Q-std                          | 102.40867  |
| Q_loss                         | 115.207634 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 902        |
| times/epoch_after_hook         | 3.17e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 533        |
| times/evaluation_metrics       | 0.000517   |
| times/evaluation_paths         | 40.9       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 67.4       |
| timestep                       | 1000       |
| timesteps_total                | 903000     |
| train-steps                    | 903000     |
| training/Q/q1_loss             | 91.22225   |
| training/sac_pi/alpha          | 0.16430393 |
| training/sac_pi/alpha_loss     | -0.5530793 |
| training/sac_pi/logp_pi        | 3.7830803  |
| training/sac_pi/pi_entropy     | 3.3944633  |
| training/sac_pi/pi_global_norm | 1.4711455  |
| training/sac_pi/policy_loss    | -214.5379  |
| training/sac_pi/std            | 0.48917833 |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 207.20676  |
| training/sac_Q/q2              | 207.49124  |
| training/sac_Q/q2_loss         | 91.961     |
| training/sac_Q/q_global_norm   | 153.45949  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17121837 |
| epoch                          | 903        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5245.8447  |
| evaluation/return-max          | 5319.619   |
| evaluation/return-min          | 5183.282   |
| evaluation/return-std          | 42.451084  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46283      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5245.8447  |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 216.97366  |
| Q-std                          | 134.17027  |
| Q_loss                         | 106.656006 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 903        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000116   |
| times/epoch_rollout_model      | 510        |
| times/evaluation_metrics       | 0.000524   |
| times/evaluation_paths         | 43.5       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 64         |
| timestep                       | 1000       |
| timesteps_total                | 904000     |
| train-steps                    | 904000     |
| training/Q/q1_loss             | 94.132965  |
| training/sac_pi/alpha          | 0.17119339 |
| training/sac_pi/alpha_loss     | 0.342479   |
| training/sac_pi/logp_pi        | 4.055787   |
| training/sac_pi/pi_entropy     | 3.5287552  |
| training/sac_pi/pi_global_norm | 1.522642   |
| training/sac_pi/policy_loss    | -220.68575 |
| training/sac_pi/std            | 0.47753614 |
| training/sac_pi/valid_num      | 5000.0     |
| training/sac_Q/q1              | 215.92891  |
| training/sac_Q/q2              | 215.52055  |
| training/sac_Q/q2_loss         | 94.93396   |
| training/sac_Q/q_global_norm   | 237.37167  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1667222  |
| epoch                          | 904        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4909.9116  |
| evaluation/return-max          | 5012.1396  |
| evaluation/return-min          | 4840.6084  |
| evaluation/return-std          | 50.047153  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46192      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4909.9116  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 210.29166  |
| Q-std                          | 147.50516  |
| Q_loss                         | 97.095406  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 904        |
| times/epoch_after_hook         | 2.04e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 512        |
| times/evaluation_metrics       | 0.000517   |
| times/evaluation_paths         | 42.8       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 66         |
| timestep                       | 1000       |
| timesteps_total                | 905000     |
| train-steps                    | 905000     |
| training/Q/q1_loss             | 112.09882  |
| training/sac_pi/alpha          | 0.166668   |
| training/sac_pi/alpha_loss     | 0.44154903 |
| training/sac_pi/logp_pi        | 4.5401316  |
| training/sac_pi/pi_entropy     | 3.3078682  |
| training/sac_pi/pi_global_norm | 1.6770368  |
| training/sac_pi/policy_loss    | -228.32285 |
| training/sac_pi/std            | 0.47760838 |
| training/sac_pi/valid_num      | 5017.0     |
| training/sac_Q/q1              | 223.49011  |
| training/sac_Q/q2              | 222.67952  |
| training/sac_Q/q2_loss         | 113.16475  |
| training/sac_Q/q_global_norm   | 213.75002  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1663183  |
| epoch                          | 905        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4846.3     |
| evaluation/return-max          | 4925.925   |
| evaluation/return-min          | 4704.87    |
| evaluation/return-std          | 56.7864    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46389      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4846.3     |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 212.37549  |
| Q-std                          | 115.44859  |
| Q_loss                         | 107.33562  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 905        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000312   |
| times/epoch_rollout_model      | 520        |
| times/evaluation_metrics       | 0.000535   |
| times/evaluation_paths         | 30.7       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 63.6       |
| timestep                       | 1000       |
| timesteps_total                | 906000     |
| train-steps                    | 906000     |
| training/Q/q1_loss             | 111.48326  |
| training/sac_pi/alpha          | 0.16632678 |
| training/sac_pi/alpha_loss     | 0.2634113  |
| training/sac_pi/logp_pi        | 4.3614645  |
| training/sac_pi/pi_entropy     | 3.439558   |
| training/sac_pi/pi_global_norm | 1.5897725  |
| training/sac_pi/policy_loss    | -213.25336 |
| training/sac_pi/std            | 0.5010324  |
| training/sac_pi/valid_num      | 4922.0     |
| training/sac_Q/q1              | 204.12166  |
| training/sac_Q/q2              | 202.96346  |
| training/sac_Q/q2_loss         | 110.4237   |
| training/sac_Q/q_global_norm   | 206.03886  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1612442   |
| epoch                          | 906         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5001.254    |
| evaluation/return-max          | 5052.1445   |
| evaluation/return-min          | 4781.673    |
| evaluation/return-std          | 75.50671    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46460       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5001.254    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 214.37431   |
| Q-std                          | 105.60806   |
| Q_loss                         | 94.88276    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 906         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 525         |
| times/evaluation_metrics       | 0.000499    |
| times/evaluation_paths         | 40          |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 67.3        |
| timestep                       | 1000        |
| timesteps_total                | 907000      |
| train-steps                    | 907000      |
| training/Q/q1_loss             | 91.44769    |
| training/sac_pi/alpha          | 0.16126142  |
| training/sac_pi/alpha_loss     | -0.10739226 |
| training/sac_pi/logp_pi        | 4.0836663   |
| training/sac_pi/pi_entropy     | 3.2992682   |
| training/sac_pi/pi_global_norm | 1.9048755   |
| training/sac_pi/policy_loss    | -224.11491  |
| training/sac_pi/std            | 0.47575477  |
| training/sac_pi/valid_num      | 4971.0      |
| training/sac_Q/q1              | 214.52596   |
| training/sac_Q/q2              | 215.79907   |
| training/sac_Q/q2_loss         | 91.5862     |
| training/sac_Q/q_global_norm   | 251.919     |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16774398  |
| epoch                          | 907         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5170.8364   |
| evaluation/return-max          | 5224.4043   |
| evaluation/return-min          | 5110.6904   |
| evaluation/return-std          | 32.80092    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46298       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5170.8364   |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 200.50159   |
| Q-std                          | 158.68665   |
| Q_loss                         | 111.3413    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 907         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000113    |
| times/epoch_rollout_model      | 523         |
| times/evaluation_metrics       | 0.000447    |
| times/evaluation_paths         | 39          |
| times/timestep_after_hook      | 0.00402     |
| times/timestep_before_hook     | 0.00809     |
| times/train                    | 68.6        |
| timestep                       | 1000        |
| timesteps_total                | 908000      |
| train-steps                    | 908000      |
| training/Q/q1_loss             | 112.511154  |
| training/sac_pi/alpha          | 0.16775762  |
| training/sac_pi/alpha_loss     | -0.07290374 |
| training/sac_pi/logp_pi        | 4.599391    |
| training/sac_pi/pi_entropy     | 3.4716842   |
| training/sac_pi/pi_global_norm | 1.4944292   |
| training/sac_pi/policy_loss    | -228.96036  |
| training/sac_pi/std            | 0.51585674  |
| training/sac_pi/valid_num      | 4975.0      |
| training/sac_Q/q1              | 216.53027   |
| training/sac_Q/q2              | 216.0553    |
| training/sac_Q/q2_loss         | 113.81035   |
| training/sac_Q/q_global_norm   | 280.6815    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16509782  |
| epoch                          | 908         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5157.4126   |
| evaluation/return-max          | 5277.2134   |
| evaluation/return-min          | 5030.57     |
| evaluation/return-std          | 77.34809    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46173       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5157.4126   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 203.64436   |
| Q-std                          | 142.84012   |
| Q_loss                         | 102.49144   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 908         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 8.36e-05    |
| times/epoch_rollout_model      | 522         |
| times/evaluation_metrics       | 0.000539    |
| times/evaluation_paths         | 36.9        |
| times/timestep_after_hook      | 0.00423     |
| times/timestep_before_hook     | 0.0081      |
| times/train                    | 73.5        |
| timestep                       | 1000        |
| timesteps_total                | 909000      |
| train-steps                    | 909000      |
| training/Q/q1_loss             | 102.6607    |
| training/sac_pi/alpha          | 0.16507328  |
| training/sac_pi/alpha_loss     | -0.15275273 |
| training/sac_pi/logp_pi        | 3.9097729   |
| training/sac_pi/pi_entropy     | 3.2823842   |
| training/sac_pi/pi_global_norm | 2.056787    |
| training/sac_pi/policy_loss    | -235.79048  |
| training/sac_pi/std            | 0.47503957  |
| training/sac_pi/valid_num      | 4969.0      |
| training/sac_Q/q1              | 225.71794   |
| training/sac_Q/q2              | 226.70193   |
| training/sac_Q/q2_loss         | 102.48848   |
| training/sac_Q/q_global_norm   | 184.86273   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16724455 |
| epoch                          | 909        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4922.405   |
| evaluation/return-max          | 4993.4424  |
| evaluation/return-min          | 4857.635   |
| evaluation/return-std          | 38.083385  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46330      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4922.405   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 222.53134  |
| Q-std                          | 118.35514  |
| Q_loss                         | 81.376     |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 909        |
| times/epoch_after_hook         | 3.17e-06   |
| times/epoch_before_hook        | 0.000279   |
| times/epoch_rollout_model      | 516        |
| times/evaluation_metrics       | 0.000534   |
| times/evaluation_paths         | 36.7       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 58.3       |
| timestep                       | 1000       |
| timesteps_total                | 910000     |
| train-steps                    | 910000     |
| training/Q/q1_loss             | 103.110306 |
| training/sac_pi/alpha          | 0.16722839 |
| training/sac_pi/alpha_loss     | 0.10403586 |
| training/sac_pi/logp_pi        | 4.5534544  |
| training/sac_pi/pi_entropy     | 3.422151   |
| training/sac_pi/pi_global_norm | 1.4294348  |
| training/sac_pi/policy_loss    | -218.11232 |
| training/sac_pi/std            | 0.49144655 |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 207.99467  |
| training/sac_Q/q2              | 207.90616  |
| training/sac_Q/q2_loss         | 103.339294 |
| training/sac_Q/q_global_norm   | 208.24765  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16749167  |
| epoch                          | 910         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4919.5605   |
| evaluation/return-max          | 5026.3164   |
| evaluation/return-min          | 4843.1294   |
| evaluation/return-std          | 53.90168    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46321       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4919.5605   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 209.63863   |
| Q-std                          | 160.13782   |
| Q_loss                         | 100.901726  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 910         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 526         |
| times/evaluation_metrics       | 0.000567    |
| times/evaluation_paths         | 36.6        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 74.6        |
| timestep                       | 1000        |
| timesteps_total                | 911000      |
| train-steps                    | 911000      |
| training/Q/q1_loss             | 91.22105    |
| training/sac_pi/alpha          | 0.16751073  |
| training/sac_pi/alpha_loss     | -0.07871657 |
| training/sac_pi/logp_pi        | 4.388789    |
| training/sac_pi/pi_entropy     | 3.464129    |
| training/sac_pi/pi_global_norm | 1.427896    |
| training/sac_pi/policy_loss    | -217.98912  |
| training/sac_pi/std            | 0.4918162   |
| training/sac_pi/valid_num      | 4927.0      |
| training/sac_Q/q1              | 208.76909   |
| training/sac_Q/q2              | 208.32986   |
| training/sac_Q/q2_loss         | 91.68689    |
| training/sac_Q/q_global_norm   | 320.64658   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17414579  |
| epoch                          | 911         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5137.1934   |
| evaluation/return-max          | 5191.485    |
| evaluation/return-min          | 5078.3374   |
| evaluation/return-std          | 30.05119    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 80.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46394       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5137.1934   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 228.89243   |
| Q-std                          | 97.88786    |
| Q_loss                         | 107.56593   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 911         |
| times/epoch_after_hook         | 1.99e-06    |
| times/epoch_before_hook        | 0.000113    |
| times/epoch_rollout_model      | 522         |
| times/evaluation_metrics       | 0.000567    |
| times/evaluation_paths         | 38.2        |
| times/timestep_after_hook      | 0.00409     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 74          |
| timestep                       | 1000        |
| timesteps_total                | 912000      |
| train-steps                    | 912000      |
| training/Q/q1_loss             | 105.1175    |
| training/sac_pi/alpha          | 0.17417327  |
| training/sac_pi/alpha_loss     | -0.36590886 |
| training/sac_pi/logp_pi        | 3.1250718   |
| training/sac_pi/pi_entropy     | 3.591146    |
| training/sac_pi/pi_global_norm | 1.526224    |
| training/sac_pi/policy_loss    | -230.24364  |
| training/sac_pi/std            | 0.46945545  |
| training/sac_pi/valid_num      | 5043.0      |
| training/sac_Q/q1              | 224.89478   |
| training/sac_Q/q2              | 225.69194   |
| training/sac_Q/q2_loss         | 106.5777    |
| training/sac_Q/q_global_norm   | 172.25659   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16997442  |
| epoch                          | 912         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4892.775    |
| evaluation/return-max          | 5026.0527   |
| evaluation/return-min          | 4817.9824   |
| evaluation/return-std          | 55.299744   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46187       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4892.775    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 198.65042   |
| Q-std                          | 161.98862   |
| Q_loss                         | 106.131325  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 912         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000143    |
| times/epoch_rollout_model      | 507         |
| times/evaluation_metrics       | 0.000552    |
| times/evaluation_paths         | 37.4        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 74.3        |
| timestep                       | 1000        |
| timesteps_total                | 913000      |
| train-steps                    | 913000      |
| training/Q/q1_loss             | 96.1202     |
| training/sac_pi/alpha          | 0.16998379  |
| training/sac_pi/alpha_loss     | -0.08455742 |
| training/sac_pi/logp_pi        | 3.4477513   |
| training/sac_pi/pi_entropy     | 3.475795    |
| training/sac_pi/pi_global_norm | 1.4252377   |
| training/sac_pi/policy_loss    | -219.4836   |
| training/sac_pi/std            | 0.46855962  |
| training/sac_pi/valid_num      | 5030.0      |
| training/sac_Q/q1              | 215.32217   |
| training/sac_Q/q2              | 214.70999   |
| training/sac_Q/q2_loss         | 94.807465   |
| training/sac_Q/q_global_norm   | 261.55444   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16910039 |
| epoch                          | 913        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5050.578   |
| evaluation/return-max          | 5079.8877  |
| evaluation/return-min          | 5001.919   |
| evaluation/return-std          | 22.970552  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46269      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5050.578   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 222.25867  |
| Q-std                          | 126.18261  |
| Q_loss                         | 76.70908   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 913        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000268   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000578   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 57.8       |
| timestep                       | 1000       |
| timesteps_total                | 914000     |
| train-steps                    | 914000     |
| training/Q/q1_loss             | 102.64331  |
| training/sac_pi/alpha          | 0.16908278 |
| training/sac_pi/alpha_loss     | 0.4816172  |
| training/sac_pi/logp_pi        | 4.5597715  |
| training/sac_pi/pi_entropy     | 3.4754307  |
| training/sac_pi/pi_global_norm | 1.7816422  |
| training/sac_pi/policy_loss    | -219.62196 |
| training/sac_pi/std            | 0.49381673 |
| training/sac_pi/valid_num      | 4944.0     |
| training/sac_Q/q1              | 207.57951  |
| training/sac_Q/q2              | 209.12057  |
| training/sac_Q/q2_loss         | 104.1775   |
| training/sac_Q/q_global_norm   | 313.78653  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16604628 |
| epoch                          | 914        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5092.5693  |
| evaluation/return-max          | 5111.1978  |
| evaluation/return-min          | 5068.752   |
| evaluation/return-std          | 12.769102  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46145      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5092.5693  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 219.46982  |
| Q-std                          | 95.705215  |
| Q_loss                         | 96.377365  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 914        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 514        |
| times/evaluation_metrics       | 0.000515   |
| times/evaluation_paths         | 40.9       |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.00788    |
| times/train                    | 64.9       |
| timestep                       | 1000       |
| timesteps_total                | 915000     |
| train-steps                    | 915000     |
| training/Q/q1_loss             | 115.734116 |
| training/sac_pi/alpha          | 0.16604604 |
| training/sac_pi/alpha_loss     | 0.19492655 |
| training/sac_pi/logp_pi        | 3.6035461  |
| training/sac_pi/pi_entropy     | 3.413054   |
| training/sac_pi/pi_global_norm | 1.5415637  |
| training/sac_pi/policy_loss    | -225.30144 |
| training/sac_pi/std            | 0.47569996 |
| training/sac_pi/valid_num      | 5006.0     |
| training/sac_Q/q1              | 219.15332  |
| training/sac_Q/q2              | 220.34317  |
| training/sac_Q/q2_loss         | 115.49272  |
| training/sac_Q/q_global_norm   | 248.08673  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1650544  |
| epoch                          | 915        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5065.987   |
| evaluation/return-max          | 5160.9956  |
| evaluation/return-min          | 4977.206   |
| evaluation/return-std          | 53.946983  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46367      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5065.987   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 202.10023  |
| Q-std                          | 186.04007  |
| Q_loss                         | 85.75758   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 915        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000666   |
| times/evaluation_paths         | 42         |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 66.1       |
| timestep                       | 1000       |
| timesteps_total                | 916000     |
| train-steps                    | 916000     |
| training/Q/q1_loss             | 99.61143   |
| training/sac_pi/alpha          | 0.16506326 |
| training/sac_pi/alpha_loss     | 0.31299844 |
| training/sac_pi/logp_pi        | 4.915828   |
| training/sac_pi/pi_entropy     | 3.5052083  |
| training/sac_pi/pi_global_norm | 1.7798163  |
| training/sac_pi/policy_loss    | -214.8359  |
| training/sac_pi/std            | 0.52263045 |
| training/sac_pi/valid_num      | 4927.0     |
| training/sac_Q/q1              | 197.72157  |
| training/sac_Q/q2              | 198.69101  |
| training/sac_Q/q2_loss         | 100.40014  |
| training/sac_Q/q_global_norm   | 207.8842   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17033678   |
| epoch                          | 916          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5030.639     |
| evaluation/return-max          | 5077.3145    |
| evaluation/return-min          | 4974.458     |
| evaluation/return-std          | 30.898964    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.07         |
| model/origin_ret               | 85           |
| model/penalty_ret              | 79.6         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46312        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5030.639     |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 210.38815    |
| Q-std                          | 146.19023    |
| Q_loss                         | 123.3662     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 916          |
| times/epoch_after_hook         | 1.85e-06     |
| times/epoch_before_hook        | 0.000153     |
| times/epoch_rollout_model      | 501          |
| times/evaluation_metrics       | 0.000716     |
| times/evaluation_paths         | 42.3         |
| times/timestep_after_hook      | 0.00393      |
| times/timestep_before_hook     | 0.00804      |
| times/train                    | 67.2         |
| timestep                       | 1000         |
| timesteps_total                | 917000       |
| train-steps                    | 917000       |
| training/Q/q1_loss             | 106.72331    |
| training/sac_pi/alpha          | 0.17034903   |
| training/sac_pi/alpha_loss     | -0.046269946 |
| training/sac_pi/logp_pi        | 4.3175573    |
| training/sac_pi/pi_entropy     | 3.5118318    |
| training/sac_pi/pi_global_norm | 1.6959983    |
| training/sac_pi/policy_loss    | -226.24957   |
| training/sac_pi/std            | 0.5142334    |
| training/sac_pi/valid_num      | 4990.0       |
| training/sac_Q/q1              | 220.34583    |
| training/sac_Q/q2              | 218.23584    |
| training/sac_Q/q2_loss         | 106.430214   |
| training/sac_Q/q_global_norm   | 161.90155    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16712657  |
| epoch                          | 917         |
| evaluation/episode-length-avg  | 927         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 266         |
| evaluation/episode-length-std  | 220         |
| evaluation/return-average      | 4460.4116   |
| evaluation/return-max          | 4933.5537   |
| evaluation/return-min          | 880.8965    |
| evaluation/return-std          | 1194.7578   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46066       |
| perf/AverageLength             | 927         |
| perf/AverageReturn             | 4460.4116   |
| perf/NormalizedReturn          | 0.971       |
| Q-avg                          | 218.82817   |
| Q-std                          | 101.501434  |
| Q_loss                         | 101.905785  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 917         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000323    |
| times/epoch_rollout_model      | 515         |
| times/evaluation_metrics       | 0.000589    |
| times/evaluation_paths         | 30.5        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00802     |
| times/train                    | 58          |
| timestep                       | 1000        |
| timesteps_total                | 918000      |
| train-steps                    | 918000      |
| training/Q/q1_loss             | 85.72138    |
| training/sac_pi/alpha          | 0.1671709   |
| training/sac_pi/alpha_loss     | -0.04623029 |
| training/sac_pi/logp_pi        | 3.9526043   |
| training/sac_pi/pi_entropy     | 3.3278656   |
| training/sac_pi/pi_global_norm | 1.8244983   |
| training/sac_pi/policy_loss    | -224.48637  |
| training/sac_pi/std            | 0.46657637  |
| training/sac_pi/valid_num      | 4999.0      |
| training/sac_Q/q1              | 220.6403    |
| training/sac_Q/q2              | 220.41812   |
| training/sac_Q/q2_loss         | 85.71709    |
| training/sac_Q/q_global_norm   | 162.9145    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17327535 |
| epoch                          | 918        |
| evaluation/episode-length-avg  | 918        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 184        |
| evaluation/episode-length-std  | 245        |
| evaluation/return-average      | 4376.198   |
| evaluation/return-max          | 4906.7344  |
| evaluation/return-min          | 491.87506  |
| evaluation/return-std          | 1296.26    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46324      |
| perf/AverageLength             | 918        |
| perf/AverageReturn             | 4376.198   |
| perf/NormalizedReturn          | 0.953      |
| Q-avg                          | 215.42685  |
| Q-std                          | 120.16212  |
| Q_loss                         | 101.15373  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 918        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 510        |
| times/evaluation_metrics       | 0.000561   |
| times/evaluation_paths         | 37.7       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 67.8       |
| timestep                       | 1000       |
| timesteps_total                | 919000     |
| train-steps                    | 919000     |
| training/Q/q1_loss             | 94.55702   |
| training/sac_pi/alpha          | 0.17326272 |
| training/sac_pi/alpha_loss     | -0.2374942 |
| training/sac_pi/logp_pi        | 4.1119013  |
| training/sac_pi/pi_entropy     | 3.1903887  |
| training/sac_pi/pi_global_norm | 1.733299   |
| training/sac_pi/policy_loss    | -230.3558  |
| training/sac_pi/std            | 0.46301892 |
| training/sac_pi/valid_num      | 4996.0     |
| training/sac_Q/q1              | 217.65157  |
| training/sac_Q/q2              | 220.53445  |
| training/sac_Q/q2_loss         | 93.06248   |
| training/sac_Q/q_global_norm   | 177.59706  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1647176  |
| epoch                          | 919        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4683.3564  |
| evaluation/return-max          | 4791.534   |
| evaluation/return-min          | 4569.24    |
| evaluation/return-std          | 57.808784  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46384      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4683.3564  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 213.55774  |
| Q-std                          | 138.17368  |
| Q_loss                         | 97.73725   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 919        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000717   |
| times/evaluation_paths         | 41.3       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 66         |
| timestep                       | 1000       |
| timesteps_total                | 920000     |
| train-steps                    | 920000     |
| training/Q/q1_loss             | 86.507065  |
| training/sac_pi/alpha          | 0.16474344 |
| training/sac_pi/alpha_loss     | -0.163781  |
| training/sac_pi/logp_pi        | 4.0832047  |
| training/sac_pi/pi_entropy     | 3.219822   |
| training/sac_pi/pi_global_norm | 1.8290584  |
| training/sac_pi/policy_loss    | -225.74086 |
| training/sac_pi/std            | 0.4759092  |
| training/sac_pi/valid_num      | 4962.0     |
| training/sac_Q/q1              | 217.54863  |
| training/sac_Q/q2              | 218.51392  |
| training/sac_Q/q2_loss         | 87.60287   |
| training/sac_Q/q_global_norm   | 231.14496  |
--------------------------------------------------------------------------------
[WARN] 920 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16844808 |
| epoch                          | 920        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5006.773   |
| evaluation/return-max          | 5045.1094  |
| evaluation/return-min          | 4972.7705  |
| evaluation/return-std          | 23.80134   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46270      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5006.773   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 210.35115  |
| Q-std                          | 115.42131  |
| Q_loss                         | 91.93578   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 920        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000511   |
| times/evaluation_paths         | 40.1       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 67.7       |
| timestep                       | 1000       |
| timesteps_total                | 921000     |
| train-steps                    | 921000     |
| training/Q/q1_loss             | 85.09246   |
| training/sac_pi/alpha          | 0.16842292 |
| training/sac_pi/alpha_loss     | 0.30276662 |
| training/sac_pi/logp_pi        | 4.265732   |
| training/sac_pi/pi_entropy     | 3.535768   |
| training/sac_pi/pi_global_norm | 1.94758    |
| training/sac_pi/policy_loss    | -224.88951 |
| training/sac_pi/std            | 0.4970024  |
| training/sac_pi/valid_num      | 5003.0     |
| training/sac_Q/q1              | 215.55669  |
| training/sac_Q/q2              | 215.606    |
| training/sac_Q/q2_loss         | 85.02355   |
| training/sac_Q/q_global_norm   | 402.79807  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16643846 |
| epoch                          | 921        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4831.525   |
| evaluation/return-max          | 4940.9004  |
| evaluation/return-min          | 4735.8022  |
| evaluation/return-std          | 61.317204  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46400      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4831.525   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 209.654    |
| Q-std                          | 122.18308  |
| Q_loss                         | 113.93278  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 921        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000308   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000583   |
| times/evaluation_paths         | 33.4       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 58.3       |
| timestep                       | 1000       |
| timesteps_total                | 922000     |
| train-steps                    | 922000     |
| training/Q/q1_loss             | 93.50993   |
| training/sac_pi/alpha          | 0.16641676 |
| training/sac_pi/alpha_loss     | 0.06787859 |
| training/sac_pi/logp_pi        | 4.3868217  |
| training/sac_pi/pi_entropy     | 3.5412807  |
| training/sac_pi/pi_global_norm | 1.6197277  |
| training/sac_pi/policy_loss    | -216.25748 |
| training/sac_pi/std            | 0.51410985 |
| training/sac_pi/valid_num      | 4998.0     |
| training/sac_Q/q1              | 208.79788  |
| training/sac_Q/q2              | 208.6027   |
| training/sac_Q/q2_loss         | 93.24043   |
| training/sac_Q/q_global_norm   | 217.74626  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16386056 |
| epoch                          | 922        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5218.6743  |
| evaluation/return-max          | 5283.4287  |
| evaluation/return-min          | 5188.6055  |
| evaluation/return-std          | 24.053581  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46317      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5218.6743  |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 220.6853   |
| Q-std                          | 114.13512  |
| Q_loss                         | 76.458664  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 922        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000519   |
| times/evaluation_paths         | 43.1       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 65.6       |
| timestep                       | 1000       |
| timesteps_total                | 923000     |
| train-steps                    | 923000     |
| training/Q/q1_loss             | 80.74392   |
| training/sac_pi/alpha          | 0.16388078 |
| training/sac_pi/alpha_loss     | -0.3317744 |
| training/sac_pi/logp_pi        | 4.675561   |
| training/sac_pi/pi_entropy     | 3.430156   |
| training/sac_pi/pi_global_norm | 1.4801843  |
| training/sac_pi/policy_loss    | -224.76523 |
| training/sac_pi/std            | 0.5083154  |
| training/sac_pi/valid_num      | 4902.0     |
| training/sac_Q/q1              | 211.1698   |
| training/sac_Q/q2              | 212.1489   |
| training/sac_Q/q2_loss         | 80.878334  |
| training/sac_Q/q_global_norm   | 197.96628  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16524142 |
| epoch                          | 923        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4890.9956  |
| evaluation/return-max          | 4907.26    |
| evaluation/return-min          | 4873.212   |
| evaluation/return-std          | 10.3171425 |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46290      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4890.9956  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 220.94507  |
| Q-std                          | 117.41924  |
| Q_loss                         | 105.5423   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 923        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000616   |
| times/evaluation_paths         | 39.2       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 70.3       |
| timestep                       | 1000       |
| timesteps_total                | 924000     |
| train-steps                    | 924000     |
| training/Q/q1_loss             | 91.24297   |
| training/sac_pi/alpha          | 0.1652173  |
| training/sac_pi/alpha_loss     | 0.25378332 |
| training/sac_pi/logp_pi        | 4.0978928  |
| training/sac_pi/pi_entropy     | 3.3934693  |
| training/sac_pi/pi_global_norm | 1.6269989  |
| training/sac_pi/policy_loss    | -226.72762 |
| training/sac_pi/std            | 0.4753912  |
| training/sac_pi/valid_num      | 5005.0     |
| training/sac_Q/q1              | 219.69687  |
| training/sac_Q/q2              | 219.87915  |
| training/sac_Q/q2_loss         | 91.614685  |
| training/sac_Q/q_global_norm   | 241.57289  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16451219 |
| epoch                          | 924        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5018.5293  |
| evaluation/return-max          | 5106.5903  |
| evaluation/return-min          | 4960.0806  |
| evaluation/return-std          | 41.1647    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46355      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5018.5293  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 221.74814  |
| Q-std                          | 103.59854  |
| Q_loss                         | 90.35961   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 924        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000154   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.00052    |
| times/evaluation_paths         | 39.1       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 71.7       |
| timestep                       | 1000       |
| timesteps_total                | 925000     |
| train-steps                    | 925000     |
| training/Q/q1_loss             | 84.7102    |
| training/sac_pi/alpha          | 0.16448879 |
| training/sac_pi/alpha_loss     | 0.22476193 |
| training/sac_pi/logp_pi        | 4.843172   |
| training/sac_pi/pi_entropy     | 3.3753674  |
| training/sac_pi/pi_global_norm | 2.0221062  |
| training/sac_pi/policy_loss    | -229.20665 |
| training/sac_pi/std            | 0.5057003  |
| training/sac_pi/valid_num      | 4896.0     |
| training/sac_Q/q1              | 212.9771   |
| training/sac_Q/q2              | 214.26343  |
| training/sac_Q/q2_loss         | 85.89342   |
| training/sac_Q/q_global_norm   | 169.07028  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16420968 |
| epoch                          | 925        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5152.313   |
| evaluation/return-max          | 5183.718   |
| evaluation/return-min          | 5091.7437  |
| evaluation/return-std          | 26.834389  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46332      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5152.313   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 213.8378   |
| Q-std                          | 101.78867  |
| Q_loss                         | 94.720345  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 925        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000307   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000565   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 57.2       |
| timestep                       | 1000       |
| timesteps_total                | 926000     |
| train-steps                    | 926000     |
| training/Q/q1_loss             | 92.954735  |
| training/sac_pi/alpha          | 0.1641723  |
| training/sac_pi/alpha_loss     | 0.18670484 |
| training/sac_pi/logp_pi        | 4.8037214  |
| training/sac_pi/pi_entropy     | 3.3120155  |
| training/sac_pi/pi_global_norm | 1.732266   |
| training/sac_pi/policy_loss    | -218.37686 |
| training/sac_pi/std            | 0.4889679  |
| training/sac_pi/valid_num      | 4921.0     |
| training/sac_Q/q1              | 201.16403  |
| training/sac_Q/q2              | 204.05405  |
| training/sac_Q/q2_loss         | 93.004036  |
| training/sac_Q/q_global_norm   | 180.61667  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16367014  |
| epoch                          | 926         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4891.002    |
| evaluation/return-max          | 4916.745    |
| evaluation/return-min          | 4840.41     |
| evaluation/return-std          | 28.835606   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46337       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4891.002    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 214.61145   |
| Q-std                          | 106.08173   |
| Q_loss                         | 111.61524   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 926         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000528    |
| times/evaluation_paths         | 37.3        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.00799     |
| times/train                    | 71.7        |
| timestep                       | 1000        |
| timesteps_total                | 927000      |
| train-steps                    | 927000      |
| training/Q/q1_loss             | 113.32653   |
| training/sac_pi/alpha          | 0.16371123  |
| training/sac_pi/alpha_loss     | -0.07150842 |
| training/sac_pi/logp_pi        | 5.547957    |
| training/sac_pi/pi_entropy     | 3.3783145   |
| training/sac_pi/pi_global_norm | 1.6513383   |
| training/sac_pi/policy_loss    | -211.26004  |
| training/sac_pi/std            | 0.5278256   |
| training/sac_pi/valid_num      | 4892.0      |
| training/sac_Q/q1              | 197.17435   |
| training/sac_Q/q2              | 196.77855   |
| training/sac_Q/q2_loss         | 112.45138   |
| training/sac_Q/q_global_norm   | 244.93172   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17013331 |
| epoch                          | 927        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4828.3364  |
| evaluation/return-max          | 4888.82    |
| evaluation/return-min          | 4763.366   |
| evaluation/return-std          | 34.302483  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46241      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4828.3364  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 206.70674  |
| Q-std                          | 147.27702  |
| Q_loss                         | 94.05877   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 927        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000142   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000605   |
| times/evaluation_paths         | 37.6       |
| times/timestep_after_hook      | 0.00397    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 73.1       |
| timestep                       | 1000       |
| timesteps_total                | 928000     |
| train-steps                    | 928000     |
| training/Q/q1_loss             | 113.47851  |
| training/sac_pi/alpha          | 0.17014892 |
| training/sac_pi/alpha_loss     | 0.33154836 |
| training/sac_pi/logp_pi        | 4.5641794  |
| training/sac_pi/pi_entropy     | 3.597824   |
| training/sac_pi/pi_global_norm | 1.3917127  |
| training/sac_pi/policy_loss    | -217.45624 |
| training/sac_pi/std            | 0.5209646  |
| training/sac_pi/valid_num      | 4990.0     |
| training/sac_Q/q1              | 206.09013  |
| training/sac_Q/q2              | 208.80673  |
| training/sac_Q/q2_loss         | 113.05547  |
| training/sac_Q/q_global_norm   | 312.4084   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16384657  |
| epoch                          | 928         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4944.671    |
| evaluation/return-max          | 5010.9033   |
| evaluation/return-min          | 4913.0645   |
| evaluation/return-std          | 27.25818    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46280       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4944.671    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 214.30371   |
| Q-std                          | 128.2723    |
| Q_loss                         | 109.13928   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 928         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000116    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000521    |
| times/evaluation_paths         | 36.5        |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 72.2        |
| timestep                       | 1000        |
| timesteps_total                | 929000      |
| train-steps                    | 929000      |
| training/Q/q1_loss             | 93.364555   |
| training/sac_pi/alpha          | 0.16382313  |
| training/sac_pi/alpha_loss     | 0.044620283 |
| training/sac_pi/logp_pi        | 4.5921445   |
| training/sac_pi/pi_entropy     | 3.4113204   |
| training/sac_pi/pi_global_norm | 1.7317662   |
| training/sac_pi/policy_loss    | -225.4624   |
| training/sac_pi/std            | 0.5103547   |
| training/sac_pi/valid_num      | 4961.0      |
| training/sac_Q/q1              | 214.25835   |
| training/sac_Q/q2              | 215.03458   |
| training/sac_Q/q2_loss         | 91.99502    |
| training/sac_Q/q_global_norm   | 220.30122   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16215537 |
| epoch                          | 929        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5030.042   |
| evaluation/return-max          | 5070.9297  |
| evaluation/return-min          | 4935.713   |
| evaluation/return-std          | 38.026665  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46394      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5030.042   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 227.75737  |
| Q-std                          | 112.954094 |
| Q_loss                         | 112.63628  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 929        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000266   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000495   |
| times/evaluation_paths         | 32.3       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00809    |
| times/train                    | 58.4       |
| timestep                       | 1000       |
| timesteps_total                | 930000     |
| train-steps                    | 930000     |
| training/Q/q1_loss             | 109.20487  |
| training/sac_pi/alpha          | 0.16216367 |
| training/sac_pi/alpha_loss     | 0.48922044 |
| training/sac_pi/logp_pi        | 3.9491546  |
| training/sac_pi/pi_entropy     | 3.2187138  |
| training/sac_pi/pi_global_norm | 1.4892305  |
| training/sac_pi/policy_loss    | -233.83623 |
| training/sac_pi/std            | 0.4609006  |
| training/sac_pi/valid_num      | 5019.0     |
| training/sac_Q/q1              | 228.00528  |
| training/sac_Q/q2              | 228.7445   |
| training/sac_Q/q2_loss         | 108.9113   |
| training/sac_Q/q_global_norm   | 205.7472   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16607852 |
| epoch                          | 930        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5159.549   |
| evaluation/return-max          | 5200.847   |
| evaluation/return-min          | 5120.063   |
| evaluation/return-std          | 25.358047  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46437      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5159.549   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 211.4941   |
| Q-std                          | 139.50833  |
| Q_loss                         | 87.00253   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 930        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000118   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000535   |
| times/evaluation_paths         | 43.5       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 63.8       |
| timestep                       | 1000       |
| timesteps_total                | 931000     |
| train-steps                    | 931000     |
| training/Q/q1_loss             | 116.03165  |
| training/sac_pi/alpha          | 0.16605477 |
| training/sac_pi/alpha_loss     | 0.3122336  |
| training/sac_pi/logp_pi        | 4.582981   |
| training/sac_pi/pi_entropy     | 3.2992713  |
| training/sac_pi/pi_global_norm | 1.7832745  |
| training/sac_pi/policy_loss    | -222.7343  |
| training/sac_pi/std            | 0.49349073 |
| training/sac_pi/valid_num      | 4999.0     |
| training/sac_Q/q1              | 211.7377   |
| training/sac_Q/q2              | 213.70781  |
| training/sac_Q/q2_loss         | 116.79774  |
| training/sac_Q/q_global_norm   | 206.97456  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16238143 |
| epoch                          | 931        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5124.84    |
| evaluation/return-max          | 5201.368   |
| evaluation/return-min          | 5036.6826  |
| evaluation/return-std          | 51.57525   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46310      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5124.84    |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 212.22641  |
| Q-std                          | 142.1955   |
| Q_loss                         | 128.96515  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 931        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000499   |
| times/evaluation_paths         | 43         |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 64.3       |
| timestep                       | 1000       |
| timesteps_total                | 932000     |
| train-steps                    | 932000     |
| training/Q/q1_loss             | 105.333466 |
| training/sac_pi/alpha          | 0.16234784 |
| training/sac_pi/alpha_loss     | 0.01093642 |
| training/sac_pi/logp_pi        | 3.7341716  |
| training/sac_pi/pi_entropy     | 3.3300147  |
| training/sac_pi/pi_global_norm | 1.985355   |
| training/sac_pi/policy_loss    | -222.54614 |
| training/sac_pi/std            | 0.46577132 |
| training/sac_pi/valid_num      | 5038.0     |
| training/sac_Q/q1              | 218.73885  |
| training/sac_Q/q2              | 219.0332   |
| training/sac_Q/q2_loss         | 105.95301  |
| training/sac_Q/q_global_norm   | 169.49426  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16109176 |
| epoch                          | 932        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5118.5986  |
| evaluation/return-max          | 5171.2217  |
| evaluation/return-min          | 5043.7812  |
| evaluation/return-std          | 42.4312    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46350      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5118.5986  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 216.48642  |
| Q-std                          | 112.98205  |
| Q_loss                         | 121.09449  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 932        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000542   |
| times/evaluation_paths         | 44.1       |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 64.3       |
| timestep                       | 1000       |
| timesteps_total                | 933000     |
| train-steps                    | 933000     |
| training/Q/q1_loss             | 112.94927  |
| training/sac_pi/alpha          | 0.16111813 |
| training/sac_pi/alpha_loss     | 0.153482   |
| training/sac_pi/logp_pi        | 4.496893   |
| training/sac_pi/pi_entropy     | 3.1831422  |
| training/sac_pi/pi_global_norm | 2.1255069  |
| training/sac_pi/policy_loss    | -233.33981 |
| training/sac_pi/std            | 0.470009   |
| training/sac_pi/valid_num      | 4949.0     |
| training/sac_Q/q1              | 223.08708  |
| training/sac_Q/q2              | 223.27934  |
| training/sac_Q/q2_loss         | 112.35545  |
| training/sac_Q/q_global_norm   | 219.17065  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16640687  |
| epoch                          | 933         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4953.2495   |
| evaluation/return-max          | 4996.0986   |
| evaluation/return-min          | 4919.788    |
| evaluation/return-std          | 21.521603   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46123       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4953.2495   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 206.18326   |
| Q-std                          | 161.73279   |
| Q_loss                         | 119.50009   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 933         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.00028     |
| times/epoch_rollout_model      | 511         |
| times/evaluation_metrics       | 0.000556    |
| times/evaluation_paths         | 32.3        |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 62          |
| timestep                       | 1000        |
| timesteps_total                | 934000      |
| train-steps                    | 934000      |
| training/Q/q1_loss             | 101.08239   |
| training/sac_pi/alpha          | 0.16641355  |
| training/sac_pi/alpha_loss     | -0.14482893 |
| training/sac_pi/logp_pi        | 4.4335403   |
| training/sac_pi/pi_entropy     | 3.403895    |
| training/sac_pi/pi_global_norm | 1.7002242   |
| training/sac_pi/policy_loss    | -220.50536  |
| training/sac_pi/std            | 0.49020875  |
| training/sac_pi/valid_num      | 4898.0      |
| training/sac_Q/q1              | 206.0026    |
| training/sac_Q/q2              | 206.19365   |
| training/sac_Q/q2_loss         | 101.60581   |
| training/sac_Q/q_global_norm   | 203.03465   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1642126    |
| epoch                          | 934          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5487.4053    |
| evaluation/return-max          | 5532.8584    |
| evaluation/return-min          | 5451.5073    |
| evaluation/return-std          | 25.29881     |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.01         |
| model/origin_ret               | 84.4         |
| model/penalty_ret              | 80.2         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46237        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5487.4053    |
| perf/NormalizedReturn          | 1.19         |
| Q-avg                          | 211.01521    |
| Q-std                          | 154.47717    |
| Q_loss                         | 107.59813    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 934          |
| times/epoch_after_hook         | 1.91e-06     |
| times/epoch_before_hook        | 0.000134     |
| times/epoch_rollout_model      | 510          |
| times/evaluation_metrics       | 0.000638     |
| times/evaluation_paths         | 40.2         |
| times/timestep_after_hook      | 0.00386      |
| times/timestep_before_hook     | 0.00813      |
| times/train                    | 69.3         |
| timestep                       | 1000         |
| timesteps_total                | 935000       |
| train-steps                    | 935000       |
| training/Q/q1_loss             | 105.36923    |
| training/sac_pi/alpha          | 0.16424528   |
| training/sac_pi/alpha_loss     | -0.019709976 |
| training/sac_pi/logp_pi        | 4.471347     |
| training/sac_pi/pi_entropy     | 3.5593948    |
| training/sac_pi/pi_global_norm | 2.4449086    |
| training/sac_pi/policy_loss    | -223.07819   |
| training/sac_pi/std            | 0.5185523    |
| training/sac_pi/valid_num      | 4937.0       |
| training/sac_Q/q1              | 212.56148    |
| training/sac_Q/q2              | 210.96957    |
| training/sac_Q/q2_loss         | 106.49756    |
| training/sac_Q/q_global_norm   | 232.72806    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17272961 |
| epoch                          | 935        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5061.1055  |
| evaluation/return-max          | 5101.531   |
| evaluation/return-min          | 5024.448   |
| evaluation/return-std          | 24.66168   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46195      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5061.1055  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 214.02185  |
| Q-std                          | 144.23064  |
| Q_loss                         | 101.9553   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 935        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 508        |
| times/evaluation_metrics       | 0.000518   |
| times/evaluation_paths         | 37.7       |
| times/timestep_after_hook      | 0.00401    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 74         |
| timestep                       | 1000       |
| timesteps_total                | 936000     |
| train-steps                    | 936000     |
| training/Q/q1_loss             | 86.69217   |
| training/sac_pi/alpha          | 0.17277475 |
| training/sac_pi/alpha_loss     | -0.3045825 |
| training/sac_pi/logp_pi        | 4.207738   |
| training/sac_pi/pi_entropy     | 3.6722667  |
| training/sac_pi/pi_global_norm | 1.5697241  |
| training/sac_pi/policy_loss    | -227.30841 |
| training/sac_pi/std            | 0.525357   |
| training/sac_pi/valid_num      | 4974.0     |
| training/sac_Q/q1              | 215.2909   |
| training/sac_Q/q2              | 216.87712  |
| training/sac_Q/q2_loss         | 85.54363   |
| training/sac_Q/q_global_norm   | 202.88936  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17195301 |
| epoch                          | 936        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4935.2725  |
| evaluation/return-max          | 5011.375   |
| evaluation/return-min          | 4874.1353  |
| evaluation/return-std          | 42.244198  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46360      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4935.2725  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 208.77505  |
| Q-std                          | 143.62453  |
| Q_loss                         | 94.02001   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 936        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000581   |
| times/evaluation_paths         | 38.1       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 71.4       |
| timestep                       | 1000       |
| timesteps_total                | 937000     |
| train-steps                    | 937000     |
| training/Q/q1_loss             | 88.36267   |
| training/sac_pi/alpha          | 0.17199354 |
| training/sac_pi/alpha_loss     | -0.144014  |
| training/sac_pi/logp_pi        | 3.5576692  |
| training/sac_pi/pi_entropy     | 3.4423416  |
| training/sac_pi/pi_global_norm | 2.4833062  |
| training/sac_pi/policy_loss    | -230.87503 |
| training/sac_pi/std            | 0.47620603 |
| training/sac_pi/valid_num      | 5041.0     |
| training/sac_Q/q1              | 227.33337  |
| training/sac_Q/q2              | 227.98528  |
| training/sac_Q/q2_loss         | 89.38425   |
| training/sac_Q/q_global_norm   | 264.58926  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1690987  |
| epoch                          | 937        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5018.251   |
| evaluation/return-max          | 5202.082   |
| evaluation/return-min          | 4927.6064  |
| evaluation/return-std          | 87.86497   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46341      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5018.251   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 215.35225  |
| Q-std                          | 111.41203  |
| Q_loss                         | 99.12491   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 937        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000353   |
| times/epoch_rollout_model      | 506        |
| times/evaluation_metrics       | 0.000582   |
| times/evaluation_paths         | 37.3       |
| times/timestep_after_hook      | 0.00387    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 56.8       |
| timestep                       | 1000       |
| timesteps_total                | 938000     |
| train-steps                    | 938000     |
| training/Q/q1_loss             | 121.33359  |
| training/sac_pi/alpha          | 0.16909723 |
| training/sac_pi/alpha_loss     | 0.13029338 |
| training/sac_pi/logp_pi        | 4.5300016  |
| training/sac_pi/pi_entropy     | 3.5786674  |
| training/sac_pi/pi_global_norm | 1.520629   |
| training/sac_pi/policy_loss    | -219.90164 |
| training/sac_pi/std            | 0.52337754 |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 208.27652  |
| training/sac_Q/q2              | 210.62009  |
| training/sac_Q/q2_loss         | 122.50002  |
| training/sac_Q/q_global_norm   | 237.86818  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17531237 |
| epoch                          | 938        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4969.909   |
| evaluation/return-max          | 5197.0444  |
| evaluation/return-min          | 4869.933   |
| evaluation/return-std          | 84.58214   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46307      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4969.909   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 198.26485  |
| Q-std                          | 153.53416  |
| Q_loss                         | 117.060905 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 938        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000635   |
| times/evaluation_paths         | 37.3       |
| times/timestep_after_hook      | 0.00403    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 72.5       |
| timestep                       | 1000       |
| timesteps_total                | 939000     |
| train-steps                    | 939000     |
| training/Q/q1_loss             | 110.782776 |
| training/sac_pi/alpha          | 0.17532769 |
| training/sac_pi/alpha_loss     | 0.1643306  |
| training/sac_pi/logp_pi        | 4.3665805  |
| training/sac_pi/pi_entropy     | 3.5466888  |
| training/sac_pi/pi_global_norm | 1.816512   |
| training/sac_pi/policy_loss    | -214.72865 |
| training/sac_pi/std            | 0.4999695  |
| training/sac_pi/valid_num      | 4979.0     |
| training/sac_Q/q1              | 205.49374  |
| training/sac_Q/q2              | 206.45708  |
| training/sac_Q/q2_loss         | 110.07866  |
| training/sac_Q/q_global_norm   | 184.98839  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16635655  |
| epoch                          | 939         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4992.6978   |
| evaluation/return-max          | 5055.3613   |
| evaluation/return-min          | 4917.214    |
| evaluation/return-std          | 42.434574   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46265       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4992.6978   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 216.23164   |
| Q-std                          | 130.95056   |
| Q_loss                         | 88.36673    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 939         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000506    |
| times/evaluation_paths         | 36.6        |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 73.8        |
| timestep                       | 1000        |
| timesteps_total                | 940000      |
| train-steps                    | 940000      |
| training/Q/q1_loss             | 107.94917   |
| training/sac_pi/alpha          | 0.16634281  |
| training/sac_pi/alpha_loss     | -0.06357846 |
| training/sac_pi/logp_pi        | 4.5174265   |
| training/sac_pi/pi_entropy     | 3.2780623   |
| training/sac_pi/pi_global_norm | 1.653907    |
| training/sac_pi/policy_loss    | -222.85191  |
| training/sac_pi/std            | 0.47554997  |
| training/sac_pi/valid_num      | 4906.0      |
| training/sac_Q/q1              | 212.21558   |
| training/sac_Q/q2              | 212.20407   |
| training/sac_Q/q2_loss         | 107.799416  |
| training/sac_Q/q_global_norm   | 283.04083   |
---------------------------------------------------------------------------------
[WARN] 940 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.1659637  |
| epoch                          | 940        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4792.4214  |
| evaluation/return-max          | 4961.0806  |
| evaluation/return-min          | 4718.2812  |
| evaluation/return-std          | 88.78631   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46286      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4792.4214  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 224.27493  |
| Q-std                          | 115.86872  |
| Q_loss                         | 94.00022   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 940        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.00014    |
| times/epoch_rollout_model      | 509        |
| times/evaluation_metrics       | 0.000532   |
| times/evaluation_paths         | 37.4       |
| times/timestep_after_hook      | 0.00398    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 73.7       |
| timestep                       | 1000       |
| timesteps_total                | 941000     |
| train-steps                    | 941000     |
| training/Q/q1_loss             | 89.70749   |
| training/sac_pi/alpha          | 0.16597979 |
| training/sac_pi/alpha_loss     | -0.4019193 |
| training/sac_pi/logp_pi        | 3.3681731  |
| training/sac_pi/pi_entropy     | 3.511095   |
| training/sac_pi/pi_global_norm | 1.5188853  |
| training/sac_pi/policy_loss    | -232.2291  |
| training/sac_pi/std            | 0.47556165 |
| training/sac_pi/valid_num      | 4988.0     |
| training/sac_Q/q1              | 226.06094  |
| training/sac_Q/q2              | 225.79024  |
| training/sac_Q/q2_loss         | 89.80373   |
| training/sac_Q/q_global_norm   | 250.57855  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1652583  |
| epoch                          | 941        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5216.9863  |
| evaluation/return-max          | 5238.065   |
| evaluation/return-min          | 5201.365   |
| evaluation/return-std          | 11.902681  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46332      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5216.9863  |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 213.31543  |
| Q-std                          | 116.941154 |
| Q_loss                         | 108.83233  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 941        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000278   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.000519   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 57.7       |
| timestep                       | 1000       |
| timesteps_total                | 942000     |
| train-steps                    | 942000     |
| training/Q/q1_loss             | 102.26669  |
| training/sac_pi/alpha          | 0.16524762 |
| training/sac_pi/alpha_loss     | 0.45017466 |
| training/sac_pi/logp_pi        | 4.2040834  |
| training/sac_pi/pi_entropy     | 3.3223472  |
| training/sac_pi/pi_global_norm | 1.6548793  |
| training/sac_pi/policy_loss    | -223.30296 |
| training/sac_pi/std            | 0.4785443  |
| training/sac_pi/valid_num      | 5015.0     |
| training/sac_Q/q1              | 212.66533  |
| training/sac_Q/q2              | 213.54663  |
| training/sac_Q/q2_loss         | 100.59166  |
| training/sac_Q/q_global_norm   | 258.40527  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1632475  |
| epoch                          | 942        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4795.298   |
| evaluation/return-max          | 4883.249   |
| evaluation/return-min          | 4712.87    |
| evaluation/return-std          | 49.628235  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46347      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4795.298   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 218.41777  |
| Q-std                          | 148.11835  |
| Q_loss                         | 107.67283  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 942        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 509        |
| times/evaluation_metrics       | 0.000597   |
| times/evaluation_paths         | 38.9       |
| times/timestep_after_hook      | 0.013      |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 74.9       |
| timestep                       | 1000       |
| timesteps_total                | 943000     |
| train-steps                    | 943000     |
| training/Q/q1_loss             | 91.40054   |
| training/sac_pi/alpha          | 0.16324347 |
| training/sac_pi/alpha_loss     | 0.07460493 |
| training/sac_pi/logp_pi        | 4.068943   |
| training/sac_pi/pi_entropy     | 3.4074612  |
| training/sac_pi/pi_global_norm | 1.5570549  |
| training/sac_pi/policy_loss    | -220.98444 |
| training/sac_pi/std            | 0.47894126 |
| training/sac_pi/valid_num      | 5013.0     |
| training/sac_Q/q1              | 214.46904  |
| training/sac_Q/q2              | 214.89026  |
| training/sac_Q/q2_loss         | 91.36289   |
| training/sac_Q/q_global_norm   | 195.00703  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16805603  |
| epoch                          | 943         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5079.905    |
| evaluation/return-max          | 5186.514    |
| evaluation/return-min          | 4957.1113   |
| evaluation/return-std          | 60.997562   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46357       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5079.905    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 213.98294   |
| Q-std                          | 137.07108   |
| Q_loss                         | 87.675255   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 943         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.00012     |
| times/epoch_rollout_model      | 511         |
| times/evaluation_metrics       | 0.000516    |
| times/evaluation_paths         | 37.2        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 74.7        |
| timestep                       | 1000        |
| timesteps_total                | 944000      |
| train-steps                    | 944000      |
| training/Q/q1_loss             | 91.46369    |
| training/sac_pi/alpha          | 0.16810411  |
| training/sac_pi/alpha_loss     | -0.42913055 |
| training/sac_pi/logp_pi        | 4.193527    |
| training/sac_pi/pi_entropy     | 3.5874372   |
| training/sac_pi/pi_global_norm | 1.5811558   |
| training/sac_pi/policy_loss    | -228.52638  |
| training/sac_pi/std            | 0.51247984  |
| training/sac_pi/valid_num      | 4952.0      |
| training/sac_Q/q1              | 218.087     |
| training/sac_Q/q2              | 218.42935   |
| training/sac_Q/q2_loss         | 91.517075   |
| training/sac_Q/q_global_norm   | 215.22762   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1683936  |
| epoch                          | 944        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4818.264   |
| evaluation/return-max          | 4933.632   |
| evaluation/return-min          | 4739.966   |
| evaluation/return-std          | 52.7151    |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46382      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4818.264   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 221.89731  |
| Q-std                          | 102.10432  |
| Q_loss                         | 100.21844  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 944        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000117   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.00054    |
| times/evaluation_paths         | 37.7       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 73.6       |
| timestep                       | 1000       |
| timesteps_total                | 945000     |
| train-steps                    | 945000     |
| training/Q/q1_loss             | 92.066635  |
| training/sac_pi/alpha          | 0.16840898 |
| training/sac_pi/alpha_loss     | -0.2902494 |
| training/sac_pi/logp_pi        | 4.2417665  |
| training/sac_pi/pi_entropy     | 3.6563034  |
| training/sac_pi/pi_global_norm | 1.7426625  |
| training/sac_pi/policy_loss    | -216.83458 |
| training/sac_pi/std            | 0.5163433  |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 198.209    |
| training/sac_Q/q2              | 200.8723   |
| training/sac_Q/q2_loss         | 91.3127    |
| training/sac_Q/q_global_norm   | 280.7189   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16485295 |
| epoch                          | 945        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4951.7783  |
| evaluation/return-max          | 5034.8027  |
| evaluation/return-min          | 4888.5435  |
| evaluation/return-std          | 49.524445  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46450      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4951.7783  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 221.23303  |
| Q-std                          | 118.89349  |
| Q_loss                         | 95.441414  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 945        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000313   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000588   |
| times/evaluation_paths         | 37         |
| times/timestep_after_hook      | 0.00398    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 58.7       |
| timestep                       | 1000       |
| timesteps_total                | 946000     |
| train-steps                    | 946000     |
| training/Q/q1_loss             | 96.99621   |
| training/sac_pi/alpha          | 0.16486982 |
| training/sac_pi/alpha_loss     | -0.0860458 |
| training/sac_pi/logp_pi        | 4.0790877  |
| training/sac_pi/pi_entropy     | 3.5113792  |
| training/sac_pi/pi_global_norm | 1.734595   |
| training/sac_pi/policy_loss    | -219.94908 |
| training/sac_pi/std            | 0.4917429  |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 211.46333  |
| training/sac_Q/q2              | 211.6261   |
| training/sac_Q/q2_loss         | 98.14053   |
| training/sac_Q/q_global_norm   | 227.2823   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16730909 |
| epoch                          | 946        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4889.1045  |
| evaluation/return-max          | 4956.934   |
| evaluation/return-min          | 4850.6416  |
| evaluation/return-std          | 32.641285  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 87.1       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46239      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4889.1045  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 208.94193  |
| Q-std                          | 133.36852  |
| Q_loss                         | 96.074104  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 946        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000152   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000535   |
| times/evaluation_paths         | 40.2       |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 73.4       |
| timestep                       | 1000       |
| timesteps_total                | 947000     |
| train-steps                    | 947000     |
| training/Q/q1_loss             | 92.223526  |
| training/sac_pi/alpha          | 0.1672986  |
| training/sac_pi/alpha_loss     | 0.09917895 |
| training/sac_pi/logp_pi        | 4.454567   |
| training/sac_pi/pi_entropy     | 3.4274783  |
| training/sac_pi/pi_global_norm | 1.4159443  |
| training/sac_pi/policy_loss    | -229.8413  |
| training/sac_pi/std            | 0.49201533 |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 218.78047  |
| training/sac_Q/q2              | 219.5483   |
| training/sac_Q/q2_loss         | 90.27862   |
| training/sac_Q/q_global_norm   | 211.28053  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1657664   |
| epoch                          | 947         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4945.846    |
| evaluation/return-max          | 5046.825    |
| evaluation/return-min          | 4842.1016   |
| evaluation/return-std          | 65.07655    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46290       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4945.846    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 221.29964   |
| Q-std                          | 110.94305   |
| Q_loss                         | 96.640274   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 947         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000139    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000545    |
| times/evaluation_paths         | 36.8        |
| times/timestep_after_hook      | 0.0041      |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 75.2        |
| timestep                       | 1000        |
| timesteps_total                | 948000      |
| train-steps                    | 948000      |
| training/Q/q1_loss             | 101.663605  |
| training/sac_pi/alpha          | 0.1657801   |
| training/sac_pi/alpha_loss     | 0.013403927 |
| training/sac_pi/logp_pi        | 4.2237806   |
| training/sac_pi/pi_entropy     | 3.4538105   |
| training/sac_pi/pi_global_norm | 1.8177027   |
| training/sac_pi/policy_loss    | -224.8546   |
| training/sac_pi/std            | 0.49459225  |
| training/sac_pi/valid_num      | 4980.0      |
| training/sac_Q/q1              | 211.92436   |
| training/sac_Q/q2              | 214.08359   |
| training/sac_Q/q2_loss         | 100.59741   |
| training/sac_Q/q_global_norm   | 215.66428   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16414209 |
| epoch                          | 948        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4728.127   |
| evaluation/return-max          | 4784.167   |
| evaluation/return-min          | 4665.0557  |
| evaluation/return-std          | 39.118427  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46210      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4728.127   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 217.10556  |
| Q-std                          | 138.18922  |
| Q_loss                         | 90.36231   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 948        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 520        |
| times/evaluation_metrics       | 0.000597   |
| times/evaluation_paths         | 38.6       |
| times/timestep_after_hook      | 0.00411    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 74.4       |
| timestep                       | 1000       |
| timesteps_total                | 949000     |
| train-steps                    | 949000     |
| training/Q/q1_loss             | 111.521904 |
| training/sac_pi/alpha          | 0.16413687 |
| training/sac_pi/alpha_loss     | 0.29875275 |
| training/sac_pi/logp_pi        | 5.079512   |
| training/sac_pi/pi_entropy     | 3.4050438  |
| training/sac_pi/pi_global_norm | 1.6185493  |
| training/sac_pi/policy_loss    | -217.99028 |
| training/sac_pi/std            | 0.5093382  |
| training/sac_pi/valid_num      | 4910.0     |
| training/sac_Q/q1              | 204.0221   |
| training/sac_Q/q2              | 206.27267  |
| training/sac_Q/q2_loss         | 111.37437  |
| training/sac_Q/q_global_norm   | 233.52544  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16855995   |
| epoch                          | 949          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5022.3545    |
| evaluation/return-max          | 5050.5884    |
| evaluation/return-min          | 4986.749     |
| evaluation/return-std          | 20.631285    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3            |
| model/origin_ret               | 84.3         |
| model/penalty_ret              | 80.7         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46316        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5022.3545    |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 212.98601    |
| Q-std                          | 143.43448    |
| Q_loss                         | 76.58034     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 949          |
| times/epoch_after_hook         | 1.88e-06     |
| times/epoch_before_hook        | 0.000273     |
| times/epoch_rollout_model      | 516          |
| times/evaluation_metrics       | 0.000603     |
| times/evaluation_paths         | 34.6         |
| times/timestep_after_hook      | 0.00407      |
| times/timestep_before_hook     | 0.00823      |
| times/train                    | 62.4         |
| timestep                       | 1000         |
| timesteps_total                | 950000       |
| train-steps                    | 950000       |
| training/Q/q1_loss             | 90.62003     |
| training/sac_pi/alpha          | 0.16854535   |
| training/sac_pi/alpha_loss     | -0.012671162 |
| training/sac_pi/logp_pi        | 4.99314      |
| training/sac_pi/pi_entropy     | 3.4762924    |
| training/sac_pi/pi_global_norm | 1.6805876    |
| training/sac_pi/policy_loss    | -217.17285   |
| training/sac_pi/std            | 0.51155096   |
| training/sac_pi/valid_num      | 4922.0       |
| training/sac_Q/q1              | 204.12631    |
| training/sac_Q/q2              | 206.79733    |
| training/sac_Q/q2_loss         | 91.07774     |
| training/sac_Q/q_global_norm   | 207.34389    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16527395  |
| epoch                          | 950         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4885.6313   |
| evaluation/return-max          | 5083.4365   |
| evaluation/return-min          | 4737.9365   |
| evaluation/return-std          | 108.22799   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46342       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4885.6313   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 211.34021   |
| Q-std                          | 121.17157   |
| Q_loss                         | 118.67917   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 950         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000523    |
| times/evaluation_paths         | 34.4        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.00802     |
| times/train                    | 67.8        |
| timestep                       | 1000        |
| timesteps_total                | 951000      |
| train-steps                    | 951000      |
| training/Q/q1_loss             | 102.13484   |
| training/sac_pi/alpha          | 0.16530654  |
| training/sac_pi/alpha_loss     | 0.034243457 |
| training/sac_pi/logp_pi        | 3.8627899   |
| training/sac_pi/pi_entropy     | 3.3393497   |
| training/sac_pi/pi_global_norm | 1.9522746   |
| training/sac_pi/policy_loss    | -221.44269  |
| training/sac_pi/std            | 0.47490323  |
| training/sac_pi/valid_num      | 5042.0      |
| training/sac_Q/q1              | 219.0372    |
| training/sac_Q/q2              | 219.2186    |
| training/sac_Q/q2_loss         | 99.972664   |
| training/sac_Q/q_global_norm   | 212.68135   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16595455  |
| epoch                          | 951         |
| evaluation/episode-length-avg  | 866         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 294         |
| evaluation/episode-length-std  | 269         |
| evaluation/return-average      | 4163.212    |
| evaluation/return-max          | 5085.9585   |
| evaluation/return-min          | 1033.4875   |
| evaluation/return-std          | 1492.4868   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46242       |
| perf/AverageLength             | 866         |
| perf/AverageReturn             | 4163.212    |
| perf/NormalizedReturn          | 0.907       |
| Q-avg                          | 213.49382   |
| Q-std                          | 125.32986   |
| Q_loss                         | 105.01539   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 951         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 514         |
| times/evaluation_metrics       | 0.000546    |
| times/evaluation_paths         | 33          |
| times/timestep_after_hook      | 0.00421     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 70.2        |
| timestep                       | 1000        |
| timesteps_total                | 952000      |
| train-steps                    | 952000      |
| training/Q/q1_loss             | 90.18959    |
| training/sac_pi/alpha          | 0.16595696  |
| training/sac_pi/alpha_loss     | -0.19856305 |
| training/sac_pi/logp_pi        | 3.513166    |
| training/sac_pi/pi_entropy     | 3.3974738   |
| training/sac_pi/pi_global_norm | 1.5667102   |
| training/sac_pi/policy_loss    | -224.36536  |
| training/sac_pi/std            | 0.4600143   |
| training/sac_pi/valid_num      | 5030.0      |
| training/sac_Q/q1              | 219.71265   |
| training/sac_Q/q2              | 219.89734   |
| training/sac_Q/q2_loss         | 89.89934    |
| training/sac_Q/q_global_norm   | 230.76193   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16386642  |
| epoch                          | 952         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4909.8853   |
| evaluation/return-max          | 5007.5977   |
| evaluation/return-min          | 4814.627    |
| evaluation/return-std          | 54.36877    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 80.2        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46260       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4909.8853   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 193.6628    |
| Q-std                          | 242.21976   |
| Q_loss                         | 106.315544  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 952         |
| times/epoch_after_hook         | 3.1e-06     |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000572    |
| times/evaluation_paths         | 40.2        |
| times/timestep_after_hook      | 0.00428     |
| times/timestep_before_hook     | 0.00858     |
| times/train                    | 74          |
| timestep                       | 1000        |
| timesteps_total                | 953000      |
| train-steps                    | 953000      |
| training/Q/q1_loss             | 89.46977    |
| training/sac_pi/alpha          | 0.16387808  |
| training/sac_pi/alpha_loss     | -0.08011281 |
| training/sac_pi/logp_pi        | 3.9176269   |
| training/sac_pi/pi_entropy     | 3.4193377   |
| training/sac_pi/pi_global_norm | 1.4881417   |
| training/sac_pi/policy_loss    | -225.70024  |
| training/sac_pi/std            | 0.48058802  |
| training/sac_pi/valid_num      | 4977.0      |
| training/sac_Q/q1              | 216.64104   |
| training/sac_Q/q2              | 217.56445   |
| training/sac_Q/q2_loss         | 88.39844    |
| training/sac_Q/q_global_norm   | 342.44836   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16370463 |
| epoch                          | 953        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4795.1924  |
| evaluation/return-max          | 4856.5537  |
| evaluation/return-min          | 4702.4424  |
| evaluation/return-std          | 40.012558  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46388      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4795.1924  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 207.6626   |
| Q-std                          | 168.25565  |
| Q_loss                         | 106.65688  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 953        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.000641   |
| times/epoch_rollout_model      | 520        |
| times/evaluation_metrics       | 0.000663   |
| times/evaluation_paths         | 34.8       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 954000     |
| train-steps                    | 954000     |
| training/Q/q1_loss             | 87.86699   |
| training/sac_pi/alpha          | 0.1637209  |
| training/sac_pi/alpha_loss     | 0.19893663 |
| training/sac_pi/logp_pi        | 3.5970826  |
| training/sac_pi/pi_entropy     | 3.350006   |
| training/sac_pi/pi_global_norm | 1.675608   |
| training/sac_pi/policy_loss    | -221.97813 |
| training/sac_pi/std            | 0.45609698 |
| training/sac_pi/valid_num      | 5043.0     |
| training/sac_Q/q1              | 218.18408  |
| training/sac_Q/q2              | 218.32881  |
| training/sac_Q/q2_loss         | 87.97367   |
| training/sac_Q/q_global_norm   | 258.64783  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16251624 |
| epoch                          | 954        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5043.792   |
| evaluation/return-max          | 5086.451   |
| evaluation/return-min          | 5019.786   |
| evaluation/return-std          | 18.636911  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46479      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5043.792   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 194.65337  |
| Q-std                          | 151.50407  |
| Q_loss                         | 109.11204  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 954        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000157   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000589   |
| times/evaluation_paths         | 38.6       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 70.3       |
| timestep                       | 1000       |
| timesteps_total                | 955000     |
| train-steps                    | 955000     |
| training/Q/q1_loss             | 108.11204  |
| training/sac_pi/alpha          | 0.1624733  |
| training/sac_pi/alpha_loss     | 0.2503584  |
| training/sac_pi/logp_pi        | 4.580271   |
| training/sac_pi/pi_entropy     | 3.3606102  |
| training/sac_pi/pi_global_norm | 1.6375408  |
| training/sac_pi/policy_loss    | -217.20355 |
| training/sac_pi/std            | 0.48779652 |
| training/sac_pi/valid_num      | 4976.0     |
| training/sac_Q/q1              | 207.75708  |
| training/sac_Q/q2              | 208.93008  |
| training/sac_Q/q2_loss         | 107.33339  |
| training/sac_Q/q_global_norm   | 205.87195  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16779341 |
| epoch                          | 955        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4963.839   |
| evaluation/return-max          | 5044.6147  |
| evaluation/return-min          | 4878.531   |
| evaluation/return-std          | 55.792126  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46354      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4963.839   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 209.1582   |
| Q-std                          | 148.86264  |
| Q_loss                         | 95.55529   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 955        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000562   |
| times/evaluation_paths         | 45.8       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 956000     |
| train-steps                    | 956000     |
| training/Q/q1_loss             | 92.80958   |
| training/sac_pi/alpha          | 0.16782552 |
| training/sac_pi/alpha_loss     | 0.03392953 |
| training/sac_pi/logp_pi        | 3.89501    |
| training/sac_pi/pi_entropy     | 3.5663466  |
| training/sac_pi/pi_global_norm | 1.5472442  |
| training/sac_pi/policy_loss    | -222.06529 |
| training/sac_pi/std            | 0.49890798 |
| training/sac_pi/valid_num      | 5023.0     |
| training/sac_Q/q1              | 215.3623   |
| training/sac_Q/q2              | 216.96306  |
| training/sac_Q/q2_loss         | 92.857994  |
| training/sac_Q/q_global_norm   | 195.78601  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16836417 |
| epoch                          | 956        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4815.069   |
| evaluation/return-max          | 4925.027   |
| evaluation/return-min          | 4671.2217  |
| evaluation/return-std          | 71.40628   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46099      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4815.069   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 219.90141  |
| Q-std                          | 94.07303   |
| Q_loss                         | 105.0879   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 956        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000586   |
| times/evaluation_paths         | 37.7       |
| times/timestep_after_hook      | 0.00381    |
| times/timestep_before_hook     | 0.00798    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 957000     |
| train-steps                    | 957000     |
| training/Q/q1_loss             | 106.657974 |
| training/sac_pi/alpha          | 0.16840182 |
| training/sac_pi/alpha_loss     | 0.04126328 |
| training/sac_pi/logp_pi        | 4.4338584  |
| training/sac_pi/pi_entropy     | 3.4325256  |
| training/sac_pi/pi_global_norm | 1.518998   |
| training/sac_pi/policy_loss    | -222.79648 |
| training/sac_pi/std            | 0.49433935 |
| training/sac_pi/valid_num      | 4962.0     |
| training/sac_Q/q1              | 214.16464  |
| training/sac_Q/q2              | 215.32271  |
| training/sac_Q/q2_loss         | 106.82191  |
| training/sac_Q/q_global_norm   | 263.34457  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16807283 |
| epoch                          | 957        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4911.199   |
| evaluation/return-max          | 5042.0957  |
| evaluation/return-min          | 4719.6846  |
| evaluation/return-std          | 99.72756   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46394      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4911.199   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 213.42471  |
| Q-std                          | 115.10354  |
| Q_loss                         | 109.61412  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 957        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000255   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000526   |
| times/evaluation_paths         | 45         |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 60         |
| timestep                       | 1000       |
| timesteps_total                | 958000     |
| train-steps                    | 958000     |
| training/Q/q1_loss             | 106.381    |
| training/sac_pi/alpha          | 0.16807337 |
| training/sac_pi/alpha_loss     | 0.14110982 |
| training/sac_pi/logp_pi        | 5.1102815  |
| training/sac_pi/pi_entropy     | 3.5875764  |
| training/sac_pi/pi_global_norm | 1.6398567  |
| training/sac_pi/policy_loss    | -227.63599 |
| training/sac_pi/std            | 0.54395604 |
| training/sac_pi/valid_num      | 4912.0     |
| training/sac_Q/q1              | 209.87846  |
| training/sac_Q/q2              | 215.0458   |
| training/sac_Q/q2_loss         | 107.6677   |
| training/sac_Q/q_global_norm   | 375.09927  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17026319  |
| epoch                          | 958         |
| evaluation/episode-length-avg  | 980         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 801         |
| evaluation/episode-length-std  | 59.7        |
| evaluation/return-average      | 4899.785    |
| evaluation/return-max          | 5075.649    |
| evaluation/return-min          | 3692.655    |
| evaluation/return-std          | 403.86356   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46265       |
| perf/AverageLength             | 980         |
| perf/AverageReturn             | 4899.785    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 205.19644   |
| Q-std                          | 123.483284  |
| Q_loss                         | 90.373634   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 958         |
| times/epoch_after_hook         | 1.65e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000582    |
| times/evaluation_paths         | 33.1        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 58.2        |
| timestep                       | 1000        |
| timesteps_total                | 959000      |
| train-steps                    | 959000      |
| training/Q/q1_loss             | 95.50131    |
| training/sac_pi/alpha          | 0.17026396  |
| training/sac_pi/alpha_loss     | 0.007866155 |
| training/sac_pi/logp_pi        | 4.097257    |
| training/sac_pi/pi_entropy     | 3.6036057   |
| training/sac_pi/pi_global_norm | 1.4320198   |
| training/sac_pi/policy_loss    | -212.67928  |
| training/sac_pi/std            | 0.510935    |
| training/sac_pi/valid_num      | 4958.0      |
| training/sac_Q/q1              | 199.23518   |
| training/sac_Q/q2              | 201.73357   |
| training/sac_Q/q2_loss         | 95.458435   |
| training/sac_Q/q_global_norm   | 266.52966   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16908774  |
| epoch                          | 959         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4809.8823   |
| evaluation/return-max          | 4856.657    |
| evaluation/return-min          | 4760.0605   |
| evaluation/return-std          | 23.100954   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46224       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4809.8823   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 213.92471   |
| Q-std                          | 132.76598   |
| Q_loss                         | 79.29069    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 959         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000142    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000572    |
| times/evaluation_paths         | 33.8        |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 960000      |
| train-steps                    | 960000      |
| training/Q/q1_loss             | 90.57516    |
| training/sac_pi/alpha          | 0.16912985  |
| training/sac_pi/alpha_loss     | 0.032767277 |
| training/sac_pi/logp_pi        | 4.091054    |
| training/sac_pi/pi_entropy     | 3.4472213   |
| training/sac_pi/pi_global_norm | 1.7692925   |
| training/sac_pi/policy_loss    | -232.84258  |
| training/sac_pi/std            | 0.49451655  |
| training/sac_pi/valid_num      | 4957.0      |
| training/sac_Q/q1              | 222.98409   |
| training/sac_Q/q2              | 225.298     |
| training/sac_Q/q2_loss         | 89.60062    |
| training/sac_Q/q_global_norm   | 197.7523    |
---------------------------------------------------------------------------------
[WARN] 960 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16860633  |
| epoch                          | 960         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4728.9053   |
| evaluation/return-max          | 4782.6025   |
| evaluation/return-min          | 4595.5527   |
| evaluation/return-std          | 55.207455   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46284       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4728.9053   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 201.65533   |
| Q-std                          | 170.36647   |
| Q_loss                         | 91.96187    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 960         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000591    |
| times/evaluation_paths         | 35.1        |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 59.3        |
| timestep                       | 1000        |
| timesteps_total                | 961000      |
| train-steps                    | 961000      |
| training/Q/q1_loss             | 92.23706    |
| training/sac_pi/alpha          | 0.16863237  |
| training/sac_pi/alpha_loss     | -0.32719433 |
| training/sac_pi/logp_pi        | 4.357852    |
| training/sac_pi/pi_entropy     | 3.3355286   |
| training/sac_pi/pi_global_norm | 1.6727041   |
| training/sac_pi/policy_loss    | -218.83086  |
| training/sac_pi/std            | 0.49590775  |
| training/sac_pi/valid_num      | 4935.0      |
| training/sac_Q/q1              | 206.44754   |
| training/sac_Q/q2              | 207.16296   |
| training/sac_Q/q2_loss         | 92.86794    |
| training/sac_Q/q_global_norm   | 160.6956    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16941135 |
| epoch                          | 961        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4956.87    |
| evaluation/return-max          | 5037.843   |
| evaluation/return-min          | 4880.077   |
| evaluation/return-std          | 41.319588  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46395      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4956.87    |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 212.54556  |
| Q-std                          | 128.08403  |
| Q_loss                         | 86.11721   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 961        |
| times/epoch_after_hook         | 2.02e-06   |
| times/epoch_before_hook        | 0.000267   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000587   |
| times/evaluation_paths         | 34         |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00794    |
| times/train                    | 59.4       |
| timestep                       | 1000       |
| timesteps_total                | 962000     |
| train-steps                    | 962000     |
| training/Q/q1_loss             | 85.31953   |
| training/sac_pi/alpha          | 0.1693974  |
| training/sac_pi/alpha_loss     | 0.18826282 |
| training/sac_pi/logp_pi        | 4.1198835  |
| training/sac_pi/pi_entropy     | 3.455539   |
| training/sac_pi/pi_global_norm | 2.2354681  |
| training/sac_pi/policy_loss    | -223.28061 |
| training/sac_pi/std            | 0.48324504 |
| training/sac_pi/valid_num      | 5014.0     |
| training/sac_Q/q1              | 215.71428  |
| training/sac_Q/q2              | 215.53098  |
| training/sac_Q/q2_loss         | 86.469444  |
| training/sac_Q/q_global_norm   | 159.3006   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16837801 |
| epoch                          | 962        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4683.7476  |
| evaluation/return-max          | 4745.331   |
| evaluation/return-min          | 4635.319   |
| evaluation/return-std          | 32.699295  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46297      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4683.7476  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 199.96664  |
| Q-std                          | 158.13023  |
| Q_loss                         | 115.15417  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 962        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000575   |
| times/evaluation_paths         | 33.7       |
| times/timestep_after_hook      | 0.00394    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 963000     |
| train-steps                    | 963000     |
| training/Q/q1_loss             | 98.057846  |
| training/sac_pi/alpha          | 0.16832565 |
| training/sac_pi/alpha_loss     | 0.3179446  |
| training/sac_pi/logp_pi        | 4.510974   |
| training/sac_pi/pi_entropy     | 3.4232612  |
| training/sac_pi/pi_global_norm | 2.0887892  |
| training/sac_pi/policy_loss    | -216.81187 |
| training/sac_pi/std            | 0.49558085 |
| training/sac_pi/valid_num      | 4949.0     |
| training/sac_Q/q1              | 205.89815  |
| training/sac_Q/q2              | 205.49146  |
| training/sac_Q/q2_loss         | 98.81244   |
| training/sac_Q/q_global_norm   | 230.23048  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1698074  |
| epoch                          | 963        |
| evaluation/episode-length-avg  | 925        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 247        |
| evaluation/episode-length-std  | 226        |
| evaluation/return-average      | 4473.816   |
| evaluation/return-max          | 4955.136   |
| evaluation/return-min          | 815.28577  |
| evaluation/return-std          | 1220.3336  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46402      |
| perf/AverageLength             | 925        |
| perf/AverageReturn             | 4473.816   |
| perf/NormalizedReturn          | 0.974      |
| Q-avg                          | 213.5566   |
| Q-std                          | 102.98254  |
| Q_loss                         | 100.61424  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 963        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.00011    |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000638   |
| times/evaluation_paths         | 32.8       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.008      |
| times/train                    | 58.9       |
| timestep                       | 1000       |
| timesteps_total                | 964000     |
| train-steps                    | 964000     |
| training/Q/q1_loss             | 91.51952   |
| training/sac_pi/alpha          | 0.16982044 |
| training/sac_pi/alpha_loss     | 0.1701816  |
| training/sac_pi/logp_pi        | 3.468232   |
| training/sac_pi/pi_entropy     | 3.4488587  |
| training/sac_pi/pi_global_norm | 2.223066   |
| training/sac_pi/policy_loss    | -220.64299 |
| training/sac_pi/std            | 0.46223697 |
| training/sac_pi/valid_num      | 4956.0     |
| training/sac_Q/q1              | 213.04619  |
| training/sac_Q/q2              | 214.35507  |
| training/sac_Q/q2_loss         | 91.83635   |
| training/sac_Q/q_global_norm   | 211.3511   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16675456 |
| epoch                          | 964        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4810.462   |
| evaluation/return-max          | 4888.904   |
| evaluation/return-min          | 4727.9346  |
| evaluation/return-std          | 51.03425   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46393      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4810.462   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 210.06226  |
| Q-std                          | 131.79623  |
| Q_loss                         | 110.374695 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 964        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000139   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000554   |
| times/evaluation_paths         | 35.3       |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 59.7       |
| timestep                       | 1000       |
| timesteps_total                | 965000     |
| train-steps                    | 965000     |
| training/Q/q1_loss             | 106.70051  |
| training/sac_pi/alpha          | 0.16671802 |
| training/sac_pi/alpha_loss     | 0.1359762  |
| training/sac_pi/logp_pi        | 4.1847396  |
| training/sac_pi/pi_entropy     | 3.3677926  |
| training/sac_pi/pi_global_norm | 3.1895158  |
| training/sac_pi/policy_loss    | -215.77864 |
| training/sac_pi/std            | 0.47248012 |
| training/sac_pi/valid_num      | 4915.0     |
| training/sac_Q/q1              | 204.81807  |
| training/sac_Q/q2              | 205.4218   |
| training/sac_Q/q2_loss         | 105.515205 |
| training/sac_Q/q_global_norm   | 179.61719  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16244031  |
| epoch                          | 965         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4522.3096   |
| evaluation/return-max          | 4705.517    |
| evaluation/return-min          | 4472.6206   |
| evaluation/return-std          | 70.080635   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.17        |
| model/origin_ret               | 87          |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46387       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4522.3096   |
| perf/NormalizedReturn          | 0.985       |
| Q-avg                          | 208.36824   |
| Q-std                          | 126.19298   |
| Q_loss                         | 89.724556   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 965         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000252    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000495    |
| times/evaluation_paths         | 35.5        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 59.4        |
| timestep                       | 1000        |
| timesteps_total                | 966000      |
| train-steps                    | 966000      |
| training/Q/q1_loss             | 93.26666    |
| training/sac_pi/alpha          | 0.16246408  |
| training/sac_pi/alpha_loss     | -0.20863286 |
| training/sac_pi/logp_pi        | 4.631437    |
| training/sac_pi/pi_entropy     | 3.2110157   |
| training/sac_pi/pi_global_norm | 1.744407    |
| training/sac_pi/policy_loss    | -225.01782  |
| training/sac_pi/std            | 0.47731388  |
| training/sac_pi/valid_num      | 4952.0      |
| training/sac_Q/q1              | 214.90344   |
| training/sac_Q/q2              | 216.67693   |
| training/sac_Q/q2_loss         | 93.35536    |
| training/sac_Q/q_global_norm   | 201.67151   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17075759 |
| epoch                          | 966        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4929.9624  |
| evaluation/return-max          | 4981.0444  |
| evaluation/return-min          | 4841.7456  |
| evaluation/return-std          | 43.21526   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46328      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4929.9624  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 216.92668  |
| Q-std                          | 138.34184  |
| Q_loss                         | 93.2157    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 966        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000572   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 967000     |
| train-steps                    | 967000     |
| training/Q/q1_loss             | 99.07847   |
| training/sac_pi/alpha          | 0.17074727 |
| training/sac_pi/alpha_loss     | 0.11487583 |
| training/sac_pi/logp_pi        | 4.991544   |
| training/sac_pi/pi_entropy     | 3.4945588  |
| training/sac_pi/pi_global_norm | 1.5577794  |
| training/sac_pi/policy_loss    | -220.02895 |
| training/sac_pi/std            | 0.5183453  |
| training/sac_pi/valid_num      | 4906.0     |
| training/sac_Q/q1              | 201.66638  |
| training/sac_Q/q2              | 202.962    |
| training/sac_Q/q2_loss         | 99.278496  |
| training/sac_Q/q_global_norm   | 172.32262  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16725387  |
| epoch                          | 967         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4960.2705   |
| evaluation/return-max          | 4993.881    |
| evaluation/return-min          | 4925.3516   |
| evaluation/return-std          | 19.268103   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46076       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4960.2705   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 213.57837   |
| Q-std                          | 134.38013   |
| Q_loss                         | 84.32384    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 967         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000593    |
| times/evaluation_paths         | 33.6        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 61.5        |
| timestep                       | 1000        |
| timesteps_total                | 968000      |
| train-steps                    | 968000      |
| training/Q/q1_loss             | 103.886505  |
| training/sac_pi/alpha          | 0.16724674  |
| training/sac_pi/alpha_loss     | -0.28173822 |
| training/sac_pi/logp_pi        | 4.648839    |
| training/sac_pi/pi_entropy     | 3.5740921   |
| training/sac_pi/pi_global_norm | 1.4683642   |
| training/sac_pi/policy_loss    | -215.85928  |
| training/sac_pi/std            | 0.52842325  |
| training/sac_pi/valid_num      | 4905.0      |
| training/sac_Q/q1              | 200.41464   |
| training/sac_Q/q2              | 202.45618   |
| training/sac_Q/q2_loss         | 103.52408   |
| training/sac_Q/q_global_norm   | 222.93712   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16843446  |
| epoch                          | 968         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5114.071    |
| evaluation/return-max          | 5174.044    |
| evaluation/return-min          | 5001.3984   |
| evaluation/return-std          | 60.484005   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46119       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5114.071    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 221.15433   |
| Q-std                          | 136.0464    |
| Q_loss                         | 104.99318   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 968         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.00014     |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000595    |
| times/evaluation_paths         | 33.4        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 61.8        |
| timestep                       | 1000        |
| timesteps_total                | 969000      |
| train-steps                    | 969000      |
| training/Q/q1_loss             | 94.22726    |
| training/sac_pi/alpha          | 0.16845025  |
| training/sac_pi/alpha_loss     | 0.050691206 |
| training/sac_pi/logp_pi        | 4.47423     |
| training/sac_pi/pi_entropy     | 3.5480099   |
| training/sac_pi/pi_global_norm | 1.8391875   |
| training/sac_pi/policy_loss    | -212.91658  |
| training/sac_pi/std            | 0.5029983   |
| training/sac_pi/valid_num      | 4933.0      |
| training/sac_Q/q1              | 202.94981   |
| training/sac_Q/q2              | 204.25323   |
| training/sac_Q/q2_loss         | 92.92566    |
| training/sac_Q/q_global_norm   | 212.59326   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17003512  |
| epoch                          | 969         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4842.417    |
| evaluation/return-max          | 4870.8345   |
| evaluation/return-min          | 4816.8877   |
| evaluation/return-std          | 17.707184   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46341       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4842.417    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 204.33484   |
| Q-std                          | 200.75017   |
| Q_loss                         | 92.01541    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 969         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000317    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000549    |
| times/evaluation_paths         | 35.1        |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 970000      |
| train-steps                    | 970000      |
| training/Q/q1_loss             | 100.73925   |
| training/sac_pi/alpha          | 0.17002444  |
| training/sac_pi/alpha_loss     | 0.047987655 |
| training/sac_pi/logp_pi        | 3.9846687   |
| training/sac_pi/pi_entropy     | 3.5149498   |
| training/sac_pi/pi_global_norm | 1.660649    |
| training/sac_pi/policy_loss    | -216.52254  |
| training/sac_pi/std            | 0.49044576  |
| training/sac_pi/valid_num      | 5015.0      |
| training/sac_Q/q1              | 211.44214   |
| training/sac_Q/q2              | 212.14177   |
| training/sac_Q/q2_loss         | 102.08878   |
| training/sac_Q/q_global_norm   | 252.26956   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17414658  |
| epoch                          | 970         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4924.394    |
| evaluation/return-max          | 4988.1665   |
| evaluation/return-min          | 4847.154    |
| evaluation/return-std          | 45.257195   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46088       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4924.394    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 209.95932   |
| Q-std                          | 141.20685   |
| Q_loss                         | 100.47586   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 970         |
| times/epoch_after_hook         | 3.21e-06    |
| times/epoch_before_hook        | 0.000208    |
| times/epoch_rollout_model      | 510         |
| times/evaluation_metrics       | 0.000545    |
| times/evaluation_paths         | 36.3        |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 971000      |
| train-steps                    | 971000      |
| training/Q/q1_loss             | 99.50217    |
| training/sac_pi/alpha          | 0.17420152  |
| training/sac_pi/alpha_loss     | -0.21178605 |
| training/sac_pi/logp_pi        | 4.3761444   |
| training/sac_pi/pi_entropy     | 3.6277702   |
| training/sac_pi/pi_global_norm | 1.6072952   |
| training/sac_pi/policy_loss    | -220.96368  |
| training/sac_pi/std            | 0.5205215   |
| training/sac_pi/valid_num      | 4909.0      |
| training/sac_Q/q1              | 209.33194   |
| training/sac_Q/q2              | 210.33398   |
| training/sac_Q/q2_loss         | 98.73811    |
| training/sac_Q/q_global_norm   | 201.51102   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1678094  |
| epoch                          | 971        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4712.2583  |
| evaluation/return-max          | 4726.8467  |
| evaluation/return-min          | 4693.0117  |
| evaluation/return-std          | 10.585068  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46286      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4712.2583  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 212.18777  |
| Q-std                          | 123.60182  |
| Q_loss                         | 77.42138   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 971        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000625   |
| times/evaluation_paths         | 35.3       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 972000     |
| train-steps                    | 972000     |
| training/Q/q1_loss             | 111.04279  |
| training/sac_pi/alpha          | 0.16781513 |
| training/sac_pi/alpha_loss     | 0.10864203 |
| training/sac_pi/logp_pi        | 5.362044   |
| training/sac_pi/pi_entropy     | 3.6867929  |
| training/sac_pi/pi_global_norm | 1.8460096  |
| training/sac_pi/policy_loss    | -212.90938 |
| training/sac_pi/std            | 0.5596799  |
| training/sac_pi/valid_num      | 4855.0     |
| training/sac_Q/q1              | 186.687    |
| training/sac_Q/q2              | 191.28828  |
| training/sac_Q/q2_loss         | 111.961685 |
| training/sac_Q/q_global_norm   | 207.78763  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17389302 |
| epoch                          | 972        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4894.701   |
| evaluation/return-max          | 4977.046   |
| evaluation/return-min          | 4854.0957  |
| evaluation/return-std          | 33.681293  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46320      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4894.701   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 213.0092   |
| Q-std                          | 107.65791  |
| Q_loss                         | 114.57077  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 972        |
| times/epoch_after_hook         | 2.23e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000673   |
| times/evaluation_paths         | 34.8       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 59.5       |
| timestep                       | 1000       |
| timesteps_total                | 973000     |
| train-steps                    | 973000     |
| training/Q/q1_loss             | 97.131256  |
| training/sac_pi/alpha          | 0.17385411 |
| training/sac_pi/alpha_loss     | 0.02290533 |
| training/sac_pi/logp_pi        | 4.1314178  |
| training/sac_pi/pi_entropy     | 3.5336776  |
| training/sac_pi/pi_global_norm | 1.4118483  |
| training/sac_pi/policy_loss    | -223.43556 |
| training/sac_pi/std            | 0.48676682 |
| training/sac_pi/valid_num      | 4983.0     |
| training/sac_Q/q1              | 218.06425  |
| training/sac_Q/q2              | 217.67374  |
| training/sac_Q/q2_loss         | 97.05905   |
| training/sac_Q/q_global_norm   | 193.45377  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17552473  |
| epoch                          | 973         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5007.3506   |
| evaluation/return-max          | 5113.006    |
| evaluation/return-min          | 4947.702    |
| evaluation/return-std          | 47.361202   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46301       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5007.3506   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 223.39517   |
| Q-std                          | 129.66641   |
| Q_loss                         | 85.67211    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 973         |
| times/epoch_after_hook         | 1.98e-06    |
| times/epoch_before_hook        | 0.000312    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000578    |
| times/evaluation_paths         | 33.7        |
| times/timestep_after_hook      | 0.00387     |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 974000      |
| train-steps                    | 974000      |
| training/Q/q1_loss             | 104.78584   |
| training/sac_pi/alpha          | 0.1755194   |
| training/sac_pi/alpha_loss     | -0.29229152 |
| training/sac_pi/logp_pi        | 3.736557    |
| training/sac_pi/pi_entropy     | 3.5341117   |
| training/sac_pi/pi_global_norm | 1.6169618   |
| training/sac_pi/policy_loss    | -232.48778  |
| training/sac_pi/std            | 0.4810001   |
| training/sac_pi/valid_num      | 5004.0      |
| training/sac_Q/q1              | 225.11646   |
| training/sac_Q/q2              | 226.49341   |
| training/sac_Q/q2_loss         | 105.12144   |
| training/sac_Q/q_global_norm   | 213.91153   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17021827 |
| epoch                          | 974        |
| evaluation/episode-length-avg  | 967        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 666        |
| evaluation/episode-length-std  | 100        |
| evaluation/return-average      | 4684.231   |
| evaluation/return-max          | 4996.6836  |
| evaluation/return-min          | 2895.201   |
| evaluation/return-std          | 603.72925  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46238      |
| perf/AverageLength             | 967        |
| perf/AverageReturn             | 4684.231   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 211.86282  |
| Q-std                          | 114.03173  |
| Q_loss                         | 90.71016   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 974        |
| times/epoch_after_hook         | 2.11e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.0006     |
| times/evaluation_paths         | 35.4       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 975000     |
| train-steps                    | 975000     |
| training/Q/q1_loss             | 89.074814  |
| training/sac_pi/alpha          | 0.17021097 |
| training/sac_pi/alpha_loss     | 0.12831369 |
| training/sac_pi/logp_pi        | 3.5793087  |
| training/sac_pi/pi_entropy     | 3.4547927  |
| training/sac_pi/pi_global_norm | 1.6379503  |
| training/sac_pi/policy_loss    | -224.74593 |
| training/sac_pi/std            | 0.4690054  |
| training/sac_pi/valid_num      | 5034.0     |
| training/sac_Q/q1              | 219.75708  |
| training/sac_Q/q2              | 220.88925  |
| training/sac_Q/q2_loss         | 88.74079   |
| training/sac_Q/q_global_norm   | 222.76675  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17132334  |
| epoch                          | 975         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4809.5205   |
| evaluation/return-max          | 4900.0576   |
| evaluation/return-min          | 4682.917    |
| evaluation/return-std          | 57.99276    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46158       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4809.5205   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 212.20808   |
| Q-std                          | 104.36551   |
| Q_loss                         | 105.68907   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 975         |
| times/epoch_after_hook         | 2.14e-06    |
| times/epoch_before_hook        | 0.000235    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000701    |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.00385     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 61.9        |
| timestep                       | 1000        |
| timesteps_total                | 976000      |
| train-steps                    | 976000      |
| training/Q/q1_loss             | 114.48757   |
| training/sac_pi/alpha          | 0.17130654  |
| training/sac_pi/alpha_loss     | -0.17088176 |
| training/sac_pi/logp_pi        | 4.234583    |
| training/sac_pi/pi_entropy     | 3.6768603   |
| training/sac_pi/pi_global_norm | 1.68017     |
| training/sac_pi/policy_loss    | -209.63283  |
| training/sac_pi/std            | 0.5162907   |
| training/sac_pi/valid_num      | 4914.0      |
| training/sac_Q/q1              | 199.68265   |
| training/sac_Q/q2              | 199.04736   |
| training/sac_Q/q2_loss         | 114.464134  |
| training/sac_Q/q_global_norm   | 255.22047   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17508516 |
| epoch                          | 976        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4922.711   |
| evaluation/return-max          | 5036.176   |
| evaluation/return-min          | 4815.8335  |
| evaluation/return-std          | 75.05478   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46363      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4922.711   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 214.08408  |
| Q-std                          | 132.02466  |
| Q_loss                         | 82.339386  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 976        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.00019    |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000652   |
| times/evaluation_paths         | 33.4       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 61.5       |
| timestep                       | 1000       |
| timesteps_total                | 977000     |
| train-steps                    | 977000     |
| training/Q/q1_loss             | 96.46466   |
| training/sac_pi/alpha          | 0.17508164 |
| training/sac_pi/alpha_loss     | 0.40300766 |
| training/sac_pi/logp_pi        | 4.6499014  |
| training/sac_pi/pi_entropy     | 3.6168995  |
| training/sac_pi/pi_global_norm | 1.4531615  |
| training/sac_pi/policy_loss    | -222.55783 |
| training/sac_pi/std            | 0.5233883  |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 209.33855  |
| training/sac_Q/q2              | 210.85083  |
| training/sac_Q/q2_loss         | 97.67278   |
| training/sac_Q/q_global_norm   | 193.91112  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1683986   |
| epoch                          | 977         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4730.62     |
| evaluation/return-max          | 4807.4927   |
| evaluation/return-min          | 4657.462    |
| evaluation/return-std          | 43.552677   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46184       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4730.62     |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 208.03516   |
| Q-std                          | 144.953     |
| Q_loss                         | 116.64607   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 977         |
| times/epoch_after_hook         | 1.93e-06    |
| times/epoch_before_hook        | 0.000421    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000581    |
| times/evaluation_paths         | 33.5        |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 60.4        |
| timestep                       | 1000        |
| timesteps_total                | 978000      |
| train-steps                    | 978000      |
| training/Q/q1_loss             | 108.63726   |
| training/sac_pi/alpha          | 0.16841921  |
| training/sac_pi/alpha_loss     | -0.28130686 |
| training/sac_pi/logp_pi        | 4.3191414   |
| training/sac_pi/pi_entropy     | 3.3872075   |
| training/sac_pi/pi_global_norm | 1.6509224   |
| training/sac_pi/policy_loss    | -220.33652  |
| training/sac_pi/std            | 0.47875854  |
| training/sac_pi/valid_num      | 4950.0      |
| training/sac_Q/q1              | 208.66      |
| training/sac_Q/q2              | 210.30855   |
| training/sac_Q/q2_loss         | 108.399635  |
| training/sac_Q/q_global_norm   | 154.2766    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16925158  |
| epoch                          | 978         |
| evaluation/episode-length-avg  | 819         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 92          |
| evaluation/episode-length-std  | 363         |
| evaluation/return-average      | 4047.5215   |
| evaluation/return-max          | 5080.756    |
| evaluation/return-min          | 184.05367   |
| evaluation/return-std          | 1930.174    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46145       |
| perf/AverageLength             | 819         |
| perf/AverageReturn             | 4047.5215   |
| perf/NormalizedReturn          | 0.881       |
| Q-avg                          | 218.1688    |
| Q-std                          | 115.63414   |
| Q_loss                         | 95.76611    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 978         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000148    |
| times/epoch_rollout_model      | 519         |
| times/evaluation_metrics       | 0.000482    |
| times/evaluation_paths         | 28.1        |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.00834     |
| times/train                    | 62.4        |
| timestep                       | 1000        |
| timesteps_total                | 979000      |
| train-steps                    | 979000      |
| training/Q/q1_loss             | 99.62291    |
| training/sac_pi/alpha          | 0.16926575  |
| training/sac_pi/alpha_loss     | -0.14241908 |
| training/sac_pi/logp_pi        | 3.9310913   |
| training/sac_pi/pi_entropy     | 3.4832382   |
| training/sac_pi/pi_global_norm | 1.4032617   |
| training/sac_pi/policy_loss    | -224.30629  |
| training/sac_pi/std            | 0.4956358   |
| training/sac_pi/valid_num      | 4943.0      |
| training/sac_Q/q1              | 210.0315    |
| training/sac_Q/q2              | 213.03745   |
| training/sac_Q/q2_loss         | 97.95493    |
| training/sac_Q/q_global_norm   | 179.36342   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16705403  |
| epoch                          | 979         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4699.8525   |
| evaluation/return-max          | 4805.7314   |
| evaluation/return-min          | 4553.8486   |
| evaluation/return-std          | 96.656494   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46387       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4699.8525   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 212.75252   |
| Q-std                          | 118.04912   |
| Q_loss                         | 91.956474   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 979         |
| times/epoch_after_hook         | 3.95e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000738    |
| times/evaluation_paths         | 33.1        |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 60          |
| timestep                       | 1000        |
| timesteps_total                | 980000      |
| train-steps                    | 980000      |
| training/Q/q1_loss             | 100.78402   |
| training/sac_pi/alpha          | 0.16708077  |
| training/sac_pi/alpha_loss     | -0.12153523 |
| training/sac_pi/logp_pi        | 4.192642    |
| training/sac_pi/pi_entropy     | 3.3356605   |
| training/sac_pi/pi_global_norm | 1.4836805   |
| training/sac_pi/policy_loss    | -216.1825   |
| training/sac_pi/std            | 0.48089868  |
| training/sac_pi/valid_num      | 4992.0      |
| training/sac_Q/q1              | 207.26897   |
| training/sac_Q/q2              | 207.45432   |
| training/sac_Q/q2_loss         | 102.284966  |
| training/sac_Q/q_global_norm   | 235.20988   |
---------------------------------------------------------------------------------
[WARN] 980 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16973503 |
| epoch                          | 980        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4986.2607  |
| evaluation/return-max          | 5021.073   |
| evaluation/return-min          | 4955.606   |
| evaluation/return-std          | 17.561428  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46451      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4986.2607  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 219.19986  |
| Q-std                          | 141.03436  |
| Q_loss                         | 86.31935   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 980        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000576   |
| times/evaluation_paths         | 35.4       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 981000     |
| train-steps                    | 981000     |
| training/Q/q1_loss             | 88.626816  |
| training/sac_pi/alpha          | 0.1697902  |
| training/sac_pi/alpha_loss     | -0.3841417 |
| training/sac_pi/logp_pi        | 3.9137619  |
| training/sac_pi/pi_entropy     | 3.47579    |
| training/sac_pi/pi_global_norm | 1.8959782  |
| training/sac_pi/policy_loss    | -220.5698  |
| training/sac_pi/std            | 0.48569557 |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 210.69168  |
| training/sac_Q/q2              | 213.11642  |
| training/sac_Q/q2_loss         | 90.60959   |
| training/sac_Q/q_global_norm   | 173.4953   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17096898  |
| epoch                          | 981         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4864.173    |
| evaluation/return-max          | 4967.657    |
| evaluation/return-min          | 4770.424    |
| evaluation/return-std          | 61.52628    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46174       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4864.173    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 212.89221   |
| Q-std                          | 122.55442   |
| Q_loss                         | 100.41738   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 981         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000245    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000637    |
| times/evaluation_paths         | 34.9        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 60.3        |
| timestep                       | 1000        |
| timesteps_total                | 982000      |
| train-steps                    | 982000      |
| training/Q/q1_loss             | 96.57554    |
| training/sac_pi/alpha          | 0.17098874  |
| training/sac_pi/alpha_loss     | -0.16775464 |
| training/sac_pi/logp_pi        | 4.038636    |
| training/sac_pi/pi_entropy     | 3.5513444   |
| training/sac_pi/pi_global_norm | 2.1062977   |
| training/sac_pi/policy_loss    | -218.49945  |
| training/sac_pi/std            | 0.4982483   |
| training/sac_pi/valid_num      | 4960.0      |
| training/sac_Q/q1              | 207.38347   |
| training/sac_Q/q2              | 208.11673   |
| training/sac_Q/q2_loss         | 94.56677    |
| training/sac_Q/q_global_norm   | 199.2164    |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16928034   |
| epoch                          | 982          |
| evaluation/episode-length-avg  | 930          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 299          |
| evaluation/episode-length-std  | 210          |
| evaluation/return-average      | 4718.55      |
| evaluation/return-max          | 5170.067     |
| evaluation/return-min          | 1154.5735    |
| evaluation/return-std          | 1188.3695    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.05         |
| model/origin_ret               | 86.2         |
| model/penalty_ret              | 81           |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46095        |
| perf/AverageLength             | 930          |
| perf/AverageReturn             | 4718.55      |
| perf/NormalizedReturn          | 1.03         |
| Q-avg                          | 219.27408    |
| Q-std                          | 150.1432     |
| Q_loss                         | 78.8208      |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 982          |
| times/epoch_after_hook         | 1.73e-06     |
| times/epoch_before_hook        | 0.000116     |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.000523     |
| times/evaluation_paths         | 31.2         |
| times/timestep_after_hook      | 0.00386      |
| times/timestep_before_hook     | 0.008        |
| times/train                    | 61.5         |
| timestep                       | 1000         |
| timesteps_total                | 983000       |
| train-steps                    | 983000       |
| training/Q/q1_loss             | 83.66674     |
| training/sac_pi/alpha          | 0.16929142   |
| training/sac_pi/alpha_loss     | -0.118044645 |
| training/sac_pi/logp_pi        | 4.73207      |
| training/sac_pi/pi_entropy     | 3.678297     |
| training/sac_pi/pi_global_norm | 1.4649636    |
| training/sac_pi/policy_loss    | -217.34203   |
| training/sac_pi/std            | 0.549926     |
| training/sac_pi/valid_num      | 4928.0       |
| training/sac_Q/q1              | 202.26709    |
| training/sac_Q/q2              | 202.7504     |
| training/sac_Q/q2_loss         | 82.46049     |
| training/sac_Q/q_global_norm   | 172.68239    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16954492 |
| epoch                          | 983        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5022.3984  |
| evaluation/return-max          | 5197.741   |
| evaluation/return-min          | 4795.2446  |
| evaluation/return-std          | 104.95695  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46107      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5022.3984  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 213.0063   |
| Q-std                          | 132.87892  |
| Q_loss                         | 104.99964  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 983        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000559   |
| times/evaluation_paths         | 34         |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00802    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 984000     |
| train-steps                    | 984000     |
| training/Q/q1_loss             | 120.32481  |
| training/sac_pi/alpha          | 0.16950436 |
| training/sac_pi/alpha_loss     | 0.39876077 |
| training/sac_pi/logp_pi        | 4.840828   |
| training/sac_pi/pi_entropy     | 3.481758   |
| training/sac_pi/pi_global_norm | 1.8333759  |
| training/sac_pi/policy_loss    | -225.5033  |
| training/sac_pi/std            | 0.5049606  |
| training/sac_pi/valid_num      | 4926.0     |
| training/sac_Q/q1              | 210.37212  |
| training/sac_Q/q2              | 210.95581  |
| training/sac_Q/q2_loss         | 119.03978  |
| training/sac_Q/q_global_norm   | 278.1787   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16685936 |
| epoch                          | 984        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4786.144   |
| evaluation/return-max          | 4817.546   |
| evaluation/return-min          | 4730.9067  |
| evaluation/return-std          | 26.093935  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46181      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4786.144   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 199.45251  |
| Q-std                          | 174.68008  |
| Q_loss                         | 95.99395   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 984        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000146   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000822   |
| times/evaluation_paths         | 35.1       |
| times/timestep_after_hook      | 0.004      |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 59.5       |
| timestep                       | 1000       |
| timesteps_total                | 985000     |
| train-steps                    | 985000     |
| training/Q/q1_loss             | 112.7168   |
| training/sac_pi/alpha          | 0.16679692 |
| training/sac_pi/alpha_loss     | 0.3766959  |
| training/sac_pi/logp_pi        | 4.985597   |
| training/sac_pi/pi_entropy     | 3.591544   |
| training/sac_pi/pi_global_norm | 1.4419672  |
| training/sac_pi/policy_loss    | -224.15706 |
| training/sac_pi/std            | 0.53359985 |
| training/sac_pi/valid_num      | 4932.0     |
| training/sac_Q/q1              | 212.16568  |
| training/sac_Q/q2              | 210.85408  |
| training/sac_Q/q2_loss         | 112.02009  |
| training/sac_Q/q_global_norm   | 236.21587  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1646765   |
| epoch                          | 985         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4774.8555   |
| evaluation/return-max          | 4864.38     |
| evaluation/return-min          | 4745.243    |
| evaluation/return-std          | 33.981804   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46246       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4774.8555   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 210.24004   |
| Q-std                          | 166.56377   |
| Q_loss                         | 127.365524  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 985         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000274    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000598    |
| times/evaluation_paths         | 34.2        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 59.3        |
| timestep                       | 1000        |
| timesteps_total                | 986000      |
| train-steps                    | 986000      |
| training/Q/q1_loss             | 99.95676    |
| training/sac_pi/alpha          | 0.1647075   |
| training/sac_pi/alpha_loss     | -0.10131625 |
| training/sac_pi/logp_pi        | 4.595437    |
| training/sac_pi/pi_entropy     | 3.256678    |
| training/sac_pi/pi_global_norm | 1.5489724   |
| training/sac_pi/policy_loss    | -223.50804  |
| training/sac_pi/std            | 0.48612636  |
| training/sac_pi/valid_num      | 4924.0      |
| training/sac_Q/q1              | 210.8457    |
| training/sac_Q/q2              | 208.89648   |
| training/sac_Q/q2_loss         | 100.82752   |
| training/sac_Q/q_global_norm   | 297.07693   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16374078 |
| epoch                          | 986        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4999.6045  |
| evaluation/return-max          | 5033.8174  |
| evaluation/return-min          | 4961.2974  |
| evaluation/return-std          | 20.748045  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46305      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4999.6045  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 215.95224  |
| Q-std                          | 130.09615  |
| Q_loss                         | 88.98244   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 986        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000589   |
| times/evaluation_paths         | 33.3       |
| times/timestep_after_hook      | 0.00396    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 987000     |
| train-steps                    | 987000     |
| training/Q/q1_loss             | 105.528786 |
| training/sac_pi/alpha          | 0.16370945 |
| training/sac_pi/alpha_loss     | 0.24776731 |
| training/sac_pi/logp_pi        | 3.930365   |
| training/sac_pi/pi_entropy     | 3.4490592  |
| training/sac_pi/pi_global_norm | 1.6864169  |
| training/sac_pi/policy_loss    | -223.23264 |
| training/sac_pi/std            | 0.48503652 |
| training/sac_pi/valid_num      | 4960.0     |
| training/sac_Q/q1              | 212.64742  |
| training/sac_Q/q2              | 213.25725  |
| training/sac_Q/q2_loss         | 105.503746 |
| training/sac_Q/q_global_norm   | 277.43723  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16786747  |
| epoch                          | 987         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4949.878    |
| evaluation/return-max          | 4977.7817   |
| evaluation/return-min          | 4910.2974   |
| evaluation/return-std          | 21.47321    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46229       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4949.878    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 210.9058    |
| Q-std                          | 136.7537    |
| Q_loss                         | 109.17413   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 987         |
| times/epoch_after_hook         | 2.1e-06     |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000534    |
| times/evaluation_paths         | 33.2        |
| times/timestep_after_hook      | 0.00411     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 988000      |
| train-steps                    | 988000      |
| training/Q/q1_loss             | 91.550674   |
| training/sac_pi/alpha          | 0.1678437   |
| training/sac_pi/alpha_loss     | -0.14301272 |
| training/sac_pi/logp_pi        | 4.4274573   |
| training/sac_pi/pi_entropy     | 3.3269658   |
| training/sac_pi/pi_global_norm | 1.633352    |
| training/sac_pi/policy_loss    | -229.40344  |
| training/sac_pi/std            | 0.48985693  |
| training/sac_pi/valid_num      | 4932.0      |
| training/sac_Q/q1              | 218.18364   |
| training/sac_Q/q2              | 215.88193   |
| training/sac_Q/q2_loss         | 90.94103    |
| training/sac_Q/q_global_norm   | 315.53943   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16737743   |
| epoch                          | 988          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4967.8735    |
| evaluation/return-max          | 5073.4355    |
| evaluation/return-min          | 4898.8555    |
| evaluation/return-std          | 51.774513    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.04         |
| model/origin_ret               | 85.6         |
| model/penalty_ret              | 80.4         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46169        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4967.8735    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 208.26675    |
| Q-std                          | 120.54308    |
| Q_loss                         | 98.729996    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 988          |
| times/epoch_after_hook         | 1.92e-06     |
| times/epoch_before_hook        | 0.000137     |
| times/epoch_rollout_model      | 481          |
| times/evaluation_metrics       | 0.000632     |
| times/evaluation_paths         | 35.4         |
| times/timestep_after_hook      | 0.00394      |
| times/timestep_before_hook     | 0.00829      |
| times/train                    | 60.1         |
| timestep                       | 1000         |
| timesteps_total                | 989000       |
| train-steps                    | 989000       |
| training/Q/q1_loss             | 98.68008     |
| training/sac_pi/alpha          | 0.16739166   |
| training/sac_pi/alpha_loss     | -0.112333894 |
| training/sac_pi/logp_pi        | 4.06573      |
| training/sac_pi/pi_entropy     | 3.4886298    |
| training/sac_pi/pi_global_norm | 1.5629518    |
| training/sac_pi/policy_loss    | -218.51181   |
| training/sac_pi/std            | 0.49959135   |
| training/sac_pi/valid_num      | 4911.0       |
| training/sac_Q/q1              | 206.68246    |
| training/sac_Q/q2              | 206.18716    |
| training/sac_Q/q2_loss         | 98.70723     |
| training/sac_Q/q_global_norm   | 191.90504    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1695764  |
| epoch                          | 989        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4930.281   |
| evaluation/return-max          | 4961.963   |
| evaluation/return-min          | 4854.8213  |
| evaluation/return-std          | 30.423136  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46347      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4930.281   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 201.20523  |
| Q-std                          | 165.15442  |
| Q_loss                         | 110.12247  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 989        |
| times/epoch_after_hook         | 2.47e-06   |
| times/epoch_before_hook        | 0.000283   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000852   |
| times/evaluation_paths         | 34.1       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 59.1       |
| timestep                       | 1000       |
| timesteps_total                | 990000     |
| train-steps                    | 990000     |
| training/Q/q1_loss             | 96.47017   |
| training/sac_pi/alpha          | 0.16957693 |
| training/sac_pi/alpha_loss     | 0.2796136  |
| training/sac_pi/logp_pi        | 3.653958   |
| training/sac_pi/pi_entropy     | 3.512301   |
| training/sac_pi/pi_global_norm | 1.5014219  |
| training/sac_pi/policy_loss    | -224.03557 |
| training/sac_pi/std            | 0.46897933 |
| training/sac_pi/valid_num      | 5023.0     |
| training/sac_Q/q1              | 219.8934   |
| training/sac_Q/q2              | 219.98743  |
| training/sac_Q/q2_loss         | 96.50973   |
| training/sac_Q/q_global_norm   | 198.14491  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17181301  |
| epoch                          | 990         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4996.4727   |
| evaluation/return-max          | 5079.4146   |
| evaluation/return-min          | 4920.4727   |
| evaluation/return-std          | 43.931225   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46164       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4996.4727   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 211.04166   |
| Q-std                          | 148.78409   |
| Q_loss                         | 102.68204   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 990         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 501         |
| times/evaluation_metrics       | 0.000662    |
| times/evaluation_paths         | 33.8        |
| times/timestep_after_hook      | 0.004       |
| times/timestep_before_hook     | 0.0104      |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 991000      |
| train-steps                    | 991000      |
| training/Q/q1_loss             | 96.728195   |
| training/sac_pi/alpha          | 0.17185159  |
| training/sac_pi/alpha_loss     | -0.48524892 |
| training/sac_pi/logp_pi        | 4.113694    |
| training/sac_pi/pi_entropy     | 3.5915275   |
| training/sac_pi/pi_global_norm | 1.5721936   |
| training/sac_pi/policy_loss    | -214.89502  |
| training/sac_pi/std            | 0.5017921   |
| training/sac_pi/valid_num      | 4959.0      |
| training/sac_Q/q1              | 204.78752   |
| training/sac_Q/q2              | 204.80766   |
| training/sac_Q/q2_loss         | 96.35221    |
| training/sac_Q/q_global_norm   | 271.91354   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1679253  |
| epoch                          | 991        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4795.4756  |
| evaluation/return-max          | 4880.137   |
| evaluation/return-min          | 4707.24    |
| evaluation/return-std          | 51.08193   |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.8       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46334      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4795.4756  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 218.9426   |
| Q-std                          | 113.17074  |
| Q_loss                         | 104.9553   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 991        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000241   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000531   |
| times/evaluation_paths         | 33.2       |
| times/timestep_after_hook      | 0.00427    |
| times/timestep_before_hook     | 0.0086     |
| times/train                    | 62.7       |
| timestep                       | 1000       |
| timesteps_total                | 992000     |
| train-steps                    | 992000     |
| training/Q/q1_loss             | 107.33519  |
| training/sac_pi/alpha          | 0.16790463 |
| training/sac_pi/alpha_loss     | 0.08313053 |
| training/sac_pi/logp_pi        | 4.970188   |
| training/sac_pi/pi_entropy     | 3.7420392  |
| training/sac_pi/pi_global_norm | 1.6727643  |
| training/sac_pi/policy_loss    | -210.12923 |
| training/sac_pi/std            | 0.5647724  |
| training/sac_pi/valid_num      | 4953.0     |
| training/sac_Q/q1              | 197.68376  |
| training/sac_Q/q2              | 198.90895  |
| training/sac_Q/q2_loss         | 106.313255 |
| training/sac_Q/q_global_norm   | 233.44514  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16491121  |
| epoch                          | 992         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4975.8647   |
| evaluation/return-max          | 5056.6445   |
| evaluation/return-min          | 4832.9297   |
| evaluation/return-std          | 56.078606   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46338       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4975.8647   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 207.65112   |
| Q-std                          | 142.30765   |
| Q_loss                         | 84.0376     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 992         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000117    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000512    |
| times/evaluation_paths         | 34.2        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 60.2        |
| timestep                       | 1000        |
| timesteps_total                | 993000      |
| train-steps                    | 993000      |
| training/Q/q1_loss             | 79.86674    |
| training/sac_pi/alpha          | 0.16492839  |
| training/sac_pi/alpha_loss     | -0.07510227 |
| training/sac_pi/logp_pi        | 4.599192    |
| training/sac_pi/pi_entropy     | 3.662381    |
| training/sac_pi/pi_global_norm | 1.6042303   |
| training/sac_pi/policy_loss    | -214.15733  |
| training/sac_pi/std            | 0.53704053  |
| training/sac_pi/valid_num      | 4956.0      |
| training/sac_Q/q1              | 195.35188   |
| training/sac_Q/q2              | 199.60295   |
| training/sac_Q/q2_loss         | 80.11722    |
| training/sac_Q/q_global_norm   | 190.42131   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16318806   |
| epoch                          | 993          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4990.7104    |
| evaluation/return-max          | 5038.087     |
| evaluation/return-min          | 4954.2163    |
| evaluation/return-std          | 21.708807    |
| model/max_penalty              | 7.27         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.04         |
| model/origin_ret               | 86.1         |
| model/penalty_ret              | 80.8         |
| model/val_loss                 | 0.39125705   |
| model/valid_num                | 46229        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4990.7104    |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 221.78699    |
| Q-std                          | 125.78362    |
| Q_loss                         | 98.08182     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 993          |
| times/epoch_after_hook         | 1.92e-06     |
| times/epoch_before_hook        | 0.000301     |
| times/epoch_rollout_model      | 488          |
| times/evaluation_metrics       | 0.000614     |
| times/evaluation_paths         | 30.8         |
| times/timestep_after_hook      | 0.00395      |
| times/timestep_before_hook     | 0.00824      |
| times/train                    | 55.9         |
| timestep                       | 1000         |
| timesteps_total                | 994000       |
| train-steps                    | 994000       |
| training/Q/q1_loss             | 82.51429     |
| training/sac_pi/alpha          | 0.16318011   |
| training/sac_pi/alpha_loss     | -0.025613613 |
| training/sac_pi/logp_pi        | 4.4027014    |
| training/sac_pi/pi_entropy     | 3.4752746    |
| training/sac_pi/pi_global_norm | 1.7248563    |
| training/sac_pi/policy_loss    | -229.6426    |
| training/sac_pi/std            | 0.5168672    |
| training/sac_pi/valid_num      | 4946.0       |
| training/sac_Q/q1              | 216.67343    |
| training/sac_Q/q2              | 217.37553    |
| training/sac_Q/q2_loss         | 84.324       |
| training/sac_Q/q_global_norm   | 209.61996    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16482559  |
| epoch                          | 994         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5128.4937   |
| evaluation/return-max          | 5160.4478   |
| evaluation/return-min          | 5088.999    |
| evaluation/return-std          | 24.564894   |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46142       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5128.4937   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 226.93384   |
| Q-std                          | 89.66715    |
| Q_loss                         | 93.94902    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 994         |
| times/epoch_after_hook         | 1.62e-06    |
| times/epoch_before_hook        | 0.000151    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000506    |
| times/evaluation_paths         | 31.9        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 56.9        |
| timestep                       | 1000        |
| timesteps_total                | 995000      |
| train-steps                    | 995000      |
| training/Q/q1_loss             | 80.486725   |
| training/sac_pi/alpha          | 0.16480948  |
| training/sac_pi/alpha_loss     | -0.07360953 |
| training/sac_pi/logp_pi        | 3.374508    |
| training/sac_pi/pi_entropy     | 3.5166976   |
| training/sac_pi/pi_global_norm | 1.5457957   |
| training/sac_pi/policy_loss    | -221.61728  |
| training/sac_pi/std            | 0.46793634  |
| training/sac_pi/valid_num      | 5020.0      |
| training/sac_Q/q1              | 217.15878   |
| training/sac_Q/q2              | 217.52054   |
| training/sac_Q/q2_loss         | 81.02388    |
| training/sac_Q/q_global_norm   | 232.39485   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1645872  |
| epoch                          | 995        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5279.324   |
| evaluation/return-max          | 5292.732   |
| evaluation/return-min          | 5257.7026  |
| evaluation/return-std          | 10.684519  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46104      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5279.324   |
| perf/NormalizedReturn          | 1.15       |
| Q-avg                          | 206.77641  |
| Q-std                          | 147.96785  |
| Q_loss                         | 106.37255  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 995        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000643   |
| times/evaluation_paths         | 31.3       |
| times/timestep_after_hook      | 0.00405    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 55.9       |
| timestep                       | 1000       |
| timesteps_total                | 996000     |
| train-steps                    | 996000     |
| training/Q/q1_loss             | 78.91996   |
| training/sac_pi/alpha          | 0.16457933 |
| training/sac_pi/alpha_loss     | 0.30049467 |
| training/sac_pi/logp_pi        | 4.3780413  |
| training/sac_pi/pi_entropy     | 3.2397296  |
| training/sac_pi/pi_global_norm | 1.989731   |
| training/sac_pi/policy_loss    | -234.67836 |
| training/sac_pi/std            | 0.4692082  |
| training/sac_pi/valid_num      | 4985.0     |
| training/sac_Q/q1              | 226.12337  |
| training/sac_Q/q2              | 226.84981  |
| training/sac_Q/q2_loss         | 79.35307   |
| training/sac_Q/q_global_norm   | 230.49423  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16286328 |
| epoch                          | 996        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5112.0537  |
| evaluation/return-max          | 5168.87    |
| evaluation/return-min          | 5028.9546  |
| evaluation/return-std          | 45.040234  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46259      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5112.0537  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 213.64584  |
| Q-std                          | 156.56427  |
| Q_loss                         | 100.72219  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 996        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000139   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000515   |
| times/evaluation_paths         | 32.3       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 57.4       |
| timestep                       | 1000       |
| timesteps_total                | 997000     |
| train-steps                    | 997000     |
| training/Q/q1_loss             | 97.75162   |
| training/sac_pi/alpha          | 0.16282974 |
| training/sac_pi/alpha_loss     | 0.21035735 |
| training/sac_pi/logp_pi        | 3.8887386  |
| training/sac_pi/pi_entropy     | 3.4380348  |
| training/sac_pi/pi_global_norm | 1.4353365  |
| training/sac_pi/policy_loss    | -219.99165 |
| training/sac_pi/std            | 0.48365757 |
| training/sac_pi/valid_num      | 5020.0     |
| training/sac_Q/q1              | 211.94131  |
| training/sac_Q/q2              | 213.2114   |
| training/sac_Q/q2_loss         | 97.501434  |
| training/sac_Q/q_global_norm   | 202.6243   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16726722 |
| epoch                          | 997        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5250.9507  |
| evaluation/return-max          | 5324.793   |
| evaluation/return-min          | 5155.177   |
| evaluation/return-std          | 60.120003  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46402      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5250.9507  |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 211.93692  |
| Q-std                          | 117.23367  |
| Q_loss                         | 124.57192  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 997        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000253   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000585   |
| times/evaluation_paths         | 31.3       |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 56.1       |
| timestep                       | 1000       |
| timesteps_total                | 998000     |
| train-steps                    | 998000     |
| training/Q/q1_loss             | 103.913185 |
| training/sac_pi/alpha          | 0.16726945 |
| training/sac_pi/alpha_loss     | 0.11491599 |
| training/sac_pi/logp_pi        | 4.2056274  |
| training/sac_pi/pi_entropy     | 3.5474648  |
| training/sac_pi/pi_global_norm | 1.6407337  |
| training/sac_pi/policy_loss    | -222.6628  |
| training/sac_pi/std            | 0.5040944  |
| training/sac_pi/valid_num      | 4981.0     |
| training/sac_Q/q1              | 210.54802  |
| training/sac_Q/q2              | 211.58125  |
| training/sac_Q/q2_loss         | 104.57519  |
| training/sac_Q/q_global_norm   | 290.41855  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16417421  |
| epoch                          | 998         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5135.159    |
| evaluation/return-max          | 5228.4927   |
| evaluation/return-min          | 5055.6494   |
| evaluation/return-std          | 46.63308    |
| model/max_penalty              | 7.27        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86          |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.39125705  |
| model/valid_num                | 46368       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5135.159    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 219.99023   |
| Q-std                          | 126.75849   |
| Q_loss                         | 100.81895   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 998         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000136    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000621    |
| times/evaluation_paths         | 31.5        |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 55          |
| timestep                       | 1000        |
| timesteps_total                | 999000      |
| train-steps                    | 999000      |
| training/Q/q1_loss             | 91.16566    |
| training/sac_pi/alpha          | 0.16420485  |
| training/sac_pi/alpha_loss     | -0.25650862 |
| training/sac_pi/logp_pi        | 3.7221227   |
| training/sac_pi/pi_entropy     | 3.6290169   |
| training/sac_pi/pi_global_norm | 1.5933732   |
| training/sac_pi/policy_loss    | -223.24664  |
| training/sac_pi/std            | 0.50023663  |
| training/sac_pi/valid_num      | 4907.0      |
| training/sac_Q/q1              | 214.15385   |
| training/sac_Q/q2              | 212.77591   |
| training/sac_Q/q2_loss         | 92.01285    |
| training/sac_Q/q_global_norm   | 323.49536   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16805166 |
| epoch                          | 999        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4874.6074  |
| evaluation/return-max          | 4903.862   |
| evaluation/return-min          | 4850.3857  |
| evaluation/return-std          | 16.672684  |
| model/max_penalty              | 7.27       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.39125705 |
| model/valid_num                | 46349      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4874.6074  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 224.7814   |
| Q-std                          | 108.74058  |
| Q_loss                         | 106.876076 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 999        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000518   |
| times/evaluation_paths         | 32.5       |
| times/timestep_after_hook      | 0.00391    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 56         |
| timestep                       | 1000       |
| timesteps_total                | 1000000    |
| train-steps                    | 1000000    |
| training/Q/q1_loss             | 110.73345  |
| training/sac_pi/alpha          | 0.16804881 |
| training/sac_pi/alpha_loss     | 0.09873071 |
| training/sac_pi/logp_pi        | 5.088534   |
| training/sac_pi/pi_entropy     | 3.363687   |
| training/sac_pi/pi_global_norm | 1.5514833  |
| training/sac_pi/policy_loss    | -221.88042 |
| training/sac_pi/std            | 0.51266026 |
| training/sac_pi/valid_num      | 4933.0     |
| training/sac_Q/q1              | 205.23584  |
| training/sac_Q/q2              | 205.88205  |
| training/sac_Q/q2_loss         | 110.48386  |
| training/sac_Q/q_global_norm   | 271.76     |
--------------------------------------------------------------------------------
