Logging to /nfs/project/chenxionghui/proj/MAPLE/log/v2_examples.config.d4rl.walker2d_medium_expert/2022/01/01/15-42-56-985568 10.83.150.44 &info=test-4&model_suffix=200&penalty_coeff=0.25&length=20&maple_200=True&run_params.seed=888&penalty_clip=20/
log dir: /nfs/project/chenxionghui/proj/MAPLE/log/v2_examples.config.d4rl.walker2d_medium_expert/2022/01/01/15-42-56-985568 10.83.150.44 &info=test-4&model_suffix=200&penalty_coeff=0.25&length=20&maple_200=True&run_params.seed=888&penalty_clip=20/
pkl_file: /nfs/project/chenxionghui/proj/MAPLE/archive_tester/v2_examples.config.d4rl.walker2d_medium_expert/2022/01/01/15-42-56-985568 10.83.150.44 &info=test-4&model_suffix=200&penalty_coeff=0.25&length=20&maple_200=True&run_params.seed=888&penalty_clip=20.pkl
checkpoint_dir: /nfs/project/chenxionghui/proj/MAPLE/checkpoint/v2_examples.config.d4rl.walker2d_medium_expert/2022/01/01/15-42-56-985568 10.83.150.44 &info=test-4&model_suffix=200&penalty_coeff=0.25&length=20&maple_200=True&run_params.seed=888&penalty_clip=20/
results_dir: /nfs/project/chenxionghui/proj/MAPLE/results/v2_examples.config.d4rl.walker2d_medium_expert/2022/01/01/15-42-56-985568 10.83.150.44 &info=test-4&model_suffix=200&penalty_coeff=0.25&length=20&maple_200=True&run_params.seed=888&penalty_clip=20/
key: Q_params, value: {'type': 'double_feedforward_Q_function', 'kwargs': {'hidden_layer_sizes': (256, 256)}}
key: algorithm_params, value: DotMap(type='MAPLE', universe='gym', kwargs=DotMap(epoch_length=1000, train_every_n_steps=1, n_train_repeat=1, eval_render_mode=None, eval_n_episodes=10, eval_deterministic=True, discount=0.99, tau=0.005, reward_scale=1.0, model_train_freq=1000, model_retain_epochs=5, rollout_batch_size=50000.0, deterministic=False, num_networks=7, num_elites=5, real_ratio=0.05, target_entropy=-3, max_model_t=None, separate_mean_var=True, penalty_learned_var=True, pool_load_path='d4rl/walker2d-medium-expert-v0', pool_load_max_size=2000000, rollout_length=1, penalty_coeff=2.0, reparameterize=True, lr=0.0003, target_update_interval=1, store_extra_policy_info=False, action_prior='uniform', n_initial_exploration_steps=5000, model_load_dir='/nfs/project/chenxionghui/proj/MAPLE/models', network_kwargs=DotMap(hidden_sizes=[256, 256], activation=<function relu at 0x7fcf1e06d3b0>, output_activation=None, lstm_hidden_unit=128, embedding_size=16)), domain='walker2d', task='medium-expert-v0', exp_name='walker2d_medium_expert')
key: config, value: examples.config.d4rl.walker2d_medium_expert
key: custom_config, value: False
key: elite_num, value: -1
key: emb_size, value: 16
key: environment_params, value: {'training': {'domain': 'walker2d', 'task': 'medium-expert-v0', 'universe': 'gym', 'kwargs': {'use_neorl': False}}, 'evaluation': <function get_variant_spec_base.<locals>.<lambda> at 0x7fcf8752f560>}
key: info, value: test-4
key: length, value: 20
key: load_date, value: 
key: load_task_name, value: 
key: maple_200, value: True
key: model_suffix, value: 200
key: n_epochs, value: 1000
key: not_inherit_hp, value: True
key: penalty_clip, value: 20
key: penalty_coeff, value: 0.25
key: policy, value: gaussian
key: policy_params, value: {'type': 'GaussianPolicy', 'kwargs': {'hidden_layer_sizes': (256, 256), 'squash': True}}
key: replay_pool_params, value: {'type': 'SimpleReplayPool', 'kwargs': {'max_size': <function get_variant_spec_base.<locals>.<lambda> at 0x7fcf8752f3b0>}}
key: retrain_model, value: False
key: run_params, value: {'seed': 888, 'checkpoint_at_end': True, 'checkpoint_frequency': 20, 'checkpoint_replay_pool': False, 'info': ''}
key: sampler_params, value: {'type': 'SimpleSampler', 'kwargs': {'max_path_length': 1000, 'min_pool_size': 1000, 'batch_size': 256}}
key: seed, value: 888
save variable :
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/Scaler/scaler_mu:0' shape=(1, 23) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/Scaler/scaler_std:0' shape=(1, 23) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/max_log_var:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/min_log_var:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/Layer0_mean/FC_weights:0' shape=(200, 23, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/Layer0_mean/FC_biases:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/Layer1_mean/FC_weights:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/Layer1_mean/FC_biases:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/Layer2_mean/FC_weights:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/Layer2_mean/FC_biases:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/Layer3_mean/FC_weights:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/Layer3_mean/FC_biases:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/Layer4_mean/FC_weights:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/Layer4_mean/FC_biases:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/Layer0_var/FC_weights:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/Layer0_var/FC_biases:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200_1/beta1_power:0' shape=() dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200_1/beta2_power:0' shape=() dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer0_mean/FC_weights/Adam:0' shape=(200, 23, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer0_mean/FC_weights/Adam_1:0' shape=(200, 23, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer0_mean/FC_biases/Adam:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer0_mean/FC_biases/Adam_1:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer1_mean/FC_weights/Adam:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer1_mean/FC_weights/Adam_1:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer1_mean/FC_biases/Adam:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer1_mean/FC_biases/Adam_1:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer2_mean/FC_weights/Adam:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer2_mean/FC_weights/Adam_1:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer2_mean/FC_biases/Adam:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer2_mean/FC_biases/Adam_1:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer3_mean/FC_weights/Adam:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer3_mean/FC_weights/Adam_1:0' shape=(200, 200, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer3_mean/FC_biases/Adam:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer3_mean/FC_biases/Adam_1:0' shape=(200, 1, 200) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer4_mean/FC_weights/Adam:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer4_mean/FC_weights/Adam_1:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer4_mean/FC_biases/Adam:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer4_mean/FC_biases/Adam_1:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer0_var/FC_weights/Adam:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer0_var/FC_weights/Adam_1:0' shape=(200, 200, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer0_var/FC_biases/Adam:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/Layer0_var/FC_biases/Adam_1:0' shape=(200, 1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/max_log_var/Adam:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/max_log_var/Adam_1:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/min_log_var/Adam:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'walker2d-medium-expert-v0_smv_888_200/walker2d-medium-expert-v0_smv_888_200/min_log_var/Adam_1:0' shape=(1, 18) dtype=float32_ref>
<tf.Variable 'global_step:0' shape=() dtype=int64_ref>
<tf.Variable 'lstm_net_p/rnn/gru_cell/gates/kernel:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_p/rnn/gru_cell/gates/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_p/rnn/gru_cell/candidate/kernel:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_p/rnn/gru_cell/candidate/bias:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_p/dense/kernel:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_p/dense/bias:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/kernel:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/kernel:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/bias:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/kernel:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/bias:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'main/pi/dense/kernel:0' shape=(33, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/kernel:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/bias:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/kernel:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/bias:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'main/q1/dense/kernel:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/kernel:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/bias:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'main/q2/dense/kernel:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/kernel:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/bias:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'target/pi/dense/kernel:0' shape=(33, 256) dtype=float32_ref>
<tf.Variable 'target/pi/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/pi/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'target/pi/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/pi/dense_2/kernel:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'target/pi/dense_2/bias:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'target/pi/dense_3/kernel:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'target/pi/dense_3/bias:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'target/q1/dense/kernel:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'target/q1/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/q1/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'target/q1/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/q1/dense_2/kernel:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'target/q1/dense_2/bias:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'target/q2/dense/kernel:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'target/q2/dense/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/q2/dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'target/q2/dense_1/bias:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'target/q2/dense_2/kernel:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'target/q2/dense_2/bias:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'log_alpha:0' shape=() dtype=float32_ref>
<tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>
<tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>
<tf.Variable 'main/pi/dense/kernel/Adam:0' shape=(33, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense/kernel/Adam_1:0' shape=(33, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/kernel/Adam:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/kernel/Adam_1:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_1/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/kernel/Adam:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/kernel/Adam_1:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/bias/Adam:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_2/bias/Adam_1:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/kernel/Adam:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/kernel/Adam_1:0' shape=(256, 6) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/bias/Adam:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'main/pi/dense_3/bias/Adam_1:0' shape=(6,) dtype=float32_ref>
<tf.Variable 'beta1_power_1:0' shape=() dtype=float32_ref>
<tf.Variable 'beta2_power_1:0' shape=() dtype=float32_ref>
<tf.Variable 'main/q1/dense/kernel/Adam:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense/kernel/Adam_1:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/kernel/Adam:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/kernel/Adam_1:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_1/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/kernel/Adam:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/kernel/Adam_1:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/bias/Adam:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'main/q1/dense_2/bias/Adam_1:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/kernel/Adam:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/kernel/Adam_1:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/kernel/Adam:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/kernel/Adam_1:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/bias/Adam:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/bias/Adam_1:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/kernel/Adam:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/kernel/Adam_1:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/bias/Adam:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/bias/Adam_1:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'beta1_power_2:0' shape=() dtype=float32_ref>
<tf.Variable 'beta2_power_2:0' shape=() dtype=float32_ref>
<tf.Variable 'main/q2/dense/kernel/Adam:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense/kernel/Adam_1:0' shape=(39, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/kernel/Adam:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/kernel/Adam_1:0' shape=(256, 256) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/bias/Adam:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_1/bias/Adam_1:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/kernel/Adam:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/kernel/Adam_1:0' shape=(256, 1) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/bias/Adam:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'main/q2/dense_2/bias/Adam_1:0' shape=(1,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/kernel/Adam_2:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/kernel/Adam_3:0' shape=(151, 256) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/bias/Adam_2:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/gates/bias/Adam_3:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/kernel/Adam_2:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/kernel/Adam_3:0' shape=(151, 128) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/bias/Adam_2:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/rnn/gru_cell/candidate/bias/Adam_3:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/kernel/Adam_2:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/kernel/Adam_3:0' shape=(128, 16) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/bias/Adam_2:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'lstm_net_v/dense/bias/Adam_3:0' shape=(16,) dtype=float32_ref>
<tf.Variable 'beta1_power_3:0' shape=() dtype=float32_ref>
<tf.Variable 'beta2_power_3:0' shape=() dtype=float32_ref>
<tf.Variable 'log_alpha/alpha_optimizer:0' shape=() dtype=float32_ref>
<tf.Variable 'log_alpha/alpha_optimizer_1:0' shape=() dtype=float32_ref>
[WARN] 0 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.7408219  |
| epoch                          | 0          |
| evaluation/episode-length-avg  | 231        |
| evaluation/episode-length-max  | 245        |
| evaluation/episode-length-min  | 216        |
| evaluation/episode-length-std  | 10.9       |
| evaluation/return-average      | 300.8417   |
| evaluation/return-max          | 362.52692  |
| evaluation/return-min          | 172.20107  |
| evaluation/return-std          | 69.90132   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | -4.61      |
| model/origin_ret               | 34.9       |
| model/penalty_ret              | 88         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 9401       |
| perf/AverageLength             | 231        |
| perf/AverageReturn             | 300.8417   |
| perf/NormalizedReturn          | 0.0652     |
| Q-avg                          | 11.0922575 |
| Q-std                          | 22.542017  |
| Q_loss                         | 6.8108635  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 0          |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000104   |
| times/epoch_rollout_model      | 508        |
| times/evaluation_metrics       | 0.000516   |
| times/evaluation_paths         | 9.46       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 78.9       |
| timestep                       | 1000       |
| timesteps_total                | 1000       |
| train-steps                    | 1000       |
| training/Q/q1_loss             | 5.9861016  |
| training/sac_pi/alpha          | 0.7410325  |
| training/sac_pi/alpha_loss     | -1.8653508 |
| training/sac_pi/logp_pi        | 7.240135   |
| training/sac_pi/pi_entropy     | 6.995632   |
| training/sac_pi/pi_global_norm | 1.3813863  |
| training/sac_pi/policy_loss    | -21.741217 |
| training/sac_pi/std            | 1.267835   |
| training/sac_pi/valid_num      | 3483.0     |
| training/sac_Q/q1              | 11.898893  |
| training/sac_Q/q2              | 10.283724  |
| training/sac_Q/q2_loss         | 6.001269   |
| training/sac_Q/q_global_norm   | 12.414948  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.56128794 |
| epoch                          | 1          |
| evaluation/episode-length-avg  | 164        |
| evaluation/episode-length-max  | 173        |
| evaluation/episode-length-min  | 158        |
| evaluation/episode-length-std  | 5.46       |
| evaluation/return-average      | 282.5187   |
| evaluation/return-max          | 291.6224   |
| evaluation/return-min          | 275.58252  |
| evaluation/return-std          | 5.643293   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | -0.0553    |
| model/origin_ret               | 65.1       |
| model/penalty_ret              | 101        |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 29028      |
| perf/AverageLength             | 164        |
| perf/AverageReturn             | 282.5187   |
| perf/NormalizedReturn          | 0.0612     |
| Q-avg                          | 20.725536  |
| Q-std                          | 32.27127   |
| Q_loss                         | 10.964879  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 1          |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000266   |
| times/epoch_rollout_model      | 510        |
| times/evaluation_metrics       | 0.000587   |
| times/evaluation_paths         | 8.71       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 77.5       |
| timestep                       | 1000       |
| timesteps_total                | 2000       |
| train-steps                    | 2000       |
| training/Q/q1_loss             | 12.141903  |
| training/sac_pi/alpha          | 0.5614326  |
| training/sac_pi/alpha_loss     | -2.9816687 |
| training/sac_pi/logp_pi        | 6.581604   |
| training/sac_pi/pi_entropy     | 6.694983   |
| training/sac_pi/pi_global_norm | 1.2462718  |
| training/sac_pi/policy_loss    | -34.59254  |
| training/sac_pi/std            | 1.081588   |
| training/sac_pi/valid_num      | 3948.0     |
| training/sac_Q/q1              | 23.36839   |
| training/sac_Q/q2              | 22.484425  |
| training/sac_Q/q2_loss         | 12.21774   |
| training/sac_Q/q_global_norm   | 38.400295  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.43065822 |
| epoch                          | 2          |
| evaluation/episode-length-avg  | 177        |
| evaluation/episode-length-max  | 188        |
| evaluation/episode-length-min  | 166        |
| evaluation/episode-length-std  | 6.38       |
| evaluation/return-average      | 301.75217  |
| evaluation/return-max          | 313.24548  |
| evaluation/return-min          | 289.58167  |
| evaluation/return-std          | 7.1794357  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 1.2        |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 105        |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 31774      |
| perf/AverageLength             | 177        |
| perf/AverageReturn             | 301.75217  |
| perf/NormalizedReturn          | 0.0654     |
| Q-avg                          | 34.881336  |
| Q-std                          | 36.85464   |
| Q_loss                         | 18.613554  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 2          |
| times/epoch_after_hook         | 1.57e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000473   |
| times/evaluation_paths         | 8.25       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 65.8       |
| timestep                       | 1000       |
| timesteps_total                | 3000       |
| train-steps                    | 3000       |
| training/Q/q1_loss             | 18.440863  |
| training/sac_pi/alpha          | 0.43076885 |
| training/sac_pi/alpha_loss     | -3.7786746 |
| training/sac_pi/logp_pi        | 6.7804823  |
| training/sac_pi/pi_entropy     | 6.476786   |
| training/sac_pi/pi_global_norm | 1.0574064  |
| training/sac_pi/policy_loss    | -44.61929  |
| training/sac_pi/std            | 1.0590855  |
| training/sac_pi/valid_num      | 4027.0     |
| training/sac_Q/q1              | 33.930656  |
| training/sac_Q/q2              | 32.631447  |
| training/sac_Q/q2_loss         | 18.397945  |
| training/sac_Q/q_global_norm   | 72.68794   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.3301494  |
| epoch                          | 3          |
| evaluation/episode-length-avg  | 207        |
| evaluation/episode-length-max  | 235        |
| evaluation/episode-length-min  | 189        |
| evaluation/episode-length-std  | 13.5       |
| evaluation/return-average      | 340.7144   |
| evaluation/return-max          | 368.67023  |
| evaluation/return-min          | 323.128    |
| evaluation/return-std          | 13.738739  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.22       |
| model/origin_ret               | 88.9       |
| model/penalty_ret              | 101        |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 39903      |
| perf/AverageLength             | 207        |
| perf/AverageReturn             | 340.7144   |
| perf/NormalizedReturn          | 0.0739     |
| Q-avg                          | 41.390816  |
| Q-std                          | 40.32342   |
| Q_loss                         | 24.772442  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 3          |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000488   |
| times/evaluation_paths         | 9.65       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 65.4       |
| timestep                       | 1000       |
| timesteps_total                | 4000       |
| train-steps                    | 4000       |
| training/Q/q1_loss             | 22.254967  |
| training/sac_pi/alpha          | 0.33023503 |
| training/sac_pi/alpha_loss     | -4.7138023 |
| training/sac_pi/logp_pi        | 5.582594   |
| training/sac_pi/pi_entropy     | 6.1313972  |
| training/sac_pi/pi_global_norm | 1.7969712  |
| training/sac_pi/policy_loss    | -50.8428   |
| training/sac_pi/std            | 0.96217847 |
| training/sac_pi/valid_num      | 4277.0     |
| training/sac_Q/q1              | 40.98385   |
| training/sac_Q/q2              | 39.732063  |
| training/sac_Q/q2_loss         | 22.016815  |
| training/sac_Q/q_global_norm   | 52.713863  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.25879315 |
| epoch                          | 4          |
| evaluation/episode-length-avg  | 190        |
| evaluation/episode-length-max  | 219        |
| evaluation/episode-length-min  | 172        |
| evaluation/episode-length-std  | 13.2       |
| evaluation/return-average      | 304.28778  |
| evaluation/return-max          | 337.21167  |
| evaluation/return-min          | 283.65997  |
| evaluation/return-std          | 14.643867  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.32       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 94         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 41408      |
| perf/AverageLength             | 190        |
| perf/AverageReturn             | 304.28778  |
| perf/NormalizedReturn          | 0.0659     |
| Q-avg                          | 52.749123  |
| Q-std                          | 42.73387   |
| Q_loss                         | 26.97274   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 4          |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000119   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000491   |
| times/evaluation_paths         | 8.83       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00851    |
| times/train                    | 68         |
| timestep                       | 1000       |
| timesteps_total                | 5000       |
| train-steps                    | 5000       |
| training/Q/q1_loss             | 27.870836  |
| training/sac_pi/alpha          | 0.25885305 |
| training/sac_pi/alpha_loss     | -4.0081997 |
| training/sac_pi/logp_pi        | 4.9857087  |
| training/sac_pi/pi_entropy     | 5.1682215  |
| training/sac_pi/pi_global_norm | 0.8839217  |
| training/sac_pi/policy_loss    | -62.30062  |
| training/sac_pi/std            | 0.77056366 |
| training/sac_pi/valid_num      | 4477.0     |
| training/sac_Q/q1              | 52.056274  |
| training/sac_Q/q2              | 51.51412   |
| training/sac_Q/q2_loss         | 27.66039   |
| training/sac_Q/q_global_norm   | 56.38246   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.20294125 |
| epoch                          | 5          |
| evaluation/episode-length-avg  | 187        |
| evaluation/episode-length-max  | 200        |
| evaluation/episode-length-min  | 166        |
| evaluation/episode-length-std  | 11.3       |
| evaluation/return-average      | 313.57892  |
| evaluation/return-max          | 328.346    |
| evaluation/return-min          | 291.66296  |
| evaluation/return-std          | 11.984586  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.4        |
| model/origin_ret               | 81.9       |
| model/penalty_ret              | 89.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 43771      |
| perf/AverageLength             | 187        |
| perf/AverageReturn             | 313.57892  |
| perf/NormalizedReturn          | 0.068      |
| Q-avg                          | 58.448265  |
| Q-std                          | 42.718872  |
| Q_loss                         | 29.265617  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 5          |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.00031    |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000447   |
| times/evaluation_paths         | 6.96       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00858    |
| times/train                    | 67.3       |
| timestep                       | 1000       |
| timesteps_total                | 6000       |
| train-steps                    | 6000       |
| training/Q/q1_loss             | 30.0312    |
| training/sac_pi/alpha          | 0.20298764 |
| training/sac_pi/alpha_loss     | -3.7427082 |
| training/sac_pi/logp_pi        | 3.0249827  |
| training/sac_pi/pi_entropy     | 4.469455   |
| training/sac_pi/pi_global_norm | 1.2452486  |
| training/sac_pi/policy_loss    | -68.18845  |
| training/sac_pi/std            | 0.61823744 |
| training/sac_pi/valid_num      | 4733.0     |
| training/sac_Q/q1              | 62.04368   |
| training/sac_Q/q2              | 62.01065   |
| training/sac_Q/q2_loss         | 30.135431  |
| training/sac_Q/q_global_norm   | 91.4803    |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1607324  |
| epoch                          | 6          |
| evaluation/episode-length-avg  | 113        |
| evaluation/episode-length-max  | 115        |
| evaluation/episode-length-min  | 111        |
| evaluation/episode-length-std  | 1.14       |
| evaluation/return-average      | 224.604    |
| evaluation/return-max          | 227.66594  |
| evaluation/return-min          | 221.67593  |
| evaluation/return-std          | 1.6547072  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.82       |
| model/origin_ret               | 89.3       |
| model/penalty_ret              | 91.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 44376      |
| perf/AverageLength             | 113        |
| perf/AverageReturn             | 224.604    |
| perf/NormalizedReturn          | 0.0486     |
| Q-avg                          | 73.34665   |
| Q-std                          | 40.39141   |
| Q_loss                         | 29.158323  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 6          |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000404   |
| times/evaluation_paths         | 4.11       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00873    |
| times/train                    | 67         |
| timestep                       | 1000       |
| timesteps_total                | 7000       |
| train-steps                    | 7000       |
| training/Q/q1_loss             | 29.722319  |
| training/sac_pi/alpha          | 0.16076674 |
| training/sac_pi/alpha_loss     | -3.0918221 |
| training/sac_pi/logp_pi        | 3.3315988  |
| training/sac_pi/pi_entropy     | 3.7843876  |
| training/sac_pi/pi_global_norm | 1.0111201  |
| training/sac_pi/policy_loss    | -81.358894 |
| training/sac_pi/std            | 0.52849686 |
| training/sac_pi/valid_num      | 4807.0     |
| training/sac_Q/q1              | 75.38176   |
| training/sac_Q/q2              | 75.551186  |
| training/sac_Q/q2_loss         | 29.773905  |
| training/sac_Q/q_global_norm   | 106.664314 |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13314447 |
| epoch                          | 7          |
| evaluation/episode-length-avg  | 91.3       |
| evaluation/episode-length-max  | 94         |
| evaluation/episode-length-min  | 90         |
| evaluation/episode-length-std  | 1.1        |
| evaluation/return-average      | 189.06998  |
| evaluation/return-max          | 192.34038  |
| evaluation/return-min          | 185.58691  |
| evaluation/return-std          | 2.2267172  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.81       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 85.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45133      |
| perf/AverageLength             | 91.3       |
| perf/AverageReturn             | 189.06998  |
| perf/NormalizedReturn          | 0.0408     |
| Q-avg                          | 90.32656   |
| Q-std                          | 42.85844   |
| Q_loss                         | 32.80608   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 7          |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 7.89e-05   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000411   |
| times/evaluation_paths         | 3.49       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00854    |
| times/train                    | 66.9       |
| timestep                       | 1000       |
| timesteps_total                | 8000       |
| train-steps                    | 8000       |
| training/Q/q1_loss             | 36.030254  |
| training/sac_pi/alpha          | 0.13316673 |
| training/sac_pi/alpha_loss     | -2.1980617 |
| training/sac_pi/logp_pi        | 4.017628   |
| training/sac_pi/pi_entropy     | 3.3946395  |
| training/sac_pi/pi_global_norm | 0.7780769  |
| training/sac_pi/policy_loss    | -91.017494 |
| training/sac_pi/std            | 0.52048147 |
| training/sac_pi/valid_num      | 4833.0     |
| training/sac_Q/q1              | 85.33532   |
| training/sac_Q/q2              | 85.7289    |
| training/sac_Q/q2_loss         | 36.01268   |
| training/sac_Q/q_global_norm   | 153.32664  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.11940173  |
| epoch                          | 8           |
| evaluation/episode-length-avg  | 256         |
| evaluation/episode-length-max  | 332         |
| evaluation/episode-length-min  | 190         |
| evaluation/episode-length-std  | 46.2        |
| evaluation/return-average      | 165.73518   |
| evaluation/return-max          | 409.86267   |
| evaluation/return-min          | 78.05861    |
| evaluation/return-std          | 92.59802    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.77        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 85.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45183       |
| perf/AverageLength             | 256         |
| perf/AverageReturn             | 165.73518   |
| perf/NormalizedReturn          | 0.0357      |
| Q-avg                          | 92.35625    |
| Q-std                          | 50.772022   |
| Q_loss                         | 34.23609    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 8           |
| times/epoch_after_hook         | 7.58e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000824    |
| times/evaluation_paths         | 11.4        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 65.6        |
| timestep                       | 1000        |
| timesteps_total                | 9000        |
| train-steps                    | 9000        |
| training/Q/q1_loss             | 38.550346   |
| training/sac_pi/alpha          | 0.119413264 |
| training/sac_pi/alpha_loss     | -0.7447466  |
| training/sac_pi/logp_pi        | 3.854034    |
| training/sac_pi/pi_entropy     | 3.1273322   |
| training/sac_pi/pi_global_norm | 1.1321068   |
| training/sac_pi/policy_loss    | -100.62868  |
| training/sac_pi/std            | 0.4560232   |
| training/sac_pi/valid_num      | 4924.0      |
| training/sac_Q/q1              | 96.75307    |
| training/sac_Q/q2              | 97.268616   |
| training/sac_Q/q2_loss         | 38.552055   |
| training/sac_Q/q_global_norm   | 161.38779   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.11337259 |
| epoch                          | 9          |
| evaluation/episode-length-avg  | 252        |
| evaluation/episode-length-max  | 378        |
| evaluation/episode-length-min  | 186        |
| evaluation/episode-length-std  | 56.4       |
| evaluation/return-average      | 138.60681  |
| evaluation/return-max          | 262.32822  |
| evaluation/return-min          | 73.17236   |
| evaluation/return-std          | 55.44977   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.84       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 85.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45190      |
| perf/AverageLength             | 252        |
| perf/AverageReturn             | 138.60681  |
| perf/NormalizedReturn          | 0.0298     |
| Q-avg                          | 105.00303  |
| Q-std                          | 48.857018  |
| Q_loss                         | 30.846859  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 9          |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000264   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000562   |
| times/evaluation_paths         | 9.42       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00852    |
| times/train                    | 64.9       |
| timestep                       | 1000       |
| timesteps_total                | 10000      |
| train-steps                    | 10000      |
| training/Q/q1_loss             | 33.781445  |
| training/sac_pi/alpha          | 0.11336396 |
| training/sac_pi/alpha_loss     | 0.45707276 |
| training/sac_pi/logp_pi        | 4.2011676  |
| training/sac_pi/pi_entropy     | 3.6349704  |
| training/sac_pi/pi_global_norm | 0.74655217 |
| training/sac_pi/policy_loss    | -108.6281  |
| training/sac_pi/std            | 0.49775746 |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 104.8761   |
| training/sac_Q/q2              | 104.892456 |
| training/sac_Q/q2_loss         | 33.662422  |
| training/sac_Q/q_global_norm   | 134.87396  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.105416946 |
| epoch                          | 10          |
| evaluation/episode-length-avg  | 249         |
| evaluation/episode-length-max  | 347         |
| evaluation/episode-length-min  | 189         |
| evaluation/episode-length-std  | 55.9        |
| evaluation/return-average      | 225.64551   |
| evaluation/return-max          | 534.5514    |
| evaluation/return-min          | 76.86388    |
| evaluation/return-std          | 189.2501    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.75        |
| model/origin_ret               | 88.7        |
| model/penalty_ret              | 86.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 44250       |
| perf/AverageLength             | 249         |
| perf/AverageReturn             | 225.64551   |
| perf/NormalizedReturn          | 0.0488      |
| Q-avg                          | 106.9106    |
| Q-std                          | 51.246002   |
| Q_loss                         | 39.10581    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 10          |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000119    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000519    |
| times/evaluation_paths         | 9.17        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00827     |
| times/train                    | 65.2        |
| timestep                       | 1000        |
| timesteps_total                | 11000       |
| train-steps                    | 11000       |
| training/Q/q1_loss             | 46.389965   |
| training/sac_pi/alpha          | 0.10542916  |
| training/sac_pi/alpha_loss     | -0.2498281  |
| training/sac_pi/logp_pi        | 4.299126    |
| training/sac_pi/pi_entropy     | 3.0474217   |
| training/sac_pi/pi_global_norm | 1.2026253   |
| training/sac_pi/policy_loss    | -114.71072  |
| training/sac_pi/std            | 0.4569169   |
| training/sac_pi/valid_num      | 4980.0      |
| training/sac_Q/q1              | 111.39172   |
| training/sac_Q/q2              | 112.191696  |
| training/sac_Q/q2_loss         | 45.970295   |
| training/sac_Q/q_global_norm   | 156.51172   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.11021807  |
| epoch                          | 11          |
| evaluation/episode-length-avg  | 100         |
| evaluation/episode-length-max  | 112         |
| evaluation/episode-length-min  | 93          |
| evaluation/episode-length-std  | 6.29        |
| evaluation/return-average      | -20.18893   |
| evaluation/return-max          | -8.712044   |
| evaluation/return-min          | -38.7888    |
| evaluation/return-std          | 9.206978    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.73        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 85.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 44941       |
| perf/AverageLength             | 100         |
| perf/AverageReturn             | -20.18893   |
| perf/NormalizedReturn          | -0.00475    |
| Q-avg                          | 116.944435  |
| Q-std                          | 56.365337   |
| Q_loss                         | 45.79725    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 11          |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000629    |
| times/evaluation_paths         | 3.43        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.0084      |
| times/train                    | 64.8        |
| timestep                       | 1000        |
| timesteps_total                | 12000       |
| train-steps                    | 12000       |
| training/Q/q1_loss             | 36.879677   |
| training/sac_pi/alpha          | 0.11023449  |
| training/sac_pi/alpha_loss     | -0.34486127 |
| training/sac_pi/logp_pi        | 4.003013    |
| training/sac_pi/pi_entropy     | 3.2766495   |
| training/sac_pi/pi_global_norm | 0.91186965  |
| training/sac_pi/policy_loss    | -124.46783  |
| training/sac_pi/std            | 0.47043556  |
| training/sac_pi/valid_num      | 4957.0      |
| training/sac_Q/q1              | 120.38252   |
| training/sac_Q/q2              | 120.62815   |
| training/sac_Q/q2_loss         | 36.837776   |
| training/sac_Q/q_global_norm   | 94.23319    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.11769781 |
| epoch                          | 12         |
| evaluation/episode-length-avg  | 301        |
| evaluation/episode-length-max  | 400        |
| evaluation/episode-length-min  | 245        |
| evaluation/episode-length-std  | 57.9       |
| evaluation/return-average      | 742.8949   |
| evaluation/return-max          | 1200.4517  |
| evaluation/return-min          | 464.77948  |
| evaluation/return-std          | 280.6613   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.8        |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 86         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45279      |
| perf/AverageLength             | 301        |
| perf/AverageReturn             | 742.8949   |
| perf/NormalizedReturn          | 0.161      |
| Q-avg                          | 131.80948  |
| Q-std                          | 56.909676  |
| Q_loss                         | 52.52497   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 12         |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000538   |
| times/evaluation_paths         | 12.9       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00873    |
| times/train                    | 66.8       |
| timestep                       | 1000       |
| timesteps_total                | 13000      |
| train-steps                    | 13000      |
| training/Q/q1_loss             | 46.889343  |
| training/sac_pi/alpha          | 0.11766274 |
| training/sac_pi/alpha_loss     | 0.7010259  |
| training/sac_pi/logp_pi        | 4.3985453  |
| training/sac_pi/pi_entropy     | 3.7079487  |
| training/sac_pi/pi_global_norm | 0.8670221  |
| training/sac_pi/policy_loss    | -137.00224 |
| training/sac_pi/std            | 0.48928338 |
| training/sac_pi/valid_num      | 5003.0     |
| training/sac_Q/q1              | 134.01778  |
| training/sac_Q/q2              | 134.49661  |
| training/sac_Q/q2_loss         | 46.888935  |
| training/sac_Q/q_global_norm   | 177.22174  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.11947081  |
| epoch                          | 13          |
| evaluation/episode-length-avg  | 162         |
| evaluation/episode-length-max  | 214         |
| evaluation/episode-length-min  | 141         |
| evaluation/episode-length-std  | 26          |
| evaluation/return-average      | 299.20627   |
| evaluation/return-max          | 324.95203   |
| evaluation/return-min          | 273.49612   |
| evaluation/return-std          | 14.249086   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 88.7        |
| model/penalty_ret              | 86.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 44389       |
| perf/AverageLength             | 162         |
| perf/AverageReturn             | 299.20627   |
| perf/NormalizedReturn          | 0.0648      |
| Q-avg                          | 127.86754   |
| Q-std                          | 56.659172   |
| Q_loss                         | 45.8186     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 13          |
| times/epoch_after_hook         | 2.08e-06    |
| times/epoch_before_hook        | 0.000326    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000567    |
| times/evaluation_paths         | 6.05        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00848     |
| times/train                    | 64.4        |
| timestep                       | 1000        |
| timesteps_total                | 14000       |
| train-steps                    | 14000       |
| training/Q/q1_loss             | 56.867928   |
| training/sac_pi/alpha          | 0.11948007  |
| training/sac_pi/alpha_loss     | -0.19422515 |
| training/sac_pi/logp_pi        | 4.3946886   |
| training/sac_pi/pi_entropy     | 3.555387    |
| training/sac_pi/pi_global_norm | 1.066176    |
| training/sac_pi/policy_loss    | -133.57848  |
| training/sac_pi/std            | 0.5037492   |
| training/sac_pi/valid_num      | 4905.0      |
| training/sac_Q/q1              | 128.63268   |
| training/sac_Q/q2              | 128.8844    |
| training/sac_Q/q2_loss         | 56.721878   |
| training/sac_Q/q_global_norm   | 212.45654   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.118000254 |
| epoch                          | 14          |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 1059.483    |
| evaluation/return-max          | 1063.516    |
| evaluation/return-min          | 1053.4465   |
| evaluation/return-std          | 4.0241547   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.7         |
| model/origin_ret               | 83.3        |
| model/penalty_ret              | 84.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45280       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 1059.483    |
| perf/NormalizedReturn          | 0.23        |
| Q-avg                          | 131.32986   |
| Q-std                          | 59.73897    |
| Q_loss                         | 58.394817   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 14          |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000169    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000649    |
| times/evaluation_paths         | 42.6        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00884     |
| times/train                    | 64          |
| timestep                       | 1000        |
| timesteps_total                | 15000       |
| train-steps                    | 15000       |
| training/Q/q1_loss             | 58.295834   |
| training/sac_pi/alpha          | 0.11799482  |
| training/sac_pi/alpha_loss     | 0.462579    |
| training/sac_pi/logp_pi        | 4.918828    |
| training/sac_pi/pi_entropy     | 3.5076523   |
| training/sac_pi/pi_global_norm | 0.74286675  |
| training/sac_pi/policy_loss    | -136.4602   |
| training/sac_pi/std            | 0.50263226  |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 131.96541   |
| training/sac_Q/q2              | 133.01668   |
| training/sac_Q/q2_loss         | 58.675953   |
| training/sac_Q/q_global_norm   | 241.21043   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13524169 |
| epoch                          | 15         |
| evaluation/episode-length-avg  | 145        |
| evaluation/episode-length-max  | 242        |
| evaluation/episode-length-min  | 83         |
| evaluation/episode-length-std  | 65         |
| evaluation/return-average      | 58.84057   |
| evaluation/return-max          | 111.78252  |
| evaluation/return-min          | 33.480873  |
| evaluation/return-std          | 28.082785  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.74       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 86.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45215      |
| perf/AverageLength             | 145        |
| perf/AverageReturn             | 58.84057   |
| perf/NormalizedReturn          | 0.0125     |
| Q-avg                          | 132.879    |
| Q-std                          | 59.15939   |
| Q_loss                         | 62.023323  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 15         |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000487   |
| times/evaluation_paths         | 5.26       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00858    |
| times/train                    | 63.3       |
| timestep                       | 1000       |
| timesteps_total                | 16000      |
| train-steps                    | 16000      |
| training/Q/q1_loss             | 57.049603  |
| training/sac_pi/alpha          | 0.13521172 |
| training/sac_pi/alpha_loss     | 0.9031364  |
| training/sac_pi/logp_pi        | 4.300092   |
| training/sac_pi/pi_entropy     | 3.773442   |
| training/sac_pi/pi_global_norm | 0.78525096 |
| training/sac_pi/policy_loss    | -137.95038 |
| training/sac_pi/std            | 0.4912033  |
| training/sac_pi/valid_num      | 4991.0     |
| training/sac_Q/q1              | 134.88051  |
| training/sac_Q/q2              | 135.24374  |
| training/sac_Q/q2_loss         | 56.721622  |
| training/sac_Q/q_global_norm   | 263.2241   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.123589836 |
| epoch                          | 16          |
| evaluation/episode-length-avg  | 832         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 306         |
| evaluation/episode-length-std  | 246         |
| evaluation/return-average      | 4096.5254   |
| evaluation/return-max          | 5165.3174   |
| evaluation/return-min          | 1040.3043   |
| evaluation/return-std          | 1441.6794   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.84        |
| model/origin_ret               | 87.4        |
| model/penalty_ret              | 83.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 44770       |
| perf/AverageLength             | 832         |
| perf/AverageReturn             | 4096.5254   |
| perf/NormalizedReturn          | 0.892       |
| Q-avg                          | 137.1897    |
| Q-std                          | 64.524605   |
| Q_loss                         | 62.781586   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 16          |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000103    |
| times/epoch_rollout_model      | 510         |
| times/evaluation_metrics       | 0.000611    |
| times/evaluation_paths         | 28.9        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 63.8        |
| timestep                       | 1000        |
| timesteps_total                | 17000       |
| train-steps                    | 17000       |
| training/Q/q1_loss             | 56.73678    |
| training/sac_pi/alpha          | 0.12360708  |
| training/sac_pi/alpha_loss     | -0.3413262  |
| training/sac_pi/logp_pi        | 3.6955743   |
| training/sac_pi/pi_entropy     | 3.5057416   |
| training/sac_pi/pi_global_norm | 0.7616567   |
| training/sac_pi/policy_loss    | -143.38408  |
| training/sac_pi/std            | 0.47378147  |
| training/sac_pi/valid_num      | 4987.0      |
| training/sac_Q/q1              | 139.90771   |
| training/sac_Q/q2              | 140.09027   |
| training/sac_Q/q2_loss         | 56.549892   |
| training/sac_Q/q_global_norm   | 175.03821   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.13348629  |
| epoch                          | 17          |
| evaluation/episode-length-avg  | 167         |
| evaluation/episode-length-max  | 250         |
| evaluation/episode-length-min  | 154         |
| evaluation/episode-length-std  | 27.8        |
| evaluation/return-average      | 424.59018   |
| evaluation/return-max          | 799.0281    |
| evaluation/return-min          | 371.52786   |
| evaluation/return-std          | 125.10277   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.78        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 84          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45468       |
| perf/AverageLength             | 167         |
| perf/AverageReturn             | 424.59018   |
| perf/NormalizedReturn          | 0.0921      |
| Q-avg                          | 142.18083   |
| Q-std                          | 63.62934    |
| Q_loss                         | 60.266018   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 17          |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000299    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000475    |
| times/evaluation_paths         | 5.48        |
| times/timestep_after_hook      | 0.00356     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 62.7        |
| timestep                       | 1000        |
| timesteps_total                | 18000       |
| train-steps                    | 18000       |
| training/Q/q1_loss             | 54.369873   |
| training/sac_pi/alpha          | 0.13348399  |
| training/sac_pi/alpha_loss     | -0.08446242 |
| training/sac_pi/logp_pi        | 4.6011567   |
| training/sac_pi/pi_entropy     | 3.6994553   |
| training/sac_pi/pi_global_norm | 0.8264866   |
| training/sac_pi/policy_loss    | -137.42867  |
| training/sac_pi/std            | 0.50832045  |
| training/sac_pi/valid_num      | 4956.0      |
| training/sac_Q/q1              | 133.52795   |
| training/sac_Q/q2              | 133.69495   |
| training/sac_Q/q2_loss         | 54.343613   |
| training/sac_Q/q_global_norm   | 151.36807   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13667853 |
| epoch                          | 18         |
| evaluation/episode-length-avg  | 281        |
| evaluation/episode-length-max  | 486        |
| evaluation/episode-length-min  | 150        |
| evaluation/episode-length-std  | 117        |
| evaluation/return-average      | 932.9344   |
| evaluation/return-max          | 1882.4543  |
| evaluation/return-min          | 396.8182   |
| evaluation/return-std          | 514.93536  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 83         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45596      |
| perf/AverageLength             | 281        |
| perf/AverageReturn             | 932.9344   |
| perf/NormalizedReturn          | 0.203      |
| Q-avg                          | 147.01553  |
| Q-std                          | 70.24488   |
| Q_loss                         | 52.071495  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 18         |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000162   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000502   |
| times/evaluation_paths         | 9.14       |
| times/timestep_after_hook      | 0.00355    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 62.1       |
| timestep                       | 1000       |
| timesteps_total                | 19000      |
| train-steps                    | 19000      |
| training/Q/q1_loss             | 75.957184  |
| training/sac_pi/alpha          | 0.13662635 |
| training/sac_pi/alpha_loss     | 0.67454344 |
| training/sac_pi/logp_pi        | 4.290954   |
| training/sac_pi/pi_entropy     | 3.8383286  |
| training/sac_pi/pi_global_norm | 1.0726192  |
| training/sac_pi/policy_loss    | -156.34467 |
| training/sac_pi/std            | 0.5014123  |
| training/sac_pi/valid_num      | 5016.0     |
| training/sac_Q/q1              | 153.6821   |
| training/sac_Q/q2              | 154.1491   |
| training/sac_Q/q2_loss         | 76.03109   |
| training/sac_Q/q_global_norm   | 227.60378  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13193695 |
| epoch                          | 19         |
| evaluation/episode-length-avg  | 273        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 34         |
| evaluation/episode-length-std  | 344        |
| evaluation/return-average      | 675.9523   |
| evaluation/return-max          | 2703.7854  |
| evaluation/return-min          | 29.332165  |
| evaluation/return-std          | 1048.5127  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 83.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45148      |
| perf/AverageLength             | 273        |
| perf/AverageReturn             | 675.9523   |
| perf/NormalizedReturn          | 0.147      |
| Q-avg                          | 154.04372  |
| Q-std                          | 61.323685  |
| Q_loss                         | 77.29837   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 19         |
| times/epoch_after_hook         | 1.63e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000461   |
| times/evaluation_paths         | 9.11       |
| times/timestep_after_hook      | 0.00347    |
| times/timestep_before_hook     | 0.00798    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 20000      |
| train-steps                    | 20000      |
| training/Q/q1_loss             | 93.13231   |
| training/sac_pi/alpha          | 0.13196278 |
| training/sac_pi/alpha_loss     | 0.08325969 |
| training/sac_pi/logp_pi        | 5.374756   |
| training/sac_pi/pi_entropy     | 3.6187809  |
| training/sac_pi/pi_global_norm | 1.1950817  |
| training/sac_pi/policy_loss    | -155.22287 |
| training/sac_pi/std            | 0.535488   |
| training/sac_pi/valid_num      | 4902.0     |
| training/sac_Q/q1              | 149.72087  |
| training/sac_Q/q2              | 150.33875  |
| training/sac_Q/q2_loss         | 93.69082   |
| training/sac_Q/q_global_norm   | 361.4974   |
--------------------------------------------------------------------------------
[WARN] 20 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.1379548  |
| epoch                          | 20         |
| evaluation/episode-length-avg  | 168        |
| evaluation/episode-length-max  | 177        |
| evaluation/episode-length-min  | 161        |
| evaluation/episode-length-std  | 4.67       |
| evaluation/return-average      | 362.4694   |
| evaluation/return-max          | 385.8423   |
| evaluation/return-min          | 346.33762  |
| evaluation/return-std          | 12.005052  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.79       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 85.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45469      |
| perf/AverageLength             | 168        |
| perf/AverageReturn             | 362.4694   |
| perf/NormalizedReturn          | 0.0786     |
| Q-avg                          | 152.44972  |
| Q-std                          | 73.21745   |
| Q_loss                         | 70.18191   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 20         |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000447   |
| times/evaluation_paths         | 5.46       |
| times/timestep_after_hook      | 0.00351    |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 21000      |
| train-steps                    | 21000      |
| training/Q/q1_loss             | 60.205273  |
| training/sac_pi/alpha          | 0.13796552 |
| training/sac_pi/alpha_loss     | 0.461733   |
| training/sac_pi/logp_pi        | 4.788784   |
| training/sac_pi/pi_entropy     | 3.5209126  |
| training/sac_pi/pi_global_norm | 0.91006017 |
| training/sac_pi/policy_loss    | -164.3     |
| training/sac_pi/std            | 0.4905015  |
| training/sac_pi/valid_num      | 4937.0     |
| training/sac_Q/q1              | 159.1207   |
| training/sac_Q/q2              | 159.2295   |
| training/sac_Q/q2_loss         | 59.947285  |
| training/sac_Q/q_global_norm   | 197.52946  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.13850309  |
| epoch                          | 21          |
| evaluation/episode-length-avg  | 752         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 127         |
| evaluation/episode-length-std  | 380         |
| evaluation/return-average      | 2540.3208   |
| evaluation/return-max          | 3738.6252   |
| evaluation/return-min          | 165.53365   |
| evaluation/return-std          | 1530.83     |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.79        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 84.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 44966       |
| perf/AverageLength             | 752         |
| perf/AverageReturn             | 2540.3208   |
| perf/NormalizedReturn          | 0.553       |
| Q-avg                          | 149.98195   |
| Q-std                          | 70.55671    |
| Q_loss                         | 82.10332    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 21          |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000321    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000501    |
| times/evaluation_paths         | 25.7        |
| times/timestep_after_hook      | 0.00351     |
| times/timestep_before_hook     | 0.00803     |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 22000       |
| train-steps                    | 22000       |
| training/Q/q1_loss             | 69.22832    |
| training/sac_pi/alpha          | 0.1385349   |
| training/sac_pi/alpha_loss     | -0.52319866 |
| training/sac_pi/logp_pi        | 3.8340554   |
| training/sac_pi/pi_entropy     | 3.544398    |
| training/sac_pi/pi_global_norm | 1.0856215   |
| training/sac_pi/policy_loss    | -161.89583  |
| training/sac_pi/std            | 0.48691246  |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 157.84277   |
| training/sac_Q/q2              | 157.64468   |
| training/sac_Q/q2_loss         | 69.07129    |
| training/sac_Q/q_global_norm   | 209.55934   |
---------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.13754348    |
| epoch                          | 22            |
| evaluation/episode-length-avg  | 334           |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 55            |
| evaluation/episode-length-std  | 248           |
| evaluation/return-average      | 897.0072      |
| evaluation/return-max          | 3116.1865     |
| evaluation/return-min          | 106.410484    |
| evaluation/return-std          | 825.229       |
| model/max_penalty              | 7.24          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 2.76          |
| model/origin_ret               | 82.8          |
| model/penalty_ret              | 82.2          |
| model/val_loss                 | 0.40512508    |
| model/valid_num                | 45781         |
| perf/AverageLength             | 334           |
| perf/AverageReturn             | 897.0072      |
| perf/NormalizedReturn          | 0.195         |
| Q-avg                          | 156.4665      |
| Q-std                          | 71.48237      |
| Q_loss                         | 65.57136      |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 22            |
| times/epoch_after_hook         | 1.77e-06      |
| times/epoch_before_hook        | 0.000111      |
| times/epoch_rollout_model      | 489           |
| times/evaluation_metrics       | 0.000503      |
| times/evaluation_paths         | 12.7          |
| times/timestep_after_hook      | 0.00353       |
| times/timestep_before_hook     | 0.00805       |
| times/train                    | 61.7          |
| timestep                       | 1000          |
| timesteps_total                | 23000         |
| train-steps                    | 23000         |
| training/Q/q1_loss             | 79.79932      |
| training/sac_pi/alpha          | 0.13756835    |
| training/sac_pi/alpha_loss     | 0.00064633467 |
| training/sac_pi/logp_pi        | 5.2697773     |
| training/sac_pi/pi_entropy     | 3.7056518     |
| training/sac_pi/pi_global_norm | 1.0719472     |
| training/sac_pi/policy_loss    | -156.68097    |
| training/sac_pi/std            | 0.5414636     |
| training/sac_pi/valid_num      | 4922.0        |
| training/sac_Q/q1              | 150.47372     |
| training/sac_Q/q2              | 151.38042     |
| training/sac_Q/q2_loss         | 79.63584      |
| training/sac_Q/q_global_norm   | 331.82806     |
-----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.14032148   |
| epoch                          | 23           |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4965.3057    |
| evaluation/return-max          | 5059.703     |
| evaluation/return-min          | 4907.953     |
| evaluation/return-std          | 47.049747    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.73         |
| model/origin_ret               | 84.8         |
| model/penalty_ret              | 84.2         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 45243        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4965.3057    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 152.61563    |
| Q-std                          | 77.25116     |
| Q_loss                         | 77.23481     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 23           |
| times/epoch_after_hook         | 1.8e-06      |
| times/epoch_before_hook        | 0.000126     |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.000617     |
| times/evaluation_paths         | 35.1         |
| times/timestep_after_hook      | 0.00348      |
| times/timestep_before_hook     | 0.00803      |
| times/train                    | 59.3         |
| timestep                       | 1000         |
| timesteps_total                | 24000        |
| train-steps                    | 24000        |
| training/Q/q1_loss             | 75.1789      |
| training/sac_pi/alpha          | 0.14033492   |
| training/sac_pi/alpha_loss     | -0.012870594 |
| training/sac_pi/logp_pi        | 4.738368     |
| training/sac_pi/pi_entropy     | 3.6980948    |
| training/sac_pi/pi_global_norm | 1.2267838    |
| training/sac_pi/policy_loss    | -158.82878   |
| training/sac_pi/std            | 0.5092316    |
| training/sac_pi/valid_num      | 4928.0       |
| training/sac_Q/q1              | 152.91483    |
| training/sac_Q/q2              | 153.82877    |
| training/sac_Q/q2_loss         | 75.13491     |
| training/sac_Q/q_global_norm   | 268.57663    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14461571 |
| epoch                          | 24         |
| evaluation/episode-length-avg  | 950        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 681        |
| evaluation/episode-length-std  | 105        |
| evaluation/return-average      | 4661.316   |
| evaluation/return-max          | 4996.1055  |
| evaluation/return-min          | 3218.7192  |
| evaluation/return-std          | 576.163    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.72       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 84.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45369      |
| perf/AverageLength             | 950        |
| perf/AverageReturn             | 4661.316   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 153.29073  |
| Q-std                          | 75.21455   |
| Q_loss                         | 87.06397   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 24         |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000513   |
| times/evaluation_paths         | 31.9       |
| times/timestep_after_hook      | 0.00345    |
| times/timestep_before_hook     | 0.00801    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 25000      |
| train-steps                    | 25000      |
| training/Q/q1_loss             | 69.94464   |
| training/sac_pi/alpha          | 0.14456947 |
| training/sac_pi/alpha_loss     | 0.5298475  |
| training/sac_pi/logp_pi        | 5.0332346  |
| training/sac_pi/pi_entropy     | 3.8282592  |
| training/sac_pi/pi_global_norm | 1.1830487  |
| training/sac_pi/policy_loss    | -154.5694  |
| training/sac_pi/std            | 0.53626853 |
| training/sac_pi/valid_num      | 4880.0     |
| training/sac_Q/q1              | 146.95715  |
| training/sac_Q/q2              | 147.19028  |
| training/sac_Q/q2_loss         | 70.05311   |
| training/sac_Q/q_global_norm   | 331.3495   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.13735361  |
| epoch                          | 25          |
| evaluation/episode-length-avg  | 138         |
| evaluation/episode-length-max  | 140         |
| evaluation/episode-length-min  | 137         |
| evaluation/episode-length-std  | 1.04        |
| evaluation/return-average      | 380.5639    |
| evaluation/return-max          | 399.75687   |
| evaluation/return-min          | 365.9688    |
| evaluation/return-std          | 9.6815405   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.89        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 82.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45314       |
| perf/AverageLength             | 138         |
| perf/AverageReturn             | 380.5639    |
| perf/NormalizedReturn          | 0.0825      |
| Q-avg                          | 156.87112   |
| Q-std                          | 73.50731    |
| Q_loss                         | 71.14274    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 25          |
| times/epoch_after_hook         | 1.65e-06    |
| times/epoch_before_hook        | 0.000274    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000691    |
| times/evaluation_paths         | 4.57        |
| times/timestep_after_hook      | 0.00354     |
| times/timestep_before_hook     | 0.00798     |
| times/train                    | 59.3        |
| timestep                       | 1000        |
| timesteps_total                | 26000       |
| train-steps                    | 26000       |
| training/Q/q1_loss             | 82.62788    |
| training/sac_pi/alpha          | 0.13734525  |
| training/sac_pi/alpha_loss     | 0.031685304 |
| training/sac_pi/logp_pi        | 4.5700417   |
| training/sac_pi/pi_entropy     | 3.7617588   |
| training/sac_pi/pi_global_norm | 0.9170185   |
| training/sac_pi/policy_loss    | -164.09857  |
| training/sac_pi/std            | 0.5325315   |
| training/sac_pi/valid_num      | 4953.0      |
| training/sac_Q/q1              | 158.77759   |
| training/sac_Q/q2              | 159.20451   |
| training/sac_Q/q2_loss         | 82.419655   |
| training/sac_Q/q_global_norm   | 263.92816   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1426735   |
| epoch                          | 26          |
| evaluation/episode-length-avg  | 324         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 147         |
| evaluation/episode-length-std  | 338         |
| evaluation/return-average      | 1113.0906   |
| evaluation/return-max          | 4090.4714   |
| evaluation/return-min          | 353.55127   |
| evaluation/return-std          | 1483.151    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 83.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45596       |
| perf/AverageLength             | 324         |
| perf/AverageReturn             | 1113.0906   |
| perf/NormalizedReturn          | 0.242       |
| Q-avg                          | 149.75624   |
| Q-std                          | 83.82868    |
| Q_loss                         | 89.48218    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 26          |
| times/epoch_after_hook         | 1.66e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 471         |
| times/evaluation_metrics       | 0.000619    |
| times/evaluation_paths         | 10.5        |
| times/timestep_after_hook      | 0.0035      |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 60.5        |
| timestep                       | 1000        |
| timesteps_total                | 27000       |
| train-steps                    | 27000       |
| training/Q/q1_loss             | 59.4448     |
| training/sac_pi/alpha          | 0.1426941   |
| training/sac_pi/alpha_loss     | -0.26541197 |
| training/sac_pi/logp_pi        | 4.0865326   |
| training/sac_pi/pi_entropy     | 3.5855134   |
| training/sac_pi/pi_global_norm | 1.0693297   |
| training/sac_pi/policy_loss    | -165.19598  |
| training/sac_pi/std            | 0.49470183  |
| training/sac_pi/valid_num      | 4956.0      |
| training/sac_Q/q1              | 160.83945   |
| training/sac_Q/q2              | 160.50215   |
| training/sac_Q/q2_loss         | 59.741734   |
| training/sac_Q/q_global_norm   | 251.9712    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14856632 |
| epoch                          | 27         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 1112.554   |
| evaluation/return-max          | 1119.7327  |
| evaluation/return-min          | 1104.8362  |
| evaluation/return-std          | 4.917118   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.7        |
| model/origin_ret               | 82.1       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45249      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 1112.554   |
| perf/NormalizedReturn          | 0.242      |
| Q-avg                          | 156.87633  |
| Q-std                          | 76.36081   |
| Q_loss                         | 90.46519   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 27         |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000101   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000566   |
| times/evaluation_paths         | 35.3       |
| times/timestep_after_hook      | 0.00352    |
| times/timestep_before_hook     | 0.0081     |
| times/train                    | 62.4       |
| timestep                       | 1000       |
| timesteps_total                | 28000      |
| train-steps                    | 28000      |
| training/Q/q1_loss             | 80.187805  |
| training/sac_pi/alpha          | 0.14854647 |
| training/sac_pi/alpha_loss     | 0.3500827  |
| training/sac_pi/logp_pi        | 4.39003    |
| training/sac_pi/pi_entropy     | 3.519258   |
| training/sac_pi/pi_global_norm | 1.3039576  |
| training/sac_pi/policy_loss    | -169.60497 |
| training/sac_pi/std            | 0.4799934  |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 165.42766  |
| training/sac_Q/q2              | 165.83226  |
| training/sac_Q/q2_loss         | 80.08212   |
| training/sac_Q/q_global_norm   | 257.084    |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14231806 |
| epoch                          | 28         |
| evaluation/episode-length-avg  | 182        |
| evaluation/episode-length-max  | 201        |
| evaluation/episode-length-min  | 33         |
| evaluation/episode-length-std  | 49.6       |
| evaluation/return-average      | 357.86765  |
| evaluation/return-max          | 429.1373   |
| evaluation/return-min          | 46.833237  |
| evaluation/return-std          | 105.58672  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.86       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 83.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45376      |
| perf/AverageLength             | 182        |
| perf/AverageReturn             | 357.86765  |
| perf/NormalizedReturn          | 0.0776     |
| Q-avg                          | 166.57193  |
| Q-std                          | 70.8321    |
| Q_loss                         | 77.59818   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 28         |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000597   |
| times/evaluation_paths         | 7.54       |
| times/timestep_after_hook      | 0.00344    |
| times/timestep_before_hook     | 0.00801    |
| times/train                    | 59.4       |
| timestep                       | 1000       |
| timesteps_total                | 29000      |
| train-steps                    | 29000      |
| training/Q/q1_loss             | 75.364044  |
| training/sac_pi/alpha          | 0.14232872 |
| training/sac_pi/alpha_loss     | -0.0903761 |
| training/sac_pi/logp_pi        | 4.6053147  |
| training/sac_pi/pi_entropy     | 3.5900528  |
| training/sac_pi/pi_global_norm | 1.5421193  |
| training/sac_pi/policy_loss    | -170.14409 |
| training/sac_pi/std            | 0.511938   |
| training/sac_pi/valid_num      | 4926.0     |
| training/sac_Q/q1              | 165.0352   |
| training/sac_Q/q2              | 164.87692  |
| training/sac_Q/q2_loss         | 74.84513   |
| training/sac_Q/q_global_norm   | 182.97299  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.13607933 |
| epoch                          | 29         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4293.406   |
| evaluation/return-max          | 4337.4673  |
| evaluation/return-min          | 4265.375   |
| evaluation/return-std          | 23.012653  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.86       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 83.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45487      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4293.406   |
| perf/NormalizedReturn          | 0.935      |
| Q-avg                          | 162.93022  |
| Q-std                          | 74.74286   |
| Q_loss                         | 80.06867   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 29         |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000275   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000687   |
| times/evaluation_paths         | 33.8       |
| times/timestep_after_hook      | 0.0035     |
| times/timestep_before_hook     | 0.00809    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 30000      |
| train-steps                    | 30000      |
| training/Q/q1_loss             | 76.487366  |
| training/sac_pi/alpha          | 0.13608524 |
| training/sac_pi/alpha_loss     | 0.1615902  |
| training/sac_pi/logp_pi        | 4.434043   |
| training/sac_pi/pi_entropy     | 3.503378   |
| training/sac_pi/pi_global_norm | 1.2325048  |
| training/sac_pi/policy_loss    | -166.82538 |
| training/sac_pi/std            | 0.49060678 |
| training/sac_pi/valid_num      | 4920.0     |
| training/sac_Q/q1              | 160.80183  |
| training/sac_Q/q2              | 160.98465  |
| training/sac_Q/q2_loss         | 76.59914   |
| training/sac_Q/q_global_norm   | 328.4276   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14565223 |
| epoch                          | 30         |
| evaluation/episode-length-avg  | 894        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 397        |
| evaluation/episode-length-std  | 201        |
| evaluation/return-average      | 3823.0854  |
| evaluation/return-max          | 4562.8506  |
| evaluation/return-min          | 1359.6134  |
| evaluation/return-std          | 999.88904  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 83.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45624      |
| perf/AverageLength             | 894        |
| perf/AverageReturn             | 3823.0854  |
| perf/NormalizedReturn          | 0.832      |
| Q-avg                          | 169.5727   |
| Q-std                          | 72.323204  |
| Q_loss                         | 80.24058   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 30         |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.000652   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.0035     |
| times/timestep_before_hook     | 0.00796    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 31000      |
| train-steps                    | 31000      |
| training/Q/q1_loss             | 87.44429   |
| training/sac_pi/alpha          | 0.1456692  |
| training/sac_pi/alpha_loss     | -0.6062312 |
| training/sac_pi/logp_pi        | 4.359734   |
| training/sac_pi/pi_entropy     | 3.612325   |
| training/sac_pi/pi_global_norm | 1.3272815  |
| training/sac_pi/policy_loss    | -171.71814 |
| training/sac_pi/std            | 0.50590134 |
| training/sac_pi/valid_num      | 4924.0     |
| training/sac_Q/q1              | 165.42851  |
| training/sac_Q/q2              | 165.33073  |
| training/sac_Q/q2_loss         | 88.14469   |
| training/sac_Q/q_global_norm   | 291.0105   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.148236    |
| epoch                          | 31          |
| evaluation/episode-length-avg  | 178         |
| evaluation/episode-length-max  | 189         |
| evaluation/episode-length-min  | 168         |
| evaluation/episode-length-std  | 6.18        |
| evaluation/return-average      | 469.37344   |
| evaluation/return-max          | 481.82718   |
| evaluation/return-min          | 451.6996    |
| evaluation/return-std          | 8.423454    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.8         |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 82.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45519       |
| perf/AverageLength             | 178         |
| perf/AverageReturn             | 469.37344   |
| perf/NormalizedReturn          | 0.102       |
| Q-avg                          | 173.98027   |
| Q-std                          | 72.31946    |
| Q_loss                         | 72.59983    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 31          |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000636    |
| times/evaluation_paths         | 5.74        |
| times/timestep_after_hook      | 0.00348     |
| times/timestep_before_hook     | 0.00787     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 32000       |
| train-steps                    | 32000       |
| training/Q/q1_loss             | 81.60409    |
| training/sac_pi/alpha          | 0.1482527   |
| training/sac_pi/alpha_loss     | -0.11597181 |
| training/sac_pi/logp_pi        | 4.70866     |
| training/sac_pi/pi_entropy     | 3.8507447   |
| training/sac_pi/pi_global_norm | 1.3968383   |
| training/sac_pi/policy_loss    | -169.60318  |
| training/sac_pi/std            | 0.5252895   |
| training/sac_pi/valid_num      | 4905.0      |
| training/sac_Q/q1              | 163.08179   |
| training/sac_Q/q2              | 163.41055   |
| training/sac_Q/q2_loss         | 82.24354    |
| training/sac_Q/q_global_norm   | 209.49838   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14568256 |
| epoch                          | 32         |
| evaluation/episode-length-avg  | 201        |
| evaluation/episode-length-max  | 213        |
| evaluation/episode-length-min  | 193        |
| evaluation/episode-length-std  | 7.4        |
| evaluation/return-average      | 529.08075  |
| evaluation/return-max          | 560.1216   |
| evaluation/return-min          | 505.22656  |
| evaluation/return-std          | 20.45792   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 83.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45612      |
| perf/AverageLength             | 201        |
| perf/AverageReturn             | 529.08075  |
| perf/NormalizedReturn          | 0.115      |
| Q-avg                          | 161.04199  |
| Q-std                          | 84.165825  |
| Q_loss                         | 90.08527   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 32         |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000503   |
| times/evaluation_paths         | 7.86       |
| times/timestep_after_hook      | 0.00347    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 59.9       |
| timestep                       | 1000       |
| timesteps_total                | 33000      |
| train-steps                    | 33000      |
| training/Q/q1_loss             | 80.756645  |
| training/sac_pi/alpha          | 0.14563943 |
| training/sac_pi/alpha_loss     | 0.52104723 |
| training/sac_pi/logp_pi        | 4.0433416  |
| training/sac_pi/pi_entropy     | 3.6607833  |
| training/sac_pi/pi_global_norm | 2.2270503  |
| training/sac_pi/policy_loss    | -180.58148 |
| training/sac_pi/std            | 0.489059   |
| training/sac_pi/valid_num      | 4917.0     |
| training/sac_Q/q1              | 173.75475  |
| training/sac_Q/q2              | 173.98503  |
| training/sac_Q/q2_loss         | 80.6227    |
| training/sac_Q/q_global_norm   | 260.17432  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15180361 |
| epoch                          | 33         |
| evaluation/episode-length-avg  | 145        |
| evaluation/episode-length-max  | 148        |
| evaluation/episode-length-min  | 142        |
| evaluation/episode-length-std  | 1.9        |
| evaluation/return-average      | 252.31308  |
| evaluation/return-max          | 255.71893  |
| evaluation/return-min          | 246.37718  |
| evaluation/return-std          | 2.8885252  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.76       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 84.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 44896      |
| perf/AverageLength             | 145        |
| perf/AverageReturn             | 252.31308  |
| perf/NormalizedReturn          | 0.0546     |
| Q-avg                          | 169.4614   |
| Q-std                          | 76.98605   |
| Q_loss                         | 85.83411   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 33         |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000266   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000458   |
| times/evaluation_paths         | 6.25       |
| times/timestep_after_hook      | 0.00353    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 59         |
| timestep                       | 1000       |
| timesteps_total                | 34000      |
| train-steps                    | 34000      |
| training/Q/q1_loss             | 73.36986   |
| training/sac_pi/alpha          | 0.15177946 |
| training/sac_pi/alpha_loss     | 0.2697947  |
| training/sac_pi/logp_pi        | 4.5748043  |
| training/sac_pi/pi_entropy     | 3.7469707  |
| training/sac_pi/pi_global_norm | 1.1872468  |
| training/sac_pi/policy_loss    | -173.19197 |
| training/sac_pi/std            | 0.521956   |
| training/sac_pi/valid_num      | 4961.0     |
| training/sac_Q/q1              | 167.80693  |
| training/sac_Q/q2              | 167.72449  |
| training/sac_Q/q2_loss         | 74.17061   |
| training/sac_Q/q_global_norm   | 193.85892  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15037607 |
| epoch                          | 34         |
| evaluation/episode-length-avg  | 951        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 733        |
| evaluation/episode-length-std  | 99         |
| evaluation/return-average      | 4006.8281  |
| evaluation/return-max          | 4293.3564  |
| evaluation/return-min          | 2996.978   |
| evaluation/return-std          | 469.8656   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.87       |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45410      |
| perf/AverageLength             | 951        |
| perf/AverageReturn             | 4006.8281  |
| perf/NormalizedReturn          | 0.872      |
| Q-avg                          | 168.25824  |
| Q-std                          | 73.97756   |
| Q_loss                         | 88.78578   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 34         |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000147   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000524   |
| times/evaluation_paths         | 31.8       |
| times/timestep_after_hook      | 0.00352    |
| times/timestep_before_hook     | 0.00796    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 35000      |
| train-steps                    | 35000      |
| training/Q/q1_loss             | 103.98263  |
| training/sac_pi/alpha          | 0.15031616 |
| training/sac_pi/alpha_loss     | 0.71833885 |
| training/sac_pi/logp_pi        | 4.381429   |
| training/sac_pi/pi_entropy     | 3.6608498  |
| training/sac_pi/pi_global_norm | 1.5330635  |
| training/sac_pi/policy_loss    | -171.53464 |
| training/sac_pi/std            | 0.4979854  |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 166.70515  |
| training/sac_Q/q2              | 166.88962  |
| training/sac_Q/q2_loss         | 104.28488  |
| training/sac_Q/q_global_norm   | 346.67743  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14753215 |
| epoch                          | 35         |
| evaluation/episode-length-avg  | 175        |
| evaluation/episode-length-max  | 185        |
| evaluation/episode-length-min  | 166        |
| evaluation/episode-length-std  | 5.42       |
| evaluation/return-average      | 270.03128  |
| evaluation/return-max          | 282.13144  |
| evaluation/return-min          | 260.9071   |
| evaluation/return-std          | 5.653822   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.81       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 82.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45597      |
| perf/AverageLength             | 175        |
| perf/AverageReturn             | 270.03128  |
| perf/NormalizedReturn          | 0.0585     |
| Q-avg                          | 173.88107  |
| Q-std                          | 73.96141   |
| Q_loss                         | 91.6916    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 35         |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000652   |
| times/evaluation_paths         | 7.14       |
| times/timestep_after_hook      | 0.00347    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 59.7       |
| timestep                       | 1000       |
| timesteps_total                | 36000      |
| train-steps                    | 36000      |
| training/Q/q1_loss             | 90.17139   |
| training/sac_pi/alpha          | 0.14751157 |
| training/sac_pi/alpha_loss     | 0.32243732 |
| training/sac_pi/logp_pi        | 4.9189715  |
| training/sac_pi/pi_entropy     | 3.6144269  |
| training/sac_pi/pi_global_norm | 1.5092913  |
| training/sac_pi/policy_loss    | -173.92625 |
| training/sac_pi/std            | 0.5148773  |
| training/sac_pi/valid_num      | 4894.0     |
| training/sac_Q/q1              | 166.40218  |
| training/sac_Q/q2              | 166.39359  |
| training/sac_Q/q2_loss         | 89.8001    |
| training/sac_Q/q_global_norm   | 219.6072   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14781763 |
| epoch                          | 36         |
| evaluation/episode-length-avg  | 159        |
| evaluation/episode-length-max  | 161        |
| evaluation/episode-length-min  | 156        |
| evaluation/episode-length-std  | 1.68       |
| evaluation/return-average      | 361.52676  |
| evaluation/return-max          | 365.97836  |
| evaluation/return-min          | 356.64484  |
| evaluation/return-std          | 3.472794   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 87.2       |
| model/penalty_ret              | 83.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45761      |
| perf/AverageLength             | 159        |
| perf/AverageReturn             | 361.52676  |
| perf/NormalizedReturn          | 0.0784     |
| Q-avg                          | 171.1352   |
| Q-std                          | 81.40839   |
| Q_loss                         | 78.02588   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 36         |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000108   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.0004     |
| times/evaluation_paths         | 5          |
| times/timestep_after_hook      | 0.00354    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 37000      |
| train-steps                    | 37000      |
| training/Q/q1_loss             | 94.375786  |
| training/sac_pi/alpha          | 0.14785933 |
| training/sac_pi/alpha_loss     | -0.6656961 |
| training/sac_pi/logp_pi        | 4.209903   |
| training/sac_pi/pi_entropy     | 3.4965775  |
| training/sac_pi/pi_global_norm | 1.2238089  |
| training/sac_pi/policy_loss    | -174.40202 |
| training/sac_pi/std            | 0.5044798  |
| training/sac_pi/valid_num      | 4990.0     |
| training/sac_Q/q1              | 170.66104  |
| training/sac_Q/q2              | 170.31859  |
| training/sac_Q/q2_loss         | 94.792984  |
| training/sac_Q/q_global_norm   | 236.0494   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1510933   |
| epoch                          | 37          |
| evaluation/episode-length-avg  | 184         |
| evaluation/episode-length-max  | 191         |
| evaluation/episode-length-min  | 178         |
| evaluation/episode-length-std  | 4.44        |
| evaluation/return-average      | 337.66553   |
| evaluation/return-max          | 349.34644   |
| evaluation/return-min          | 324.27942   |
| evaluation/return-std          | 8.938049    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.79        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 83.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45782       |
| perf/AverageLength             | 184         |
| perf/AverageReturn             | 337.66553   |
| perf/NormalizedReturn          | 0.0732      |
| Q-avg                          | 168.00806   |
| Q-std                          | 77.729774   |
| Q_loss                         | 89.70766    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 37          |
| times/epoch_after_hook         | 1.65e-06    |
| times/epoch_before_hook        | 0.000268    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000496    |
| times/evaluation_paths         | 6.07        |
| times/timestep_after_hook      | 0.00356     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 38000       |
| train-steps                    | 38000       |
| training/Q/q1_loss             | 83.54132    |
| training/sac_pi/alpha          | 0.15107907  |
| training/sac_pi/alpha_loss     | -0.19772238 |
| training/sac_pi/logp_pi        | 4.5890465   |
| training/sac_pi/pi_entropy     | 3.512125    |
| training/sac_pi/pi_global_norm | 1.0141705   |
| training/sac_pi/policy_loss    | -183.03627  |
| training/sac_pi/std            | 0.49975598  |
| training/sac_pi/valid_num      | 4929.0      |
| training/sac_Q/q1              | 177.0325    |
| training/sac_Q/q2              | 176.55498   |
| training/sac_Q/q2_loss         | 83.101425   |
| training/sac_Q/q_global_norm   | 213.96623   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15131418  |
| epoch                          | 38          |
| evaluation/episode-length-avg  | 397         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 219         |
| evaluation/episode-length-std  | 302         |
| evaluation/return-average      | 1294.9581   |
| evaluation/return-max          | 4307.698    |
| evaluation/return-min          | 520.3268    |
| evaluation/return-std          | 1499.1309   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45514       |
| perf/AverageLength             | 397         |
| perf/AverageReturn             | 1294.9581   |
| perf/NormalizedReturn          | 0.282       |
| Q-avg                          | 173.38245   |
| Q-std                          | 83.13854    |
| Q_loss                         | 96.02687    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 38          |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000116    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000576    |
| times/evaluation_paths         | 14.4        |
| times/timestep_after_hook      | 0.00348     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 59          |
| timestep                       | 1000        |
| timesteps_total                | 39000       |
| train-steps                    | 39000       |
| training/Q/q1_loss             | 77.466545   |
| training/sac_pi/alpha          | 0.15131323  |
| training/sac_pi/alpha_loss     | -0.10508112 |
| training/sac_pi/logp_pi        | 3.9570231   |
| training/sac_pi/pi_entropy     | 3.7847266   |
| training/sac_pi/pi_global_norm | 1.2315838   |
| training/sac_pi/policy_loss    | -184.26663  |
| training/sac_pi/std            | 0.52305037  |
| training/sac_pi/valid_num      | 4970.0      |
| training/sac_Q/q1              | 179.67691   |
| training/sac_Q/q2              | 180.07071   |
| training/sac_Q/q2_loss         | 77.63536    |
| training/sac_Q/q_global_norm   | 371.15543   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14938802  |
| epoch                          | 39          |
| evaluation/episode-length-avg  | 159         |
| evaluation/episode-length-max  | 189         |
| evaluation/episode-length-min  | 138         |
| evaluation/episode-length-std  | 15.8        |
| evaluation/return-average      | 390.1623    |
| evaluation/return-max          | 423.9267    |
| evaluation/return-min          | 368.5614    |
| evaluation/return-std          | 19.629517   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.91        |
| model/origin_ret               | 87.1        |
| model/penalty_ret              | 83.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45213       |
| perf/AverageLength             | 159         |
| perf/AverageReturn             | 390.1623    |
| perf/NormalizedReturn          | 0.0846      |
| Q-avg                          | 171.20674   |
| Q-std                          | 80.02771    |
| Q_loss                         | 82.04738    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 39          |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.00011     |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000417    |
| times/evaluation_paths         | 6.56        |
| times/timestep_after_hook      | 0.00349     |
| times/timestep_before_hook     | 0.0081      |
| times/train                    | 59.4        |
| timestep                       | 1000        |
| timesteps_total                | 40000       |
| train-steps                    | 40000       |
| training/Q/q1_loss             | 89.1046     |
| training/sac_pi/alpha          | 0.14939727  |
| training/sac_pi/alpha_loss     | -0.06868177 |
| training/sac_pi/logp_pi        | 3.6468315   |
| training/sac_pi/pi_entropy     | 3.6947773   |
| training/sac_pi/pi_global_norm | 1.4209815   |
| training/sac_pi/policy_loss    | -180.41684  |
| training/sac_pi/std            | 0.49112266  |
| training/sac_pi/valid_num      | 5017.0      |
| training/sac_Q/q1              | 177.45218   |
| training/sac_Q/q2              | 177.37402   |
| training/sac_Q/q2_loss         | 89.16376    |
| training/sac_Q/q_global_norm   | 316.7676    |
---------------------------------------------------------------------------------
[WARN] 40 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.14947304 |
| epoch                          | 40         |
| evaluation/episode-length-avg  | 144        |
| evaluation/episode-length-max  | 149        |
| evaluation/episode-length-min  | 141        |
| evaluation/episode-length-std  | 2.8        |
| evaluation/return-average      | 230.11868  |
| evaluation/return-max          | 244.28807  |
| evaluation/return-min          | 219.4764   |
| evaluation/return-std          | 7.4290276  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.83       |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45573      |
| perf/AverageLength             | 144        |
| perf/AverageReturn             | 230.11868  |
| perf/NormalizedReturn          | 0.0498     |
| Q-avg                          | 174.663    |
| Q-std                          | 80.67487   |
| Q_loss                         | 68.445656  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 40         |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 5.99e-05   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000396   |
| times/evaluation_paths         | 4.62       |
| times/timestep_after_hook      | 0.0035     |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 62.2       |
| timestep                       | 1000       |
| timesteps_total                | 41000      |
| train-steps                    | 41000      |
| training/Q/q1_loss             | 87.01604   |
| training/sac_pi/alpha          | 0.1494948  |
| training/sac_pi/alpha_loss     | 0.19808996 |
| training/sac_pi/logp_pi        | 4.5375247  |
| training/sac_pi/pi_entropy     | 3.6739488  |
| training/sac_pi/pi_global_norm | 1.0190829  |
| training/sac_pi/policy_loss    | -180.08853 |
| training/sac_pi/std            | 0.5203469  |
| training/sac_pi/valid_num      | 4864.0     |
| training/sac_Q/q1              | 171.3357   |
| training/sac_Q/q2              | 170.55911  |
| training/sac_Q/q2_loss         | 86.89979   |
| training/sac_Q/q_global_norm   | 229.99638  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14882511  |
| epoch                          | 41          |
| evaluation/episode-length-avg  | 165         |
| evaluation/episode-length-max  | 167         |
| evaluation/episode-length-min  | 161         |
| evaluation/episode-length-std  | 2           |
| evaluation/return-average      | 370.6763    |
| evaluation/return-max          | 376.11554   |
| evaluation/return-min          | 366.417     |
| evaluation/return-std          | 2.9507072   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.86        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 82.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45570       |
| perf/AverageLength             | 165         |
| perf/AverageReturn             | 370.6763    |
| perf/NormalizedReturn          | 0.0804      |
| Q-avg                          | 171.27744   |
| Q-std                          | 82.79122    |
| Q_loss                         | 89.71739    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 41          |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000313    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000457    |
| times/evaluation_paths         | 5.27        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00879     |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 42000       |
| train-steps                    | 42000       |
| training/Q/q1_loss             | 74.26132    |
| training/sac_pi/alpha          | 0.14881909  |
| training/sac_pi/alpha_loss     | -0.04942941 |
| training/sac_pi/logp_pi        | 5.2399077   |
| training/sac_pi/pi_entropy     | 3.6736355   |
| training/sac_pi/pi_global_norm | 0.9546688   |
| training/sac_pi/policy_loss    | -182.21301  |
| training/sac_pi/std            | 0.5475481   |
| training/sac_pi/valid_num      | 4853.0      |
| training/sac_Q/q1              | 172.57698   |
| training/sac_Q/q2              | 171.20389   |
| training/sac_Q/q2_loss         | 73.97994    |
| training/sac_Q/q_global_norm   | 339.83282   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.14511085  |
| epoch                          | 42          |
| evaluation/episode-length-avg  | 710         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 123         |
| evaluation/episode-length-std  | 371         |
| evaluation/return-average      | 3162.173    |
| evaluation/return-max          | 4597.1206   |
| evaluation/return-min          | 355.21637   |
| evaluation/return-std          | 1774.0796   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.84        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45683       |
| perf/AverageLength             | 710         |
| perf/AverageReturn             | 3162.173    |
| perf/NormalizedReturn          | 0.688       |
| Q-avg                          | 182.88509   |
| Q-std                          | 74.250854   |
| Q_loss                         | 81.13383    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 42          |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000112    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000485    |
| times/evaluation_paths         | 24.1        |
| times/timestep_after_hook      | 0.00357     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 43000       |
| train-steps                    | 43000       |
| training/Q/q1_loss             | 68.86489    |
| training/sac_pi/alpha          | 0.14512326  |
| training/sac_pi/alpha_loss     | -0.43317774 |
| training/sac_pi/logp_pi        | 4.2109466   |
| training/sac_pi/pi_entropy     | 3.8447623   |
| training/sac_pi/pi_global_norm | 1.3998464   |
| training/sac_pi/policy_loss    | -191.46112  |
| training/sac_pi/std            | 0.5442629   |
| training/sac_pi/valid_num      | 4949.0      |
| training/sac_Q/q1              | 186.11641   |
| training/sac_Q/q2              | 185.5946    |
| training/sac_Q/q2_loss         | 69.194336   |
| training/sac_Q/q_global_norm   | 206.35948   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.152441   |
| epoch                          | 43         |
| evaluation/episode-length-avg  | 92         |
| evaluation/episode-length-max  | 98         |
| evaluation/episode-length-min  | 81         |
| evaluation/episode-length-std  | 5.95       |
| evaluation/return-average      | 135.66528  |
| evaluation/return-max          | 144.93198  |
| evaluation/return-min          | 118.827324 |
| evaluation/return-std          | 8.859401   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.75       |
| model/origin_ret               | 82.1       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45640      |
| perf/AverageLength             | 92         |
| perf/AverageReturn             | 135.66528  |
| perf/NormalizedReturn          | 0.0292     |
| Q-avg                          | 175.5218   |
| Q-std                          | 80.71218   |
| Q_loss                         | 85.86131   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 43         |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000109   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.0004     |
| times/evaluation_paths         | 3.97       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 44000      |
| train-steps                    | 44000      |
| training/Q/q1_loss             | 86.79974   |
| training/sac_pi/alpha          | 0.1524518  |
| training/sac_pi/alpha_loss     | 0.2557711  |
| training/sac_pi/logp_pi        | 4.7399783  |
| training/sac_pi/pi_entropy     | 3.933268   |
| training/sac_pi/pi_global_norm | 1.9532982  |
| training/sac_pi/policy_loss    | -179.15845 |
| training/sac_pi/std            | 0.5550474  |
| training/sac_pi/valid_num      | 4934.0     |
| training/sac_Q/q1              | 172.61539  |
| training/sac_Q/q2              | 171.7055   |
| training/sac_Q/q2_loss         | 86.24968   |
| training/sac_Q/q_global_norm   | 286.13083  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15543771   |
| epoch                          | 44           |
| evaluation/episode-length-avg  | 170          |
| evaluation/episode-length-max  | 188          |
| evaluation/episode-length-min  | 162          |
| evaluation/episode-length-std  | 7.28         |
| evaluation/return-average      | 377.9476     |
| evaluation/return-max          | 401.92664    |
| evaluation/return-min          | 368.64148    |
| evaluation/return-std          | 9.405496     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.85         |
| model/origin_ret               | 84.4         |
| model/penalty_ret              | 82.2         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 45743        |
| perf/AverageLength             | 170          |
| perf/AverageReturn             | 377.9476     |
| perf/NormalizedReturn          | 0.082        |
| Q-avg                          | 174.54254    |
| Q-std                          | 83.027565    |
| Q_loss                         | 85.09226     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 44           |
| times/epoch_after_hook         | 1.68e-06     |
| times/epoch_before_hook        | 8.24e-05     |
| times/epoch_rollout_model      | 479          |
| times/evaluation_metrics       | 0.000443     |
| times/evaluation_paths         | 5.32         |
| times/timestep_after_hook      | 0.00355      |
| times/timestep_before_hook     | 0.00825      |
| times/train                    | 60.7         |
| timestep                       | 1000         |
| timesteps_total                | 45000        |
| train-steps                    | 45000        |
| training/Q/q1_loss             | 83.72667     |
| training/sac_pi/alpha          | 0.15543105   |
| training/sac_pi/alpha_loss     | -0.027002314 |
| training/sac_pi/logp_pi        | 4.005016     |
| training/sac_pi/pi_entropy     | 3.7520623    |
| training/sac_pi/pi_global_norm | 1.5685354    |
| training/sac_pi/policy_loss    | -179.253     |
| training/sac_pi/std            | 0.49968415   |
| training/sac_pi/valid_num      | 4990.0       |
| training/sac_Q/q1              | 175.32846    |
| training/sac_Q/q2              | 175.20616    |
| training/sac_Q/q2_loss         | 84.47465     |
| training/sac_Q/q_global_norm   | 293.09323    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14807734 |
| epoch                          | 45         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4721.044   |
| evaluation/return-max          | 4873.423   |
| evaluation/return-min          | 4508.085   |
| evaluation/return-std          | 119.459305 |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 82.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45579      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4721.044   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 167.68715  |
| Q-std                          | 88.60401   |
| Q_loss                         | 80.92737   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 45         |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000269   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000627   |
| times/evaluation_paths         | 35.5       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 60         |
| timestep                       | 1000       |
| timesteps_total                | 46000      |
| train-steps                    | 46000      |
| training/Q/q1_loss             | 78.31203   |
| training/sac_pi/alpha          | 0.14801715 |
| training/sac_pi/alpha_loss     | 0.8182273  |
| training/sac_pi/logp_pi        | 4.570828   |
| training/sac_pi/pi_entropy     | 3.7447724  |
| training/sac_pi/pi_global_norm | 1.469484   |
| training/sac_pi/policy_loss    | -185.82718 |
| training/sac_pi/std            | 0.5189941  |
| training/sac_pi/valid_num      | 4995.0     |
| training/sac_Q/q1              | 181.5749   |
| training/sac_Q/q2              | 180.77553  |
| training/sac_Q/q2_loss         | 78.947876  |
| training/sac_Q/q_global_norm   | 302.19604  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1527037  |
| epoch                          | 46         |
| evaluation/episode-length-avg  | 115        |
| evaluation/episode-length-max  | 131        |
| evaluation/episode-length-min  | 105        |
| evaluation/episode-length-std  | 10.7       |
| evaluation/return-average      | 227.67038  |
| evaluation/return-max          | 277.32257  |
| evaluation/return-min          | 196.1365   |
| evaluation/return-std          | 34.232094  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 82.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45523      |
| perf/AverageLength             | 115        |
| perf/AverageReturn             | 227.67038  |
| perf/NormalizedReturn          | 0.0492     |
| Q-avg                          | 177.79732  |
| Q-std                          | 85.53194   |
| Q_loss                         | 102.551186 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 46         |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000443   |
| times/evaluation_paths         | 5.2        |
| times/timestep_after_hook      | 0.00354    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 59.9       |
| timestep                       | 1000       |
| timesteps_total                | 47000      |
| train-steps                    | 47000      |
| training/Q/q1_loss             | 69.42539   |
| training/sac_pi/alpha          | 0.15271357 |
| training/sac_pi/alpha_loss     | 0.10912269 |
| training/sac_pi/logp_pi        | 4.650289   |
| training/sac_pi/pi_entropy     | 4.0823     |
| training/sac_pi/pi_global_norm | 1.5235757  |
| training/sac_pi/policy_loss    | -188.29262 |
| training/sac_pi/std            | 0.5594786  |
| training/sac_pi/valid_num      | 4946.0     |
| training/sac_Q/q1              | 182.76212  |
| training/sac_Q/q2              | 182.13829  |
| training/sac_Q/q2_loss         | 69.30586   |
| training/sac_Q/q_global_norm   | 217.7253   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15218478 |
| epoch                          | 47         |
| evaluation/episode-length-avg  | 871        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 348        |
| evaluation/episode-length-std  | 258        |
| evaluation/return-average      | 4003.9858  |
| evaluation/return-max          | 4789.293   |
| evaluation/return-min          | 1257.8994  |
| evaluation/return-std          | 1358.1919  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.88       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 82.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45189      |
| perf/AverageLength             | 871        |
| perf/AverageReturn             | 4003.9858  |
| perf/NormalizedReturn          | 0.872      |
| Q-avg                          | 180.03365  |
| Q-std                          | 77.32531   |
| Q_loss                         | 87.05166   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 47         |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 8.36e-05   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.0005     |
| times/evaluation_paths         | 30.5       |
| times/timestep_after_hook      | 0.00356    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 48000      |
| train-steps                    | 48000      |
| training/Q/q1_loss             | 101.64214  |
| training/sac_pi/alpha          | 0.15217474 |
| training/sac_pi/alpha_loss     | 0.36516437 |
| training/sac_pi/logp_pi        | 5.0312667  |
| training/sac_pi/pi_entropy     | 3.6401317  |
| training/sac_pi/pi_global_norm | 1.7844889  |
| training/sac_pi/policy_loss    | -178.7353  |
| training/sac_pi/std            | 0.5184414  |
| training/sac_pi/valid_num      | 4890.0     |
| training/sac_Q/q1              | 170.96289  |
| training/sac_Q/q2              | 170.68083  |
| training/sac_Q/q2_loss         | 101.87082  |
| training/sac_Q/q_global_norm   | 265.27316  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15510549 |
| epoch                          | 48         |
| evaluation/episode-length-avg  | 126        |
| evaluation/episode-length-max  | 135        |
| evaluation/episode-length-min  | 120        |
| evaluation/episode-length-std  | 4.52       |
| evaluation/return-average      | 262.9553   |
| evaluation/return-max          | 293.33282  |
| evaluation/return-min          | 237.7659   |
| evaluation/return-std          | 16.345953  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.78       |
| model/origin_ret               | 83.4       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45485      |
| perf/AverageLength             | 126        |
| perf/AverageReturn             | 262.9553   |
| perf/NormalizedReturn          | 0.0569     |
| Q-avg                          | 165.78436  |
| Q-std                          | 82.337265  |
| Q_loss                         | 112.48037  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 48         |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000552   |
| times/evaluation_paths         | 4          |
| times/timestep_after_hook      | 0.00356    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 59.3       |
| timestep                       | 1000       |
| timesteps_total                | 49000      |
| train-steps                    | 49000      |
| training/Q/q1_loss             | 94.47609   |
| training/sac_pi/alpha          | 0.15505908 |
| training/sac_pi/alpha_loss     | 0.4826568  |
| training/sac_pi/logp_pi        | 5.0500517  |
| training/sac_pi/pi_entropy     | 3.734398   |
| training/sac_pi/pi_global_norm | 2.7315283  |
| training/sac_pi/policy_loss    | -176.46884 |
| training/sac_pi/std            | 0.54906964 |
| training/sac_pi/valid_num      | 4902.0     |
| training/sac_Q/q1              | 169.16727  |
| training/sac_Q/q2              | 168.43314  |
| training/sac_Q/q2_loss         | 94.59707   |
| training/sac_Q/q_global_norm   | 315.017    |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15624915 |
| epoch                          | 49         |
| evaluation/episode-length-avg  | 145        |
| evaluation/episode-length-max  | 169        |
| evaluation/episode-length-min  | 126        |
| evaluation/episode-length-std  | 12.4       |
| evaluation/return-average      | 324.87045  |
| evaluation/return-max          | 404.82996  |
| evaluation/return-min          | 265.06244  |
| evaluation/return-std          | 41.379158  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.74       |
| model/origin_ret               | 83.4       |
| model/penalty_ret              | 82.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45489      |
| perf/AverageLength             | 145        |
| perf/AverageReturn             | 324.87045  |
| perf/NormalizedReturn          | 0.0704     |
| Q-avg                          | 179.44064  |
| Q-std                          | 83.94038   |
| Q_loss                         | 103.66497  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 49         |
| times/epoch_after_hook         | 2.09e-06   |
| times/epoch_before_hook        | 0.000268   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000547   |
| times/evaluation_paths         | 6.3        |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00803    |
| times/train                    | 59.3       |
| timestep                       | 1000       |
| timesteps_total                | 50000      |
| train-steps                    | 50000      |
| training/Q/q1_loss             | 108.43071  |
| training/sac_pi/alpha          | 0.15618461 |
| training/sac_pi/alpha_loss     | 0.81395125 |
| training/sac_pi/logp_pi        | 4.666299   |
| training/sac_pi/pi_entropy     | 4.013138   |
| training/sac_pi/pi_global_norm | 1.7628535  |
| training/sac_pi/policy_loss    | -179.39677 |
| training/sac_pi/std            | 0.5409264  |
| training/sac_pi/valid_num      | 4977.0     |
| training/sac_Q/q1              | 175.2864   |
| training/sac_Q/q2              | 174.4426   |
| training/sac_Q/q2_loss         | 107.6756   |
| training/sac_Q/q_global_norm   | 265.79517  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15008925 |
| epoch                          | 50         |
| evaluation/episode-length-avg  | 168        |
| evaluation/episode-length-max  | 171        |
| evaluation/episode-length-min  | 164        |
| evaluation/episode-length-std  | 2.15       |
| evaluation/return-average      | 334.30472  |
| evaluation/return-max          | 346.5464   |
| evaluation/return-min          | 321.66882  |
| evaluation/return-std          | 7.1653385  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45676      |
| perf/AverageLength             | 168        |
| perf/AverageReturn             | 334.30472  |
| perf/NormalizedReturn          | 0.0725     |
| Q-avg                          | 191.03757  |
| Q-std                          | 73.008484  |
| Q_loss                         | 90.436066  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 50         |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 7.34e-05   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000539   |
| times/evaluation_paths         | 5.43       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 61.5       |
| timestep                       | 1000       |
| timesteps_total                | 51000      |
| train-steps                    | 51000      |
| training/Q/q1_loss             | 103.52664  |
| training/sac_pi/alpha          | 0.15005375 |
| training/sac_pi/alpha_loss     | 0.5394839  |
| training/sac_pi/logp_pi        | 4.679854   |
| training/sac_pi/pi_entropy     | 3.7648807  |
| training/sac_pi/pi_global_norm | 1.4620246  |
| training/sac_pi/policy_loss    | -181.01505 |
| training/sac_pi/std            | 0.5259455  |
| training/sac_pi/valid_num      | 4903.0     |
| training/sac_Q/q1              | 173.57889  |
| training/sac_Q/q2              | 173.55507  |
| training/sac_Q/q2_loss         | 102.77764  |
| training/sac_Q/q_global_norm   | 359.86777  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15358976 |
| epoch                          | 51         |
| evaluation/episode-length-avg  | 484        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 410        |
| evaluation/episode-length-std  | 172        |
| evaluation/return-average      | 884.5137   |
| evaluation/return-max          | 3211.9531  |
| evaluation/return-min          | 610.13544  |
| evaluation/return-std          | 776.21326  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.83       |
| model/origin_ret               | 82.6       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45895      |
| perf/AverageLength             | 484        |
| perf/AverageReturn             | 884.5137   |
| perf/NormalizedReturn          | 0.192      |
| Q-avg                          | 186.27222  |
| Q-std                          | 78.9961    |
| Q_loss                         | 104.99436  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 51         |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.00061    |
| times/evaluation_paths         | 17.2       |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 52000      |
| train-steps                    | 52000      |
| training/Q/q1_loss             | 115.88811  |
| training/sac_pi/alpha          | 0.15357311 |
| training/sac_pi/alpha_loss     | 0.57138115 |
| training/sac_pi/logp_pi        | 4.738608   |
| training/sac_pi/pi_entropy     | 3.6545258  |
| training/sac_pi/pi_global_norm | 1.3947749  |
| training/sac_pi/policy_loss    | -180.36018 |
| training/sac_pi/std            | 0.5297297  |
| training/sac_pi/valid_num      | 4920.0     |
| training/sac_Q/q1              | 174.06091  |
| training/sac_Q/q2              | 173.20802  |
| training/sac_Q/q2_loss         | 115.112206 |
| training/sac_Q/q_global_norm   | 258.70816  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15653639 |
| epoch                          | 52         |
| evaluation/episode-length-avg  | 113        |
| evaluation/episode-length-max  | 114        |
| evaluation/episode-length-min  | 112        |
| evaluation/episode-length-std  | 0.632      |
| evaluation/return-average      | 237.47456  |
| evaluation/return-max          | 242.81573  |
| evaluation/return-min          | 233.60481  |
| evaluation/return-std          | 2.7545185  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 83.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45504      |
| perf/AverageLength             | 113        |
| perf/AverageReturn             | 237.47456  |
| perf/NormalizedReturn          | 0.0514     |
| Q-avg                          | 174.08218  |
| Q-std                          | 80.89821   |
| Q_loss                         | 91.32665   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 52         |
| times/epoch_after_hook         | 2.13e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 517        |
| times/evaluation_metrics       | 0.000771   |
| times/evaluation_paths         | 3.75       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 59.2       |
| timestep                       | 1000       |
| timesteps_total                | 53000      |
| train-steps                    | 53000      |
| training/Q/q1_loss             | 86.28965   |
| training/sac_pi/alpha          | 0.15654315 |
| training/sac_pi/alpha_loss     | -0.2748063 |
| training/sac_pi/logp_pi        | 4.3005023  |
| training/sac_pi/pi_entropy     | 3.8033187  |
| training/sac_pi/pi_global_norm | 1.8664969  |
| training/sac_pi/policy_loss    | -179.01572 |
| training/sac_pi/std            | 0.5333356  |
| training/sac_pi/valid_num      | 4956.0     |
| training/sac_Q/q1              | 173.70786  |
| training/sac_Q/q2              | 172.80345  |
| training/sac_Q/q2_loss         | 86.31572   |
| training/sac_Q/q_global_norm   | 191.19464  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.14732686 |
| epoch                          | 53         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4208.0225  |
| evaluation/return-max          | 4278.462   |
| evaluation/return-min          | 4120.46    |
| evaluation/return-std          | 53.175716  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.89       |
| model/origin_ret               | 83.7       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45734      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4208.0225  |
| perf/NormalizedReturn          | 0.916      |
| Q-avg                          | 172.96683  |
| Q-std                          | 84.2174    |
| Q_loss                         | 79.86174   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 53         |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000317   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000597   |
| times/evaluation_paths         | 34         |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00805    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 54000      |
| train-steps                    | 54000      |
| training/Q/q1_loss             | 89.70408   |
| training/sac_pi/alpha          | 0.14730999 |
| training/sac_pi/alpha_loss     | 0.21455435 |
| training/sac_pi/logp_pi        | 4.0243216  |
| training/sac_pi/pi_entropy     | 3.713356   |
| training/sac_pi/pi_global_norm | 2.0349245  |
| training/sac_pi/policy_loss    | -180.18733 |
| training/sac_pi/std            | 0.5155903  |
| training/sac_pi/valid_num      | 5006.0     |
| training/sac_Q/q1              | 176.96231  |
| training/sac_Q/q2              | 177.0032   |
| training/sac_Q/q2_loss         | 89.261154  |
| training/sac_Q/q_global_norm   | 251.81958  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15321155  |
| epoch                          | 54          |
| evaluation/episode-length-avg  | 659         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 146         |
| evaluation/episode-length-std  | 418         |
| evaluation/return-average      | 3364.2747   |
| evaluation/return-max          | 5454.5176   |
| evaluation/return-min          | 434.2494    |
| evaluation/return-std          | 2390.594    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.93        |
| model/origin_ret               | 87.4        |
| model/penalty_ret              | 84.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45235       |
| perf/AverageLength             | 659         |
| perf/AverageReturn             | 3364.2747   |
| perf/NormalizedReturn          | 0.732       |
| Q-avg                          | 178.81082   |
| Q-std                          | 85.30417    |
| Q_loss                         | 95.05991    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 54          |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000593    |
| times/evaluation_paths         | 22.2        |
| times/timestep_after_hook      | 0.00356     |
| times/timestep_before_hook     | 0.00822     |
| times/train                    | 59.2        |
| timestep                       | 1000        |
| timesteps_total                | 55000       |
| train-steps                    | 55000       |
| training/Q/q1_loss             | 106.70754   |
| training/sac_pi/alpha          | 0.15322489  |
| training/sac_pi/alpha_loss     | -0.27228656 |
| training/sac_pi/logp_pi        | 4.048285    |
| training/sac_pi/pi_entropy     | 3.8265412   |
| training/sac_pi/pi_global_norm | 1.4250239   |
| training/sac_pi/policy_loss    | -183.70935  |
| training/sac_pi/std            | 0.51365817  |
| training/sac_pi/valid_num      | 4943.0      |
| training/sac_Q/q1              | 178.0315    |
| training/sac_Q/q2              | 178.24184   |
| training/sac_Q/q2_loss         | 106.36677   |
| training/sac_Q/q_global_norm   | 271.33005   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1582539  |
| epoch                          | 55         |
| evaluation/episode-length-avg  | 776        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 254        |
| evaluation/episode-length-std  | 342        |
| evaluation/return-average      | 3433.873   |
| evaluation/return-max          | 4623.6025  |
| evaluation/return-min          | 834.38184  |
| evaluation/return-std          | 1700.8542  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.81       |
| model/origin_ret               | 83.2       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45744      |
| perf/AverageLength             | 776        |
| perf/AverageReturn             | 3433.873   |
| perf/NormalizedReturn          | 0.748      |
| Q-avg                          | 180.76408  |
| Q-std                          | 81.9014    |
| Q_loss                         | 95.86244   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 55         |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000105   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000645   |
| times/evaluation_paths         | 26.7       |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 59         |
| timestep                       | 1000       |
| timesteps_total                | 56000      |
| train-steps                    | 56000      |
| training/Q/q1_loss             | 96.235886  |
| training/sac_pi/alpha          | 0.15818399 |
| training/sac_pi/alpha_loss     | 0.06893196 |
| training/sac_pi/logp_pi        | 5.1911135  |
| training/sac_pi/pi_entropy     | 3.8575478  |
| training/sac_pi/pi_global_norm | 2.0754702  |
| training/sac_pi/policy_loss    | -184.0078  |
| training/sac_pi/std            | 0.55467457 |
| training/sac_pi/valid_num      | 4904.0     |
| training/sac_Q/q1              | 176.97057  |
| training/sac_Q/q2              | 176.5637   |
| training/sac_Q/q2_loss         | 95.98053   |
| training/sac_Q/q_global_norm   | 248.08945  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15343992 |
| epoch                          | 56         |
| evaluation/episode-length-avg  | 136        |
| evaluation/episode-length-max  | 137        |
| evaluation/episode-length-min  | 134        |
| evaluation/episode-length-std  | 1          |
| evaluation/return-average      | 390.9981   |
| evaluation/return-max          | 401.14618  |
| evaluation/return-min          | 381.06998  |
| evaluation/return-std          | 6.970618   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 86.8       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45362      |
| perf/AverageLength             | 136        |
| perf/AverageReturn             | 390.9981   |
| perf/NormalizedReturn          | 0.0848     |
| Q-avg                          | 173.92966  |
| Q-std                          | 88.58557   |
| Q_loss                         | 84.79818   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 56         |
| times/epoch_after_hook         | 3.13e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000698   |
| times/evaluation_paths         | 4.43       |
| times/timestep_after_hook      | 0.00355    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 57000      |
| train-steps                    | 57000      |
| training/Q/q1_loss             | 84.163765  |
| training/sac_pi/alpha          | 0.1534257  |
| training/sac_pi/alpha_loss     | 0.28849888 |
| training/sac_pi/logp_pi        | 4.306712   |
| training/sac_pi/pi_entropy     | 3.5675483  |
| training/sac_pi/pi_global_norm | 1.875832   |
| training/sac_pi/policy_loss    | -195.6951  |
| training/sac_pi/std            | 0.50044113 |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 190.64217  |
| training/sac_Q/q2              | 189.72244  |
| training/sac_Q/q2_loss         | 84.842125  |
| training/sac_Q/q_global_norm   | 284.55682  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16168356  |
| epoch                          | 57          |
| evaluation/episode-length-avg  | 126         |
| evaluation/episode-length-max  | 131         |
| evaluation/episode-length-min  | 120         |
| evaluation/episode-length-std  | 4.5         |
| evaluation/return-average      | 310.81915   |
| evaluation/return-max          | 328.23322   |
| evaluation/return-min          | 296.79996   |
| evaluation/return-std          | 11.725126   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.82        |
| model/origin_ret               | 82          |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45806       |
| perf/AverageLength             | 126         |
| perf/AverageReturn             | 310.81915   |
| perf/NormalizedReturn          | 0.0674      |
| Q-avg                          | 177.91992   |
| Q-std                          | 81.98053    |
| Q_loss                         | 89.78732    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 57          |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000277    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.00054     |
| times/evaluation_paths         | 4.06        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 62.2        |
| timestep                       | 1000        |
| timesteps_total                | 58000       |
| train-steps                    | 58000       |
| training/Q/q1_loss             | 85.295235   |
| training/sac_pi/alpha          | 0.16166213  |
| training/sac_pi/alpha_loss     | 0.016655972 |
| training/sac_pi/logp_pi        | 4.2149453   |
| training/sac_pi/pi_entropy     | 3.6671093   |
| training/sac_pi/pi_global_norm | 2.2826114   |
| training/sac_pi/policy_loss    | -178.36673  |
| training/sac_pi/std            | 0.5057493   |
| training/sac_pi/valid_num      | 4980.0      |
| training/sac_Q/q1              | 173.93408   |
| training/sac_Q/q2              | 174.22873   |
| training/sac_Q/q2_loss         | 84.571785   |
| training/sac_Q/q_global_norm   | 218.38196   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16033836 |
| epoch                          | 58         |
| evaluation/episode-length-avg  | 131        |
| evaluation/episode-length-max  | 132        |
| evaluation/episode-length-min  | 130        |
| evaluation/episode-length-std  | 0.7        |
| evaluation/return-average      | 333.05197  |
| evaluation/return-max          | 339.30585  |
| evaluation/return-min          | 324.85577  |
| evaluation/return-std          | 4.557955   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.87       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45735      |
| perf/AverageLength             | 131        |
| perf/AverageReturn             | 333.05197  |
| perf/NormalizedReturn          | 0.0722     |
| Q-avg                          | 183.40088  |
| Q-std                          | 79.46875   |
| Q_loss                         | 82.09213   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 58         |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000107   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000584   |
| times/evaluation_paths         | 4.27       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 59.7       |
| timestep                       | 1000       |
| timesteps_total                | 59000      |
| train-steps                    | 59000      |
| training/Q/q1_loss             | 79.87468   |
| training/sac_pi/alpha          | 0.16030186 |
| training/sac_pi/alpha_loss     | 0.2216015  |
| training/sac_pi/logp_pi        | 4.1579223  |
| training/sac_pi/pi_entropy     | 3.5495384  |
| training/sac_pi/pi_global_norm | 1.4590157  |
| training/sac_pi/policy_loss    | -185.44067 |
| training/sac_pi/std            | 0.5014701  |
| training/sac_pi/valid_num      | 4951.0     |
| training/sac_Q/q1              | 179.54716  |
| training/sac_Q/q2              | 179.7874   |
| training/sac_Q/q2_loss         | 79.33016   |
| training/sac_Q/q_global_norm   | 230.4717   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16062532  |
| epoch                          | 59          |
| evaluation/episode-length-avg  | 135         |
| evaluation/episode-length-max  | 137         |
| evaluation/episode-length-min  | 133         |
| evaluation/episode-length-std  | 1.51        |
| evaluation/return-average      | 355.9477    |
| evaluation/return-max          | 361.38605   |
| evaluation/return-min          | 350.50977   |
| evaluation/return-std          | 3.8069754   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45816       |
| perf/AverageLength             | 135         |
| perf/AverageReturn             | 355.9477    |
| perf/NormalizedReturn          | 0.0772      |
| Q-avg                          | 176.08887   |
| Q-std                          | 85.571754   |
| Q_loss                         | 82.55621    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 59          |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000485    |
| times/evaluation_paths         | 5.67        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 58.6        |
| timestep                       | 1000        |
| timesteps_total                | 60000       |
| train-steps                    | 60000       |
| training/Q/q1_loss             | 94.0624     |
| training/sac_pi/alpha          | 0.16064821  |
| training/sac_pi/alpha_loss     | -0.42882943 |
| training/sac_pi/logp_pi        | 3.8432553   |
| training/sac_pi/pi_entropy     | 3.6523232   |
| training/sac_pi/pi_global_norm | 1.4479189   |
| training/sac_pi/policy_loss    | -180.88991  |
| training/sac_pi/std            | 0.5038778   |
| training/sac_pi/valid_num      | 4947.0      |
| training/sac_Q/q1              | 175.28671   |
| training/sac_Q/q2              | 175.29584   |
| training/sac_Q/q2_loss         | 94.424774   |
| training/sac_Q/q_global_norm   | 277.2803    |
---------------------------------------------------------------------------------
[WARN] 60 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.15236758 |
| epoch                          | 60         |
| evaluation/episode-length-avg  | 506        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 136        |
| evaluation/episode-length-std  | 406        |
| evaluation/return-average      | 2338.2424  |
| evaluation/return-max          | 4953.7827  |
| evaluation/return-min          | 439.57428  |
| evaluation/return-std          | 2113.5762  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.9        |
| model/origin_ret               | 83.8       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45858      |
| perf/AverageLength             | 506        |
| perf/AverageReturn             | 2338.2424  |
| perf/NormalizedReturn          | 0.509      |
| Q-avg                          | 180.60071  |
| Q-std                          | 80.49667   |
| Q_loss                         | 102.424706 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 60         |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 474        |
| times/evaluation_metrics       | 0.000453   |
| times/evaluation_paths         | 16         |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 61000      |
| train-steps                    | 61000      |
| training/Q/q1_loss             | 75.72089   |
| training/sac_pi/alpha          | 0.15233038 |
| training/sac_pi/alpha_loss     | 0.18274541 |
| training/sac_pi/logp_pi        | 4.0178847  |
| training/sac_pi/pi_entropy     | 3.6684074  |
| training/sac_pi/pi_global_norm | 1.331542   |
| training/sac_pi/policy_loss    | -183.87962 |
| training/sac_pi/std            | 0.49669278 |
| training/sac_pi/valid_num      | 4998.0     |
| training/sac_Q/q1              | 180.05296  |
| training/sac_Q/q2              | 179.85257  |
| training/sac_Q/q2_loss         | 76.45151   |
| training/sac_Q/q_global_norm   | 216.98485  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16863942 |
| epoch                          | 61         |
| evaluation/episode-length-avg  | 891        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 387        |
| evaluation/episode-length-std  | 220        |
| evaluation/return-average      | 3894.2788  |
| evaluation/return-max          | 4646.406   |
| evaluation/return-min          | 1357.9711  |
| evaluation/return-std          | 1097.8815  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 83.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45557      |
| perf/AverageLength             | 891        |
| perf/AverageReturn             | 3894.2788  |
| perf/NormalizedReturn          | 0.848      |
| Q-avg                          | 179.41171  |
| Q-std                          | 84.40063   |
| Q_loss                         | 91.83342   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 61         |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.00029    |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000701   |
| times/evaluation_paths         | 29.9       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 62000      |
| train-steps                    | 62000      |
| training/Q/q1_loss             | 93.5817    |
| training/sac_pi/alpha          | 0.16865323 |
| training/sac_pi/alpha_loss     | 0.15431954 |
| training/sac_pi/logp_pi        | 3.694121   |
| training/sac_pi/pi_entropy     | 3.812167   |
| training/sac_pi/pi_global_norm | 1.9913076  |
| training/sac_pi/policy_loss    | -196.36768 |
| training/sac_pi/std            | 0.48895612 |
| training/sac_pi/valid_num      | 4983.0     |
| training/sac_Q/q1              | 191.87207  |
| training/sac_Q/q2              | 191.95113  |
| training/sac_Q/q2_loss         | 92.7731    |
| training/sac_Q/q_global_norm   | 222.72173  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15687294  |
| epoch                          | 62          |
| evaluation/episode-length-avg  | 741         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 134         |
| evaluation/episode-length-std  | 396         |
| evaluation/return-average      | 3808.7935   |
| evaluation/return-max          | 5299.776    |
| evaluation/return-min          | 367.56445   |
| evaluation/return-std          | 2245.6863   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.85        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 83          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45444       |
| perf/AverageLength             | 741         |
| perf/AverageReturn             | 3808.7935   |
| perf/NormalizedReturn          | 0.829       |
| Q-avg                          | 177.46048   |
| Q-std                          | 89.408165   |
| Q_loss                         | 101.42483   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 62          |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 474         |
| times/evaluation_metrics       | 0.000652    |
| times/evaluation_paths         | 25.2        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 63000       |
| train-steps                    | 63000       |
| training/Q/q1_loss             | 75.20415    |
| training/sac_pi/alpha          | 0.15692037  |
| training/sac_pi/alpha_loss     | -0.52122545 |
| training/sac_pi/logp_pi        | 3.1990886   |
| training/sac_pi/pi_entropy     | 3.8138885   |
| training/sac_pi/pi_global_norm | 1.2976999   |
| training/sac_pi/policy_loss    | -192.1526   |
| training/sac_pi/std            | 0.49966905  |
| training/sac_pi/valid_num      | 5030.0      |
| training/sac_Q/q1              | 189.59413   |
| training/sac_Q/q2              | 189.62646   |
| training/sac_Q/q2_loss         | 74.69702    |
| training/sac_Q/q_global_norm   | 371.15732   |
---------------------------------------------------------------------------------
------------------------------------------------------------------------------------
| alpha                          | 0.16203476     |
| epoch                          | 63             |
| evaluation/episode-length-avg  | 101            |
| evaluation/episode-length-max  | 107            |
| evaluation/episode-length-min  | 97             |
| evaluation/episode-length-std  | 3.38           |
| evaluation/return-average      | 171.18814      |
| evaluation/return-max          | 198.37016      |
| evaluation/return-min          | 158.18279      |
| evaluation/return-std          | 14.331174      |
| model/max_penalty              | 7.24           |
| model/mean_rollout_length      | 20             |
| model/mean_rollout_reward      | 2.91           |
| model/origin_ret               | 84.2           |
| model/penalty_ret              | 81.8           |
| model/val_loss                 | 0.40512508     |
| model/valid_num                | 45715          |
| perf/AverageLength             | 101            |
| perf/AverageReturn             | 171.18814      |
| perf/NormalizedReturn          | 0.0369         |
| Q-avg                          | 181.36633      |
| Q-std                          | 80.37675       |
| Q_loss                         | 93.24906       |
| sampler/episodes               | 0              |
| sampler/last-path-return       | 0              |
| sampler/max-path-return        | -inf           |
| sampler/pool-size              | 1000000        |
| sampler/total-samples          | 0              |
| time-step                      | 63             |
| times/epoch_after_hook         | 1.8e-06        |
| times/epoch_before_hook        | 0.000118       |
| times/epoch_rollout_model      | 476            |
| times/evaluation_metrics       | 0.000504       |
| times/evaluation_paths         | 4.73           |
| times/timestep_after_hook      | 0.0036         |
| times/timestep_before_hook     | 0.00807        |
| times/train                    | 58.4           |
| timestep                       | 1000           |
| timesteps_total                | 64000          |
| train-steps                    | 64000          |
| training/Q/q1_loss             | 92.396034      |
| training/sac_pi/alpha          | 0.16201681     |
| training/sac_pi/alpha_loss     | -0.00016064776 |
| training/sac_pi/logp_pi        | 3.800277       |
| training/sac_pi/pi_entropy     | 3.801525       |
| training/sac_pi/pi_global_norm | 1.1796709      |
| training/sac_pi/policy_loss    | -187.3851      |
| training/sac_pi/std            | 0.5053211      |
| training/sac_pi/valid_num      | 4998.0         |
| training/sac_Q/q1              | 182.98076      |
| training/sac_Q/q2              | 182.44145      |
| training/sac_Q/q2_loss         | 92.30559       |
| training/sac_Q/q_global_norm   | 386.27527      |
------------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16034049 |
| epoch                          | 64         |
| evaluation/episode-length-avg  | 99.7       |
| evaluation/episode-length-max  | 102        |
| evaluation/episode-length-min  | 98         |
| evaluation/episode-length-std  | 1          |
| evaluation/return-average      | 207.2321   |
| evaluation/return-max          | 214.61893  |
| evaluation/return-min          | 200.4332   |
| evaluation/return-std          | 3.8975527  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 82.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45547      |
| perf/AverageLength             | 99.7       |
| perf/AverageReturn             | 207.2321   |
| perf/NormalizedReturn          | 0.0448     |
| Q-avg                          | 177.58517  |
| Q-std                          | 88.24699   |
| Q_loss                         | 113.17051  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 64         |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000101   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000479   |
| times/evaluation_paths         | 4.43       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 65000      |
| train-steps                    | 65000      |
| training/Q/q1_loss             | 94.21934   |
| training/sac_pi/alpha          | 0.16037987 |
| training/sac_pi/alpha_loss     | -0.3853357 |
| training/sac_pi/logp_pi        | 3.7514298  |
| training/sac_pi/pi_entropy     | 3.6369305  |
| training/sac_pi/pi_global_norm | 1.2966976  |
| training/sac_pi/policy_loss    | -197.13353 |
| training/sac_pi/std            | 0.4983014  |
| training/sac_pi/valid_num      | 4984.0     |
| training/sac_Q/q1              | 192.65773  |
| training/sac_Q/q2              | 192.15616  |
| training/sac_Q/q2_loss         | 94.05532   |
| training/sac_Q/q_global_norm   | 355.2166   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16619183  |
| epoch                          | 65          |
| evaluation/episode-length-avg  | 112         |
| evaluation/episode-length-max  | 113         |
| evaluation/episode-length-min  | 110         |
| evaluation/episode-length-std  | 0.98        |
| evaluation/return-average      | 247.2703    |
| evaluation/return-max          | 254.16905   |
| evaluation/return-min          | 239.51527   |
| evaluation/return-std          | 4.55757     |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 83.8        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45895       |
| perf/AverageLength             | 112         |
| perf/AverageReturn             | 247.2703    |
| perf/NormalizedReturn          | 0.0535      |
| Q-avg                          | 185.50745   |
| Q-std                          | 86.97347    |
| Q_loss                         | 107.67138   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 65          |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000276    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000482    |
| times/evaluation_paths         | 3.62        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 58.6        |
| timestep                       | 1000        |
| timesteps_total                | 66000       |
| train-steps                    | 66000       |
| training/Q/q1_loss             | 87.259415   |
| training/sac_pi/alpha          | 0.16623874  |
| training/sac_pi/alpha_loss     | 0.026138546 |
| training/sac_pi/logp_pi        | 5.4789386   |
| training/sac_pi/pi_entropy     | 3.478232    |
| training/sac_pi/pi_global_norm | 1.8776832   |
| training/sac_pi/policy_loss    | -189.0315   |
| training/sac_pi/std            | 0.52258414  |
| training/sac_pi/valid_num      | 4871.0      |
| training/sac_Q/q1              | 180.15901   |
| training/sac_Q/q2              | 179.56947   |
| training/sac_Q/q2_loss         | 86.99694    |
| training/sac_Q/q_global_norm   | 220.20743   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16707599   |
| epoch                          | 66           |
| evaluation/episode-length-avg  | 110          |
| evaluation/episode-length-max  | 112          |
| evaluation/episode-length-min  | 109          |
| evaluation/episode-length-std  | 1.02         |
| evaluation/return-average      | 202.92891    |
| evaluation/return-max          | 207.43552    |
| evaluation/return-min          | 197.51912    |
| evaluation/return-std          | 3.2981603    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.84         |
| model/origin_ret               | 84.4         |
| model/penalty_ret              | 81.1         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 45474        |
| perf/AverageLength             | 110          |
| perf/AverageReturn             | 202.92891    |
| perf/NormalizedReturn          | 0.0438       |
| Q-avg                          | 182.40077    |
| Q-std                          | 83.05206     |
| Q_loss                         | 85.27243     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 66           |
| times/epoch_after_hook         | 1.65e-06     |
| times/epoch_before_hook        | 8.5e-05      |
| times/epoch_rollout_model      | 480          |
| times/evaluation_metrics       | 0.000414     |
| times/evaluation_paths         | 3.55         |
| times/timestep_after_hook      | 0.00359      |
| times/timestep_before_hook     | 0.00827      |
| times/train                    | 60           |
| timestep                       | 1000         |
| timesteps_total                | 67000        |
| train-steps                    | 67000        |
| training/Q/q1_loss             | 75.66262     |
| training/sac_pi/alpha          | 0.16709262   |
| training/sac_pi/alpha_loss     | -0.124296084 |
| training/sac_pi/logp_pi        | 3.8593452    |
| training/sac_pi/pi_entropy     | 3.8194923    |
| training/sac_pi/pi_global_norm | 1.0939738    |
| training/sac_pi/policy_loss    | -193.72174   |
| training/sac_pi/std            | 0.5101045    |
| training/sac_pi/valid_num      | 4978.0       |
| training/sac_Q/q1              | 188.995      |
| training/sac_Q/q2              | 188.82889    |
| training/sac_Q/q2_loss         | 75.28574     |
| training/sac_Q/q_global_norm   | 233.6462     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16347636 |
| epoch                          | 67         |
| evaluation/episode-length-avg  | 944        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 442        |
| evaluation/episode-length-std  | 167        |
| evaluation/return-average      | 3974.5125  |
| evaluation/return-max          | 4489.255   |
| evaluation/return-min          | 1259.4344  |
| evaluation/return-std          | 914.3008   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45867      |
| perf/AverageLength             | 944        |
| perf/AverageReturn             | 3974.5125  |
| perf/NormalizedReturn          | 0.865      |
| Q-avg                          | 181.96957  |
| Q-std                          | 83.34734   |
| Q_loss                         | 87.62783   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 67         |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 6.56e-05   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000542   |
| times/evaluation_paths         | 32.4       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 59.4       |
| timestep                       | 1000       |
| timesteps_total                | 68000      |
| train-steps                    | 68000      |
| training/Q/q1_loss             | 85.75975   |
| training/sac_pi/alpha          | 0.1634563  |
| training/sac_pi/alpha_loss     | 0.43941474 |
| training/sac_pi/logp_pi        | 4.277185   |
| training/sac_pi/pi_entropy     | 3.63797    |
| training/sac_pi/pi_global_norm | 1.402723   |
| training/sac_pi/policy_loss    | -188.19164 |
| training/sac_pi/std            | 0.50019544 |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 183.24057  |
| training/sac_Q/q2              | 183.1742   |
| training/sac_Q/q2_loss         | 85.78985   |
| training/sac_Q/q_global_norm   | 291.60333  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16311386  |
| epoch                          | 68          |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4764.5615   |
| evaluation/return-max          | 5001.6084   |
| evaluation/return-min          | 4620.4976   |
| evaluation/return-std          | 117.308014  |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.9         |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 82.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45764       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4764.5615   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 185.9694    |
| Q-std                          | 90.51011    |
| Q_loss                         | 80.78611    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 68          |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000625    |
| times/evaluation_paths         | 35.2        |
| times/timestep_after_hook      | 0.00357     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 58          |
| timestep                       | 1000        |
| timesteps_total                | 69000       |
| train-steps                    | 69000       |
| training/Q/q1_loss             | 101.23922   |
| training/sac_pi/alpha          | 0.16312288  |
| training/sac_pi/alpha_loss     | 0.004961903 |
| training/sac_pi/logp_pi        | 5.000719    |
| training/sac_pi/pi_entropy     | 3.8300223   |
| training/sac_pi/pi_global_norm | 1.4997853   |
| training/sac_pi/policy_loss    | -190.93636  |
| training/sac_pi/std            | 0.5525173   |
| training/sac_pi/valid_num      | 4910.0      |
| training/sac_Q/q1              | 181.9366    |
| training/sac_Q/q2              | 181.19492   |
| training/sac_Q/q2_loss         | 101.22898   |
| training/sac_Q/q_global_norm   | 249.90411   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16381386 |
| epoch                          | 69         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4599.3022  |
| evaluation/return-max          | 4667.267   |
| evaluation/return-min          | 4538.291   |
| evaluation/return-std          | 43.8693    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 83.4       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45924      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4599.3022  |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 191.4031   |
| Q-std                          | 75.6139    |
| Q_loss                         | 88.23168   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 69         |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.000293   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000542   |
| times/evaluation_paths         | 33.5       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00811    |
| times/train                    | 59.7       |
| timestep                       | 1000       |
| timesteps_total                | 70000      |
| train-steps                    | 70000      |
| training/Q/q1_loss             | 113.73742  |
| training/sac_pi/alpha          | 0.16378278 |
| training/sac_pi/alpha_loss     | 0.06767503 |
| training/sac_pi/logp_pi        | 4.7690444  |
| training/sac_pi/pi_entropy     | 3.8031287  |
| training/sac_pi/pi_global_norm | 1.1921043  |
| training/sac_pi/policy_loss    | -184.456   |
| training/sac_pi/std            | 0.52343583 |
| training/sac_pi/valid_num      | 4855.0     |
| training/sac_Q/q1              | 175.3597   |
| training/sac_Q/q2              | 175.17781  |
| training/sac_Q/q2_loss         | 113.04881  |
| training/sac_Q/q_global_norm   | 328.98624  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15560743  |
| epoch                          | 70          |
| evaluation/episode-length-avg  | 139         |
| evaluation/episode-length-max  | 177         |
| evaluation/episode-length-min  | 127         |
| evaluation/episode-length-std  | 18.6        |
| evaluation/return-average      | 308.7647    |
| evaluation/return-max          | 413.58905   |
| evaluation/return-min          | 265.79733   |
| evaluation/return-std          | 52.31761    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 87          |
| model/penalty_ret              | 82.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45797       |
| perf/AverageLength             | 139         |
| perf/AverageReturn             | 308.7647    |
| perf/NormalizedReturn          | 0.0669      |
| Q-avg                          | 191.32889   |
| Q-std                          | 77.96499    |
| Q_loss                         | 108.701416  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 70          |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000594    |
| times/evaluation_paths         | 4.49        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00822     |
| times/train                    | 60.2        |
| timestep                       | 1000        |
| timesteps_total                | 71000       |
| train-steps                    | 71000       |
| training/Q/q1_loss             | 79.46504    |
| training/sac_pi/alpha          | 0.15558852  |
| training/sac_pi/alpha_loss     | -0.31575584 |
| training/sac_pi/logp_pi        | 4.1285543   |
| training/sac_pi/pi_entropy     | 3.6850693   |
| training/sac_pi/pi_global_norm | 1.28759     |
| training/sac_pi/policy_loss    | -195.26976  |
| training/sac_pi/std            | 0.5177554   |
| training/sac_pi/valid_num      | 4961.0      |
| training/sac_Q/q1              | 189.13295   |
| training/sac_Q/q2              | 189.22612   |
| training/sac_Q/q2_loss         | 79.88654    |
| training/sac_Q/q_global_norm   | 229.98102   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15810367  |
| epoch                          | 71          |
| evaluation/episode-length-avg  | 100         |
| evaluation/episode-length-max  | 102         |
| evaluation/episode-length-min  | 99          |
| evaluation/episode-length-std  | 0.98        |
| evaluation/return-average      | 192.66528   |
| evaluation/return-max          | 201.37076   |
| evaluation/return-min          | 187.75162   |
| evaluation/return-std          | 4.3515644   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45863       |
| perf/AverageLength             | 100         |
| perf/AverageReturn             | 192.66528   |
| perf/NormalizedReturn          | 0.0416      |
| Q-avg                          | 188.52705   |
| Q-std                          | 80.48866    |
| Q_loss                         | 110.42072   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 71          |
| times/epoch_after_hook         | 1.63e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000555    |
| times/evaluation_paths         | 3.32        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 59.2        |
| timestep                       | 1000        |
| timesteps_total                | 72000       |
| train-steps                    | 72000       |
| training/Q/q1_loss             | 83.47161    |
| training/sac_pi/alpha          | 0.1581222   |
| training/sac_pi/alpha_loss     | -0.24351765 |
| training/sac_pi/logp_pi        | 4.3517632   |
| training/sac_pi/pi_entropy     | 3.7118125   |
| training/sac_pi/pi_global_norm | 1.3544804   |
| training/sac_pi/policy_loss    | -190.50346  |
| training/sac_pi/std            | 0.5176574   |
| training/sac_pi/valid_num      | 4952.0      |
| training/sac_Q/q1              | 184.76144   |
| training/sac_Q/q2              | 183.67882   |
| training/sac_Q/q2_loss         | 83.72534    |
| training/sac_Q/q_global_norm   | 236.84595   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15917315 |
| epoch                          | 72         |
| evaluation/episode-length-avg  | 128        |
| evaluation/episode-length-max  | 129        |
| evaluation/episode-length-min  | 126        |
| evaluation/episode-length-std  | 0.831      |
| evaluation/return-average      | 297.81635  |
| evaluation/return-max          | 306.05493  |
| evaluation/return-min          | 286.8098   |
| evaluation/return-std          | 4.773896   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45694      |
| perf/AverageLength             | 128        |
| perf/AverageReturn             | 297.81635  |
| perf/NormalizedReturn          | 0.0645     |
| Q-avg                          | 176.89449  |
| Q-std                          | 88.87242   |
| Q_loss                         | 116.13181  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 72         |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000488   |
| times/evaluation_paths         | 4.25       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 58.2       |
| timestep                       | 1000       |
| timesteps_total                | 73000      |
| train-steps                    | 73000      |
| training/Q/q1_loss             | 81.85644   |
| training/sac_pi/alpha          | 0.15915062 |
| training/sac_pi/alpha_loss     | 0.39552265 |
| training/sac_pi/logp_pi        | 4.386654   |
| training/sac_pi/pi_entropy     | 3.674837   |
| training/sac_pi/pi_global_norm | 1.733535   |
| training/sac_pi/policy_loss    | -196.68982 |
| training/sac_pi/std            | 0.5193187  |
| training/sac_pi/valid_num      | 4956.0     |
| training/sac_Q/q1              | 190.62651  |
| training/sac_Q/q2              | 190.44528  |
| training/sac_Q/q2_loss         | 80.93545   |
| training/sac_Q/q_global_norm   | 257.4814   |
--------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.15545814    |
| epoch                          | 73            |
| evaluation/episode-length-avg  | 873           |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 362           |
| evaluation/episode-length-std  | 253           |
| evaluation/return-average      | 3857.3625     |
| evaluation/return-max          | 4623.078      |
| evaluation/return-min          | 1246.1995     |
| evaluation/return-std          | 1306.5643     |
| model/max_penalty              | 7.24          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 2.91          |
| model/origin_ret               | 84.8          |
| model/penalty_ret              | 80.8          |
| model/val_loss                 | 0.40512508    |
| model/valid_num                | 45687         |
| perf/AverageLength             | 873           |
| perf/AverageReturn             | 3857.3625     |
| perf/NormalizedReturn          | 0.84          |
| Q-avg                          | 185.56595     |
| Q-std                          | 86.94283      |
| Q_loss                         | 96.19049      |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 73            |
| times/epoch_after_hook         | 1.74e-06      |
| times/epoch_before_hook        | 0.000413      |
| times/epoch_rollout_model      | 480           |
| times/evaluation_metrics       | 0.000682      |
| times/evaluation_paths         | 30            |
| times/timestep_after_hook      | 0.00361       |
| times/timestep_before_hook     | 0.00817       |
| times/train                    | 59.7          |
| timestep                       | 1000          |
| timesteps_total                | 74000         |
| train-steps                    | 74000         |
| training/Q/q1_loss             | 95.80208      |
| training/sac_pi/alpha          | 0.15542406    |
| training/sac_pi/alpha_loss     | -0.0040370505 |
| training/sac_pi/logp_pi        | 4.3665376     |
| training/sac_pi/pi_entropy     | 3.621657      |
| training/sac_pi/pi_global_norm | 1.3299392     |
| training/sac_pi/policy_loss    | -191.17215    |
| training/sac_pi/std            | 0.51365656    |
| training/sac_pi/valid_num      | 4880.0        |
| training/sac_Q/q1              | 182.76059     |
| training/sac_Q/q2              | 181.70914     |
| training/sac_Q/q2_loss         | 95.64557      |
| training/sac_Q/q_global_norm   | 320.79852     |
-----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15355259 |
| epoch                          | 74         |
| evaluation/episode-length-avg  | 180        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 88         |
| evaluation/episode-length-std  | 273        |
| evaluation/return-average      | 684.6965   |
| evaluation/return-max          | 5300.0312  |
| evaluation/return-min          | 165.96503  |
| evaluation/return-std          | 1538.453   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45776      |
| perf/AverageLength             | 180        |
| perf/AverageReturn             | 684.6965   |
| perf/NormalizedReturn          | 0.149      |
| Q-avg                          | 183.90678  |
| Q-std                          | 76.289024  |
| Q_loss                         | 97.14319   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 74         |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000524   |
| times/evaluation_paths         | 5.68       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 59.9       |
| timestep                       | 1000       |
| timesteps_total                | 75000      |
| train-steps                    | 75000      |
| training/Q/q1_loss             | 120.06524  |
| training/sac_pi/alpha          | 0.15353507 |
| training/sac_pi/alpha_loss     | 0.32537124 |
| training/sac_pi/logp_pi        | 4.4788203  |
| training/sac_pi/pi_entropy     | 3.748867   |
| training/sac_pi/pi_global_norm | 1.2808512  |
| training/sac_pi/policy_loss    | -196.5677  |
| training/sac_pi/std            | 0.5226509  |
| training/sac_pi/valid_num      | 4909.0     |
| training/sac_Q/q1              | 189.1161   |
| training/sac_Q/q2              | 188.66629  |
| training/sac_Q/q2_loss         | 119.42057  |
| training/sac_Q/q_global_norm   | 333.1193   |
--------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.15462193    |
| epoch                          | 75            |
| evaluation/episode-length-avg  | 979           |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 820           |
| evaluation/episode-length-std  | 53.7          |
| evaluation/return-average      | 4413.486      |
| evaluation/return-max          | 4642.4824     |
| evaluation/return-min          | 3537.6643     |
| evaluation/return-std          | 304.6761      |
| model/max_penalty              | 7.24          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 2.89          |
| model/origin_ret               | 83.9          |
| model/penalty_ret              | 80.2          |
| model/val_loss                 | 0.40512508    |
| model/valid_num                | 45794         |
| perf/AverageLength             | 979           |
| perf/AverageReturn             | 4413.486      |
| perf/NormalizedReturn          | 0.961         |
| Q-avg                          | 188.1772      |
| Q-std                          | 83.40027      |
| Q_loss                         | 78.645805     |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 75            |
| times/epoch_after_hook         | 1.88e-06      |
| times/epoch_before_hook        | 0.000127      |
| times/epoch_rollout_model      | 499           |
| times/evaluation_metrics       | 0.000613      |
| times/evaluation_paths         | 32.2          |
| times/timestep_after_hook      | 0.00356       |
| times/timestep_before_hook     | 0.00807       |
| times/train                    | 59.9          |
| timestep                       | 1000          |
| timesteps_total                | 76000         |
| train-steps                    | 76000         |
| training/Q/q1_loss             | 85.57022      |
| training/sac_pi/alpha          | 0.15461981    |
| training/sac_pi/alpha_loss     | -0.0027416924 |
| training/sac_pi/logp_pi        | 4.404528      |
| training/sac_pi/pi_entropy     | 3.7783866     |
| training/sac_pi/pi_global_norm | 1.4208047     |
| training/sac_pi/policy_loss    | -180.62958    |
| training/sac_pi/std            | 0.5311043     |
| training/sac_pi/valid_num      | 4968.0        |
| training/sac_Q/q1              | 173.88828     |
| training/sac_Q/q2              | 173.86081     |
| training/sac_Q/q2_loss         | 85.5668       |
| training/sac_Q/q_global_norm   | 221.80154     |
-----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15739173 |
| epoch                          | 76         |
| evaluation/episode-length-avg  | 107        |
| evaluation/episode-length-max  | 113        |
| evaluation/episode-length-min  | 104        |
| evaluation/episode-length-std  | 2.72       |
| evaluation/return-average      | 183.24017  |
| evaluation/return-max          | 197.0527   |
| evaluation/return-min          | 173.9623   |
| evaluation/return-std          | 7.5326743  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45674      |
| perf/AverageLength             | 107        |
| perf/AverageReturn             | 183.24017  |
| perf/NormalizedReturn          | 0.0396     |
| Q-avg                          | 194.66003  |
| Q-std                          | 79.91235   |
| Q_loss                         | 83.94825   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 76         |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000525   |
| times/evaluation_paths         | 3.39       |
| times/timestep_after_hook      | 0.00355    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 77000      |
| train-steps                    | 77000      |
| training/Q/q1_loss             | 95.57856   |
| training/sac_pi/alpha          | 0.15739854 |
| training/sac_pi/alpha_loss     | 0.04572894 |
| training/sac_pi/logp_pi        | 4.513867   |
| training/sac_pi/pi_entropy     | 3.6169639  |
| training/sac_pi/pi_global_norm | 1.6695136  |
| training/sac_pi/policy_loss    | -190.64217 |
| training/sac_pi/std            | 0.50799686 |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 184.5886   |
| training/sac_Q/q2              | 184.83315  |
| training/sac_Q/q2_loss         | 95.77168   |
| training/sac_Q/q_global_norm   | 259.79947  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1533568   |
| epoch                          | 77          |
| evaluation/episode-length-avg  | 142         |
| evaluation/episode-length-max  | 148         |
| evaluation/episode-length-min  | 130         |
| evaluation/episode-length-std  | 5.16        |
| evaluation/return-average      | 331.09747   |
| evaluation/return-max          | 346.92834   |
| evaluation/return-min          | 294.44836   |
| evaluation/return-std          | 15.237818   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45836       |
| perf/AverageLength             | 142         |
| perf/AverageReturn             | 331.09747   |
| perf/NormalizedReturn          | 0.0718      |
| Q-avg                          | 193.92679   |
| Q-std                          | 76.83052    |
| Q_loss                         | 101.16467   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 77          |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000327    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000565    |
| times/evaluation_paths         | 4.55        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00809     |
| times/train                    | 60.1        |
| timestep                       | 1000        |
| timesteps_total                | 78000       |
| train-steps                    | 78000       |
| training/Q/q1_loss             | 83.761116   |
| training/sac_pi/alpha          | 0.15339464  |
| training/sac_pi/alpha_loss     | -0.27612072 |
| training/sac_pi/logp_pi        | 4.3445406   |
| training/sac_pi/pi_entropy     | 3.6307423   |
| training/sac_pi/pi_global_norm | 1.4710121   |
| training/sac_pi/policy_loss    | -197.50653  |
| training/sac_pi/std            | 0.5208595   |
| training/sac_pi/valid_num      | 4959.0      |
| training/sac_Q/q1              | 190.93614   |
| training/sac_Q/q2              | 189.96039   |
| training/sac_Q/q2_loss         | 83.64446    |
| training/sac_Q/q_global_norm   | 305.49493   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15811986 |
| epoch                          | 78         |
| evaluation/episode-length-avg  | 142        |
| evaluation/episode-length-max  | 149        |
| evaluation/episode-length-min  | 138        |
| evaluation/episode-length-std  | 3.11       |
| evaluation/return-average      | 230.95093  |
| evaluation/return-max          | 255.64725  |
| evaluation/return-min          | 220.0385   |
| evaluation/return-std          | 9.7723     |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45894      |
| perf/AverageLength             | 142        |
| perf/AverageReturn             | 230.95093  |
| perf/NormalizedReturn          | 0.05       |
| Q-avg                          | 175.99374  |
| Q-std                          | 92.75309   |
| Q_loss                         | 98.65979   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 78         |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000532   |
| times/evaluation_paths         | 4.71       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 59.9       |
| timestep                       | 1000       |
| timesteps_total                | 79000      |
| train-steps                    | 79000      |
| training/Q/q1_loss             | 86.8947    |
| training/sac_pi/alpha          | 0.15810686 |
| training/sac_pi/alpha_loss     | 0.287808   |
| training/sac_pi/logp_pi        | 4.00069    |
| training/sac_pi/pi_entropy     | 3.618653   |
| training/sac_pi/pi_global_norm | 1.5536759  |
| training/sac_pi/policy_loss    | -194.2276  |
| training/sac_pi/std            | 0.49223492 |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 188.48303  |
| training/sac_Q/q2              | 187.93501  |
| training/sac_Q/q2_loss         | 87.12024   |
| training/sac_Q/q_global_norm   | 305.20242  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16133057 |
| epoch                          | 79         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5041.374   |
| evaluation/return-max          | 5098.8213  |
| evaluation/return-min          | 4959.078   |
| evaluation/return-std          | 37.799847  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.78       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 82.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45557      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5041.374   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 171.21596  |
| Q-std                          | 94.746086  |
| Q_loss                         | 101.08731  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 79         |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000526   |
| times/evaluation_paths         | 35.5       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 59.1       |
| timestep                       | 1000       |
| timesteps_total                | 80000      |
| train-steps                    | 80000      |
| training/Q/q1_loss             | 111.93035  |
| training/sac_pi/alpha          | 0.161311   |
| training/sac_pi/alpha_loss     | 0.09411568 |
| training/sac_pi/logp_pi        | 5.641636   |
| training/sac_pi/pi_entropy     | 3.725348   |
| training/sac_pi/pi_global_norm | 1.3764749  |
| training/sac_pi/policy_loss    | -192.84814 |
| training/sac_pi/std            | 0.548897   |
| training/sac_pi/valid_num      | 4819.0     |
| training/sac_Q/q1              | 179.80733  |
| training/sac_Q/q2              | 178.54097  |
| training/sac_Q/q2_loss         | 112.26023  |
| training/sac_Q/q_global_norm   | 287.3498   |
--------------------------------------------------------------------------------
[WARN] 80 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.15622823 |
| epoch                          | 80         |
| evaluation/episode-length-avg  | 411        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 147        |
| evaluation/episode-length-std  | 386        |
| evaluation/return-average      | 1765.2317  |
| evaluation/return-max          | 4977.1562  |
| evaluation/return-min          | 360.34583  |
| evaluation/return-std          | 2054.2366  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45891      |
| perf/AverageLength             | 411        |
| perf/AverageReturn             | 1765.2317  |
| perf/NormalizedReturn          | 0.384      |
| Q-avg                          | 186.57794  |
| Q-std                          | 88.25153   |
| Q_loss                         | 91.44579   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 80         |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.000115   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000552   |
| times/evaluation_paths         | 14.9       |
| times/timestep_after_hook      | 0.00355    |
| times/timestep_before_hook     | 0.00809    |
| times/train                    | 59.3       |
| timestep                       | 1000       |
| timesteps_total                | 81000      |
| train-steps                    | 81000      |
| training/Q/q1_loss             | 81.804695  |
| training/sac_pi/alpha          | 0.15617289 |
| training/sac_pi/alpha_loss     | 0.2015724  |
| training/sac_pi/logp_pi        | 3.7382426  |
| training/sac_pi/pi_entropy     | 3.7187736  |
| training/sac_pi/pi_global_norm | 1.3995843  |
| training/sac_pi/policy_loss    | -192.50578 |
| training/sac_pi/std            | 0.4881029  |
| training/sac_pi/valid_num      | 5010.0     |
| training/sac_Q/q1              | 188.79625  |
| training/sac_Q/q2              | 188.60722  |
| training/sac_Q/q2_loss         | 81.599434  |
| training/sac_Q/q_global_norm   | 225.31984  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16067477 |
| epoch                          | 81         |
| evaluation/episode-length-avg  | 657        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 136        |
| evaluation/episode-length-std  | 420        |
| evaluation/return-average      | 3024.2812  |
| evaluation/return-max          | 4846.318   |
| evaluation/return-min          | 294.34155  |
| evaluation/return-std          | 2207.795   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45804      |
| perf/AverageLength             | 657        |
| perf/AverageReturn             | 3024.2812  |
| perf/NormalizedReturn          | 0.658      |
| Q-avg                          | 183.92981  |
| Q-std                          | 79.48659   |
| Q_loss                         | 95.47466   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 81         |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000279   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000614   |
| times/evaluation_paths         | 22.3       |
| times/timestep_after_hook      | 0.00356    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 82000      |
| train-steps                    | 82000      |
| training/Q/q1_loss             | 101.226906 |
| training/sac_pi/alpha          | 0.16066365 |
| training/sac_pi/alpha_loss     | 0.04989752 |
| training/sac_pi/logp_pi        | 4.2231507  |
| training/sac_pi/pi_entropy     | 3.7827122  |
| training/sac_pi/pi_global_norm | 1.3570702  |
| training/sac_pi/policy_loss    | -190.50114 |
| training/sac_pi/std            | 0.5248312  |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 185.74992  |
| training/sac_Q/q2              | 185.40634  |
| training/sac_Q/q2_loss         | 101.57559  |
| training/sac_Q/q_global_norm   | 240.44626  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15614323 |
| epoch                          | 82         |
| evaluation/episode-length-avg  | 176        |
| evaluation/episode-length-max  | 180        |
| evaluation/episode-length-min  | 166        |
| evaluation/episode-length-std  | 3.53       |
| evaluation/return-average      | 386.88776  |
| evaluation/return-max          | 394.09454  |
| evaluation/return-min          | 367.76428  |
| evaluation/return-std          | 7.5556903  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 81.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45961      |
| perf/AverageLength             | 176        |
| perf/AverageReturn             | 386.88776  |
| perf/NormalizedReturn          | 0.0839     |
| Q-avg                          | 190.12724  |
| Q-std                          | 82.45728   |
| Q_loss                         | 97.21669   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 82         |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000119   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.00058    |
| times/evaluation_paths         | 5.88       |
| times/timestep_after_hook      | 0.00355    |
| times/timestep_before_hook     | 0.00815    |
| times/train                    | 59.7       |
| timestep                       | 1000       |
| timesteps_total                | 83000      |
| train-steps                    | 83000      |
| training/Q/q1_loss             | 106.140305 |
| training/sac_pi/alpha          | 0.15611525 |
| training/sac_pi/alpha_loss     | 0.20458038 |
| training/sac_pi/logp_pi        | 4.5837593  |
| training/sac_pi/pi_entropy     | 3.6856697  |
| training/sac_pi/pi_global_norm | 1.9337072  |
| training/sac_pi/policy_loss    | -185.48575 |
| training/sac_pi/std            | 0.53786725 |
| training/sac_pi/valid_num      | 4991.0     |
| training/sac_Q/q1              | 180.7789   |
| training/sac_Q/q2              | 180.30945  |
| training/sac_Q/q2_loss         | 106.14515  |
| training/sac_Q/q_global_norm   | 312.65228  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16105479  |
| epoch                          | 83          |
| evaluation/episode-length-avg  | 125         |
| evaluation/episode-length-max  | 129         |
| evaluation/episode-length-min  | 119         |
| evaluation/episode-length-std  | 3.83        |
| evaluation/return-average      | 263.44037   |
| evaluation/return-max          | 283.52112   |
| evaluation/return-min          | 244.01414   |
| evaluation/return-std          | 14.274502   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45813       |
| perf/AverageLength             | 125         |
| perf/AverageReturn             | 263.44037   |
| perf/NormalizedReturn          | 0.057       |
| Q-avg                          | 188.84186   |
| Q-std                          | 80.317184   |
| Q_loss                         | 101.20854   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 83          |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000489    |
| times/evaluation_paths         | 3.98        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 84000       |
| train-steps                    | 84000       |
| training/Q/q1_loss             | 85.460945   |
| training/sac_pi/alpha          | 0.16108394  |
| training/sac_pi/alpha_loss     | 0.054611333 |
| training/sac_pi/logp_pi        | 4.286734    |
| training/sac_pi/pi_entropy     | 3.8060105   |
| training/sac_pi/pi_global_norm | 1.4978625   |
| training/sac_pi/policy_loss    | -192.46649  |
| training/sac_pi/std            | 0.5346863   |
| training/sac_pi/valid_num      | 4965.0      |
| training/sac_Q/q1              | 186.23956   |
| training/sac_Q/q2              | 185.39043   |
| training/sac_Q/q2_loss         | 85.67331    |
| training/sac_Q/q_global_norm   | 241.64542   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15760513 |
| epoch                          | 84         |
| evaluation/episode-length-avg  | 578        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 133        |
| evaluation/episode-length-std  | 423        |
| evaluation/return-average      | 2427.9038  |
| evaluation/return-max          | 4592.962   |
| evaluation/return-min          | 300.53638  |
| evaluation/return-std          | 2041.4315  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45975      |
| perf/AverageLength             | 578        |
| perf/AverageReturn             | 2427.9038  |
| perf/NormalizedReturn          | 0.529      |
| Q-avg                          | 178.4769   |
| Q-std                          | 98.6752    |
| Q_loss                         | 101.43998  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 84         |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000588   |
| times/evaluation_paths         | 20.6       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 62.5       |
| timestep                       | 1000       |
| timesteps_total                | 85000      |
| train-steps                    | 85000      |
| training/Q/q1_loss             | 107.58807  |
| training/sac_pi/alpha          | 0.1576315  |
| training/sac_pi/alpha_loss     | -0.1684938 |
| training/sac_pi/logp_pi        | 4.305002   |
| training/sac_pi/pi_entropy     | 3.7662778  |
| training/sac_pi/pi_global_norm | 1.2232484  |
| training/sac_pi/policy_loss    | -189.3306  |
| training/sac_pi/std            | 0.53077227 |
| training/sac_pi/valid_num      | 4912.0     |
| training/sac_Q/q1              | 180.96574  |
| training/sac_Q/q2              | 180.26909  |
| training/sac_Q/q2_loss         | 107.71069  |
| training/sac_Q/q_global_norm   | 269.97937  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16215834  |
| epoch                          | 85          |
| evaluation/episode-length-avg  | 660         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 150         |
| evaluation/episode-length-std  | 416         |
| evaluation/return-average      | 2921.7427   |
| evaluation/return-max          | 4681.1914   |
| evaluation/return-min          | 392.69864   |
| evaluation/return-std          | 2063.4675   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46016       |
| perf/AverageLength             | 660         |
| perf/AverageReturn             | 2921.7427   |
| perf/NormalizedReturn          | 0.636       |
| Q-avg                          | 187.40007   |
| Q-std                          | 90.919136   |
| Q_loss                         | 104.00822   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 85          |
| times/epoch_after_hook         | 2.01e-06    |
| times/epoch_before_hook        | 0.000283    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000532    |
| times/evaluation_paths         | 22.4        |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00834     |
| times/train                    | 58.7        |
| timestep                       | 1000        |
| timesteps_total                | 86000       |
| train-steps                    | 86000       |
| training/Q/q1_loss             | 95.911194   |
| training/sac_pi/alpha          | 0.16211328  |
| training/sac_pi/alpha_loss     | 0.118561625 |
| training/sac_pi/logp_pi        | 4.608512    |
| training/sac_pi/pi_entropy     | 3.884951    |
| training/sac_pi/pi_global_norm | 1.1527157   |
| training/sac_pi/policy_loss    | -191.16478  |
| training/sac_pi/std            | 0.54253477  |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 184.22586   |
| training/sac_Q/q2              | 183.4617    |
| training/sac_Q/q2_loss         | 97.27369    |
| training/sac_Q/q_global_norm   | 311.6926    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15690869 |
| epoch                          | 86         |
| evaluation/episode-length-avg  | 134        |
| evaluation/episode-length-max  | 141        |
| evaluation/episode-length-min  | 112        |
| evaluation/episode-length-std  | 7.76       |
| evaluation/return-average      | 304.91986  |
| evaluation/return-max          | 327.84183  |
| evaluation/return-min          | 225.87775  |
| evaluation/return-std          | 27.764267  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 81.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45809      |
| perf/AverageLength             | 134        |
| perf/AverageReturn             | 304.91986  |
| perf/NormalizedReturn          | 0.0661     |
| Q-avg                          | 187.663    |
| Q-std                          | 81.463585  |
| Q_loss                         | 76.13109   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 86         |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 5.82       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 59.9       |
| timestep                       | 1000       |
| timesteps_total                | 87000      |
| train-steps                    | 87000      |
| training/Q/q1_loss             | 87.306816  |
| training/sac_pi/alpha          | 0.15685076 |
| training/sac_pi/alpha_loss     | 0.5463152  |
| training/sac_pi/logp_pi        | 4.1937046  |
| training/sac_pi/pi_entropy     | 3.5948296  |
| training/sac_pi/pi_global_norm | 1.3131262  |
| training/sac_pi/policy_loss    | -196.74567 |
| training/sac_pi/std            | 0.4981118  |
| training/sac_pi/valid_num      | 4984.0     |
| training/sac_Q/q1              | 191.68709  |
| training/sac_Q/q2              | 190.78793  |
| training/sac_Q/q2_loss         | 87.47011   |
| training/sac_Q/q_global_norm   | 260.15543  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15918162 |
| epoch                          | 87         |
| evaluation/episode-length-avg  | 143        |
| evaluation/episode-length-max  | 145        |
| evaluation/episode-length-min  | 140        |
| evaluation/episode-length-std  | 1.79       |
| evaluation/return-average      | 295.71698  |
| evaluation/return-max          | 317.52255  |
| evaluation/return-min          | 285.42517  |
| evaluation/return-std          | 9.076219   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45999      |
| perf/AverageLength             | 143        |
| perf/AverageReturn             | 295.71698  |
| perf/NormalizedReturn          | 0.0641     |
| Q-avg                          | 183.63083  |
| Q-std                          | 89.469536  |
| Q_loss                         | 96.27329   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 87         |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000114   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000607   |
| times/evaluation_paths         | 4.63       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00842    |
| times/train                    | 61.5       |
| timestep                       | 1000       |
| timesteps_total                | 88000      |
| train-steps                    | 88000      |
| training/Q/q1_loss             | 95.88275   |
| training/sac_pi/alpha          | 0.15919699 |
| training/sac_pi/alpha_loss     | -0.1351681 |
| training/sac_pi/logp_pi        | 4.077117   |
| training/sac_pi/pi_entropy     | 3.6313775  |
| training/sac_pi/pi_global_norm | 1.4141626  |
| training/sac_pi/policy_loss    | -195.28609 |
| training/sac_pi/std            | 0.5142554  |
| training/sac_pi/valid_num      | 4997.0     |
| training/sac_Q/q1              | 190.34827  |
| training/sac_Q/q2              | 189.83737  |
| training/sac_Q/q2_loss         | 96.81099   |
| training/sac_Q/q_global_norm   | 193.0766   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15851179 |
| epoch                          | 88         |
| evaluation/episode-length-avg  | 916        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 157        |
| evaluation/episode-length-std  | 253        |
| evaluation/return-average      | 4456.9375  |
| evaluation/return-max          | 5041.6924  |
| evaluation/return-min          | 343.8734   |
| evaluation/return-std          | 1372.8203  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.94       |
| model/origin_ret               | 83.8       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46083      |
| perf/AverageLength             | 916        |
| perf/AverageReturn             | 4456.9375  |
| perf/NormalizedReturn          | 0.971      |
| Q-avg                          | 189.84225  |
| Q-std                          | 80.0932    |
| Q_loss                         | 92.00718   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 88         |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000511   |
| times/evaluation_paths         | 34.2       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 68.1       |
| timestep                       | 1000       |
| timesteps_total                | 89000      |
| train-steps                    | 89000      |
| training/Q/q1_loss             | 91.904076  |
| training/sac_pi/alpha          | 0.15845674 |
| training/sac_pi/alpha_loss     | 0.14620899 |
| training/sac_pi/logp_pi        | 4.406456   |
| training/sac_pi/pi_entropy     | 3.734649   |
| training/sac_pi/pi_global_norm | 1.8590102  |
| training/sac_pi/policy_loss    | -192.692   |
| training/sac_pi/std            | 0.5251929  |
| training/sac_pi/valid_num      | 4937.0     |
| training/sac_Q/q1              | 186.43723  |
| training/sac_Q/q2              | 185.7091   |
| training/sac_Q/q2_loss         | 92.10748   |
| training/sac_Q/q_global_norm   | 267.3876   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15596776  |
| epoch                          | 89          |
| evaluation/episode-length-avg  | 137         |
| evaluation/episode-length-max  | 140         |
| evaluation/episode-length-min  | 135         |
| evaluation/episode-length-std  | 1.58        |
| evaluation/return-average      | 405.10587   |
| evaluation/return-max          | 411.64682   |
| evaluation/return-min          | 400.64908   |
| evaluation/return-std          | 2.9580057   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45889       |
| perf/AverageLength             | 137         |
| perf/AverageReturn             | 405.10587   |
| perf/NormalizedReturn          | 0.0879      |
| Q-avg                          | 198.36923   |
| Q-std                          | 81.271      |
| Q_loss                         | 86.95147    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 89          |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000382    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000628    |
| times/evaluation_paths         | 4.44        |
| times/timestep_after_hook      | 0.00357     |
| times/timestep_before_hook     | 0.00829     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 90000       |
| train-steps                    | 90000       |
| training/Q/q1_loss             | 95.762794   |
| training/sac_pi/alpha          | 0.15594654  |
| training/sac_pi/alpha_loss     | -0.22180656 |
| training/sac_pi/logp_pi        | 3.5232544   |
| training/sac_pi/pi_entropy     | 3.642976    |
| training/sac_pi/pi_global_norm | 1.1837372   |
| training/sac_pi/policy_loss    | -200.08206  |
| training/sac_pi/std            | 0.48319903  |
| training/sac_pi/valid_num      | 5033.0      |
| training/sac_Q/q1              | 197.21463   |
| training/sac_Q/q2              | 196.93103   |
| training/sac_Q/q2_loss         | 95.54564    |
| training/sac_Q/q_global_norm   | 209.94316   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15739529  |
| epoch                          | 90          |
| evaluation/episode-length-avg  | 914         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 143         |
| evaluation/episode-length-std  | 257         |
| evaluation/return-average      | 4208.0767   |
| evaluation/return-max          | 4757.173    |
| evaluation/return-min          | 344.58508   |
| evaluation/return-std          | 1289.8917   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46092       |
| perf/AverageLength             | 914         |
| perf/AverageReturn             | 4208.0767   |
| perf/NormalizedReturn          | 0.916       |
| Q-avg                          | 193.05746   |
| Q-std                          | 82.077034   |
| Q_loss                         | 104.592575  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 90          |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000137    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000583    |
| times/evaluation_paths         | 34          |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 68.9        |
| timestep                       | 1000        |
| timesteps_total                | 91000       |
| train-steps                    | 91000       |
| training/Q/q1_loss             | 75.54618    |
| training/sac_pi/alpha          | 0.1573796   |
| training/sac_pi/alpha_loss     | -0.19659057 |
| training/sac_pi/logp_pi        | 4.3642063   |
| training/sac_pi/pi_entropy     | 3.8101966   |
| training/sac_pi/pi_global_norm | 1.3766618   |
| training/sac_pi/policy_loss    | -197.29616  |
| training/sac_pi/std            | 0.5455246   |
| training/sac_pi/valid_num      | 4924.0      |
| training/sac_Q/q1              | 190.1486    |
| training/sac_Q/q2              | 189.96951   |
| training/sac_Q/q2_loss         | 75.96341    |
| training/sac_Q/q_global_norm   | 256.27567   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15214147  |
| epoch                          | 91          |
| evaluation/episode-length-avg  | 491         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 140         |
| evaluation/episode-length-std  | 416         |
| evaluation/return-average      | 2067.8892   |
| evaluation/return-max          | 4677.1826   |
| evaluation/return-min          | 326.08014   |
| evaluation/return-std          | 2076.265    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45915       |
| perf/AverageLength             | 491         |
| perf/AverageReturn             | 2067.8892   |
| perf/NormalizedReturn          | 0.45        |
| Q-avg                          | 199.23521   |
| Q-std                          | 81.52179    |
| Q_loss                         | 72.08102    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 91          |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.00014     |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000535    |
| times/evaluation_paths         | 18.1        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 65.9        |
| timestep                       | 1000        |
| timesteps_total                | 92000       |
| train-steps                    | 92000       |
| training/Q/q1_loss             | 92.86563    |
| training/sac_pi/alpha          | 0.15213645  |
| training/sac_pi/alpha_loss     | 0.005584462 |
| training/sac_pi/logp_pi        | 4.4511766   |
| training/sac_pi/pi_entropy     | 3.605629    |
| training/sac_pi/pi_global_norm | 1.2132982   |
| training/sac_pi/policy_loss    | -192.59573  |
| training/sac_pi/std            | 0.5073839   |
| training/sac_pi/valid_num      | 4911.0      |
| training/sac_Q/q1              | 184.76595   |
| training/sac_Q/q2              | 185.01396   |
| training/sac_Q/q2_loss         | 93.20801    |
| training/sac_Q/q_global_norm   | 187.9266    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15690665  |
| epoch                          | 92          |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4951.535    |
| evaluation/return-max          | 5043.6465   |
| evaluation/return-min          | 4915.253    |
| evaluation/return-std          | 35.810146   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 81.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46061       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4951.535    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 188.4765    |
| Q-std                          | 92.37067    |
| Q_loss                         | 103.39449   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 92          |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000599    |
| times/evaluation_paths         | 36.1        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 70.4        |
| timestep                       | 1000        |
| timesteps_total                | 93000       |
| train-steps                    | 93000       |
| training/Q/q1_loss             | 100.72761   |
| training/sac_pi/alpha          | 0.15692472  |
| training/sac_pi/alpha_loss     | -0.22970083 |
| training/sac_pi/logp_pi        | 3.566835    |
| training/sac_pi/pi_entropy     | 3.6585495   |
| training/sac_pi/pi_global_norm | 1.5331218   |
| training/sac_pi/policy_loss    | -198.73833  |
| training/sac_pi/std            | 0.49202916  |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 193.6038    |
| training/sac_Q/q2              | 193.59596   |
| training/sac_Q/q2_loss         | 100.559006  |
| training/sac_Q/q_global_norm   | 223.27493   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16141959 |
| epoch                          | 93         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4816.632   |
| evaluation/return-max          | 4877.2676  |
| evaluation/return-min          | 4730.9395  |
| evaluation/return-std          | 43.8892    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.87       |
| model/origin_ret               | 83.2       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45864      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4816.632   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 189.10323  |
| Q-std                          | 85.627266  |
| Q_loss                         | 96.01889   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 93         |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000279   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000675   |
| times/evaluation_paths         | 33.7       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 64.8       |
| timestep                       | 1000       |
| timesteps_total                | 94000      |
| train-steps                    | 94000      |
| training/Q/q1_loss             | 97.10397   |
| training/sac_pi/alpha          | 0.16143686 |
| training/sac_pi/alpha_loss     | -0.2679753 |
| training/sac_pi/logp_pi        | 3.8334785  |
| training/sac_pi/pi_entropy     | 3.5938897  |
| training/sac_pi/pi_global_norm | 1.8736277  |
| training/sac_pi/policy_loss    | -201.56343 |
| training/sac_pi/std            | 0.49662432 |
| training/sac_pi/valid_num      | 5017.0     |
| training/sac_Q/q1              | 197.74863  |
| training/sac_Q/q2              | 197.37938  |
| training/sac_Q/q2_loss         | 96.64504   |
| training/sac_Q/q_global_norm   | 282.31165  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16368128   |
| epoch                          | 94           |
| evaluation/episode-length-avg  | 416          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 162          |
| evaluation/episode-length-std  | 382          |
| evaluation/return-average      | 1591.9799    |
| evaluation/return-max          | 4304.285     |
| evaluation/return-min          | 432.30597    |
| evaluation/return-std          | 1751.5791    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.99         |
| model/origin_ret               | 85.3         |
| model/penalty_ret              | 80.9         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 45718        |
| perf/AverageLength             | 416          |
| perf/AverageReturn             | 1591.9799    |
| perf/NormalizedReturn          | 0.346        |
| Q-avg                          | 189.28246    |
| Q-std                          | 90.15518     |
| Q_loss                         | 92.96191     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 94           |
| times/epoch_after_hook         | 1.91e-06     |
| times/epoch_before_hook        | 0.000127     |
| times/epoch_rollout_model      | 506          |
| times/evaluation_metrics       | 0.000609     |
| times/evaluation_paths         | 14.7         |
| times/timestep_after_hook      | 0.00355      |
| times/timestep_before_hook     | 0.00821      |
| times/train                    | 60.2         |
| timestep                       | 1000         |
| timesteps_total                | 95000        |
| train-steps                    | 95000        |
| training/Q/q1_loss             | 83.09488     |
| training/sac_pi/alpha          | 0.16363488   |
| training/sac_pi/alpha_loss     | -0.023266401 |
| training/sac_pi/logp_pi        | 3.4451752    |
| training/sac_pi/pi_entropy     | 3.9131958    |
| training/sac_pi/pi_global_norm | 1.340156     |
| training/sac_pi/policy_loss    | -185.96808   |
| training/sac_pi/std            | 0.50763893   |
| training/sac_pi/valid_num      | 5025.0       |
| training/sac_Q/q1              | 182.23605    |
| training/sac_Q/q2              | 182.45955    |
| training/sac_Q/q2_loss         | 81.80587     |
| training/sac_Q/q_global_norm   | 224.65791    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16706756  |
| epoch                          | 95          |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4365.581    |
| evaluation/return-max          | 4555.178    |
| evaluation/return-min          | 4215.9014   |
| evaluation/return-std          | 117.897156  |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 87.8        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45850       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4365.581    |
| perf/NormalizedReturn          | 0.951       |
| Q-avg                          | 193.38329   |
| Q-std                          | 84.82083    |
| Q_loss                         | 82.68939    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 95          |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000149    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000629    |
| times/evaluation_paths         | 33.9        |
| times/timestep_after_hook      | 0.00352     |
| times/timestep_before_hook     | 0.00827     |
| times/train                    | 59.7        |
| timestep                       | 1000        |
| timesteps_total                | 96000       |
| train-steps                    | 96000       |
| training/Q/q1_loss             | 79.65677    |
| training/sac_pi/alpha          | 0.16705965  |
| training/sac_pi/alpha_loss     | -0.03962955 |
| training/sac_pi/logp_pi        | 4.10908     |
| training/sac_pi/pi_entropy     | 3.7347474   |
| training/sac_pi/pi_global_norm | 1.3328549   |
| training/sac_pi/policy_loss    | -199.16924  |
| training/sac_pi/std            | 0.5131889   |
| training/sac_pi/valid_num      | 4950.0      |
| training/sac_Q/q1              | 192.42392   |
| training/sac_Q/q2              | 192.54495   |
| training/sac_Q/q2_loss         | 80.12755    |
| training/sac_Q/q_global_norm   | 275.88785   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16572489 |
| epoch                          | 96         |
| evaluation/episode-length-avg  | 941        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 624        |
| evaluation/episode-length-std  | 123        |
| evaluation/return-average      | 4502.6133  |
| evaluation/return-max          | 4978.1323  |
| evaluation/return-min          | 2865.233   |
| evaluation/return-std          | 644.5249   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.93       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45714      |
| perf/AverageLength             | 941        |
| perf/AverageReturn             | 4502.6133  |
| perf/NormalizedReturn          | 0.98       |
| Q-avg                          | 181.57535  |
| Q-std                          | 102.47232  |
| Q_loss                         | 101.81099  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 96         |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.00017    |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000546   |
| times/evaluation_paths         | 35.5       |
| times/timestep_after_hook      | 0.00351    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 59         |
| timestep                       | 1000       |
| timesteps_total                | 97000      |
| train-steps                    | 97000      |
| training/Q/q1_loss             | 86.03076   |
| training/sac_pi/alpha          | 0.16573325 |
| training/sac_pi/alpha_loss     | 0.14444788 |
| training/sac_pi/logp_pi        | 4.325694   |
| training/sac_pi/pi_entropy     | 3.6251788  |
| training/sac_pi/pi_global_norm | 1.4899902  |
| training/sac_pi/policy_loss    | -193.7375  |
| training/sac_pi/std            | 0.506364   |
| training/sac_pi/valid_num      | 4931.0     |
| training/sac_Q/q1              | 186.47482  |
| training/sac_Q/q2              | 186.27298  |
| training/sac_Q/q2_loss         | 86.23082   |
| training/sac_Q/q_global_norm   | 242.87138  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17057572 |
| epoch                          | 97         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4370.7554  |
| evaluation/return-max          | 4505.4795  |
| evaluation/return-min          | 4292.072   |
| evaluation/return-std          | 60.74196   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45867      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4370.7554  |
| perf/NormalizedReturn          | 0.952      |
| Q-avg                          | 190.82993  |
| Q-std                          | 88.41377   |
| Q_loss                         | 88.145134  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 97         |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000518   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000673   |
| times/evaluation_paths         | 34.8       |
| times/timestep_after_hook      | 0.00352    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 98000      |
| train-steps                    | 98000      |
| training/Q/q1_loss             | 106.852684 |
| training/sac_pi/alpha          | 0.17055945 |
| training/sac_pi/alpha_loss     | 0.10362865 |
| training/sac_pi/logp_pi        | 4.2937155  |
| training/sac_pi/pi_entropy     | 3.8222473  |
| training/sac_pi/pi_global_norm | 1.4463989  |
| training/sac_pi/policy_loss    | -189.46257 |
| training/sac_pi/std            | 0.51861733 |
| training/sac_pi/valid_num      | 4979.0     |
| training/sac_Q/q1              | 184.465    |
| training/sac_Q/q2              | 183.84282  |
| training/sac_Q/q2_loss         | 106.26982  |
| training/sac_Q/q_global_norm   | 231.87968  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16071358  |
| epoch                          | 98          |
| evaluation/episode-length-avg  | 123         |
| evaluation/episode-length-max  | 132         |
| evaluation/episode-length-min  | 119         |
| evaluation/episode-length-std  | 3.74        |
| evaluation/return-average      | 240.94644   |
| evaluation/return-max          | 270.22668   |
| evaluation/return-min          | 227.15512   |
| evaluation/return-std          | 12.4671135  |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45926       |
| perf/AverageLength             | 123         |
| perf/AverageReturn             | 240.94644   |
| perf/NormalizedReturn          | 0.0521      |
| Q-avg                          | 177.33353   |
| Q-std                          | 97.090126   |
| Q_loss                         | 88.93824    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 98          |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.00015     |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000483    |
| times/evaluation_paths         | 3.97        |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 99000       |
| train-steps                    | 99000       |
| training/Q/q1_loss             | 80.337166   |
| training/sac_pi/alpha          | 0.16072349  |
| training/sac_pi/alpha_loss     | -0.11474689 |
| training/sac_pi/logp_pi        | 3.777565    |
| training/sac_pi/pi_entropy     | 3.478581    |
| training/sac_pi/pi_global_norm | 1.4099439   |
| training/sac_pi/policy_loss    | -193.45691  |
| training/sac_pi/std            | 0.4816502   |
| training/sac_pi/valid_num      | 4987.0      |
| training/sac_Q/q1              | 187.72147   |
| training/sac_Q/q2              | 187.83519   |
| training/sac_Q/q2_loss         | 81.05415    |
| training/sac_Q/q_global_norm   | 224.93158   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15982006 |
| epoch                          | 99         |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4618.674   |
| evaluation/return-max          | 4656.5137  |
| evaluation/return-min          | 4568.281   |
| evaluation/return-std          | 30.951511  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.91       |
| model/origin_ret               | 83         |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45950      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4618.674   |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 190.20337  |
| Q-std                          | 88.76691   |
| Q_loss                         | 89.2032    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 99         |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 7.03e-05   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.00058    |
| times/evaluation_paths         | 36.6       |
| times/timestep_after_hook      | 0.00353    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 65.2       |
| timestep                       | 1000       |
| timesteps_total                | 100000     |
| train-steps                    | 100000     |
| training/Q/q1_loss             | 91.39625   |
| training/sac_pi/alpha          | 0.15979064 |
| training/sac_pi/alpha_loss     | 0.29904383 |
| training/sac_pi/logp_pi        | 4.908297   |
| training/sac_pi/pi_entropy     | 3.5523338  |
| training/sac_pi/pi_global_norm | 1.1873196  |
| training/sac_pi/policy_loss    | -196.30826 |
| training/sac_pi/std            | 0.5222918  |
| training/sac_pi/valid_num      | 4931.0     |
| training/sac_Q/q1              | 189.52133  |
| training/sac_Q/q2              | 189.32043  |
| training/sac_Q/q2_loss         | 92.674995  |
| training/sac_Q/q_global_norm   | 333.83527  |
--------------------------------------------------------------------------------
[WARN] 100 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.1610006   |
| epoch                          | 100         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4854.1265   |
| evaluation/return-max          | 4899.7686   |
| evaluation/return-min          | 4796.048    |
| evaluation/return-std          | 30.790052   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45906       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4854.1265   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 187.47885   |
| Q-std                          | 84.075714   |
| Q_loss                         | 107.44719   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 100         |
| times/epoch_after_hook         | 1.66e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000531    |
| times/evaluation_paths         | 33          |
| times/timestep_after_hook      | 0.00356     |
| times/timestep_before_hook     | 0.00822     |
| times/train                    | 64.2        |
| timestep                       | 1000        |
| timesteps_total                | 101000      |
| train-steps                    | 101000      |
| training/Q/q1_loss             | 85.2842     |
| training/sac_pi/alpha          | 0.1609852   |
| training/sac_pi/alpha_loss     | -0.24277854 |
| training/sac_pi/logp_pi        | 4.2822485   |
| training/sac_pi/pi_entropy     | 3.680097    |
| training/sac_pi/pi_global_norm | 1.5091729   |
| training/sac_pi/policy_loss    | -197.71236  |
| training/sac_pi/std            | 0.52143365  |
| training/sac_pi/valid_num      | 4937.0      |
| training/sac_Q/q1              | 189.80603   |
| training/sac_Q/q2              | 190.12064   |
| training/sac_Q/q2_loss         | 84.84791    |
| training/sac_Q/q_global_norm   | 223.9972    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16636465  |
| epoch                          | 101         |
| evaluation/episode-length-avg  | 746         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 151         |
| evaluation/episode-length-std  | 389         |
| evaluation/return-average      | 3455.0632   |
| evaluation/return-max          | 4874.17     |
| evaluation/return-min          | 420.17786   |
| evaluation/return-std          | 1986.443    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46097       |
| perf/AverageLength             | 746         |
| perf/AverageReturn             | 3455.0632   |
| perf/NormalizedReturn          | 0.752       |
| Q-avg                          | 197.40874   |
| Q-std                          | 95.832344   |
| Q_loss                         | 92.982216   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 101         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000282    |
| times/epoch_rollout_model      | 523         |
| times/evaluation_metrics       | 0.00068     |
| times/evaluation_paths         | 27.3        |
| times/timestep_after_hook      | 0.0035      |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 65          |
| timestep                       | 1000        |
| timesteps_total                | 102000      |
| train-steps                    | 102000      |
| training/Q/q1_loss             | 103.6732    |
| training/sac_pi/alpha          | 0.16639073  |
| training/sac_pi/alpha_loss     | -0.12556472 |
| training/sac_pi/logp_pi        | 3.6543148   |
| training/sac_pi/pi_entropy     | 3.8273723   |
| training/sac_pi/pi_global_norm | 1.3232356   |
| training/sac_pi/policy_loss    | -201.47644  |
| training/sac_pi/std            | 0.5060357   |
| training/sac_pi/valid_num      | 5037.0      |
| training/sac_Q/q1              | 198.15158   |
| training/sac_Q/q2              | 198.03989   |
| training/sac_Q/q2_loss         | 103.94019   |
| training/sac_Q/q_global_norm   | 258.42615   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16637173  |
| epoch                          | 102         |
| evaluation/episode-length-avg  | 123         |
| evaluation/episode-length-max  | 126         |
| evaluation/episode-length-min  | 122         |
| evaluation/episode-length-std  | 1.04        |
| evaluation/return-average      | 323.77032   |
| evaluation/return-max          | 332.58395   |
| evaluation/return-min          | 318.7381    |
| evaluation/return-std          | 4.6635084   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45819       |
| perf/AverageLength             | 123         |
| perf/AverageReturn             | 323.77032   |
| perf/NormalizedReturn          | 0.0702      |
| Q-avg                          | 197.43388   |
| Q-std                          | 90.102844   |
| Q_loss                         | 86.180275   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 102         |
| times/epoch_after_hook         | 1.65e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000621    |
| times/evaluation_paths         | 4.67        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 66.7        |
| timestep                       | 1000        |
| timesteps_total                | 103000      |
| train-steps                    | 103000      |
| training/Q/q1_loss             | 95.50743    |
| training/sac_pi/alpha          | 0.16639064  |
| training/sac_pi/alpha_loss     | -0.24270174 |
| training/sac_pi/logp_pi        | 3.652825    |
| training/sac_pi/pi_entropy     | 3.9230278   |
| training/sac_pi/pi_global_norm | 1.689686    |
| training/sac_pi/policy_loss    | -200.7285   |
| training/sac_pi/std            | 0.52237755  |
| training/sac_pi/valid_num      | 4993.0      |
| training/sac_Q/q1              | 196.50955   |
| training/sac_Q/q2              | 195.6195    |
| training/sac_Q/q2_loss         | 96.56606    |
| training/sac_Q/q_global_norm   | 210.63736   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17589708 |
| epoch                          | 103        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4299.4463  |
| evaluation/return-max          | 4329.6777  |
| evaluation/return-min          | 4274.6904  |
| evaluation/return-std          | 18.047617  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45807      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4299.4463  |
| perf/NormalizedReturn          | 0.936      |
| Q-avg                          | 194.17534  |
| Q-std                          | 87.90203   |
| Q_loss                         | 95.107635  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 103        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 9.83e-05   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.00056    |
| times/evaluation_paths         | 35.6       |
| times/timestep_after_hook      | 0.00355    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 73.9       |
| timestep                       | 1000       |
| timesteps_total                | 104000     |
| train-steps                    | 104000     |
| training/Q/q1_loss             | 78.39268   |
| training/sac_pi/alpha          | 0.17590295 |
| training/sac_pi/alpha_loss     | -0.3545841 |
| training/sac_pi/logp_pi        | 4.7131844  |
| training/sac_pi/pi_entropy     | 4.018879   |
| training/sac_pi/pi_global_norm | 1.571782   |
| training/sac_pi/policy_loss    | -190.60742 |
| training/sac_pi/std            | 0.5820332  |
| training/sac_pi/valid_num      | 4862.0     |
| training/sac_Q/q1              | 179.6226   |
| training/sac_Q/q2              | 179.97246  |
| training/sac_Q/q2_loss         | 77.69935   |
| training/sac_Q/q_global_norm   | 239.65446  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16512915  |
| epoch                          | 104         |
| evaluation/episode-length-avg  | 146         |
| evaluation/episode-length-max  | 153         |
| evaluation/episode-length-min  | 142         |
| evaluation/episode-length-std  | 2.91        |
| evaluation/return-average      | 310.435     |
| evaluation/return-max          | 321.75568   |
| evaluation/return-min          | 304.0512    |
| evaluation/return-std          | 4.8907504   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 82.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45920       |
| perf/AverageLength             | 146         |
| perf/AverageReturn             | 310.435     |
| perf/NormalizedReturn          | 0.0673      |
| Q-avg                          | 201.01561   |
| Q-std                          | 82.50847    |
| Q_loss                         | 91.260826   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 104         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000484    |
| times/evaluation_paths         | 5.83        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 69.8        |
| timestep                       | 1000        |
| timesteps_total                | 105000      |
| train-steps                    | 105000      |
| training/Q/q1_loss             | 94.15226    |
| training/sac_pi/alpha          | 0.16509332  |
| training/sac_pi/alpha_loss     | -0.16870774 |
| training/sac_pi/logp_pi        | 3.8605504   |
| training/sac_pi/pi_entropy     | 3.9492898   |
| training/sac_pi/pi_global_norm | 1.0283145   |
| training/sac_pi/policy_loss    | -194.71428  |
| training/sac_pi/std            | 0.53128904  |
| training/sac_pi/valid_num      | 4952.0      |
| training/sac_Q/q1              | 188.32526   |
| training/sac_Q/q2              | 188.38019   |
| training/sac_Q/q2_loss         | 94.316414   |
| training/sac_Q/q_global_norm   | 309.4833    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16950873  |
| epoch                          | 105         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5221.157    |
| evaluation/return-max          | 5266.0127   |
| evaluation/return-min          | 5187.5806   |
| evaluation/return-std          | 20.516264   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.97        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 80.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46070       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5221.157    |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 192.72133   |
| Q-std                          | 88.4106     |
| Q_loss                         | 113.12268   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 105         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000274    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000686    |
| times/evaluation_paths         | 36.7        |
| times/timestep_after_hook      | 0.00357     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 70.8        |
| timestep                       | 1000        |
| timesteps_total                | 106000      |
| train-steps                    | 106000      |
| training/Q/q1_loss             | 98.68692    |
| training/sac_pi/alpha          | 0.1695289   |
| training/sac_pi/alpha_loss     | -0.07102701 |
| training/sac_pi/logp_pi        | 3.9452693   |
| training/sac_pi/pi_entropy     | 3.7330704   |
| training/sac_pi/pi_global_norm | 1.8894869   |
| training/sac_pi/policy_loss    | -206.38638  |
| training/sac_pi/std            | 0.5012482   |
| training/sac_pi/valid_num      | 5005.0      |
| training/sac_Q/q1              | 202.04556   |
| training/sac_Q/q2              | 201.71582   |
| training/sac_Q/q2_loss         | 99.12223    |
| training/sac_Q/q_global_norm   | 365.27954   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16439213 |
| epoch                          | 106        |
| evaluation/episode-length-avg  | 132        |
| evaluation/episode-length-max  | 135        |
| evaluation/episode-length-min  | 129        |
| evaluation/episode-length-std  | 1.79       |
| evaluation/return-average      | 273.2413   |
| evaluation/return-max          | 284.31125  |
| evaluation/return-min          | 262.19647  |
| evaluation/return-std          | 6.344914   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45934      |
| perf/AverageLength             | 132        |
| perf/AverageReturn             | 273.2413   |
| perf/NormalizedReturn          | 0.0592     |
| Q-avg                          | 200.69432  |
| Q-std                          | 77.62125   |
| Q_loss                         | 85.20044   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 106        |
| times/epoch_after_hook         | 1.61e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000508   |
| times/evaluation_paths         | 4.95       |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 67.5       |
| timestep                       | 1000       |
| timesteps_total                | 107000     |
| train-steps                    | 107000     |
| training/Q/q1_loss             | 91.91734   |
| training/sac_pi/alpha          | 0.16439576 |
| training/sac_pi/alpha_loss     | 0.33967704 |
| training/sac_pi/logp_pi        | 4.705147   |
| training/sac_pi/pi_entropy     | 3.822726   |
| training/sac_pi/pi_global_norm | 1.9762567  |
| training/sac_pi/policy_loss    | -189.49582 |
| training/sac_pi/std            | 0.5521949  |
| training/sac_pi/valid_num      | 4948.0     |
| training/sac_Q/q1              | 181.2247   |
| training/sac_Q/q2              | 180.99283  |
| training/sac_Q/q2_loss         | 92.07769   |
| training/sac_Q/q_global_norm   | 387.16132  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16675474  |
| epoch                          | 107         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4804.4746   |
| evaluation/return-max          | 4842.4893   |
| evaluation/return-min          | 4773.3896   |
| evaluation/return-std          | 21.973148   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.88        |
| model/origin_ret               | 83.3        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46151       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4804.4746   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 185.35567   |
| Q-std                          | 89.48321    |
| Q_loss                         | 107.925095  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 107         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000223    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000622    |
| times/evaluation_paths         | 40.3        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 70.1        |
| timestep                       | 1000        |
| timesteps_total                | 108000      |
| train-steps                    | 108000      |
| training/Q/q1_loss             | 86.68394    |
| training/sac_pi/alpha          | 0.16679686  |
| training/sac_pi/alpha_loss     | -0.19391489 |
| training/sac_pi/logp_pi        | 3.647348    |
| training/sac_pi/pi_entropy     | 3.5721002   |
| training/sac_pi/pi_global_norm | 1.34407     |
| training/sac_pi/policy_loss    | -202.24309  |
| training/sac_pi/std            | 0.48808652  |
| training/sac_pi/valid_num      | 5022.0      |
| training/sac_Q/q1              | 198.50609   |
| training/sac_Q/q2              | 198.82822   |
| training/sac_Q/q2_loss         | 86.00022    |
| training/sac_Q/q_global_norm   | 242.80667   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16736372  |
| epoch                          | 108         |
| evaluation/episode-length-avg  | 831         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 147         |
| evaluation/episode-length-std  | 338         |
| evaluation/return-average      | 4344.8623   |
| evaluation/return-max          | 5422.7754   |
| evaluation/return-min          | 468.11298   |
| evaluation/return-std          | 1931.459    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 81.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45999       |
| perf/AverageLength             | 831         |
| perf/AverageReturn             | 4344.8623   |
| perf/NormalizedReturn          | 0.946       |
| Q-avg                          | 190.65314   |
| Q-std                          | 90.773384   |
| Q_loss                         | 115.82547   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 108         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000142    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000581    |
| times/evaluation_paths         | 35.8        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 70.7        |
| timestep                       | 1000        |
| timesteps_total                | 109000      |
| train-steps                    | 109000      |
| training/Q/q1_loss             | 110.28956   |
| training/sac_pi/alpha          | 0.16739881  |
| training/sac_pi/alpha_loss     | 0.063008405 |
| training/sac_pi/logp_pi        | 4.0471373   |
| training/sac_pi/pi_entropy     | 3.748965    |
| training/sac_pi/pi_global_norm | 1.339352    |
| training/sac_pi/policy_loss    | -197.82576  |
| training/sac_pi/std            | 0.5156599   |
| training/sac_pi/valid_num      | 4989.0      |
| training/sac_Q/q1              | 192.57076   |
| training/sac_Q/q2              | 193.10335   |
| training/sac_Q/q2_loss         | 109.73872   |
| training/sac_Q/q_global_norm   | 191.52916   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1674817  |
| epoch                          | 109        |
| evaluation/episode-length-avg  | 706        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 538        |
| evaluation/episode-length-std  | 166        |
| evaluation/return-average      | 3140.6294  |
| evaluation/return-max          | 4738.934   |
| evaluation/return-min          | 2242.0737  |
| evaluation/return-std          | 892.2859   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46025      |
| perf/AverageLength             | 706        |
| perf/AverageReturn             | 3140.6294  |
| perf/NormalizedReturn          | 0.684      |
| Q-avg                          | 184.8166   |
| Q-std                          | 93.30924   |
| Q_loss                         | 106.5225   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 109        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000288   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000483   |
| times/evaluation_paths         | 28.1       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 72.4       |
| timestep                       | 1000       |
| timesteps_total                | 110000     |
| train-steps                    | 110000     |
| training/Q/q1_loss             | 90.79898   |
| training/sac_pi/alpha          | 0.16742577 |
| training/sac_pi/alpha_loss     | 0.2409288  |
| training/sac_pi/logp_pi        | 3.9549785  |
| training/sac_pi/pi_entropy     | 3.8240256  |
| training/sac_pi/pi_global_norm | 1.1326709  |
| training/sac_pi/policy_loss    | -193.94138 |
| training/sac_pi/std            | 0.51007664 |
| training/sac_pi/valid_num      | 5006.0     |
| training/sac_Q/q1              | 189.2117   |
| training/sac_Q/q2              | 188.79424  |
| training/sac_Q/q2_loss         | 90.248276  |
| training/sac_Q/q_global_norm   | 210.74825  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16007388 |
| epoch                          | 110        |
| evaluation/episode-length-avg  | 134        |
| evaluation/episode-length-max  | 142        |
| evaluation/episode-length-min  | 126        |
| evaluation/episode-length-std  | 4.71       |
| evaluation/return-average      | 289.01883  |
| evaluation/return-max          | 319.89294  |
| evaluation/return-min          | 251.50208  |
| evaluation/return-std          | 18.952105  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 88.7       |
| model/penalty_ret              | 82.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45789      |
| perf/AverageLength             | 134        |
| perf/AverageReturn             | 289.01883  |
| perf/NormalizedReturn          | 0.0626     |
| Q-avg                          | 189.80989  |
| Q-std                          | 93.00148   |
| Q_loss                         | 88.20787   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 110        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.0004     |
| times/evaluation_paths         | 6.12       |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 72.1       |
| timestep                       | 1000       |
| timesteps_total                | 111000     |
| train-steps                    | 111000     |
| training/Q/q1_loss             | 99.15685   |
| training/sac_pi/alpha          | 0.16005708 |
| training/sac_pi/alpha_loss     | 0.30261165 |
| training/sac_pi/logp_pi        | 4.294947   |
| training/sac_pi/pi_entropy     | 3.6684036  |
| training/sac_pi/pi_global_norm | 1.3392261  |
| training/sac_pi/policy_loss    | -197.94194 |
| training/sac_pi/std            | 0.5063591  |
| training/sac_pi/valid_num      | 4887.0     |
| training/sac_Q/q1              | 189.21724  |
| training/sac_Q/q2              | 189.15376  |
| training/sac_Q/q2_loss         | 98.87249   |
| training/sac_Q/q_global_norm   | 369.44165  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1596683   |
| epoch                          | 111         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4595.928    |
| evaluation/return-max          | 4634.4795   |
| evaluation/return-min          | 4553.118    |
| evaluation/return-std          | 22.15453    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 82.8        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46168       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4595.928    |
| perf/NormalizedReturn          | 1           |
| Q-avg                          | 191.4236    |
| Q-std                          | 92.73685    |
| Q_loss                         | 98.108505   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 111         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 8.1e-05     |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000549    |
| times/evaluation_paths         | 46.6        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00855     |
| times/train                    | 67.2        |
| timestep                       | 1000        |
| timesteps_total                | 112000      |
| train-steps                    | 112000      |
| training/Q/q1_loss             | 99.99809    |
| training/sac_pi/alpha          | 0.15968879  |
| training/sac_pi/alpha_loss     | 0.038488492 |
| training/sac_pi/logp_pi        | 4.417736    |
| training/sac_pi/pi_entropy     | 3.8219833   |
| training/sac_pi/pi_global_norm | 1.67467     |
| training/sac_pi/policy_loss    | -200.62068  |
| training/sac_pi/std            | 0.5264857   |
| training/sac_pi/valid_num      | 4914.0      |
| training/sac_Q/q1              | 191.86877   |
| training/sac_Q/q2              | 191.46712   |
| training/sac_Q/q2_loss         | 100.22687   |
| training/sac_Q/q_global_norm   | 382.1524    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16118947  |
| epoch                          | 112         |
| evaluation/episode-length-avg  | 748         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 426         |
| evaluation/episode-length-std  | 258         |
| evaluation/return-average      | 3220.0413   |
| evaluation/return-max          | 4630.1797   |
| evaluation/return-min          | 1556.7981   |
| evaluation/return-std          | 1342.7379   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46066       |
| perf/AverageLength             | 748         |
| perf/AverageReturn             | 3220.0413   |
| perf/NormalizedReturn          | 0.701       |
| Q-avg                          | 202.54225   |
| Q-std                          | 83.98191    |
| Q_loss                         | 89.089066   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 112         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000458    |
| times/evaluation_paths         | 31.9        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00839     |
| times/train                    | 68.7        |
| timestep                       | 1000        |
| timesteps_total                | 113000      |
| train-steps                    | 113000      |
| training/Q/q1_loss             | 94.58608    |
| training/sac_pi/alpha          | 0.16120282  |
| training/sac_pi/alpha_loss     | -0.40049714 |
| training/sac_pi/logp_pi        | 3.8375237   |
| training/sac_pi/pi_entropy     | 3.7431521   |
| training/sac_pi/pi_global_norm | 1.2759234   |
| training/sac_pi/policy_loss    | -205.60355  |
| training/sac_pi/std            | 0.5157995   |
| training/sac_pi/valid_num      | 4977.0      |
| training/sac_Q/q1              | 199.88892   |
| training/sac_Q/q2              | 200.1303    |
| training/sac_Q/q2_loss         | 94.85845    |
| training/sac_Q/q_global_norm   | 226.3058    |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16319673   |
| epoch                          | 113          |
| evaluation/episode-length-avg  | 328          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 156          |
| evaluation/episode-length-std  | 336          |
| evaluation/return-average      | 1255.2415    |
| evaluation/return-max          | 4531.948     |
| evaluation/return-min          | 427.70117    |
| evaluation/return-std          | 1629.651     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.98         |
| model/origin_ret               | 84.5         |
| model/penalty_ret              | 80.7         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46112        |
| perf/AverageLength             | 328          |
| perf/AverageReturn             | 1255.2415    |
| perf/NormalizedReturn          | 0.273        |
| Q-avg                          | 198.50166    |
| Q-std                          | 85.63616     |
| Q_loss                         | 85.811646    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 113          |
| times/epoch_after_hook         | 1.89e-06     |
| times/epoch_before_hook        | 0.00033      |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.000685     |
| times/evaluation_paths         | 15.5         |
| times/timestep_after_hook      | 0.00364      |
| times/timestep_before_hook     | 0.00831      |
| times/train                    | 70.8         |
| timestep                       | 1000         |
| timesteps_total                | 114000       |
| train-steps                    | 114000       |
| training/Q/q1_loss             | 97.81895     |
| training/sac_pi/alpha          | 0.16318907   |
| training/sac_pi/alpha_loss     | -0.044897422 |
| training/sac_pi/logp_pi        | 4.433694     |
| training/sac_pi/pi_entropy     | 3.6304383    |
| training/sac_pi/pi_global_norm | 1.6172714    |
| training/sac_pi/policy_loss    | -197.67026   |
| training/sac_pi/std            | 0.5091132    |
| training/sac_pi/valid_num      | 4957.0       |
| training/sac_Q/q1              | 192.42374    |
| training/sac_Q/q2              | 191.40222    |
| training/sac_Q/q2_loss         | 96.96128     |
| training/sac_Q/q_global_norm   | 220.68143    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16395487 |
| epoch                          | 114        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4799.882   |
| evaluation/return-max          | 4847.452   |
| evaluation/return-min          | 4762.2476  |
| evaluation/return-std          | 26.261158  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46054      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4799.882   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 196.62833  |
| Q-std                          | 89.76197   |
| Q_loss                         | 110.6068   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 114        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000684   |
| times/evaluation_paths         | 43.9       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 67.9       |
| timestep                       | 1000       |
| timesteps_total                | 115000     |
| train-steps                    | 115000     |
| training/Q/q1_loss             | 109.3765   |
| training/sac_pi/alpha          | 0.16397682 |
| training/sac_pi/alpha_loss     | 0.09256915 |
| training/sac_pi/logp_pi        | 4.4803667  |
| training/sac_pi/pi_entropy     | 3.7859035  |
| training/sac_pi/pi_global_norm | 1.3480213  |
| training/sac_pi/policy_loss    | -203.19754 |
| training/sac_pi/std            | 0.5265435  |
| training/sac_pi/valid_num      | 4908.0     |
| training/sac_Q/q1              | 194.21022  |
| training/sac_Q/q2              | 193.63632  |
| training/sac_Q/q2_loss         | 109.25139  |
| training/sac_Q/q_global_norm   | 397.93933  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16972284 |
| epoch                          | 115        |
| evaluation/episode-length-avg  | 159        |
| evaluation/episode-length-max  | 164        |
| evaluation/episode-length-min  | 153        |
| evaluation/episode-length-std  | 4.31       |
| evaluation/return-average      | 438.72104  |
| evaluation/return-max          | 450.4851   |
| evaluation/return-min          | 426.62366  |
| evaluation/return-std          | 9.081428   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46144      |
| perf/AverageLength             | 159        |
| perf/AverageReturn             | 438.72104  |
| perf/NormalizedReturn          | 0.0952     |
| Q-avg                          | 188.63936  |
| Q-std                          | 94.60283   |
| Q_loss                         | 148.99945  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 115        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000592   |
| times/evaluation_paths         | 7.57       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 68.3       |
| timestep                       | 1000       |
| timesteps_total                | 116000     |
| train-steps                    | 116000     |
| training/Q/q1_loss             | 93.46425   |
| training/sac_pi/alpha          | 0.16969429 |
| training/sac_pi/alpha_loss     | -0.2241252 |
| training/sac_pi/logp_pi        | 4.389756   |
| training/sac_pi/pi_entropy     | 3.8382428  |
| training/sac_pi/pi_global_norm | 1.2550739  |
| training/sac_pi/policy_loss    | -207.88928 |
| training/sac_pi/std            | 0.5316227  |
| training/sac_pi/valid_num      | 4953.0     |
| training/sac_Q/q1              | 200.10522  |
| training/sac_Q/q2              | 200.12776  |
| training/sac_Q/q2_loss         | 93.26988   |
| training/sac_Q/q_global_norm   | 226.2226   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16076854 |
| epoch                          | 116        |
| evaluation/episode-length-avg  | 116        |
| evaluation/episode-length-max  | 125        |
| evaluation/episode-length-min  | 105        |
| evaluation/episode-length-std  | 7.07       |
| evaluation/return-average      | 242.65532  |
| evaluation/return-max          | 278.123    |
| evaluation/return-min          | 207.6006   |
| evaluation/return-std          | 24.99856   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 87.6       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45818      |
| perf/AverageLength             | 116        |
| perf/AverageReturn             | 242.65532  |
| perf/NormalizedReturn          | 0.0525     |
| Q-avg                          | 196.15047  |
| Q-std                          | 85.32409   |
| Q_loss                         | 86.83642   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 116        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 9.96e-05   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000572   |
| times/evaluation_paths         | 5.33       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 62.9       |
| timestep                       | 1000       |
| timesteps_total                | 117000     |
| train-steps                    | 117000     |
| training/Q/q1_loss             | 87.4884    |
| training/sac_pi/alpha          | 0.16070873 |
| training/sac_pi/alpha_loss     | 0.22359891 |
| training/sac_pi/logp_pi        | 3.728304   |
| training/sac_pi/pi_entropy     | 3.71489    |
| training/sac_pi/pi_global_norm | 2.3029053  |
| training/sac_pi/policy_loss    | -204.76993 |
| training/sac_pi/std            | 0.50334656 |
| training/sac_pi/valid_num      | 5012.0     |
| training/sac_Q/q1              | 200.87004  |
| training/sac_Q/q2              | 200.77522  |
| training/sac_Q/q2_loss         | 87.01833   |
| training/sac_Q/q_global_norm   | 245.40572  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15750268 |
| epoch                          | 117        |
| evaluation/episode-length-avg  | 348        |
| evaluation/episode-length-max  | 408        |
| evaluation/episode-length-min  | 306        |
| evaluation/episode-length-std  | 29.6       |
| evaluation/return-average      | 521.0194   |
| evaluation/return-max          | 626.8102   |
| evaluation/return-min          | 337.3899   |
| evaluation/return-std          | 95.57476   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46197      |
| perf/AverageLength             | 348        |
| perf/AverageReturn             | 521.0194   |
| perf/NormalizedReturn          | 0.113      |
| Q-avg                          | 193.27231  |
| Q-std                          | 91.61979   |
| Q_loss                         | 99.21309   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 117        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000431   |
| times/epoch_rollout_model      | 517        |
| times/evaluation_metrics       | 0.00051    |
| times/evaluation_paths         | 16.1       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 62.5       |
| timestep                       | 1000       |
| timesteps_total                | 118000     |
| train-steps                    | 118000     |
| training/Q/q1_loss             | 97.46627   |
| training/sac_pi/alpha          | 0.15749523 |
| training/sac_pi/alpha_loss     | 0.48910248 |
| training/sac_pi/logp_pi        | 4.7004137  |
| training/sac_pi/pi_entropy     | 3.7266586  |
| training/sac_pi/pi_global_norm | 1.6095022  |
| training/sac_pi/policy_loss    | -196.94673 |
| training/sac_pi/std            | 0.5460722  |
| training/sac_pi/valid_num      | 4883.0     |
| training/sac_Q/q1              | 186.37154  |
| training/sac_Q/q2              | 187.37802  |
| training/sac_Q/q2_loss         | 97.155075  |
| training/sac_Q/q_global_norm   | 346.63998  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15327093 |
| epoch                          | 118        |
| evaluation/episode-length-avg  | 132        |
| evaluation/episode-length-max  | 135        |
| evaluation/episode-length-min  | 128        |
| evaluation/episode-length-std  | 2.4        |
| evaluation/return-average      | 298.64764  |
| evaluation/return-max          | 310.2139   |
| evaluation/return-min          | 284.56516  |
| evaluation/return-std          | 8.475209   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 82.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45969      |
| perf/AverageLength             | 132        |
| perf/AverageReturn             | 298.64764  |
| perf/NormalizedReturn          | 0.0647     |
| Q-avg                          | 196.47864  |
| Q-std                          | 76.33009   |
| Q_loss                         | 92.94181   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 118        |
| times/epoch_after_hook         | 1.65e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000412   |
| times/evaluation_paths         | 4.43       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 119000     |
| train-steps                    | 119000     |
| training/Q/q1_loss             | 98.06363   |
| training/sac_pi/alpha          | 0.15324914 |
| training/sac_pi/alpha_loss     | 0.20627995 |
| training/sac_pi/logp_pi        | 4.040931   |
| training/sac_pi/pi_entropy     | 3.6153977  |
| training/sac_pi/pi_global_norm | 1.9806677  |
| training/sac_pi/policy_loss    | -198.78404 |
| training/sac_pi/std            | 0.50396436 |
| training/sac_pi/valid_num      | 4973.0     |
| training/sac_Q/q1              | 193.2609   |
| training/sac_Q/q2              | 193.22733  |
| training/sac_Q/q2_loss         | 98.046364  |
| training/sac_Q/q_global_norm   | 302.74857  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15689677  |
| epoch                          | 119         |
| evaluation/episode-length-avg  | 150         |
| evaluation/episode-length-max  | 152         |
| evaluation/episode-length-min  | 148         |
| evaluation/episode-length-std  | 1.1         |
| evaluation/return-average      | 370.59302   |
| evaluation/return-max          | 377.3874    |
| evaluation/return-min          | 361.24615   |
| evaluation/return-std          | 4.5439696   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46068       |
| perf/AverageLength             | 150         |
| perf/AverageReturn             | 370.59302   |
| perf/NormalizedReturn          | 0.0804      |
| Q-avg                          | 186.2164    |
| Q-std                          | 94.26241    |
| Q_loss                         | 113.02136   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 119         |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000103    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000441    |
| times/evaluation_paths         | 4.8         |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 62.4        |
| timestep                       | 1000        |
| timesteps_total                | 120000      |
| train-steps                    | 120000      |
| training/Q/q1_loss             | 110.68364   |
| training/sac_pi/alpha          | 0.15689439  |
| training/sac_pi/alpha_loss     | -0.17823394 |
| training/sac_pi/logp_pi        | 4.146861    |
| training/sac_pi/pi_entropy     | 3.674968    |
| training/sac_pi/pi_global_norm | 1.9306957   |
| training/sac_pi/policy_loss    | -194.88956  |
| training/sac_pi/std            | 0.51795185  |
| training/sac_pi/valid_num      | 4954.0      |
| training/sac_Q/q1              | 187.63925   |
| training/sac_Q/q2              | 187.98447   |
| training/sac_Q/q2_loss         | 109.2013    |
| training/sac_Q/q_global_norm   | 291.21545   |
---------------------------------------------------------------------------------
[WARN] 120 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.15978883   |
| epoch                          | 120          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4493.889     |
| evaluation/return-max          | 4604.4785    |
| evaluation/return-min          | 4428.3574    |
| evaluation/return-std          | 56.349567    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.92         |
| model/origin_ret               | 83.4         |
| model/penalty_ret              | 80.5         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46167        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4493.889     |
| perf/NormalizedReturn          | 0.979        |
| Q-avg                          | 193.28976    |
| Q-std                          | 80.74425     |
| Q_loss                         | 111.3571     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 120          |
| times/epoch_after_hook         | 1.82e-06     |
| times/epoch_before_hook        | 8.54e-05     |
| times/epoch_rollout_model      | 479          |
| times/evaluation_metrics       | 0.000614     |
| times/evaluation_paths         | 35           |
| times/timestep_after_hook      | 0.00363      |
| times/timestep_before_hook     | 0.00829      |
| times/train                    | 62.6         |
| timestep                       | 1000         |
| timesteps_total                | 121000       |
| train-steps                    | 121000       |
| training/Q/q1_loss             | 99.47397     |
| training/sac_pi/alpha          | 0.1597979    |
| training/sac_pi/alpha_loss     | -0.008320493 |
| training/sac_pi/logp_pi        | 5.126685     |
| training/sac_pi/pi_entropy     | 4.0072985    |
| training/sac_pi/pi_global_norm | 1.420401     |
| training/sac_pi/policy_loss    | -189.83258   |
| training/sac_pi/std            | 0.61216855   |
| training/sac_pi/valid_num      | 4829.0       |
| training/sac_Q/q1              | 176.48709    |
| training/sac_Q/q2              | 176.54652    |
| training/sac_Q/q2_loss         | 99.27065     |
| training/sac_Q/q_global_norm   | 242.584      |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16388723 |
| epoch                          | 121        |
| evaluation/episode-length-avg  | 654        |
| evaluation/episode-length-max  | 684        |
| evaluation/episode-length-min  | 599        |
| evaluation/episode-length-std  | 29.6       |
| evaluation/return-average      | 2782.2607  |
| evaluation/return-max          | 2903.4675  |
| evaluation/return-min          | 2409.3071  |
| evaluation/return-std          | 145.35268  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46128      |
| perf/AverageLength             | 654        |
| perf/AverageReturn             | 2782.2607  |
| perf/NormalizedReturn          | 0.606      |
| Q-avg                          | 195.16162  |
| Q-std                          | 84.757065  |
| Q_loss                         | 104.73609  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 121        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000277   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.00057    |
| times/evaluation_paths         | 23.5       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 63.6       |
| timestep                       | 1000       |
| timesteps_total                | 122000     |
| train-steps                    | 122000     |
| training/Q/q1_loss             | 106.43589  |
| training/sac_pi/alpha          | 0.16385627 |
| training/sac_pi/alpha_loss     | 0.18381861 |
| training/sac_pi/logp_pi        | 4.4010406  |
| training/sac_pi/pi_entropy     | 3.8728135  |
| training/sac_pi/pi_global_norm | 1.2645457  |
| training/sac_pi/policy_loss    | -196.53178 |
| training/sac_pi/std            | 0.5429586  |
| training/sac_pi/valid_num      | 4928.0     |
| training/sac_Q/q1              | 189.35909  |
| training/sac_Q/q2              | 188.8337   |
| training/sac_Q/q2_loss         | 106.42546  |
| training/sac_Q/q_global_norm   | 292.13455  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1591304  |
| epoch                          | 122        |
| evaluation/episode-length-avg  | 139        |
| evaluation/episode-length-max  | 143        |
| evaluation/episode-length-min  | 136        |
| evaluation/episode-length-std  | 2.1        |
| evaluation/return-average      | 331.57538  |
| evaluation/return-max          | 347.10468  |
| evaluation/return-min          | 319.1598   |
| evaluation/return-std          | 8.518342   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46001      |
| perf/AverageLength             | 139        |
| perf/AverageReturn             | 331.57538  |
| perf/NormalizedReturn          | 0.0719     |
| Q-avg                          | 197.91171  |
| Q-std                          | 93.0629    |
| Q_loss                         | 84.64287   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 122        |
| times/epoch_after_hook         | 3.12e-06   |
| times/epoch_before_hook        | 0.000173   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000567   |
| times/evaluation_paths         | 4.83       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 123000     |
| train-steps                    | 123000     |
| training/Q/q1_loss             | 78.477905  |
| training/sac_pi/alpha          | 0.15913035 |
| training/sac_pi/alpha_loss     | 0.23274136 |
| training/sac_pi/logp_pi        | 3.9925163  |
| training/sac_pi/pi_entropy     | 3.510177   |
| training/sac_pi/pi_global_norm | 1.8502002  |
| training/sac_pi/policy_loss    | -203.3456  |
| training/sac_pi/std            | 0.49308947 |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 197.64322  |
| training/sac_Q/q2              | 197.5057   |
| training/sac_Q/q2_loss         | 78.16288   |
| training/sac_Q/q_global_norm   | 256.79984  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16308299 |
| epoch                          | 123        |
| evaluation/episode-length-avg  | 141        |
| evaluation/episode-length-max  | 142        |
| evaluation/episode-length-min  | 139        |
| evaluation/episode-length-std  | 1.04       |
| evaluation/return-average      | 314.96368  |
| evaluation/return-max          | 322.4182   |
| evaluation/return-min          | 309.51     |
| evaluation/return-std          | 3.8391454  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46120      |
| perf/AverageLength             | 141        |
| perf/AverageReturn             | 314.96368  |
| perf/NormalizedReturn          | 0.0683     |
| Q-avg                          | 199.52196  |
| Q-std                          | 84.03247   |
| Q_loss                         | 88.57301   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 123        |
| times/epoch_after_hook         | 1.17e-05   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000574   |
| times/evaluation_paths         | 6.21       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 124000     |
| train-steps                    | 124000     |
| training/Q/q1_loss             | 93.06019   |
| training/sac_pi/alpha          | 0.16306451 |
| training/sac_pi/alpha_loss     | 0.04807781 |
| training/sac_pi/logp_pi        | 3.579911   |
| training/sac_pi/pi_entropy     | 3.5974991  |
| training/sac_pi/pi_global_norm | 1.1555161  |
| training/sac_pi/policy_loss    | -205.48268 |
| training/sac_pi/std            | 0.4795669  |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 199.95883  |
| training/sac_Q/q2              | 200.06174  |
| training/sac_Q/q2_loss         | 93.87123   |
| training/sac_Q/q_global_norm   | 261.34595  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16174687 |
| epoch                          | 124        |
| evaluation/episode-length-avg  | 168        |
| evaluation/episode-length-max  | 203        |
| evaluation/episode-length-min  | 148        |
| evaluation/episode-length-std  | 22.8       |
| evaluation/return-average      | 359.84396  |
| evaluation/return-max          | 461.83356  |
| evaluation/return-min          | 300.0475   |
| evaluation/return-std          | 65.4209    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46114      |
| perf/AverageLength             | 168        |
| perf/AverageReturn             | 359.84396  |
| perf/NormalizedReturn          | 0.078      |
| Q-avg                          | 192.65652  |
| Q-std                          | 85.92875   |
| Q_loss                         | 107.65197  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 124        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000146   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000496   |
| times/evaluation_paths         | 5.95       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 66.3       |
| timestep                       | 1000       |
| timesteps_total                | 125000     |
| train-steps                    | 125000     |
| training/Q/q1_loss             | 85.73564   |
| training/sac_pi/alpha          | 0.16177629 |
| training/sac_pi/alpha_loss     | -0.2827845 |
| training/sac_pi/logp_pi        | 4.3885536  |
| training/sac_pi/pi_entropy     | 3.5868716  |
| training/sac_pi/pi_global_norm | 1.3636118  |
| training/sac_pi/policy_loss    | -196.8716  |
| training/sac_pi/std            | 0.5242646  |
| training/sac_pi/valid_num      | 4970.0     |
| training/sac_Q/q1              | 190.40906  |
| training/sac_Q/q2              | 191.09534  |
| training/sac_Q/q2_loss         | 85.47484   |
| training/sac_Q/q_global_norm   | 232.19334  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16330485 |
| epoch                          | 125        |
| evaluation/episode-length-avg  | 421        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 160        |
| evaluation/episode-length-std  | 379        |
| evaluation/return-average      | 1626.407   |
| evaluation/return-max          | 4568.7207  |
| evaluation/return-min          | 376.69183  |
| evaluation/return-std          | 1862.5044  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45985      |
| perf/AverageLength             | 421        |
| perf/AverageReturn             | 1626.407   |
| perf/NormalizedReturn          | 0.354      |
| Q-avg                          | 187.38522  |
| Q-std                          | 95.04256   |
| Q_loss                         | 105.661316 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 125        |
| times/epoch_after_hook         | 1.59e-06   |
| times/epoch_before_hook        | 0.000282   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000465   |
| times/evaluation_paths         | 14.5       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 65.6       |
| timestep                       | 1000       |
| timesteps_total                | 126000     |
| train-steps                    | 126000     |
| training/Q/q1_loss             | 99.32173   |
| training/sac_pi/alpha          | 0.16332011 |
| training/sac_pi/alpha_loss     | 0.24850708 |
| training/sac_pi/logp_pi        | 4.8423824  |
| training/sac_pi/pi_entropy     | 3.6968238  |
| training/sac_pi/pi_global_norm | 1.7595632  |
| training/sac_pi/policy_loss    | -206.2543  |
| training/sac_pi/std            | 0.5469642  |
| training/sac_pi/valid_num      | 4932.0     |
| training/sac_Q/q1              | 197.60953  |
| training/sac_Q/q2              | 197.76505  |
| training/sac_Q/q2_loss         | 98.66909   |
| training/sac_Q/q_global_norm   | 439.53433  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16658194  |
| epoch                          | 126         |
| evaluation/episode-length-avg  | 166         |
| evaluation/episode-length-max  | 172         |
| evaluation/episode-length-min  | 159         |
| evaluation/episode-length-std  | 3.82        |
| evaluation/return-average      | 382.58002   |
| evaluation/return-max          | 394.78607   |
| evaluation/return-min          | 368.70685   |
| evaluation/return-std          | 8.092168    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.87        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45889       |
| perf/AverageLength             | 166         |
| perf/AverageReturn             | 382.58002   |
| perf/NormalizedReturn          | 0.083       |
| Q-avg                          | 190.16116   |
| Q-std                          | 93.963234   |
| Q_loss                         | 103.30045   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 126         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.00049     |
| times/evaluation_paths         | 5.57        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 63.4        |
| timestep                       | 1000        |
| timesteps_total                | 127000      |
| train-steps                    | 127000      |
| training/Q/q1_loss             | 119.6688    |
| training/sac_pi/alpha          | 0.16658965  |
| training/sac_pi/alpha_loss     | -0.16630389 |
| training/sac_pi/logp_pi        | 3.7425866   |
| training/sac_pi/pi_entropy     | 3.733993    |
| training/sac_pi/pi_global_norm | 2.0514414   |
| training/sac_pi/policy_loss    | -199.97063  |
| training/sac_pi/std            | 0.50530946  |
| training/sac_pi/valid_num      | 4997.0      |
| training/sac_Q/q1              | 195.4646    |
| training/sac_Q/q2              | 195.82727   |
| training/sac_Q/q2_loss         | 119.95751   |
| training/sac_Q/q_global_norm   | 536.644     |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16952308  |
| epoch                          | 127         |
| evaluation/episode-length-avg  | 714         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 192         |
| evaluation/episode-length-std  | 289         |
| evaluation/return-average      | 2984.709    |
| evaluation/return-max          | 4544.333    |
| evaluation/return-min          | 310.1258    |
| evaluation/return-std          | 1504.2075   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45938       |
| perf/AverageLength             | 714         |
| perf/AverageReturn             | 2984.709    |
| perf/NormalizedReturn          | 0.65        |
| Q-avg                          | 185.98573   |
| Q-std                          | 96.192986   |
| Q_loss                         | 85.377396   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 127         |
| times/epoch_after_hook         | 1.66e-06    |
| times/epoch_before_hook        | 0.000169    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000585    |
| times/evaluation_paths         | 27          |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.0106      |
| times/train                    | 64          |
| timestep                       | 1000        |
| timesteps_total                | 128000      |
| train-steps                    | 128000      |
| training/Q/q1_loss             | 84.838455   |
| training/sac_pi/alpha          | 0.16952361  |
| training/sac_pi/alpha_loss     | -0.38661247 |
| training/sac_pi/logp_pi        | 3.8332849   |
| training/sac_pi/pi_entropy     | 3.6446354   |
| training/sac_pi/pi_global_norm | 1.4311641   |
| training/sac_pi/policy_loss    | -208.92397  |
| training/sac_pi/std            | 0.50080806  |
| training/sac_pi/valid_num      | 5001.0      |
| training/sac_Q/q1              | 204.17549   |
| training/sac_Q/q2              | 203.88187   |
| training/sac_Q/q2_loss         | 84.78513    |
| training/sac_Q/q_global_norm   | 376.2844    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16017723 |
| epoch                          | 128        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4835.7373  |
| evaluation/return-max          | 4939.383   |
| evaluation/return-min          | 4752.962   |
| evaluation/return-std          | 52.0307    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 87.2       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45900      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4835.7373  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 192.30121  |
| Q-std                          | 94.03609   |
| Q_loss                         | 91.28317   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 128        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000577   |
| times/evaluation_paths         | 35.1       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 64.1       |
| timestep                       | 1000       |
| timesteps_total                | 129000     |
| train-steps                    | 129000     |
| training/Q/q1_loss             | 92.802444  |
| training/sac_pi/alpha          | 0.16017607 |
| training/sac_pi/alpha_loss     | 0.31046742 |
| training/sac_pi/logp_pi        | 5.021281   |
| training/sac_pi/pi_entropy     | 3.520515   |
| training/sac_pi/pi_global_norm | 1.5341494  |
| training/sac_pi/policy_loss    | -201.22311 |
| training/sac_pi/std            | 0.53387505 |
| training/sac_pi/valid_num      | 4910.0     |
| training/sac_Q/q1              | 193.26193  |
| training/sac_Q/q2              | 193.25098  |
| training/sac_Q/q2_loss         | 92.076454  |
| training/sac_Q/q_global_norm   | 267.4872   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16522603 |
| epoch                          | 129        |
| evaluation/episode-length-avg  | 914        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 144        |
| evaluation/episode-length-std  | 257        |
| evaluation/return-average      | 4454.9756  |
| evaluation/return-max          | 5010.435   |
| evaluation/return-min          | 344.16992  |
| evaluation/return-std          | 1371.2684  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46084      |
| perf/AverageLength             | 914        |
| perf/AverageReturn             | 4454.9756  |
| perf/NormalizedReturn          | 0.97       |
| Q-avg                          | 202.36006  |
| Q-std                          | 86.87315   |
| Q_loss                         | 93.84658   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 129        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000331   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000521   |
| times/evaluation_paths         | 33.1       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 63.9       |
| timestep                       | 1000       |
| timesteps_total                | 130000     |
| train-steps                    | 130000     |
| training/Q/q1_loss             | 103.8486   |
| training/sac_pi/alpha          | 0.16520447 |
| training/sac_pi/alpha_loss     | 0.09121208 |
| training/sac_pi/logp_pi        | 5.0674744  |
| training/sac_pi/pi_entropy     | 3.7195687  |
| training/sac_pi/pi_global_norm | 1.5048155  |
| training/sac_pi/policy_loss    | -199.19698 |
| training/sac_pi/std            | 0.55625814 |
| training/sac_pi/valid_num      | 4932.0     |
| training/sac_Q/q1              | 191.14867  |
| training/sac_Q/q2              | 191.55122  |
| training/sac_Q/q2_loss         | 103.85042  |
| training/sac_Q/q_global_norm   | 257.58566  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16331568 |
| epoch                          | 130        |
| evaluation/episode-length-avg  | 386        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 114        |
| evaluation/episode-length-std  | 402        |
| evaluation/return-average      | 1593.5682  |
| evaluation/return-max          | 4707.4834  |
| evaluation/return-min          | 239.21751  |
| evaluation/return-std          | 2021.7087  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46137      |
| perf/AverageLength             | 386        |
| perf/AverageReturn             | 1593.5682  |
| perf/NormalizedReturn          | 0.347      |
| Q-avg                          | 199.37827  |
| Q-std                          | 83.58913   |
| Q_loss                         | 98.05916   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 130        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.00014    |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000511   |
| times/evaluation_paths         | 14.6       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 131000     |
| train-steps                    | 131000     |
| training/Q/q1_loss             | 77.35703   |
| training/sac_pi/alpha          | 0.16330767 |
| training/sac_pi/alpha_loss     | -0.2989143 |
| training/sac_pi/logp_pi        | 3.9692535  |
| training/sac_pi/pi_entropy     | 3.7621505  |
| training/sac_pi/pi_global_norm | 1.7880919  |
| training/sac_pi/policy_loss    | -202.69656 |
| training/sac_pi/std            | 0.53091025 |
| training/sac_pi/valid_num      | 4955.0     |
| training/sac_Q/q1              | 197.26291  |
| training/sac_Q/q2              | 196.38326  |
| training/sac_Q/q2_loss         | 78.20917   |
| training/sac_Q/q_global_norm   | 432.19     |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16202483  |
| epoch                          | 131         |
| evaluation/episode-length-avg  | 151         |
| evaluation/episode-length-max  | 170         |
| evaluation/episode-length-min  | 133         |
| evaluation/episode-length-std  | 16.2        |
| evaluation/return-average      | 381.65964   |
| evaluation/return-max          | 455.13083   |
| evaluation/return-min          | 313.63257   |
| evaluation/return-std          | 63.00052    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 81.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46045       |
| perf/AverageLength             | 151         |
| perf/AverageReturn             | 381.65964   |
| perf/NormalizedReturn          | 0.0828      |
| Q-avg                          | 198.89992   |
| Q-std                          | 85.25252    |
| Q_loss                         | 107.57501   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 131         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000144    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000409    |
| times/evaluation_paths         | 5.26        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00839     |
| times/train                    | 63.4        |
| timestep                       | 1000        |
| timesteps_total                | 132000      |
| train-steps                    | 132000      |
| training/Q/q1_loss             | 101.855736  |
| training/sac_pi/alpha          | 0.16204734  |
| training/sac_pi/alpha_loss     | 0.106666714 |
| training/sac_pi/logp_pi        | 4.4422903   |
| training/sac_pi/pi_entropy     | 3.5257592   |
| training/sac_pi/pi_global_norm | 1.7764579   |
| training/sac_pi/policy_loss    | -201.59076  |
| training/sac_pi/std            | 0.50955236  |
| training/sac_pi/valid_num      | 4928.0      |
| training/sac_Q/q1              | 193.35925   |
| training/sac_Q/q2              | 193.76114   |
| training/sac_Q/q2_loss         | 101.06762   |
| training/sac_Q/q_global_norm   | 234.96072   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1618401  |
| epoch                          | 132        |
| evaluation/episode-length-avg  | 350        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 172        |
| evaluation/episode-length-std  | 325        |
| evaluation/return-average      | 1283.884   |
| evaluation/return-max          | 4452.591   |
| evaluation/return-min          | 430.65094  |
| evaluation/return-std          | 1561.2065  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46105      |
| perf/AverageLength             | 350        |
| perf/AverageReturn             | 1283.884   |
| perf/NormalizedReturn          | 0.279      |
| Q-avg                          | 193.95226  |
| Q-std                          | 100.94373  |
| Q_loss                         | 115.38662  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 132        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 8.36e-05   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000406   |
| times/evaluation_paths         | 12.1       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 66         |
| timestep                       | 1000       |
| timesteps_total                | 133000     |
| train-steps                    | 133000     |
| training/Q/q1_loss             | 86.12648   |
| training/sac_pi/alpha          | 0.16178906 |
| training/sac_pi/alpha_loss     | 0.5978436  |
| training/sac_pi/logp_pi        | 4.712077   |
| training/sac_pi/pi_entropy     | 3.590053   |
| training/sac_pi/pi_global_norm | 1.493392   |
| training/sac_pi/policy_loss    | -209.3939  |
| training/sac_pi/std            | 0.5267027  |
| training/sac_pi/valid_num      | 4909.0     |
| training/sac_Q/q1              | 200.1558   |
| training/sac_Q/q2              | 199.76584  |
| training/sac_Q/q2_loss         | 86.72281   |
| training/sac_Q/q_global_norm   | 236.3612   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16270213 |
| epoch                          | 133        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4569.543   |
| evaluation/return-max          | 4621.6577  |
| evaluation/return-min          | 4523.0957  |
| evaluation/return-std          | 33.432945  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46007      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4569.543   |
| perf/NormalizedReturn          | 0.995      |
| Q-avg                          | 204.43948  |
| Q-std                          | 92.465775  |
| Q_loss                         | 72.4988    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 133        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.00032    |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000641   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 64.3       |
| timestep                       | 1000       |
| timesteps_total                | 134000     |
| train-steps                    | 134000     |
| training/Q/q1_loss             | 96.957405  |
| training/sac_pi/alpha          | 0.1626464  |
| training/sac_pi/alpha_loss     | 0.53304636 |
| training/sac_pi/logp_pi        | 4.070836   |
| training/sac_pi/pi_entropy     | 3.7104821  |
| training/sac_pi/pi_global_norm | 1.772412   |
| training/sac_pi/policy_loss    | -198.91653 |
| training/sac_pi/std            | 0.49366924 |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 193.18059  |
| training/sac_Q/q2              | 193.50269  |
| training/sac_Q/q2_loss         | 97.79539   |
| training/sac_Q/q_global_norm   | 398.26483  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1596857  |
| epoch                          | 134        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4757.7437  |
| evaluation/return-max          | 4833.9985  |
| evaluation/return-min          | 4680.5283  |
| evaluation/return-std          | 39.122295  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46087      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4757.7437  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 198.54504  |
| Q-std                          | 90.7948    |
| Q_loss                         | 116.61062  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 134        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000569   |
| times/evaluation_paths         | 35         |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 135000     |
| train-steps                    | 135000     |
| training/Q/q1_loss             | 91.52043   |
| training/sac_pi/alpha          | 0.15969174 |
| training/sac_pi/alpha_loss     | 0.04551398 |
| training/sac_pi/logp_pi        | 4.6540284  |
| training/sac_pi/pi_entropy     | 3.6671638  |
| training/sac_pi/pi_global_norm | 1.9000697  |
| training/sac_pi/policy_loss    | -206.5555  |
| training/sac_pi/std            | 0.5520668  |
| training/sac_pi/valid_num      | 4927.0     |
| training/sac_Q/q1              | 198.91524  |
| training/sac_Q/q2              | 198.66089  |
| training/sac_Q/q2_loss         | 91.3117    |
| training/sac_Q/q_global_norm   | 259.55756  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16285793 |
| epoch                          | 135        |
| evaluation/episode-length-avg  | 586        |
| evaluation/episode-length-max  | 848        |
| evaluation/episode-length-min  | 400        |
| evaluation/episode-length-std  | 174        |
| evaluation/return-average      | 2560.4963  |
| evaluation/return-max          | 3944.5532  |
| evaluation/return-min          | 1607.8691  |
| evaluation/return-std          | 920.88055  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46098      |
| perf/AverageLength             | 586        |
| perf/AverageReturn             | 2560.4963  |
| perf/NormalizedReturn          | 0.557      |
| Q-avg                          | 204.49002  |
| Q-std                          | 90.04067   |
| Q_loss                         | 96.226944  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 135        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.00061    |
| times/evaluation_paths         | 20.7       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 63.2       |
| timestep                       | 1000       |
| timesteps_total                | 136000     |
| train-steps                    | 136000     |
| training/Q/q1_loss             | 88.71972   |
| training/sac_pi/alpha          | 0.1628341  |
| training/sac_pi/alpha_loss     | 0.17234151 |
| training/sac_pi/logp_pi        | 4.4230385  |
| training/sac_pi/pi_entropy     | 3.7597363  |
| training/sac_pi/pi_global_norm | 1.3476925  |
| training/sac_pi/policy_loss    | -206.88506 |
| training/sac_pi/std            | 0.526519   |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 200.26399  |
| training/sac_Q/q2              | 199.25174  |
| training/sac_Q/q2_loss         | 88.34369   |
| training/sac_Q/q_global_norm   | 295.46774  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16379504  |
| epoch                          | 136         |
| evaluation/episode-length-avg  | 145         |
| evaluation/episode-length-max  | 148         |
| evaluation/episode-length-min  | 143         |
| evaluation/episode-length-std  | 1.62        |
| evaluation/return-average      | 373.2287    |
| evaluation/return-max          | 390.52716   |
| evaluation/return-min          | 365.13867   |
| evaluation/return-std          | 8.823753    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 88.9        |
| model/penalty_ret              | 83.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 45723       |
| perf/AverageLength             | 145         |
| perf/AverageReturn             | 373.2287    |
| perf/NormalizedReturn          | 0.0809      |
| Q-avg                          | 196.31148   |
| Q-std                          | 87.45815    |
| Q_loss                         | 86.23776    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 136         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000147    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.00057     |
| times/evaluation_paths         | 5.38        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 63.4        |
| timestep                       | 1000        |
| timesteps_total                | 137000      |
| train-steps                    | 137000      |
| training/Q/q1_loss             | 100.03784   |
| training/sac_pi/alpha          | 0.16377208  |
| training/sac_pi/alpha_loss     | 0.054610744 |
| training/sac_pi/logp_pi        | 3.9163914   |
| training/sac_pi/pi_entropy     | 3.551371    |
| training/sac_pi/pi_global_norm | 1.6875376   |
| training/sac_pi/policy_loss    | -207.30377  |
| training/sac_pi/std            | 0.49464765  |
| training/sac_pi/valid_num      | 4973.0      |
| training/sac_Q/q1              | 201.78812   |
| training/sac_Q/q2              | 201.69934   |
| training/sac_Q/q2_loss         | 99.99681    |
| training/sac_Q/q_global_norm   | 214.28096   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16079226 |
| epoch                          | 137        |
| evaluation/episode-length-avg  | 119        |
| evaluation/episode-length-max  | 121        |
| evaluation/episode-length-min  | 117        |
| evaluation/episode-length-std  | 1.37       |
| evaluation/return-average      | 259.30762  |
| evaluation/return-max          | 266.43393  |
| evaluation/return-min          | 250.60799  |
| evaluation/return-std          | 5.1345663  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46040      |
| perf/AverageLength             | 119        |
| perf/AverageReturn             | 259.30762  |
| perf/NormalizedReturn          | 0.0561     |
| Q-avg                          | 205.14282  |
| Q-std                          | 83.96784   |
| Q_loss                         | 102.219376 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 137        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000303   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000459   |
| times/evaluation_paths         | 4.11       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 64.6       |
| timestep                       | 1000       |
| timesteps_total                | 138000     |
| train-steps                    | 138000     |
| training/Q/q1_loss             | 111.49013  |
| training/sac_pi/alpha          | 0.16078976 |
| training/sac_pi/alpha_loss     | 0.09364585 |
| training/sac_pi/logp_pi        | 4.573758   |
| training/sac_pi/pi_entropy     | 3.6862235  |
| training/sac_pi/pi_global_norm | 1.6200277  |
| training/sac_pi/policy_loss    | -200.62485 |
| training/sac_pi/std            | 0.5247024  |
| training/sac_pi/valid_num      | 4984.0     |
| training/sac_Q/q1              | 194.92325  |
| training/sac_Q/q2              | 196.38492  |
| training/sac_Q/q2_loss         | 112.45314  |
| training/sac_Q/q_global_norm   | 291.2403   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16271603  |
| epoch                          | 138         |
| evaluation/episode-length-avg  | 179         |
| evaluation/episode-length-max  | 184         |
| evaluation/episode-length-min  | 167         |
| evaluation/episode-length-std  | 4.61        |
| evaluation/return-average      | 383.96603   |
| evaluation/return-max          | 394.45245   |
| evaluation/return-min          | 345.0694    |
| evaluation/return-std          | 14.982997   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46259       |
| perf/AverageLength             | 179         |
| perf/AverageReturn             | 383.96603   |
| perf/NormalizedReturn          | 0.0833      |
| Q-avg                          | 200.9196    |
| Q-std                          | 88.99203    |
| Q_loss                         | 93.9445     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 138         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 8.4e-05     |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000528    |
| times/evaluation_paths         | 6.58        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00864     |
| times/train                    | 66.6        |
| timestep                       | 1000        |
| timesteps_total                | 139000      |
| train-steps                    | 139000      |
| training/Q/q1_loss             | 94.84727    |
| training/sac_pi/alpha          | 0.16270986  |
| training/sac_pi/alpha_loss     | -0.18179196 |
| training/sac_pi/logp_pi        | 4.358571    |
| training/sac_pi/pi_entropy     | 3.5941052   |
| training/sac_pi/pi_global_norm | 1.2502077   |
| training/sac_pi/policy_loss    | -216.74678  |
| training/sac_pi/std            | 0.5142694   |
| training/sac_pi/valid_num      | 4963.0      |
| training/sac_Q/q1              | 208.33926   |
| training/sac_Q/q2              | 209.327     |
| training/sac_Q/q2_loss         | 94.20744    |
| training/sac_Q/q_global_norm   | 233.04184   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16603018   |
| epoch                          | 139          |
| evaluation/episode-length-avg  | 157          |
| evaluation/episode-length-max  | 158          |
| evaluation/episode-length-min  | 155          |
| evaluation/episode-length-std  | 0.98         |
| evaluation/return-average      | 372.62665    |
| evaluation/return-max          | 374.91956    |
| evaluation/return-min          | 369.04446    |
| evaluation/return-std          | 2.0326104    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.97         |
| model/origin_ret               | 85.1         |
| model/penalty_ret              | 80.8         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 45961        |
| perf/AverageLength             | 157          |
| perf/AverageReturn             | 372.62665    |
| perf/NormalizedReturn          | 0.0808       |
| Q-avg                          | 200.81819    |
| Q-std                          | 93.75422     |
| Q_loss                         | 101.797264   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 139          |
| times/epoch_after_hook         | 1.68e-06     |
| times/epoch_before_hook        | 0.000124     |
| times/epoch_rollout_model      | 528          |
| times/evaluation_metrics       | 0.000526     |
| times/evaluation_paths         | 6.19         |
| times/timestep_after_hook      | 0.00387      |
| times/timestep_before_hook     | 0.00855      |
| times/train                    | 67.1         |
| timestep                       | 1000         |
| timesteps_total                | 140000       |
| train-steps                    | 140000       |
| training/Q/q1_loss             | 102.63001    |
| training/sac_pi/alpha          | 0.1660268    |
| training/sac_pi/alpha_loss     | -0.063954055 |
| training/sac_pi/logp_pi        | 4.0284777    |
| training/sac_pi/pi_entropy     | 3.6578202    |
| training/sac_pi/pi_global_norm | 1.7437346    |
| training/sac_pi/policy_loss    | -209.67508   |
| training/sac_pi/std            | 0.51523113   |
| training/sac_pi/valid_num      | 5005.0       |
| training/sac_Q/q1              | 204.3175     |
| training/sac_Q/q2              | 205.41422    |
| training/sac_Q/q2_loss         | 102.48895    |
| training/sac_Q/q_global_norm   | 240.63042    |
----------------------------------------------------------------------------------
[WARN] 140 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.1663648   |
| epoch                          | 140         |
| evaluation/episode-length-avg  | 137         |
| evaluation/episode-length-max  | 140         |
| evaluation/episode-length-min  | 133         |
| evaluation/episode-length-std  | 2.07        |
| evaluation/return-average      | 276.54868   |
| evaluation/return-max          | 283.60028   |
| evaluation/return-min          | 272.82562   |
| evaluation/return-std          | 2.8595324   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46225       |
| perf/AverageLength             | 137         |
| perf/AverageReturn             | 276.54868   |
| perf/NormalizedReturn          | 0.0599      |
| Q-avg                          | 200.60773   |
| Q-std                          | 84.37586    |
| Q_loss                         | 97.04468    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 140         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 8.38e-05    |
| times/epoch_rollout_model      | 527         |
| times/evaluation_metrics       | 0.000446    |
| times/evaluation_paths         | 6.43        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 66.2        |
| timestep                       | 1000        |
| timesteps_total                | 141000      |
| train-steps                    | 141000      |
| training/Q/q1_loss             | 95.856575   |
| training/sac_pi/alpha          | 0.16640499  |
| training/sac_pi/alpha_loss     | 0.032140248 |
| training/sac_pi/logp_pi        | 4.1947327   |
| training/sac_pi/pi_entropy     | 3.535141    |
| training/sac_pi/pi_global_norm | 2.0504427   |
| training/sac_pi/policy_loss    | -209.01376  |
| training/sac_pi/std            | 0.503456    |
| training/sac_pi/valid_num      | 5002.0      |
| training/sac_Q/q1              | 203.9897    |
| training/sac_Q/q2              | 204.86157   |
| training/sac_Q/q2_loss         | 96.4295     |
| training/sac_Q/q_global_norm   | 242.88165   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17202388  |
| epoch                          | 141         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4569.1416   |
| evaluation/return-max          | 4639.776    |
| evaluation/return-min          | 4521.038    |
| evaluation/return-std          | 40.958992   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46013       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4569.1416   |
| perf/NormalizedReturn          | 0.995       |
| Q-avg                          | 204.55342   |
| Q-std                          | 83.09378    |
| Q_loss                         | 86.28176    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 141         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000329    |
| times/epoch_rollout_model      | 542         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 38.1        |
| times/timestep_after_hook      | 0.00376     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 67.7        |
| timestep                       | 1000        |
| timesteps_total                | 142000      |
| train-steps                    | 142000      |
| training/Q/q1_loss             | 113.16487   |
| training/sac_pi/alpha          | 0.17206162  |
| training/sac_pi/alpha_loss     | -0.30226368 |
| training/sac_pi/logp_pi        | 4.073287    |
| training/sac_pi/pi_entropy     | 3.8299065   |
| training/sac_pi/pi_global_norm | 1.5792227   |
| training/sac_pi/policy_loss    | -201.65057  |
| training/sac_pi/std            | 0.52535385  |
| training/sac_pi/valid_num      | 4897.0      |
| training/sac_Q/q1              | 192.17473   |
| training/sac_Q/q2              | 192.33511   |
| training/sac_Q/q2_loss         | 112.62451   |
| training/sac_Q/q_global_norm   | 230.02582   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17644341 |
| epoch                          | 142        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4598.815   |
| evaluation/return-max          | 4617.7705  |
| evaluation/return-min          | 4569.9595  |
| evaluation/return-std          | 13.522539  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45924      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4598.815   |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 191.89404  |
| Q-std                          | 92.88762   |
| Q_loss                         | 104.37113  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 142        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.000632   |
| times/evaluation_paths         | 37.9       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 65.6       |
| timestep                       | 1000       |
| timesteps_total                | 143000     |
| train-steps                    | 143000     |
| training/Q/q1_loss             | 100.754425 |
| training/sac_pi/alpha          | 0.17642468 |
| training/sac_pi/alpha_loss     | 0.3719605  |
| training/sac_pi/logp_pi        | 4.7548447  |
| training/sac_pi/pi_entropy     | 3.7376657  |
| training/sac_pi/pi_global_norm | 1.57904    |
| training/sac_pi/policy_loss    | -200.06932 |
| training/sac_pi/std            | 0.5295981  |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 192.55943  |
| training/sac_Q/q2              | 193.00188  |
| training/sac_Q/q2_loss         | 101.05503  |
| training/sac_Q/q_global_norm   | 241.68915  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16217051 |
| epoch                          | 143        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4507.715   |
| evaluation/return-max          | 4542.3184  |
| evaluation/return-min          | 4481.952   |
| evaluation/return-std          | 20.015125  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46013      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4507.715   |
| perf/NormalizedReturn          | 0.982      |
| Q-avg                          | 195.16377  |
| Q-std                          | 92.853775  |
| Q_loss                         | 98.82358   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 143        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000146   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000583   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 62.5       |
| timestep                       | 1000       |
| timesteps_total                | 144000     |
| train-steps                    | 144000     |
| training/Q/q1_loss             | 90.959206  |
| training/sac_pi/alpha          | 0.16216026 |
| training/sac_pi/alpha_loss     | 0.25539997 |
| training/sac_pi/logp_pi        | 3.8950257  |
| training/sac_pi/pi_entropy     | 3.6443012  |
| training/sac_pi/pi_global_norm | 1.2939932  |
| training/sac_pi/policy_loss    | -199.76154 |
| training/sac_pi/std            | 0.50121826 |
| training/sac_pi/valid_num      | 4976.0     |
| training/sac_Q/q1              | 193.88248  |
| training/sac_Q/q2              | 194.31528  |
| training/sac_Q/q2_loss         | 90.782104  |
| training/sac_Q/q_global_norm   | 206.08455  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1641454   |
| epoch                          | 144         |
| evaluation/episode-length-avg  | 678         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 192         |
| evaluation/episode-length-std  | 394         |
| evaluation/return-average      | 2976.579    |
| evaluation/return-max          | 4647.9014   |
| evaluation/return-min          | 514.0014    |
| evaluation/return-std          | 1997.5878   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46035       |
| perf/AverageLength             | 678         |
| perf/AverageReturn             | 2976.579    |
| perf/NormalizedReturn          | 0.648       |
| Q-avg                          | 191.46127   |
| Q-std                          | 95.80602    |
| Q_loss                         | 90.112564   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 144         |
| times/epoch_after_hook         | 1.62e-06    |
| times/epoch_before_hook        | 0.00017     |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000701    |
| times/evaluation_paths         | 24.7        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00827     |
| times/train                    | 62.4        |
| timestep                       | 1000        |
| timesteps_total                | 145000      |
| train-steps                    | 145000      |
| training/Q/q1_loss             | 107.47661   |
| training/sac_pi/alpha          | 0.16415852  |
| training/sac_pi/alpha_loss     | 0.020953223 |
| training/sac_pi/logp_pi        | 4.5640097   |
| training/sac_pi/pi_entropy     | 3.6826477   |
| training/sac_pi/pi_global_norm | 1.4328201   |
| training/sac_pi/policy_loss    | -199.97421  |
| training/sac_pi/std            | 0.52771163  |
| training/sac_pi/valid_num      | 4941.0      |
| training/sac_Q/q1              | 191.90836   |
| training/sac_Q/q2              | 193.40582   |
| training/sac_Q/q2_loss         | 107.3214    |
| training/sac_Q/q_global_norm   | 301.21997   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16046263   |
| epoch                          | 145          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4681.005     |
| evaluation/return-max          | 4781.583     |
| evaluation/return-min          | 4583.541     |
| evaluation/return-std          | 58.33155     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.06         |
| model/origin_ret               | 86.3         |
| model/penalty_ret              | 81.3         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46221        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4681.005     |
| perf/NormalizedReturn          | 1.02         |
| Q-avg                          | 198.9698     |
| Q-std                          | 87.275246    |
| Q_loss                         | 102.59915    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 145          |
| times/epoch_after_hook         | 1.67e-06     |
| times/epoch_before_hook        | 0.000454     |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.000631     |
| times/evaluation_paths         | 35.2         |
| times/timestep_after_hook      | 0.00366      |
| times/timestep_before_hook     | 0.00836      |
| times/train                    | 63.4         |
| timestep                       | 1000         |
| timesteps_total                | 146000       |
| train-steps                    | 146000       |
| training/Q/q1_loss             | 101.278076   |
| training/sac_pi/alpha          | 0.16048293   |
| training/sac_pi/alpha_loss     | -0.062296595 |
| training/sac_pi/logp_pi        | 3.9920144    |
| training/sac_pi/pi_entropy     | 3.6255355    |
| training/sac_pi/pi_global_norm | 1.4069641    |
| training/sac_pi/policy_loss    | -202.77437   |
| training/sac_pi/std            | 0.506183     |
| training/sac_pi/valid_num      | 4955.0       |
| training/sac_Q/q1              | 196.06693    |
| training/sac_Q/q2              | 196.3556     |
| training/sac_Q/q2_loss         | 101.57528    |
| training/sac_Q/q_global_norm   | 228.7903     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16205806 |
| epoch                          | 146        |
| evaluation/episode-length-avg  | 737        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 120        |
| evaluation/episode-length-std  | 401        |
| evaluation/return-average      | 3626.066   |
| evaluation/return-max          | 5080.092   |
| evaluation/return-min          | 280.0299   |
| evaluation/return-std          | 2178.4153  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46254      |
| perf/AverageLength             | 737        |
| perf/AverageReturn             | 3626.066   |
| perf/NormalizedReturn          | 0.79       |
| Q-avg                          | 190.11768  |
| Q-std                          | 103.83743  |
| Q_loss                         | 107.37403  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 146        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000148   |
| times/epoch_rollout_model      | 525        |
| times/evaluation_metrics       | 0.000632   |
| times/evaluation_paths         | 27.1       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.0105     |
| times/train                    | 62.7       |
| timestep                       | 1000       |
| timesteps_total                | 147000     |
| train-steps                    | 147000     |
| training/Q/q1_loss             | 108.932755 |
| training/sac_pi/alpha          | 0.16202906 |
| training/sac_pi/alpha_loss     | 0.223786   |
| training/sac_pi/logp_pi        | 4.565093   |
| training/sac_pi/pi_entropy     | 3.7364872  |
| training/sac_pi/pi_global_norm | 1.5520942  |
| training/sac_pi/policy_loss    | -203.40587 |
| training/sac_pi/std            | 0.5337553  |
| training/sac_pi/valid_num      | 4916.0     |
| training/sac_Q/q1              | 193.67816  |
| training/sac_Q/q2              | 193.8561   |
| training/sac_Q/q2_loss         | 109.83142  |
| training/sac_Q/q_global_norm   | 248.87929  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1546401  |
| epoch                          | 147        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4737.8843  |
| evaluation/return-max          | 4937.848   |
| evaluation/return-min          | 4580.6357  |
| evaluation/return-std          | 139.68263  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46214      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4737.8843  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 190.84915  |
| Q-std                          | 109.09787  |
| Q_loss                         | 99.54697   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 147        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 529        |
| times/evaluation_metrics       | 0.000766   |
| times/evaluation_paths         | 38.1       |
| times/timestep_after_hook      | 0.00402    |
| times/timestep_before_hook     | 0.00875    |
| times/train                    | 62.9       |
| timestep                       | 1000       |
| timesteps_total                | 148000     |
| train-steps                    | 148000     |
| training/Q/q1_loss             | 80.22069   |
| training/sac_pi/alpha          | 0.1546448  |
| training/sac_pi/alpha_loss     | 0.18350567 |
| training/sac_pi/logp_pi        | 4.1643343  |
| training/sac_pi/pi_entropy     | 3.5193658  |
| training/sac_pi/pi_global_norm | 1.3167514  |
| training/sac_pi/policy_loss    | -219.06972 |
| training/sac_pi/std            | 0.50501084 |
| training/sac_pi/valid_num      | 4967.0     |
| training/sac_Q/q1              | 210.35542  |
| training/sac_Q/q2              | 210.27666  |
| training/sac_Q/q2_loss         | 80.997086  |
| training/sac_Q/q_global_norm   | 252.31084  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15860265  |
| epoch                          | 148         |
| evaluation/episode-length-avg  | 142         |
| evaluation/episode-length-max  | 143         |
| evaluation/episode-length-min  | 141         |
| evaluation/episode-length-std  | 0.7         |
| evaluation/return-average      | 333.76434   |
| evaluation/return-max          | 341.2879    |
| evaluation/return-min          | 327.59747   |
| evaluation/return-std          | 4.214881    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 81.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46185       |
| perf/AverageLength             | 142         |
| perf/AverageReturn             | 333.76434   |
| perf/NormalizedReturn          | 0.0724      |
| Q-avg                          | 212.311     |
| Q-std                          | 77.72063    |
| Q_loss                         | 88.68964    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 148         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 556         |
| times/evaluation_metrics       | 0.000723    |
| times/evaluation_paths         | 6.65        |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 66          |
| timestep                       | 1000        |
| timesteps_total                | 149000      |
| train-steps                    | 149000      |
| training/Q/q1_loss             | 78.40232    |
| training/sac_pi/alpha          | 0.1585896   |
| training/sac_pi/alpha_loss     | -0.15421003 |
| training/sac_pi/logp_pi        | 4.312871    |
| training/sac_pi/pi_entropy     | 3.4736638   |
| training/sac_pi/pi_global_norm | 1.3454422   |
| training/sac_pi/policy_loss    | -209.8768   |
| training/sac_pi/std            | 0.50714475  |
| training/sac_pi/valid_num      | 4998.0      |
| training/sac_Q/q1              | 203.41016   |
| training/sac_Q/q2              | 203.91257   |
| training/sac_Q/q2_loss         | 78.856544   |
| training/sac_Q/q_global_norm   | 217.38591   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16500674  |
| epoch                          | 149         |
| evaluation/episode-length-avg  | 437         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 192         |
| evaluation/episode-length-std  | 369         |
| evaluation/return-average      | 1834.766    |
| evaluation/return-max          | 5073.792    |
| evaluation/return-min          | 439.37476   |
| evaluation/return-std          | 2109.6228   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46169       |
| perf/AverageLength             | 437         |
| perf/AverageReturn             | 1834.766    |
| perf/NormalizedReturn          | 0.399       |
| Q-avg                          | 207.25166   |
| Q-std                          | 90.86953    |
| Q_loss                         | 87.48471    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 149         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000838    |
| times/epoch_rollout_model      | 541         |
| times/evaluation_metrics       | 0.000666    |
| times/evaluation_paths         | 18.6        |
| times/timestep_after_hook      | 0.0038      |
| times/timestep_before_hook     | 0.0111      |
| times/train                    | 73.3        |
| timestep                       | 1000        |
| timesteps_total                | 150000      |
| train-steps                    | 150000      |
| training/Q/q1_loss             | 89.94047    |
| training/sac_pi/alpha          | 0.16502292  |
| training/sac_pi/alpha_loss     | -0.17873135 |
| training/sac_pi/logp_pi        | 3.6521847   |
| training/sac_pi/pi_entropy     | 3.6136475   |
| training/sac_pi/pi_global_norm | 1.4709476   |
| training/sac_pi/policy_loss    | -209.74388  |
| training/sac_pi/std            | 0.48892516  |
| training/sac_pi/valid_num      | 5010.0      |
| training/sac_Q/q1              | 205.67355   |
| training/sac_Q/q2              | 205.55905   |
| training/sac_Q/q2_loss         | 90.32356    |
| training/sac_Q/q_global_norm   | 272.68692   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16815649 |
| epoch                          | 150        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4572.538   |
| evaluation/return-max          | 4632.544   |
| evaluation/return-min          | 4489.649   |
| evaluation/return-std          | 44.26992   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46137      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4572.538   |
| perf/NormalizedReturn          | 0.996      |
| Q-avg                          | 197.90019  |
| Q-std                          | 95.95154   |
| Q_loss                         | 101.42935  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 150        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000148   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000599   |
| times/evaluation_paths         | 38.7       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00856    |
| times/train                    | 71.6       |
| timestep                       | 1000       |
| timesteps_total                | 151000     |
| train-steps                    | 151000     |
| training/Q/q1_loss             | 114.64641  |
| training/sac_pi/alpha          | 0.16814816 |
| training/sac_pi/alpha_loss     | 0.4107334  |
| training/sac_pi/logp_pi        | 4.04857    |
| training/sac_pi/pi_entropy     | 3.7946632  |
| training/sac_pi/pi_global_norm | 1.63042    |
| training/sac_pi/policy_loss    | -200.76909 |
| training/sac_pi/std            | 0.51447713 |
| training/sac_pi/valid_num      | 4986.0     |
| training/sac_Q/q1              | 194.88367  |
| training/sac_Q/q2              | 195.25484  |
| training/sac_Q/q2_loss         | 113.7505   |
| training/sac_Q/q_global_norm   | 268.09692  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15983917 |
| epoch                          | 151        |
| evaluation/episode-length-avg  | 168        |
| evaluation/episode-length-max  | 182        |
| evaluation/episode-length-min  | 161        |
| evaluation/episode-length-std  | 7.12       |
| evaluation/return-average      | 403.88904  |
| evaluation/return-max          | 440.25726  |
| evaluation/return-min          | 381.0694   |
| evaluation/return-std          | 18.865032  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 86.8       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46018      |
| perf/AverageLength             | 168        |
| perf/AverageReturn             | 403.88904  |
| perf/NormalizedReturn          | 0.0876     |
| Q-avg                          | 201.07181  |
| Q-std                          | 92.23851   |
| Q_loss                         | 97.133385  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 151        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.000115   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000636   |
| times/evaluation_paths         | 6.08       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 72.4       |
| timestep                       | 1000       |
| timesteps_total                | 152000     |
| train-steps                    | 152000     |
| training/Q/q1_loss             | 115.94518  |
| training/sac_pi/alpha          | 0.15986633 |
| training/sac_pi/alpha_loss     | 0.13904643 |
| training/sac_pi/logp_pi        | 4.1700315  |
| training/sac_pi/pi_entropy     | 3.577414   |
| training/sac_pi/pi_global_norm | 1.7129158  |
| training/sac_pi/policy_loss    | -202.71696 |
| training/sac_pi/std            | 0.503213   |
| training/sac_pi/valid_num      | 4996.0     |
| training/sac_Q/q1              | 197.81917  |
| training/sac_Q/q2              | 198.13379  |
| training/sac_Q/q2_loss         | 116.810326 |
| training/sac_Q/q_global_norm   | 235.9052   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16749303 |
| epoch                          | 152        |
| evaluation/episode-length-avg  | 148        |
| evaluation/episode-length-max  | 156        |
| evaluation/episode-length-min  | 139        |
| evaluation/episode-length-std  | 4.99       |
| evaluation/return-average      | 347.97333  |
| evaluation/return-max          | 376.19037  |
| evaluation/return-min          | 314.10553  |
| evaluation/return-std          | 18.930748  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46232      |
| perf/AverageLength             | 148        |
| perf/AverageReturn             | 347.97333  |
| perf/NormalizedReturn          | 0.0754     |
| Q-avg                          | 202.45647  |
| Q-std                          | 93.685036  |
| Q_loss                         | 127.62183  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 152        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000114   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000488   |
| times/evaluation_paths         | 6.88       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 69.3       |
| timestep                       | 1000       |
| timesteps_total                | 153000     |
| train-steps                    | 153000     |
| training/Q/q1_loss             | 105.55183  |
| training/sac_pi/alpha          | 0.16749671 |
| training/sac_pi/alpha_loss     | 0.13911456 |
| training/sac_pi/logp_pi        | 4.765304   |
| training/sac_pi/pi_entropy     | 3.7571945  |
| training/sac_pi/pi_global_norm | 1.473621   |
| training/sac_pi/policy_loss    | -209.09023 |
| training/sac_pi/std            | 0.55951697 |
| training/sac_pi/valid_num      | 4935.0     |
| training/sac_Q/q1              | 199.71898  |
| training/sac_Q/q2              | 201.38327  |
| training/sac_Q/q2_loss         | 105.73713  |
| training/sac_Q/q_global_norm   | 368.4536   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17147066 |
| epoch                          | 153        |
| evaluation/episode-length-avg  | 134        |
| evaluation/episode-length-max  | 151        |
| evaluation/episode-length-min  | 125        |
| evaluation/episode-length-std  | 9.05       |
| evaluation/return-average      | 322.63364  |
| evaluation/return-max          | 367.79913  |
| evaluation/return-min          | 296.11108  |
| evaluation/return-std          | 24.680561  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46213      |
| perf/AverageLength             | 134        |
| perf/AverageReturn             | 322.63364  |
| perf/NormalizedReturn          | 0.0699     |
| Q-avg                          | 188.69002  |
| Q-std                          | 110.66674  |
| Q_loss                         | 111.10379  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 153        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000389   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000487   |
| times/evaluation_paths         | 6.2        |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00898    |
| times/train                    | 69.1       |
| timestep                       | 1000       |
| timesteps_total                | 154000     |
| train-steps                    | 154000     |
| training/Q/q1_loss             | 92.56255   |
| training/sac_pi/alpha          | 0.17141956 |
| training/sac_pi/alpha_loss     | 0.12808284 |
| training/sac_pi/logp_pi        | 4.4490137  |
| training/sac_pi/pi_entropy     | 3.7904334  |
| training/sac_pi/pi_global_norm | 1.4615458  |
| training/sac_pi/policy_loss    | -211.20235 |
| training/sac_pi/std            | 0.53906596 |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 203.03282  |
| training/sac_Q/q2              | 203.89372  |
| training/sac_Q/q2_loss         | 93.493645  |
| training/sac_Q/q_global_norm   | 230.7961   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16736406  |
| epoch                          | 154         |
| evaluation/episode-length-avg  | 138         |
| evaluation/episode-length-max  | 149         |
| evaluation/episode-length-min  | 120         |
| evaluation/episode-length-std  | 10.1        |
| evaluation/return-average      | 310.5366    |
| evaluation/return-max          | 336.26074   |
| evaluation/return-min          | 250.3805    |
| evaluation/return-std          | 31.424402   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46111       |
| perf/AverageLength             | 138         |
| perf/AverageReturn             | 310.5366    |
| perf/NormalizedReturn          | 0.0673      |
| Q-avg                          | 193.1908    |
| Q-std                          | 90.673584   |
| Q_loss                         | 104.011566  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 154         |
| times/epoch_after_hook         | 1.63e-06    |
| times/epoch_before_hook        | 8.36e-05    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000571    |
| times/evaluation_paths         | 6.35        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 62.7        |
| timestep                       | 1000        |
| timesteps_total                | 155000      |
| train-steps                    | 155000      |
| training/Q/q1_loss             | 106.03323   |
| training/sac_pi/alpha          | 0.16734982  |
| training/sac_pi/alpha_loss     | 0.038356766 |
| training/sac_pi/logp_pi        | 4.178295    |
| training/sac_pi/pi_entropy     | 3.598947    |
| training/sac_pi/pi_global_norm | 1.7238173   |
| training/sac_pi/policy_loss    | -203.23772  |
| training/sac_pi/std            | 0.51673764  |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 196.17653   |
| training/sac_Q/q2              | 196.65593   |
| training/sac_Q/q2_loss         | 106.69311   |
| training/sac_Q/q_global_norm   | 334.68597   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16722673  |
| epoch                          | 155         |
| evaluation/episode-length-avg  | 217         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 121         |
| evaluation/episode-length-std  | 261         |
| evaluation/return-average      | 776.73175   |
| evaluation/return-max          | 5057.8887   |
| evaluation/return-min          | 274.82687   |
| evaluation/return-std          | 1427.3137   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46096       |
| perf/AverageLength             | 217         |
| perf/AverageReturn             | 776.73175   |
| perf/NormalizedReturn          | 0.169       |
| Q-avg                          | 197.49059   |
| Q-std                          | 87.666595   |
| Q_loss                         | 104.58229   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 155         |
| times/epoch_after_hook         | 2.91e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000515    |
| times/evaluation_paths         | 7.12        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 62.4        |
| timestep                       | 1000        |
| timesteps_total                | 156000      |
| train-steps                    | 156000      |
| training/Q/q1_loss             | 108.09815   |
| training/sac_pi/alpha          | 0.16726446  |
| training/sac_pi/alpha_loss     | -0.37628785 |
| training/sac_pi/logp_pi        | 4.0787454   |
| training/sac_pi/pi_entropy     | 3.509943    |
| training/sac_pi/pi_global_norm | 1.8106263   |
| training/sac_pi/policy_loss    | -210.36534  |
| training/sac_pi/std            | 0.49862957  |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 201.50252   |
| training/sac_Q/q2              | 202.6503    |
| training/sac_Q/q2_loss         | 108.679886  |
| training/sac_Q/q_global_norm   | 363.4882    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16365281 |
| epoch                          | 156        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4556.3506  |
| evaluation/return-max          | 4685.1963  |
| evaluation/return-min          | 4445.641   |
| evaluation/return-std          | 67.04338   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46239      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4556.3506  |
| perf/NormalizedReturn          | 0.992      |
| Q-avg                          | 193.74976  |
| Q-std                          | 91.979965  |
| Q_loss                         | 97.23248   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 156        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000577   |
| times/evaluation_paths         | 36.2       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00874    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 157000     |
| train-steps                    | 157000     |
| training/Q/q1_loss             | 125.15795  |
| training/sac_pi/alpha          | 0.163649   |
| training/sac_pi/alpha_loss     | 0.27139136 |
| training/sac_pi/logp_pi        | 4.0679526  |
| training/sac_pi/pi_entropy     | 3.4863515  |
| training/sac_pi/pi_global_norm | 1.5634595  |
| training/sac_pi/policy_loss    | -204.29422 |
| training/sac_pi/std            | 0.4853359  |
| training/sac_pi/valid_num      | 5007.0     |
| training/sac_Q/q1              | 199.7307   |
| training/sac_Q/q2              | 200.3168   |
| training/sac_Q/q2_loss         | 124.439285 |
| training/sac_Q/q_global_norm   | 296.1621   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16670392 |
| epoch                          | 157        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4261.241   |
| evaluation/return-max          | 4439.741   |
| evaluation/return-min          | 4089.5557  |
| evaluation/return-std          | 119.02276  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46165      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4261.241   |
| perf/NormalizedReturn          | 0.928      |
| Q-avg                          | 204.87712  |
| Q-std                          | 106.72842  |
| Q_loss                         | 105.98397  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 157        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000385   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000529   |
| times/evaluation_paths         | 38.1       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 158000     |
| train-steps                    | 158000     |
| training/Q/q1_loss             | 98.81091   |
| training/sac_pi/alpha          | 0.16668533 |
| training/sac_pi/alpha_loss     | 0.6503512  |
| training/sac_pi/logp_pi        | 4.6702323  |
| training/sac_pi/pi_entropy     | 3.7091389  |
| training/sac_pi/pi_global_norm | 1.8682635  |
| training/sac_pi/policy_loss    | -205.27788 |
| training/sac_pi/std            | 0.5215321  |
| training/sac_pi/valid_num      | 4961.0     |
| training/sac_Q/q1              | 199.18723  |
| training/sac_Q/q2              | 199.11678  |
| training/sac_Q/q2_loss         | 99.18715   |
| training/sac_Q/q_global_norm   | 325.59152  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16242495 |
| epoch                          | 158        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4795.5005  |
| evaluation/return-max          | 4835.667   |
| evaluation/return-min          | 4672.0156  |
| evaluation/return-std          | 49.744274  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46083      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4795.5005  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 199.8423   |
| Q-std                          | 83.38203   |
| Q_loss                         | 93.086586  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 158        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.00054    |
| times/evaluation_paths         | 40.2       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 159000     |
| train-steps                    | 159000     |
| training/Q/q1_loss             | 109.31584  |
| training/sac_pi/alpha          | 0.16239354 |
| training/sac_pi/alpha_loss     | 0.1386254  |
| training/sac_pi/logp_pi        | 4.360582   |
| training/sac_pi/pi_entropy     | 3.6352081  |
| training/sac_pi/pi_global_norm | 1.5603116  |
| training/sac_pi/policy_loss    | -210.03375 |
| training/sac_pi/std            | 0.5189361  |
| training/sac_pi/valid_num      | 4995.0     |
| training/sac_Q/q1              | 205.09721  |
| training/sac_Q/q2              | 205.97177  |
| training/sac_Q/q2_loss         | 109.40886  |
| training/sac_Q/q_global_norm   | 318.20575  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16158676 |
| epoch                          | 159        |
| evaluation/episode-length-avg  | 198        |
| evaluation/episode-length-max  | 209        |
| evaluation/episode-length-min  | 189        |
| evaluation/episode-length-std  | 5.29       |
| evaluation/return-average      | 435.329    |
| evaluation/return-max          | 453.27728  |
| evaluation/return-min          | 427.40555  |
| evaluation/return-std          | 7.416132   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46228      |
| perf/AverageLength             | 198        |
| perf/AverageReturn             | 435.329    |
| perf/NormalizedReturn          | 0.0945     |
| Q-avg                          | 194.1718   |
| Q-std                          | 92.71359   |
| Q_loss                         | 98.88692   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 159        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000536   |
| times/evaluation_paths         | 6.6        |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 160000     |
| train-steps                    | 160000     |
| training/Q/q1_loss             | 102.87711  |
| training/sac_pi/alpha          | 0.1615628  |
| training/sac_pi/alpha_loss     | 0.3046578  |
| training/sac_pi/logp_pi        | 4.1579437  |
| training/sac_pi/pi_entropy     | 3.6470566  |
| training/sac_pi/pi_global_norm | 1.4667127  |
| training/sac_pi/policy_loss    | -199.11415 |
| training/sac_pi/std            | 0.5061029  |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 193.52742  |
| training/sac_Q/q2              | 192.78532  |
| training/sac_Q/q2_loss         | 103.66826  |
| training/sac_Q/q_global_norm   | 310.8931   |
--------------------------------------------------------------------------------
[WARN] 160 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.1594246  |
| epoch                          | 160        |
| evaluation/episode-length-avg  | 160        |
| evaluation/episode-length-max  | 168        |
| evaluation/episode-length-min  | 154        |
| evaluation/episode-length-std  | 4.48       |
| evaluation/return-average      | 508.26596  |
| evaluation/return-max          | 534.82385  |
| evaluation/return-min          | 484.88068  |
| evaluation/return-std          | 14.593402  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 82         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46172      |
| perf/AverageLength             | 160        |
| perf/AverageReturn             | 508.26596  |
| perf/NormalizedReturn          | 0.11       |
| Q-avg                          | 196.13863  |
| Q-std                          | 103.257095 |
| Q_loss                         | 86.250916  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 160        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000118   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 5.39       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 161000     |
| train-steps                    | 161000     |
| training/Q/q1_loss             | 82.57076   |
| training/sac_pi/alpha          | 0.1594078  |
| training/sac_pi/alpha_loss     | 0.10924242 |
| training/sac_pi/logp_pi        | 4.001836   |
| training/sac_pi/pi_entropy     | 3.3652892  |
| training/sac_pi/pi_global_norm | 1.5421133  |
| training/sac_pi/policy_loss    | -208.02736 |
| training/sac_pi/std            | 0.47635487 |
| training/sac_pi/valid_num      | 4992.0     |
| training/sac_Q/q1              | 201.73746  |
| training/sac_Q/q2              | 202.84843  |
| training/sac_Q/q2_loss         | 83.49029   |
| training/sac_Q/q_global_norm   | 196.77298  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16247244 |
| epoch                          | 161        |
| evaluation/episode-length-avg  | 129        |
| evaluation/episode-length-max  | 131        |
| evaluation/episode-length-min  | 124        |
| evaluation/episode-length-std  | 2          |
| evaluation/return-average      | 288.25003  |
| evaluation/return-max          | 295.6274   |
| evaluation/return-min          | 269.54858  |
| evaluation/return-std          | 7.4341993  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.99       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46096      |
| perf/AverageLength             | 129        |
| perf/AverageReturn             | 288.25003  |
| perf/NormalizedReturn          | 0.0624     |
| Q-avg                          | 203.2402   |
| Q-std                          | 88.08214   |
| Q_loss                         | 94.178825  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 161        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.000272   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.0005     |
| times/evaluation_paths         | 4.37       |
| times/timestep_after_hook      | 0.00354    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 162000     |
| train-steps                    | 162000     |
| training/Q/q1_loss             | 87.62233   |
| training/sac_pi/alpha          | 0.16246836 |
| training/sac_pi/alpha_loss     | 0.06935669 |
| training/sac_pi/logp_pi        | 5.0631576  |
| training/sac_pi/pi_entropy     | 3.7102685  |
| training/sac_pi/pi_global_norm | 1.5863875  |
| training/sac_pi/policy_loss    | -198.80087 |
| training/sac_pi/std            | 0.5475197  |
| training/sac_pi/valid_num      | 4894.0     |
| training/sac_Q/q1              | 188.39731  |
| training/sac_Q/q2              | 188.94429  |
| training/sac_Q/q2_loss         | 86.20314   |
| training/sac_Q/q_global_norm   | 452.58463  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16300459  |
| epoch                          | 162         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4747.792    |
| evaluation/return-max          | 4803.5776   |
| evaluation/return-min          | 4709.466    |
| evaluation/return-std          | 24.83697    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46305       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4747.792    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 194.98657   |
| Q-std                          | 97.20407    |
| Q_loss                         | 90.90022    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 162         |
| times/epoch_after_hook         | 2.74e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000802    |
| times/evaluation_paths         | 34.9        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00847     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 163000      |
| train-steps                    | 163000      |
| training/Q/q1_loss             | 102.525024  |
| training/sac_pi/alpha          | 0.16302988  |
| training/sac_pi/alpha_loss     | -0.42687574 |
| training/sac_pi/logp_pi        | 4.232635    |
| training/sac_pi/pi_entropy     | 3.559597    |
| training/sac_pi/pi_global_norm | 1.7395087   |
| training/sac_pi/policy_loss    | -207.61513  |
| training/sac_pi/std            | 0.5141655   |
| training/sac_pi/valid_num      | 4962.0      |
| training/sac_Q/q1              | 198.26097   |
| training/sac_Q/q2              | 198.23581   |
| training/sac_Q/q2_loss         | 102.61556   |
| training/sac_Q/q_global_norm   | 224.06137   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17720585  |
| epoch                          | 163         |
| evaluation/episode-length-avg  | 663         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 144         |
| evaluation/episode-length-std  | 413         |
| evaluation/return-average      | 3169.4988   |
| evaluation/return-max          | 5083.254    |
| evaluation/return-min          | 349.34207   |
| evaluation/return-std          | 2264.828    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46233       |
| perf/AverageLength             | 663         |
| perf/AverageReturn             | 3169.4988   |
| perf/NormalizedReturn          | 0.69        |
| Q-avg                          | 203.36006   |
| Q-std                          | 90.021805   |
| Q_loss                         | 97.203026   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 163         |
| times/epoch_after_hook         | 2.2e-06     |
| times/epoch_before_hook        | 0.000162    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000842    |
| times/evaluation_paths         | 23.7        |
| times/timestep_after_hook      | 0.00397     |
| times/timestep_before_hook     | 0.00847     |
| times/train                    | 60.2        |
| timestep                       | 1000        |
| timesteps_total                | 164000      |
| train-steps                    | 164000      |
| training/Q/q1_loss             | 114.82407   |
| training/sac_pi/alpha          | 0.1772413   |
| training/sac_pi/alpha_loss     | 0.005860613 |
| training/sac_pi/logp_pi        | 3.9576836   |
| training/sac_pi/pi_entropy     | 3.6849952   |
| training/sac_pi/pi_global_norm | 1.780544    |
| training/sac_pi/policy_loss    | -204.71678  |
| training/sac_pi/std            | 0.50526303  |
| training/sac_pi/valid_num      | 4978.0      |
| training/sac_Q/q1              | 198.45576   |
| training/sac_Q/q2              | 198.98372   |
| training/sac_Q/q2_loss         | 114.1334    |
| training/sac_Q/q_global_norm   | 376.4825    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16903155  |
| epoch                          | 164         |
| evaluation/episode-length-avg  | 577         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 149         |
| evaluation/episode-length-std  | 423         |
| evaluation/return-average      | 2523.3003   |
| evaluation/return-max          | 4702.0693   |
| evaluation/return-min          | 373.80704   |
| evaluation/return-std          | 2130.839    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46116       |
| perf/AverageLength             | 577         |
| perf/AverageReturn             | 2523.3003   |
| perf/NormalizedReturn          | 0.549       |
| Q-avg                          | 189.71547   |
| Q-std                          | 97.45264    |
| Q_loss                         | 109.81148   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 164         |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000184    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000615    |
| times/evaluation_paths         | 20.5        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00838     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 165000      |
| train-steps                    | 165000      |
| training/Q/q1_loss             | 79.337234   |
| training/sac_pi/alpha          | 0.1690452   |
| training/sac_pi/alpha_loss     | -0.22663511 |
| training/sac_pi/logp_pi        | 3.6540947   |
| training/sac_pi/pi_entropy     | 3.856406    |
| training/sac_pi/pi_global_norm | 1.5945262   |
| training/sac_pi/policy_loss    | -204.11606  |
| training/sac_pi/std            | 0.5212355   |
| training/sac_pi/valid_num      | 5005.0      |
| training/sac_Q/q1              | 198.29521   |
| training/sac_Q/q2              | 198.59097   |
| training/sac_Q/q2_loss         | 79.44271    |
| training/sac_Q/q_global_norm   | 264.2947    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16465081  |
| epoch                          | 165         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4920.5283   |
| evaluation/return-max          | 4986.8027   |
| evaluation/return-min          | 4810.9014   |
| evaluation/return-std          | 49.681206   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46063       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4920.5283   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 202.18694   |
| Q-std                          | 92.57628    |
| Q_loss                         | 89.887764   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 165         |
| times/epoch_after_hook         | 1.66e-06    |
| times/epoch_before_hook        | 0.000473    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000582    |
| times/evaluation_paths         | 34.1        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00846     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 166000      |
| train-steps                    | 166000      |
| training/Q/q1_loss             | 90.345894   |
| training/sac_pi/alpha          | 0.1646404   |
| training/sac_pi/alpha_loss     | -0.07218926 |
| training/sac_pi/logp_pi        | 3.9600334   |
| training/sac_pi/pi_entropy     | 3.6812909   |
| training/sac_pi/pi_global_norm | 1.66621     |
| training/sac_pi/policy_loss    | -213.74504  |
| training/sac_pi/std            | 0.5118338   |
| training/sac_pi/valid_num      | 5012.0      |
| training/sac_Q/q1              | 209.79951   |
| training/sac_Q/q2              | 209.94351   |
| training/sac_Q/q2_loss         | 89.818924   |
| training/sac_Q/q_global_norm   | 286.59015   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16534892   |
| epoch                          | 166          |
| evaluation/episode-length-avg  | 141          |
| evaluation/episode-length-max  | 145          |
| evaluation/episode-length-min  | 138          |
| evaluation/episode-length-std  | 2            |
| evaluation/return-average      | 361.08002    |
| evaluation/return-max          | 376.19       |
| evaluation/return-min          | 350.6048     |
| evaluation/return-std          | 7.2972097    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.02         |
| model/origin_ret               | 85.2         |
| model/penalty_ret              | 80.9         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46251        |
| perf/AverageLength             | 141          |
| perf/AverageReturn             | 361.08002    |
| perf/NormalizedReturn          | 0.0783       |
| Q-avg                          | 202.40475    |
| Q-std                          | 94.74744     |
| Q_loss                         | 88.207664    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 166          |
| times/epoch_after_hook         | 1.86e-06     |
| times/epoch_before_hook        | 0.000185     |
| times/epoch_rollout_model      | 491          |
| times/evaluation_metrics       | 0.000747     |
| times/evaluation_paths         | 4.93         |
| times/timestep_after_hook      | 0.00369      |
| times/timestep_before_hook     | 0.00867      |
| times/train                    | 61.2         |
| timestep                       | 1000         |
| timesteps_total                | 167000       |
| train-steps                    | 167000       |
| training/Q/q1_loss             | 88.0503      |
| training/sac_pi/alpha          | 0.16531135   |
| training/sac_pi/alpha_loss     | -0.054827377 |
| training/sac_pi/logp_pi        | 3.9943824    |
| training/sac_pi/pi_entropy     | 3.7374508    |
| training/sac_pi/pi_global_norm | 1.4812641    |
| training/sac_pi/policy_loss    | -208.74791   |
| training/sac_pi/std            | 0.53418326   |
| training/sac_pi/valid_num      | 4931.0       |
| training/sac_Q/q1              | 200.16019    |
| training/sac_Q/q2              | 200.38063    |
| training/sac_Q/q2_loss         | 88.85743     |
| training/sac_Q/q_global_norm   | 269.91937    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16165967 |
| epoch                          | 167        |
| evaluation/episode-length-avg  | 117        |
| evaluation/episode-length-max  | 120        |
| evaluation/episode-length-min  | 116        |
| evaluation/episode-length-std  | 1.19       |
| evaluation/return-average      | 229.91837  |
| evaluation/return-max          | 241.2915   |
| evaluation/return-min          | 221.55084  |
| evaluation/return-std          | 5.322163   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46342      |
| perf/AverageLength             | 117        |
| perf/AverageReturn             | 229.91837  |
| perf/NormalizedReturn          | 0.0497     |
| Q-avg                          | 197.04721  |
| Q-std                          | 99.38461   |
| Q_loss                         | 108.39358  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 167        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000141   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.00047    |
| times/evaluation_paths         | 5.63       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 168000     |
| train-steps                    | 168000     |
| training/Q/q1_loss             | 93.53613   |
| training/sac_pi/alpha          | 0.16170232 |
| training/sac_pi/alpha_loss     | -0.3031665 |
| training/sac_pi/logp_pi        | 3.702745   |
| training/sac_pi/pi_entropy     | 3.5496635  |
| training/sac_pi/pi_global_norm | 1.1734065  |
| training/sac_pi/policy_loss    | -210.3096  |
| training/sac_pi/std            | 0.50120354 |
| training/sac_pi/valid_num      | 5033.0     |
| training/sac_Q/q1              | 207.51216  |
| training/sac_Q/q2              | 207.14082  |
| training/sac_Q/q2_loss         | 93.34718   |
| training/sac_Q/q_global_norm   | 334.2934   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15785122 |
| epoch                          | 168        |
| evaluation/episode-length-avg  | 165        |
| evaluation/episode-length-max  | 167        |
| evaluation/episode-length-min  | 163        |
| evaluation/episode-length-std  | 1.26       |
| evaluation/return-average      | 474.46973  |
| evaluation/return-max          | 479.63052  |
| evaluation/return-min          | 468.9664   |
| evaluation/return-std          | 3.329559   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84         |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46241      |
| perf/AverageLength             | 165        |
| perf/AverageReturn             | 474.46973  |
| perf/NormalizedReturn          | 0.103      |
| Q-avg                          | 209.30293  |
| Q-std                          | 87.87978   |
| Q_loss                         | 81.919945  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 168        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000109   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000428   |
| times/evaluation_paths         | 6.29       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00844    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 169000     |
| train-steps                    | 169000     |
| training/Q/q1_loss             | 91.37415   |
| training/sac_pi/alpha          | 0.15785284 |
| training/sac_pi/alpha_loss     | 0.26025626 |
| training/sac_pi/logp_pi        | 4.032102   |
| training/sac_pi/pi_entropy     | 3.4178512  |
| training/sac_pi/pi_global_norm | 1.6525645  |
| training/sac_pi/policy_loss    | -204.82979 |
| training/sac_pi/std            | 0.49268845 |
| training/sac_pi/valid_num      | 5004.0     |
| training/sac_Q/q1              | 199.75937  |
| training/sac_Q/q2              | 200.65413  |
| training/sac_Q/q2_loss         | 90.75709   |
| training/sac_Q/q_global_norm   | 240.07376  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1581009   |
| epoch                          | 169         |
| evaluation/episode-length-avg  | 834         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 164         |
| evaluation/episode-length-std  | 333         |
| evaluation/return-average      | 4109.595    |
| evaluation/return-max          | 5102.2393   |
| evaluation/return-min          | 486.90778   |
| evaluation/return-std          | 1804.9774   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 83.8        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46215       |
| perf/AverageLength             | 834         |
| perf/AverageReturn             | 4109.595    |
| perf/NormalizedReturn          | 0.895       |
| Q-avg                          | 190.24336   |
| Q-std                          | 96.875374   |
| Q_loss                         | 93.78818    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 169         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000272    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000594    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00838     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 170000      |
| train-steps                    | 170000      |
| training/Q/q1_loss             | 106.2502    |
| training/sac_pi/alpha          | 0.15808329  |
| training/sac_pi/alpha_loss     | 0.043680206 |
| training/sac_pi/logp_pi        | 4.460609    |
| training/sac_pi/pi_entropy     | 3.6459155   |
| training/sac_pi/pi_global_norm | 1.4983593   |
| training/sac_pi/policy_loss    | -206.31447  |
| training/sac_pi/std            | 0.54018265  |
| training/sac_pi/valid_num      | 4953.0      |
| training/sac_Q/q1              | 196.23738   |
| training/sac_Q/q2              | 196.14288   |
| training/sac_Q/q2_loss         | 106.19068   |
| training/sac_Q/q_global_norm   | 481.5869    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16679189  |
| epoch                          | 170         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4970.3      |
| evaluation/return-max          | 5019.3887   |
| evaluation/return-min          | 4897.614    |
| evaluation/return-std          | 31.92715    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 83.6        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46115       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4970.3      |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 201.69504   |
| Q-std                          | 101.81073   |
| Q_loss                         | 108.66426   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 170         |
| times/epoch_after_hook         | 9.76e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.00179     |
| times/evaluation_paths         | 36.1        |
| times/timestep_after_hook      | 0.00373     |
| times/timestep_before_hook     | 0.00839     |
| times/train                    | 59.5        |
| timestep                       | 1000        |
| timesteps_total                | 171000      |
| train-steps                    | 171000      |
| training/Q/q1_loss             | 82.284096   |
| training/sac_pi/alpha          | 0.16680494  |
| training/sac_pi/alpha_loss     | -0.33272412 |
| training/sac_pi/logp_pi        | 4.586409    |
| training/sac_pi/pi_entropy     | 3.882855    |
| training/sac_pi/pi_global_norm | 1.3865547   |
| training/sac_pi/policy_loss    | -201.83762  |
| training/sac_pi/std            | 0.56248957  |
| training/sac_pi/valid_num      | 4933.0      |
| training/sac_Q/q1              | 191.36389   |
| training/sac_Q/q2              | 191.29568   |
| training/sac_Q/q2_loss         | 83.33132    |
| training/sac_Q/q_global_norm   | 275.64795   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17001294 |
| epoch                          | 171        |
| evaluation/episode-length-avg  | 233        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 121        |
| evaluation/episode-length-std  | 256        |
| evaluation/return-average      | 795.65485  |
| evaluation/return-max          | 4822.1313  |
| evaluation/return-min          | 250.4583   |
| evaluation/return-std          | 1342.8513  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 81.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46235      |
| perf/AverageLength             | 233        |
| perf/AverageReturn             | 795.65485  |
| perf/NormalizedReturn          | 0.173      |
| Q-avg                          | 201.90466  |
| Q-std                          | 94.241356  |
| Q_loss                         | 99.714745  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 171        |
| times/epoch_after_hook         | 3.21e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000545   |
| times/evaluation_paths         | 9.37       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 172000     |
| train-steps                    | 172000     |
| training/Q/q1_loss             | 88.16966   |
| training/sac_pi/alpha          | 0.16999213 |
| training/sac_pi/alpha_loss     | -0.3092634 |
| training/sac_pi/logp_pi        | 3.9268565  |
| training/sac_pi/pi_entropy     | 3.5814195  |
| training/sac_pi/pi_global_norm | 1.5369008  |
| training/sac_pi/policy_loss    | -219.20528 |
| training/sac_pi/std            | 0.5055585  |
| training/sac_pi/valid_num      | 4987.0     |
| training/sac_Q/q1              | 213.26286  |
| training/sac_Q/q2              | 213.627    |
| training/sac_Q/q2_loss         | 88.016205  |
| training/sac_Q/q_global_norm   | 230.94505  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.165751   |
| epoch                          | 172        |
| evaluation/episode-length-avg  | 129        |
| evaluation/episode-length-max  | 141        |
| evaluation/episode-length-min  | 120        |
| evaluation/episode-length-std  | 6.54       |
| evaluation/return-average      | 280.1512   |
| evaluation/return-max          | 323.22272  |
| evaluation/return-min          | 242.98212  |
| evaluation/return-std          | 25.582207  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 85         |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46226      |
| perf/AverageLength             | 129        |
| perf/AverageReturn             | 280.1512   |
| perf/NormalizedReturn          | 0.0607     |
| Q-avg                          | 194.86356  |
| Q-std                          | 103.49673  |
| Q_loss                         | 99.82627   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 172        |
| times/epoch_after_hook         | 1.6e-06    |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.00082    |
| times/evaluation_paths         | 4.88       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 173000     |
| train-steps                    | 173000     |
| training/Q/q1_loss             | 106.80133  |
| training/sac_pi/alpha          | 0.16572465 |
| training/sac_pi/alpha_loss     | 0.23621203 |
| training/sac_pi/logp_pi        | 5.0559473  |
| training/sac_pi/pi_entropy     | 3.6246254  |
| training/sac_pi/pi_global_norm | 1.5643599  |
| training/sac_pi/policy_loss    | -208.69797 |
| training/sac_pi/std            | 0.5514291  |
| training/sac_pi/valid_num      | 4959.0     |
| training/sac_Q/q1              | 200.7673   |
| training/sac_Q/q2              | 201.07848  |
| training/sac_Q/q2_loss         | 107.37796  |
| training/sac_Q/q_global_norm   | 230.9183   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16506398  |
| epoch                          | 173         |
| evaluation/episode-length-avg  | 664         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 148         |
| evaluation/episode-length-std  | 412         |
| evaluation/return-average      | 3137.9263   |
| evaluation/return-max          | 5016.2207   |
| evaluation/return-min          | 398.06012   |
| evaluation/return-std          | 2199.0889   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46195       |
| perf/AverageLength             | 664         |
| perf/AverageReturn             | 3137.9263   |
| perf/NormalizedReturn          | 0.683       |
| Q-avg                          | 214.20444   |
| Q-std                          | 81.91909    |
| Q_loss                         | 89.992645   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 173         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000273    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000595    |
| times/evaluation_paths         | 23.3        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 60.1        |
| timestep                       | 1000        |
| timesteps_total                | 174000      |
| train-steps                    | 174000      |
| training/Q/q1_loss             | 98.65418    |
| training/sac_pi/alpha          | 0.16504002  |
| training/sac_pi/alpha_loss     | -0.03789318 |
| training/sac_pi/logp_pi        | 4.2461386   |
| training/sac_pi/pi_entropy     | 3.7486854   |
| training/sac_pi/pi_global_norm | 1.4587337   |
| training/sac_pi/policy_loss    | -214.83578  |
| training/sac_pi/std            | 0.53012365  |
| training/sac_pi/valid_num      | 4967.0      |
| training/sac_Q/q1              | 207.42636   |
| training/sac_Q/q2              | 207.18222   |
| training/sac_Q/q2_loss         | 97.827446   |
| training/sac_Q/q_global_norm   | 254.20354   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1656113  |
| epoch                          | 174        |
| evaluation/episode-length-avg  | 420        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 164        |
| evaluation/episode-length-std  | 380        |
| evaluation/return-average      | 1724.5576  |
| evaluation/return-max          | 4552.787   |
| evaluation/return-min          | 509.06152  |
| evaluation/return-std          | 1828.0181  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46303      |
| perf/AverageLength             | 420        |
| perf/AverageReturn             | 1724.5576  |
| perf/NormalizedReturn          | 0.375      |
| Q-avg                          | 204.91035  |
| Q-std                          | 99.181465  |
| Q_loss                         | 85.8053    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 174        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000275   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000566   |
| times/evaluation_paths         | 14.4       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00851    |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 175000     |
| train-steps                    | 175000     |
| training/Q/q1_loss             | 115.640625 |
| training/sac_pi/alpha          | 0.1656127  |
| training/sac_pi/alpha_loss     | 0.09783971 |
| training/sac_pi/logp_pi        | 4.266385   |
| training/sac_pi/pi_entropy     | 3.7732131  |
| training/sac_pi/pi_global_norm | 1.5764753  |
| training/sac_pi/policy_loss    | -208.03824 |
| training/sac_pi/std            | 0.53910506 |
| training/sac_pi/valid_num      | 4919.0     |
| training/sac_Q/q1              | 198.48763  |
| training/sac_Q/q2              | 199.95776  |
| training/sac_Q/q2_loss         | 115.86364  |
| training/sac_Q/q_global_norm   | 380.98642  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.163262    |
| epoch                          | 175         |
| evaluation/episode-length-avg  | 994         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 937         |
| evaluation/episode-length-std  | 18.9        |
| evaluation/return-average      | 4680.867    |
| evaluation/return-max          | 4933.448    |
| evaluation/return-min          | 4169.7783   |
| evaluation/return-std          | 219.92441   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46270       |
| perf/AverageLength             | 994         |
| perf/AverageReturn             | 4680.867    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 194.14853   |
| Q-std                          | 103.1251    |
| Q_loss                         | 112.53989   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 175         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000641    |
| times/evaluation_paths         | 34.6        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 176000      |
| train-steps                    | 176000      |
| training/Q/q1_loss             | 110.564896  |
| training/sac_pi/alpha          | 0.16329531  |
| training/sac_pi/alpha_loss     | -0.16129257 |
| training/sac_pi/logp_pi        | 4.452596    |
| training/sac_pi/pi_entropy     | 3.5316627   |
| training/sac_pi/pi_global_norm | 1.3046113   |
| training/sac_pi/policy_loss    | -201.52075  |
| training/sac_pi/std            | 0.5055101   |
| training/sac_pi/valid_num      | 4935.0      |
| training/sac_Q/q1              | 193.68932   |
| training/sac_Q/q2              | 194.27261   |
| training/sac_Q/q2_loss         | 109.84493   |
| training/sac_Q/q_global_norm   | 236.1045    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16704832  |
| epoch                          | 176         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4985.6953   |
| evaluation/return-max          | 5063.882    |
| evaluation/return-min          | 4892.88     |
| evaluation/return-std          | 55.284042   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46100       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4985.6953   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 205.8558    |
| Q-std                          | 91.96476    |
| Q_loss                         | 91.36163    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 176         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.00056     |
| times/evaluation_paths         | 34.6        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00822     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 177000      |
| train-steps                    | 177000      |
| training/Q/q1_loss             | 102.29312   |
| training/sac_pi/alpha          | 0.16706154  |
| training/sac_pi/alpha_loss     | -0.14876588 |
| training/sac_pi/logp_pi        | 3.674377    |
| training/sac_pi/pi_entropy     | 3.4866319   |
| training/sac_pi/pi_global_norm | 1.7423996   |
| training/sac_pi/policy_loss    | -217.89809  |
| training/sac_pi/std            | 0.4717822   |
| training/sac_pi/valid_num      | 5031.0      |
| training/sac_Q/q1              | 214.49231   |
| training/sac_Q/q2              | 214.47115   |
| training/sac_Q/q2_loss         | 101.33016   |
| training/sac_Q/q_global_norm   | 294.03757   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1698099  |
| epoch                          | 177        |
| evaluation/episode-length-avg  | 989        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 935        |
| evaluation/episode-length-std  | 22         |
| evaluation/return-average      | 4800.8115  |
| evaluation/return-max          | 4913.943   |
| evaluation/return-min          | 4526.7134  |
| evaluation/return-std          | 115.54736  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46014      |
| perf/AverageLength             | 989        |
| perf/AverageReturn             | 4800.8115  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 213.88516  |
| Q-std                          | 86.77056   |
| Q_loss                         | 84.11043   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 177        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000675   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000509   |
| times/evaluation_paths         | 35.8       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00883    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 178000     |
| train-steps                    | 178000     |
| training/Q/q1_loss             | 100.24455  |
| training/sac_pi/alpha          | 0.16983879 |
| training/sac_pi/alpha_loss     | 0.21533242 |
| training/sac_pi/logp_pi        | 4.6321883  |
| training/sac_pi/pi_entropy     | 3.7641556  |
| training/sac_pi/pi_global_norm | 1.404509   |
| training/sac_pi/policy_loss    | -208.49837 |
| training/sac_pi/std            | 0.5436133  |
| training/sac_pi/valid_num      | 4971.0     |
| training/sac_Q/q1              | 199.30664  |
| training/sac_Q/q2              | 199.22018  |
| training/sac_Q/q2_loss         | 99.30251   |
| training/sac_Q/q_global_norm   | 352.2165   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1657811  |
| epoch                          | 178        |
| evaluation/episode-length-avg  | 432        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 131        |
| evaluation/episode-length-std  | 389        |
| evaluation/return-average      | 1830.699   |
| evaluation/return-max          | 4831.326   |
| evaluation/return-min          | 324.9726   |
| evaluation/return-std          | 1976.2263  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 87.3       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 45959      |
| perf/AverageLength             | 432        |
| perf/AverageReturn             | 1830.699   |
| perf/NormalizedReturn          | 0.398      |
| Q-avg                          | 200.06422  |
| Q-std                          | 99.58687   |
| Q_loss                         | 97.91632   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 178        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000506   |
| times/evaluation_paths         | 14.5       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 179000     |
| train-steps                    | 179000     |
| training/Q/q1_loss             | 102.85402  |
| training/sac_pi/alpha          | 0.16573098 |
| training/sac_pi/alpha_loss     | 0.15414095 |
| training/sac_pi/logp_pi        | 3.5356038  |
| training/sac_pi/pi_entropy     | 3.6610382  |
| training/sac_pi/pi_global_norm | 1.5997394  |
| training/sac_pi/policy_loss    | -210.06943 |
| training/sac_pi/std            | 0.48242277 |
| training/sac_pi/valid_num      | 5029.0     |
| training/sac_Q/q1              | 206.99394  |
| training/sac_Q/q2              | 206.91977  |
| training/sac_Q/q2_loss         | 102.8126   |
| training/sac_Q/q_global_norm   | 258.2824   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1680573   |
| epoch                          | 179         |
| evaluation/episode-length-avg  | 144         |
| evaluation/episode-length-max  | 149         |
| evaluation/episode-length-min  | 142         |
| evaluation/episode-length-std  | 1.94        |
| evaluation/return-average      | 340.55872   |
| evaluation/return-max          | 353.53265   |
| evaluation/return-min          | 331.08026   |
| evaluation/return-std          | 5.931791    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46181       |
| perf/AverageLength             | 144         |
| perf/AverageReturn             | 340.55872   |
| perf/NormalizedReturn          | 0.0738      |
| Q-avg                          | 198.45755   |
| Q-std                          | 103.0375    |
| Q_loss                         | 85.97265    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 179         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000724    |
| times/evaluation_paths         | 4.9         |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00886     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 180000      |
| train-steps                    | 180000      |
| training/Q/q1_loss             | 91.91137    |
| training/sac_pi/alpha          | 0.16805916  |
| training/sac_pi/alpha_loss     | 0.013635973 |
| training/sac_pi/logp_pi        | 4.2779245   |
| training/sac_pi/pi_entropy     | 3.7081637   |
| training/sac_pi/pi_global_norm | 1.8451345   |
| training/sac_pi/policy_loss    | -209.58752  |
| training/sac_pi/std            | 0.52628326  |
| training/sac_pi/valid_num      | 4937.0      |
| training/sac_Q/q1              | 201.45361   |
| training/sac_Q/q2              | 200.49303   |
| training/sac_Q/q2_loss         | 92.07865    |
| training/sac_Q/q_global_norm   | 238.2438    |
---------------------------------------------------------------------------------
[WARN] 180 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.1677014  |
| epoch                          | 180        |
| evaluation/episode-length-avg  | 150        |
| evaluation/episode-length-max  | 152        |
| evaluation/episode-length-min  | 147        |
| evaluation/episode-length-std  | 1.43       |
| evaluation/return-average      | 309.10718  |
| evaluation/return-max          | 320.10635  |
| evaluation/return-min          | 298.39185  |
| evaluation/return-std          | 6.033019   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46132      |
| perf/AverageLength             | 150        |
| perf/AverageReturn             | 309.10718  |
| perf/NormalizedReturn          | 0.067      |
| Q-avg                          | 191.01016  |
| Q-std                          | 110.78433  |
| Q_loss                         | 96.97853   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 180        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000437   |
| times/evaluation_paths         | 5.1        |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 181000     |
| train-steps                    | 181000     |
| training/Q/q1_loss             | 97.74509   |
| training/sac_pi/alpha          | 0.16763543 |
| training/sac_pi/alpha_loss     | 0.9117755  |
| training/sac_pi/logp_pi        | 4.7112627  |
| training/sac_pi/pi_entropy     | 3.5539021  |
| training/sac_pi/pi_global_norm | 2.020913   |
| training/sac_pi/policy_loss    | -201.05148 |
| training/sac_pi/std            | 0.519107   |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 193.59502  |
| training/sac_Q/q2              | 193.73552  |
| training/sac_Q/q2_loss         | 98.58579   |
| training/sac_Q/q_global_norm   | 265.43228  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16579504  |
| epoch                          | 181         |
| evaluation/episode-length-avg  | 942         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 425         |
| evaluation/episode-length-std  | 172         |
| evaluation/return-average      | 4919.15     |
| evaluation/return-max          | 5304.8027   |
| evaluation/return-min          | 1818.2401   |
| evaluation/return-std          | 1033.7983   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46251       |
| perf/AverageLength             | 942         |
| perf/AverageReturn             | 4919.15     |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 197.50894   |
| Q-std                          | 105.43418   |
| Q_loss                         | 127.27077   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 181         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000272    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000547    |
| times/evaluation_paths         | 32.6        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 182000      |
| train-steps                    | 182000      |
| training/Q/q1_loss             | 102.49979   |
| training/sac_pi/alpha          | 0.16579512  |
| training/sac_pi/alpha_loss     | -0.40602857 |
| training/sac_pi/logp_pi        | 4.082359    |
| training/sac_pi/pi_entropy     | 3.5803196   |
| training/sac_pi/pi_global_norm | 1.579927    |
| training/sac_pi/policy_loss    | -216.00394  |
| training/sac_pi/std            | 0.5266432   |
| training/sac_pi/valid_num      | 4956.0      |
| training/sac_Q/q1              | 207.51694   |
| training/sac_Q/q2              | 208.06723   |
| training/sac_Q/q2_loss         | 102.70931   |
| training/sac_Q/q_global_norm   | 321.84314   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1656956   |
| epoch                          | 182         |
| evaluation/episode-length-avg  | 147         |
| evaluation/episode-length-max  | 150         |
| evaluation/episode-length-min  | 145         |
| evaluation/episode-length-std  | 1.72        |
| evaluation/return-average      | 431.75543   |
| evaluation/return-max          | 446.02258   |
| evaluation/return-min          | 419.37604   |
| evaluation/return-std          | 8.19074     |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46133       |
| perf/AverageLength             | 147         |
| perf/AverageReturn             | 431.75543   |
| perf/NormalizedReturn          | 0.0937      |
| Q-avg                          | 202.4878    |
| Q-std                          | 101.30984   |
| Q_loss                         | 83.82149    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 182         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000468    |
| times/evaluation_paths         | 4.87        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 183000      |
| train-steps                    | 183000      |
| training/Q/q1_loss             | 99.356834   |
| training/sac_pi/alpha          | 0.16566992  |
| training/sac_pi/alpha_loss     | 0.012313775 |
| training/sac_pi/logp_pi        | 4.1722293   |
| training/sac_pi/pi_entropy     | 3.5776794   |
| training/sac_pi/pi_global_norm | 1.8970441   |
| training/sac_pi/policy_loss    | -204.40703  |
| training/sac_pi/std            | 0.50511783  |
| training/sac_pi/valid_num      | 4930.0      |
| training/sac_Q/q1              | 194.68594   |
| training/sac_Q/q2              | 193.97768   |
| training/sac_Q/q2_loss         | 98.93002    |
| training/sac_Q/q_global_norm   | 297.45572   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16931958 |
| epoch                          | 183        |
| evaluation/episode-length-avg  | 990        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 900        |
| evaluation/episode-length-std  | 30         |
| evaluation/return-average      | 5110.5537  |
| evaluation/return-max          | 5232.711   |
| evaluation/return-min          | 4632.872   |
| evaluation/return-std          | 167.31396  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46154      |
| perf/AverageLength             | 990        |
| perf/AverageReturn             | 5110.5537  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 199.349    |
| Q-std                          | 97.02697   |
| Q_loss                         | 93.57158   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 183        |
| times/epoch_after_hook         | 1.62e-06   |
| times/epoch_before_hook        | 8.14e-05   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000545   |
| times/evaluation_paths         | 34.1       |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.00842    |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 184000     |
| train-steps                    | 184000     |
| training/Q/q1_loss             | 109.961586 |
| training/sac_pi/alpha          | 0.16927432 |
| training/sac_pi/alpha_loss     | 0.1341356  |
| training/sac_pi/logp_pi        | 4.8439384  |
| training/sac_pi/pi_entropy     | 3.752718   |
| training/sac_pi/pi_global_norm | 1.7000086  |
| training/sac_pi/policy_loss    | -207.84288 |
| training/sac_pi/std            | 0.5597285  |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 198.33511  |
| training/sac_Q/q2              | 199.11812  |
| training/sac_Q/q2_loss         | 109.84311  |
| training/sac_Q/q_global_norm   | 325.6722   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16422556   |
| epoch                          | 184          |
| evaluation/episode-length-avg  | 750          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 163          |
| evaluation/episode-length-std  | 382          |
| evaluation/return-average      | 3687.352     |
| evaluation/return-max          | 5095.5117    |
| evaluation/return-min          | 499.04608    |
| evaluation/return-std          | 2075.608     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.94         |
| model/origin_ret               | 85           |
| model/penalty_ret              | 80.1         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46038        |
| perf/AverageLength             | 750          |
| perf/AverageReturn             | 3687.352     |
| perf/NormalizedReturn          | 0.803        |
| Q-avg                          | 205.11006    |
| Q-std                          | 88.15818     |
| Q_loss                         | 105.17971    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 184          |
| times/epoch_after_hook         | 1.77e-06     |
| times/epoch_before_hook        | 0.000124     |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.000594     |
| times/evaluation_paths         | 26.9         |
| times/timestep_after_hook      | 0.0038       |
| times/timestep_before_hook     | 0.00858      |
| times/train                    | 61.2         |
| timestep                       | 1000         |
| timesteps_total                | 185000       |
| train-steps                    | 185000       |
| training/Q/q1_loss             | 97.431015    |
| training/sac_pi/alpha          | 0.1642447    |
| training/sac_pi/alpha_loss     | -0.033115275 |
| training/sac_pi/logp_pi        | 3.8324814    |
| training/sac_pi/pi_entropy     | 3.53343      |
| training/sac_pi/pi_global_norm | 1.870992     |
| training/sac_pi/policy_loss    | -207.1851    |
| training/sac_pi/std            | 0.48915133   |
| training/sac_pi/valid_num      | 4993.0       |
| training/sac_Q/q1              | 201.4207     |
| training/sac_Q/q2              | 201.9611     |
| training/sac_Q/q2_loss         | 97.45371     |
| training/sac_Q/q_global_norm   | 175.24854    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16571368 |
| epoch                          | 185        |
| evaluation/episode-length-avg  | 937        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 367        |
| evaluation/episode-length-std  | 190        |
| evaluation/return-average      | 4116.1675  |
| evaluation/return-max          | 4593.875   |
| evaluation/return-min          | 1228.2544  |
| evaluation/return-std          | 969.00665  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46282      |
| perf/AverageLength             | 937        |
| perf/AverageReturn             | 4116.1675  |
| perf/NormalizedReturn          | 0.896      |
| Q-avg                          | 202.22353  |
| Q-std                          | 96.2998    |
| Q_loss                         | 102.23737  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 185        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000266   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000471   |
| times/evaluation_paths         | 33         |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 61.5       |
| timestep                       | 1000       |
| timesteps_total                | 186000     |
| train-steps                    | 186000     |
| training/Q/q1_loss             | 83.989235  |
| training/sac_pi/alpha          | 0.16572723 |
| training/sac_pi/alpha_loss     | 0.1347962  |
| training/sac_pi/logp_pi        | 4.4424133  |
| training/sac_pi/pi_entropy     | 3.4158287  |
| training/sac_pi/pi_global_norm | 2.3130977  |
| training/sac_pi/policy_loss    | -212.58253 |
| training/sac_pi/std            | 0.51009816 |
| training/sac_pi/valid_num      | 4942.0     |
| training/sac_Q/q1              | 203.9694   |
| training/sac_Q/q2              | 203.79462  |
| training/sac_Q/q2_loss         | 83.720184  |
| training/sac_Q/q_global_norm   | 246.18018  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1699147   |
| epoch                          | 186         |
| evaluation/episode-length-avg  | 917         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 167         |
| evaluation/episode-length-std  | 250         |
| evaluation/return-average      | 4277.4155   |
| evaluation/return-max          | 4749.7905   |
| evaluation/return-min          | 388.46344   |
| evaluation/return-std          | 1296.5289   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46034       |
| perf/AverageLength             | 917         |
| perf/AverageReturn             | 4277.4155   |
| perf/NormalizedReturn          | 0.931       |
| Q-avg                          | 200.78004   |
| Q-std                          | 96.28702    |
| Q_loss                         | 113.12706   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 186         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000623    |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00851     |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 187000      |
| train-steps                    | 187000      |
| training/Q/q1_loss             | 103.17411   |
| training/sac_pi/alpha          | 0.16993847  |
| training/sac_pi/alpha_loss     | -0.09845147 |
| training/sac_pi/logp_pi        | 4.331014    |
| training/sac_pi/pi_entropy     | 3.624064    |
| training/sac_pi/pi_global_norm | 1.4948125   |
| training/sac_pi/policy_loss    | -215.66106  |
| training/sac_pi/std            | 0.5086163   |
| training/sac_pi/valid_num      | 4947.0      |
| training/sac_Q/q1              | 208.85901   |
| training/sac_Q/q2              | 208.11723   |
| training/sac_Q/q2_loss         | 103.41946   |
| training/sac_Q/q_global_norm   | 296.51135   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16648078 |
| epoch                          | 187        |
| evaluation/episode-length-avg  | 579        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 126        |
| evaluation/episode-length-std  | 421        |
| evaluation/return-average      | 2518.2732  |
| evaluation/return-max          | 4879.117   |
| evaluation/return-min          | 245.73656  |
| evaluation/return-std          | 2195.3328  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46261      |
| perf/AverageLength             | 579        |
| perf/AverageReturn             | 2518.2732  |
| perf/NormalizedReturn          | 0.548      |
| Q-avg                          | 193.60359  |
| Q-std                          | 94.588936  |
| Q_loss                         | 101.649826 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 187        |
| times/epoch_after_hook         | 2.88e-06   |
| times/epoch_before_hook        | 0.000168   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000454   |
| times/evaluation_paths         | 20.6       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 188000     |
| train-steps                    | 188000     |
| training/Q/q1_loss             | 98.925606  |
| training/sac_pi/alpha          | 0.16645667 |
| training/sac_pi/alpha_loss     | 0.3798006  |
| training/sac_pi/logp_pi        | 4.586316   |
| training/sac_pi/pi_entropy     | 3.6976738  |
| training/sac_pi/pi_global_norm | 1.880267   |
| training/sac_pi/policy_loss    | -206.96326 |
| training/sac_pi/std            | 0.52419496 |
| training/sac_pi/valid_num      | 4912.0     |
| training/sac_Q/q1              | 198.43144  |
| training/sac_Q/q2              | 197.77908  |
| training/sac_Q/q2_loss         | 99.45759   |
| training/sac_Q/q_global_norm   | 333.35068  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16205396 |
| epoch                          | 188        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4707.1963  |
| evaluation/return-max          | 4813.603   |
| evaluation/return-min          | 4497.3877  |
| evaluation/return-std          | 87.896706  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46387      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4707.1963  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 200.46725  |
| Q-std                          | 101.49108  |
| Q_loss                         | 103.43698  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 188        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000541   |
| times/evaluation_paths         | 36.7       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 60.2       |
| timestep                       | 1000       |
| timesteps_total                | 189000     |
| train-steps                    | 189000     |
| training/Q/q1_loss             | 95.737495  |
| training/sac_pi/alpha          | 0.16205643 |
| training/sac_pi/alpha_loss     | -0.0629294 |
| training/sac_pi/logp_pi        | 3.9348915  |
| training/sac_pi/pi_entropy     | 3.4769187  |
| training/sac_pi/pi_global_norm | 1.8455812  |
| training/sac_pi/policy_loss    | -209.016   |
| training/sac_pi/std            | 0.4936784  |
| training/sac_pi/valid_num      | 4962.0     |
| training/sac_Q/q1              | 201.12418  |
| training/sac_Q/q2              | 200.16287  |
| training/sac_Q/q2_loss         | 96.18225   |
| training/sac_Q/q_global_norm   | 271.28986  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1669269   |
| epoch                          | 189         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4701.402    |
| evaluation/return-max          | 4807.6777   |
| evaluation/return-min          | 4390.033    |
| evaluation/return-std          | 122.67431   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46174       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4701.402    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 197.66447   |
| Q-std                          | 99.6333     |
| Q_loss                         | 112.70243   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 189         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000328    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000603    |
| times/evaluation_paths         | 36.7        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00856     |
| times/train                    | 60.1        |
| timestep                       | 1000        |
| timesteps_total                | 190000      |
| train-steps                    | 190000      |
| training/Q/q1_loss             | 95.88431    |
| training/sac_pi/alpha          | 0.16692752  |
| training/sac_pi/alpha_loss     | -0.41383973 |
| training/sac_pi/logp_pi        | 4.439568    |
| training/sac_pi/pi_entropy     | 3.654225    |
| training/sac_pi/pi_global_norm | 1.4350724   |
| training/sac_pi/policy_loss    | -208.2876   |
| training/sac_pi/std            | 0.5387351   |
| training/sac_pi/valid_num      | 4900.0      |
| training/sac_Q/q1              | 197.30798   |
| training/sac_Q/q2              | 196.40073   |
| training/sac_Q/q2_loss         | 95.34009    |
| training/sac_Q/q_global_norm   | 256.5111    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16036008 |
| epoch                          | 190        |
| evaluation/episode-length-avg  | 156        |
| evaluation/episode-length-max  | 162        |
| evaluation/episode-length-min  | 151        |
| evaluation/episode-length-std  | 2.91       |
| evaluation/return-average      | 504.32358  |
| evaluation/return-max          | 517.9182   |
| evaluation/return-min          | 494.97928  |
| evaluation/return-std          | 7.0705085  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46046      |
| perf/AverageLength             | 156        |
| perf/AverageReturn             | 504.32358  |
| perf/NormalizedReturn          | 0.11       |
| Q-avg                          | 197.5616   |
| Q-std                          | 100.82043  |
| Q_loss                         | 96.79723   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 190        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000143   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000676   |
| times/evaluation_paths         | 5.1        |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 191000     |
| train-steps                    | 191000     |
| training/Q/q1_loss             | 99.7485    |
| training/sac_pi/alpha          | 0.16033266 |
| training/sac_pi/alpha_loss     | 0.1291368  |
| training/sac_pi/logp_pi        | 4.7172832  |
| training/sac_pi/pi_entropy     | 3.785041   |
| training/sac_pi/pi_global_norm | 1.476169   |
| training/sac_pi/policy_loss    | -209.87105 |
| training/sac_pi/std            | 0.5674846  |
| training/sac_pi/valid_num      | 4913.0     |
| training/sac_Q/q1              | 197.77472  |
| training/sac_Q/q2              | 199.29666  |
| training/sac_Q/q2_loss         | 99.30922   |
| training/sac_Q/q_global_norm   | 214.3026   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16501643 |
| epoch                          | 191        |
| evaluation/episode-length-avg  | 916        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 163        |
| evaluation/episode-length-std  | 251        |
| evaluation/return-average      | 4324.2275  |
| evaluation/return-max          | 4877.036   |
| evaluation/return-min          | 507.12317  |
| evaluation/return-std          | 1274.3884  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46179      |
| perf/AverageLength             | 916        |
| perf/AverageReturn             | 4324.2275  |
| perf/NormalizedReturn          | 0.942      |
| Q-avg                          | 206.43591  |
| Q-std                          | 98.22685   |
| Q_loss                         | 98.572945  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 191        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000147   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000522   |
| times/evaluation_paths         | 33.2       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 59.3       |
| timestep                       | 1000       |
| timesteps_total                | 192000     |
| train-steps                    | 192000     |
| training/Q/q1_loss             | 88.79846   |
| training/sac_pi/alpha          | 0.16500703 |
| training/sac_pi/alpha_loss     | 0.39486587 |
| training/sac_pi/logp_pi        | 4.465214   |
| training/sac_pi/pi_entropy     | 3.4573715  |
| training/sac_pi/pi_global_norm | 1.8953391  |
| training/sac_pi/policy_loss    | -211.69148 |
| training/sac_pi/std            | 0.49629983 |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 202.32022  |
| training/sac_Q/q2              | 202.57553  |
| training/sac_Q/q2_loss         | 88.29663   |
| training/sac_Q/q_global_norm   | 241.15672  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16914459  |
| epoch                          | 192         |
| evaluation/episode-length-avg  | 134         |
| evaluation/episode-length-max  | 136         |
| evaluation/episode-length-min  | 133         |
| evaluation/episode-length-std  | 0.781       |
| evaluation/return-average      | 386.442     |
| evaluation/return-max          | 391.09454   |
| evaluation/return-min          | 383.30078   |
| evaluation/return-std          | 2.4251556   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.95        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 80.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46163       |
| perf/AverageLength             | 134         |
| perf/AverageReturn             | 386.442     |
| perf/NormalizedReturn          | 0.0838      |
| Q-avg                          | 201.27165   |
| Q-std                          | 104.02256   |
| Q_loss                         | 91.82146    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 192         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000531    |
| times/evaluation_paths         | 5.55        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00855     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 193000      |
| train-steps                    | 193000      |
| training/Q/q1_loss             | 106.81041   |
| training/sac_pi/alpha          | 0.16915189  |
| training/sac_pi/alpha_loss     | -0.52924585 |
| training/sac_pi/logp_pi        | 3.4505858   |
| training/sac_pi/pi_entropy     | 3.6592164   |
| training/sac_pi/pi_global_norm | 1.6746956   |
| training/sac_pi/policy_loss    | -207.6808   |
| training/sac_pi/std            | 0.5011232   |
| training/sac_pi/valid_num      | 4939.0      |
| training/sac_Q/q1              | 200.3508    |
| training/sac_Q/q2              | 200.66446   |
| training/sac_Q/q2_loss         | 107.84392   |
| training/sac_Q/q_global_norm   | 271.49237   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17476976  |
| epoch                          | 193         |
| evaluation/episode-length-avg  | 808         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 549         |
| evaluation/episode-length-std  | 188         |
| evaluation/return-average      | 3725.7363   |
| evaluation/return-max          | 4735.5903   |
| evaluation/return-min          | 2377.4033   |
| evaluation/return-std          | 970.4228    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.94        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46086       |
| perf/AverageLength             | 808         |
| perf/AverageReturn             | 3725.7363   |
| perf/NormalizedReturn          | 0.811       |
| Q-avg                          | 198.37463   |
| Q-std                          | 103.84192   |
| Q_loss                         | 106.85423   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 193         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.00027     |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000505    |
| times/evaluation_paths         | 29.9        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 60.1        |
| timestep                       | 1000        |
| timesteps_total                | 194000      |
| train-steps                    | 194000      |
| training/Q/q1_loss             | 96.32538    |
| training/sac_pi/alpha          | 0.17478915  |
| training/sac_pi/alpha_loss     | -0.25577188 |
| training/sac_pi/logp_pi        | 4.640143    |
| training/sac_pi/pi_entropy     | 3.8750405   |
| training/sac_pi/pi_global_norm | 1.8998073   |
| training/sac_pi/policy_loss    | -217.31067  |
| training/sac_pi/std            | 0.56777513  |
| training/sac_pi/valid_num      | 4929.0      |
| training/sac_Q/q1              | 206.07442   |
| training/sac_Q/q2              | 207.37447   |
| training/sac_Q/q2_loss         | 96.14946    |
| training/sac_Q/q_global_norm   | 271.31982   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16599531 |
| epoch                          | 194        |
| evaluation/episode-length-avg  | 936        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 360        |
| evaluation/episode-length-std  | 192        |
| evaluation/return-average      | 4850.3     |
| evaluation/return-max          | 5326.842   |
| evaluation/return-min          | 1453.502   |
| evaluation/return-std          | 1135.1932  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46021      |
| perf/AverageLength             | 936        |
| perf/AverageReturn             | 4850.3     |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 193.34164  |
| Q-std                          | 97.495636  |
| Q_loss                         | 105.20626  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 194        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000652   |
| times/evaluation_paths         | 33.6       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00851    |
| times/train                    | 59.3       |
| timestep                       | 1000       |
| timesteps_total                | 195000     |
| train-steps                    | 195000     |
| training/Q/q1_loss             | 136.61223  |
| training/sac_pi/alpha          | 0.16599603 |
| training/sac_pi/alpha_loss     | 0.17570284 |
| training/sac_pi/logp_pi        | 4.6655025  |
| training/sac_pi/pi_entropy     | 3.6852145  |
| training/sac_pi/pi_global_norm | 1.8974713  |
| training/sac_pi/policy_loss    | -206.36365 |
| training/sac_pi/std            | 0.5344799  |
| training/sac_pi/valid_num      | 4884.0     |
| training/sac_Q/q1              | 194.79782  |
| training/sac_Q/q2              | 195.25208  |
| training/sac_Q/q2_loss         | 137.137    |
| training/sac_Q/q_global_norm   | 291.84174  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17074318  |
| epoch                          | 195         |
| evaluation/episode-length-avg  | 119         |
| evaluation/episode-length-max  | 123         |
| evaluation/episode-length-min  | 112         |
| evaluation/episode-length-std  | 2.97        |
| evaluation/return-average      | 314.1153    |
| evaluation/return-max          | 340.95984   |
| evaluation/return-min          | 293.97528   |
| evaluation/return-std          | 17.23049    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46249       |
| perf/AverageLength             | 119         |
| perf/AverageReturn             | 314.1153    |
| perf/NormalizedReturn          | 0.0681      |
| Q-avg                          | 200.87485   |
| Q-std                          | 110.012085  |
| Q_loss                         | 89.69452    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 195         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000582    |
| times/evaluation_paths         | 3.95        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00852     |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 196000      |
| train-steps                    | 196000      |
| training/Q/q1_loss             | 105.96721   |
| training/sac_pi/alpha          | 0.17078501  |
| training/sac_pi/alpha_loss     | -0.13721016 |
| training/sac_pi/logp_pi        | 4.2128663   |
| training/sac_pi/pi_entropy     | 3.8176277   |
| training/sac_pi/pi_global_norm | 1.8051004   |
| training/sac_pi/policy_loss    | -214.12381  |
| training/sac_pi/std            | 0.54145366  |
| training/sac_pi/valid_num      | 4961.0      |
| training/sac_Q/q1              | 206.20537   |
| training/sac_Q/q2              | 206.75154   |
| training/sac_Q/q2_loss         | 105.92683   |
| training/sac_Q/q_global_norm   | 312.93225   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16746825   |
| epoch                          | 196          |
| evaluation/episode-length-avg  | 323          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 149          |
| evaluation/episode-length-std  | 338          |
| evaluation/return-average      | 1338.9691    |
| evaluation/return-max          | 5024.9307    |
| evaluation/return-min          | 406.64166    |
| evaluation/return-std          | 1831.7692    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.99         |
| model/origin_ret               | 85.1         |
| model/penalty_ret              | 80.7         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46048        |
| perf/AverageLength             | 323          |
| perf/AverageReturn             | 1338.9691    |
| perf/NormalizedReturn          | 0.291        |
| Q-avg                          | 188.38312    |
| Q-std                          | 106.30822    |
| Q_loss                         | 116.117485   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 196          |
| times/epoch_after_hook         | 1.7e-06      |
| times/epoch_before_hook        | 0.000122     |
| times/epoch_rollout_model      | 497          |
| times/evaluation_metrics       | 0.000485     |
| times/evaluation_paths         | 10.8         |
| times/timestep_after_hook      | 0.00368      |
| times/timestep_before_hook     | 0.00854      |
| times/train                    | 61.4         |
| timestep                       | 1000         |
| timesteps_total                | 197000       |
| train-steps                    | 197000       |
| training/Q/q1_loss             | 90.145515    |
| training/sac_pi/alpha          | 0.16746637   |
| training/sac_pi/alpha_loss     | -0.003708482 |
| training/sac_pi/logp_pi        | 4.292366     |
| training/sac_pi/pi_entropy     | 3.809606     |
| training/sac_pi/pi_global_norm | 1.8632945    |
| training/sac_pi/policy_loss    | -212.67747   |
| training/sac_pi/std            | 0.5367786    |
| training/sac_pi/valid_num      | 4938.0       |
| training/sac_Q/q1              | 203.67317    |
| training/sac_Q/q2              | 205.15152    |
| training/sac_Q/q2_loss         | 91.008446    |
| training/sac_Q/q_global_norm   | 216.88528    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1666321   |
| epoch                          | 197         |
| evaluation/episode-length-avg  | 834         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 456         |
| evaluation/episode-length-std  | 175         |
| evaluation/return-average      | 3958.0464   |
| evaluation/return-max          | 4940.4224   |
| evaluation/return-min          | 1994.5255   |
| evaluation/return-std          | 913.4584    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46240       |
| perf/AverageLength             | 834         |
| perf/AverageReturn             | 3958.0464   |
| perf/NormalizedReturn          | 0.862       |
| Q-avg                          | 201.65059   |
| Q-std                          | 97.30726    |
| Q_loss                         | 88.20899    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 197         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000275    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000805    |
| times/evaluation_paths         | 29          |
| times/timestep_after_hook      | 0.00354     |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 59.1        |
| timestep                       | 1000        |
| timesteps_total                | 198000      |
| train-steps                    | 198000      |
| training/Q/q1_loss             | 85.52112    |
| training/sac_pi/alpha          | 0.16666424  |
| training/sac_pi/alpha_loss     | -0.19267981 |
| training/sac_pi/logp_pi        | 3.9386597   |
| training/sac_pi/pi_entropy     | 3.780173    |
| training/sac_pi/pi_global_norm | 2.053792    |
| training/sac_pi/policy_loss    | -210.90352  |
| training/sac_pi/std            | 0.52964497  |
| training/sac_pi/valid_num      | 4958.0      |
| training/sac_Q/q1              | 202.03293   |
| training/sac_Q/q2              | 202.06033   |
| training/sac_Q/q2_loss         | 85.81621    |
| training/sac_Q/q_global_norm   | 284.7566    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16786803 |
| epoch                          | 198        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4742.6084  |
| evaluation/return-max          | 4869.3027  |
| evaluation/return-min          | 4446.9883  |
| evaluation/return-std          | 112.81116  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.95       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46186      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4742.6084  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 206.50508  |
| Q-std                          | 99.01284   |
| Q_loss                         | 71.449165  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 198        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000149   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000589   |
| times/evaluation_paths         | 36.2       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 59.1       |
| timestep                       | 1000       |
| timesteps_total                | 199000     |
| train-steps                    | 199000     |
| training/Q/q1_loss             | 98.851814  |
| training/sac_pi/alpha          | 0.16785322 |
| training/sac_pi/alpha_loss     | 0.38027912 |
| training/sac_pi/logp_pi        | 4.50961    |
| training/sac_pi/pi_entropy     | 3.6327407  |
| training/sac_pi/pi_global_norm | 2.1414094  |
| training/sac_pi/policy_loss    | -207.88837 |
| training/sac_pi/std            | 0.51780164 |
| training/sac_pi/valid_num      | 4963.0     |
| training/sac_Q/q1              | 200.61238  |
| training/sac_Q/q2              | 202.59145  |
| training/sac_Q/q2_loss         | 100.002205 |
| training/sac_Q/q_global_norm   | 345.44806  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16848427 |
| epoch                          | 199        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4651.8994  |
| evaluation/return-max          | 4719.7686  |
| evaluation/return-min          | 4553.519   |
| evaluation/return-std          | 53.379227  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 81.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46065      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4651.8994  |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 200.94608  |
| Q-std                          | 94.61354   |
| Q_loss                         | 116.15677  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 199        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000118   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000542   |
| times/evaluation_paths         | 34.5       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 200000     |
| train-steps                    | 200000     |
| training/Q/q1_loss             | 87.78767   |
| training/sac_pi/alpha          | 0.16845883 |
| training/sac_pi/alpha_loss     | 0.3162913  |
| training/sac_pi/logp_pi        | 4.578428   |
| training/sac_pi/pi_entropy     | 3.9643242  |
| training/sac_pi/pi_global_norm | 1.6302563  |
| training/sac_pi/policy_loss    | -209.90028 |
| training/sac_pi/std            | 0.56542736 |
| training/sac_pi/valid_num      | 4949.0     |
| training/sac_Q/q1              | 200.5221   |
| training/sac_Q/q2              | 201.67584  |
| training/sac_Q/q2_loss         | 87.78445   |
| training/sac_Q/q_global_norm   | 201.24033  |
--------------------------------------------------------------------------------
[WARN] 200 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16354257 |
| epoch                          | 200        |
| evaluation/episode-length-avg  | 747        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 155        |
| evaluation/episode-length-std  | 386        |
| evaluation/return-average      | 3742.1453  |
| evaluation/return-max          | 5197.055   |
| evaluation/return-min          | 505.6315   |
| evaluation/return-std          | 2110.6116  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.97       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46104      |
| perf/AverageLength             | 747        |
| perf/AverageReturn             | 3742.1453  |
| perf/NormalizedReturn          | 0.815      |
| Q-avg                          | 205.81963  |
| Q-std                          | 88.45162   |
| Q_loss                         | 110.78904  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 200        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000882   |
| times/evaluation_paths         | 27.8       |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.00846    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 201000     |
| train-steps                    | 201000     |
| training/Q/q1_loss             | 122.963264 |
| training/sac_pi/alpha          | 0.16352348 |
| training/sac_pi/alpha_loss     | 0.54472846 |
| training/sac_pi/logp_pi        | 4.1638794  |
| training/sac_pi/pi_entropy     | 3.6077752  |
| training/sac_pi/pi_global_norm | 1.7496532  |
| training/sac_pi/policy_loss    | -207.28949 |
| training/sac_pi/std            | 0.5067681  |
| training/sac_pi/valid_num      | 4999.0     |
| training/sac_Q/q1              | 202.54341  |
| training/sac_Q/q2              | 203.44987  |
| training/sac_Q/q2_loss         | 122.37566  |
| training/sac_Q/q_global_norm   | 334.95764  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16734515  |
| epoch                          | 201         |
| evaluation/episode-length-avg  | 499         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 164         |
| evaluation/episode-length-std  | 409         |
| evaluation/return-average      | 2401.1987   |
| evaluation/return-max          | 5330.1353   |
| evaluation/return-min          | 521.57104   |
| evaluation/return-std          | 2296.7659   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46239       |
| perf/AverageLength             | 499         |
| perf/AverageReturn             | 2401.1987   |
| perf/NormalizedReturn          | 0.523       |
| Q-avg                          | 202.069     |
| Q-std                          | 103.88987   |
| Q_loss                         | 75.971924   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 201         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000282    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000784    |
| times/evaluation_paths         | 18.1        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 59.2        |
| timestep                       | 1000        |
| timesteps_total                | 202000      |
| train-steps                    | 202000      |
| training/Q/q1_loss             | 106.11568   |
| training/sac_pi/alpha          | 0.16736248  |
| training/sac_pi/alpha_loss     | -0.21535815 |
| training/sac_pi/logp_pi        | 4.218436    |
| training/sac_pi/pi_entropy     | 3.9679928   |
| training/sac_pi/pi_global_norm | 1.7627833   |
| training/sac_pi/policy_loss    | -207.34302  |
| training/sac_pi/std            | 0.552329    |
| training/sac_pi/valid_num      | 4920.0      |
| training/sac_Q/q1              | 195.26855   |
| training/sac_Q/q2              | 196.18156   |
| training/sac_Q/q2_loss         | 107.7628    |
| training/sac_Q/q_global_norm   | 248.50914   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17191623  |
| epoch                          | 202         |
| evaluation/episode-length-avg  | 323         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 150         |
| evaluation/episode-length-std  | 339         |
| evaluation/return-average      | 1396.0535   |
| evaluation/return-max          | 5130.067    |
| evaluation/return-min          | 479.5103    |
| evaluation/return-std          | 1812.1956   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 81.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46113       |
| perf/AverageLength             | 323         |
| perf/AverageReturn             | 1396.0535   |
| perf/NormalizedReturn          | 0.304       |
| Q-avg                          | 204.46521   |
| Q-std                          | 84.39891    |
| Q_loss                         | 83.011444   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 202         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000256    |
| times/epoch_rollout_model      | 503         |
| times/evaluation_metrics       | 0.000554    |
| times/evaluation_paths         | 10.5        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 203000      |
| train-steps                    | 203000      |
| training/Q/q1_loss             | 106.38015   |
| training/sac_pi/alpha          | 0.17193381  |
| training/sac_pi/alpha_loss     | -0.39917082 |
| training/sac_pi/logp_pi        | 4.9083734   |
| training/sac_pi/pi_entropy     | 3.705426    |
| training/sac_pi/pi_global_norm | 1.6613822   |
| training/sac_pi/policy_loss    | -211.4845   |
| training/sac_pi/std            | 0.5681324   |
| training/sac_pi/valid_num      | 4900.0      |
| training/sac_Q/q1              | 200.42044   |
| training/sac_Q/q2              | 202.49712   |
| training/sac_Q/q2_loss         | 106.7963    |
| training/sac_Q/q_global_norm   | 314.57565   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16454436  |
| epoch                          | 203         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5024.4756   |
| evaluation/return-max          | 5210.7275   |
| evaluation/return-min          | 4838.38     |
| evaluation/return-std          | 116.05749   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85          |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46154       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5024.4756   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 203.44485   |
| Q-std                          | 94.34805    |
| Q_loss                         | 90.274605   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 203         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.00012     |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000646    |
| times/evaluation_paths         | 36.1        |
| times/timestep_after_hook      | 0.0038      |
| times/timestep_before_hook     | 0.00881     |
| times/train                    | 60.2        |
| timestep                       | 1000        |
| timesteps_total                | 204000      |
| train-steps                    | 204000      |
| training/Q/q1_loss             | 70.75661    |
| training/sac_pi/alpha          | 0.1645438   |
| training/sac_pi/alpha_loss     | -0.07223022 |
| training/sac_pi/logp_pi        | 3.9537659   |
| training/sac_pi/pi_entropy     | 3.5002975   |
| training/sac_pi/pi_global_norm | 1.6042613   |
| training/sac_pi/policy_loss    | -213.72977  |
| training/sac_pi/std            | 0.48336893  |
| training/sac_pi/valid_num      | 5006.0      |
| training/sac_Q/q1              | 208.35855   |
| training/sac_Q/q2              | 209.63167   |
| training/sac_Q/q2_loss         | 70.38353    |
| training/sac_Q/q_global_norm   | 177.25455   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17241557  |
| epoch                          | 204         |
| evaluation/episode-length-avg  | 250         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 157         |
| evaluation/episode-length-std  | 250         |
| evaluation/return-average      | 837.13574   |
| evaluation/return-max          | 4724.562    |
| evaluation/return-min          | 367.57904   |
| evaluation/return-std          | 1296.0359   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46359       |
| perf/AverageLength             | 250         |
| perf/AverageReturn             | 837.13574   |
| perf/NormalizedReturn          | 0.182       |
| Q-avg                          | 205.04288   |
| Q-std                          | 101.46992   |
| Q_loss                         | 106.94514   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 204         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000549    |
| times/evaluation_paths         | 8.23        |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.00853     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 205000      |
| train-steps                    | 205000      |
| training/Q/q1_loss             | 85.90283    |
| training/sac_pi/alpha          | 0.17245893  |
| training/sac_pi/alpha_loss     | -0.15176573 |
| training/sac_pi/logp_pi        | 4.370191    |
| training/sac_pi/pi_entropy     | 3.8925622   |
| training/sac_pi/pi_global_norm | 1.7689164   |
| training/sac_pi/policy_loss    | -217.40445  |
| training/sac_pi/std            | 0.55361545  |
| training/sac_pi/valid_num      | 4907.0      |
| training/sac_Q/q1              | 206.45471   |
| training/sac_Q/q2              | 207.71664   |
| training/sac_Q/q2_loss         | 86.68392    |
| training/sac_Q/q_global_norm   | 249.14505   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17268473   |
| epoch                          | 205          |
| evaluation/episode-length-avg  | 247          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 161          |
| evaluation/episode-length-std  | 251          |
| evaluation/return-average      | 961.44696    |
| evaluation/return-max          | 5036.3555    |
| evaluation/return-min          | 492.77405    |
| evaluation/return-std          | 1358.3206    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.02         |
| model/origin_ret               | 85.9         |
| model/penalty_ret              | 82           |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 45966        |
| perf/AverageLength             | 247          |
| perf/AverageReturn             | 961.44696    |
| perf/NormalizedReturn          | 0.209        |
| Q-avg                          | 198.52919    |
| Q-std                          | 97.33236     |
| Q_loss                         | 87.79508     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 205          |
| times/epoch_after_hook         | 1.73e-06     |
| times/epoch_before_hook        | 0.000278     |
| times/epoch_rollout_model      | 494          |
| times/evaluation_metrics       | 0.000538     |
| times/evaluation_paths         | 8            |
| times/timestep_after_hook      | 0.00375      |
| times/timestep_before_hook     | 0.00837      |
| times/train                    | 61           |
| timestep                       | 1000         |
| timesteps_total                | 206000       |
| train-steps                    | 206000       |
| training/Q/q1_loss             | 84.24774     |
| training/sac_pi/alpha          | 0.17270255   |
| training/sac_pi/alpha_loss     | -0.057121955 |
| training/sac_pi/logp_pi        | 4.1498003    |
| training/sac_pi/pi_entropy     | 3.942945     |
| training/sac_pi/pi_global_norm | 1.6174128    |
| training/sac_pi/policy_loss    | -209.83632   |
| training/sac_pi/std            | 0.5392196    |
| training/sac_pi/valid_num      | 4961.0       |
| training/sac_Q/q1              | 202.16919    |
| training/sac_Q/q2              | 203.84322    |
| training/sac_Q/q2_loss         | 84.37412     |
| training/sac_Q/q_global_norm   | 270.0153     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17390107 |
| epoch                          | 206        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5157.0347  |
| evaluation/return-max          | 5237.4126  |
| evaluation/return-min          | 5102.752   |
| evaluation/return-std          | 44.323223  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46155      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5157.0347  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 207.78984  |
| Q-std                          | 89.48786   |
| Q_loss                         | 96.31083   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 206        |
| times/epoch_after_hook         | 1.63e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000565   |
| times/evaluation_paths         | 34.8       |
| times/timestep_after_hook      | 0.00403    |
| times/timestep_before_hook     | 0.00854    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 207000     |
| train-steps                    | 207000     |
| training/Q/q1_loss             | 87.719536  |
| training/sac_pi/alpha          | 0.17391594 |
| training/sac_pi/alpha_loss     | -0.3806042 |
| training/sac_pi/logp_pi        | 4.1960936  |
| training/sac_pi/pi_entropy     | 3.751304   |
| training/sac_pi/pi_global_norm | 1.4883223  |
| training/sac_pi/policy_loss    | -213.14893 |
| training/sac_pi/std            | 0.531723   |
| training/sac_pi/valid_num      | 4876.0     |
| training/sac_Q/q1              | 201.30185  |
| training/sac_Q/q2              | 200.50558  |
| training/sac_Q/q2_loss         | 88.41817   |
| training/sac_Q/q_global_norm   | 231.05879  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17040727   |
| epoch                          | 207          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4966.753     |
| evaluation/return-max          | 5033.689     |
| evaluation/return-min          | 4869.317     |
| evaluation/return-std          | 41.07615     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.03         |
| model/origin_ret               | 85.4         |
| model/penalty_ret              | 80.4         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46149        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4966.753     |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 205.26375    |
| Q-std                          | 105.59189    |
| Q_loss                         | 85.76074     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 207          |
| times/epoch_after_hook         | 1.89e-06     |
| times/epoch_before_hook        | 0.000109     |
| times/epoch_rollout_model      | 495          |
| times/evaluation_metrics       | 0.000778     |
| times/evaluation_paths         | 36.3         |
| times/timestep_after_hook      | 0.00362      |
| times/timestep_before_hook     | 0.0085       |
| times/train                    | 59.2         |
| timestep                       | 1000         |
| timesteps_total                | 208000       |
| train-steps                    | 208000       |
| training/Q/q1_loss             | 84.703896    |
| training/sac_pi/alpha          | 0.17043135   |
| training/sac_pi/alpha_loss     | -0.009243147 |
| training/sac_pi/logp_pi        | 3.5647378    |
| training/sac_pi/pi_entropy     | 3.4988701    |
| training/sac_pi/pi_global_norm | 1.7828932    |
| training/sac_pi/policy_loss    | -219.81807   |
| training/sac_pi/std            | 0.47931704   |
| training/sac_pi/valid_num      | 5010.0       |
| training/sac_Q/q1              | 215.04146    |
| training/sac_Q/q2              | 215.47092    |
| training/sac_Q/q2_loss         | 84.94966     |
| training/sac_Q/q_global_norm   | 289.16418    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1637234  |
| epoch                          | 208        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5072.303   |
| evaluation/return-max          | 5123.6104  |
| evaluation/return-min          | 5038.369   |
| evaluation/return-std          | 26.521791  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46289      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5072.303   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 206.47917  |
| Q-std                          | 102.91384  |
| Q_loss                         | 90.078224  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 208        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000151   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000609   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00873    |
| times/train                    | 59.3       |
| timestep                       | 1000       |
| timesteps_total                | 209000     |
| train-steps                    | 209000     |
| training/Q/q1_loss             | 91.587006  |
| training/sac_pi/alpha          | 0.16369992 |
| training/sac_pi/alpha_loss     | 0.3733826  |
| training/sac_pi/logp_pi        | 3.9084842  |
| training/sac_pi/pi_entropy     | 3.6016212  |
| training/sac_pi/pi_global_norm | 1.5748774  |
| training/sac_pi/policy_loss    | -212.55309 |
| training/sac_pi/std            | 0.4910027  |
| training/sac_pi/valid_num      | 5020.0     |
| training/sac_Q/q1              | 208.72859  |
| training/sac_Q/q2              | 209.20078  |
| training/sac_Q/q2_loss         | 92.03185   |
| training/sac_Q/q_global_norm   | 264.55603  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16956969 |
| epoch                          | 209        |
| evaluation/episode-length-avg  | 234        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 145        |
| evaluation/episode-length-std  | 255        |
| evaluation/return-average      | 929.9543   |
| evaluation/return-max          | 4924.119   |
| evaluation/return-min          | 455.4862   |
| evaluation/return-std          | 1331.466   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46198      |
| perf/AverageLength             | 234        |
| perf/AverageReturn             | 929.9543   |
| perf/NormalizedReturn          | 0.202      |
| Q-avg                          | 218.88228  |
| Q-std                          | 85.835144  |
| Q_loss                         | 77.082664  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 209        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000276   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000505   |
| times/evaluation_paths         | 7.74       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 210000     |
| train-steps                    | 210000     |
| training/Q/q1_loss             | 102.40099  |
| training/sac_pi/alpha          | 0.16959159 |
| training/sac_pi/alpha_loss     | 0.02646736 |
| training/sac_pi/logp_pi        | 4.674605   |
| training/sac_pi/pi_entropy     | 3.4755752  |
| training/sac_pi/pi_global_norm | 1.9833912  |
| training/sac_pi/policy_loss    | -218.80713 |
| training/sac_pi/std            | 0.5072613  |
| training/sac_pi/valid_num      | 4985.0     |
| training/sac_Q/q1              | 212.52686  |
| training/sac_Q/q2              | 211.92117  |
| training/sac_Q/q2_loss         | 103.03021  |
| training/sac_Q/q_global_norm   | 249.18364  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16450948 |
| epoch                          | 210        |
| evaluation/episode-length-avg  | 576        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 130        |
| evaluation/episode-length-std  | 424        |
| evaluation/return-average      | 2587.4946  |
| evaluation/return-max          | 4863.1733  |
| evaluation/return-min          | 292.0056   |
| evaluation/return-std          | 2232.207   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46250      |
| perf/AverageLength             | 576        |
| perf/AverageReturn             | 2587.4946  |
| perf/NormalizedReturn          | 0.563      |
| Q-avg                          | 201.18605  |
| Q-std                          | 104.03394  |
| Q_loss                         | 101.13711  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 210        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000578   |
| times/evaluation_paths         | 20.8       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00857    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 211000     |
| train-steps                    | 211000     |
| training/Q/q1_loss             | 84.361115  |
| training/sac_pi/alpha          | 0.16450462 |
| training/sac_pi/alpha_loss     | 0.3464983  |
| training/sac_pi/logp_pi        | 3.9334335  |
| training/sac_pi/pi_entropy     | 3.6802402  |
| training/sac_pi/pi_global_norm | 1.735161   |
| training/sac_pi/policy_loss    | -214.3174  |
| training/sac_pi/std            | 0.49856535 |
| training/sac_pi/valid_num      | 5015.0     |
| training/sac_Q/q1              | 209.72847  |
| training/sac_Q/q2              | 209.90244  |
| training/sac_Q/q2_loss         | 84.89879   |
| training/sac_Q/q_global_norm   | 229.51994  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16183658  |
| epoch                          | 211         |
| evaluation/episode-length-avg  | 916         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 161         |
| evaluation/episode-length-std  | 252         |
| evaluation/return-average      | 4697.6445   |
| evaluation/return-max          | 5181.913    |
| evaluation/return-min          | 540.5515    |
| evaluation/return-std          | 1385.753    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46244       |
| perf/AverageLength             | 916         |
| perf/AverageReturn             | 4697.6445   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 201.47615   |
| Q-std                          | 105.322174  |
| Q_loss                         | 128.20201   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 211         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000153    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.00052     |
| times/evaluation_paths         | 31.9        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00832     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 212000      |
| train-steps                    | 212000      |
| training/Q/q1_loss             | 102.41532   |
| training/sac_pi/alpha          | 0.161887    |
| training/sac_pi/alpha_loss     | -0.17328273 |
| training/sac_pi/logp_pi        | 3.7008808   |
| training/sac_pi/pi_entropy     | 3.4381447   |
| training/sac_pi/pi_global_norm | 1.4880425   |
| training/sac_pi/policy_loss    | -223.62437  |
| training/sac_pi/std            | 0.47530258  |
| training/sac_pi/valid_num      | 5006.0      |
| training/sac_Q/q1              | 218.65332   |
| training/sac_Q/q2              | 218.79819   |
| training/sac_Q/q2_loss         | 102.17359   |
| training/sac_Q/q_global_norm   | 295.10092   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15938315 |
| epoch                          | 212        |
| evaluation/episode-length-avg  | 750        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 156        |
| evaluation/episode-length-std  | 383        |
| evaluation/return-average      | 3552.5234  |
| evaluation/return-max          | 4997.68    |
| evaluation/return-min          | 485.49164  |
| evaluation/return-std          | 1985.5502  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46150      |
| perf/AverageLength             | 750        |
| perf/AverageReturn             | 3552.5234  |
| perf/NormalizedReturn          | 0.774      |
| Q-avg                          | 212.59415  |
| Q-std                          | 108.51452  |
| Q_loss                         | 76.027016  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 212        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000509   |
| times/evaluation_paths         | 26.2       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00872    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 213000     |
| train-steps                    | 213000     |
| training/Q/q1_loss             | 81.4719    |
| training/sac_pi/alpha          | 0.15935041 |
| training/sac_pi/alpha_loss     | 0.33806172 |
| training/sac_pi/logp_pi        | 4.802423   |
| training/sac_pi/pi_entropy     | 3.5255818  |
| training/sac_pi/pi_global_norm | 1.8318379  |
| training/sac_pi/policy_loss    | -216.3612  |
| training/sac_pi/std            | 0.52608407 |
| training/sac_pi/valid_num      | 4939.0     |
| training/sac_Q/q1              | 207.74399  |
| training/sac_Q/q2              | 209.24582  |
| training/sac_Q/q2_loss         | 80.99992   |
| training/sac_Q/q_global_norm   | 183.27412  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1696677  |
| epoch                          | 213        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4760.491   |
| evaluation/return-max          | 4822.9805  |
| evaluation/return-min          | 4593.8843  |
| evaluation/return-std          | 67.404686  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.98       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46230      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4760.491   |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 204.19312  |
| Q-std                          | 102.79134  |
| Q_loss                         | 81.83355   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 213        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000269   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000916   |
| times/evaluation_paths         | 34.7       |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 214000     |
| train-steps                    | 214000     |
| training/Q/q1_loss             | 100.16526  |
| training/sac_pi/alpha          | 0.16963188 |
| training/sac_pi/alpha_loss     | 0.39093024 |
| training/sac_pi/logp_pi        | 4.19967    |
| training/sac_pi/pi_entropy     | 3.5229213  |
| training/sac_pi/pi_global_norm | 1.7360152  |
| training/sac_pi/policy_loss    | -216.29352 |
| training/sac_pi/std            | 0.48685744 |
| training/sac_pi/valid_num      | 4961.0     |
| training/sac_Q/q1              | 209.26985  |
| training/sac_Q/q2              | 209.86426  |
| training/sac_Q/q2_loss         | 100.08958  |
| training/sac_Q/q_global_norm   | 329.4379   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1710659   |
| epoch                          | 214         |
| evaluation/episode-length-avg  | 928         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 282         |
| evaluation/episode-length-std  | 215         |
| evaluation/return-average      | 4544.666    |
| evaluation/return-max          | 5042.6396   |
| evaluation/return-min          | 1010.4137   |
| evaluation/return-std          | 1180.9741   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46220       |
| perf/AverageLength             | 928         |
| perf/AverageReturn             | 4544.666    |
| perf/NormalizedReturn          | 0.99        |
| Q-avg                          | 205.40234   |
| Q-std                          | 98.82041    |
| Q_loss                         | 93.0033     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 214         |
| times/epoch_after_hook         | 2.05e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000653    |
| times/evaluation_paths         | 32.2        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 215000      |
| train-steps                    | 215000      |
| training/Q/q1_loss             | 100.544785  |
| training/sac_pi/alpha          | 0.17108844  |
| training/sac_pi/alpha_loss     | -0.24091631 |
| training/sac_pi/logp_pi        | 4.427939    |
| training/sac_pi/pi_entropy     | 3.7306945   |
| training/sac_pi/pi_global_norm | 1.7350234   |
| training/sac_pi/policy_loss    | -217.24165  |
| training/sac_pi/std            | 0.5228058   |
| training/sac_pi/valid_num      | 4940.0      |
| training/sac_Q/q1              | 209.2624    |
| training/sac_Q/q2              | 210.01086   |
| training/sac_Q/q2_loss         | 101.17863   |
| training/sac_Q/q_global_norm   | 241.65524   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1687703  |
| epoch                          | 215        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4760.9814  |
| evaluation/return-max          | 4812.3105  |
| evaluation/return-min          | 4717.1074  |
| evaluation/return-std          | 30.9018    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46128      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4760.9814  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 208.07999  |
| Q-std                          | 92.91278   |
| Q_loss                         | 95.784676  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 215        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000119   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000621   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 59.3       |
| timestep                       | 1000       |
| timesteps_total                | 216000     |
| train-steps                    | 216000     |
| training/Q/q1_loss             | 111.524864 |
| training/sac_pi/alpha          | 0.16878317 |
| training/sac_pi/alpha_loss     | 0.4237382  |
| training/sac_pi/logp_pi        | 3.93386    |
| training/sac_pi/pi_entropy     | 3.6365402  |
| training/sac_pi/pi_global_norm | 1.951687   |
| training/sac_pi/policy_loss    | -212.0583  |
| training/sac_pi/std            | 0.50005835 |
| training/sac_pi/valid_num      | 5028.0     |
| training/sac_Q/q1              | 207.69283  |
| training/sac_Q/q2              | 207.81055  |
| training/sac_Q/q2_loss         | 112.353645 |
| training/sac_Q/q_global_norm   | 360.25452  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16576828 |
| epoch                          | 216        |
| evaluation/episode-length-avg  | 226        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 134        |
| evaluation/episode-length-std  | 258        |
| evaluation/return-average      | 841.61816  |
| evaluation/return-max          | 4992.876   |
| evaluation/return-min          | 347.57086  |
| evaluation/return-std          | 1383.9185  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46224      |
| perf/AverageLength             | 226        |
| perf/AverageReturn             | 841.61816  |
| perf/NormalizedReturn          | 0.183      |
| Q-avg                          | 218.27959  |
| Q-std                          | 91.515945  |
| Q_loss                         | 104.29437  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 216        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000577   |
| times/evaluation_paths         | 9.02       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 60         |
| timestep                       | 1000       |
| timesteps_total                | 217000     |
| train-steps                    | 217000     |
| training/Q/q1_loss             | 73.87532   |
| training/sac_pi/alpha          | 0.16571051 |
| training/sac_pi/alpha_loss     | 0.31637248 |
| training/sac_pi/logp_pi        | 4.4566417  |
| training/sac_pi/pi_entropy     | 3.709692   |
| training/sac_pi/pi_global_norm | 1.70081    |
| training/sac_pi/policy_loss    | -217.99237 |
| training/sac_pi/std            | 0.52538043 |
| training/sac_pi/valid_num      | 4919.0     |
| training/sac_Q/q1              | 206.63916  |
| training/sac_Q/q2              | 209.1014   |
| training/sac_Q/q2_loss         | 73.057304  |
| training/sac_Q/q_global_norm   | 235.6947   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16299985  |
| epoch                          | 217         |
| evaluation/episode-length-avg  | 892         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 448         |
| evaluation/episode-length-std  | 215         |
| evaluation/return-average      | 4409.921    |
| evaluation/return-max          | 5159.326    |
| evaluation/return-min          | 1983.1118   |
| evaluation/return-std          | 1198.0209   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46135       |
| perf/AverageLength             | 892         |
| perf/AverageReturn             | 4409.921    |
| perf/NormalizedReturn          | 0.96        |
| Q-avg                          | 203.97583   |
| Q-std                          | 97.68965    |
| Q_loss                         | 102.72188   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 217         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000276    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000556    |
| times/evaluation_paths         | 31.1        |
| times/timestep_after_hook      | 0.00382     |
| times/timestep_before_hook     | 0.00871     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 218000      |
| train-steps                    | 218000      |
| training/Q/q1_loss             | 104.14734   |
| training/sac_pi/alpha          | 0.16296226  |
| training/sac_pi/alpha_loss     | -0.27098534 |
| training/sac_pi/logp_pi        | 4.1301084   |
| training/sac_pi/pi_entropy     | 3.6717668   |
| training/sac_pi/pi_global_norm | 1.8915919   |
| training/sac_pi/policy_loss    | -218.79854  |
| training/sac_pi/std            | 0.51512694  |
| training/sac_pi/valid_num      | 4942.0      |
| training/sac_Q/q1              | 210.16235   |
| training/sac_Q/q2              | 210.53592   |
| training/sac_Q/q2_loss         | 104.004616  |
| training/sac_Q/q_global_norm   | 249.24147   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16601555  |
| epoch                          | 218         |
| evaluation/episode-length-avg  | 250         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 160         |
| evaluation/episode-length-std  | 250         |
| evaluation/return-average      | 1001.6637   |
| evaluation/return-max          | 5319.1914   |
| evaluation/return-min          | 502.25787   |
| evaluation/return-std          | 1439.239    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 81.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46270       |
| perf/AverageLength             | 250         |
| perf/AverageReturn             | 1001.6637   |
| perf/NormalizedReturn          | 0.218       |
| Q-avg                          | 208.67757   |
| Q-std                          | 100.186226  |
| Q_loss                         | 108.00902   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 218         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000451    |
| times/evaluation_paths         | 9.64        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00839     |
| times/train                    | 59.8        |
| timestep                       | 1000        |
| timesteps_total                | 219000      |
| train-steps                    | 219000      |
| training/Q/q1_loss             | 116.22413   |
| training/sac_pi/alpha          | 0.16601497  |
| training/sac_pi/alpha_loss     | -0.34124792 |
| training/sac_pi/logp_pi        | 4.2460947   |
| training/sac_pi/pi_entropy     | 3.4794648   |
| training/sac_pi/pi_global_norm | 2.0575702   |
| training/sac_pi/policy_loss    | -221.47365  |
| training/sac_pi/std            | 0.49927378  |
| training/sac_pi/valid_num      | 4962.0      |
| training/sac_Q/q1              | 212.43918   |
| training/sac_Q/q2              | 213.91528   |
| training/sac_Q/q2_loss         | 116.516716  |
| training/sac_Q/q_global_norm   | 268.67975   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16432284  |
| epoch                          | 219         |
| evaluation/episode-length-avg  | 497         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 159         |
| evaluation/episode-length-std  | 411         |
| evaluation/return-average      | 2273.2026   |
| evaluation/return-max          | 4949.0923   |
| evaluation/return-min          | 490.0913    |
| evaluation/return-std          | 2177.966    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46204       |
| perf/AverageLength             | 497         |
| perf/AverageReturn             | 2273.2026   |
| perf/NormalizedReturn          | 0.495       |
| Q-avg                          | 215.63596   |
| Q-std                          | 96.269394   |
| Q_loss                         | 78.96558    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 219         |
| times/epoch_after_hook         | 1.61e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000511    |
| times/evaluation_paths         | 18.2        |
| times/timestep_after_hook      | 0.00378     |
| times/timestep_before_hook     | 0.00852     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 220000      |
| train-steps                    | 220000      |
| training/Q/q1_loss             | 80.39539    |
| training/sac_pi/alpha          | 0.16431923  |
| training/sac_pi/alpha_loss     | 0.015422349 |
| training/sac_pi/logp_pi        | 3.3439648   |
| training/sac_pi/pi_entropy     | 3.5500522   |
| training/sac_pi/pi_global_norm | 1.8464994   |
| training/sac_pi/policy_loss    | -212.76831  |
| training/sac_pi/std            | 0.46778482  |
| training/sac_pi/valid_num      | 5030.0      |
| training/sac_Q/q1              | 209.9158    |
| training/sac_Q/q2              | 209.62227   |
| training/sac_Q/q2_loss         | 80.36026    |
| training/sac_Q/q_global_norm   | 346.1981    |
---------------------------------------------------------------------------------
[WARN] 220 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.1682344  |
| epoch                          | 220        |
| evaluation/episode-length-avg  | 854        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 123        |
| evaluation/episode-length-std  | 300        |
| evaluation/return-average      | 4006.2173  |
| evaluation/return-max          | 4860.5703  |
| evaluation/return-min          | 255.94304  |
| evaluation/return-std          | 1593.8943  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46141      |
| perf/AverageLength             | 854        |
| perf/AverageReturn             | 4006.2173  |
| perf/NormalizedReturn          | 0.872      |
| Q-avg                          | 203.6398   |
| Q-std                          | 109.474144 |
| Q_loss                         | 106.57403  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 220        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000551   |
| times/evaluation_paths         | 31.6       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00853    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 221000     |
| train-steps                    | 221000     |
| training/Q/q1_loss             | 110.79616  |
| training/sac_pi/alpha          | 0.16821128 |
| training/sac_pi/alpha_loss     | 0.1765681  |
| training/sac_pi/logp_pi        | 3.622895   |
| training/sac_pi/pi_entropy     | 3.3294425  |
| training/sac_pi/pi_global_norm | 2.5436606  |
| training/sac_pi/policy_loss    | -224.40439 |
| training/sac_pi/std            | 0.46008846 |
| training/sac_pi/valid_num      | 4999.0     |
| training/sac_Q/q1              | 218.89404  |
| training/sac_Q/q2              | 219.38745  |
| training/sac_Q/q2_loss         | 110.30093  |
| training/sac_Q/q_global_norm   | 342.83237  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16918583 |
| epoch                          | 221        |
| evaluation/episode-length-avg  | 155        |
| evaluation/episode-length-max  | 159        |
| evaluation/episode-length-min  | 151        |
| evaluation/episode-length-std  | 2.24       |
| evaluation/return-average      | 504.10968  |
| evaluation/return-max          | 518.1764   |
| evaluation/return-min          | 486.8999   |
| evaluation/return-std          | 10.695037  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46183      |
| perf/AverageLength             | 155        |
| perf/AverageReturn             | 504.10968  |
| perf/NormalizedReturn          | 0.109      |
| Q-avg                          | 204.51184  |
| Q-std                          | 101.672356 |
| Q_loss                         | 120.858116 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 221        |
| times/epoch_after_hook         | 1.62e-06   |
| times/epoch_before_hook        | 0.000339   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000775   |
| times/evaluation_paths         | 5.2        |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 222000     |
| train-steps                    | 222000     |
| training/Q/q1_loss             | 96.26847   |
| training/sac_pi/alpha          | 0.16915435 |
| training/sac_pi/alpha_loss     | 0.2813819  |
| training/sac_pi/logp_pi        | 3.952914   |
| training/sac_pi/pi_entropy     | 3.6070793  |
| training/sac_pi/pi_global_norm | 1.852245   |
| training/sac_pi/policy_loss    | -214.66805 |
| training/sac_pi/std            | 0.49141824 |
| training/sac_pi/valid_num      | 5010.0     |
| training/sac_Q/q1              | 209.83891  |
| training/sac_Q/q2              | 210.35066  |
| training/sac_Q/q2_loss         | 96.92933   |
| training/sac_Q/q_global_norm   | 276.84576  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16993366 |
| epoch                          | 222        |
| evaluation/episode-length-avg  | 733        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 275        |
| evaluation/episode-length-std  | 333        |
| evaluation/return-average      | 3310.3823  |
| evaluation/return-max          | 4772.0977  |
| evaluation/return-min          | 950.47546  |
| evaluation/return-std          | 1724.0538  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46141      |
| perf/AverageLength             | 733        |
| perf/AverageReturn             | 3310.3823  |
| perf/NormalizedReturn          | 0.721      |
| Q-avg                          | 199.5837   |
| Q-std                          | 105.38323  |
| Q_loss                         | 109.169525 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 222        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 8.19e-05   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000509   |
| times/evaluation_paths         | 26.2       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 223000     |
| train-steps                    | 223000     |
| training/Q/q1_loss             | 84.03627   |
| training/sac_pi/alpha          | 0.16991355 |
| training/sac_pi/alpha_loss     | 0.2674432  |
| training/sac_pi/logp_pi        | 3.9961414  |
| training/sac_pi/pi_entropy     | 3.5378063  |
| training/sac_pi/pi_global_norm | 1.9588789  |
| training/sac_pi/policy_loss    | -218.29912 |
| training/sac_pi/std            | 0.48363814 |
| training/sac_pi/valid_num      | 5000.0     |
| training/sac_Q/q1              | 213.56143  |
| training/sac_Q/q2              | 214.03535  |
| training/sac_Q/q2_loss         | 84.10273   |
| training/sac_Q/q_global_norm   | 274.75848  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16659096 |
| epoch                          | 223        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4861.324   |
| evaluation/return-max          | 4897.7295  |
| evaluation/return-min          | 4830.448   |
| evaluation/return-std          | 20.4042    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46108      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4861.324   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 201.65804  |
| Q-std                          | 112.454636 |
| Q_loss                         | 122.086006 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 223        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000108   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000607   |
| times/evaluation_paths         | 36.1       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00882    |
| times/train                    | 60.2       |
| timestep                       | 1000       |
| timesteps_total                | 224000     |
| train-steps                    | 224000     |
| training/Q/q1_loss             | 107.19958  |
| training/sac_pi/alpha          | 0.16657373 |
| training/sac_pi/alpha_loss     | 0.1305093  |
| training/sac_pi/logp_pi        | 4.2272024  |
| training/sac_pi/pi_entropy     | 3.8145242  |
| training/sac_pi/pi_global_norm | 1.7464159  |
| training/sac_pi/policy_loss    | -203.14563 |
| training/sac_pi/std            | 0.52687514 |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 195.8057   |
| training/sac_Q/q2              | 194.97424  |
| training/sac_Q/q2_loss         | 105.87723  |
| training/sac_Q/q_global_norm   | 241.84555  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.166266    |
| epoch                          | 224         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5167.495    |
| evaluation/return-max          | 5248.6846   |
| evaluation/return-min          | 5106.523    |
| evaluation/return-std          | 47.66854    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46191       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5167.495    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 199.07765   |
| Q-std                          | 110.18691   |
| Q_loss                         | 79.262474   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 224         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000602    |
| times/evaluation_paths         | 36.4        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00829     |
| times/train                    | 59.7        |
| timestep                       | 1000        |
| timesteps_total                | 225000      |
| train-steps                    | 225000      |
| training/Q/q1_loss             | 114.31843   |
| training/sac_pi/alpha          | 0.16628397  |
| training/sac_pi/alpha_loss     | -0.21344042 |
| training/sac_pi/logp_pi        | 3.5737522   |
| training/sac_pi/pi_entropy     | 3.6040833   |
| training/sac_pi/pi_global_norm | 2.0952845   |
| training/sac_pi/policy_loss    | -215.78806  |
| training/sac_pi/std            | 0.4913011   |
| training/sac_pi/valid_num      | 4969.0      |
| training/sac_Q/q1              | 209.17087   |
| training/sac_Q/q2              | 209.44547   |
| training/sac_Q/q2_loss         | 113.63497   |
| training/sac_Q/q_global_norm   | 372.9755    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.171053    |
| epoch                          | 225         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4917.965    |
| evaluation/return-max          | 4974.7104   |
| evaluation/return-min          | 4863.619    |
| evaluation/return-std          | 37.37854    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.96        |
| model/origin_ret               | 83.8        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46169       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4917.965    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 204.3706    |
| Q-std                          | 97.12597    |
| Q_loss                         | 98.95192    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 225         |
| times/epoch_after_hook         | 1.96e-06    |
| times/epoch_before_hook        | 0.00028     |
| times/epoch_rollout_model      | 501         |
| times/evaluation_metrics       | 0.000698    |
| times/evaluation_paths         | 36          |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00854     |
| times/train                    | 60.1        |
| timestep                       | 1000        |
| timesteps_total                | 226000      |
| train-steps                    | 226000      |
| training/Q/q1_loss             | 93.1325     |
| training/sac_pi/alpha          | 0.17104256  |
| training/sac_pi/alpha_loss     | -0.23645107 |
| training/sac_pi/logp_pi        | 4.5698347   |
| training/sac_pi/pi_entropy     | 3.7421842   |
| training/sac_pi/pi_global_norm | 1.6067837   |
| training/sac_pi/policy_loss    | -216.53752  |
| training/sac_pi/std            | 0.54680276  |
| training/sac_pi/valid_num      | 4961.0      |
| training/sac_Q/q1              | 207.19539   |
| training/sac_Q/q2              | 207.9288    |
| training/sac_Q/q2_loss         | 93.11012    |
| training/sac_Q/q_global_norm   | 238.26186   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17222694  |
| epoch                          | 226         |
| evaluation/episode-length-avg  | 105         |
| evaluation/episode-length-max  | 108         |
| evaluation/episode-length-min  | 102         |
| evaluation/episode-length-std  | 2.49        |
| evaluation/return-average      | 233.92915   |
| evaluation/return-max          | 250.68329   |
| evaluation/return-min          | 218.0655    |
| evaluation/return-std          | 13.520162   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46008       |
| perf/AverageLength             | 105         |
| perf/AverageReturn             | 233.92915   |
| perf/NormalizedReturn          | 0.0506      |
| Q-avg                          | 211.48987   |
| Q-std                          | 89.308174   |
| Q_loss                         | 100.21323   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 226         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000152    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000447    |
| times/evaluation_paths         | 3.5         |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.0086      |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 227000      |
| train-steps                    | 227000      |
| training/Q/q1_loss             | 93.1224     |
| training/sac_pi/alpha          | 0.17220454  |
| training/sac_pi/alpha_loss     | -0.14085846 |
| training/sac_pi/logp_pi        | 4.2809663   |
| training/sac_pi/pi_entropy     | 3.6861496   |
| training/sac_pi/pi_global_norm | 2.254561    |
| training/sac_pi/policy_loss    | -218.0839   |
| training/sac_pi/std            | 0.52952933  |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 211.73677   |
| training/sac_Q/q2              | 212.7189    |
| training/sac_Q/q2_loss         | 91.75873    |
| training/sac_Q/q_global_norm   | 401.63922   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17291804 |
| epoch                          | 227        |
| evaluation/episode-length-avg  | 842        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 692        |
| evaluation/episode-length-std  | 101        |
| evaluation/return-average      | 3942.2239  |
| evaluation/return-max          | 4868.66    |
| evaluation/return-min          | 3141.6018  |
| evaluation/return-std          | 542.7115   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46226      |
| perf/AverageLength             | 842        |
| perf/AverageReturn             | 3942.2239  |
| perf/NormalizedReturn          | 0.858      |
| Q-avg                          | 205.40347  |
| Q-std                          | 106.08903  |
| Q_loss                         | 103.86854  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 227        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 8.61e-05   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000513   |
| times/evaluation_paths         | 29.3       |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.00853    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 228000     |
| train-steps                    | 228000     |
| training/Q/q1_loss             | 93.57303   |
| training/sac_pi/alpha          | 0.17285955 |
| training/sac_pi/alpha_loss     | 0.5441838  |
| training/sac_pi/logp_pi        | 4.2577085  |
| training/sac_pi/pi_entropy     | 3.5802531  |
| training/sac_pi/pi_global_norm | 1.5704597  |
| training/sac_pi/policy_loss    | -216.58513 |
| training/sac_pi/std            | 0.49546874 |
| training/sac_pi/valid_num      | 4984.0     |
| training/sac_Q/q1              | 208.56401  |
| training/sac_Q/q2              | 209.68369  |
| training/sac_Q/q2_loss         | 93.257866  |
| training/sac_Q/q_global_norm   | 305.95297  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17070659   |
| epoch                          | 228          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5035.993     |
| evaluation/return-max          | 5068.538     |
| evaluation/return-min          | 4972.1045    |
| evaluation/return-std          | 27.42441     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.12         |
| model/origin_ret               | 87.5         |
| model/penalty_ret              | 80.3         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46308        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5035.993     |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 204.15251    |
| Q-std                          | 106.70246    |
| Q_loss                         | 100.69415    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 228          |
| times/epoch_after_hook         | 1.68e-06     |
| times/epoch_before_hook        | 0.000124     |
| times/epoch_rollout_model      | 490          |
| times/evaluation_metrics       | 0.00055      |
| times/evaluation_paths         | 34.7         |
| times/timestep_after_hook      | 0.00365      |
| times/timestep_before_hook     | 0.00852      |
| times/train                    | 60.1         |
| timestep                       | 1000         |
| timesteps_total                | 229000       |
| train-steps                    | 229000       |
| training/Q/q1_loss             | 91.13959     |
| training/sac_pi/alpha          | 0.17070056   |
| training/sac_pi/alpha_loss     | -0.079511695 |
| training/sac_pi/logp_pi        | 3.8910306    |
| training/sac_pi/pi_entropy     | 3.749394     |
| training/sac_pi/pi_global_norm | 2.3360858    |
| training/sac_pi/policy_loss    | -208.17548   |
| training/sac_pi/std            | 0.5152829    |
| training/sac_pi/valid_num      | 4990.0       |
| training/sac_Q/q1              | 201.82889    |
| training/sac_Q/q2              | 202.17944    |
| training/sac_Q/q2_loss         | 91.67878     |
| training/sac_Q/q_global_norm   | 213.40366    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16275385  |
| epoch                          | 229         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4776.112    |
| evaluation/return-max          | 4828.944    |
| evaluation/return-min          | 4738.3457   |
| evaluation/return-std          | 31.04041    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46278       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4776.112    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 208.55437   |
| Q-std                          | 99.54269    |
| Q_loss                         | 103.729546  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 229         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000283    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000658    |
| times/evaluation_paths         | 36.3        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00841     |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 230000      |
| train-steps                    | 230000      |
| training/Q/q1_loss             | 100.97703   |
| training/sac_pi/alpha          | 0.16274883  |
| training/sac_pi/alpha_loss     | -0.12517056 |
| training/sac_pi/logp_pi        | 4.6412644   |
| training/sac_pi/pi_entropy     | 3.6353443   |
| training/sac_pi/pi_global_norm | 1.4560177   |
| training/sac_pi/policy_loss    | -212.00368  |
| training/sac_pi/std            | 0.5400896   |
| training/sac_pi/valid_num      | 4989.0      |
| training/sac_Q/q1              | 204.32082   |
| training/sac_Q/q2              | 206.41638   |
| training/sac_Q/q2_loss         | 101.47922   |
| training/sac_Q/q_global_norm   | 221.45448   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16680975   |
| epoch                          | 230          |
| evaluation/episode-length-avg  | 929          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 293          |
| evaluation/episode-length-std  | 212          |
| evaluation/return-average      | 4536.868     |
| evaluation/return-max          | 4951.397     |
| evaluation/return-min          | 1152.5432    |
| evaluation/return-std          | 1128.3676    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.03         |
| model/origin_ret               | 85.4         |
| model/penalty_ret              | 80.3         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46221        |
| perf/AverageLength             | 929          |
| perf/AverageReturn             | 4536.868     |
| perf/NormalizedReturn          | 0.988        |
| Q-avg                          | 206.48352    |
| Q-std                          | 99.71658     |
| Q_loss                         | 93.90322     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 230          |
| times/epoch_after_hook         | 1.85e-06     |
| times/epoch_before_hook        | 0.00013      |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.000527     |
| times/evaluation_paths         | 34.1         |
| times/timestep_after_hook      | 0.00373      |
| times/timestep_before_hook     | 0.00839      |
| times/train                    | 59.6         |
| timestep                       | 1000         |
| timesteps_total                | 231000       |
| train-steps                    | 231000       |
| training/Q/q1_loss             | 108.33243    |
| training/sac_pi/alpha          | 0.1667746    |
| training/sac_pi/alpha_loss     | -0.031425312 |
| training/sac_pi/logp_pi        | 3.968769     |
| training/sac_pi/pi_entropy     | 3.716903     |
| training/sac_pi/pi_global_norm | 1.9347751    |
| training/sac_pi/policy_loss    | -205.5761    |
| training/sac_pi/std            | 0.51583356   |
| training/sac_pi/valid_num      | 5012.0       |
| training/sac_Q/q1              | 200.40376    |
| training/sac_Q/q2              | 200.9002     |
| training/sac_Q/q2_loss         | 106.8228     |
| training/sac_Q/q_global_norm   | 268.22375    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16684233 |
| epoch                          | 231        |
| evaluation/episode-length-avg  | 869        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 477        |
| evaluation/episode-length-std  | 200        |
| evaluation/return-average      | 4155.948   |
| evaluation/return-max          | 4960.912   |
| evaluation/return-min          | 2081.2102  |
| evaluation/return-std          | 1071.6871  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46226      |
| perf/AverageLength             | 869        |
| perf/AverageReturn             | 4155.948   |
| perf/NormalizedReturn          | 0.905      |
| Q-avg                          | 213.61508  |
| Q-std                          | 90.954666  |
| Q_loss                         | 93.31722   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 231        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.0006     |
| times/evaluation_paths         | 30.3       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 232000     |
| train-steps                    | 232000     |
| training/Q/q1_loss             | 105.45594  |
| training/sac_pi/alpha          | 0.16682479 |
| training/sac_pi/alpha_loss     | 0.22480966 |
| training/sac_pi/logp_pi        | 4.0554004  |
| training/sac_pi/pi_entropy     | 3.738694   |
| training/sac_pi/pi_global_norm | 1.7102642  |
| training/sac_pi/policy_loss    | -204.9722  |
| training/sac_pi/std            | 0.50831693 |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 197.9639   |
| training/sac_Q/q2              | 198.65833  |
| training/sac_Q/q2_loss         | 105.73374  |
| training/sac_Q/q_global_norm   | 217.20284  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16702111 |
| epoch                          | 232        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4560.3154  |
| evaluation/return-max          | 4724.1323  |
| evaluation/return-min          | 4448.1875  |
| evaluation/return-std          | 78.94943   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46385      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4560.3154  |
| perf/NormalizedReturn          | 0.993      |
| Q-avg                          | 210.15604  |
| Q-std                          | 104.35581  |
| Q_loss                         | 89.00739   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 232        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000315   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000623   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00867    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 233000     |
| train-steps                    | 233000     |
| training/Q/q1_loss             | 92.51397   |
| training/sac_pi/alpha          | 0.16703694 |
| training/sac_pi/alpha_loss     | -0.3231098 |
| training/sac_pi/logp_pi        | 3.6293335  |
| training/sac_pi/pi_entropy     | 3.7356453  |
| training/sac_pi/pi_global_norm | 1.5106987  |
| training/sac_pi/policy_loss    | -210.8448  |
| training/sac_pi/std            | 0.5080589  |
| training/sac_pi/valid_num      | 5001.0     |
| training/sac_Q/q1              | 204.66617  |
| training/sac_Q/q2              | 205.94888  |
| training/sac_Q/q2_loss         | 92.51162   |
| training/sac_Q/q_global_norm   | 256.14352  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17093644  |
| epoch                          | 233         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4912.2354   |
| evaluation/return-max          | 4930.621    |
| evaluation/return-min          | 4879.114    |
| evaluation/return-std          | 13.260157   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46266       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4912.2354   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 206.717     |
| Q-std                          | 90.977104   |
| Q_loss                         | 92.793495   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 233         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000288    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000513    |
| times/evaluation_paths         | 35.2        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00864     |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 234000      |
| train-steps                    | 234000      |
| training/Q/q1_loss             | 99.10432    |
| training/sac_pi/alpha          | 0.17096592  |
| training/sac_pi/alpha_loss     | -0.11895631 |
| training/sac_pi/logp_pi        | 4.4735847   |
| training/sac_pi/pi_entropy     | 3.7964852   |
| training/sac_pi/pi_global_norm | 1.5447078   |
| training/sac_pi/policy_loss    | -211.69647  |
| training/sac_pi/std            | 0.5535554   |
| training/sac_pi/valid_num      | 4942.0      |
| training/sac_Q/q1              | 201.87541   |
| training/sac_Q/q2              | 203.83801   |
| training/sac_Q/q2_loss         | 100.61563   |
| training/sac_Q/q_global_norm   | 248.14928   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16774538 |
| epoch                          | 234        |
| evaluation/episode-length-avg  | 666        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 159        |
| evaluation/episode-length-std  | 409        |
| evaluation/return-average      | 3207.67    |
| evaluation/return-max          | 5024.645   |
| evaluation/return-min          | 491.18283  |
| evaluation/return-std          | 2198.527   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46190      |
| perf/AverageLength             | 666        |
| perf/AverageReturn             | 3207.67    |
| perf/NormalizedReturn          | 0.698      |
| Q-avg                          | 217.50183  |
| Q-std                          | 90.758514  |
| Q_loss                         | 101.27417  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 234        |
| times/epoch_after_hook         | 1.62e-06   |
| times/epoch_before_hook        | 0.000229   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.00057    |
| times/evaluation_paths         | 23.8       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 235000     |
| train-steps                    | 235000     |
| training/Q/q1_loss             | 107.204834 |
| training/sac_pi/alpha          | 0.16775925 |
| training/sac_pi/alpha_loss     | 0.19229703 |
| training/sac_pi/logp_pi        | 4.1984363  |
| training/sac_pi/pi_entropy     | 3.7536693  |
| training/sac_pi/pi_global_norm | 1.9070401  |
| training/sac_pi/policy_loss    | -217.92691 |
| training/sac_pi/std            | 0.5197966  |
| training/sac_pi/valid_num      | 4980.0     |
| training/sac_Q/q1              | 210.72636  |
| training/sac_Q/q2              | 211.62842  |
| training/sac_Q/q2_loss         | 106.01726  |
| training/sac_Q/q_global_norm   | 340.1504   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17510611 |
| epoch                          | 235        |
| evaluation/episode-length-avg  | 403        |
| evaluation/episode-length-max  | 433        |
| evaluation/episode-length-min  | 375        |
| evaluation/episode-length-std  | 16         |
| evaluation/return-average      | 1806.03    |
| evaluation/return-max          | 1985.0521  |
| evaluation/return-min          | 1622.5762  |
| evaluation/return-std          | 95.22946   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46294      |
| perf/AverageLength             | 403        |
| perf/AverageReturn             | 1806.03    |
| perf/NormalizedReturn          | 0.393      |
| Q-avg                          | 196.36267  |
| Q-std                          | 120.80878  |
| Q_loss                         | 96.77977   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 235        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000604   |
| times/evaluation_paths         | 14.9       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 236000     |
| train-steps                    | 236000     |
| training/Q/q1_loss             | 96.226425  |
| training/sac_pi/alpha          | 0.17508735 |
| training/sac_pi/alpha_loss     | 0.15843815 |
| training/sac_pi/logp_pi        | 3.552817   |
| training/sac_pi/pi_entropy     | 3.5766876  |
| training/sac_pi/pi_global_norm | 2.0646365  |
| training/sac_pi/policy_loss    | -219.96965 |
| training/sac_pi/std            | 0.47561896 |
| training/sac_pi/valid_num      | 5046.0     |
| training/sac_Q/q1              | 217.40836  |
| training/sac_Q/q2              | 217.94995  |
| training/sac_Q/q2_loss         | 97.31204   |
| training/sac_Q/q_global_norm   | 284.36636  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16476679 |
| epoch                          | 236        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5263.3164  |
| evaluation/return-max          | 5371.3135  |
| evaluation/return-min          | 5069.7563  |
| evaluation/return-std          | 76.604546  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46174      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5263.3164  |
| perf/NormalizedReturn          | 1.15       |
| Q-avg                          | 205.94414  |
| Q-std                          | 97.680374  |
| Q_loss                         | 116.25457  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 236        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000668   |
| times/evaluation_paths         | 34.3       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 237000     |
| train-steps                    | 237000     |
| training/Q/q1_loss             | 96.030106  |
| training/sac_pi/alpha          | 0.16474995 |
| training/sac_pi/alpha_loss     | 0.06459907 |
| training/sac_pi/logp_pi        | 3.7510433  |
| training/sac_pi/pi_entropy     | 3.667794   |
| training/sac_pi/pi_global_norm | 1.7716458  |
| training/sac_pi/policy_loss    | -211.9251  |
| training/sac_pi/std            | 0.5044037  |
| training/sac_pi/valid_num      | 4983.0     |
| training/sac_Q/q1              | 205.1976   |
| training/sac_Q/q2              | 206.96469  |
| training/sac_Q/q2_loss         | 95.81572   |
| training/sac_Q/q_global_norm   | 206.6234   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.171257    |
| epoch                          | 237         |
| evaluation/episode-length-avg  | 946         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 807         |
| evaluation/episode-length-std  | 70.6        |
| evaluation/return-average      | 4443.5405   |
| evaluation/return-max          | 4796.782    |
| evaluation/return-min          | 3761.2324   |
| evaluation/return-std          | 337.20166   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46009       |
| perf/AverageLength             | 946         |
| perf/AverageReturn             | 4443.5405   |
| perf/NormalizedReturn          | 0.968       |
| Q-avg                          | 196.40842   |
| Q-std                          | 104.38797   |
| Q_loss                         | 96.192345   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 237         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000333    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000601    |
| times/evaluation_paths         | 34.3        |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00839     |
| times/train                    | 60.2        |
| timestep                       | 1000        |
| timesteps_total                | 238000      |
| train-steps                    | 238000      |
| training/Q/q1_loss             | 79.339386   |
| training/sac_pi/alpha          | 0.17123736  |
| training/sac_pi/alpha_loss     | -0.22517946 |
| training/sac_pi/logp_pi        | 3.9009767   |
| training/sac_pi/pi_entropy     | 3.4895816   |
| training/sac_pi/pi_global_norm | 1.6850864   |
| training/sac_pi/policy_loss    | -216.94511  |
| training/sac_pi/std            | 0.4909112   |
| training/sac_pi/valid_num      | 4988.0      |
| training/sac_Q/q1              | 210.81978   |
| training/sac_Q/q2              | 212.91382   |
| training/sac_Q/q2_loss         | 80.18594    |
| training/sac_Q/q_global_norm   | 178.28603   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16923086  |
| epoch                          | 238         |
| evaluation/episode-length-avg  | 661         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 135         |
| evaluation/episode-length-std  | 303         |
| evaluation/return-average      | 3317.8267   |
| evaluation/return-max          | 5314.505    |
| evaluation/return-min          | 411.82635   |
| evaluation/return-std          | 1710.4335   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46297       |
| perf/AverageLength             | 661         |
| perf/AverageReturn             | 3317.8267   |
| perf/NormalizedReturn          | 0.722       |
| Q-avg                          | 201.11505   |
| Q-std                          | 107.805405  |
| Q_loss                         | 107.6703    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 238         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000154    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.00048     |
| times/evaluation_paths         | 23          |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 239000      |
| train-steps                    | 239000      |
| training/Q/q1_loss             | 117.88438   |
| training/sac_pi/alpha          | 0.16926444  |
| training/sac_pi/alpha_loss     | -0.10162296 |
| training/sac_pi/logp_pi        | 4.3298807   |
| training/sac_pi/pi_entropy     | 3.7055829   |
| training/sac_pi/pi_global_norm | 1.5678778   |
| training/sac_pi/policy_loss    | -211.25269  |
| training/sac_pi/std            | 0.52753854  |
| training/sac_pi/valid_num      | 4974.0      |
| training/sac_Q/q1              | 203.37608   |
| training/sac_Q/q2              | 204.15622   |
| training/sac_Q/q2_loss         | 119.22311   |
| training/sac_Q/q_global_norm   | 294.2526    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16840552 |
| epoch                          | 239        |
| evaluation/episode-length-avg  | 662        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 147        |
| evaluation/episode-length-std  | 415        |
| evaluation/return-average      | 3069.0508  |
| evaluation/return-max          | 4922.5664  |
| evaluation/return-min          | 455.47504  |
| evaluation/return-std          | 2118.1304  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46200      |
| perf/AverageLength             | 662        |
| perf/AverageReturn             | 3069.0508  |
| perf/NormalizedReturn          | 0.668      |
| Q-avg                          | 206.13663  |
| Q-std                          | 105.53195  |
| Q_loss                         | 84.66685   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 239        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.00011    |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000557   |
| times/evaluation_paths         | 23.6       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 240000     |
| train-steps                    | 240000     |
| training/Q/q1_loss             | 91.701385  |
| training/sac_pi/alpha          | 0.16845107 |
| training/sac_pi/alpha_loss     | 0.07333921 |
| training/sac_pi/logp_pi        | 4.338732   |
| training/sac_pi/pi_entropy     | 3.5278957  |
| training/sac_pi/pi_global_norm | 1.9544623  |
| training/sac_pi/policy_loss    | -211.90013 |
| training/sac_pi/std            | 0.50867325 |
| training/sac_pi/valid_num      | 4970.0     |
| training/sac_Q/q1              | 203.36537  |
| training/sac_Q/q2              | 205.16544  |
| training/sac_Q/q2_loss         | 92.42028   |
| training/sac_Q/q_global_norm   | 228.79605  |
--------------------------------------------------------------------------------
[WARN] 240 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.17194778 |
| epoch                          | 240        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4844.241   |
| evaluation/return-max          | 4916.725   |
| evaluation/return-min          | 4798.385   |
| evaluation/return-std          | 37.61839   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 83.8       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46225      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4844.241   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 200.52386  |
| Q-std                          | 109.21869  |
| Q_loss                         | 105.53785  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 240        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000622   |
| times/evaluation_paths         | 35.4       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00865    |
| times/train                    | 62.1       |
| timestep                       | 1000       |
| timesteps_total                | 241000     |
| train-steps                    | 241000     |
| training/Q/q1_loss             | 94.51716   |
| training/sac_pi/alpha          | 0.17193519 |
| training/sac_pi/alpha_loss     | -0.141554  |
| training/sac_pi/logp_pi        | 3.2402375  |
| training/sac_pi/pi_entropy     | 3.3685164  |
| training/sac_pi/pi_global_norm | 2.8942115  |
| training/sac_pi/policy_loss    | -212.5591  |
| training/sac_pi/std            | 0.4520503  |
| training/sac_pi/valid_num      | 5066.0     |
| training/sac_Q/q1              | 210.77872  |
| training/sac_Q/q2              | 210.65659  |
| training/sac_Q/q2_loss         | 94.98756   |
| training/sac_Q/q_global_norm   | 212.6978   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17670423   |
| epoch                          | 241          |
| evaluation/episode-length-avg  | 320          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 139          |
| evaluation/episode-length-std  | 340          |
| evaluation/return-average      | 1319.6946    |
| evaluation/return-max          | 5045.7646    |
| evaluation/return-min          | 355.33258    |
| evaluation/return-std          | 1847.3574    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 2.99         |
| model/origin_ret               | 84.4         |
| model/penalty_ret              | 79.7         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46293        |
| perf/AverageLength             | 320          |
| perf/AverageReturn             | 1319.6946    |
| perf/NormalizedReturn          | 0.287        |
| Q-avg                          | 203.66516    |
| Q-std                          | 91.17313     |
| Q_loss                         | 92.11763     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 241          |
| times/epoch_after_hook         | 1.84e-06     |
| times/epoch_before_hook        | 0.000324     |
| times/epoch_rollout_model      | 487          |
| times/evaluation_metrics       | 0.000655     |
| times/evaluation_paths         | 12.3         |
| times/timestep_after_hook      | 0.00371      |
| times/timestep_before_hook     | 0.00833      |
| times/train                    | 59.9         |
| timestep                       | 1000         |
| timesteps_total                | 242000       |
| train-steps                    | 242000       |
| training/Q/q1_loss             | 89.48905     |
| training/sac_pi/alpha          | 0.17669573   |
| training/sac_pi/alpha_loss     | -0.000717194 |
| training/sac_pi/logp_pi        | 3.8737426    |
| training/sac_pi/pi_entropy     | 3.9097283    |
| training/sac_pi/pi_global_norm | 2.0293038    |
| training/sac_pi/policy_loss    | -214.01271   |
| training/sac_pi/std            | 0.5321603    |
| training/sac_pi/valid_num      | 4934.0       |
| training/sac_Q/q1              | 205.65799    |
| training/sac_Q/q2              | 206.99536    |
| training/sac_Q/q2_loss         | 89.341324    |
| training/sac_Q/q_global_norm   | 185.23286    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17064244   |
| epoch                          | 242          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4934.4155    |
| evaluation/return-max          | 4965.499     |
| evaluation/return-min          | 4892.3267    |
| evaluation/return-std          | 18.098225    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.09         |
| model/origin_ret               | 86.1         |
| model/penalty_ret              | 79.6         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46345        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4934.4155    |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 198.91476    |
| Q-std                          | 101.28302    |
| Q_loss                         | 101.712105   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 242          |
| times/epoch_after_hook         | 1.75e-06     |
| times/epoch_before_hook        | 0.000128     |
| times/epoch_rollout_model      | 482          |
| times/evaluation_metrics       | 0.000529     |
| times/evaluation_paths         | 36.5         |
| times/timestep_after_hook      | 0.00369      |
| times/timestep_before_hook     | 0.0107       |
| times/train                    | 60.4         |
| timestep                       | 1000         |
| timesteps_total                | 243000       |
| train-steps                    | 243000       |
| training/Q/q1_loss             | 91.263466    |
| training/sac_pi/alpha          | 0.17060328   |
| training/sac_pi/alpha_loss     | -0.075812645 |
| training/sac_pi/logp_pi        | 4.2594757    |
| training/sac_pi/pi_entropy     | 3.5686755    |
| training/sac_pi/pi_global_norm | 1.7897996    |
| training/sac_pi/policy_loss    | -215.10559   |
| training/sac_pi/std            | 0.5054891    |
| training/sac_pi/valid_num      | 4984.0       |
| training/sac_Q/q1              | 208.81754    |
| training/sac_Q/q2              | 210.62642    |
| training/sac_Q/q2_loss         | 92.13536     |
| training/sac_Q/q_global_norm   | 218.66496    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16995984  |
| epoch                          | 243         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5176.536    |
| evaluation/return-max          | 5208.444    |
| evaluation/return-min          | 5151.2866   |
| evaluation/return-std          | 17.210379   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46123       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5176.536    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 205.59892   |
| Q-std                          | 94.407845   |
| Q_loss                         | 87.708855   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 243         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000787    |
| times/evaluation_paths         | 35.5        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00861     |
| times/train                    | 62.8        |
| timestep                       | 1000        |
| timesteps_total                | 244000      |
| train-steps                    | 244000      |
| training/Q/q1_loss             | 76.95245    |
| training/sac_pi/alpha          | 0.16993034  |
| training/sac_pi/alpha_loss     | -0.21595803 |
| training/sac_pi/logp_pi        | 3.3623276   |
| training/sac_pi/pi_entropy     | 3.63792     |
| training/sac_pi/pi_global_norm | 1.621979    |
| training/sac_pi/policy_loss    | -224.7213   |
| training/sac_pi/std            | 0.48099002  |
| training/sac_pi/valid_num      | 5008.0      |
| training/sac_Q/q1              | 220.15239   |
| training/sac_Q/q2              | 220.36496   |
| training/sac_Q/q2_loss         | 76.56954    |
| training/sac_Q/q_global_norm   | 303.01697   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16494255 |
| epoch                          | 244        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5009.585   |
| evaluation/return-max          | 5088.8184  |
| evaluation/return-min          | 4808.1655  |
| evaluation/return-std          | 79.445915  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46289      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5009.585   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 209.11044  |
| Q-std                          | 96.02298   |
| Q_loss                         | 78.28429   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 244        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000166   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000857   |
| times/evaluation_paths         | 37.4       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 245000     |
| train-steps                    | 245000     |
| training/Q/q1_loss             | 89.76934   |
| training/sac_pi/alpha          | 0.16490881 |
| training/sac_pi/alpha_loss     | 0.14387584 |
| training/sac_pi/logp_pi        | 4.460478   |
| training/sac_pi/pi_entropy     | 3.586203   |
| training/sac_pi/pi_global_norm | 2.198301   |
| training/sac_pi/policy_loss    | -215.77422 |
| training/sac_pi/std            | 0.5223314  |
| training/sac_pi/valid_num      | 4915.0     |
| training/sac_Q/q1              | 203.76834  |
| training/sac_Q/q2              | 206.2065   |
| training/sac_Q/q2_loss         | 90.27069   |
| training/sac_Q/q_global_norm   | 224.36201  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16101316 |
| epoch                          | 245        |
| evaluation/episode-length-avg  | 929        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 561        |
| evaluation/episode-length-std  | 147        |
| evaluation/return-average      | 4383.12    |
| evaluation/return-max          | 4929.3286  |
| evaluation/return-min          | 2449.6465  |
| evaluation/return-std          | 780.37537  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46347      |
| perf/AverageLength             | 929        |
| perf/AverageReturn             | 4383.12    |
| perf/NormalizedReturn          | 0.954      |
| Q-avg                          | 199.61905  |
| Q-std                          | 96.63312   |
| Q_loss                         | 112.429886 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 245        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000319   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000808   |
| times/evaluation_paths         | 32.5       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 61.5       |
| timestep                       | 1000       |
| timesteps_total                | 246000     |
| train-steps                    | 246000     |
| training/Q/q1_loss             | 115.52441  |
| training/sac_pi/alpha          | 0.16099894 |
| training/sac_pi/alpha_loss     | 0.233267   |
| training/sac_pi/logp_pi        | 5.1016855  |
| training/sac_pi/pi_entropy     | 3.48169    |
| training/sac_pi/pi_global_norm | 1.6590406  |
| training/sac_pi/policy_loss    | -215.9207  |
| training/sac_pi/std            | 0.5263959  |
| training/sac_pi/valid_num      | 4934.0     |
| training/sac_Q/q1              | 206.37378  |
| training/sac_Q/q2              | 208.74918  |
| training/sac_Q/q2_loss         | 115.35478  |
| training/sac_Q/q_global_norm   | 276.50302  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16652684  |
| epoch                          | 246         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4740.571    |
| evaluation/return-max          | 4759.0967   |
| evaluation/return-min          | 4718.8516   |
| evaluation/return-std          | 13.609857   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 81.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46277       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4740.571    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 222.12224   |
| Q-std                          | 79.25306    |
| Q_loss                         | 89.63978    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 246         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000158    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000551    |
| times/evaluation_paths         | 36.4        |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 247000      |
| train-steps                    | 247000      |
| training/Q/q1_loss             | 103.35985   |
| training/sac_pi/alpha          | 0.16650863  |
| training/sac_pi/alpha_loss     | 0.089621834 |
| training/sac_pi/logp_pi        | 3.7129111   |
| training/sac_pi/pi_entropy     | 3.4768596   |
| training/sac_pi/pi_global_norm | 1.6225586   |
| training/sac_pi/policy_loss    | -209.55199  |
| training/sac_pi/std            | 0.47934702  |
| training/sac_pi/valid_num      | 5028.0      |
| training/sac_Q/q1              | 205.72134   |
| training/sac_Q/q2              | 206.77188   |
| training/sac_Q/q2_loss         | 103.71026   |
| training/sac_Q/q_global_norm   | 325.07367   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1673848   |
| epoch                          | 247         |
| evaluation/episode-length-avg  | 916         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 164         |
| evaluation/episode-length-std  | 251         |
| evaluation/return-average      | 4455.2705   |
| evaluation/return-max          | 4967.6133   |
| evaluation/return-min          | 534.3607    |
| evaluation/return-std          | 1308.2214   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.92        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46154       |
| perf/AverageLength             | 916         |
| perf/AverageReturn             | 4455.2705   |
| perf/NormalizedReturn          | 0.97        |
| Q-avg                          | 209.50188   |
| Q-std                          | 83.98965    |
| Q_loss                         | 97.44346    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 247         |
| times/epoch_after_hook         | 2.04e-06    |
| times/epoch_before_hook        | 0.000181    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000596    |
| times/evaluation_paths         | 31.6        |
| times/timestep_after_hook      | 0.00376     |
| times/timestep_before_hook     | 0.00877     |
| times/train                    | 62.3        |
| timestep                       | 1000        |
| timesteps_total                | 248000      |
| train-steps                    | 248000      |
| training/Q/q1_loss             | 89.11678    |
| training/sac_pi/alpha          | 0.16740827  |
| training/sac_pi/alpha_loss     | -0.64927745 |
| training/sac_pi/logp_pi        | 3.4137692   |
| training/sac_pi/pi_entropy     | 3.4309986   |
| training/sac_pi/pi_global_norm | 1.7147181   |
| training/sac_pi/policy_loss    | -215.17535  |
| training/sac_pi/std            | 0.48656502  |
| training/sac_pi/valid_num      | 5029.0      |
| training/sac_Q/q1              | 209.71683   |
| training/sac_Q/q2              | 210.94453   |
| training/sac_Q/q2_loss         | 88.25645    |
| training/sac_Q/q_global_norm   | 356.06638   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17271133  |
| epoch                          | 248         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4981.0723   |
| evaluation/return-max          | 5108.064    |
| evaluation/return-min          | 4921.4893   |
| evaluation/return-std          | 49.928635   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46182       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4981.0723   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 206.50186   |
| Q-std                          | 96.35033    |
| Q_loss                         | 99.220634   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 248         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.00058     |
| times/evaluation_paths         | 37.7        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00861     |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 249000      |
| train-steps                    | 249000      |
| training/Q/q1_loss             | 94.64438    |
| training/sac_pi/alpha          | 0.17274782  |
| training/sac_pi/alpha_loss     | -0.27801713 |
| training/sac_pi/logp_pi        | 4.079783    |
| training/sac_pi/pi_entropy     | 3.7252548   |
| training/sac_pi/pi_global_norm | 1.5561305   |
| training/sac_pi/policy_loss    | -216.06914  |
| training/sac_pi/std            | 0.5206297   |
| training/sac_pi/valid_num      | 4979.0      |
| training/sac_Q/q1              | 206.6914    |
| training/sac_Q/q2              | 209.06223   |
| training/sac_Q/q2_loss         | 94.23553    |
| training/sac_Q/q_global_norm   | 195.96019   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.171072   |
| epoch                          | 249        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5137.4385  |
| evaluation/return-max          | 5200.876   |
| evaluation/return-min          | 5063.1724  |
| evaluation/return-std          | 41.165916  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46148      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5137.4385  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 203.28911  |
| Q-std                          | 94.50923   |
| Q_loss                         | 99.36461   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 249        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000311   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000568   |
| times/evaluation_paths         | 36.6       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00878    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 250000     |
| train-steps                    | 250000     |
| training/Q/q1_loss             | 94.3542    |
| training/sac_pi/alpha          | 0.17103188 |
| training/sac_pi/alpha_loss     | 0.15806344 |
| training/sac_pi/logp_pi        | 4.6946726  |
| training/sac_pi/pi_entropy     | 3.6273124  |
| training/sac_pi/pi_global_norm | 1.895781   |
| training/sac_pi/policy_loss    | -219.16014 |
| training/sac_pi/std            | 0.5305368  |
| training/sac_pi/valid_num      | 4926.0     |
| training/sac_Q/q1              | 207.69807  |
| training/sac_Q/q2              | 209.94331  |
| training/sac_Q/q2_loss         | 93.37975   |
| training/sac_Q/q_global_norm   | 228.09966  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16743025 |
| epoch                          | 250        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5207.1416  |
| evaluation/return-max          | 5230.1123  |
| evaluation/return-min          | 5170.2324  |
| evaluation/return-std          | 17.005985  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46264      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5207.1416  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 208.90585  |
| Q-std                          | 102.895584 |
| Q_loss                         | 83.91136   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 250        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000548   |
| times/evaluation_paths         | 36.5       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00855    |
| times/train                    | 62.2       |
| timestep                       | 1000       |
| timesteps_total                | 251000     |
| train-steps                    | 251000     |
| training/Q/q1_loss             | 108.70008  |
| training/sac_pi/alpha          | 0.16739285 |
| training/sac_pi/alpha_loss     | 0.37640104 |
| training/sac_pi/logp_pi        | 4.7294564  |
| training/sac_pi/pi_entropy     | 3.844133   |
| training/sac_pi/pi_global_norm | 1.766003   |
| training/sac_pi/policy_loss    | -209.15784 |
| training/sac_pi/std            | 0.5597518  |
| training/sac_pi/valid_num      | 4944.0     |
| training/sac_Q/q1              | 198.49701  |
| training/sac_Q/q2              | 201.42221  |
| training/sac_Q/q2_loss         | 107.651146 |
| training/sac_Q/q_global_norm   | 266.29102  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16426459 |
| epoch                          | 251        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 1063.3923  |
| evaluation/return-max          | 1066.0972  |
| evaluation/return-min          | 1060.5806  |
| evaluation/return-std          | 1.7651879  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.17       |
| model/origin_ret               | 87.4       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46301      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 1063.3923  |
| perf/NormalizedReturn          | 0.231      |
| Q-avg                          | 204.26996  |
| Q-std                          | 94.7665    |
| Q_loss                         | 101.039185 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 251        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000557   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00844    |
| times/train                    | 62.9       |
| timestep                       | 1000       |
| timesteps_total                | 252000     |
| train-steps                    | 252000     |
| training/Q/q1_loss             | 124.15843  |
| training/sac_pi/alpha          | 0.16429028 |
| training/sac_pi/alpha_loss     | 0.4517042  |
| training/sac_pi/logp_pi        | 4.303485   |
| training/sac_pi/pi_entropy     | 3.388309   |
| training/sac_pi/pi_global_norm | 2.1638963  |
| training/sac_pi/policy_loss    | -213.71898 |
| training/sac_pi/std            | 0.48480493 |
| training/sac_pi/valid_num      | 5020.0     |
| training/sac_Q/q1              | 207.88203  |
| training/sac_Q/q2              | 209.82732  |
| training/sac_Q/q2_loss         | 123.46999  |
| training/sac_Q/q_global_norm   | 276.70346  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1664044  |
| epoch                          | 252        |
| evaluation/episode-length-avg  | 259        |
| evaluation/episode-length-max  | 784        |
| evaluation/episode-length-min  | 145        |
| evaluation/episode-length-std  | 187        |
| evaluation/return-average      | 1039.0823  |
| evaluation/return-max          | 3786.1167  |
| evaluation/return-min          | 457.36447  |
| evaluation/return-std          | 972.9533   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 83.6       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46278      |
| perf/AverageLength             | 259        |
| perf/AverageReturn             | 1039.0823  |
| perf/NormalizedReturn          | 0.226      |
| Q-avg                          | 214.38367  |
| Q-std                          | 96.600105  |
| Q_loss                         | 96.7445    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 252        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000601   |
| times/evaluation_paths         | 10.3       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 61.5       |
| timestep                       | 1000       |
| timesteps_total                | 253000     |
| train-steps                    | 253000     |
| training/Q/q1_loss             | 88.07076   |
| training/sac_pi/alpha          | 0.16636744 |
| training/sac_pi/alpha_loss     | 0.13146156 |
| training/sac_pi/logp_pi        | 4.841384   |
| training/sac_pi/pi_entropy     | 3.5874772  |
| training/sac_pi/pi_global_norm | 1.613104   |
| training/sac_pi/policy_loss    | -210.20297 |
| training/sac_pi/std            | 0.5310686  |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 199.81017  |
| training/sac_Q/q2              | 202.35745  |
| training/sac_Q/q2_loss         | 88.10347   |
| training/sac_Q/q_global_norm   | 245.52287  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16657872  |
| epoch                          | 253         |
| evaluation/episode-length-avg  | 154         |
| evaluation/episode-length-max  | 161         |
| evaluation/episode-length-min  | 142         |
| evaluation/episode-length-std  | 7.93        |
| evaluation/return-average      | 491.2397    |
| evaluation/return-max          | 519.87744   |
| evaluation/return-min          | 449.08948   |
| evaluation/return-std          | 26.586147   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46287       |
| perf/AverageLength             | 154         |
| perf/AverageReturn             | 491.2397    |
| perf/NormalizedReturn          | 0.107       |
| Q-avg                          | 207.54976   |
| Q-std                          | 97.03816    |
| Q_loss                         | 92.45027    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 253         |
| times/epoch_after_hook         | 3.07e-06    |
| times/epoch_before_hook        | 0.000295    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.00049     |
| times/evaluation_paths         | 5.21        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00863     |
| times/train                    | 62.6        |
| timestep                       | 1000        |
| timesteps_total                | 254000      |
| train-steps                    | 254000      |
| training/Q/q1_loss             | 86.71003    |
| training/sac_pi/alpha          | 0.1665832   |
| training/sac_pi/alpha_loss     | -0.35289454 |
| training/sac_pi/logp_pi        | 3.9674897   |
| training/sac_pi/pi_entropy     | 3.472269    |
| training/sac_pi/pi_global_norm | 1.6238682   |
| training/sac_pi/policy_loss    | -212.3689   |
| training/sac_pi/std            | 0.49503437  |
| training/sac_pi/valid_num      | 4971.0      |
| training/sac_Q/q1              | 203.47578   |
| training/sac_Q/q2              | 205.39188   |
| training/sac_Q/q2_loss         | 87.4758     |
| training/sac_Q/q_global_norm   | 186.55296   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16263872  |
| epoch                          | 254         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5009.723    |
| evaluation/return-max          | 5194.7314   |
| evaluation/return-min          | 4888.287    |
| evaluation/return-std          | 84.29002    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46093       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5009.723    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 209.05615   |
| Q-std                          | 94.849236   |
| Q_loss                         | 94.610985   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 254         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000147    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000593    |
| times/evaluation_paths         | 37          |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00868     |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 255000      |
| train-steps                    | 255000      |
| training/Q/q1_loss             | 106.383415  |
| training/sac_pi/alpha          | 0.16265485  |
| training/sac_pi/alpha_loss     | -0.11366665 |
| training/sac_pi/logp_pi        | 4.560196    |
| training/sac_pi/pi_entropy     | 3.7645936   |
| training/sac_pi/pi_global_norm | 1.8215352   |
| training/sac_pi/policy_loss    | -208.64146  |
| training/sac_pi/std            | 0.5621148   |
| training/sac_pi/valid_num      | 4910.0      |
| training/sac_Q/q1              | 197.1027    |
| training/sac_Q/q2              | 199.01854   |
| training/sac_Q/q2_loss         | 106.45582   |
| training/sac_Q/q_global_norm   | 256.60538   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17037578 |
| epoch                          | 255        |
| evaluation/episode-length-avg  | 143        |
| evaluation/episode-length-max  | 149        |
| evaluation/episode-length-min  | 141        |
| evaluation/episode-length-std  | 2.17       |
| evaluation/return-average      | 403.61688  |
| evaluation/return-max          | 415.7288   |
| evaluation/return-min          | 391.02148  |
| evaluation/return-std          | 8.617944   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 2.96       |
| model/origin_ret               | 83.2       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46192      |
| perf/AverageLength             | 143        |
| perf/AverageReturn             | 403.61688  |
| perf/NormalizedReturn          | 0.0876     |
| Q-avg                          | 210.50095  |
| Q-std                          | 98.283134  |
| Q_loss                         | 99.00876   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 255        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.00011    |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000555   |
| times/evaluation_paths         | 4.79       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 256000     |
| train-steps                    | 256000     |
| training/Q/q1_loss             | 111.08817  |
| training/sac_pi/alpha          | 0.17033221 |
| training/sac_pi/alpha_loss     | 0.6372524  |
| training/sac_pi/logp_pi        | 4.6373897  |
| training/sac_pi/pi_entropy     | 3.424974   |
| training/sac_pi/pi_global_norm | 1.9774301  |
| training/sac_pi/policy_loss    | -211.45592 |
| training/sac_pi/std            | 0.48838466 |
| training/sac_pi/valid_num      | 4991.0     |
| training/sac_Q/q1              | 203.59956  |
| training/sac_Q/q2              | 206.81381  |
| training/sac_Q/q2_loss         | 110.68527  |
| training/sac_Q/q_global_norm   | 345.77512  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17084368  |
| epoch                          | 256         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4731.538    |
| evaluation/return-max          | 4782.763    |
| evaluation/return-min          | 4616.039    |
| evaluation/return-std          | 55.001717   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 87.5        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46151       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4731.538    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 202.47578   |
| Q-std                          | 116.55354   |
| Q_loss                         | 102.56516   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 256         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000117    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000604    |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 257000      |
| train-steps                    | 257000      |
| training/Q/q1_loss             | 94.78547    |
| training/sac_pi/alpha          | 0.17086901  |
| training/sac_pi/alpha_loss     | -0.20898898 |
| training/sac_pi/logp_pi        | 3.6803672   |
| training/sac_pi/pi_entropy     | 3.556295    |
| training/sac_pi/pi_global_norm | 2.6266236   |
| training/sac_pi/policy_loss    | -220.28334  |
| training/sac_pi/std            | 0.49533275  |
| training/sac_pi/valid_num      | 4980.0      |
| training/sac_Q/q1              | 213.12534   |
| training/sac_Q/q2              | 213.3562    |
| training/sac_Q/q2_loss         | 93.15993    |
| training/sac_Q/q_global_norm   | 255.3401    |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16984156   |
| epoch                          | 257          |
| evaluation/episode-length-avg  | 816          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 374          |
| evaluation/episode-length-std  | 282          |
| evaluation/return-average      | 4029.0884    |
| evaluation/return-max          | 5201.696     |
| evaluation/return-min          | 1534.3164    |
| evaluation/return-std          | 1581.3064    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.1          |
| model/origin_ret               | 86.4         |
| model/penalty_ret              | 81           |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46318        |
| perf/AverageLength             | 816          |
| perf/AverageReturn             | 4029.0884    |
| perf/NormalizedReturn          | 0.877        |
| Q-avg                          | 209.51181    |
| Q-std                          | 99.98109     |
| Q_loss                         | 83.19619     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 257          |
| times/epoch_after_hook         | 1.93e-06     |
| times/epoch_before_hook        | 0.000276     |
| times/epoch_rollout_model      | 493          |
| times/evaluation_metrics       | 0.000814     |
| times/evaluation_paths         | 28.4         |
| times/timestep_after_hook      | 0.0038       |
| times/timestep_before_hook     | 0.0084       |
| times/train                    | 62.5         |
| timestep                       | 1000         |
| timesteps_total                | 258000       |
| train-steps                    | 258000       |
| training/Q/q1_loss             | 116.28908    |
| training/sac_pi/alpha          | 0.16986084   |
| training/sac_pi/alpha_loss     | -0.061679386 |
| training/sac_pi/logp_pi        | 4.1624794    |
| training/sac_pi/pi_entropy     | 3.6421993    |
| training/sac_pi/pi_global_norm | 1.7297397    |
| training/sac_pi/policy_loss    | -210.335     |
| training/sac_pi/std            | 0.5099002    |
| training/sac_pi/valid_num      | 4942.0       |
| training/sac_Q/q1              | 200.03906    |
| training/sac_Q/q2              | 202.44992    |
| training/sac_Q/q2_loss         | 116.68535    |
| training/sac_Q/q_global_norm   | 284.3312     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16952059 |
| epoch                          | 258        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5100.909   |
| evaluation/return-max          | 5164.3027  |
| evaluation/return-min          | 4976.425   |
| evaluation/return-std          | 49.685658  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46329      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5100.909   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 203.36205  |
| Q-std                          | 103.85386  |
| Q_loss                         | 86.58818   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 258        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000639   |
| times/evaluation_paths         | 37.2       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 259000     |
| train-steps                    | 259000     |
| training/Q/q1_loss             | 86.12621   |
| training/sac_pi/alpha          | 0.16947894 |
| training/sac_pi/alpha_loss     | 0.4076492  |
| training/sac_pi/logp_pi        | 4.1744537  |
| training/sac_pi/pi_entropy     | 3.7467914  |
| training/sac_pi/pi_global_norm | 1.7140887  |
| training/sac_pi/policy_loss    | -211.5879  |
| training/sac_pi/std            | 0.5130545  |
| training/sac_pi/valid_num      | 4987.0     |
| training/sac_Q/q1              | 205.1042   |
| training/sac_Q/q2              | 206.01074  |
| training/sac_Q/q2_loss         | 85.569115  |
| training/sac_Q/q_global_norm   | 234.69551  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1662511  |
| epoch                          | 259        |
| evaluation/episode-length-avg  | 145        |
| evaluation/episode-length-max  | 159        |
| evaluation/episode-length-min  | 140        |
| evaluation/episode-length-std  | 6.43       |
| evaluation/return-average      | 468.74628  |
| evaluation/return-max          | 522.9448   |
| evaluation/return-min          | 448.3794   |
| evaluation/return-std          | 24.800787  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46162      |
| perf/AverageLength             | 145        |
| perf/AverageReturn             | 468.74628  |
| perf/NormalizedReturn          | 0.102      |
| Q-avg                          | 210.15479  |
| Q-std                          | 92.842255  |
| Q_loss                         | 103.55377  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 259        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.00101    |
| times/evaluation_paths         | 4.85       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 260000     |
| train-steps                    | 260000     |
| training/Q/q1_loss             | 107.44228  |
| training/sac_pi/alpha          | 0.1662204  |
| training/sac_pi/alpha_loss     | 0.641957   |
| training/sac_pi/logp_pi        | 4.2074533  |
| training/sac_pi/pi_entropy     | 3.7159817  |
| training/sac_pi/pi_global_norm | 1.7781872  |
| training/sac_pi/policy_loss    | -209.07286 |
| training/sac_pi/std            | 0.5044765  |
| training/sac_pi/valid_num      | 5046.0     |
| training/sac_Q/q1              | 204.89421  |
| training/sac_Q/q2              | 206.10251  |
| training/sac_Q/q2_loss         | 106.77138  |
| training/sac_Q/q_global_norm   | 244.5581   |
--------------------------------------------------------------------------------
[WARN] 260 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.1665796   |
| epoch                          | 260         |
| evaluation/episode-length-avg  | 917         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 170         |
| evaluation/episode-length-std  | 249         |
| evaluation/return-average      | 4486.4346   |
| evaluation/return-max          | 5073.8623   |
| evaluation/return-min          | 459.5361    |
| evaluation/return-std          | 1344.5353   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.99        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46274       |
| perf/AverageLength             | 917         |
| perf/AverageReturn             | 4486.4346   |
| perf/NormalizedReturn          | 0.977       |
| Q-avg                          | 209.26595   |
| Q-std                          | 95.06042    |
| Q_loss                         | 120.0395    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 260         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000522    |
| times/evaluation_paths         | 32.7        |
| times/timestep_after_hook      | 0.00385     |
| times/timestep_before_hook     | 0.0093      |
| times/train                    | 62.6        |
| timestep                       | 1000        |
| timesteps_total                | 261000      |
| train-steps                    | 261000      |
| training/Q/q1_loss             | 110.20601   |
| training/sac_pi/alpha          | 0.16660132  |
| training/sac_pi/alpha_loss     | -0.30527243 |
| training/sac_pi/logp_pi        | 4.252614    |
| training/sac_pi/pi_entropy     | 3.83292     |
| training/sac_pi/pi_global_norm | 3.067339    |
| training/sac_pi/policy_loss    | -214.80865  |
| training/sac_pi/std            | 0.549044    |
| training/sac_pi/valid_num      | 4933.0      |
| training/sac_Q/q1              | 205.4283    |
| training/sac_Q/q2              | 206.3583    |
| training/sac_Q/q2_loss         | 110.47988   |
| training/sac_Q/q_global_norm   | 287.91638   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16314954 |
| epoch                          | 261        |
| evaluation/episode-length-avg  | 576        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 147        |
| evaluation/episode-length-std  | 424        |
| evaluation/return-average      | 2788.5417  |
| evaluation/return-max          | 5185.216   |
| evaluation/return-min          | 410.838    |
| evaluation/return-std          | 2349.6858  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46256      |
| perf/AverageLength             | 576        |
| perf/AverageReturn             | 2788.5417  |
| perf/NormalizedReturn          | 0.607      |
| Q-avg                          | 208.58345  |
| Q-std                          | 98.95682   |
| Q_loss                         | 88.54024   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 261        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000333   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000536   |
| times/evaluation_paths         | 21.3       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 62.1       |
| timestep                       | 1000       |
| timesteps_total                | 262000     |
| train-steps                    | 262000     |
| training/Q/q1_loss             | 97.97863   |
| training/sac_pi/alpha          | 0.1631222  |
| training/sac_pi/alpha_loss     | 0.01775832 |
| training/sac_pi/logp_pi        | 3.8097222  |
| training/sac_pi/pi_entropy     | 3.4961457  |
| training/sac_pi/pi_global_norm | 1.7119607  |
| training/sac_pi/policy_loss    | -215.18492 |
| training/sac_pi/std            | 0.4947216  |
| training/sac_pi/valid_num      | 4990.0     |
| training/sac_Q/q1              | 209.56564  |
| training/sac_Q/q2              | 209.78604  |
| training/sac_Q/q2_loss         | 97.220406  |
| training/sac_Q/q_global_norm   | 274.71942  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16810974 |
| epoch                          | 262        |
| evaluation/episode-length-avg  | 826        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 142        |
| evaluation/episode-length-std  | 337        |
| evaluation/return-average      | 4007.214   |
| evaluation/return-max          | 5070.424   |
| evaluation/return-min          | 375.9672   |
| evaluation/return-std          | 1800.1261  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46321      |
| perf/AverageLength             | 826        |
| perf/AverageReturn             | 4007.214   |
| perf/NormalizedReturn          | 0.873      |
| Q-avg                          | 200.13545  |
| Q-std                          | 101.06759  |
| Q_loss                         | 114.48063  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 262        |
| times/epoch_after_hook         | 2.01e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.0005     |
| times/evaluation_paths         | 29.3       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00853    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 263000     |
| train-steps                    | 263000     |
| training/Q/q1_loss             | 95.60703   |
| training/sac_pi/alpha          | 0.16812897 |
| training/sac_pi/alpha_loss     | 0.06052293 |
| training/sac_pi/logp_pi        | 3.9005997  |
| training/sac_pi/pi_entropy     | 3.6577287  |
| training/sac_pi/pi_global_norm | 1.551232   |
| training/sac_pi/policy_loss    | -214.27129 |
| training/sac_pi/std            | 0.5043322  |
| training/sac_pi/valid_num      | 5016.0     |
| training/sac_Q/q1              | 208.18436  |
| training/sac_Q/q2              | 209.30313  |
| training/sac_Q/q2_loss         | 95.25993   |
| training/sac_Q/q_global_norm   | 211.7619   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16907822  |
| epoch                          | 263         |
| evaluation/episode-length-avg  | 696         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 141         |
| evaluation/episode-length-std  | 336         |
| evaluation/return-average      | 3436.2754   |
| evaluation/return-max          | 5205.9976   |
| evaluation/return-min          | 361.3811    |
| evaluation/return-std          | 1876.2329   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46132       |
| perf/AverageLength             | 696         |
| perf/AverageReturn             | 3436.2754   |
| perf/NormalizedReturn          | 0.748       |
| Q-avg                          | 208.82622   |
| Q-std                          | 102.77618   |
| Q_loss                         | 107.96563   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 263         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000534    |
| times/evaluation_paths         | 24.5        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 264000      |
| train-steps                    | 264000      |
| training/Q/q1_loss             | 90.48965    |
| training/sac_pi/alpha          | 0.16907094  |
| training/sac_pi/alpha_loss     | 0.108744666 |
| training/sac_pi/logp_pi        | 3.8958716   |
| training/sac_pi/pi_entropy     | 3.5246124   |
| training/sac_pi/pi_global_norm | 1.7817513   |
| training/sac_pi/policy_loss    | -217.80537  |
| training/sac_pi/std            | 0.50254595  |
| training/sac_pi/valid_num      | 5021.0      |
| training/sac_Q/q1              | 211.42715   |
| training/sac_Q/q2              | 212.46268   |
| training/sac_Q/q2_loss         | 91.33136    |
| training/sac_Q/q_global_norm   | 153.81693   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17112985 |
| epoch                          | 264        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4768.4067  |
| evaluation/return-max          | 4887.037   |
| evaluation/return-min          | 4644.4287  |
| evaluation/return-std          | 74.54389   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46230      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4768.4067  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 211.04013  |
| Q-std                          | 96.98664   |
| Q_loss                         | 106.46951  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 264        |
| times/epoch_after_hook         | 1.65e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000584   |
| times/evaluation_paths         | 37         |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 265000     |
| train-steps                    | 265000     |
| training/Q/q1_loss             | 92.63484   |
| training/sac_pi/alpha          | 0.17108157 |
| training/sac_pi/alpha_loss     | 0.5509749  |
| training/sac_pi/logp_pi        | 4.4793267  |
| training/sac_pi/pi_entropy     | 3.576807   |
| training/sac_pi/pi_global_norm | 2.136501   |
| training/sac_pi/policy_loss    | -222.99579 |
| training/sac_pi/std            | 0.50248855 |
| training/sac_pi/valid_num      | 5012.0     |
| training/sac_Q/q1              | 217.7172   |
| training/sac_Q/q2              | 218.40022  |
| training/sac_Q/q2_loss         | 92.5852    |
| training/sac_Q/q_global_norm   | 219.37944  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16858698 |
| epoch                          | 265        |
| evaluation/episode-length-avg  | 884        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 389        |
| evaluation/episode-length-std  | 215        |
| evaluation/return-average      | 4290.8945  |
| evaluation/return-max          | 4927.2856  |
| evaluation/return-min          | 1658.7356  |
| evaluation/return-std          | 1163.2747  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46354      |
| perf/AverageLength             | 884        |
| perf/AverageReturn             | 4290.8945  |
| perf/NormalizedReturn          | 0.934      |
| Q-avg                          | 208.15486  |
| Q-std                          | 101.7135   |
| Q_loss                         | 106.72359  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 265        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000286   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000623   |
| times/evaluation_paths         | 32.3       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 266000     |
| train-steps                    | 266000     |
| training/Q/q1_loss             | 92.90562   |
| training/sac_pi/alpha          | 0.1685901  |
| training/sac_pi/alpha_loss     | 0.2738621  |
| training/sac_pi/logp_pi        | 4.301294   |
| training/sac_pi/pi_entropy     | 3.5776832  |
| training/sac_pi/pi_global_norm | 1.5007997  |
| training/sac_pi/policy_loss    | -215.56306 |
| training/sac_pi/std            | 0.51031435 |
| training/sac_pi/valid_num      | 4973.0     |
| training/sac_Q/q1              | 207.09976  |
| training/sac_Q/q2              | 208.51718  |
| training/sac_Q/q2_loss         | 93.16738   |
| training/sac_Q/q_global_norm   | 243.23634  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17013827  |
| epoch                          | 266         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4856.383    |
| evaluation/return-max          | 5124.1035   |
| evaluation/return-min          | 4625.1157   |
| evaluation/return-std          | 199.90962   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.02        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46276       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4856.383    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 206.24973   |
| Q-std                          | 98.81464    |
| Q_loss                         | 102.96413   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 266         |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000538    |
| times/evaluation_paths         | 36.6        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 60.4        |
| timestep                       | 1000        |
| timesteps_total                | 267000      |
| train-steps                    | 267000      |
| training/Q/q1_loss             | 86.03873    |
| training/sac_pi/alpha          | 0.17015167  |
| training/sac_pi/alpha_loss     | -0.06865083 |
| training/sac_pi/logp_pi        | 4.374527    |
| training/sac_pi/pi_entropy     | 3.3779984   |
| training/sac_pi/pi_global_norm | 2.5707004   |
| training/sac_pi/policy_loss    | -220.3426   |
| training/sac_pi/std            | 0.49792948  |
| training/sac_pi/valid_num      | 4992.0      |
| training/sac_Q/q1              | 212.71838   |
| training/sac_Q/q2              | 214.35478   |
| training/sac_Q/q2_loss         | 86.88103    |
| training/sac_Q/q_global_norm   | 222.89961   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16895683 |
| epoch                          | 267        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5140.0503  |
| evaluation/return-max          | 5285.5244  |
| evaluation/return-min          | 5046.934   |
| evaluation/return-std          | 68.51137   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46254      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5140.0503  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 207.6727   |
| Q-std                          | 116.935265 |
| Q_loss                         | 96.21446   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 267        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.00056    |
| times/evaluation_paths         | 36.8       |
| times/timestep_after_hook      | 0.00375    |
| times/timestep_before_hook     | 0.00862    |
| times/train                    | 59.5       |
| timestep                       | 1000       |
| timesteps_total                | 268000     |
| train-steps                    | 268000     |
| training/Q/q1_loss             | 82.999466  |
| training/sac_pi/alpha          | 0.16895919 |
| training/sac_pi/alpha_loss     | -0.3058824 |
| training/sac_pi/logp_pi        | 3.337468   |
| training/sac_pi/pi_entropy     | 3.6239457  |
| training/sac_pi/pi_global_norm | 1.7638023  |
| training/sac_pi/policy_loss    | -216.88033 |
| training/sac_pi/std            | 0.4889149  |
| training/sac_pi/valid_num      | 4993.0     |
| training/sac_Q/q1              | 211.91411  |
| training/sac_Q/q2              | 211.92041  |
| training/sac_Q/q2_loss         | 82.53316   |
| training/sac_Q/q_global_norm   | 194.15965  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16675574 |
| epoch                          | 268        |
| evaluation/episode-length-avg  | 932        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 315        |
| evaluation/episode-length-std  | 206        |
| evaluation/return-average      | 4474.1313  |
| evaluation/return-max          | 4847.8574  |
| evaluation/return-min          | 1267.0876  |
| evaluation/return-std          | 1069.0618  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 81.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46221      |
| perf/AverageLength             | 932        |
| perf/AverageReturn             | 4474.1313  |
| perf/NormalizedReturn          | 0.974      |
| Q-avg                          | 217.01949  |
| Q-std                          | 104.05358  |
| Q_loss                         | 107.4099   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 268        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000611   |
| times/evaluation_paths         | 32.3       |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00864    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 269000     |
| train-steps                    | 269000     |
| training/Q/q1_loss             | 98.00956   |
| training/sac_pi/alpha          | 0.16675623 |
| training/sac_pi/alpha_loss     | -0.4201168 |
| training/sac_pi/logp_pi        | 3.7454693  |
| training/sac_pi/pi_entropy     | 3.734623   |
| training/sac_pi/pi_global_norm | 1.9368359  |
| training/sac_pi/policy_loss    | -221.14264 |
| training/sac_pi/std            | 0.5258413  |
| training/sac_pi/valid_num      | 4976.0     |
| training/sac_Q/q1              | 213.41843  |
| training/sac_Q/q2              | 213.73083  |
| training/sac_Q/q2_loss         | 97.541275  |
| training/sac_Q/q_global_norm   | 205.5545   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.170498   |
| epoch                          | 269        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4824.0205  |
| evaluation/return-max          | 4855.153   |
| evaluation/return-min          | 4783.407   |
| evaluation/return-std          | 22.34249   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 81.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46224      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4824.0205  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 204.17886  |
| Q-std                          | 107.16103  |
| Q_loss                         | 77.930016  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 269        |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.000387   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000528   |
| times/evaluation_paths         | 35.5       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 270000     |
| train-steps                    | 270000     |
| training/Q/q1_loss             | 111.23039  |
| training/sac_pi/alpha          | 0.17050499 |
| training/sac_pi/alpha_loss     | 0.38610303 |
| training/sac_pi/logp_pi        | 4.343006   |
| training/sac_pi/pi_entropy     | 3.681192   |
| training/sac_pi/pi_global_norm | 1.8207779  |
| training/sac_pi/policy_loss    | -212.07861 |
| training/sac_pi/std            | 0.5167018  |
| training/sac_pi/valid_num      | 4947.0     |
| training/sac_Q/q1              | 205.01431  |
| training/sac_Q/q2              | 206.20293  |
| training/sac_Q/q2_loss         | 110.800514 |
| training/sac_Q/q_global_norm   | 290.7609   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16767377   |
| epoch                          | 270          |
| evaluation/episode-length-avg  | 500          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 163          |
| evaluation/episode-length-std  | 408          |
| evaluation/return-average      | 2306.1328    |
| evaluation/return-max          | 5020.6787    |
| evaluation/return-min          | 506.5356     |
| evaluation/return-std          | 2190.0305    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.08         |
| model/origin_ret               | 85.5         |
| model/penalty_ret              | 79.6         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46340        |
| perf/AverageLength             | 500          |
| perf/AverageReturn             | 2306.1328    |
| perf/NormalizedReturn          | 0.502        |
| Q-avg                          | 213.63423    |
| Q-std                          | 95.80649     |
| Q_loss                         | 100.61926    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 270          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.000431     |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.000465     |
| times/evaluation_paths         | 17.2         |
| times/timestep_after_hook      | 0.00371      |
| times/timestep_before_hook     | 0.00873      |
| times/train                    | 62.2         |
| timestep                       | 1000         |
| timesteps_total                | 271000       |
| train-steps                    | 271000       |
| training/Q/q1_loss             | 87.11986     |
| training/sac_pi/alpha          | 0.16765514   |
| training/sac_pi/alpha_loss     | 0.0078581115 |
| training/sac_pi/logp_pi        | 3.6994293    |
| training/sac_pi/pi_entropy     | 3.460942     |
| training/sac_pi/pi_global_norm | 2.0823584    |
| training/sac_pi/policy_loss    | -220.6422    |
| training/sac_pi/std            | 0.4904806    |
| training/sac_pi/valid_num      | 4986.0       |
| training/sac_Q/q1              | 213.94429    |
| training/sac_Q/q2              | 214.3877     |
| training/sac_Q/q2_loss         | 87.267075    |
| training/sac_Q/q_global_norm   | 349.5132     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16984573 |
| epoch                          | 271        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5048.1826  |
| evaluation/return-max          | 5092.0176  |
| evaluation/return-min          | 4993.3525  |
| evaluation/return-std          | 26.45256   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46620      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5048.1826  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 205.25517  |
| Q-std                          | 103.77477  |
| Q_loss                         | 108.37672  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 271        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000118   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000641   |
| times/evaluation_paths         | 36.2       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00858    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 272000     |
| train-steps                    | 272000     |
| training/Q/q1_loss             | 86.71111   |
| training/sac_pi/alpha          | 0.16985576 |
| training/sac_pi/alpha_loss     | -0.2200788 |
| training/sac_pi/logp_pi        | 4.034812   |
| training/sac_pi/pi_entropy     | 3.680888   |
| training/sac_pi/pi_global_norm | 2.0152726  |
| training/sac_pi/policy_loss    | -217.00327 |
| training/sac_pi/std            | 0.5153494  |
| training/sac_pi/valid_num      | 4986.0     |
| training/sac_Q/q1              | 209.73923  |
| training/sac_Q/q2              | 211.3339   |
| training/sac_Q/q2_loss         | 85.21322   |
| training/sac_Q/q_global_norm   | 186.9773   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16511805   |
| epoch                          | 272          |
| evaluation/episode-length-avg  | 932          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 321          |
| evaluation/episode-length-std  | 204          |
| evaluation/return-average      | 4653.905     |
| evaluation/return-max          | 5127.8843    |
| evaluation/return-min          | 1341.5297    |
| evaluation/return-std          | 1106.0482    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.12         |
| model/origin_ret               | 86.3         |
| model/penalty_ret              | 81           |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46400        |
| perf/AverageLength             | 932          |
| perf/AverageReturn             | 4653.905     |
| perf/NormalizedReturn          | 1.01         |
| Q-avg                          | 207.51059    |
| Q-std                          | 91.95283     |
| Q_loss                         | 118.611      |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 272          |
| times/epoch_after_hook         | 1.82e-06     |
| times/epoch_before_hook        | 0.000146     |
| times/epoch_rollout_model      | 489          |
| times/evaluation_metrics       | 0.000637     |
| times/evaluation_paths         | 34.4         |
| times/timestep_after_hook      | 0.00376      |
| times/timestep_before_hook     | 0.00847      |
| times/train                    | 60.8         |
| timestep                       | 1000         |
| timesteps_total                | 273000       |
| train-steps                    | 273000       |
| training/Q/q1_loss             | 106.161896   |
| training/sac_pi/alpha          | 0.16513962   |
| training/sac_pi/alpha_loss     | -0.066440165 |
| training/sac_pi/logp_pi        | 3.968907     |
| training/sac_pi/pi_entropy     | 3.7790756    |
| training/sac_pi/pi_global_norm | 1.7152702    |
| training/sac_pi/policy_loss    | -208.9885    |
| training/sac_pi/std            | 0.5193779    |
| training/sac_pi/valid_num      | 4933.0       |
| training/sac_Q/q1              | 200.14627    |
| training/sac_Q/q2              | 200.82396    |
| training/sac_Q/q2_loss         | 106.314766   |
| training/sac_Q/q_global_norm   | 228.6949     |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16480012  |
| epoch                          | 273         |
| evaluation/episode-length-avg  | 717         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 349         |
| evaluation/episode-length-std  | 292         |
| evaluation/return-average      | 3396.7532   |
| evaluation/return-max          | 4908.0747   |
| evaluation/return-min          | 1486.4702   |
| evaluation/return-std          | 1478.9806   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46287       |
| perf/AverageLength             | 717         |
| perf/AverageReturn             | 3396.7532   |
| perf/NormalizedReturn          | 0.74        |
| Q-avg                          | 200.49704   |
| Q-std                          | 113.22597   |
| Q_loss                         | 83.84676    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 273         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000325    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000616    |
| times/evaluation_paths         | 26.8        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00848     |
| times/train                    | 59.9        |
| timestep                       | 1000        |
| timesteps_total                | 274000      |
| train-steps                    | 274000      |
| training/Q/q1_loss             | 110.58547   |
| training/sac_pi/alpha          | 0.1647904   |
| training/sac_pi/alpha_loss     | -0.12735438 |
| training/sac_pi/logp_pi        | 4.012507    |
| training/sac_pi/pi_entropy     | 3.5468323   |
| training/sac_pi/pi_global_norm | 1.538501    |
| training/sac_pi/policy_loss    | -217.53583  |
| training/sac_pi/std            | 0.5007997   |
| training/sac_pi/valid_num      | 4927.0      |
| training/sac_Q/q1              | 206.48906   |
| training/sac_Q/q2              | 208.35635   |
| training/sac_Q/q2_loss         | 111.454056  |
| training/sac_Q/q_global_norm   | 236.54463   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16927755 |
| epoch                          | 274        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4978.048   |
| evaluation/return-max          | 5064.755   |
| evaluation/return-min          | 4862.5874  |
| evaluation/return-std          | 58.421043  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46375      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4978.048   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 212.06267  |
| Q-std                          | 95.03031   |
| Q_loss                         | 104.209984 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 274        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000175   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000532   |
| times/evaluation_paths         | 37.9       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.0089     |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 275000     |
| train-steps                    | 275000     |
| training/Q/q1_loss             | 73.6073    |
| training/sac_pi/alpha          | 0.16933332 |
| training/sac_pi/alpha_loss     | -0.3217834 |
| training/sac_pi/logp_pi        | 3.8796983  |
| training/sac_pi/pi_entropy     | 3.58853    |
| training/sac_pi/pi_global_norm | 1.7638947  |
| training/sac_pi/policy_loss    | -220.59163 |
| training/sac_pi/std            | 0.49921963 |
| training/sac_pi/valid_num      | 4955.0     |
| training/sac_Q/q1              | 212.45084  |
| training/sac_Q/q2              | 213.55405  |
| training/sac_Q/q2_loss         | 73.73896   |
| training/sac_Q/q_global_norm   | 190.89293  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17831844 |
| epoch                          | 275        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4891.966   |
| evaluation/return-max          | 4971.931   |
| evaluation/return-min          | 4838.781   |
| evaluation/return-std          | 39.304985  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46342      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4891.966   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 211.06123  |
| Q-std                          | 106.01118  |
| Q_loss                         | 96.34922   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 275        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000119   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000623   |
| times/evaluation_paths         | 37.3       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 276000     |
| train-steps                    | 276000     |
| training/Q/q1_loss             | 89.71345   |
| training/sac_pi/alpha          | 0.1783205  |
| training/sac_pi/alpha_loss     | 0.20103711 |
| training/sac_pi/logp_pi        | 5.095843   |
| training/sac_pi/pi_entropy     | 3.8424156  |
| training/sac_pi/pi_global_norm | 1.656411   |
| training/sac_pi/policy_loss    | -216.07622 |
| training/sac_pi/std            | 0.58363235 |
| training/sac_pi/valid_num      | 4905.0     |
| training/sac_Q/q1              | 202.1261   |
| training/sac_Q/q2              | 204.3791   |
| training/sac_Q/q2_loss         | 90.32724   |
| training/sac_Q/q_global_norm   | 284.1367   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17257583  |
| epoch                          | 276         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5006.7183   |
| evaluation/return-max          | 5057.465    |
| evaluation/return-min          | 4914.84     |
| evaluation/return-std          | 43.077457   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46278       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5006.7183   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 217.15295   |
| Q-std                          | 101.83373   |
| Q_loss                         | 92.834724   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 276         |
| times/epoch_after_hook         | 3.06e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000559    |
| times/evaluation_paths         | 35.5        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 277000      |
| train-steps                    | 277000      |
| training/Q/q1_loss             | 104.45569   |
| training/sac_pi/alpha          | 0.17261255  |
| training/sac_pi/alpha_loss     | -0.12798588 |
| training/sac_pi/logp_pi        | 3.9811656   |
| training/sac_pi/pi_entropy     | 3.645055    |
| training/sac_pi/pi_global_norm | 1.6407889   |
| training/sac_pi/policy_loss    | -219.20012  |
| training/sac_pi/std            | 0.5078945   |
| training/sac_pi/valid_num      | 5004.0      |
| training/sac_Q/q1              | 213.6731    |
| training/sac_Q/q2              | 213.46196   |
| training/sac_Q/q2_loss         | 105.03643   |
| training/sac_Q/q_global_norm   | 255.8495    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17363045 |
| epoch                          | 277        |
| evaluation/episode-length-avg  | 644        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 158        |
| evaluation/episode-length-std  | 217        |
| evaluation/return-average      | 2931.4404  |
| evaluation/return-max          | 4853.9473  |
| evaluation/return-min          | 468.06955  |
| evaluation/return-std          | 1132.8181  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46142      |
| perf/AverageLength             | 644        |
| perf/AverageReturn             | 2931.4404  |
| perf/NormalizedReturn          | 0.638      |
| Q-avg                          | 202.84555  |
| Q-std                          | 107.24724  |
| Q_loss                         | 91.96735   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 277        |
| times/epoch_after_hook         | 1.62e-06   |
| times/epoch_before_hook        | 0.000317   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000493   |
| times/evaluation_paths         | 23.9       |
| times/timestep_after_hook      | 0.00375    |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 278000     |
| train-steps                    | 278000     |
| training/Q/q1_loss             | 94.66389   |
| training/sac_pi/alpha          | 0.1736117  |
| training/sac_pi/alpha_loss     | 0.273185   |
| training/sac_pi/logp_pi        | 4.879695   |
| training/sac_pi/pi_entropy     | 3.5291982  |
| training/sac_pi/pi_global_norm | 2.7977223  |
| training/sac_pi/policy_loss    | -212.63428 |
| training/sac_pi/std            | 0.5027448  |
| training/sac_pi/valid_num      | 4928.0     |
| training/sac_Q/q1              | 204.78506  |
| training/sac_Q/q2              | 205.36223  |
| training/sac_Q/q2_loss         | 93.87049   |
| training/sac_Q/q_global_norm   | 238.01909  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16762471   |
| epoch                          | 278          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5081.565     |
| evaluation/return-max          | 5215.012     |
| evaluation/return-min          | 5030.043     |
| evaluation/return-std          | 55.13464     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.07         |
| model/origin_ret               | 86.7         |
| model/penalty_ret              | 81.2         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46261        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5081.565     |
| perf/NormalizedReturn          | 1.11         |
| Q-avg                          | 206.92143    |
| Q-std                          | 102.21003    |
| Q_loss                         | 93.07097     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 278          |
| times/epoch_after_hook         | 1.67e-06     |
| times/epoch_before_hook        | 0.000127     |
| times/epoch_rollout_model      | 487          |
| times/evaluation_metrics       | 0.000518     |
| times/evaluation_paths         | 35           |
| times/timestep_after_hook      | 0.00391      |
| times/timestep_before_hook     | 0.0088       |
| times/train                    | 63.8         |
| timestep                       | 1000         |
| timesteps_total                | 279000       |
| train-steps                    | 279000       |
| training/Q/q1_loss             | 103.301      |
| training/sac_pi/alpha          | 0.16763754   |
| training/sac_pi/alpha_loss     | -0.029436085 |
| training/sac_pi/logp_pi        | 4.192521     |
| training/sac_pi/pi_entropy     | 3.7142906    |
| training/sac_pi/pi_global_norm | 2.043421     |
| training/sac_pi/policy_loss    | -205.41185   |
| training/sac_pi/std            | 0.518643     |
| training/sac_pi/valid_num      | 4882.0       |
| training/sac_Q/q1              | 193.21655    |
| training/sac_Q/q2              | 194.82393    |
| training/sac_Q/q2_loss         | 103.67827    |
| training/sac_Q/q_global_norm   | 273.1333     |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16830292   |
| epoch                          | 279          |
| evaluation/episode-length-avg  | 662          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 137          |
| evaluation/episode-length-std  | 395          |
| evaluation/return-average      | 2986.212     |
| evaluation/return-max          | 4776.1167    |
| evaluation/return-min          | 342.8849     |
| evaluation/return-std          | 2015.1528    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.09         |
| model/origin_ret               | 86.1         |
| model/penalty_ret              | 79.9         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46318        |
| perf/AverageLength             | 662          |
| perf/AverageReturn             | 2986.212     |
| perf/NormalizedReturn          | 0.65         |
| Q-avg                          | 209.94829    |
| Q-std                          | 86.23087     |
| Q_loss                         | 103.62129    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 279          |
| times/epoch_after_hook         | 1.86e-06     |
| times/epoch_before_hook        | 0.000131     |
| times/epoch_rollout_model      | 485          |
| times/evaluation_metrics       | 0.000612     |
| times/evaluation_paths         | 23.5         |
| times/timestep_after_hook      | 0.00378      |
| times/timestep_before_hook     | 0.00853      |
| times/train                    | 62.2         |
| timestep                       | 1000         |
| timesteps_total                | 280000       |
| train-steps                    | 280000       |
| training/Q/q1_loss             | 96.742256    |
| training/sac_pi/alpha          | 0.16830026   |
| training/sac_pi/alpha_loss     | -0.024300743 |
| training/sac_pi/logp_pi        | 4.3060713    |
| training/sac_pi/pi_entropy     | 3.6081543    |
| training/sac_pi/pi_global_norm | 1.9768014    |
| training/sac_pi/policy_loss    | -213.67812   |
| training/sac_pi/std            | 0.5183846    |
| training/sac_pi/valid_num      | 4956.0       |
| training/sac_Q/q1              | 204.90857    |
| training/sac_Q/q2              | 207.05525    |
| training/sac_Q/q2_loss         | 96.97047     |
| training/sac_Q/q_global_norm   | 198.03033    |
----------------------------------------------------------------------------------
[WARN] 280 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16672377  |
| epoch                          | 280         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4928.8984   |
| evaluation/return-max          | 5015.705    |
| evaluation/return-min          | 4813.934    |
| evaluation/return-std          | 80.32573    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46345       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4928.8984   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 215.06514   |
| Q-std                          | 105.47035   |
| Q_loss                         | 92.85068    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 280         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000116    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.00065     |
| times/evaluation_paths         | 36.8        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 62.3        |
| timestep                       | 1000        |
| timesteps_total                | 281000      |
| train-steps                    | 281000      |
| training/Q/q1_loss             | 101.16465   |
| training/sac_pi/alpha          | 0.16676368  |
| training/sac_pi/alpha_loss     | -0.45529246 |
| training/sac_pi/logp_pi        | 4.4017043   |
| training/sac_pi/pi_entropy     | 3.475676    |
| training/sac_pi/pi_global_norm | 1.9435564   |
| training/sac_pi/policy_loss    | -227.62222  |
| training/sac_pi/std            | 0.51860553  |
| training/sac_pi/valid_num      | 4899.0      |
| training/sac_Q/q1              | 213.45598   |
| training/sac_Q/q2              | 215.52625   |
| training/sac_Q/q2_loss         | 100.785034  |
| training/sac_Q/q_global_norm   | 304.599     |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17026241 |
| epoch                          | 281        |
| evaluation/episode-length-avg  | 806        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 443        |
| evaluation/episode-length-std  | 227        |
| evaluation/return-average      | 3853.316   |
| evaluation/return-max          | 4985.98    |
| evaluation/return-min          | 1857.899   |
| evaluation/return-std          | 1250.5337  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46453      |
| perf/AverageLength             | 806        |
| perf/AverageReturn             | 3853.316   |
| perf/NormalizedReturn          | 0.839      |
| Q-avg                          | 202.63634  |
| Q-std                          | 99.90539   |
| Q_loss                         | 98.88587   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 281        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000284   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000617   |
| times/evaluation_paths         | 30         |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00863    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 282000     |
| train-steps                    | 282000     |
| training/Q/q1_loss             | 114.56324  |
| training/sac_pi/alpha          | 0.17027506 |
| training/sac_pi/alpha_loss     | 0.07847956 |
| training/sac_pi/logp_pi        | 4.0561447  |
| training/sac_pi/pi_entropy     | 3.6099143  |
| training/sac_pi/pi_global_norm | 2.416394   |
| training/sac_pi/policy_loss    | -213.57367 |
| training/sac_pi/std            | 0.49692562 |
| training/sac_pi/valid_num      | 4988.0     |
| training/sac_Q/q1              | 207.14912  |
| training/sac_Q/q2              | 208.87466  |
| training/sac_Q/q2_loss         | 115.36293  |
| training/sac_Q/q_global_norm   | 246.274    |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16600037   |
| epoch                          | 282          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4939.087     |
| evaluation/return-max          | 5044.7725    |
| evaluation/return-min          | 4903.5044    |
| evaluation/return-std          | 42.153496    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.08         |
| model/origin_ret               | 85.3         |
| model/penalty_ret              | 80.3         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46458        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4939.087     |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 216.72087    |
| Q-std                          | 96.45187     |
| Q_loss                         | 92.64619     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 282          |
| times/epoch_after_hook         | 1.78e-06     |
| times/epoch_before_hook        | 0.000124     |
| times/epoch_rollout_model      | 494          |
| times/evaluation_metrics       | 0.000789     |
| times/evaluation_paths         | 34.5         |
| times/timestep_after_hook      | 0.00374      |
| times/timestep_before_hook     | 0.00853      |
| times/train                    | 61.1         |
| timestep                       | 1000         |
| timesteps_total                | 283000       |
| train-steps                    | 283000       |
| training/Q/q1_loss             | 111.75095    |
| training/sac_pi/alpha          | 0.16602641   |
| training/sac_pi/alpha_loss     | -0.062079694 |
| training/sac_pi/logp_pi        | 3.9348369    |
| training/sac_pi/pi_entropy     | 3.4409027    |
| training/sac_pi/pi_global_norm | 1.8927143    |
| training/sac_pi/policy_loss    | -216.66524   |
| training/sac_pi/std            | 0.49006894   |
| training/sac_pi/valid_num      | 4977.0       |
| training/sac_Q/q1              | 210.7623     |
| training/sac_Q/q2              | 211.5245     |
| training/sac_Q/q2_loss         | 112.25183    |
| training/sac_Q/q_global_norm   | 250.89207    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17461693 |
| epoch                          | 283        |
| evaluation/episode-length-avg  | 649        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 136        |
| evaluation/episode-length-std  | 417        |
| evaluation/return-average      | 3026.427   |
| evaluation/return-max          | 5035.212   |
| evaluation/return-min          | 420.21616  |
| evaluation/return-std          | 2125.4275  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46389      |
| perf/AverageLength             | 649        |
| perf/AverageReturn             | 3026.427   |
| perf/NormalizedReturn          | 0.659      |
| Q-avg                          | 211.2918   |
| Q-std                          | 97.3714    |
| Q_loss                         | 99.168846  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 283        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000179   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000494   |
| times/evaluation_paths         | 24.4       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.0088     |
| times/train                    | 63.6       |
| timestep                       | 1000       |
| timesteps_total                | 284000     |
| train-steps                    | 284000     |
| training/Q/q1_loss             | 83.728     |
| training/sac_pi/alpha          | 0.17461897 |
| training/sac_pi/alpha_loss     | 0.23257536 |
| training/sac_pi/logp_pi        | 3.9911308  |
| training/sac_pi/pi_entropy     | 3.5225189  |
| training/sac_pi/pi_global_norm | 1.6871971  |
| training/sac_pi/policy_loss    | -215.31758 |
| training/sac_pi/std            | 0.48356283 |
| training/sac_pi/valid_num      | 5005.0     |
| training/sac_Q/q1              | 208.86604  |
| training/sac_Q/q2              | 210.0457   |
| training/sac_Q/q2_loss         | 83.734955  |
| training/sac_Q/q_global_norm   | 303.3128   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17592372  |
| epoch                          | 284         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4764.5557   |
| evaluation/return-max          | 4836.9604   |
| evaluation/return-min          | 4728.1006   |
| evaluation/return-std          | 35.879627   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46448       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4764.5557   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 207.87724   |
| Q-std                          | 92.613686   |
| Q_loss                         | 131.77461   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 284         |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 9.07e-05    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.00081     |
| times/evaluation_paths         | 35.7        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00866     |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 285000      |
| train-steps                    | 285000      |
| training/Q/q1_loss             | 98.26165    |
| training/sac_pi/alpha          | 0.17589925  |
| training/sac_pi/alpha_loss     | -0.14526697 |
| training/sac_pi/logp_pi        | 3.7414684   |
| training/sac_pi/pi_entropy     | 3.584528    |
| training/sac_pi/pi_global_norm | 2.0571127   |
| training/sac_pi/policy_loss    | -217.80086  |
| training/sac_pi/std            | 0.48844615  |
| training/sac_pi/valid_num      | 4979.0      |
| training/sac_Q/q1              | 210.15486   |
| training/sac_Q/q2              | 210.74927   |
| training/sac_Q/q2_loss         | 99.059746   |
| training/sac_Q/q_global_norm   | 201.68086   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1688147   |
| epoch                          | 285         |
| evaluation/episode-length-avg  | 833         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 163         |
| evaluation/episode-length-std  | 335         |
| evaluation/return-average      | 4224.7217   |
| evaluation/return-max          | 5223.6304   |
| evaluation/return-min          | 517.8052    |
| evaluation/return-std          | 1853.672    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46321       |
| perf/AverageLength             | 833         |
| perf/AverageReturn             | 4224.7217   |
| perf/NormalizedReturn          | 0.92        |
| Q-avg                          | 211.59477   |
| Q-std                          | 97.06844    |
| Q_loss                         | 85.805695   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 285         |
| times/epoch_after_hook         | 3.38e-06    |
| times/epoch_before_hook        | 0.00034     |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000501    |
| times/evaluation_paths         | 29.8        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00872     |
| times/train                    | 64.9        |
| timestep                       | 1000        |
| timesteps_total                | 286000      |
| train-steps                    | 286000      |
| training/Q/q1_loss             | 111.86571   |
| training/sac_pi/alpha          | 0.16883022  |
| training/sac_pi/alpha_loss     | -0.40217525 |
| training/sac_pi/logp_pi        | 4.1978464   |
| training/sac_pi/pi_entropy     | 3.4749305   |
| training/sac_pi/pi_global_norm | 2.3148582   |
| training/sac_pi/policy_loss    | -213.99605  |
| training/sac_pi/std            | 0.4965327   |
| training/sac_pi/valid_num      | 4963.0      |
| training/sac_Q/q1              | 204.77252   |
| training/sac_Q/q2              | 207.21695   |
| training/sac_Q/q2_loss         | 111.29662   |
| training/sac_Q/q_global_norm   | 259.54733   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16565396 |
| epoch                          | 286        |
| evaluation/episode-length-avg  | 808        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 152        |
| evaluation/episode-length-std  | 334        |
| evaluation/return-average      | 4100.5005  |
| evaluation/return-max          | 5224.0947  |
| evaluation/return-min          | 500.66687  |
| evaluation/return-std          | 1836.0205  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46514      |
| perf/AverageLength             | 808        |
| perf/AverageReturn             | 4100.5005  |
| perf/NormalizedReturn          | 0.893      |
| Q-avg                          | 207.31494  |
| Q-std                          | 95.34443   |
| Q_loss                         | 92.99322   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 286        |
| times/epoch_after_hook         | 3.1e-06    |
| times/epoch_before_hook        | 0.000139   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000598   |
| times/evaluation_paths         | 30.2       |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.00851    |
| times/train                    | 60.2       |
| timestep                       | 1000       |
| timesteps_total                | 287000     |
| train-steps                    | 287000     |
| training/Q/q1_loss             | 95.295906  |
| training/sac_pi/alpha          | 0.1656512  |
| training/sac_pi/alpha_loss     | 0.26846647 |
| training/sac_pi/logp_pi        | 4.4478726  |
| training/sac_pi/pi_entropy     | 3.3974063  |
| training/sac_pi/pi_global_norm | 1.9842722  |
| training/sac_pi/policy_loss    | -218.33167 |
| training/sac_pi/std            | 0.4970996  |
| training/sac_pi/valid_num      | 5010.0     |
| training/sac_Q/q1              | 212.18997  |
| training/sac_Q/q2              | 214.81894  |
| training/sac_Q/q2_loss         | 95.60121   |
| training/sac_Q/q_global_norm   | 346.92407  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16958502  |
| epoch                          | 287         |
| evaluation/episode-length-avg  | 873         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 671         |
| evaluation/episode-length-std  | 133         |
| evaluation/return-average      | 4223.8105   |
| evaluation/return-max          | 4931.18     |
| evaluation/return-min          | 3178.7415   |
| evaluation/return-std          | 677.19434   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46393       |
| perf/AverageLength             | 873         |
| perf/AverageReturn             | 4223.8105   |
| perf/NormalizedReturn          | 0.92        |
| Q-avg                          | 203.84216   |
| Q-std                          | 107.91637   |
| Q_loss                         | 98.43973    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 287         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000151    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000621    |
| times/evaluation_paths         | 31          |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00869     |
| times/train                    | 64.5        |
| timestep                       | 1000        |
| timesteps_total                | 288000      |
| train-steps                    | 288000      |
| training/Q/q1_loss             | 96.87102    |
| training/sac_pi/alpha          | 0.16958278  |
| training/sac_pi/alpha_loss     | 0.014006592 |
| training/sac_pi/logp_pi        | 3.9724846   |
| training/sac_pi/pi_entropy     | 3.5914288   |
| training/sac_pi/pi_global_norm | 1.7248843   |
| training/sac_pi/policy_loss    | -215.68475  |
| training/sac_pi/std            | 0.4938346   |
| training/sac_pi/valid_num      | 4939.0      |
| training/sac_Q/q1              | 206.21272   |
| training/sac_Q/q2              | 207.60774   |
| training/sac_Q/q2_loss         | 96.19232    |
| training/sac_Q/q_global_norm   | 247.6963    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16714571 |
| epoch                          | 288        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5020.3325  |
| evaluation/return-max          | 5114.255   |
| evaluation/return-min          | 4976.3174  |
| evaluation/return-std          | 40.16162   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46181      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5020.3325  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 199.86569  |
| Q-std                          | 122.87666  |
| Q_loss                         | 86.7119    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 288        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000261   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.00052    |
| times/evaluation_paths         | 35.7       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00852    |
| times/train                    | 63.8       |
| timestep                       | 1000       |
| timesteps_total                | 289000     |
| train-steps                    | 289000     |
| training/Q/q1_loss             | 103.57512  |
| training/sac_pi/alpha          | 0.16713578 |
| training/sac_pi/alpha_loss     | 0.18244469 |
| training/sac_pi/logp_pi        | 4.3400154  |
| training/sac_pi/pi_entropy     | 3.6442878  |
| training/sac_pi/pi_global_norm | 1.7850382  |
| training/sac_pi/policy_loss    | -226.12263 |
| training/sac_pi/std            | 0.5167352  |
| training/sac_pi/valid_num      | 4972.0     |
| training/sac_Q/q1              | 219.47055  |
| training/sac_Q/q2              | 220.01973  |
| training/sac_Q/q2_loss         | 103.98655  |
| training/sac_Q/q_global_norm   | 221.93472  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16299772   |
| epoch                          | 289          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4976.034     |
| evaluation/return-max          | 5033.162     |
| evaluation/return-min          | 4919.8516    |
| evaluation/return-std          | 33.70048     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.14         |
| model/origin_ret               | 86.5         |
| model/penalty_ret              | 81           |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46401        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4976.034     |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 207.30745    |
| Q-std                          | 97.9665      |
| Q_loss                         | 108.46178    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 289          |
| times/epoch_after_hook         | 1.78e-06     |
| times/epoch_before_hook        | 0.000484     |
| times/epoch_rollout_model      | 500          |
| times/evaluation_metrics       | 0.000897     |
| times/evaluation_paths         | 34           |
| times/timestep_after_hook      | 0.00371      |
| times/timestep_before_hook     | 0.00856      |
| times/train                    | 61.4         |
| timestep                       | 1000         |
| timesteps_total                | 290000       |
| train-steps                    | 290000       |
| training/Q/q1_loss             | 123.7259     |
| training/sac_pi/alpha          | 0.16297042   |
| training/sac_pi/alpha_loss     | -0.038004138 |
| training/sac_pi/logp_pi        | 4.651229     |
| training/sac_pi/pi_entropy     | 3.6813233    |
| training/sac_pi/pi_global_norm | 1.8293307    |
| training/sac_pi/policy_loss    | -208.27875   |
| training/sac_pi/std            | 0.5295833    |
| training/sac_pi/valid_num      | 4894.0       |
| training/sac_Q/q1              | 198.11679    |
| training/sac_Q/q2              | 199.22067    |
| training/sac_Q/q2_loss         | 124.667564   |
| training/sac_Q/q_global_norm   | 286.71454    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.169803   |
| epoch                          | 290        |
| evaluation/episode-length-avg  | 164        |
| evaluation/episode-length-max  | 167        |
| evaluation/episode-length-min  | 159        |
| evaluation/episode-length-std  | 2.48       |
| evaluation/return-average      | 532.5809   |
| evaluation/return-max          | 548.9335   |
| evaluation/return-min          | 514.0504   |
| evaluation/return-std          | 11.501596  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46325      |
| perf/AverageLength             | 164        |
| perf/AverageReturn             | 532.5809   |
| perf/NormalizedReturn          | 0.116      |
| Q-avg                          | 217.50711  |
| Q-std                          | 106.797554 |
| Q_loss                         | 113.48007  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 290        |
| times/epoch_after_hook         | 1.57e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000494   |
| times/evaluation_paths         | 5.37       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 291000     |
| train-steps                    | 291000     |
| training/Q/q1_loss             | 106.96438  |
| training/sac_pi/alpha          | 0.16984305 |
| training/sac_pi/alpha_loss     | -0.5802571 |
| training/sac_pi/logp_pi        | 4.010639   |
| training/sac_pi/pi_entropy     | 3.6914825  |
| training/sac_pi/pi_global_norm | 2.0063558  |
| training/sac_pi/policy_loss    | -216.60388 |
| training/sac_pi/std            | 0.5283798  |
| training/sac_pi/valid_num      | 4914.0     |
| training/sac_Q/q1              | 205.10278  |
| training/sac_Q/q2              | 208.07446  |
| training/sac_Q/q2_loss         | 108.84123  |
| training/sac_Q/q_global_norm   | 301.27084  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17029122  |
| epoch                          | 291         |
| evaluation/episode-length-avg  | 736         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 332         |
| evaluation/episode-length-std  | 323         |
| evaluation/return-average      | 3343.287    |
| evaluation/return-max          | 4764.3604   |
| evaluation/return-min          | 1274.458    |
| evaluation/return-std          | 1658.3237   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46255       |
| perf/AverageLength             | 736         |
| perf/AverageReturn             | 3343.287    |
| perf/NormalizedReturn          | 0.728       |
| Q-avg                          | 208.97623   |
| Q-std                          | 112.33431   |
| Q_loss                         | 94.4971     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 291         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 8.38e-05    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000841    |
| times/evaluation_paths         | 28.1        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00851     |
| times/train                    | 62.7        |
| timestep                       | 1000        |
| timesteps_total                | 292000      |
| train-steps                    | 292000      |
| training/Q/q1_loss             | 110.12769   |
| training/sac_pi/alpha          | 0.17029437  |
| training/sac_pi/alpha_loss     | -0.27190423 |
| training/sac_pi/logp_pi        | 4.52427     |
| training/sac_pi/pi_entropy     | 3.5664496   |
| training/sac_pi/pi_global_norm | 1.7828779   |
| training/sac_pi/policy_loss    | -216.60947  |
| training/sac_pi/std            | 0.51521     |
| training/sac_pi/valid_num      | 4963.0      |
| training/sac_Q/q1              | 207.28824   |
| training/sac_Q/q2              | 209.17017   |
| training/sac_Q/q2_loss         | 108.78898   |
| training/sac_Q/q_global_norm   | 314.70834   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16764314 |
| epoch                          | 292        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4995.0107  |
| evaluation/return-max          | 5082.75    |
| evaluation/return-min          | 4919.012   |
| evaluation/return-std          | 60.8294    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46442      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4995.0107  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 208.04395  |
| Q-std                          | 105.33828  |
| Q_loss                         | 101.099815 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 292        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000521   |
| times/evaluation_paths         | 37.1       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00882    |
| times/train                    | 68.1       |
| timestep                       | 1000       |
| timesteps_total                | 293000     |
| train-steps                    | 293000     |
| training/Q/q1_loss             | 104.05403  |
| training/sac_pi/alpha          | 0.16764991 |
| training/sac_pi/alpha_loss     | 0.16489343 |
| training/sac_pi/logp_pi        | 4.6280494  |
| training/sac_pi/pi_entropy     | 3.4350853  |
| training/sac_pi/pi_global_norm | 1.7446731  |
| training/sac_pi/policy_loss    | -218.0816  |
| training/sac_pi/std            | 0.50058436 |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 208.74731  |
| training/sac_Q/q2              | 211.09123  |
| training/sac_Q/q2_loss         | 104.207825 |
| training/sac_Q/q_global_norm   | 324.5409   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16651577 |
| epoch                          | 293        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4481.07    |
| evaluation/return-max          | 4668.157   |
| evaluation/return-min          | 4332.8223  |
| evaluation/return-std          | 102.342636 |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46535      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4481.07    |
| perf/NormalizedReturn          | 0.976      |
| Q-avg                          | 211.20247  |
| Q-std                          | 101.8033   |
| Q_loss                         | 89.70886   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 293        |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.000277   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000669   |
| times/evaluation_paths         | 38         |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.0087     |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 294000     |
| train-steps                    | 294000     |
| training/Q/q1_loss             | 108.714745 |
| training/sac_pi/alpha          | 0.16649254 |
| training/sac_pi/alpha_loss     | 0.69285107 |
| training/sac_pi/logp_pi        | 5.1073318  |
| training/sac_pi/pi_entropy     | 3.6418297  |
| training/sac_pi/pi_global_norm | 2.1558435  |
| training/sac_pi/policy_loss    | -213.54593 |
| training/sac_pi/std            | 0.5418106  |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 202.3038   |
| training/sac_Q/q2              | 203.77657  |
| training/sac_Q/q2_loss         | 110.001114 |
| training/sac_Q/q_global_norm   | 269.92734  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17118017 |
| epoch                          | 294        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5001.26    |
| evaluation/return-max          | 5033.79    |
| evaluation/return-min          | 4969.158   |
| evaluation/return-std          | 24.452528  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46324      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5001.26    |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 208.51714  |
| Q-std                          | 90.106766  |
| Q_loss                         | 83.636246  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 294        |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.000152   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000566   |
| times/evaluation_paths         | 36.8       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 64.4       |
| timestep                       | 1000       |
| timesteps_total                | 295000     |
| train-steps                    | 295000     |
| training/Q/q1_loss             | 105.10891  |
| training/sac_pi/alpha          | 0.17116167 |
| training/sac_pi/alpha_loss     | 0.14317289 |
| training/sac_pi/logp_pi        | 4.679586   |
| training/sac_pi/pi_entropy     | 3.7187867  |
| training/sac_pi/pi_global_norm | 1.7742395  |
| training/sac_pi/policy_loss    | -210.92795 |
| training/sac_pi/std            | 0.54317147 |
| training/sac_pi/valid_num      | 4897.0     |
| training/sac_Q/q1              | 200.60439  |
| training/sac_Q/q2              | 202.87437  |
| training/sac_Q/q2_loss         | 105.87015  |
| training/sac_Q/q_global_norm   | 318.57074  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16630979 |
| epoch                          | 295        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4871.829   |
| evaluation/return-max          | 4931.1455  |
| evaluation/return-min          | 4828.671   |
| evaluation/return-std          | 31.101625  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46223      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4871.829   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 210.13882  |
| Q-std                          | 98.961655  |
| Q_loss                         | 89.13484   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 295        |
| times/epoch_after_hook         | 1.6e-06    |
| times/epoch_before_hook        | 0.000186   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 34.7       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 296000     |
| train-steps                    | 296000     |
| training/Q/q1_loss             | 86.5758    |
| training/sac_pi/alpha          | 0.16629778 |
| training/sac_pi/alpha_loss     | 0.29719418 |
| training/sac_pi/logp_pi        | 3.682244   |
| training/sac_pi/pi_entropy     | 3.4647446  |
| training/sac_pi/pi_global_norm | 1.4948196  |
| training/sac_pi/policy_loss    | -220.2348  |
| training/sac_pi/std            | 0.47018832 |
| training/sac_pi/valid_num      | 5051.0     |
| training/sac_Q/q1              | 216.42705  |
| training/sac_Q/q2              | 217.36101  |
| training/sac_Q/q2_loss         | 85.868385  |
| training/sac_Q/q_global_norm   | 227.30592  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16220397  |
| epoch                          | 296         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4921.4536   |
| evaluation/return-max          | 4963.3037   |
| evaluation/return-min          | 4835.752    |
| evaluation/return-std          | 35.423107   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46245       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4921.4536   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 206.10051   |
| Q-std                          | 107.796455  |
| Q_loss                         | 106.81779   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 296         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000511    |
| times/evaluation_paths         | 37.2        |
| times/timestep_after_hook      | 0.0038      |
| times/timestep_before_hook     | 0.00896     |
| times/train                    | 60.4        |
| timestep                       | 1000        |
| timesteps_total                | 297000      |
| train-steps                    | 297000      |
| training/Q/q1_loss             | 105.93582   |
| training/sac_pi/alpha          | 0.16227576  |
| training/sac_pi/alpha_loss     | -0.19343449 |
| training/sac_pi/logp_pi        | 4.324626    |
| training/sac_pi/pi_entropy     | 3.676992    |
| training/sac_pi/pi_global_norm | 2.0347111   |
| training/sac_pi/policy_loss    | -212.27686  |
| training/sac_pi/std            | 0.5342855   |
| training/sac_pi/valid_num      | 4958.0      |
| training/sac_Q/q1              | 202.97781   |
| training/sac_Q/q2              | 205.33623   |
| training/sac_Q/q2_loss         | 104.2798    |
| training/sac_Q/q_global_norm   | 368.48935   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16401987 |
| epoch                          | 297        |
| evaluation/episode-length-avg  | 780        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 145        |
| evaluation/episode-length-std  | 336        |
| evaluation/return-average      | 3770.3704  |
| evaluation/return-max          | 5027.65    |
| evaluation/return-min          | 394.94708  |
| evaluation/return-std          | 1792.2423  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46365      |
| perf/AverageLength             | 780        |
| perf/AverageReturn             | 3770.3704  |
| perf/NormalizedReturn          | 0.821      |
| Q-avg                          | 207.26082  |
| Q-std                          | 95.260284  |
| Q_loss                         | 122.12067  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 297        |
| times/epoch_after_hook         | 3.15e-06   |
| times/epoch_before_hook        | 0.000296   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000682   |
| times/evaluation_paths         | 28.2       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00872    |
| times/train                    | 64.2       |
| timestep                       | 1000       |
| timesteps_total                | 298000     |
| train-steps                    | 298000     |
| training/Q/q1_loss             | 98.32015   |
| training/sac_pi/alpha          | 0.16400485 |
| training/sac_pi/alpha_loss     | 0.23007433 |
| training/sac_pi/logp_pi        | 4.1483507  |
| training/sac_pi/pi_entropy     | 3.6432672  |
| training/sac_pi/pi_global_norm | 1.7360142  |
| training/sac_pi/policy_loss    | -215.24713 |
| training/sac_pi/std            | 0.5070452  |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 205.81912  |
| training/sac_Q/q2              | 208.0942   |
| training/sac_Q/q2_loss         | 98.1026    |
| training/sac_Q/q_global_norm   | 352.29788  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1630926  |
| epoch                          | 298        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5149.123   |
| evaluation/return-max          | 5184.0444  |
| evaluation/return-min          | 5001.7686  |
| evaluation/return-std          | 50.1679    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46380      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5149.123   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 204.34409  |
| Q-std                          | 117.80039  |
| Q_loss                         | 98.60899   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 298        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.00057    |
| times/evaluation_paths         | 35.6       |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.00858    |
| times/train                    | 62.5       |
| timestep                       | 1000       |
| timesteps_total                | 299000     |
| train-steps                    | 299000     |
| training/Q/q1_loss             | 90.18491   |
| training/sac_pi/alpha          | 0.16306998 |
| training/sac_pi/alpha_loss     | 0.17445083 |
| training/sac_pi/logp_pi        | 4.2331653  |
| training/sac_pi/pi_entropy     | 3.5306733  |
| training/sac_pi/pi_global_norm | 2.1366348  |
| training/sac_pi/policy_loss    | -218.98471 |
| training/sac_pi/std            | 0.5150686  |
| training/sac_pi/valid_num      | 4996.0     |
| training/sac_Q/q1              | 210.71733  |
| training/sac_Q/q2              | 211.66008  |
| training/sac_Q/q2_loss         | 91.00977   |
| training/sac_Q/q_global_norm   | 201.74701  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1647362  |
| epoch                          | 299        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4948.351   |
| evaluation/return-max          | 5151.46    |
| evaluation/return-min          | 4868.5195  |
| evaluation/return-std          | 82.48818   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46413      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4948.351   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 220.46748  |
| Q-std                          | 106.431076 |
| Q_loss                         | 99.50598   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 299        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000633   |
| times/evaluation_paths         | 39.8       |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.00877    |
| times/train                    | 67.6       |
| timestep                       | 1000       |
| timesteps_total                | 300000     |
| train-steps                    | 300000     |
| training/Q/q1_loss             | 77.70146   |
| training/sac_pi/alpha          | 0.1647156  |
| training/sac_pi/alpha_loss     | -0.3891016 |
| training/sac_pi/logp_pi        | 3.74571    |
| training/sac_pi/pi_entropy     | 3.6927288  |
| training/sac_pi/pi_global_norm | 1.8672528  |
| training/sac_pi/policy_loss    | -222.90793 |
| training/sac_pi/std            | 0.51146054 |
| training/sac_pi/valid_num      | 4939.0     |
| training/sac_Q/q1              | 213.00229  |
| training/sac_Q/q2              | 215.45044  |
| training/sac_Q/q2_loss         | 77.09558   |
| training/sac_Q/q_global_norm   | 348.9399   |
--------------------------------------------------------------------------------
[WARN] 300 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16316205 |
| epoch                          | 300        |
| evaluation/episode-length-avg  | 404        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 146        |
| evaluation/episode-length-std  | 390        |
| evaluation/return-average      | 1845.0989  |
| evaluation/return-max          | 5155.233   |
| evaluation/return-min          | 443.89145  |
| evaluation/return-std          | 2113.6572  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46398      |
| perf/AverageLength             | 404        |
| perf/AverageReturn             | 1845.0989  |
| perf/NormalizedReturn          | 0.402      |
| Q-avg                          | 210.6958   |
| Q-std                          | 105.95427  |
| Q_loss                         | 99.37762   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 300        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 15.4       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 68.1       |
| timestep                       | 1000       |
| timesteps_total                | 301000     |
| train-steps                    | 301000     |
| training/Q/q1_loss             | 96.16767   |
| training/sac_pi/alpha          | 0.1631663  |
| training/sac_pi/alpha_loss     | 0.13174957 |
| training/sac_pi/logp_pi        | 4.5562334  |
| training/sac_pi/pi_entropy     | 3.5311503  |
| training/sac_pi/pi_global_norm | 1.9739377  |
| training/sac_pi/policy_loss    | -216.23419 |
| training/sac_pi/std            | 0.52555746 |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 205.10654  |
| training/sac_Q/q2              | 206.30766  |
| training/sac_Q/q2_loss         | 96.21357   |
| training/sac_Q/q_global_norm   | 231.26541  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17207025 |
| epoch                          | 301        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5037.844   |
| evaluation/return-max          | 5096.956   |
| evaluation/return-min          | 4990.478   |
| evaluation/return-std          | 28.459581  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 83.9       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46324      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5037.844   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 209.18062  |
| Q-std                          | 105.81364  |
| Q_loss                         | 90.884056  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 301        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000273   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000617   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.0088     |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 302000     |
| train-steps                    | 302000     |
| training/Q/q1_loss             | 110.953    |
| training/sac_pi/alpha          | 0.17201076 |
| training/sac_pi/alpha_loss     | 0.6152411  |
| training/sac_pi/logp_pi        | 5.2075014  |
| training/sac_pi/pi_entropy     | 3.736917   |
| training/sac_pi/pi_global_norm | 1.6435605  |
| training/sac_pi/policy_loss    | -207.80028 |
| training/sac_pi/std            | 0.5584249  |
| training/sac_pi/valid_num      | 4875.0     |
| training/sac_Q/q1              | 192.80252  |
| training/sac_Q/q2              | 194.12039  |
| training/sac_Q/q2_loss         | 112.320114 |
| training/sac_Q/q_global_norm   | 251.12343  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17095895 |
| epoch                          | 302        |
| evaluation/episode-length-avg  | 916        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 162        |
| evaluation/episode-length-std  | 251        |
| evaluation/return-average      | 4385.019   |
| evaluation/return-max          | 4915.835   |
| evaluation/return-min          | 424.0929   |
| evaluation/return-std          | 1320.9463  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 87         |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46154      |
| perf/AverageLength             | 916        |
| perf/AverageReturn             | 4385.019   |
| perf/NormalizedReturn          | 0.955      |
| Q-avg                          | 207.9388   |
| Q-std                          | 97.49658   |
| Q_loss                         | 104.29447  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 302        |
| times/epoch_after_hook         | 1.6e-06    |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000575   |
| times/evaluation_paths         | 41.4       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00907    |
| times/train                    | 65.1       |
| timestep                       | 1000       |
| timesteps_total                | 303000     |
| train-steps                    | 303000     |
| training/Q/q1_loss             | 108.85731  |
| training/sac_pi/alpha          | 0.17094459 |
| training/sac_pi/alpha_loss     | 0.466189   |
| training/sac_pi/logp_pi        | 3.7025256  |
| training/sac_pi/pi_entropy     | 3.5456765  |
| training/sac_pi/pi_global_norm | 1.8604658  |
| training/sac_pi/policy_loss    | -208.84465 |
| training/sac_pi/std            | 0.47163385 |
| training/sac_pi/valid_num      | 4963.0     |
| training/sac_Q/q1              | 202.50601  |
| training/sac_Q/q2              | 203.1906   |
| training/sac_Q/q2_loss         | 107.29868  |
| training/sac_Q/q_global_norm   | 230.79631  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16932388 |
| epoch                          | 303        |
| evaluation/episode-length-avg  | 580        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 146        |
| evaluation/episode-length-std  | 420        |
| evaluation/return-average      | 2663.6375  |
| evaluation/return-max          | 4966.468   |
| evaluation/return-min          | 373.31348  |
| evaluation/return-std          | 2244.6902  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 81.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46405      |
| perf/AverageLength             | 580        |
| perf/AverageReturn             | 2663.6375  |
| perf/NormalizedReturn          | 0.58       |
| Q-avg                          | 215.52226  |
| Q-std                          | 91.99085   |
| Q_loss                         | 83.241684  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 303        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000568   |
| times/evaluation_paths         | 27.2       |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.00856    |
| times/train                    | 63.3       |
| timestep                       | 1000       |
| timesteps_total                | 304000     |
| train-steps                    | 304000     |
| training/Q/q1_loss             | 98.57872   |
| training/sac_pi/alpha          | 0.1693604  |
| training/sac_pi/alpha_loss     | -0.3391127 |
| training/sac_pi/logp_pi        | 3.9629104  |
| training/sac_pi/pi_entropy     | 3.570208   |
| training/sac_pi/pi_global_norm | 2.2871864  |
| training/sac_pi/policy_loss    | -213.79128 |
| training/sac_pi/std            | 0.5115847  |
| training/sac_pi/valid_num      | 4991.0     |
| training/sac_Q/q1              | 205.09067  |
| training/sac_Q/q2              | 206.5192   |
| training/sac_Q/q2_loss         | 99.23439   |
| training/sac_Q/q_global_norm   | 218.11684  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16427155 |
| epoch                          | 304        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4860.0947  |
| evaluation/return-max          | 5047.122   |
| evaluation/return-min          | 4734.9395  |
| evaluation/return-std          | 99.43163   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46342      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4860.0947  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 222.09456  |
| Q-std                          | 91.28913   |
| Q_loss                         | 99.16298   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 304        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000659   |
| times/evaluation_paths         | 40.1       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00885    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 305000     |
| train-steps                    | 305000     |
| training/Q/q1_loss             | 89.29063   |
| training/sac_pi/alpha          | 0.16425811 |
| training/sac_pi/alpha_loss     | 0.08733706 |
| training/sac_pi/logp_pi        | 3.7463467  |
| training/sac_pi/pi_entropy     | 3.5507226  |
| training/sac_pi/pi_global_norm | 1.9593017  |
| training/sac_pi/policy_loss    | -212.8509  |
| training/sac_pi/std            | 0.4950162  |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 205.06477  |
| training/sac_Q/q2              | 205.1722   |
| training/sac_Q/q2_loss         | 88.63309   |
| training/sac_Q/q_global_norm   | 174.16258  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16562486 |
| epoch                          | 305        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4953.007   |
| evaluation/return-max          | 4975.6387  |
| evaluation/return-min          | 4917.8564  |
| evaluation/return-std          | 16.241785  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46341      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4953.007   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 216.74055  |
| Q-std                          | 90.71486   |
| Q_loss                         | 89.30648   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 305        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000274   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000689   |
| times/evaluation_paths         | 42.6       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 68.2       |
| timestep                       | 1000       |
| timesteps_total                | 306000     |
| train-steps                    | 306000     |
| training/Q/q1_loss             | 106.18701  |
| training/sac_pi/alpha          | 0.16564716 |
| training/sac_pi/alpha_loss     | 0.34497827 |
| training/sac_pi/logp_pi        | 4.815465   |
| training/sac_pi/pi_entropy     | 3.3470898  |
| training/sac_pi/pi_global_norm | 2.041156   |
| training/sac_pi/policy_loss    | -215.85846 |
| training/sac_pi/std            | 0.5058896  |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 204.40494  |
| training/sac_Q/q2              | 207.06918  |
| training/sac_Q/q2_loss         | 106.30348  |
| training/sac_Q/q_global_norm   | 293.8459   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16408964 |
| epoch                          | 306        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4980.1426  |
| evaluation/return-max          | 5030.808   |
| evaluation/return-min          | 4899.9346  |
| evaluation/return-std          | 40.220394  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46253      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4980.1426  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 206.6668   |
| Q-std                          | 101.67671  |
| Q_loss                         | 131.94838  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 306        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000119   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000619   |
| times/evaluation_paths         | 34.9       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00858    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 307000     |
| train-steps                    | 307000     |
| training/Q/q1_loss             | 100.76742  |
| training/sac_pi/alpha          | 0.16408256 |
| training/sac_pi/alpha_loss     | 0.29934222 |
| training/sac_pi/logp_pi        | 5.222789   |
| training/sac_pi/pi_entropy     | 3.4576836  |
| training/sac_pi/pi_global_norm | 1.8654159  |
| training/sac_pi/policy_loss    | -211.11311 |
| training/sac_pi/std            | 0.5282543  |
| training/sac_pi/valid_num      | 4879.0     |
| training/sac_Q/q1              | 197.67532  |
| training/sac_Q/q2              | 199.22862  |
| training/sac_Q/q2_loss         | 102.15403  |
| training/sac_Q/q_global_norm   | 278.66498  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1617966  |
| epoch                          | 307        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5050.2593  |
| evaluation/return-max          | 5102.5083  |
| evaluation/return-min          | 4893.2896  |
| evaluation/return-std          | 55.575584  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46347      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5050.2593  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 207.22038  |
| Q-std                          | 95.72494   |
| Q_loss                         | 98.57053   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 307        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000565   |
| times/evaluation_paths         | 35         |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00863    |
| times/train                    | 61.5       |
| timestep                       | 1000       |
| timesteps_total                | 308000     |
| train-steps                    | 308000     |
| training/Q/q1_loss             | 97.66217   |
| training/sac_pi/alpha          | 0.16179301 |
| training/sac_pi/alpha_loss     | 0.12866937 |
| training/sac_pi/logp_pi        | 4.6558256  |
| training/sac_pi/pi_entropy     | 3.507122   |
| training/sac_pi/pi_global_norm | 2.2097116  |
| training/sac_pi/policy_loss    | -216.94861 |
| training/sac_pi/std            | 0.5138708  |
| training/sac_pi/valid_num      | 4928.0     |
| training/sac_Q/q1              | 204.8392   |
| training/sac_Q/q2              | 206.64554  |
| training/sac_Q/q2_loss         | 97.88869   |
| training/sac_Q/q_global_norm   | 239.4394   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16198055 |
| epoch                          | 308        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5191.8164  |
| evaluation/return-max          | 5262.1143  |
| evaluation/return-min          | 5102.6006  |
| evaluation/return-std          | 41.651413  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46249      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5191.8164  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 210.61772  |
| Q-std                          | 100.66771  |
| Q_loss                         | 94.90886   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 308        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000602   |
| times/evaluation_paths         | 35.8       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00878    |
| times/train                    | 61.5       |
| timestep                       | 1000       |
| timesteps_total                | 309000     |
| train-steps                    | 309000     |
| training/Q/q1_loss             | 111.311714 |
| training/sac_pi/alpha          | 0.16196492 |
| training/sac_pi/alpha_loss     | 0.14351259 |
| training/sac_pi/logp_pi        | 4.851285   |
| training/sac_pi/pi_entropy     | 3.5598845  |
| training/sac_pi/pi_global_norm | 1.6539463  |
| training/sac_pi/policy_loss    | -210.5595  |
| training/sac_pi/std            | 0.5129585  |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 202.67856  |
| training/sac_Q/q2              | 205.80977  |
| training/sac_Q/q2_loss         | 111.43543  |
| training/sac_Q/q_global_norm   | 407.77875  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1653073    |
| epoch                          | 309          |
| evaluation/episode-length-avg  | 915          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 154          |
| evaluation/episode-length-std  | 254          |
| evaluation/return-average      | 4406.4814    |
| evaluation/return-max          | 4878.961     |
| evaluation/return-min          | 472.18362    |
| evaluation/return-std          | 1311.6815    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.14         |
| model/origin_ret               | 86.9         |
| model/penalty_ret              | 80.5         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46305        |
| perf/AverageLength             | 915          |
| perf/AverageReturn             | 4406.4814    |
| perf/NormalizedReturn          | 0.96         |
| Q-avg                          | 208.38986    |
| Q-std                          | 98.03965     |
| Q_loss                         | 124.16039    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 309          |
| times/epoch_after_hook         | 1.69e-06     |
| times/epoch_before_hook        | 0.000274     |
| times/epoch_rollout_model      | 488          |
| times/evaluation_metrics       | 0.000712     |
| times/evaluation_paths         | 32.5         |
| times/timestep_after_hook      | 0.00374      |
| times/timestep_before_hook     | 0.00865      |
| times/train                    | 59.8         |
| timestep                       | 1000         |
| timesteps_total                | 310000       |
| train-steps                    | 310000       |
| training/Q/q1_loss             | 100.31587    |
| training/sac_pi/alpha          | 0.16526991   |
| training/sac_pi/alpha_loss     | -0.019044604 |
| training/sac_pi/logp_pi        | 5.0413065    |
| training/sac_pi/pi_entropy     | 3.7256134    |
| training/sac_pi/pi_global_norm | 1.5901233    |
| training/sac_pi/policy_loss    | -219.36607   |
| training/sac_pi/std            | 0.5693874    |
| training/sac_pi/valid_num      | 4888.0       |
| training/sac_Q/q1              | 206.8457     |
| training/sac_Q/q2              | 210.74179    |
| training/sac_Q/q2_loss         | 101.396355   |
| training/sac_Q/q_global_norm   | 256.94452    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16699617  |
| epoch                          | 310         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5249.2915   |
| evaluation/return-max          | 5334.462    |
| evaluation/return-min          | 5174.673    |
| evaluation/return-std          | 44.140892   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 80.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46496       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5249.2915   |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 211.9316    |
| Q-std                          | 89.03014    |
| Q_loss                         | 89.07131    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 310         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000234    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000594    |
| times/evaluation_paths         | 35.7        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00886     |
| times/train                    | 61.8        |
| timestep                       | 1000        |
| timesteps_total                | 311000      |
| train-steps                    | 311000      |
| training/Q/q1_loss             | 124.61311   |
| training/sac_pi/alpha          | 0.16703114  |
| training/sac_pi/alpha_loss     | -0.16968597 |
| training/sac_pi/logp_pi        | 4.6902337   |
| training/sac_pi/pi_entropy     | 3.7363372   |
| training/sac_pi/pi_global_norm | 2.2257776   |
| training/sac_pi/policy_loss    | -219.10873  |
| training/sac_pi/std            | 0.5408645   |
| training/sac_pi/valid_num      | 4926.0      |
| training/sac_Q/q1              | 207.36177   |
| training/sac_Q/q2              | 210.15259   |
| training/sac_Q/q2_loss         | 125.16421   |
| training/sac_Q/q_global_norm   | 271.3247    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16536587 |
| epoch                          | 311        |
| evaluation/episode-length-avg  | 747        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 154        |
| evaluation/episode-length-std  | 387        |
| evaluation/return-average      | 3683.105   |
| evaluation/return-max          | 5128.3477  |
| evaluation/return-min          | 495.97528  |
| evaluation/return-std          | 2082.1794  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46479      |
| perf/AverageLength             | 747        |
| perf/AverageReturn             | 3683.105   |
| perf/NormalizedReturn          | 0.802      |
| Q-avg                          | 216.62862  |
| Q-std                          | 97.84027   |
| Q_loss                         | 94.69355   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 311        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000451   |
| times/evaluation_paths         | 26.5       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00865    |
| times/train                    | 62.4       |
| timestep                       | 1000       |
| timesteps_total                | 312000     |
| train-steps                    | 312000     |
| training/Q/q1_loss             | 112.850655 |
| training/sac_pi/alpha          | 0.16537373 |
| training/sac_pi/alpha_loss     | 0.3072851  |
| training/sac_pi/logp_pi        | 5.044297   |
| training/sac_pi/pi_entropy     | 3.3072705  |
| training/sac_pi/pi_global_norm | 2.0999947  |
| training/sac_pi/policy_loss    | -220.07074 |
| training/sac_pi/std            | 0.47800675 |
| training/sac_pi/valid_num      | 4967.0     |
| training/sac_Q/q1              | 210.51936  |
| training/sac_Q/q2              | 213.01814  |
| training/sac_Q/q2_loss         | 112.34682  |
| training/sac_Q/q_global_norm   | 276.26404  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17349629 |
| epoch                          | 312        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4773.7617  |
| evaluation/return-max          | 4961.525   |
| evaluation/return-min          | 4680.2173  |
| evaluation/return-std          | 77.49115   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46425      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4773.7617  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 209.09677  |
| Q-std                          | 101.31698  |
| Q_loss                         | 93.33144   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 312        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000631   |
| times/evaluation_paths         | 35.9       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00863    |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 313000     |
| train-steps                    | 313000     |
| training/Q/q1_loss             | 95.48442   |
| training/sac_pi/alpha          | 0.17349757 |
| training/sac_pi/alpha_loss     | 0.16566917 |
| training/sac_pi/logp_pi        | 4.116693   |
| training/sac_pi/pi_entropy     | 3.4834435  |
| training/sac_pi/pi_global_norm | 1.6145769  |
| training/sac_pi/policy_loss    | -210.50938 |
| training/sac_pi/std            | 0.49144867 |
| training/sac_pi/valid_num      | 4999.0     |
| training/sac_Q/q1              | 203.74893  |
| training/sac_Q/q2              | 205.43803  |
| training/sac_Q/q2_loss         | 95.06608   |
| training/sac_Q/q_global_norm   | 208.65984  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17281681 |
| epoch                          | 313        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5106.5557  |
| evaluation/return-max          | 5150.877   |
| evaluation/return-min          | 5067.3594  |
| evaluation/return-std          | 29.42884   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46268      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5106.5557  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 210.2146   |
| Q-std                          | 97.800354  |
| Q_loss                         | 111.391174 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 313        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000286   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000546   |
| times/evaluation_paths         | 37.9       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 314000     |
| train-steps                    | 314000     |
| training/Q/q1_loss             | 106.889175 |
| training/sac_pi/alpha          | 0.17282328 |
| training/sac_pi/alpha_loss     | 0.12950318 |
| training/sac_pi/logp_pi        | 3.9132257  |
| training/sac_pi/pi_entropy     | 3.5878072  |
| training/sac_pi/pi_global_norm | 2.05625    |
| training/sac_pi/policy_loss    | -211.84624 |
| training/sac_pi/std            | 0.49318177 |
| training/sac_pi/valid_num      | 5027.0     |
| training/sac_Q/q1              | 207.3873   |
| training/sac_Q/q2              | 208.45256  |
| training/sac_Q/q2_loss         | 106.22459  |
| training/sac_Q/q_global_norm   | 260.82053  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17088754 |
| epoch                          | 314        |
| evaluation/episode-length-avg  | 929        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 287        |
| evaluation/episode-length-std  | 214        |
| evaluation/return-average      | 4486.461   |
| evaluation/return-max          | 4880.559   |
| evaluation/return-min          | 1144.67    |
| evaluation/return-std          | 1114.0542  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46421      |
| perf/AverageLength             | 929        |
| perf/AverageReturn             | 4486.461   |
| perf/NormalizedReturn          | 0.977      |
| Q-avg                          | 215.10986  |
| Q-std                          | 95.23587   |
| Q_loss                         | 108.69398  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 314        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000808   |
| times/evaluation_paths         | 35.2       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00866    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 315000     |
| train-steps                    | 315000     |
| training/Q/q1_loss             | 92.35568   |
| training/sac_pi/alpha          | 0.17086798 |
| training/sac_pi/alpha_loss     | 0.38244608 |
| training/sac_pi/logp_pi        | 4.336168   |
| training/sac_pi/pi_entropy     | 3.512032   |
| training/sac_pi/pi_global_norm | 1.5683675  |
| training/sac_pi/policy_loss    | -217.399   |
| training/sac_pi/std            | 0.49452597 |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 209.5396   |
| training/sac_Q/q2              | 209.30722  |
| training/sac_Q/q2_loss         | 91.980865  |
| training/sac_Q/q_global_norm   | 246.93102  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.170153   |
| epoch                          | 315        |
| evaluation/episode-length-avg  | 865        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 386        |
| evaluation/episode-length-std  | 241        |
| evaluation/return-average      | 4186.232   |
| evaluation/return-max          | 5114.9053  |
| evaluation/return-min          | 1642.0635  |
| evaluation/return-std          | 1290.5476  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46386      |
| perf/AverageLength             | 865        |
| perf/AverageReturn             | 4186.232   |
| perf/NormalizedReturn          | 0.912      |
| Q-avg                          | 199.41989  |
| Q-std                          | 114.454185 |
| Q_loss                         | 86.02284   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 315        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000625   |
| times/evaluation_paths         | 32.5       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00857    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 316000     |
| train-steps                    | 316000     |
| training/Q/q1_loss             | 81.69639   |
| training/sac_pi/alpha          | 0.17012113 |
| training/sac_pi/alpha_loss     | 0.17411496 |
| training/sac_pi/logp_pi        | 4.3661757  |
| training/sac_pi/pi_entropy     | 3.5432854  |
| training/sac_pi/pi_global_norm | 1.8865628  |
| training/sac_pi/policy_loss    | -227.83472 |
| training/sac_pi/std            | 0.5044271  |
| training/sac_pi/valid_num      | 4956.0     |
| training/sac_Q/q1              | 218.65388  |
| training/sac_Q/q2              | 219.74332  |
| training/sac_Q/q2_loss         | 80.686066  |
| training/sac_Q/q_global_norm   | 271.52267  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17064856 |
| epoch                          | 316        |
| evaluation/episode-length-avg  | 915        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 148        |
| evaluation/episode-length-std  | 256        |
| evaluation/return-average      | 4034.1133  |
| evaluation/return-max          | 4504.3057  |
| evaluation/return-min          | 461.78616  |
| evaluation/return-std          | 1191.7697  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46370      |
| perf/AverageLength             | 915        |
| perf/AverageReturn             | 4034.1133  |
| perf/NormalizedReturn          | 0.878      |
| Q-avg                          | 204.31369  |
| Q-std                          | 100.52984  |
| Q_loss                         | 100.64419  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 316        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000538   |
| times/evaluation_paths         | 33.7       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 317000     |
| train-steps                    | 317000     |
| training/Q/q1_loss             | 93.27167   |
| training/sac_pi/alpha          | 0.17060213 |
| training/sac_pi/alpha_loss     | 0.40489852 |
| training/sac_pi/logp_pi        | 3.8157082  |
| training/sac_pi/pi_entropy     | 3.3905983  |
| training/sac_pi/pi_global_norm | 1.8524456  |
| training/sac_pi/policy_loss    | -215.18085 |
| training/sac_pi/std            | 0.4568641  |
| training/sac_pi/valid_num      | 5011.0     |
| training/sac_Q/q1              | 210.83101  |
| training/sac_Q/q2              | 211.68465  |
| training/sac_Q/q2_loss         | 94.26893   |
| training/sac_Q/q_global_norm   | 204.06229  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16839927 |
| epoch                          | 317        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5013.741   |
| evaluation/return-max          | 5081.6484  |
| evaluation/return-min          | 4918.3667  |
| evaluation/return-std          | 52.781944  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46377      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5013.741   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 199.97234  |
| Q-std                          | 117.33387  |
| Q_loss                         | 115.71161  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 317        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000277   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000546   |
| times/evaluation_paths         | 36.9       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 318000     |
| train-steps                    | 318000     |
| training/Q/q1_loss             | 104.41301  |
| training/sac_pi/alpha          | 0.1683676  |
| training/sac_pi/alpha_loss     | 0.33006397 |
| training/sac_pi/logp_pi        | 4.0332723  |
| training/sac_pi/pi_entropy     | 3.438945   |
| training/sac_pi/pi_global_norm | 1.8200516  |
| training/sac_pi/policy_loss    | -215.94312 |
| training/sac_pi/std            | 0.48194414 |
| training/sac_pi/valid_num      | 4984.0     |
| training/sac_Q/q1              | 208.18442  |
| training/sac_Q/q2              | 209.26431  |
| training/sac_Q/q2_loss         | 105.12477  |
| training/sac_Q/q_global_norm   | 242.47083  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16892397 |
| epoch                          | 318        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5092.018   |
| evaluation/return-max          | 5119.087   |
| evaluation/return-min          | 5066.5737  |
| evaluation/return-std          | 15.244614  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46366      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5092.018   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 218.87495  |
| Q-std                          | 92.93779   |
| Q_loss                         | 75.36044   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 318        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000146   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000549   |
| times/evaluation_paths         | 37.7       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00846    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 319000     |
| train-steps                    | 319000     |
| training/Q/q1_loss             | 98.36766   |
| training/sac_pi/alpha          | 0.16888282 |
| training/sac_pi/alpha_loss     | 0.108632   |
| training/sac_pi/logp_pi        | 4.1141562  |
| training/sac_pi/pi_entropy     | 3.5115914  |
| training/sac_pi/pi_global_norm | 1.7335755  |
| training/sac_pi/policy_loss    | -219.0283  |
| training/sac_pi/std            | 0.49795324 |
| training/sac_pi/valid_num      | 4963.0     |
| training/sac_Q/q1              | 210.96506  |
| training/sac_Q/q2              | 212.00664  |
| training/sac_Q/q2_loss         | 98.84383   |
| training/sac_Q/q_global_norm   | 227.2456   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16691744 |
| epoch                          | 319        |
| evaluation/episode-length-avg  | 159        |
| evaluation/episode-length-max  | 177        |
| evaluation/episode-length-min  | 139        |
| evaluation/episode-length-std  | 11.3       |
| evaluation/return-average      | 408.79694  |
| evaluation/return-max          | 475.0636   |
| evaluation/return-min          | 303.94147  |
| evaluation/return-std          | 54.178326  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46206      |
| perf/AverageLength             | 159        |
| perf/AverageReturn             | 408.79694  |
| perf/NormalizedReturn          | 0.0887     |
| Q-avg                          | 218.2094   |
| Q-std                          | 103.82228  |
| Q_loss                         | 87.33634   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 319        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000513   |
| times/evaluation_paths         | 6.94       |
| times/timestep_after_hook      | 0.00649    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 320000     |
| train-steps                    | 320000     |
| training/Q/q1_loss             | 105.10777  |
| training/sac_pi/alpha          | 0.16691934 |
| training/sac_pi/alpha_loss     | 0.12299893 |
| training/sac_pi/logp_pi        | 4.1879454  |
| training/sac_pi/pi_entropy     | 3.4052818  |
| training/sac_pi/pi_global_norm | 2.3013787  |
| training/sac_pi/policy_loss    | -221.63475 |
| training/sac_pi/std            | 0.49915996 |
| training/sac_pi/valid_num      | 4985.0     |
| training/sac_Q/q1              | 214.6459   |
| training/sac_Q/q2              | 216.68462  |
| training/sac_Q/q2_loss         | 104.350464 |
| training/sac_Q/q_global_norm   | 279.02194  |
--------------------------------------------------------------------------------
[WARN] 320 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16810274  |
| epoch                          | 320         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5077.8315   |
| evaluation/return-max          | 5137.7363   |
| evaluation/return-min          | 5005.7812   |
| evaluation/return-std          | 45.006077   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46361       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5077.8315   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 214.15543   |
| Q-std                          | 100.31138   |
| Q_loss                         | 97.206604   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 320         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 8.37e-05    |
| times/epoch_rollout_model      | 516         |
| times/evaluation_metrics       | 0.000613    |
| times/evaluation_paths         | 36.9        |
| times/timestep_after_hook      | 0.00387     |
| times/timestep_before_hook     | 0.00853     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 321000      |
| train-steps                    | 321000      |
| training/Q/q1_loss             | 85.77012    |
| training/sac_pi/alpha          | 0.16810249  |
| training/sac_pi/alpha_loss     | -0.24077444 |
| training/sac_pi/logp_pi        | 3.7640023   |
| training/sac_pi/pi_entropy     | 3.3768623   |
| training/sac_pi/pi_global_norm | 1.6088387   |
| training/sac_pi/policy_loss    | -221.73997  |
| training/sac_pi/std            | 0.4822658   |
| training/sac_pi/valid_num      | 5049.0      |
| training/sac_Q/q1              | 217.54517   |
| training/sac_Q/q2              | 219.36084   |
| training/sac_Q/q2_loss         | 86.20976    |
| training/sac_Q/q_global_norm   | 220.95616   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17132604   |
| epoch                          | 321          |
| evaluation/episode-length-avg  | 832          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 159          |
| evaluation/episode-length-std  | 336          |
| evaluation/return-average      | 4325.496     |
| evaluation/return-max          | 5284.3516    |
| evaluation/return-min          | 536.56647    |
| evaluation/return-std          | 1892.9513    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.08         |
| model/origin_ret               | 86.3         |
| model/penalty_ret              | 79.8         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46408        |
| perf/AverageLength             | 832          |
| perf/AverageReturn             | 4325.496     |
| perf/NormalizedReturn          | 0.942        |
| Q-avg                          | 212.29597    |
| Q-std                          | 108.54656    |
| Q_loss                         | 113.590385   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 321          |
| times/epoch_after_hook         | 1.73e-06     |
| times/epoch_before_hook        | 0.000282     |
| times/epoch_rollout_model      | 491          |
| times/evaluation_metrics       | 0.000504     |
| times/evaluation_paths         | 29.5         |
| times/timestep_after_hook      | 0.00375      |
| times/timestep_before_hook     | 0.00884      |
| times/train                    | 62.5         |
| timestep                       | 1000         |
| timesteps_total                | 322000       |
| train-steps                    | 322000       |
| training/Q/q1_loss             | 99.96459     |
| training/sac_pi/alpha          | 0.17134686   |
| training/sac_pi/alpha_loss     | -0.115024656 |
| training/sac_pi/logp_pi        | 3.7317307    |
| training/sac_pi/pi_entropy     | 3.6625793    |
| training/sac_pi/pi_global_norm | 1.5851902    |
| training/sac_pi/policy_loss    | -220.11646   |
| training/sac_pi/std            | 0.4932376    |
| training/sac_pi/valid_num      | 5018.0       |
| training/sac_Q/q1              | 213.53516    |
| training/sac_Q/q2              | 215.08794    |
| training/sac_Q/q2_loss         | 99.4566      |
| training/sac_Q/q_global_norm   | 211.593      |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16946751  |
| epoch                          | 322         |
| evaluation/episode-length-avg  | 411         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 151         |
| evaluation/episode-length-std  | 386         |
| evaluation/return-average      | 1838.2708   |
| evaluation/return-max          | 4984.7227   |
| evaluation/return-min          | 468.08496   |
| evaluation/return-std          | 2056.063    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46393       |
| perf/AverageLength             | 411         |
| perf/AverageReturn             | 1838.2708   |
| perf/NormalizedReturn          | 0.4         |
| Q-avg                          | 206.94614   |
| Q-std                          | 120.32194   |
| Q_loss                         | 88.6893     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 322         |
| times/epoch_after_hook         | 1.66e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000538    |
| times/evaluation_paths         | 15.9        |
| times/timestep_after_hook      | 0.00381     |
| times/timestep_before_hook     | 0.00856     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 323000      |
| train-steps                    | 323000      |
| training/Q/q1_loss             | 91.147354   |
| training/sac_pi/alpha          | 0.16947025  |
| training/sac_pi/alpha_loss     | -0.37122893 |
| training/sac_pi/logp_pi        | 4.0928965   |
| training/sac_pi/pi_entropy     | 3.6386917   |
| training/sac_pi/pi_global_norm | 2.0369134   |
| training/sac_pi/policy_loss    | -212.69698  |
| training/sac_pi/std            | 0.52699274  |
| training/sac_pi/valid_num      | 4967.0      |
| training/sac_Q/q1              | 204.57292   |
| training/sac_Q/q2              | 206.88184   |
| training/sac_Q/q2_loss         | 91.24076    |
| training/sac_Q/q_global_norm   | 291.79285   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16245367 |
| epoch                          | 323        |
| evaluation/episode-length-avg  | 933        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 330        |
| evaluation/episode-length-std  | 201        |
| evaluation/return-average      | 4537.702   |
| evaluation/return-max          | 5015.037   |
| evaluation/return-min          | 1291.11    |
| evaluation/return-std          | 1084.9707  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46276      |
| perf/AverageLength             | 933        |
| perf/AverageReturn             | 4537.702   |
| perf/NormalizedReturn          | 0.988      |
| Q-avg                          | 208.37956  |
| Q-std                          | 105.55775  |
| Q_loss                         | 132.66953  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 323        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000699   |
| times/evaluation_paths         | 32.5       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 324000     |
| train-steps                    | 324000     |
| training/Q/q1_loss             | 85.82882   |
| training/sac_pi/alpha          | 0.16248013 |
| training/sac_pi/alpha_loss     | -0.2620771 |
| training/sac_pi/logp_pi        | 4.3358717  |
| training/sac_pi/pi_entropy     | 3.6430688  |
| training/sac_pi/pi_global_norm | 1.9595484  |
| training/sac_pi/policy_loss    | -222.62637 |
| training/sac_pi/std            | 0.5337699  |
| training/sac_pi/valid_num      | 4942.0     |
| training/sac_Q/q1              | 211.23653  |
| training/sac_Q/q2              | 213.29301  |
| training/sac_Q/q2_loss         | 86.59298   |
| training/sac_Q/q_global_norm   | 389.7232   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16900744 |
| epoch                          | 324        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4750.2725  |
| evaluation/return-max          | 4814.254   |
| evaluation/return-min          | 4691.7417  |
| evaluation/return-std          | 40.789265  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46246      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4750.2725  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 214.40909  |
| Q-std                          | 85.94254   |
| Q_loss                         | 91.51039   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 324        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000314   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000564   |
| times/evaluation_paths         | 34.9       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 325000     |
| train-steps                    | 325000     |
| training/Q/q1_loss             | 103.36865  |
| training/sac_pi/alpha          | 0.16903764 |
| training/sac_pi/alpha_loss     | 0.10237813 |
| training/sac_pi/logp_pi        | 4.518094   |
| training/sac_pi/pi_entropy     | 3.5769439  |
| training/sac_pi/pi_global_norm | 1.6660019  |
| training/sac_pi/policy_loss    | -212.17625 |
| training/sac_pi/std            | 0.5151204  |
| training/sac_pi/valid_num      | 4955.0     |
| training/sac_Q/q1              | 204.8894   |
| training/sac_Q/q2              | 206.36617  |
| training/sac_Q/q2_loss         | 103.107124 |
| training/sac_Q/q_global_norm   | 228.86453  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1702472  |
| epoch                          | 325        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4928.3525  |
| evaluation/return-max          | 5006.0117  |
| evaluation/return-min          | 4857.0166  |
| evaluation/return-std          | 38.75946   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46311      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4928.3525  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 209.87102  |
| Q-std                          | 107.20768  |
| Q_loss                         | 96.42682   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 325        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.000455   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000983   |
| times/evaluation_paths         | 36.3       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 326000     |
| train-steps                    | 326000     |
| training/Q/q1_loss             | 136.75012  |
| training/sac_pi/alpha          | 0.17024007 |
| training/sac_pi/alpha_loss     | 0.16805099 |
| training/sac_pi/logp_pi        | 4.5238867  |
| training/sac_pi/pi_entropy     | 3.7977207  |
| training/sac_pi/pi_global_norm | 1.448265   |
| training/sac_pi/policy_loss    | -219.97054 |
| training/sac_pi/std            | 0.5495188  |
| training/sac_pi/valid_num      | 4938.0     |
| training/sac_Q/q1              | 209.00533  |
| training/sac_Q/q2              | 210.93315  |
| training/sac_Q/q2_loss         | 137.6558   |
| training/sac_Q/q_global_norm   | 274.1308   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16719586 |
| epoch                          | 326        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4970.837   |
| evaluation/return-max          | 5032.294   |
| evaluation/return-min          | 4842.2725  |
| evaluation/return-std          | 59.113216  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46245      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4970.837   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 210.58752  |
| Q-std                          | 101.62117  |
| Q_loss                         | 108.8065   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 326        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000596   |
| times/evaluation_paths         | 37.3       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00846    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 327000     |
| train-steps                    | 327000     |
| training/Q/q1_loss             | 90.55612   |
| training/sac_pi/alpha          | 0.1671542  |
| training/sac_pi/alpha_loss     | 0.40864483 |
| training/sac_pi/logp_pi        | 4.8480177  |
| training/sac_pi/pi_entropy     | 3.3404243  |
| training/sac_pi/pi_global_norm | 2.448205   |
| training/sac_pi/policy_loss    | -222.31236 |
| training/sac_pi/std            | 0.49363986 |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 210.84526  |
| training/sac_Q/q2              | 212.40384  |
| training/sac_Q/q2_loss         | 90.603714  |
| training/sac_Q/q_global_norm   | 230.02841  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16836531  |
| epoch                          | 327         |
| evaluation/episode-length-avg  | 924         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 481         |
| evaluation/episode-length-std  | 155         |
| evaluation/return-average      | 4642.0645   |
| evaluation/return-max          | 5118.8486   |
| evaluation/return-min          | 2205.374    |
| evaluation/return-std          | 861.80096   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46292       |
| perf/AverageLength             | 924         |
| perf/AverageReturn             | 4642.0645   |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 200.9849    |
| Q-std                          | 124.001144  |
| Q_loss                         | 108.41016   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 327         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000153    |
| times/epoch_rollout_model      | 507         |
| times/evaluation_metrics       | 0.000543    |
| times/evaluation_paths         | 32.3        |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.00871     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 328000      |
| train-steps                    | 328000      |
| training/Q/q1_loss             | 88.40866    |
| training/sac_pi/alpha          | 0.16837528  |
| training/sac_pi/alpha_loss     | -0.36424732 |
| training/sac_pi/logp_pi        | 4.0704966   |
| training/sac_pi/pi_entropy     | 3.3358123   |
| training/sac_pi/pi_global_norm | 2.146292    |
| training/sac_pi/policy_loss    | -219.75845  |
| training/sac_pi/std            | 0.4825262   |
| training/sac_pi/valid_num      | 4997.0      |
| training/sac_Q/q1              | 214.39468   |
| training/sac_Q/q2              | 216.74287   |
| training/sac_Q/q2_loss         | 89.34218    |
| training/sac_Q/q_global_norm   | 246.63478   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17504792  |
| epoch                          | 328         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5026.526    |
| evaluation/return-max          | 5151.356    |
| evaluation/return-min          | 4930.6665   |
| evaluation/return-std          | 65.043846   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46434       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5026.526    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 217.04956   |
| Q-std                          | 91.74976    |
| Q_loss                         | 105.15011   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 328         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000668    |
| times/evaluation_paths         | 35.4        |
| times/timestep_after_hook      | 0.0038      |
| times/timestep_before_hook     | 0.00861     |
| times/train                    | 61.6        |
| timestep                       | 1000        |
| timesteps_total                | 329000      |
| train-steps                    | 329000      |
| training/Q/q1_loss             | 88.987595   |
| training/sac_pi/alpha          | 0.17505556  |
| training/sac_pi/alpha_loss     | -0.15964857 |
| training/sac_pi/logp_pi        | 4.445456    |
| training/sac_pi/pi_entropy     | 3.6023116   |
| training/sac_pi/pi_global_norm | 2.1725252   |
| training/sac_pi/policy_loss    | -223.21907  |
| training/sac_pi/std            | 0.51841414  |
| training/sac_pi/valid_num      | 4956.0      |
| training/sac_Q/q1              | 214.41891   |
| training/sac_Q/q2              | 216.04053   |
| training/sac_Q/q2_loss         | 90.008095   |
| training/sac_Q/q_global_norm   | 319.793     |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17064352   |
| epoch                          | 329          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5405.083     |
| evaluation/return-max          | 5454.0674    |
| evaluation/return-min          | 5186.9326    |
| evaluation/return-std          | 74.41873     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.12         |
| model/origin_ret               | 86.3         |
| model/penalty_ret              | 79.3         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46236        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5405.083     |
| perf/NormalizedReturn          | 1.18         |
| Q-avg                          | 214.51978    |
| Q-std                          | 101.37575    |
| Q_loss                         | 118.6965     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 329          |
| times/epoch_after_hook         | 1.82e-06     |
| times/epoch_before_hook        | 0.000299     |
| times/epoch_rollout_model      | 499          |
| times/evaluation_metrics       | 0.000534     |
| times/evaluation_paths         | 36.3         |
| times/timestep_after_hook      | 0.00394      |
| times/timestep_before_hook     | 0.00853      |
| times/train                    | 60.2         |
| timestep                       | 1000         |
| timesteps_total                | 330000       |
| train-steps                    | 330000       |
| training/Q/q1_loss             | 110.47274    |
| training/sac_pi/alpha          | 0.17064908   |
| training/sac_pi/alpha_loss     | -0.060676556 |
| training/sac_pi/logp_pi        | 3.699461     |
| training/sac_pi/pi_entropy     | 3.595138     |
| training/sac_pi/pi_global_norm | 1.6524323    |
| training/sac_pi/policy_loss    | -223.67247   |
| training/sac_pi/std            | 0.4914266    |
| training/sac_pi/valid_num      | 4964.0       |
| training/sac_Q/q1              | 215.6386     |
| training/sac_Q/q2              | 217.0909     |
| training/sac_Q/q2_loss         | 111.16512    |
| training/sac_Q/q_global_norm   | 242.19878    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17006071 |
| epoch                          | 330        |
| evaluation/episode-length-avg  | 151        |
| evaluation/episode-length-max  | 153        |
| evaluation/episode-length-min  | 148        |
| evaluation/episode-length-std  | 1.37       |
| evaluation/return-average      | 472.04816  |
| evaluation/return-max          | 479.2658   |
| evaluation/return-min          | 460.83844  |
| evaluation/return-std          | 4.887006   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 84.2       |
| model/penalty_ret              | 79         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46198      |
| perf/AverageLength             | 151        |
| perf/AverageReturn             | 472.04816  |
| perf/NormalizedReturn          | 0.102      |
| Q-avg                          | 217.33342  |
| Q-std                          | 93.92445   |
| Q_loss                         | 81.84401   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 330        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000654   |
| times/evaluation_paths         | 5.16       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00856    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 331000     |
| train-steps                    | 331000     |
| training/Q/q1_loss             | 97.02417   |
| training/sac_pi/alpha          | 0.1701065  |
| training/sac_pi/alpha_loss     | -0.3288076 |
| training/sac_pi/logp_pi        | 4.0659475  |
| training/sac_pi/pi_entropy     | 3.3591244  |
| training/sac_pi/pi_global_norm | 1.8731145  |
| training/sac_pi/policy_loss    | -219.71625 |
| training/sac_pi/std            | 0.48033372 |
| training/sac_pi/valid_num      | 5022.0     |
| training/sac_Q/q1              | 215.45605  |
| training/sac_Q/q2              | 215.96465  |
| training/sac_Q/q2_loss         | 96.86226   |
| training/sac_Q/q_global_norm   | 206.02898  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17245564 |
| epoch                          | 331        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4931.104   |
| evaluation/return-max          | 4979.861   |
| evaluation/return-min          | 4876.245   |
| evaluation/return-std          | 33.21577   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46411      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4931.104   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 201.08841  |
| Q-std                          | 120.98497  |
| Q_loss                         | 74.31108   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 331        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000108   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000571   |
| times/evaluation_paths         | 35.9       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 332000     |
| train-steps                    | 332000     |
| training/Q/q1_loss             | 79.84141   |
| training/sac_pi/alpha          | 0.17238285 |
| training/sac_pi/alpha_loss     | 0.24304037 |
| training/sac_pi/logp_pi        | 4.0864496  |
| training/sac_pi/pi_entropy     | 3.5146496  |
| training/sac_pi/pi_global_norm | 1.7930932  |
| training/sac_pi/policy_loss    | -223.71948 |
| training/sac_pi/std            | 0.48116475 |
| training/sac_pi/valid_num      | 5031.0     |
| training/sac_Q/q1              | 218.89693  |
| training/sac_Q/q2              | 219.76175  |
| training/sac_Q/q2_loss         | 80.26619   |
| training/sac_Q/q_global_norm   | 173.67978  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17295861   |
| epoch                          | 332          |
| evaluation/episode-length-avg  | 146          |
| evaluation/episode-length-max  | 152          |
| evaluation/episode-length-min  | 137          |
| evaluation/episode-length-std  | 5.7          |
| evaluation/return-average      | 458.08847    |
| evaluation/return-max          | 475.48767    |
| evaluation/return-min          | 427.26312    |
| evaluation/return-std          | 18.818556    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.05         |
| model/origin_ret               | 86.2         |
| model/penalty_ret              | 80.6         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46269        |
| perf/AverageLength             | 146          |
| perf/AverageReturn             | 458.08847    |
| perf/NormalizedReturn          | 0.0994       |
| Q-avg                          | 210.04239    |
| Q-std                          | 121.53164    |
| Q_loss                         | 107.91794    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 332          |
| times/epoch_after_hook         | 1.7e-06      |
| times/epoch_before_hook        | 0.000127     |
| times/epoch_rollout_model      | 497          |
| times/evaluation_metrics       | 0.000443     |
| times/evaluation_paths         | 4.94         |
| times/timestep_after_hook      | 0.00378      |
| times/timestep_before_hook     | 0.00841      |
| times/train                    | 62.1         |
| timestep                       | 1000         |
| timesteps_total                | 333000       |
| train-steps                    | 333000       |
| training/Q/q1_loss             | 107.03691    |
| training/sac_pi/alpha          | 0.17298661   |
| training/sac_pi/alpha_loss     | -0.001490204 |
| training/sac_pi/logp_pi        | 4.689118     |
| training/sac_pi/pi_entropy     | 3.3936696    |
| training/sac_pi/pi_global_norm | 1.6172955    |
| training/sac_pi/policy_loss    | -224.49715   |
| training/sac_pi/std            | 0.5061594    |
| training/sac_pi/valid_num      | 4941.0       |
| training/sac_Q/q1              | 211.77078    |
| training/sac_Q/q2              | 215.67325    |
| training/sac_Q/q2_loss         | 107.95138    |
| training/sac_Q/q_global_norm   | 282.96487    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17370282   |
| epoch                          | 333          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4939.413     |
| evaluation/return-max          | 4987.954     |
| evaluation/return-min          | 4872.3926    |
| evaluation/return-std          | 43.149406    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.06         |
| model/origin_ret               | 84.6         |
| model/penalty_ret              | 79.8         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46496        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4939.413     |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 213.9769     |
| Q-std                          | 118.16264    |
| Q_loss                         | 85.50147     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 333          |
| times/epoch_after_hook         | 1.68e-06     |
| times/epoch_before_hook        | 0.000275     |
| times/epoch_rollout_model      | 488          |
| times/evaluation_metrics       | 0.000691     |
| times/evaluation_paths         | 37.2         |
| times/timestep_after_hook      | 0.00373      |
| times/timestep_before_hook     | 0.00846      |
| times/train                    | 61           |
| timestep                       | 1000         |
| timesteps_total                | 334000       |
| train-steps                    | 334000       |
| training/Q/q1_loss             | 121.38381    |
| training/sac_pi/alpha          | 0.17371106   |
| training/sac_pi/alpha_loss     | -0.114521794 |
| training/sac_pi/logp_pi        | 5.188651     |
| training/sac_pi/pi_entropy     | 3.707175     |
| training/sac_pi/pi_global_norm | 2.0761006    |
| training/sac_pi/policy_loss    | -210.1427    |
| training/sac_pi/std            | 0.57318336   |
| training/sac_pi/valid_num      | 4824.0       |
| training/sac_Q/q1              | 193.65799    |
| training/sac_Q/q2              | 197.12585    |
| training/sac_Q/q2_loss         | 120.637505   |
| training/sac_Q/q_global_norm   | 225.22984    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1705391  |
| epoch                          | 334        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4567.0356  |
| evaluation/return-max          | 4612.7534  |
| evaluation/return-min          | 4513.6777  |
| evaluation/return-std          | 28.593021  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46267      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4567.0356  |
| perf/NormalizedReturn          | 0.994      |
| Q-avg                          | 207.02055  |
| Q-std                          | 105.74836  |
| Q_loss                         | 132.19168  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 334        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 516        |
| times/evaluation_metrics       | 0.000608   |
| times/evaluation_paths         | 37.3       |
| times/timestep_after_hook      | 0.00399    |
| times/timestep_before_hook     | 0.00879    |
| times/train                    | 62.7       |
| timestep                       | 1000       |
| timesteps_total                | 335000     |
| train-steps                    | 335000     |
| training/Q/q1_loss             | 107.37544  |
| training/sac_pi/alpha          | 0.1704819  |
| training/sac_pi/alpha_loss     | 0.5821701  |
| training/sac_pi/logp_pi        | 4.3067503  |
| training/sac_pi/pi_entropy     | 3.3317916  |
| training/sac_pi/pi_global_norm | 1.8394681  |
| training/sac_pi/policy_loss    | -221.01024 |
| training/sac_pi/std            | 0.4628481  |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 212.57187  |
| training/sac_Q/q2              | 213.53372  |
| training/sac_Q/q2_loss         | 105.67009  |
| training/sac_Q/q_global_norm   | 310.86044  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16586572  |
| epoch                          | 335         |
| evaluation/episode-length-avg  | 662         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 148         |
| evaluation/episode-length-std  | 414         |
| evaluation/return-average      | 3177.6472   |
| evaluation/return-max          | 5119.0527   |
| evaluation/return-min          | 391.06927   |
| evaluation/return-std          | 2256.9119   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 80.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46340       |
| perf/AverageLength             | 662         |
| perf/AverageReturn             | 3177.6472   |
| perf/NormalizedReturn          | 0.692       |
| Q-avg                          | 219.31706   |
| Q-std                          | 96.88076    |
| Q_loss                         | 91.439735   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 335         |
| times/epoch_after_hook         | 2.02e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 544         |
| times/evaluation_metrics       | 0.00062     |
| times/evaluation_paths         | 23.7        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 63.4        |
| timestep                       | 1000        |
| timesteps_total                | 336000      |
| train-steps                    | 336000      |
| training/Q/q1_loss             | 122.82136   |
| training/sac_pi/alpha          | 0.16585973  |
| training/sac_pi/alpha_loss     | -0.08513173 |
| training/sac_pi/logp_pi        | 4.1129103   |
| training/sac_pi/pi_entropy     | 3.4358087   |
| training/sac_pi/pi_global_norm | 1.8919628   |
| training/sac_pi/policy_loss    | -224.85152  |
| training/sac_pi/std            | 0.48863614  |
| training/sac_pi/valid_num      | 4994.0      |
| training/sac_Q/q1              | 218.27812   |
| training/sac_Q/q2              | 219.15756   |
| training/sac_Q/q2_loss         | 123.81428   |
| training/sac_Q/q_global_norm   | 266.93036   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16635972 |
| epoch                          | 336        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5172.1533  |
| evaluation/return-max          | 5253.3213  |
| evaluation/return-min          | 4999.506   |
| evaluation/return-std          | 65.27839   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46338      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5172.1533  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 210.75752  |
| Q-std                          | 96.08615   |
| Q_loss                         | 87.159485  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 336        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000613   |
| times/evaluation_paths         | 36.6       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00872    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 337000     |
| train-steps                    | 337000     |
| training/Q/q1_loss             | 95.1247    |
| training/sac_pi/alpha          | 0.16640244 |
| training/sac_pi/alpha_loss     | -0.3138744 |
| training/sac_pi/logp_pi        | 3.890202   |
| training/sac_pi/pi_entropy     | 3.3416202  |
| training/sac_pi/pi_global_norm | 1.9416199  |
| training/sac_pi/policy_loss    | -226.83174 |
| training/sac_pi/std            | 0.49326167 |
| training/sac_pi/valid_num      | 5013.0     |
| training/sac_Q/q1              | 219.83206  |
| training/sac_Q/q2              | 221.2109   |
| training/sac_Q/q2_loss         | 94.06538   |
| training/sac_Q/q_global_norm   | 193.54413  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16955717  |
| epoch                          | 337         |
| evaluation/episode-length-avg  | 998         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 976         |
| evaluation/episode-length-std  | 7.2         |
| evaluation/return-average      | 5367.0684   |
| evaluation/return-max          | 5497.7695   |
| evaluation/return-min          | 5274.3823   |
| evaluation/return-std          | 65.046684   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46267       |
| perf/AverageLength             | 998         |
| perf/AverageReturn             | 5367.0684   |
| perf/NormalizedReturn          | 1.17        |
| Q-avg                          | 204.8099    |
| Q-std                          | 104.589325  |
| Q_loss                         | 96.98654    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 337         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000299    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.00058     |
| times/evaluation_paths         | 38.8        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 62.5        |
| timestep                       | 1000        |
| timesteps_total                | 338000      |
| train-steps                    | 338000      |
| training/Q/q1_loss             | 96.1779     |
| training/sac_pi/alpha          | 0.16954328  |
| training/sac_pi/alpha_loss     | -0.16724199 |
| training/sac_pi/logp_pi        | 3.994758    |
| training/sac_pi/pi_entropy     | 3.689668    |
| training/sac_pi/pi_global_norm | 1.569071    |
| training/sac_pi/policy_loss    | -222.16263  |
| training/sac_pi/std            | 0.5131289   |
| training/sac_pi/valid_num      | 4987.0      |
| training/sac_Q/q1              | 214.0655    |
| training/sac_Q/q2              | 215.2509    |
| training/sac_Q/q2_loss         | 98.58541    |
| training/sac_Q/q_global_norm   | 289.57538   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16554144 |
| epoch                          | 338        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4857.6704  |
| evaluation/return-max          | 4912.6445  |
| evaluation/return-min          | 4796.2964  |
| evaluation/return-std          | 35.50251   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46112      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4857.6704  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 203.27762  |
| Q-std                          | 133.59537  |
| Q_loss                         | 113.11935  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 338        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000784   |
| times/evaluation_paths         | 35.7       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00864    |
| times/train                    | 62.4       |
| timestep                       | 1000       |
| timesteps_total                | 339000     |
| train-steps                    | 339000     |
| training/Q/q1_loss             | 102.58323  |
| training/sac_pi/alpha          | 0.1655015  |
| training/sac_pi/alpha_loss     | 0.29796806 |
| training/sac_pi/logp_pi        | 4.4935794  |
| training/sac_pi/pi_entropy     | 3.4467812  |
| training/sac_pi/pi_global_norm | 2.216724   |
| training/sac_pi/policy_loss    | -225.66835 |
| training/sac_pi/std            | 0.4962125  |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 217.21762  |
| training/sac_Q/q2              | 219.77048  |
| training/sac_Q/q2_loss         | 104.08518  |
| training/sac_Q/q_global_norm   | 310.6743   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16642359 |
| epoch                          | 339        |
| evaluation/episode-length-avg  | 914        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 138        |
| evaluation/episode-length-std  | 259        |
| evaluation/return-average      | 4134.728   |
| evaluation/return-max          | 4575.38    |
| evaluation/return-min          | 346.68274  |
| evaluation/return-std          | 1262.7424  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46285      |
| perf/AverageLength             | 914        |
| perf/AverageReturn             | 4134.728   |
| perf/NormalizedReturn          | 0.9        |
| Q-avg                          | 221.91545  |
| Q-std                          | 95.45299   |
| Q_loss                         | 98.24133   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 339        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000147   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000603   |
| times/evaluation_paths         | 33.8       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 340000     |
| train-steps                    | 340000     |
| training/Q/q1_loss             | 88.7879    |
| training/sac_pi/alpha          | 0.16642083 |
| training/sac_pi/alpha_loss     | 0.16703318 |
| training/sac_pi/logp_pi        | 4.086583   |
| training/sac_pi/pi_entropy     | 3.2483108  |
| training/sac_pi/pi_global_norm | 2.681824   |
| training/sac_pi/policy_loss    | -225.4169  |
| training/sac_pi/std            | 0.46013108 |
| training/sac_pi/valid_num      | 5008.0     |
| training/sac_Q/q1              | 220.08272  |
| training/sac_Q/q2              | 221.25288  |
| training/sac_Q/q2_loss         | 87.08081   |
| training/sac_Q/q_global_norm   | 362.41022  |
--------------------------------------------------------------------------------
[WARN] 340 : sync: start
------------------------------------------------------------------------------------
| alpha                          | 0.17105183     |
| epoch                          | 340            |
| evaluation/episode-length-avg  | 409            |
| evaluation/episode-length-max  | 1000           |
| evaluation/episode-length-min  | 154            |
| evaluation/episode-length-std  | 387            |
| evaluation/return-average      | 1850.1904      |
| evaluation/return-max          | 5016.5073      |
| evaluation/return-min          | 488.2604       |
| evaluation/return-std          | 2070.586       |
| model/max_penalty              | 7.24           |
| model/mean_rollout_length      | 20             |
| model/mean_rollout_reward      | 3.17           |
| model/origin_ret               | 87.2           |
| model/penalty_ret              | 80.3           |
| model/val_loss                 | 0.40512508     |
| model/valid_num                | 46344          |
| perf/AverageLength             | 409            |
| perf/AverageReturn             | 1850.1904      |
| perf/NormalizedReturn          | 0.403          |
| Q-avg                          | 210.90137      |
| Q-std                          | 100.0822       |
| Q_loss                         | 120.819664     |
| sampler/episodes               | 0              |
| sampler/last-path-return       | 0              |
| sampler/max-path-return        | -inf           |
| sampler/pool-size              | 1000000        |
| sampler/total-samples          | 0              |
| time-step                      | 340            |
| times/epoch_after_hook         | 1.75e-06       |
| times/epoch_before_hook        | 0.000191       |
| times/epoch_rollout_model      | 492            |
| times/evaluation_metrics       | 0.000568       |
| times/evaluation_paths         | 13.6           |
| times/timestep_after_hook      | 0.00368        |
| times/timestep_before_hook     | 0.00852        |
| times/train                    | 61.9           |
| timestep                       | 1000           |
| timesteps_total                | 341000         |
| train-steps                    | 341000         |
| training/Q/q1_loss             | 119.843636     |
| training/sac_pi/alpha          | 0.17103079     |
| training/sac_pi/alpha_loss     | -0.00018173773 |
| training/sac_pi/logp_pi        | 3.8086019      |
| training/sac_pi/pi_entropy     | 3.5480218      |
| training/sac_pi/pi_global_norm | 2.2922764      |
| training/sac_pi/policy_loss    | -217.22488     |
| training/sac_pi/std            | 0.48198372     |
| training/sac_pi/valid_num      | 4998.0         |
| training/sac_Q/q1              | 211.1541       |
| training/sac_Q/q2              | 212.29512      |
| training/sac_Q/q2_loss         | 120.23855      |
| training/sac_Q/q_global_norm   | 289.6622       |
------------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17047596 |
| epoch                          | 341        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4748.6387  |
| evaluation/return-max          | 4811.9487  |
| evaluation/return-min          | 4650.0645  |
| evaluation/return-std          | 50.389267  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46251      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4748.6387  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 208.41512  |
| Q-std                          | 106.3901   |
| Q_loss                         | 113.434975 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 341        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000489   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000592   |
| times/evaluation_paths         | 39.7       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 342000     |
| train-steps                    | 342000     |
| training/Q/q1_loss             | 97.69426   |
| training/sac_pi/alpha          | 0.17045781 |
| training/sac_pi/alpha_loss     | 0.5520056  |
| training/sac_pi/logp_pi        | 4.556907   |
| training/sac_pi/pi_entropy     | 3.6203353  |
| training/sac_pi/pi_global_norm | 1.7895501  |
| training/sac_pi/policy_loss    | -216.53156 |
| training/sac_pi/std            | 0.5223958  |
| training/sac_pi/valid_num      | 5002.0     |
| training/sac_Q/q1              | 208.29208  |
| training/sac_Q/q2              | 208.46773  |
| training/sac_Q/q2_loss         | 97.72638   |
| training/sac_Q/q_global_norm   | 269.796    |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16638944 |
| epoch                          | 342        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4988.078   |
| evaluation/return-max          | 5022.2534  |
| evaluation/return-min          | 4937.478   |
| evaluation/return-std          | 24.32367   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46302      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4988.078   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 210.58118  |
| Q-std                          | 105.38328  |
| Q_loss                         | 98.6847    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 342        |
| times/epoch_after_hook         | 1.62e-06   |
| times/epoch_before_hook        | 0.000146   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000596   |
| times/evaluation_paths         | 38.6       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00864    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 343000     |
| train-steps                    | 343000     |
| training/Q/q1_loss             | 105.85608  |
| training/sac_pi/alpha          | 0.16635072 |
| training/sac_pi/alpha_loss     | 0.14530079 |
| training/sac_pi/logp_pi        | 3.5664382  |
| training/sac_pi/pi_entropy     | 3.523704   |
| training/sac_pi/pi_global_norm | 1.5780584  |
| training/sac_pi/policy_loss    | -215.74165 |
| training/sac_pi/std            | 0.47222176 |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 209.5397   |
| training/sac_Q/q2              | 209.72891  |
| training/sac_Q/q2_loss         | 105.344536 |
| training/sac_Q/q_global_norm   | 276.91443  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17000282 |
| epoch                          | 343        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4921.6396  |
| evaluation/return-max          | 4995.385   |
| evaluation/return-min          | 4842.8643  |
| evaluation/return-std          | 51.081818  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46371      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4921.6396  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 207.45816  |
| Q-std                          | 103.44159  |
| Q_loss                         | 85.19866   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 343        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000635   |
| times/evaluation_paths         | 35.8       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 344000     |
| train-steps                    | 344000     |
| training/Q/q1_loss             | 107.61499  |
| training/sac_pi/alpha          | 0.170013   |
| training/sac_pi/alpha_loss     | 0.1336475  |
| training/sac_pi/logp_pi        | 3.5044658  |
| training/sac_pi/pi_entropy     | 3.1887672  |
| training/sac_pi/pi_global_norm | 2.86674    |
| training/sac_pi/policy_loss    | -223.50563 |
| training/sac_pi/std            | 0.44326618 |
| training/sac_pi/valid_num      | 5015.0     |
| training/sac_Q/q1              | 219.59293  |
| training/sac_Q/q2              | 219.77603  |
| training/sac_Q/q2_loss         | 108.070786 |
| training/sac_Q/q_global_norm   | 342.91275  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17636469 |
| epoch                          | 344        |
| evaluation/episode-length-avg  | 329        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 158        |
| evaluation/episode-length-std  | 336        |
| evaluation/return-average      | 1412.637   |
| evaluation/return-max          | 5006.082   |
| evaluation/return-min          | 505.2332   |
| evaluation/return-std          | 1789.5321  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3          |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46275      |
| perf/AverageLength             | 329        |
| perf/AverageReturn             | 1412.637   |
| perf/NormalizedReturn          | 0.307      |
| Q-avg                          | 208.19568  |
| Q-std                          | 109.239586 |
| Q_loss                         | 92.6475    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 344        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000161   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000498   |
| times/evaluation_paths         | 10.7       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00859    |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 345000     |
| train-steps                    | 345000     |
| training/Q/q1_loss             | 110.55768  |
| training/sac_pi/alpha          | 0.17634276 |
| training/sac_pi/alpha_loss     | 0.16755717 |
| training/sac_pi/logp_pi        | 4.14854    |
| training/sac_pi/pi_entropy     | 3.4200387  |
| training/sac_pi/pi_global_norm | 1.8993571  |
| training/sac_pi/policy_loss    | -220.2231  |
| training/sac_pi/std            | 0.48481274 |
| training/sac_pi/valid_num      | 5031.0     |
| training/sac_Q/q1              | 212.34341  |
| training/sac_Q/q2              | 214.01242  |
| training/sac_Q/q2_loss         | 109.22975  |
| training/sac_Q/q_global_norm   | 305.94904  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16814105  |
| epoch                          | 345         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4738.737    |
| evaluation/return-max          | 4771.8584   |
| evaluation/return-min          | 4705.6875   |
| evaluation/return-std          | 23.08714    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46382       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4738.737    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 206.73723   |
| Q-std                          | 108.88531   |
| Q_loss                         | 83.36411    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 345         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000279    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000523    |
| times/evaluation_paths         | 37.8        |
| times/timestep_after_hook      | 0.00376     |
| times/timestep_before_hook     | 0.00847     |
| times/train                    | 62.8        |
| timestep                       | 1000        |
| timesteps_total                | 346000      |
| train-steps                    | 346000      |
| training/Q/q1_loss             | 113.346535  |
| training/sac_pi/alpha          | 0.16814676  |
| training/sac_pi/alpha_loss     | -0.09501702 |
| training/sac_pi/logp_pi        | 4.7134166   |
| training/sac_pi/pi_entropy     | 3.489128    |
| training/sac_pi/pi_global_norm | 1.6553997   |
| training/sac_pi/policy_loss    | -214.25497  |
| training/sac_pi/std            | 0.51495403  |
| training/sac_pi/valid_num      | 4945.0      |
| training/sac_Q/q1              | 203.061     |
| training/sac_Q/q2              | 204.47546   |
| training/sac_Q/q2_loss         | 113.9571    |
| training/sac_Q/q_global_norm   | 223.34935   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16703437  |
| epoch                          | 346         |
| evaluation/episode-length-avg  | 916         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 160         |
| evaluation/episode-length-std  | 252         |
| evaluation/return-average      | 4642.227    |
| evaluation/return-max          | 5170.9077   |
| evaluation/return-min          | 519.6478    |
| evaluation/return-std          | 1374.499    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 80.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46281       |
| perf/AverageLength             | 916         |
| perf/AverageReturn             | 4642.227    |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 204.7351    |
| Q-std                          | 120.1333    |
| Q_loss                         | 113.39201   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 346         |
| times/epoch_after_hook         | 1.93e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000671    |
| times/evaluation_paths         | 32.2        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 62.2        |
| timestep                       | 1000        |
| timesteps_total                | 347000      |
| train-steps                    | 347000      |
| training/Q/q1_loss             | 91.40989    |
| training/sac_pi/alpha          | 0.1670669   |
| training/sac_pi/alpha_loss     | -0.29484424 |
| training/sac_pi/logp_pi        | 3.3615837   |
| training/sac_pi/pi_entropy     | 3.558595    |
| training/sac_pi/pi_global_norm | 2.0347743   |
| training/sac_pi/policy_loss    | -220.88649  |
| training/sac_pi/std            | 0.4818649   |
| training/sac_pi/valid_num      | 4993.0      |
| training/sac_Q/q1              | 214.8909    |
| training/sac_Q/q2              | 215.99663   |
| training/sac_Q/q2_loss         | 92.05369    |
| training/sac_Q/q_global_norm   | 311.4029    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17043926  |
| epoch                          | 347         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5018.9727   |
| evaluation/return-max          | 5139.479    |
| evaluation/return-min          | 4949.8887   |
| evaluation/return-std          | 54.10938    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46360       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5018.9727   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 212.50993   |
| Q-std                          | 118.77181   |
| Q_loss                         | 104.91466   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 347         |
| times/epoch_after_hook         | 2e-06       |
| times/epoch_before_hook        | 0.000145    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000958    |
| times/evaluation_paths         | 35.3        |
| times/timestep_after_hook      | 0.00399     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 62.2        |
| timestep                       | 1000        |
| timesteps_total                | 348000      |
| train-steps                    | 348000      |
| training/Q/q1_loss             | 90.6611     |
| training/sac_pi/alpha          | 0.17047423  |
| training/sac_pi/alpha_loss     | -0.19575147 |
| training/sac_pi/logp_pi        | 4.148331    |
| training/sac_pi/pi_entropy     | 3.422891    |
| training/sac_pi/pi_global_norm | 1.6575162   |
| training/sac_pi/policy_loss    | -225.5235   |
| training/sac_pi/std            | 0.49017122  |
| training/sac_pi/valid_num      | 4957.0      |
| training/sac_Q/q1              | 214.48514   |
| training/sac_Q/q2              | 215.8649    |
| training/sac_Q/q2_loss         | 91.63015    |
| training/sac_Q/q_global_norm   | 205.94896   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17007467 |
| epoch                          | 348        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5056.342   |
| evaluation/return-max          | 5185.141   |
| evaluation/return-min          | 4882.7803  |
| evaluation/return-std          | 84.354034  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 78.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46473      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5056.342   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 203.84009  |
| Q-std                          | 124.588745 |
| Q_loss                         | 98.93162   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 348        |
| times/epoch_after_hook         | 2.16e-06   |
| times/epoch_before_hook        | 0.000177   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000785   |
| times/evaluation_paths         | 35.4       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.0086     |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 349000     |
| train-steps                    | 349000     |
| training/Q/q1_loss             | 135.69498  |
| training/sac_pi/alpha          | 0.17008159 |
| training/sac_pi/alpha_loss     | 0.2944829  |
| training/sac_pi/logp_pi        | 5.0555496  |
| training/sac_pi/pi_entropy     | 3.4686153  |
| training/sac_pi/pi_global_norm | 1.760861   |
| training/sac_pi/policy_loss    | -215.69281 |
| training/sac_pi/std            | 0.52329516 |
| training/sac_pi/valid_num      | 4927.0     |
| training/sac_Q/q1              | 203.53993  |
| training/sac_Q/q2              | 205.90608  |
| training/sac_Q/q2_loss         | 136.2013   |
| training/sac_Q/q_global_norm   | 278.61047  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16805503  |
| epoch                          | 349         |
| evaluation/episode-length-avg  | 940         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 395         |
| evaluation/episode-length-std  | 182         |
| evaluation/return-average      | 4729.339    |
| evaluation/return-max          | 5143.275    |
| evaluation/return-min          | 1689.2928   |
| evaluation/return-std          | 1014.51324  |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46313       |
| perf/AverageLength             | 940         |
| perf/AverageReturn             | 4729.339    |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 219.6742    |
| Q-std                          | 109.646255  |
| Q_loss                         | 80.19977    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 349         |
| times/epoch_after_hook         | 1.63e-06    |
| times/epoch_before_hook        | 0.00038     |
| times/epoch_rollout_model      | 501         |
| times/evaluation_metrics       | 0.0006      |
| times/evaluation_paths         | 43.2        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 350000      |
| train-steps                    | 350000      |
| training/Q/q1_loss             | 101.03652   |
| training/sac_pi/alpha          | 0.16806436  |
| training/sac_pi/alpha_loss     | -0.13315135 |
| training/sac_pi/logp_pi        | 4.252541    |
| training/sac_pi/pi_entropy     | 3.6932495   |
| training/sac_pi/pi_global_norm | 1.6429117   |
| training/sac_pi/policy_loss    | -219.17075  |
| training/sac_pi/std            | 0.538037    |
| training/sac_pi/valid_num      | 4932.0      |
| training/sac_Q/q1              | 206.89236   |
| training/sac_Q/q2              | 209.41435   |
| training/sac_Q/q2_loss         | 100.31686   |
| training/sac_Q/q_global_norm   | 222.79625   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16285191 |
| epoch                          | 350        |
| evaluation/episode-length-avg  | 748        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 158        |
| evaluation/episode-length-std  | 385        |
| evaluation/return-average      | 3428.6472  |
| evaluation/return-max          | 4750.259   |
| evaluation/return-min          | 470.89594  |
| evaluation/return-std          | 1934.0348  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46316      |
| perf/AverageLength             | 748        |
| perf/AverageReturn             | 3428.6472  |
| perf/NormalizedReturn          | 0.747      |
| Q-avg                          | 206.06645  |
| Q-std                          | 107.462875 |
| Q_loss                         | 119.5607   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 350        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000161   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000626   |
| times/evaluation_paths         | 28         |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00855    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 351000     |
| train-steps                    | 351000     |
| training/Q/q1_loss             | 107.172    |
| training/sac_pi/alpha          | 0.16283154 |
| training/sac_pi/alpha_loss     | 0.36177576 |
| training/sac_pi/logp_pi        | 4.468132   |
| training/sac_pi/pi_entropy     | 3.314452   |
| training/sac_pi/pi_global_norm | 2.026916   |
| training/sac_pi/policy_loss    | -214.9077  |
| training/sac_pi/std            | 0.49569303 |
| training/sac_pi/valid_num      | 5000.0     |
| training/sac_Q/q1              | 208.76102  |
| training/sac_Q/q2              | 210.93497  |
| training/sac_Q/q2_loss         | 107.860664 |
| training/sac_Q/q_global_norm   | 235.31918  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16239879  |
| epoch                          | 351         |
| evaluation/episode-length-avg  | 145         |
| evaluation/episode-length-max  | 146         |
| evaluation/episode-length-min  | 144         |
| evaluation/episode-length-std  | 0.64        |
| evaluation/return-average      | 455.2184    |
| evaluation/return-max          | 458.84286   |
| evaluation/return-min          | 447.78677   |
| evaluation/return-std          | 2.8846483   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46384       |
| perf/AverageLength             | 145         |
| perf/AverageReturn             | 455.2184    |
| perf/NormalizedReturn          | 0.0988      |
| Q-avg                          | 198.6113    |
| Q-std                          | 135.82819   |
| Q_loss                         | 106.917366  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 351         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.00042     |
| times/evaluation_paths         | 5.02        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00852     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 352000      |
| train-steps                    | 352000      |
| training/Q/q1_loss             | 105.44407   |
| training/sac_pi/alpha          | 0.16236956  |
| training/sac_pi/alpha_loss     | 0.085170224 |
| training/sac_pi/logp_pi        | 4.049526    |
| training/sac_pi/pi_entropy     | 3.4797592   |
| training/sac_pi/pi_global_norm | 1.7258878   |
| training/sac_pi/policy_loss    | -228.0818   |
| training/sac_pi/std            | 0.49220595  |
| training/sac_pi/valid_num      | 4972.0      |
| training/sac_Q/q1              | 221.69202   |
| training/sac_Q/q2              | 221.84648   |
| training/sac_Q/q2_loss         | 105.208954  |
| training/sac_Q/q_global_norm   | 290.631     |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17221725  |
| epoch                          | 352         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4920.637    |
| evaluation/return-max          | 4966.1895   |
| evaluation/return-min          | 4859.8936   |
| evaluation/return-std          | 32.817905   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46517       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4920.637    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 205.31607   |
| Q-std                          | 121.743416  |
| Q_loss                         | 103.85637   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 352         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000101    |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000571    |
| times/evaluation_paths         | 36.6        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00834     |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 353000      |
| train-steps                    | 353000      |
| training/Q/q1_loss             | 104.349915  |
| training/sac_pi/alpha          | 0.17219768  |
| training/sac_pi/alpha_loss     | 0.041243766 |
| training/sac_pi/logp_pi        | 4.005806    |
| training/sac_pi/pi_entropy     | 3.5417106   |
| training/sac_pi/pi_global_norm | 2.2777884   |
| training/sac_pi/policy_loss    | -218.17888  |
| training/sac_pi/std            | 0.48725268  |
| training/sac_pi/valid_num      | 5030.0      |
| training/sac_Q/q1              | 213.62595   |
| training/sac_Q/q2              | 214.09766   |
| training/sac_Q/q2_loss         | 105.31311   |
| training/sac_Q/q_global_norm   | 250.41704   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17197825 |
| epoch                          | 353        |
| evaluation/episode-length-avg  | 327        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 152        |
| evaluation/episode-length-std  | 337        |
| evaluation/return-average      | 1359.9214  |
| evaluation/return-max          | 4966.8433  |
| evaluation/return-min          | 438.72852  |
| evaluation/return-std          | 1789.6455  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.02       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46271      |
| perf/AverageLength             | 327        |
| perf/AverageReturn             | 1359.9214  |
| perf/NormalizedReturn          | 0.296      |
| Q-avg                          | 214.73831  |
| Q-std                          | 108.5188   |
| Q_loss                         | 109.74299  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 353        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000328   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000491   |
| times/evaluation_paths         | 13.5       |
| times/timestep_after_hook      | 0.00356    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 354000     |
| train-steps                    | 354000     |
| training/Q/q1_loss             | 96.38101   |
| training/sac_pi/alpha          | 0.17198892 |
| training/sac_pi/alpha_loss     | 0.25485006 |
| training/sac_pi/logp_pi        | 3.7696197  |
| training/sac_pi/pi_entropy     | 3.3069847  |
| training/sac_pi/pi_global_norm | 3.0497046  |
| training/sac_pi/policy_loss    | -223.57104 |
| training/sac_pi/std            | 0.4558512  |
| training/sac_pi/valid_num      | 5039.0     |
| training/sac_Q/q1              | 219.80305  |
| training/sac_Q/q2              | 220.46431  |
| training/sac_Q/q2_loss         | 96.49992   |
| training/sac_Q/q_global_norm   | 227.86053  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16882087  |
| epoch                          | 354         |
| evaluation/episode-length-avg  | 916         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 165         |
| evaluation/episode-length-std  | 250         |
| evaluation/return-average      | 4593.6553   |
| evaluation/return-max          | 5096.4062   |
| evaluation/return-min          | 536.84357   |
| evaluation/return-std          | 1353.2123   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46393       |
| perf/AverageLength             | 916         |
| perf/AverageReturn             | 4593.6553   |
| perf/NormalizedReturn          | 1           |
| Q-avg                          | 213.54428   |
| Q-std                          | 105.59533   |
| Q_loss                         | 102.94423   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 354         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.00012     |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000535    |
| times/evaluation_paths         | 32.9        |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.00865     |
| times/train                    | 62          |
| timestep                       | 1000        |
| timesteps_total                | 355000      |
| train-steps                    | 355000      |
| training/Q/q1_loss             | 108.54994   |
| training/sac_pi/alpha          | 0.16883507  |
| training/sac_pi/alpha_loss     | -0.33947408 |
| training/sac_pi/logp_pi        | 4.7344527   |
| training/sac_pi/pi_entropy     | 3.4774318   |
| training/sac_pi/pi_global_norm | 2.529779    |
| training/sac_pi/policy_loss    | -224.72433  |
| training/sac_pi/std            | 0.53486186  |
| training/sac_pi/valid_num      | 4928.0      |
| training/sac_Q/q1              | 210.50847   |
| training/sac_Q/q2              | 210.9528    |
| training/sac_Q/q2_loss         | 107.1601    |
| training/sac_Q/q_global_norm   | 264.31772   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.18017176 |
| epoch                          | 355        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5045.1     |
| evaluation/return-max          | 5098.254   |
| evaluation/return-min          | 4989.19    |
| evaluation/return-std          | 33.13189   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.01       |
| model/origin_ret               | 84.1       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46268      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5045.1     |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 207.94958  |
| Q-std                          | 107.35275  |
| Q_loss                         | 85.38583   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 355        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000208   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000617   |
| times/evaluation_paths         | 36.5       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 356000     |
| train-steps                    | 356000     |
| training/Q/q1_loss             | 122.75499  |
| training/sac_pi/alpha          | 0.18018213 |
| training/sac_pi/alpha_loss     | 0.30655542 |
| training/sac_pi/logp_pi        | 4.0241256  |
| training/sac_pi/pi_entropy     | 3.5931613  |
| training/sac_pi/pi_global_norm | 1.6191958  |
| training/sac_pi/policy_loss    | -221.87901 |
| training/sac_pi/std            | 0.49500787 |
| training/sac_pi/valid_num      | 5007.0     |
| training/sac_Q/q1              | 214.67032  |
| training/sac_Q/q2              | 216.68997  |
| training/sac_Q/q2_loss         | 124.00116  |
| training/sac_Q/q_global_norm   | 282.45444  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17132843  |
| epoch                          | 356         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4918.9385   |
| evaluation/return-max          | 4946.629    |
| evaluation/return-min          | 4855.038    |
| evaluation/return-std          | 22.931326   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46161       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4918.9385   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 204.17668   |
| Q-std                          | 107.83023   |
| Q_loss                         | 113.577446  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 356         |
| times/epoch_after_hook         | 3.27e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000575    |
| times/evaluation_paths         | 37          |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00833     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 357000      |
| train-steps                    | 357000      |
| training/Q/q1_loss             | 92.39614    |
| training/sac_pi/alpha          | 0.17135386  |
| training/sac_pi/alpha_loss     | -0.15009975 |
| training/sac_pi/logp_pi        | 3.7929254   |
| training/sac_pi/pi_entropy     | 3.570256    |
| training/sac_pi/pi_global_norm | 1.6578323   |
| training/sac_pi/policy_loss    | -227.2695   |
| training/sac_pi/std            | 0.47917876  |
| training/sac_pi/valid_num      | 5011.0      |
| training/sac_Q/q1              | 221.11246   |
| training/sac_Q/q2              | 221.82048   |
| training/sac_Q/q2_loss         | 91.058235   |
| training/sac_Q/q_global_norm   | 209.2112    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16167983  |
| epoch                          | 357         |
| evaluation/episode-length-avg  | 482         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 131         |
| evaluation/episode-length-std  | 423         |
| evaluation/return-average      | 2286.934    |
| evaluation/return-max          | 5217.0996   |
| evaluation/return-min          | 338.85284   |
| evaluation/return-std          | 2340.3752   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46269       |
| perf/AverageLength             | 482         |
| perf/AverageReturn             | 2286.934    |
| perf/NormalizedReturn          | 0.498       |
| Q-avg                          | 215.13965   |
| Q-std                          | 112.38548   |
| Q_loss                         | 104.70703   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 357         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000294    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000662    |
| times/evaluation_paths         | 16.8        |
| times/timestep_after_hook      | 0.00404     |
| times/timestep_before_hook     | 0.00856     |
| times/train                    | 61.5        |
| timestep                       | 1000        |
| timesteps_total                | 358000      |
| train-steps                    | 358000      |
| training/Q/q1_loss             | 76.79886    |
| training/sac_pi/alpha          | 0.16166161  |
| training/sac_pi/alpha_loss     | -0.10875464 |
| training/sac_pi/logp_pi        | 4.1897254   |
| training/sac_pi/pi_entropy     | 3.3258228   |
| training/sac_pi/pi_global_norm | 1.7156421   |
| training/sac_pi/policy_loss    | -226.76376  |
| training/sac_pi/std            | 0.5026352   |
| training/sac_pi/valid_num      | 4995.0      |
| training/sac_Q/q1              | 218.46786   |
| training/sac_Q/q2              | 219.7188    |
| training/sac_Q/q2_loss         | 76.84927    |
| training/sac_Q/q_global_norm   | 219.58533   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16862135  |
| epoch                          | 358         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5146.6943   |
| evaluation/return-max          | 5187.531    |
| evaluation/return-min          | 5085.5034   |
| evaluation/return-std          | 34.311275   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3           |
| model/origin_ret               | 83.8        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46356       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5146.6943   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 219.55127   |
| Q-std                          | 86.22288    |
| Q_loss                         | 97.98256    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 358         |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000539    |
| times/evaluation_paths         | 36.4        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00869     |
| times/train                    | 60.3        |
| timestep                       | 1000        |
| timesteps_total                | 359000      |
| train-steps                    | 359000      |
| training/Q/q1_loss             | 99.38335    |
| training/sac_pi/alpha          | 0.16862924  |
| training/sac_pi/alpha_loss     | -0.09673825 |
| training/sac_pi/logp_pi        | 4.159275    |
| training/sac_pi/pi_entropy     | 3.3679283   |
| training/sac_pi/pi_global_norm | 2.8363922   |
| training/sac_pi/policy_loss    | -227.29596  |
| training/sac_pi/std            | 0.48950502  |
| training/sac_pi/valid_num      | 4977.0      |
| training/sac_Q/q1              | 219.9019    |
| training/sac_Q/q2              | 220.9187    |
| training/sac_Q/q2_loss         | 99.192535   |
| training/sac_Q/q_global_norm   | 273.84848   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16692412 |
| epoch                          | 359        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5124.6094  |
| evaluation/return-max          | 5172.32    |
| evaluation/return-min          | 5037.7075  |
| evaluation/return-std          | 35.093075  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46402      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5124.6094  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 224.66183  |
| Q-std                          | 95.28603   |
| Q_loss                         | 88.76787   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 359        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000595   |
| times/evaluation_paths         | 35.6       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 62.2       |
| timestep                       | 1000       |
| timesteps_total                | 360000     |
| train-steps                    | 360000     |
| training/Q/q1_loss             | 98.79827   |
| training/sac_pi/alpha          | 0.1669212  |
| training/sac_pi/alpha_loss     | 0.24967161 |
| training/sac_pi/logp_pi        | 4.207856   |
| training/sac_pi/pi_entropy     | 3.6007705  |
| training/sac_pi/pi_global_norm | 1.4397814  |
| training/sac_pi/policy_loss    | -228.32051 |
| training/sac_pi/std            | 0.5170436  |
| training/sac_pi/valid_num      | 4955.0     |
| training/sac_Q/q1              | 218.53365  |
| training/sac_Q/q2              | 218.24825  |
| training/sac_Q/q2_loss         | 97.43516   |
| training/sac_Q/q_global_norm   | 219.23569  |
--------------------------------------------------------------------------------
[WARN] 360 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16900279 |
| epoch                          | 360        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4906.3076  |
| evaluation/return-max          | 5033.7324  |
| evaluation/return-min          | 4785.912   |
| evaluation/return-std          | 64.19664   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46439      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4906.3076  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 211.17583  |
| Q-std                          | 104.86119  |
| Q_loss                         | 99.58933   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 360        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.00051    |
| times/evaluation_paths         | 35         |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 361000     |
| train-steps                    | 361000     |
| training/Q/q1_loss             | 93.99269   |
| training/sac_pi/alpha          | 0.16899082 |
| training/sac_pi/alpha_loss     | 0.22775792 |
| training/sac_pi/logp_pi        | 4.6598186  |
| training/sac_pi/pi_entropy     | 3.3716846  |
| training/sac_pi/pi_global_norm | 1.8494688  |
| training/sac_pi/policy_loss    | -216.59268 |
| training/sac_pi/std            | 0.48989066 |
| training/sac_pi/valid_num      | 4920.0     |
| training/sac_Q/q1              | 204.39131  |
| training/sac_Q/q2              | 205.90572  |
| training/sac_Q/q2_loss         | 94.36259   |
| training/sac_Q/q_global_norm   | 234.99995  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16560893 |
| epoch                          | 361        |
| evaluation/episode-length-avg  | 404        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 141        |
| evaluation/episode-length-std  | 390        |
| evaluation/return-average      | 1801.583   |
| evaluation/return-max          | 4923.6094  |
| evaluation/return-min          | 447.8151   |
| evaluation/return-std          | 2016.7689  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46385      |
| perf/AverageLength             | 404        |
| perf/AverageReturn             | 1801.583   |
| perf/NormalizedReturn          | 0.392      |
| Q-avg                          | 206.13179  |
| Q-std                          | 129.00722  |
| Q_loss                         | 104.197    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 361        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000307   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000446   |
| times/evaluation_paths         | 18.8       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00859    |
| times/train                    | 70.1       |
| timestep                       | 1000       |
| timesteps_total                | 362000     |
| train-steps                    | 362000     |
| training/Q/q1_loss             | 79.03231   |
| training/sac_pi/alpha          | 0.16560432 |
| training/sac_pi/alpha_loss     | 0.20466909 |
| training/sac_pi/logp_pi        | 4.79794    |
| training/sac_pi/pi_entropy     | 3.4499512  |
| training/sac_pi/pi_global_norm | 1.9118153  |
| training/sac_pi/policy_loss    | -228.18129 |
| training/sac_pi/std            | 0.5030214  |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 217.89389  |
| training/sac_Q/q2              | 219.80452  |
| training/sac_Q/q2_loss         | 79.729546  |
| training/sac_Q/q_global_norm   | 255.32274  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16650683 |
| epoch                          | 362        |
| evaluation/episode-length-avg  | 915        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 151        |
| evaluation/episode-length-std  | 255        |
| evaluation/return-average      | 4303.3975  |
| evaluation/return-max          | 4817.186   |
| evaluation/return-min          | 422.18408  |
| evaluation/return-std          | 1294.5359  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46386      |
| perf/AverageLength             | 915        |
| perf/AverageReturn             | 4303.3975  |
| perf/NormalizedReturn          | 0.937      |
| Q-avg                          | 217.04428  |
| Q-std                          | 99.87765   |
| Q_loss                         | 100.62378  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 362        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000119   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000748   |
| times/evaluation_paths         | 32.4       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 363000     |
| train-steps                    | 363000     |
| training/Q/q1_loss             | 101.661316 |
| training/sac_pi/alpha          | 0.16650783 |
| training/sac_pi/alpha_loss     | 0.43472373 |
| training/sac_pi/logp_pi        | 4.290609   |
| training/sac_pi/pi_entropy     | 3.714206   |
| training/sac_pi/pi_global_norm | 1.7286061  |
| training/sac_pi/policy_loss    | -216.86972 |
| training/sac_pi/std            | 0.5296301  |
| training/sac_pi/valid_num      | 4901.0     |
| training/sac_Q/q1              | 203.30347  |
| training/sac_Q/q2              | 205.84619  |
| training/sac_Q/q2_loss         | 100.909454 |
| training/sac_Q/q_global_norm   | 274.04474  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15696092 |
| epoch                          | 363        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4729.8037  |
| evaluation/return-max          | 4801.123   |
| evaluation/return-min          | 4625.1484  |
| evaluation/return-std          | 55.60659   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46254      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4729.8037  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 214.87985  |
| Q-std                          | 103.47278  |
| Q_loss                         | 93.89262   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 363        |
| times/epoch_after_hook         | 1.63e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000547   |
| times/evaluation_paths         | 44.3       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 364000     |
| train-steps                    | 364000     |
| training/Q/q1_loss             | 108.25898  |
| training/sac_pi/alpha          | 0.15695478 |
| training/sac_pi/alpha_loss     | -0.2692407 |
| training/sac_pi/logp_pi        | 4.9688087  |
| training/sac_pi/pi_entropy     | 3.647192   |
| training/sac_pi/pi_global_norm | 2.234694   |
| training/sac_pi/policy_loss    | -226.0846  |
| training/sac_pi/std            | 0.5612373  |
| training/sac_pi/valid_num      | 4926.0     |
| training/sac_Q/q1              | 211.07755  |
| training/sac_Q/q2              | 213.67744  |
| training/sac_Q/q2_loss         | 107.702255 |
| training/sac_Q/q_global_norm   | 269.2852   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16382343  |
| epoch                          | 364         |
| evaluation/episode-length-avg  | 916         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 163         |
| evaluation/episode-length-std  | 251         |
| evaluation/return-average      | 4654.4854   |
| evaluation/return-max          | 5159.2036   |
| evaluation/return-min          | 517.1463    |
| evaluation/return-std          | 1379.4058   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 80.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46390       |
| perf/AverageLength             | 916         |
| perf/AverageReturn             | 4654.4854   |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 216.90475   |
| Q-std                          | 92.142746   |
| Q_loss                         | 119.70988   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 364         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000563    |
| times/evaluation_paths         | 42.5        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 365000      |
| train-steps                    | 365000      |
| training/Q/q1_loss             | 76.2306     |
| training/sac_pi/alpha          | 0.1638342   |
| training/sac_pi/alpha_loss     | -0.21064366 |
| training/sac_pi/logp_pi        | 3.6228127   |
| training/sac_pi/pi_entropy     | 3.3742461   |
| training/sac_pi/pi_global_norm | 2.268689    |
| training/sac_pi/policy_loss    | -225.84775  |
| training/sac_pi/std            | 0.46998397  |
| training/sac_pi/valid_num      | 5018.0      |
| training/sac_Q/q1              | 222.0378    |
| training/sac_Q/q2              | 222.32117   |
| training/sac_Q/q2_loss         | 76.1909     |
| training/sac_Q/q_global_norm   | 361.3887    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1689885  |
| epoch                          | 365        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5081.7256  |
| evaluation/return-max          | 5152.781   |
| evaluation/return-min          | 4971.7637  |
| evaluation/return-std          | 55.502983  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46327      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5081.7256  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 217.81255  |
| Q-std                          | 94.84848   |
| Q_loss                         | 110.75192  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 365        |
| times/epoch_after_hook         | 1.86e-06   |
| times/epoch_before_hook        | 0.000288   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000606   |
| times/evaluation_paths         | 36.9       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 71.9       |
| timestep                       | 1000       |
| timesteps_total                | 366000     |
| train-steps                    | 366000     |
| training/Q/q1_loss             | 92.04847   |
| training/sac_pi/alpha          | 0.1690401  |
| training/sac_pi/alpha_loss     | -0.593094  |
| training/sac_pi/logp_pi        | 3.4702973  |
| training/sac_pi/pi_entropy     | 3.6048157  |
| training/sac_pi/pi_global_norm | 1.7140127  |
| training/sac_pi/policy_loss    | -226.77048 |
| training/sac_pi/std            | 0.48609808 |
| training/sac_pi/valid_num      | 4989.0     |
| training/sac_Q/q1              | 218.72678  |
| training/sac_Q/q2              | 220.44038  |
| training/sac_Q/q2_loss         | 93.03222   |
| training/sac_Q/q_global_norm   | 294.89774  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17259379 |
| epoch                          | 366        |
| evaluation/episode-length-avg  | 321        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 143        |
| evaluation/episode-length-std  | 339        |
| evaluation/return-average      | 1394.8157  |
| evaluation/return-max          | 4968.4756  |
| evaluation/return-min          | 474.65778  |
| evaluation/return-std          | 1777.5006  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 81         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46261      |
| perf/AverageLength             | 321        |
| perf/AverageReturn             | 1394.8157  |
| perf/NormalizedReturn          | 0.303      |
| Q-avg                          | 205.74455  |
| Q-std                          | 147.293    |
| Q_loss                         | 89.681046  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 366        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000614   |
| times/evaluation_paths         | 15.6       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 62.4       |
| timestep                       | 1000       |
| timesteps_total                | 367000     |
| train-steps                    | 367000     |
| training/Q/q1_loss             | 82.39283   |
| training/sac_pi/alpha          | 0.17262824 |
| training/sac_pi/alpha_loss     | -0.4793261 |
| training/sac_pi/logp_pi        | 3.855845   |
| training/sac_pi/pi_entropy     | 3.5040812  |
| training/sac_pi/pi_global_norm | 2.5531554  |
| training/sac_pi/policy_loss    | -231.34087 |
| training/sac_pi/std            | 0.49775207 |
| training/sac_pi/valid_num      | 4976.0     |
| training/sac_Q/q1              | 222.62027  |
| training/sac_Q/q2              | 224.92041  |
| training/sac_Q/q2_loss         | 82.538246  |
| training/sac_Q/q_global_norm   | 194.56508  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17184842 |
| epoch                          | 367        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4987.9814  |
| evaluation/return-max          | 5029.091   |
| evaluation/return-min          | 4953.159   |
| evaluation/return-std          | 24.52275   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 81.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46255      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4987.9814  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 222.0142   |
| Q-std                          | 82.65878   |
| Q_loss                         | 109.902824 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 367        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 511        |
| times/evaluation_metrics       | 0.000723   |
| times/evaluation_paths         | 47.1       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 62.5       |
| timestep                       | 1000       |
| timesteps_total                | 368000     |
| train-steps                    | 368000     |
| training/Q/q1_loss             | 108.57238  |
| training/sac_pi/alpha          | 0.17184526 |
| training/sac_pi/alpha_loss     | 0.04417487 |
| training/sac_pi/logp_pi        | 3.4150798  |
| training/sac_pi/pi_entropy     | 3.5681891  |
| training/sac_pi/pi_global_norm | 1.8512316  |
| training/sac_pi/policy_loss    | -225.02068 |
| training/sac_pi/std            | 0.4735154  |
| training/sac_pi/valid_num      | 5018.0     |
| training/sac_Q/q1              | 219.57832  |
| training/sac_Q/q2              | 220.6665   |
| training/sac_Q/q2_loss         | 108.21176  |
| training/sac_Q/q_global_norm   | 294.1108   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16928504   |
| epoch                          | 368          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4877.3276    |
| evaluation/return-max          | 4900.3457    |
| evaluation/return-min          | 4851.205     |
| evaluation/return-std          | 15.474922    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.1          |
| model/origin_ret               | 85.7         |
| model/penalty_ret              | 80           |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46427        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4877.3276    |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 204.7789     |
| Q-std                          | 119.26211    |
| Q_loss                         | 92.84491     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 368          |
| times/epoch_after_hook         | 1.81e-06     |
| times/epoch_before_hook        | 0.00012      |
| times/epoch_rollout_model      | 489          |
| times/evaluation_metrics       | 0.000653     |
| times/evaluation_paths         | 46.1         |
| times/timestep_after_hook      | 0.00372      |
| times/timestep_before_hook     | 0.00836      |
| times/train                    | 64.6         |
| timestep                       | 1000         |
| timesteps_total                | 369000       |
| train-steps                    | 369000       |
| training/Q/q1_loss             | 97.90467     |
| training/sac_pi/alpha          | 0.16930892   |
| training/sac_pi/alpha_loss     | -0.050259948 |
| training/sac_pi/logp_pi        | 4.236972     |
| training/sac_pi/pi_entropy     | 3.4567978    |
| training/sac_pi/pi_global_norm | 1.7550278    |
| training/sac_pi/policy_loss    | -227.20387   |
| training/sac_pi/std            | 0.48858497   |
| training/sac_pi/valid_num      | 4995.0       |
| training/sac_Q/q1              | 220.24185    |
| training/sac_Q/q2              | 221.76419    |
| training/sac_Q/q2_loss         | 98.77969     |
| training/sac_Q/q_global_norm   | 202.70288    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16488838 |
| epoch                          | 369        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5033.9077  |
| evaluation/return-max          | 5148.1694  |
| evaluation/return-min          | 4926.422   |
| evaluation/return-std          | 67.407906  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46324      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5033.9077  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 219.89957  |
| Q-std                          | 94.48925   |
| Q_loss                         | 113.486275 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 369        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000267   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000645   |
| times/evaluation_paths         | 35         |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.0087     |
| times/train                    | 65.3       |
| timestep                       | 1000       |
| timesteps_total                | 370000     |
| train-steps                    | 370000     |
| training/Q/q1_loss             | 112.43345  |
| training/sac_pi/alpha          | 0.16489027 |
| training/sac_pi/alpha_loss     | 0.25239563 |
| training/sac_pi/logp_pi        | 4.019444   |
| training/sac_pi/pi_entropy     | 3.2944837  |
| training/sac_pi/pi_global_norm | 1.957156   |
| training/sac_pi/policy_loss    | -223.57895 |
| training/sac_pi/std            | 0.46696076 |
| training/sac_pi/valid_num      | 5002.0     |
| training/sac_Q/q1              | 217.1647   |
| training/sac_Q/q2              | 217.5339   |
| training/sac_Q/q2_loss         | 111.96015  |
| training/sac_Q/q_global_norm   | 221.79333  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17435816  |
| epoch                          | 370         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5085.699    |
| evaluation/return-max          | 5291.7617   |
| evaluation/return-min          | 4972.17     |
| evaluation/return-std          | 110.839554  |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46295       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5085.699    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 211.64026   |
| Q-std                          | 111.27304   |
| Q_loss                         | 82.58133    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 370         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000506    |
| times/evaluation_paths         | 44          |
| times/timestep_after_hook      | 0.00391     |
| times/timestep_before_hook     | 0.00857     |
| times/train                    | 68.2        |
| timestep                       | 1000        |
| timesteps_total                | 371000      |
| train-steps                    | 371000      |
| training/Q/q1_loss             | 91.15029    |
| training/sac_pi/alpha          | 0.17440835  |
| training/sac_pi/alpha_loss     | -0.48441863 |
| training/sac_pi/logp_pi        | 3.7176814   |
| training/sac_pi/pi_entropy     | 3.6000977   |
| training/sac_pi/pi_global_norm | 1.8020015   |
| training/sac_pi/policy_loss    | -226.77681  |
| training/sac_pi/std            | 0.5076821   |
| training/sac_pi/valid_num      | 4957.0      |
| training/sac_Q/q1              | 216.50626   |
| training/sac_Q/q2              | 218.846     |
| training/sac_Q/q2_loss         | 90.7032     |
| training/sac_Q/q_global_norm   | 224.0485    |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16739725   |
| epoch                          | 371          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5144.645     |
| evaluation/return-max          | 5192.343     |
| evaluation/return-min          | 5110.7993    |
| evaluation/return-std          | 23.253681    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.01         |
| model/origin_ret               | 84.2         |
| model/penalty_ret              | 80.3         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46198        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5144.645     |
| perf/NormalizedReturn          | 1.12         |
| Q-avg                          | 207.15799    |
| Q-std                          | 109.87844    |
| Q_loss                         | 102.23439    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 371          |
| times/epoch_after_hook         | 1.66e-06     |
| times/epoch_before_hook        | 0.000119     |
| times/epoch_rollout_model      | 495          |
| times/evaluation_metrics       | 0.000513     |
| times/evaluation_paths         | 43.9         |
| times/timestep_after_hook      | 0.0039       |
| times/timestep_before_hook     | 0.00841      |
| times/train                    | 68.8         |
| timestep                       | 1000         |
| timesteps_total                | 372000       |
| train-steps                    | 372000       |
| training/Q/q1_loss             | 93.36331     |
| training/sac_pi/alpha          | 0.16740496   |
| training/sac_pi/alpha_loss     | -0.099305175 |
| training/sac_pi/logp_pi        | 4.048256     |
| training/sac_pi/pi_entropy     | 3.3900661    |
| training/sac_pi/pi_global_norm | 1.6471336    |
| training/sac_pi/policy_loss    | -222.973     |
| training/sac_pi/std            | 0.4856605    |
| training/sac_pi/valid_num      | 4973.0       |
| training/sac_Q/q1              | 214.7107     |
| training/sac_Q/q2              | 215.60278    |
| training/sac_Q/q2_loss         | 93.49355     |
| training/sac_Q/q_global_norm   | 273.05423    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16261123 |
| epoch                          | 372        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5249.3354  |
| evaluation/return-max          | 5271.4785  |
| evaluation/return-min          | 5234.3755  |
| evaluation/return-std          | 11.914262  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46246      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5249.3354  |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 217.96994  |
| Q-std                          | 108.45012  |
| Q_loss                         | 111.39706  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 372        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000518   |
| times/evaluation_paths         | 42         |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00873    |
| times/train                    | 70.7       |
| timestep                       | 1000       |
| timesteps_total                | 373000     |
| train-steps                    | 373000     |
| training/Q/q1_loss             | 91.33819   |
| training/sac_pi/alpha          | 0.16263732 |
| training/sac_pi/alpha_loss     | 0.17928877 |
| training/sac_pi/logp_pi        | 4.0329657  |
| training/sac_pi/pi_entropy     | 3.4328125  |
| training/sac_pi/pi_global_norm | 2.054226   |
| training/sac_pi/policy_loss    | -231.35315 |
| training/sac_pi/std            | 0.48420513 |
| training/sac_pi/valid_num      | 5035.0     |
| training/sac_Q/q1              | 225.6221   |
| training/sac_Q/q2              | 226.21065  |
| training/sac_Q/q2_loss         | 90.8728    |
| training/sac_Q/q_global_norm   | 272.89603  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1690391   |
| epoch                          | 373         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4976.103    |
| evaluation/return-max          | 5022.694    |
| evaluation/return-min          | 4917.3867   |
| evaluation/return-std          | 30.318054   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46298       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4976.103    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 204.56905   |
| Q-std                          | 115.38266   |
| Q_loss                         | 122.44594   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 373         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000295    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000689    |
| times/evaluation_paths         | 39.3        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 374000      |
| train-steps                    | 374000      |
| training/Q/q1_loss             | 104.03176   |
| training/sac_pi/alpha          | 0.16906747  |
| training/sac_pi/alpha_loss     | -0.17896803 |
| training/sac_pi/logp_pi        | 4.534765    |
| training/sac_pi/pi_entropy     | 3.5441387   |
| training/sac_pi/pi_global_norm | 1.7917137   |
| training/sac_pi/policy_loss    | -223.12106  |
| training/sac_pi/std            | 0.5229767   |
| training/sac_pi/valid_num      | 4928.0      |
| training/sac_Q/q1              | 211.78415   |
| training/sac_Q/q2              | 212.12381   |
| training/sac_Q/q2_loss         | 102.3719    |
| training/sac_Q/q_global_norm   | 328.50473   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16857903 |
| epoch                          | 374        |
| evaluation/episode-length-avg  | 328        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 157        |
| evaluation/episode-length-std  | 336        |
| evaluation/return-average      | 1444.8093  |
| evaluation/return-max          | 5188.372   |
| evaluation/return-min          | 501.1707   |
| evaluation/return-std          | 1865.9672  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46241      |
| perf/AverageLength             | 328        |
| perf/AverageReturn             | 1444.8093  |
| perf/NormalizedReturn          | 0.314      |
| Q-avg                          | 221.70972  |
| Q-std                          | 104.71896  |
| Q_loss                         | 99.49498   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 374        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000602   |
| times/evaluation_paths         | 14.3       |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 72.7       |
| timestep                       | 1000       |
| timesteps_total                | 375000     |
| train-steps                    | 375000     |
| training/Q/q1_loss             | 90.544235  |
| training/sac_pi/alpha          | 0.16855435 |
| training/sac_pi/alpha_loss     | 0.07159556 |
| training/sac_pi/logp_pi        | 3.7492776  |
| training/sac_pi/pi_entropy     | 3.6350188  |
| training/sac_pi/pi_global_norm | 1.6936692  |
| training/sac_pi/policy_loss    | -220.90796 |
| training/sac_pi/std            | 0.5005091  |
| training/sac_pi/valid_num      | 4990.0     |
| training/sac_Q/q1              | 213.07549  |
| training/sac_Q/q2              | 213.51921  |
| training/sac_Q/q2_loss         | 91.23705   |
| training/sac_Q/q_global_norm   | 249.35405  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16970634 |
| epoch                          | 375        |
| evaluation/episode-length-avg  | 155        |
| evaluation/episode-length-max  | 158        |
| evaluation/episode-length-min  | 153        |
| evaluation/episode-length-std  | 1.54       |
| evaluation/return-average      | 483.795    |
| evaluation/return-max          | 495.99316  |
| evaluation/return-min          | 476.19553  |
| evaluation/return-std          | 5.5926237  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46233      |
| perf/AverageLength             | 155        |
| perf/AverageReturn             | 483.795    |
| perf/NormalizedReturn          | 0.105      |
| Q-avg                          | 207.78738  |
| Q-std                          | 127.44125  |
| Q_loss                         | 87.36237   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 375        |
| times/epoch_after_hook         | 3.29e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000564   |
| times/evaluation_paths         | 7.26       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00857    |
| times/train                    | 66         |
| timestep                       | 1000       |
| timesteps_total                | 376000     |
| train-steps                    | 376000     |
| training/Q/q1_loss             | 116.44256  |
| training/sac_pi/alpha          | 0.16975275 |
| training/sac_pi/alpha_loss     | -0.2555077 |
| training/sac_pi/logp_pi        | 4.111745   |
| training/sac_pi/pi_entropy     | 3.8054237  |
| training/sac_pi/pi_global_norm | 1.7337221  |
| training/sac_pi/policy_loss    | -212.96686 |
| training/sac_pi/std            | 0.5459108  |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 203.96867  |
| training/sac_Q/q2              | 206.02621  |
| training/sac_Q/q2_loss         | 116.922745 |
| training/sac_Q/q_global_norm   | 284.67035  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17404003 |
| epoch                          | 376        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4978.21    |
| evaluation/return-max          | 5032.3623  |
| evaluation/return-min          | 4909.208   |
| evaluation/return-std          | 38.257214  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46450      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4978.21    |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 214.95015  |
| Q-std                          | 104.48221  |
| Q_loss                         | 95.95759   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 376        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000578   |
| times/evaluation_paths         | 44.9       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00859    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 377000     |
| train-steps                    | 377000     |
| training/Q/q1_loss             | 99.90752   |
| training/sac_pi/alpha          | 0.17403884 |
| training/sac_pi/alpha_loss     | 0.49018818 |
| training/sac_pi/logp_pi        | 4.7321954  |
| training/sac_pi/pi_entropy     | 3.625648   |
| training/sac_pi/pi_global_norm | 2.2200615  |
| training/sac_pi/policy_loss    | -216.71889 |
| training/sac_pi/std            | 0.51968735 |
| training/sac_pi/valid_num      | 4959.0     |
| training/sac_Q/q1              | 204.94992  |
| training/sac_Q/q2              | 207.17407  |
| training/sac_Q/q2_loss         | 100.62945  |
| training/sac_Q/q_global_norm   | 272.67075  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.168145    |
| epoch                          | 377         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4868.16     |
| evaluation/return-max          | 4934.867    |
| evaluation/return-min          | 4738.513    |
| evaluation/return-std          | 54.053776   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46299       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4868.16     |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 210.40752   |
| Q-std                          | 105.45764   |
| Q_loss                         | 105.68493   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 377         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000324    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000666    |
| times/evaluation_paths         | 37          |
| times/timestep_after_hook      | 0.00376     |
| times/timestep_before_hook     | 0.009       |
| times/train                    | 72.2        |
| timestep                       | 1000        |
| timesteps_total                | 378000      |
| train-steps                    | 378000      |
| training/Q/q1_loss             | 99.157936   |
| training/sac_pi/alpha          | 0.16812713  |
| training/sac_pi/alpha_loss     | -0.16596508 |
| training/sac_pi/logp_pi        | 3.800386    |
| training/sac_pi/pi_entropy     | 3.5218425   |
| training/sac_pi/pi_global_norm | 2.0073228   |
| training/sac_pi/policy_loss    | -218.77257  |
| training/sac_pi/std            | 0.49548578  |
| training/sac_pi/valid_num      | 4989.0      |
| training/sac_Q/q1              | 209.2957    |
| training/sac_Q/q2              | 210.62625   |
| training/sac_Q/q2_loss         | 99.297005   |
| training/sac_Q/q_global_norm   | 235.4541    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16514102  |
| epoch                          | 378         |
| evaluation/episode-length-avg  | 573         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 145         |
| evaluation/episode-length-std  | 427         |
| evaluation/return-average      | 2772.2336   |
| evaluation/return-max          | 5135.7075   |
| evaluation/return-min          | 442.39752   |
| evaluation/return-std          | 2321.8323   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46181       |
| perf/AverageLength             | 573         |
| perf/AverageReturn             | 2772.2336   |
| perf/NormalizedReturn          | 0.604       |
| Q-avg                          | 214.06119   |
| Q-std                          | 110.205444  |
| Q_loss                         | 112.92142   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 378         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000658    |
| times/evaluation_paths         | 27.3        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00846     |
| times/train                    | 62          |
| timestep                       | 1000        |
| timesteps_total                | 379000      |
| train-steps                    | 379000      |
| training/Q/q1_loss             | 106.00714   |
| training/sac_pi/alpha          | 0.16512205  |
| training/sac_pi/alpha_loss     | 0.059812434 |
| training/sac_pi/logp_pi        | 5.5427074   |
| training/sac_pi/pi_entropy     | 3.6413207   |
| training/sac_pi/pi_global_norm | 1.9393921   |
| training/sac_pi/policy_loss    | -218.10942  |
| training/sac_pi/std            | 0.56370157  |
| training/sac_pi/valid_num      | 4838.0      |
| training/sac_Q/q1              | 197.56287   |
| training/sac_Q/q2              | 200.49704   |
| training/sac_Q/q2_loss         | 106.78314   |
| training/sac_Q/q_global_norm   | 194.74869   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1717422   |
| epoch                          | 379         |
| evaluation/episode-length-avg  | 579         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 156         |
| evaluation/episode-length-std  | 421         |
| evaluation/return-average      | 2693.8208   |
| evaluation/return-max          | 4913.7227   |
| evaluation/return-min          | 502.10626   |
| evaluation/return-std          | 2182.497    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86          |
| model/penalty_ret              | 81.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46272       |
| perf/AverageLength             | 579         |
| perf/AverageReturn             | 2693.8208   |
| perf/NormalizedReturn          | 0.586       |
| Q-avg                          | 207.931     |
| Q-std                          | 113.6584    |
| Q_loss                         | 109.3465    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 379         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000606    |
| times/evaluation_paths         | 24.6        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 60.1        |
| timestep                       | 1000        |
| timesteps_total                | 380000      |
| train-steps                    | 380000      |
| training/Q/q1_loss             | 99.03581    |
| training/sac_pi/alpha          | 0.17173825  |
| training/sac_pi/alpha_loss     | -0.13424169 |
| training/sac_pi/logp_pi        | 3.9420662   |
| training/sac_pi/pi_entropy     | 3.384037    |
| training/sac_pi/pi_global_norm | 1.8275448   |
| training/sac_pi/policy_loss    | -224.66792  |
| training/sac_pi/std            | 0.47991568  |
| training/sac_pi/valid_num      | 4971.0      |
| training/sac_Q/q1              | 215.12251   |
| training/sac_Q/q2              | 216.01726   |
| training/sac_Q/q2_loss         | 97.39802    |
| training/sac_Q/q_global_norm   | 265.0298    |
---------------------------------------------------------------------------------
[WARN] 380 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16444482 |
| epoch                          | 380        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4895.398   |
| evaluation/return-max          | 4984.372   |
| evaluation/return-min          | 4781.6963  |
| evaluation/return-std          | 63.21148   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46422      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4895.398   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 207.45818  |
| Q-std                          | 101.768234 |
| Q_loss                         | 99.31414   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 380        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000605   |
| times/evaluation_paths         | 46         |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00884    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 381000     |
| train-steps                    | 381000     |
| training/Q/q1_loss             | 106.62014  |
| training/sac_pi/alpha          | 0.16444084 |
| training/sac_pi/alpha_loss     | 0.24162473 |
| training/sac_pi/logp_pi        | 4.882296   |
| training/sac_pi/pi_entropy     | 3.3836339  |
| training/sac_pi/pi_global_norm | 1.5964408  |
| training/sac_pi/policy_loss    | -227.52367 |
| training/sac_pi/std            | 0.51505    |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 215.99197  |
| training/sac_Q/q2              | 216.56287  |
| training/sac_Q/q2_loss         | 107.94659  |
| training/sac_Q/q_global_norm   | 244.28473  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17040682 |
| epoch                          | 381        |
| evaluation/episode-length-avg  | 916        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 162        |
| evaluation/episode-length-std  | 251        |
| evaluation/return-average      | 4574.1855  |
| evaluation/return-max          | 5052.6514  |
| evaluation/return-min          | 527.3415   |
| evaluation/return-std          | 1349.1726  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46500      |
| perf/AverageLength             | 916        |
| perf/AverageReturn             | 4574.1855  |
| perf/NormalizedReturn          | 0.996      |
| Q-avg                          | 208.48618  |
| Q-std                          | 112.49091  |
| Q_loss                         | 97.25788   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 381        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.00028    |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000634   |
| times/evaluation_paths         | 34.4       |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.00844    |
| times/train                    | 63.2       |
| timestep                       | 1000       |
| timesteps_total                | 382000     |
| train-steps                    | 382000     |
| training/Q/q1_loss             | 110.356224 |
| training/sac_pi/alpha          | 0.17038205 |
| training/sac_pi/alpha_loss     | 0.31387845 |
| training/sac_pi/logp_pi        | 5.0418077  |
| training/sac_pi/pi_entropy     | 3.4370236  |
| training/sac_pi/pi_global_norm | 1.5638436  |
| training/sac_pi/policy_loss    | -216.76338 |
| training/sac_pi/std            | 0.5178028  |
| training/sac_pi/valid_num      | 4940.0     |
| training/sac_Q/q1              | 203.31003  |
| training/sac_Q/q2              | 205.33318  |
| training/sac_Q/q2_loss         | 110.69469  |
| training/sac_Q/q_global_norm   | 278.04523  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17251253  |
| epoch                          | 382         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4739.5474   |
| evaluation/return-max          | 4891.8125   |
| evaluation/return-min          | 4626.9453   |
| evaluation/return-std          | 80.97832    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46448       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4739.5474   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 219.00015   |
| Q-std                          | 100.90585   |
| Q_loss                         | 110.565674  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 382         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000759    |
| times/evaluation_paths         | 43.5        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00884     |
| times/train                    | 70.8        |
| timestep                       | 1000        |
| timesteps_total                | 383000      |
| train-steps                    | 383000      |
| training/Q/q1_loss             | 101.921196  |
| training/sac_pi/alpha          | 0.17251351  |
| training/sac_pi/alpha_loss     | -0.12698391 |
| training/sac_pi/logp_pi        | 5.0565705   |
| training/sac_pi/pi_entropy     | 3.3143325   |
| training/sac_pi/pi_global_norm | 2.3851118   |
| training/sac_pi/policy_loss    | -222.35411  |
| training/sac_pi/std            | 0.49999663  |
| training/sac_pi/valid_num      | 4932.0      |
| training/sac_Q/q1              | 205.45113   |
| training/sac_Q/q2              | 209.54318   |
| training/sac_Q/q2_loss         | 101.98458   |
| training/sac_Q/q_global_norm   | 232.55687   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17057875 |
| epoch                          | 383        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4981.6123  |
| evaluation/return-max          | 5018.495   |
| evaluation/return-min          | 4944.0815  |
| evaluation/return-std          | 23.725723  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46297      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4981.6123  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 217.28088  |
| Q-std                          | 100.3137   |
| Q_loss                         | 91.21042   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 383        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000142   |
| times/epoch_rollout_model      | 529        |
| times/evaluation_metrics       | 0.000789   |
| times/evaluation_paths         | 37.9       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 71.7       |
| timestep                       | 1000       |
| timesteps_total                | 384000     |
| train-steps                    | 384000     |
| training/Q/q1_loss             | 113.872086 |
| training/sac_pi/alpha          | 0.17059642 |
| training/sac_pi/alpha_loss     | 0.12694554 |
| training/sac_pi/logp_pi        | 4.1866546  |
| training/sac_pi/pi_entropy     | 3.652593   |
| training/sac_pi/pi_global_norm | 2.3025703  |
| training/sac_pi/policy_loss    | -217.62004 |
| training/sac_pi/std            | 0.50719565 |
| training/sac_pi/valid_num      | 4934.0     |
| training/sac_Q/q1              | 206.3492   |
| training/sac_Q/q2              | 206.65918  |
| training/sac_Q/q2_loss         | 113.43507  |
| training/sac_Q/q_global_norm   | 260.305    |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17659444 |
| epoch                          | 384        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5027.586   |
| evaluation/return-max          | 5048.3945  |
| evaluation/return-min          | 5009.336   |
| evaluation/return-std          | 13.106591  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46361      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5027.586   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 217.48734  |
| Q-std                          | 105.60685  |
| Q_loss                         | 106.896164 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 384        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000634   |
| times/evaluation_paths         | 38.8       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 72.3       |
| timestep                       | 1000       |
| timesteps_total                | 385000     |
| train-steps                    | 385000     |
| training/Q/q1_loss             | 106.397194 |
| training/sac_pi/alpha          | 0.17663594 |
| training/sac_pi/alpha_loss     | -0.2603816 |
| training/sac_pi/logp_pi        | 3.2716613  |
| training/sac_pi/pi_entropy     | 3.6309228  |
| training/sac_pi/pi_global_norm | 2.3761191  |
| training/sac_pi/policy_loss    | -216.53496 |
| training/sac_pi/std            | 0.48023674 |
| training/sac_pi/valid_num      | 5010.0     |
| training/sac_Q/q1              | 210.61795  |
| training/sac_Q/q2              | 210.73799  |
| training/sac_Q/q2_loss         | 105.198654 |
| training/sac_Q/q_global_norm   | 344.19492  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17485826 |
| epoch                          | 385        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4957.062   |
| evaluation/return-max          | 5020.2783  |
| evaluation/return-min          | 4919.3926  |
| evaluation/return-std          | 34.052036  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46265      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4957.062   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 210.7013   |
| Q-std                          | 98.336105  |
| Q_loss                         | 84.74152   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 385        |
| times/epoch_after_hook         | 3.06e-06   |
| times/epoch_before_hook        | 0.000271   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000622   |
| times/evaluation_paths         | 41         |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 386000     |
| train-steps                    | 386000     |
| training/Q/q1_loss             | 92.02879   |
| training/sac_pi/alpha          | 0.17479137 |
| training/sac_pi/alpha_loss     | 0.64226466 |
| training/sac_pi/logp_pi        | 3.9964416  |
| training/sac_pi/pi_entropy     | 3.4212708  |
| training/sac_pi/pi_global_norm | 2.1493485  |
| training/sac_pi/policy_loss    | -223.3924  |
| training/sac_pi/std            | 0.46630704 |
| training/sac_pi/valid_num      | 5044.0     |
| training/sac_Q/q1              | 219.44539  |
| training/sac_Q/q2              | 220.15259  |
| training/sac_Q/q2_loss         | 92.47717   |
| training/sac_Q/q_global_norm   | 296.9302   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17418942  |
| epoch                          | 386         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4960.1313   |
| evaluation/return-max          | 5020.8945   |
| evaluation/return-min          | 4882.451    |
| evaluation/return-std          | 45.55021    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.17        |
| model/origin_ret               | 87.6        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46266       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4960.1313   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 211.64249   |
| Q-std                          | 122.33476   |
| Q_loss                         | 116.16371   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 386         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000687    |
| times/evaluation_paths         | 40.5        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00858     |
| times/train                    | 74          |
| timestep                       | 1000        |
| timesteps_total                | 387000      |
| train-steps                    | 387000      |
| training/Q/q1_loss             | 110.09477   |
| training/sac_pi/alpha          | 0.17421573  |
| training/sac_pi/alpha_loss     | -0.10005169 |
| training/sac_pi/logp_pi        | 4.1600895   |
| training/sac_pi/pi_entropy     | 3.4870086   |
| training/sac_pi/pi_global_norm | 2.1766195   |
| training/sac_pi/policy_loss    | -227.31783  |
| training/sac_pi/std            | 0.5059574   |
| training/sac_pi/valid_num      | 4985.0      |
| training/sac_Q/q1              | 219.76724   |
| training/sac_Q/q2              | 221.11641   |
| training/sac_Q/q2_loss         | 110.65963   |
| training/sac_Q/q_global_norm   | 274.78668   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16827558   |
| epoch                          | 387          |
| evaluation/episode-length-avg  | 147          |
| evaluation/episode-length-max  | 149          |
| evaluation/episode-length-min  | 139          |
| evaluation/episode-length-std  | 2.86         |
| evaluation/return-average      | 468.16196    |
| evaluation/return-max          | 478.7724     |
| evaluation/return-min          | 433.58835    |
| evaluation/return-std          | 12.000556    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.08         |
| model/origin_ret               | 85.4         |
| model/penalty_ret              | 80.3         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46270        |
| perf/AverageLength             | 147          |
| perf/AverageReturn             | 468.16196    |
| perf/NormalizedReturn          | 0.102        |
| Q-avg                          | 202.97415    |
| Q-std                          | 127.444084   |
| Q_loss                         | 113.1267     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 387          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.000125     |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.000535     |
| times/evaluation_paths         | 7.05         |
| times/timestep_after_hook      | 0.00383      |
| times/timestep_before_hook     | 0.00851      |
| times/train                    | 77.5         |
| timestep                       | 1000         |
| timesteps_total                | 388000       |
| train-steps                    | 388000       |
| training/Q/q1_loss             | 93.36068     |
| training/sac_pi/alpha          | 0.16830501   |
| training/sac_pi/alpha_loss     | -0.034423973 |
| training/sac_pi/logp_pi        | 4.6040177    |
| training/sac_pi/pi_entropy     | 3.3839202    |
| training/sac_pi/pi_global_norm | 2.4836543    |
| training/sac_pi/policy_loss    | -219.54028   |
| training/sac_pi/std            | 0.5099466    |
| training/sac_pi/valid_num      | 4986.0       |
| training/sac_Q/q1              | 210.11784    |
| training/sac_Q/q2              | 210.47444    |
| training/sac_Q/q2_loss         | 93.212425    |
| training/sac_Q/q_global_norm   | 307.40433    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17341821 |
| epoch                          | 388        |
| evaluation/episode-length-avg  | 916        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 157        |
| evaluation/episode-length-std  | 253        |
| evaluation/return-average      | 4666.025   |
| evaluation/return-max          | 5241.4834  |
| evaluation/return-min          | 510.57767  |
| evaluation/return-std          | 1386.1809  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 83.4       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46483      |
| perf/AverageLength             | 916        |
| perf/AverageReturn             | 4666.025   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 213.41113  |
| Q-std                          | 125.86705  |
| Q_loss                         | 86.52126   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 388        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000119   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000604   |
| times/evaluation_paths         | 48.9       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00852    |
| times/train                    | 73.4       |
| timestep                       | 1000       |
| timesteps_total                | 389000     |
| train-steps                    | 389000     |
| training/Q/q1_loss             | 98.89702   |
| training/sac_pi/alpha          | 0.1734353  |
| training/sac_pi/alpha_loss     | 0.02659809 |
| training/sac_pi/logp_pi        | 4.1014485  |
| training/sac_pi/pi_entropy     | 3.6083343  |
| training/sac_pi/pi_global_norm | 2.0827098  |
| training/sac_pi/policy_loss    | -217.3129  |
| training/sac_pi/std            | 0.5076237  |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 208.32756  |
| training/sac_Q/q2              | 208.34824  |
| training/sac_Q/q2_loss         | 98.210976  |
| training/sac_Q/q_global_norm   | 248.13254  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17258973 |
| epoch                          | 389        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5095.6577  |
| evaluation/return-max          | 5139.647   |
| evaluation/return-min          | 5075.1875  |
| evaluation/return-std          | 22.028652  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46391      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5095.6577  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 209.49426  |
| Q-std                          | 115.56235  |
| Q_loss                         | 92.57264   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 389        |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.000277   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.00061    |
| times/evaluation_paths         | 50         |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00878    |
| times/train                    | 80.3       |
| timestep                       | 1000       |
| timesteps_total                | 390000     |
| train-steps                    | 390000     |
| training/Q/q1_loss             | 100.89504  |
| training/sac_pi/alpha          | 0.1725636  |
| training/sac_pi/alpha_loss     | 0.03838217 |
| training/sac_pi/logp_pi        | 4.525441   |
| training/sac_pi/pi_entropy     | 3.7564168  |
| training/sac_pi/pi_global_norm | 1.9616653  |
| training/sac_pi/policy_loss    | -210.07495 |
| training/sac_pi/std            | 0.5396721  |
| training/sac_pi/valid_num      | 4848.0     |
| training/sac_Q/q1              | 196.26407  |
| training/sac_Q/q2              | 197.45737  |
| training/sac_Q/q2_loss         | 102.022415 |
| training/sac_Q/q_global_norm   | 237.32271  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16754386  |
| epoch                          | 390         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4936.529    |
| evaluation/return-max          | 5041.7393   |
| evaluation/return-min          | 4793.584    |
| evaluation/return-std          | 87.664894   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46359       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4936.529    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 222.35811   |
| Q-std                          | 89.971146   |
| Q_loss                         | 100.66778   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 390         |
| times/epoch_after_hook         | 2.1e-06     |
| times/epoch_before_hook        | 0.000148    |
| times/epoch_rollout_model      | 514         |
| times/evaluation_metrics       | 0.000771    |
| times/evaluation_paths         | 48.1        |
| times/timestep_after_hook      | 0.00423     |
| times/timestep_before_hook     | 0.0089      |
| times/train                    | 78.4        |
| timestep                       | 1000        |
| timesteps_total                | 391000      |
| train-steps                    | 391000      |
| training/Q/q1_loss             | 83.29474    |
| training/sac_pi/alpha          | 0.16753569  |
| training/sac_pi/alpha_loss     | 0.012064238 |
| training/sac_pi/logp_pi        | 4.0111585   |
| training/sac_pi/pi_entropy     | 3.4298089   |
| training/sac_pi/pi_global_norm | 1.851683    |
| training/sac_pi/policy_loss    | -219.40898  |
| training/sac_pi/std            | 0.48981008  |
| training/sac_pi/valid_num      | 5010.0      |
| training/sac_Q/q1              | 212.68245   |
| training/sac_Q/q2              | 213.19502   |
| training/sac_Q/q2_loss         | 83.08413    |
| training/sac_Q/q_global_norm   | 198.48871   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16902871   |
| epoch                          | 391          |
| evaluation/episode-length-avg  | 830          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 150          |
| evaluation/episode-length-std  | 339          |
| evaluation/return-average      | 4230.2056    |
| evaluation/return-max          | 5181.025     |
| evaluation/return-min          | 454.99503    |
| evaluation/return-std          | 1881.9348    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.12         |
| model/origin_ret               | 85.8         |
| model/penalty_ret              | 80.3         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46489        |
| perf/AverageLength             | 830          |
| perf/AverageReturn             | 4230.2056    |
| perf/NormalizedReturn          | 0.921        |
| Q-avg                          | 211.19096    |
| Q-std                          | 133.2242     |
| Q_loss                         | 104.1376     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 391          |
| times/epoch_after_hook         | 1.75e-06     |
| times/epoch_before_hook        | 0.000161     |
| times/epoch_rollout_model      | 513          |
| times/evaluation_metrics       | 0.000769     |
| times/evaluation_paths         | 41.3         |
| times/timestep_after_hook      | 0.00412      |
| times/timestep_before_hook     | 0.00933      |
| times/train                    | 83.5         |
| timestep                       | 1000         |
| timesteps_total                | 392000       |
| train-steps                    | 392000       |
| training/Q/q1_loss             | 85.67804     |
| training/sac_pi/alpha          | 0.16905503   |
| training/sac_pi/alpha_loss     | -0.059489638 |
| training/sac_pi/logp_pi        | 3.6471176    |
| training/sac_pi/pi_entropy     | 3.4097085    |
| training/sac_pi/pi_global_norm | 2.24753      |
| training/sac_pi/policy_loss    | -226.2292    |
| training/sac_pi/std            | 0.46746656   |
| training/sac_pi/valid_num      | 4940.0       |
| training/sac_Q/q1              | 217.72983    |
| training/sac_Q/q2              | 218.69966    |
| training/sac_Q/q2_loss         | 85.25341     |
| training/sac_Q/q_global_norm   | 230.03925    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16727798  |
| epoch                          | 392         |
| evaluation/episode-length-avg  | 916         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 159         |
| evaluation/episode-length-std  | 252         |
| evaluation/return-average      | 4848.207    |
| evaluation/return-max          | 5392.487    |
| evaluation/return-min          | 483.91318   |
| evaluation/return-std          | 1455.5933   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46373       |
| perf/AverageLength             | 916         |
| perf/AverageReturn             | 4848.207    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 215.50757   |
| Q-std                          | 116.4682    |
| Q_loss                         | 108.776924  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 392         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000171    |
| times/epoch_rollout_model      | 525         |
| times/evaluation_metrics       | 0.00067     |
| times/evaluation_paths         | 37.9        |
| times/timestep_after_hook      | 0.00394     |
| times/timestep_before_hook     | 0.00893     |
| times/train                    | 74          |
| timestep                       | 1000        |
| timesteps_total                | 393000      |
| train-steps                    | 393000      |
| training/Q/q1_loss             | 99.61918    |
| training/sac_pi/alpha          | 0.16730185  |
| training/sac_pi/alpha_loss     | -0.07174812 |
| training/sac_pi/logp_pi        | 3.9944031   |
| training/sac_pi/pi_entropy     | 3.5701241   |
| training/sac_pi/pi_global_norm | 1.9230658   |
| training/sac_pi/policy_loss    | -218.82684  |
| training/sac_pi/std            | 0.5034708   |
| training/sac_pi/valid_num      | 4984.0      |
| training/sac_Q/q1              | 209.5666    |
| training/sac_Q/q2              | 211.84355   |
| training/sac_Q/q2_loss         | 100.42316   |
| training/sac_Q/q_global_norm   | 389.72275   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16696902  |
| epoch                          | 393         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5020.2163   |
| evaluation/return-max          | 5156.5723   |
| evaluation/return-min          | 4915.1787   |
| evaluation/return-std          | 71.17703    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 2.98        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46189       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5020.2163   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 207.20596   |
| Q-std                          | 134.11496   |
| Q_loss                         | 115.198746  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 393         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.00047     |
| times/epoch_rollout_model      | 512         |
| times/evaluation_metrics       | 0.000705    |
| times/evaluation_paths         | 37.9        |
| times/timestep_after_hook      | 0.00401     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 63          |
| timestep                       | 1000        |
| timesteps_total                | 394000      |
| train-steps                    | 394000      |
| training/Q/q1_loss             | 131.56924   |
| training/sac_pi/alpha          | 0.166989    |
| training/sac_pi/alpha_loss     | -0.16343914 |
| training/sac_pi/logp_pi        | 5.150449    |
| training/sac_pi/pi_entropy     | 3.5747695   |
| training/sac_pi/pi_global_norm | 1.8704276   |
| training/sac_pi/policy_loss    | -215.75456  |
| training/sac_pi/std            | 0.5401711   |
| training/sac_pi/valid_num      | 4869.0      |
| training/sac_Q/q1              | 201.26126   |
| training/sac_Q/q2              | 201.78305   |
| training/sac_Q/q2_loss         | 131.41258   |
| training/sac_Q/q_global_norm   | 266.9902    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16786335 |
| epoch                          | 394        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4971.6924  |
| evaluation/return-max          | 5003.4175  |
| evaluation/return-min          | 4934.244   |
| evaluation/return-std          | 25.007618  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46431      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4971.6924  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 211.38443  |
| Q-std                          | 104.762146 |
| Q_loss                         | 90.83278   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 394        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000139   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000711   |
| times/evaluation_paths         | 39.4       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00853    |
| times/train                    | 74.1       |
| timestep                       | 1000       |
| timesteps_total                | 395000     |
| train-steps                    | 395000     |
| training/Q/q1_loss             | 83.5314    |
| training/sac_pi/alpha          | 0.16783628 |
| training/sac_pi/alpha_loss     | 0.29498264 |
| training/sac_pi/logp_pi        | 3.7722251  |
| training/sac_pi/pi_entropy     | 3.5499198  |
| training/sac_pi/pi_global_norm | 1.7451468  |
| training/sac_pi/policy_loss    | -228.07617 |
| training/sac_pi/std            | 0.4817323  |
| training/sac_pi/valid_num      | 5010.0     |
| training/sac_Q/q1              | 221.1567   |
| training/sac_Q/q2              | 222.35489  |
| training/sac_Q/q2_loss         | 83.650696  |
| training/sac_Q/q_global_norm   | 213.16847  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17219634 |
| epoch                          | 395        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5049.0283  |
| evaluation/return-max          | 5106.6074  |
| evaluation/return-min          | 4987.6807  |
| evaluation/return-std          | 40.74649   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 87.4       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46382      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5049.0283  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 213.81824  |
| Q-std                          | 106.55247  |
| Q_loss                         | 109.24808  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 395        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000153   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000607   |
| times/evaluation_paths         | 39.2       |
| times/timestep_after_hook      | 0.00384    |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 72.2       |
| timestep                       | 1000       |
| timesteps_total                | 396000     |
| train-steps                    | 396000     |
| training/Q/q1_loss             | 109.60959  |
| training/sac_pi/alpha          | 0.17216693 |
| training/sac_pi/alpha_loss     | 0.11831607 |
| training/sac_pi/logp_pi        | 4.241391   |
| training/sac_pi/pi_entropy     | 3.5227878  |
| training/sac_pi/pi_global_norm | 1.7877747  |
| training/sac_pi/policy_loss    | -213.58719 |
| training/sac_pi/std            | 0.49508682 |
| training/sac_pi/valid_num      | 4973.0     |
| training/sac_Q/q1              | 206.65097  |
| training/sac_Q/q2              | 207.49458  |
| training/sac_Q/q2_loss         | 108.97981  |
| training/sac_Q/q_global_norm   | 263.40903  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16933182  |
| epoch                          | 396         |
| evaluation/episode-length-avg  | 245         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 160         |
| evaluation/episode-length-std  | 252         |
| evaluation/return-average      | 970.4945    |
| evaluation/return-max          | 5073.451    |
| evaluation/return-min          | 505.61554   |
| evaluation/return-std          | 1367.6593   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46451       |
| perf/AverageLength             | 245         |
| perf/AverageReturn             | 970.4945    |
| perf/NormalizedReturn          | 0.211       |
| Q-avg                          | 222.10507   |
| Q-std                          | 114.72332   |
| Q_loss                         | 83.66476    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 396         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000601    |
| times/evaluation_paths         | 10.2        |
| times/timestep_after_hook      | 0.00384     |
| times/timestep_before_hook     | 0.00848     |
| times/train                    | 73.6        |
| timestep                       | 1000        |
| timesteps_total                | 397000      |
| train-steps                    | 397000      |
| training/Q/q1_loss             | 99.06931    |
| training/sac_pi/alpha          | 0.16935362  |
| training/sac_pi/alpha_loss     | -0.27150613 |
| training/sac_pi/logp_pi        | 3.623991    |
| training/sac_pi/pi_entropy     | 3.4883132   |
| training/sac_pi/pi_global_norm | 1.6983116   |
| training/sac_pi/policy_loss    | -220.44952  |
| training/sac_pi/std            | 0.48958454  |
| training/sac_pi/valid_num      | 5019.0      |
| training/sac_Q/q1              | 214.08076   |
| training/sac_Q/q2              | 214.54597   |
| training/sac_Q/q2_loss         | 99.14218    |
| training/sac_Q/q_global_norm   | 230.08926   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16476397  |
| epoch                          | 397         |
| evaluation/episode-length-avg  | 576         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 149         |
| evaluation/episode-length-std  | 424         |
| evaluation/return-average      | 2732.9292   |
| evaluation/return-max          | 5080.977    |
| evaluation/return-min          | 442.05594   |
| evaluation/return-std          | 2271.6414   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46429       |
| perf/AverageLength             | 576         |
| perf/AverageReturn             | 2732.9292   |
| perf/NormalizedReturn          | 0.595       |
| Q-avg                          | 204.55188   |
| Q-std                          | 117.63689   |
| Q_loss                         | 98.55032    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 397         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000276    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000612    |
| times/evaluation_paths         | 20          |
| times/timestep_after_hook      | 0.00378     |
| times/timestep_before_hook     | 0.00852     |
| times/train                    | 64.5        |
| timestep                       | 1000        |
| timesteps_total                | 398000      |
| train-steps                    | 398000      |
| training/Q/q1_loss             | 114.46448   |
| training/sac_pi/alpha          | 0.16472168  |
| training/sac_pi/alpha_loss     | -0.05219999 |
| training/sac_pi/logp_pi        | 4.0970273   |
| training/sac_pi/pi_entropy     | 3.3988724   |
| training/sac_pi/pi_global_norm | 2.3835196   |
| training/sac_pi/policy_loss    | -226.20677  |
| training/sac_pi/std            | 0.48169103  |
| training/sac_pi/valid_num      | 4985.0      |
| training/sac_Q/q1              | 215.95346   |
| training/sac_Q/q2              | 216.60889   |
| training/sac_Q/q2_loss         | 112.885254  |
| training/sac_Q/q_global_norm   | 283.67233   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15919584  |
| epoch                          | 398         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5142.822    |
| evaluation/return-max          | 5194.254    |
| evaluation/return-min          | 5113.829    |
| evaluation/return-std          | 21.083023   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 84.4        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46395       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5142.822    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 216.45027   |
| Q-std                          | 123.25632   |
| Q_loss                         | 67.28731    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 398         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000536    |
| times/evaluation_paths         | 46.1        |
| times/timestep_after_hook      | 0.00376     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 64.9        |
| timestep                       | 1000        |
| timesteps_total                | 399000      |
| train-steps                    | 399000      |
| training/Q/q1_loss             | 85.2654     |
| training/sac_pi/alpha          | 0.1591674   |
| training/sac_pi/alpha_loss     | 0.018377537 |
| training/sac_pi/logp_pi        | 4.550212    |
| training/sac_pi/pi_entropy     | 3.5399203   |
| training/sac_pi/pi_global_norm | 1.8814392   |
| training/sac_pi/policy_loss    | -222.67995  |
| training/sac_pi/std            | 0.5242352   |
| training/sac_pi/valid_num      | 4945.0      |
| training/sac_Q/q1              | 212.02339   |
| training/sac_Q/q2              | 211.6407    |
| training/sac_Q/q2_loss         | 86.124565   |
| training/sac_Q/q_global_norm   | 242.56319   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16352238 |
| epoch                          | 399        |
| evaluation/episode-length-avg  | 243        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 152        |
| evaluation/episode-length-std  | 252        |
| evaluation/return-average      | 950.79364  |
| evaluation/return-max          | 5139.217   |
| evaluation/return-min          | 458.95547  |
| evaluation/return-std          | 1396.2255  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46462      |
| perf/AverageLength             | 243        |
| perf/AverageReturn             | 950.79364  |
| perf/NormalizedReturn          | 0.207      |
| Q-avg                          | 210.78287  |
| Q-std                          | 115.963684 |
| Q_loss                         | 107.815544 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 399        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000579   |
| times/evaluation_paths         | 9.8        |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 74.6       |
| timestep                       | 1000       |
| timesteps_total                | 400000     |
| train-steps                    | 400000     |
| training/Q/q1_loss             | 108.030624 |
| training/sac_pi/alpha          | 0.16357738 |
| training/sac_pi/alpha_loss     | -0.4673174 |
| training/sac_pi/logp_pi        | 4.8948894  |
| training/sac_pi/pi_entropy     | 3.5950325  |
| training/sac_pi/pi_global_norm | 1.9449769  |
| training/sac_pi/policy_loss    | -222.3884  |
| training/sac_pi/std            | 0.54450244 |
| training/sac_pi/valid_num      | 4908.0     |
| training/sac_Q/q1              | 209.82224  |
| training/sac_Q/q2              | 209.86691  |
| training/sac_Q/q2_loss         | 109.06094  |
| training/sac_Q/q_global_norm   | 241.30933  |
--------------------------------------------------------------------------------
[WARN] 400 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.17085227  |
| epoch                          | 400         |
| evaluation/episode-length-avg  | 144         |
| evaluation/episode-length-max  | 153         |
| evaluation/episode-length-min  | 142         |
| evaluation/episode-length-std  | 2.94        |
| evaluation/return-average      | 394.74738   |
| evaluation/return-max          | 440.71954   |
| evaluation/return-min          | 385.9198    |
| evaluation/return-std          | 15.634777   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46451       |
| perf/AverageLength             | 144         |
| perf/AverageReturn             | 394.74738   |
| perf/NormalizedReturn          | 0.0856      |
| Q-avg                          | 217.31943   |
| Q-std                          | 115.40072   |
| Q_loss                         | 85.732      |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 400         |
| times/epoch_after_hook         | 1.98e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.0006      |
| times/evaluation_paths         | 7           |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00853     |
| times/train                    | 69.6        |
| timestep                       | 1000        |
| timesteps_total                | 401000      |
| train-steps                    | 401000      |
| training/Q/q1_loss             | 115.91413   |
| training/sac_pi/alpha          | 0.17086323  |
| training/sac_pi/alpha_loss     | -0.39888918 |
| training/sac_pi/logp_pi        | 3.7157562   |
| training/sac_pi/pi_entropy     | 3.4213738   |
| training/sac_pi/pi_global_norm | 1.72082     |
| training/sac_pi/policy_loss    | -220.37851  |
| training/sac_pi/std            | 0.46278578  |
| training/sac_pi/valid_num      | 4996.0      |
| training/sac_Q/q1              | 213.82059   |
| training/sac_Q/q2              | 215.19254   |
| training/sac_Q/q2_loss         | 115.211655  |
| training/sac_Q/q_global_norm   | 361.8504    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17588627  |
| epoch                          | 401         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4676.2305   |
| evaluation/return-max          | 4968.7725   |
| evaluation/return-min          | 4550.4087   |
| evaluation/return-std          | 106.103355  |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.15        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46420       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4676.2305   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 220.42976   |
| Q-std                          | 101.75588   |
| Q_loss                         | 97.43567    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 401         |
| times/epoch_after_hook         | 1.63e-06    |
| times/epoch_before_hook        | 0.00033     |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000641    |
| times/evaluation_paths         | 38.7        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00829     |
| times/train                    | 74.2        |
| timestep                       | 1000        |
| timesteps_total                | 402000      |
| train-steps                    | 402000      |
| training/Q/q1_loss             | 98.262024   |
| training/sac_pi/alpha          | 0.17589386  |
| training/sac_pi/alpha_loss     | -0.11594209 |
| training/sac_pi/logp_pi        | 3.8213477   |
| training/sac_pi/pi_entropy     | 3.4629066   |
| training/sac_pi/pi_global_norm | 1.7692927   |
| training/sac_pi/policy_loss    | -226.6074   |
| training/sac_pi/std            | 0.47426346  |
| training/sac_pi/valid_num      | 5002.0      |
| training/sac_Q/q1              | 219.8868    |
| training/sac_Q/q2              | 221.62993   |
| training/sac_Q/q2_loss         | 96.65029    |
| training/sac_Q/q_global_norm   | 302.19562   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16780439 |
| epoch                          | 402        |
| evaluation/episode-length-avg  | 964        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 640        |
| evaluation/episode-length-std  | 108        |
| evaluation/return-average      | 4590.03    |
| evaluation/return-max          | 4970.413   |
| evaluation/return-min          | 2695.689   |
| evaluation/return-std          | 645.2127   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46357      |
| perf/AverageLength             | 964        |
| perf/AverageReturn             | 4590.03    |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 215.62842  |
| Q-std                          | 101.82743  |
| Q_loss                         | 92.364105  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 402        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000591   |
| times/evaluation_paths         | 45.4       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 403000     |
| train-steps                    | 403000     |
| training/Q/q1_loss             | 100.20446  |
| training/sac_pi/alpha          | 0.16774894 |
| training/sac_pi/alpha_loss     | 0.3680707  |
| training/sac_pi/logp_pi        | 4.1907606  |
| training/sac_pi/pi_entropy     | 3.428201   |
| training/sac_pi/pi_global_norm | 2.1015553  |
| training/sac_pi/policy_loss    | -216.70287 |
| training/sac_pi/std            | 0.47428137 |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 207.70891  |
| training/sac_Q/q2              | 208.37314  |
| training/sac_Q/q2_loss         | 101.29603  |
| training/sac_Q/q_global_norm   | 194.47234  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16978711 |
| epoch                          | 403        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4841.6777  |
| evaluation/return-max          | 4899.302   |
| evaluation/return-min          | 4753.182   |
| evaluation/return-std          | 41.036037  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46424      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4841.6777  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 206.06912  |
| Q-std                          | 129.33464  |
| Q_loss                         | 93.87663   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 403        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000119   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000572   |
| times/evaluation_paths         | 46.4       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00886    |
| times/train                    | 68.1       |
| timestep                       | 1000       |
| timesteps_total                | 404000     |
| train-steps                    | 404000     |
| training/Q/q1_loss             | 92.022865  |
| training/sac_pi/alpha          | 0.16979727 |
| training/sac_pi/alpha_loss     | 0.0839568  |
| training/sac_pi/logp_pi        | 4.3624177  |
| training/sac_pi/pi_entropy     | 3.3704705  |
| training/sac_pi/pi_global_norm | 2.1362026  |
| training/sac_pi/policy_loss    | -220.63153 |
| training/sac_pi/std            | 0.4806732  |
| training/sac_pi/valid_num      | 4918.0     |
| training/sac_Q/q1              | 208.23564  |
| training/sac_Q/q2              | 210.04092  |
| training/sac_Q/q2_loss         | 92.14813   |
| training/sac_Q/q_global_norm   | 255.51132  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1702786  |
| epoch                          | 404        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5030.8135  |
| evaluation/return-max          | 5071.4497  |
| evaluation/return-min          | 4938.1333  |
| evaluation/return-std          | 45.272713  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46325      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5030.8135  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 206.57857  |
| Q-std                          | 109.46013  |
| Q_loss                         | 104.21636  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 404        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000595   |
| times/evaluation_paths         | 45.1       |
| times/timestep_after_hook      | 0.00386    |
| times/timestep_before_hook     | 0.00868    |
| times/train                    | 69.7       |
| timestep                       | 1000       |
| timesteps_total                | 405000     |
| train-steps                    | 405000     |
| training/Q/q1_loss             | 93.23747   |
| training/sac_pi/alpha          | 0.17022368 |
| training/sac_pi/alpha_loss     | 0.23257354 |
| training/sac_pi/logp_pi        | 4.382955   |
| training/sac_pi/pi_entropy     | 3.5653954  |
| training/sac_pi/pi_global_norm | 1.8244776  |
| training/sac_pi/policy_loss    | -219.50842 |
| training/sac_pi/std            | 0.5032174  |
| training/sac_pi/valid_num      | 4955.0     |
| training/sac_Q/q1              | 207.9335   |
| training/sac_Q/q2              | 210.29878  |
| training/sac_Q/q2_loss         | 93.43812   |
| training/sac_Q/q_global_norm   | 184.41104  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16304174  |
| epoch                          | 405         |
| evaluation/episode-length-avg  | 492         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 138         |
| evaluation/episode-length-std  | 415         |
| evaluation/return-average      | 2180.231    |
| evaluation/return-max          | 4841.0713   |
| evaluation/return-min          | 383.50894   |
| evaluation/return-std          | 2127.5806   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46309       |
| perf/AverageLength             | 492         |
| perf/AverageReturn             | 2180.231    |
| perf/NormalizedReturn          | 0.475       |
| Q-avg                          | 221.525     |
| Q-std                          | 119.41863   |
| Q_loss                         | 105.949554  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 405         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000335    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000731    |
| times/evaluation_paths         | 20.3        |
| times/timestep_after_hook      | 0.00383     |
| times/timestep_before_hook     | 0.00847     |
| times/train                    | 60.2        |
| timestep                       | 1000        |
| timesteps_total                | 406000      |
| train-steps                    | 406000      |
| training/Q/q1_loss             | 103.91299   |
| training/sac_pi/alpha          | 0.16304262  |
| training/sac_pi/alpha_loss     | 0.005988679 |
| training/sac_pi/logp_pi        | 4.5210485   |
| training/sac_pi/pi_entropy     | 3.3598187   |
| training/sac_pi/pi_global_norm | 1.752647    |
| training/sac_pi/policy_loss    | -215.24467  |
| training/sac_pi/std            | 0.50535107  |
| training/sac_pi/valid_num      | 4974.0      |
| training/sac_Q/q1              | 204.99516   |
| training/sac_Q/q2              | 208.92477   |
| training/sac_Q/q2_loss         | 102.98534   |
| training/sac_Q/q_global_norm   | 281.37454   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1615253  |
| epoch                          | 406        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5108.042   |
| evaluation/return-max          | 5235.1553  |
| evaluation/return-min          | 4972.4697  |
| evaluation/return-std          | 85.134254  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46387      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5108.042   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 207.95288  |
| Q-std                          | 123.944    |
| Q_loss                         | 98.69208   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 406        |
| times/epoch_after_hook         | 1.59e-06   |
| times/epoch_before_hook        | 0.0003     |
| times/epoch_rollout_model      | 527        |
| times/evaluation_metrics       | 0.000607   |
| times/evaluation_paths         | 39.1       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 70.2       |
| timestep                       | 1000       |
| timesteps_total                | 407000     |
| train-steps                    | 407000     |
| training/Q/q1_loss             | 106.18438  |
| training/sac_pi/alpha          | 0.16151729 |
| training/sac_pi/alpha_loss     | 0.23514739 |
| training/sac_pi/logp_pi        | 4.397077   |
| training/sac_pi/pi_entropy     | 3.3333366  |
| training/sac_pi/pi_global_norm | 2.0681214  |
| training/sac_pi/policy_loss    | -224.15614 |
| training/sac_pi/std            | 0.48446116 |
| training/sac_pi/valid_num      | 4948.0     |
| training/sac_Q/q1              | 215.00821  |
| training/sac_Q/q2              | 216.4351   |
| training/sac_Q/q2_loss         | 104.79975  |
| training/sac_Q/q_global_norm   | 267.93222  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16868588   |
| epoch                          | 407          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4994.981     |
| evaluation/return-max          | 5060.826     |
| evaluation/return-min          | 4932.9814    |
| evaluation/return-std          | 38.015575    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.07         |
| model/origin_ret               | 84.8         |
| model/penalty_ret              | 79.5         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46569        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4994.981     |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 217.83542    |
| Q-std                          | 118.67593    |
| Q_loss                         | 91.65303     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 407          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.000127     |
| times/epoch_rollout_model      | 488          |
| times/evaluation_metrics       | 0.000595     |
| times/evaluation_paths         | 37.5         |
| times/timestep_after_hook      | 0.00616      |
| times/timestep_before_hook     | 0.00854      |
| times/train                    | 70.1         |
| timestep                       | 1000         |
| timesteps_total                | 408000       |
| train-steps                    | 408000       |
| training/Q/q1_loss             | 75.17581     |
| training/sac_pi/alpha          | 0.16866216   |
| training/sac_pi/alpha_loss     | -0.027789587 |
| training/sac_pi/logp_pi        | 4.145896     |
| training/sac_pi/pi_entropy     | 3.5784545    |
| training/sac_pi/pi_global_norm | 1.7366834    |
| training/sac_pi/policy_loss    | -228.4413    |
| training/sac_pi/std            | 0.5043028    |
| training/sac_pi/valid_num      | 4974.0       |
| training/sac_Q/q1              | 218.3937     |
| training/sac_Q/q2              | 219.39987    |
| training/sac_Q/q2_loss         | 74.459816    |
| training/sac_Q/q_global_norm   | 297.49783    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16341141 |
| epoch                          | 408        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4936.8174  |
| evaluation/return-max          | 4990.331   |
| evaluation/return-min          | 4852.994   |
| evaluation/return-std          | 46.287464  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86.8       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46461      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4936.8174  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 214.02637  |
| Q-std                          | 109.57681  |
| Q_loss                         | 98.06184   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 408        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000679   |
| times/evaluation_paths         | 40.8       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00862    |
| times/train                    | 73.3       |
| timestep                       | 1000       |
| timesteps_total                | 409000     |
| train-steps                    | 409000     |
| training/Q/q1_loss             | 106.83265  |
| training/sac_pi/alpha          | 0.16339771 |
| training/sac_pi/alpha_loss     | 0.2188586  |
| training/sac_pi/logp_pi        | 3.9088006  |
| training/sac_pi/pi_entropy     | 3.4927223  |
| training/sac_pi/pi_global_norm | 2.2459297  |
| training/sac_pi/policy_loss    | -216.52582 |
| training/sac_pi/std            | 0.48367664 |
| training/sac_pi/valid_num      | 5000.0     |
| training/sac_Q/q1              | 208.51465  |
| training/sac_Q/q2              | 210.22778  |
| training/sac_Q/q2_loss         | 105.80007  |
| training/sac_Q/q_global_norm   | 305.01617  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1604386  |
| epoch                          | 409        |
| evaluation/episode-length-avg  | 242        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 152        |
| evaluation/episode-length-std  | 253        |
| evaluation/return-average      | 903.5187   |
| evaluation/return-max          | 5018.573   |
| evaluation/return-min          | 423.41815  |
| evaluation/return-std          | 1371.7487  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46333      |
| perf/AverageLength             | 242        |
| perf/AverageReturn             | 903.5187   |
| perf/NormalizedReturn          | 0.196      |
| Q-avg                          | 214.97949  |
| Q-std                          | 113.00797  |
| Q_loss                         | 110.76589  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 409        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000272   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000606   |
| times/evaluation_paths         | 10.2       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 410000     |
| train-steps                    | 410000     |
| training/Q/q1_loss             | 104.049286 |
| training/sac_pi/alpha          | 0.16040218 |
| training/sac_pi/alpha_loss     | 0.42808294 |
| training/sac_pi/logp_pi        | 4.5138083  |
| training/sac_pi/pi_entropy     | 3.0990033  |
| training/sac_pi/pi_global_norm | 2.3897662  |
| training/sac_pi/policy_loss    | -223.72458 |
| training/sac_pi/std            | 0.4593005  |
| training/sac_pi/valid_num      | 4985.0     |
| training/sac_Q/q1              | 215.57852  |
| training/sac_Q/q2              | 216.74423  |
| training/sac_Q/q2_loss         | 104.419395 |
| training/sac_Q/q_global_norm   | 248.31609  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1574668  |
| epoch                          | 410        |
| evaluation/episode-length-avg  | 139        |
| evaluation/episode-length-max  | 141        |
| evaluation/episode-length-min  | 135        |
| evaluation/episode-length-std  | 1.64       |
| evaluation/return-average      | 426.82935  |
| evaluation/return-max          | 443.0785   |
| evaluation/return-min          | 405.14413  |
| evaluation/return-std          | 10.548837  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 84.3       |
| model/penalty_ret              | 79         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46489      |
| perf/AverageLength             | 139        |
| perf/AverageReturn             | 426.82935  |
| perf/NormalizedReturn          | 0.0926     |
| Q-avg                          | 217.4847   |
| Q-std                          | 124.720924 |
| Q_loss                         | 114.9526   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 410        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000683   |
| times/evaluation_paths         | 6.78       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00861    |
| times/train                    | 71         |
| timestep                       | 1000       |
| timesteps_total                | 411000     |
| train-steps                    | 411000     |
| training/Q/q1_loss             | 98.82271   |
| training/sac_pi/alpha          | 0.15744784 |
| training/sac_pi/alpha_loss     | 0.28383976 |
| training/sac_pi/logp_pi        | 4.215486   |
| training/sac_pi/pi_entropy     | 3.3193297  |
| training/sac_pi/pi_global_norm | 1.923916   |
| training/sac_pi/policy_loss    | -222.689   |
| training/sac_pi/std            | 0.4733389  |
| training/sac_pi/valid_num      | 4983.0     |
| training/sac_Q/q1              | 214.22823  |
| training/sac_Q/q2              | 214.48369  |
| training/sac_Q/q2_loss         | 99.85358   |
| training/sac_Q/q_global_norm   | 216.4257   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16188413 |
| epoch                          | 411        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5169.8594  |
| evaluation/return-max          | 5223.4805  |
| evaluation/return-min          | 5055.1016  |
| evaluation/return-std          | 45.562008  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46404      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5169.8594  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 215.9744   |
| Q-std                          | 102.46329  |
| Q_loss                         | 105.452324 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 411        |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000516   |
| times/evaluation_paths         | 48.1       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00864    |
| times/train                    | 66.1       |
| timestep                       | 1000       |
| timesteps_total                | 412000     |
| train-steps                    | 412000     |
| training/Q/q1_loss             | 109.1864   |
| training/sac_pi/alpha          | 0.16190375 |
| training/sac_pi/alpha_loss     | 0.39436674 |
| training/sac_pi/logp_pi        | 4.530975   |
| training/sac_pi/pi_entropy     | 3.2957702  |
| training/sac_pi/pi_global_norm | 2.515413   |
| training/sac_pi/policy_loss    | -221.14066 |
| training/sac_pi/std            | 0.4815215  |
| training/sac_pi/valid_num      | 4948.0     |
| training/sac_Q/q1              | 211.7186   |
| training/sac_Q/q2              | 214.45259  |
| training/sac_Q/q2_loss         | 109.49217  |
| training/sac_Q/q_global_norm   | 414.11307  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16801035 |
| epoch                          | 412        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4678.2017  |
| evaluation/return-max          | 4738.4453  |
| evaluation/return-min          | 4571.7065  |
| evaluation/return-std          | 45.58825   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46437      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4678.2017  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 214.76314  |
| Q-std                          | 99.14412   |
| Q_loss                         | 99.44755   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 412        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000707   |
| times/evaluation_paths         | 46         |
| times/timestep_after_hook      | 0.00381    |
| times/timestep_before_hook     | 0.00866    |
| times/train                    | 68         |
| timestep                       | 1000       |
| timesteps_total                | 413000     |
| train-steps                    | 413000     |
| training/Q/q1_loss             | 97.979385  |
| training/sac_pi/alpha          | 0.16796394 |
| training/sac_pi/alpha_loss     | 0.10844171 |
| training/sac_pi/logp_pi        | 4.045773   |
| training/sac_pi/pi_entropy     | 3.3253894  |
| training/sac_pi/pi_global_norm | 1.8707122  |
| training/sac_pi/policy_loss    | -228.6354  |
| training/sac_pi/std            | 0.46808848 |
| training/sac_pi/valid_num      | 4996.0     |
| training/sac_Q/q1              | 222.56955  |
| training/sac_Q/q2              | 223.01584  |
| training/sac_Q/q2_loss         | 97.40176   |
| training/sac_Q/q_global_norm   | 225.09503  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16033301 |
| epoch                          | 413        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4928.638   |
| evaluation/return-max          | 4973.891   |
| evaluation/return-min          | 4844.786   |
| evaluation/return-std          | 38.66431   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.03       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46226      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4928.638   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 219.3271   |
| Q-std                          | 123.21735  |
| Q_loss                         | 91.91012   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 413        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000334   |
| times/epoch_rollout_model      | 512        |
| times/evaluation_metrics       | 0.00077    |
| times/evaluation_paths         | 38.4       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00865    |
| times/train                    | 66         |
| timestep                       | 1000       |
| timesteps_total                | 414000     |
| train-steps                    | 414000     |
| training/Q/q1_loss             | 99.79258   |
| training/sac_pi/alpha          | 0.1602923  |
| training/sac_pi/alpha_loss     | 0.3014507  |
| training/sac_pi/logp_pi        | 4.1827774  |
| training/sac_pi/pi_entropy     | 3.3275666  |
| training/sac_pi/pi_global_norm | 1.9794644  |
| training/sac_pi/policy_loss    | -222.56195 |
| training/sac_pi/std            | 0.47788474 |
| training/sac_pi/valid_num      | 4998.0     |
| training/sac_Q/q1              | 214.87582  |
| training/sac_Q/q2              | 215.66692  |
| training/sac_Q/q2_loss         | 100.90616  |
| training/sac_Q/q_global_norm   | 199.49954  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16521567   |
| epoch                          | 414          |
| evaluation/episode-length-avg  | 153          |
| evaluation/episode-length-max  | 160          |
| evaluation/episode-length-min  | 150          |
| evaluation/episode-length-std  | 2.93         |
| evaluation/return-average      | 485.29742    |
| evaluation/return-max          | 509.8245     |
| evaluation/return-min          | 475.83398    |
| evaluation/return-std          | 9.66014      |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.06         |
| model/origin_ret               | 85           |
| model/penalty_ret              | 80           |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46347        |
| perf/AverageLength             | 153          |
| perf/AverageReturn             | 485.29742    |
| perf/NormalizedReturn          | 0.105        |
| Q-avg                          | 221.11014    |
| Q-std                          | 95.00527     |
| Q_loss                         | 116.35287    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 414          |
| times/epoch_after_hook         | 1.58e-06     |
| times/epoch_before_hook        | 0.000133     |
| times/epoch_rollout_model      | 496          |
| times/evaluation_metrics       | 0.000579     |
| times/evaluation_paths         | 7.69         |
| times/timestep_after_hook      | 0.00375      |
| times/timestep_before_hook     | 0.00844      |
| times/train                    | 65.2         |
| timestep                       | 1000         |
| timesteps_total                | 415000       |
| train-steps                    | 415000       |
| training/Q/q1_loss             | 110.94201    |
| training/sac_pi/alpha          | 0.16520664   |
| training/sac_pi/alpha_loss     | -0.075325616 |
| training/sac_pi/logp_pi        | 4.0734572    |
| training/sac_pi/pi_entropy     | 3.5103683    |
| training/sac_pi/pi_global_norm | 1.7367978    |
| training/sac_pi/policy_loss    | -219.08696   |
| training/sac_pi/std            | 0.4946206    |
| training/sac_pi/valid_num      | 4966.0       |
| training/sac_Q/q1              | 208.71802    |
| training/sac_Q/q2              | 208.69498    |
| training/sac_Q/q2_loss         | 111.10718    |
| training/sac_Q/q_global_norm   | 212.58784    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16636313 |
| epoch                          | 415        |
| evaluation/episode-length-avg  | 158        |
| evaluation/episode-length-max  | 163        |
| evaluation/episode-length-min  | 151        |
| evaluation/episode-length-std  | 4.8        |
| evaluation/return-average      | 524.43134  |
| evaluation/return-max          | 544.27014  |
| evaluation/return-min          | 492.75104  |
| evaluation/return-std          | 19.311726  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46454      |
| perf/AverageLength             | 158        |
| perf/AverageReturn             | 524.43134  |
| perf/NormalizedReturn          | 0.114      |
| Q-avg                          | 218.02084  |
| Q-std                          | 92.0095    |
| Q_loss                         | 118.550446 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 415        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000482   |
| times/evaluation_paths         | 5.32       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00873    |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 416000     |
| train-steps                    | 416000     |
| training/Q/q1_loss             | 96.306755  |
| training/sac_pi/alpha          | 0.16638015 |
| training/sac_pi/alpha_loss     | -0.0911437 |
| training/sac_pi/logp_pi        | 4.3943686  |
| training/sac_pi/pi_entropy     | 3.438151   |
| training/sac_pi/pi_global_norm | 1.7056483  |
| training/sac_pi/policy_loss    | -226.61821 |
| training/sac_pi/std            | 0.5157826  |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 217.35818  |
| training/sac_Q/q2              | 215.68181  |
| training/sac_Q/q2_loss         | 96.488976  |
| training/sac_Q/q_global_norm   | 327.6288   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1667534  |
| epoch                          | 416        |
| evaluation/episode-length-avg  | 322        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 142        |
| evaluation/episode-length-std  | 339        |
| evaluation/return-average      | 1339.7782  |
| evaluation/return-max          | 4899.843   |
| evaluation/return-min          | 420.00568  |
| evaluation/return-std          | 1779.1814  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46252      |
| perf/AverageLength             | 322        |
| perf/AverageReturn             | 1339.7782  |
| perf/NormalizedReturn          | 0.291      |
| Q-avg                          | 216.6268   |
| Q-std                          | 99.27626   |
| Q_loss                         | 114.19448  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 416        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000491   |
| times/evaluation_paths         | 11.1       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00842    |
| times/train                    | 63.3       |
| timestep                       | 1000       |
| timesteps_total                | 417000     |
| train-steps                    | 417000     |
| training/Q/q1_loss             | 127.3852   |
| training/sac_pi/alpha          | 0.16676319 |
| training/sac_pi/alpha_loss     | -0.3287735 |
| training/sac_pi/logp_pi        | 3.948162   |
| training/sac_pi/pi_entropy     | 3.4978995  |
| training/sac_pi/pi_global_norm | 1.7572159  |
| training/sac_pi/policy_loss    | -212.11528 |
| training/sac_pi/std            | 0.48596573 |
| training/sac_pi/valid_num      | 4977.0     |
| training/sac_Q/q1              | 203.68683  |
| training/sac_Q/q2              | 204.56656  |
| training/sac_Q/q2_loss         | 127.51683  |
| training/sac_Q/q_global_norm   | 277.9082   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16774139  |
| epoch                          | 417         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5102.118    |
| evaluation/return-max          | 5144.3613   |
| evaluation/return-min          | 5029.1367   |
| evaluation/return-std          | 38.97577    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46375       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5102.118    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 200.83234   |
| Q-std                          | 108.407684  |
| Q_loss                         | 123.44573   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 417         |
| times/epoch_after_hook         | 2.01e-06    |
| times/epoch_before_hook        | 0.000277    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.001       |
| times/evaluation_paths         | 48          |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00846     |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 418000      |
| train-steps                    | 418000      |
| training/Q/q1_loss             | 113.9666    |
| training/sac_pi/alpha          | 0.16774441  |
| training/sac_pi/alpha_loss     | -0.15489319 |
| training/sac_pi/logp_pi        | 4.1556635   |
| training/sac_pi/pi_entropy     | 3.5103233   |
| training/sac_pi/pi_global_norm | 1.994258    |
| training/sac_pi/policy_loss    | -211.95023  |
| training/sac_pi/std            | 0.5075427   |
| training/sac_pi/valid_num      | 4975.0      |
| training/sac_Q/q1              | 202.65088   |
| training/sac_Q/q2              | 203.47423   |
| training/sac_Q/q2_loss         | 113.27471   |
| training/sac_Q/q_global_norm   | 290.93964   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17410932  |
| epoch                          | 418         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4921.279    |
| evaluation/return-max          | 4990.848    |
| evaluation/return-min          | 4860.3916   |
| evaluation/return-std          | 36.323418   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46272       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4921.279    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 208.9063    |
| Q-std                          | 109.54906   |
| Q_loss                         | 115.69057   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 418         |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000627    |
| times/evaluation_paths         | 38.3        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 419000      |
| train-steps                    | 419000      |
| training/Q/q1_loss             | 125.82913   |
| training/sac_pi/alpha          | 0.17413305  |
| training/sac_pi/alpha_loss     | -0.32404903 |
| training/sac_pi/logp_pi        | 4.760627    |
| training/sac_pi/pi_entropy     | 3.3946228   |
| training/sac_pi/pi_global_norm | 2.204936    |
| training/sac_pi/policy_loss    | -223.09904  |
| training/sac_pi/std            | 0.50549996  |
| training/sac_pi/valid_num      | 4911.0      |
| training/sac_Q/q1              | 210.60184   |
| training/sac_Q/q2              | 212.8837    |
| training/sac_Q/q2_loss         | 126.91795   |
| training/sac_Q/q_global_norm   | 334.5858    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17327392  |
| epoch                          | 419         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5065.028    |
| evaluation/return-max          | 5100.4688   |
| evaluation/return-min          | 5030.258    |
| evaluation/return-std          | 24.192362   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46343       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5065.028    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 222.99966   |
| Q-std                          | 95.04688    |
| Q_loss                         | 91.1097     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 419         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000154    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000627    |
| times/evaluation_paths         | 39.4        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00864     |
| times/train                    | 62.2        |
| timestep                       | 1000        |
| timesteps_total                | 420000      |
| train-steps                    | 420000      |
| training/Q/q1_loss             | 105.12622   |
| training/sac_pi/alpha          | 0.1733045   |
| training/sac_pi/alpha_loss     | -0.22406198 |
| training/sac_pi/logp_pi        | 4.35462     |
| training/sac_pi/pi_entropy     | 3.5456173   |
| training/sac_pi/pi_global_norm | 2.033122    |
| training/sac_pi/policy_loss    | -217.91388  |
| training/sac_pi/std            | 0.50485486  |
| training/sac_pi/valid_num      | 4977.0      |
| training/sac_Q/q1              | 206.4509    |
| training/sac_Q/q2              | 206.88712   |
| training/sac_Q/q2_loss         | 105.49162   |
| training/sac_Q/q_global_norm   | 222.68324   |
---------------------------------------------------------------------------------
[WARN] 420 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.16857882   |
| epoch                          | 420          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4889.1064    |
| evaluation/return-max          | 4991.19      |
| evaluation/return-min          | 4824.8125    |
| evaluation/return-std          | 51.406857    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.1          |
| model/origin_ret               | 86.2         |
| model/penalty_ret              | 80.4         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46293        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4889.1064    |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 203.6825     |
| Q-std                          | 142.02351    |
| Q_loss                         | 92.45971     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 420          |
| times/epoch_after_hook         | 1.83e-06     |
| times/epoch_before_hook        | 0.00019      |
| times/epoch_rollout_model      | 491          |
| times/evaluation_metrics       | 0.000719     |
| times/evaluation_paths         | 38.1         |
| times/timestep_after_hook      | 0.00378      |
| times/timestep_before_hook     | 0.00858      |
| times/train                    | 62.4         |
| timestep                       | 1000         |
| timesteps_total                | 421000       |
| train-steps                    | 421000       |
| training/Q/q1_loss             | 91.74705     |
| training/sac_pi/alpha          | 0.16858225   |
| training/sac_pi/alpha_loss     | -0.072423816 |
| training/sac_pi/logp_pi        | 4.0465803    |
| training/sac_pi/pi_entropy     | 3.287428     |
| training/sac_pi/pi_global_norm | 1.9182464    |
| training/sac_pi/policy_loss    | -226.94133   |
| training/sac_pi/std            | 0.47199214   |
| training/sac_pi/valid_num      | 4985.0       |
| training/sac_Q/q1              | 218.03703    |
| training/sac_Q/q2              | 216.86665    |
| training/sac_Q/q2_loss         | 90.996994    |
| training/sac_Q/q_global_norm   | 229.23253    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16441233 |
| epoch                          | 421        |
| evaluation/episode-length-avg  | 916        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 161        |
| evaluation/episode-length-std  | 252        |
| evaluation/return-average      | 4742.6343  |
| evaluation/return-max          | 5271.585   |
| evaluation/return-min          | 494.37433  |
| evaluation/return-std          | 1416.3663  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46454      |
| perf/AverageLength             | 916        |
| perf/AverageReturn             | 4742.6343  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 206.41704  |
| Q-std                          | 120.07996  |
| Q_loss                         | 105.38524  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 421        |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.000291   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000559   |
| times/evaluation_paths         | 41.8       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 67.5       |
| timestep                       | 1000       |
| timesteps_total                | 422000     |
| train-steps                    | 422000     |
| training/Q/q1_loss             | 96.52187   |
| training/sac_pi/alpha          | 0.16443147 |
| training/sac_pi/alpha_loss     | 0.2009901  |
| training/sac_pi/logp_pi        | 4.016631   |
| training/sac_pi/pi_entropy     | 3.1482182  |
| training/sac_pi/pi_global_norm | 2.1993353  |
| training/sac_pi/policy_loss    | -223.11592 |
| training/sac_pi/std            | 0.44395578 |
| training/sac_pi/valid_num      | 5024.0     |
| training/sac_Q/q1              | 218.70227  |
| training/sac_Q/q2              | 218.6774   |
| training/sac_Q/q2_loss         | 95.495636  |
| training/sac_Q/q_global_norm   | 283.47925  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16511373 |
| epoch                          | 422        |
| evaluation/episode-length-avg  | 916        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 163        |
| evaluation/episode-length-std  | 251        |
| evaluation/return-average      | 4640.9014  |
| evaluation/return-max          | 5134.907   |
| evaluation/return-min          | 500.14728  |
| evaluation/return-std          | 1380.8931  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46430      |
| perf/AverageLength             | 916        |
| perf/AverageReturn             | 4640.9014  |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 211.78769  |
| Q-std                          | 111.205444 |
| Q_loss                         | 111.66036  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 422        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 527        |
| times/evaluation_metrics       | 0.000573   |
| times/evaluation_paths         | 43.9       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 67.3       |
| timestep                       | 1000       |
| timesteps_total                | 423000     |
| train-steps                    | 423000     |
| training/Q/q1_loss             | 104.2628   |
| training/sac_pi/alpha          | 0.16511458 |
| training/sac_pi/alpha_loss     | 0.12964411 |
| training/sac_pi/logp_pi        | 3.885301   |
| training/sac_pi/pi_entropy     | 3.5858033  |
| training/sac_pi/pi_global_norm | 2.2311766  |
| training/sac_pi/policy_loss    | -220.2195  |
| training/sac_pi/std            | 0.49050248 |
| training/sac_pi/valid_num      | 5020.0     |
| training/sac_Q/q1              | 214.15536  |
| training/sac_Q/q2              | 213.3654   |
| training/sac_Q/q2_loss         | 103.95625  |
| training/sac_Q/q_global_norm   | 251.77287  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15763299 |
| epoch                          | 423        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5108.793   |
| evaluation/return-max          | 5176.8525  |
| evaluation/return-min          | 5048.1177  |
| evaluation/return-std          | 49.325947  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46353      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5108.793   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 207.8197   |
| Q-std                          | 103.997894 |
| Q_loss                         | 94.07913   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 423        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 509        |
| times/evaluation_metrics       | 0.00057    |
| times/evaluation_paths         | 43.4       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00853    |
| times/train                    | 64.2       |
| timestep                       | 1000       |
| timesteps_total                | 424000     |
| train-steps                    | 424000     |
| training/Q/q1_loss             | 111.98329  |
| training/sac_pi/alpha          | 0.15762047 |
| training/sac_pi/alpha_loss     | 0.16677254 |
| training/sac_pi/logp_pi        | 4.436915   |
| training/sac_pi/pi_entropy     | 3.5039678  |
| training/sac_pi/pi_global_norm | 1.6516064  |
| training/sac_pi/policy_loss    | -213.83916 |
| training/sac_pi/std            | 0.50655293 |
| training/sac_pi/valid_num      | 4983.0     |
| training/sac_Q/q1              | 203.52702  |
| training/sac_Q/q2              | 205.59607  |
| training/sac_Q/q2_loss         | 113.50845  |
| training/sac_Q/q_global_norm   | 262.98825  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15822744  |
| epoch                          | 424         |
| evaluation/episode-length-avg  | 155         |
| evaluation/episode-length-max  | 162         |
| evaluation/episode-length-min  | 149         |
| evaluation/episode-length-std  | 4.18        |
| evaluation/return-average      | 452.81598   |
| evaluation/return-max          | 483.91293   |
| evaluation/return-min          | 428.51904   |
| evaluation/return-std          | 17.7921     |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46303       |
| perf/AverageLength             | 155         |
| perf/AverageReturn             | 452.81598   |
| perf/NormalizedReturn          | 0.0983      |
| Q-avg                          | 220.62024   |
| Q-std                          | 90.07351    |
| Q_loss                         | 104.71092   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 424         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000663    |
| times/evaluation_paths         | 5.49        |
| times/timestep_after_hook      | 0.00398     |
| times/timestep_before_hook     | 0.00866     |
| times/train                    | 64.9        |
| timestep                       | 1000        |
| timesteps_total                | 425000      |
| train-steps                    | 425000      |
| training/Q/q1_loss             | 102.84651   |
| training/sac_pi/alpha          | 0.15824033  |
| training/sac_pi/alpha_loss     | -0.07859048 |
| training/sac_pi/logp_pi        | 4.530757    |
| training/sac_pi/pi_entropy     | 3.3963609   |
| training/sac_pi/pi_global_norm | 1.6293741   |
| training/sac_pi/policy_loss    | -222.13461  |
| training/sac_pi/std            | 0.5043198   |
| training/sac_pi/valid_num      | 4969.0      |
| training/sac_Q/q1              | 210.9384    |
| training/sac_Q/q2              | 211.68265   |
| training/sac_Q/q2_loss         | 102.4847    |
| training/sac_Q/q_global_norm   | 261.84155   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16449712 |
| epoch                          | 425        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5053.615   |
| evaluation/return-max          | 5106.4883  |
| evaluation/return-min          | 4995.5093  |
| evaluation/return-std          | 31.65481   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46457      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5053.615   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 213.6918   |
| Q-std                          | 105.11378  |
| Q_loss                         | 105.282364 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 425        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000379   |
| times/epoch_rollout_model      | 501        |
| times/evaluation_metrics       | 0.000681   |
| times/evaluation_paths         | 46         |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 69.8       |
| timestep                       | 1000       |
| timesteps_total                | 426000     |
| train-steps                    | 426000     |
| training/Q/q1_loss             | 92.889496  |
| training/sac_pi/alpha          | 0.16452824 |
| training/sac_pi/alpha_loss     | -0.4026273 |
| training/sac_pi/logp_pi        | 4.235751   |
| training/sac_pi/pi_entropy     | 3.6313012  |
| training/sac_pi/pi_global_norm | 1.7611876  |
| training/sac_pi/policy_loss    | -215.63882 |
| training/sac_pi/std            | 0.5251905  |
| training/sac_pi/valid_num      | 4971.0     |
| training/sac_Q/q1              | 206.59018  |
| training/sac_Q/q2              | 207.5658   |
| training/sac_Q/q2_loss         | 91.830246  |
| training/sac_Q/q_global_norm   | 247.19644  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1674077   |
| epoch                          | 426         |
| evaluation/episode-length-avg  | 962         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 622         |
| evaluation/episode-length-std  | 113         |
| evaluation/return-average      | 4837.0576   |
| evaluation/return-max          | 5204.994    |
| evaluation/return-min          | 2885.8457   |
| evaluation/return-std          | 670.7518    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46378       |
| perf/AverageLength             | 962         |
| perf/AverageReturn             | 4837.0576   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 211.85776   |
| Q-std                          | 113.172554  |
| Q_loss                         | 86.17937    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 426         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000141    |
| times/epoch_rollout_model      | 544         |
| times/evaluation_metrics       | 0.000649    |
| times/evaluation_paths         | 43.7        |
| times/timestep_after_hook      | 0.00406     |
| times/timestep_before_hook     | 0.00864     |
| times/train                    | 70.7        |
| timestep                       | 1000        |
| timesteps_total                | 427000      |
| train-steps                    | 427000      |
| training/Q/q1_loss             | 102.11575   |
| training/sac_pi/alpha          | 0.16742732  |
| training/sac_pi/alpha_loss     | -0.24459845 |
| training/sac_pi/logp_pi        | 3.7696052   |
| training/sac_pi/pi_entropy     | 3.4976628   |
| training/sac_pi/pi_global_norm | 1.7917048   |
| training/sac_pi/policy_loss    | -222.96596  |
| training/sac_pi/std            | 0.48841184  |
| training/sac_pi/valid_num      | 5001.0      |
| training/sac_Q/q1              | 217.40897   |
| training/sac_Q/q2              | 217.59216   |
| training/sac_Q/q2_loss         | 102.78524   |
| training/sac_Q/q_global_norm   | 207.4325    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16734181 |
| epoch                          | 427        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4927.276   |
| evaluation/return-max          | 4999.418   |
| evaluation/return-min          | 4845.498   |
| evaluation/return-std          | 51.28825   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46503      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4927.276   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 211.87553  |
| Q-std                          | 97.21725   |
| Q_loss                         | 91.858345  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 427        |
| times/epoch_after_hook         | 3.18e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000699   |
| times/evaluation_paths         | 44.5       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 69.3       |
| timestep                       | 1000       |
| timesteps_total                | 428000     |
| train-steps                    | 428000     |
| training/Q/q1_loss             | 92.573524  |
| training/sac_pi/alpha          | 0.16732816 |
| training/sac_pi/alpha_loss     | -0.2900076 |
| training/sac_pi/logp_pi        | 3.9450638  |
| training/sac_pi/pi_entropy     | 3.5839164  |
| training/sac_pi/pi_global_norm | 2.20376    |
| training/sac_pi/policy_loss    | -220.9598  |
| training/sac_pi/std            | 0.4984602  |
| training/sac_pi/valid_num      | 4927.0     |
| training/sac_Q/q1              | 209.79465  |
| training/sac_Q/q2              | 210.0004   |
| training/sac_Q/q2_loss         | 92.07137   |
| training/sac_Q/q_global_norm   | 334.34955  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16585152 |
| epoch                          | 428        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4903.16    |
| evaluation/return-max          | 4952.2056  |
| evaluation/return-min          | 4857.3745  |
| evaluation/return-std          | 30.329983  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46372      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4903.16    |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 218.8027   |
| Q-std                          | 107.33956  |
| Q_loss                         | 93.739944  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 428        |
| times/epoch_after_hook         | 3.22e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000672   |
| times/evaluation_paths         | 42.7       |
| times/timestep_after_hook      | 0.00422    |
| times/timestep_before_hook     | 0.00896    |
| times/train                    | 70.4       |
| timestep                       | 1000       |
| timesteps_total                | 429000     |
| train-steps                    | 429000     |
| training/Q/q1_loss             | 89.34773   |
| training/sac_pi/alpha          | 0.16582018 |
| training/sac_pi/alpha_loss     | 0.29990372 |
| training/sac_pi/logp_pi        | 4.4767466  |
| training/sac_pi/pi_entropy     | 3.6387138  |
| training/sac_pi/pi_global_norm | 1.8744395  |
| training/sac_pi/policy_loss    | -221.08449 |
| training/sac_pi/std            | 0.5192883  |
| training/sac_pi/valid_num      | 4921.0     |
| training/sac_Q/q1              | 209.26799  |
| training/sac_Q/q2              | 212.15707  |
| training/sac_Q/q2_loss         | 89.83559   |
| training/sac_Q/q_global_norm   | 239.09248  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16110958   |
| epoch                          | 429          |
| evaluation/episode-length-avg  | 155          |
| evaluation/episode-length-max  | 158          |
| evaluation/episode-length-min  | 152          |
| evaluation/episode-length-std  | 1.79         |
| evaluation/return-average      | 490.37396    |
| evaluation/return-max          | 502.41617    |
| evaluation/return-min          | 479.62234    |
| evaluation/return-std          | 6.948998     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.13         |
| model/origin_ret               | 86.5         |
| model/penalty_ret              | 79.7         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46487        |
| perf/AverageLength             | 155          |
| perf/AverageReturn             | 490.37396    |
| perf/NormalizedReturn          | 0.106        |
| Q-avg                          | 227.03299    |
| Q-std                          | 92.08591     |
| Q_loss                         | 75.509544    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 429          |
| times/epoch_after_hook         | 1.8e-06      |
| times/epoch_before_hook        | 0.000343     |
| times/epoch_rollout_model      | 538          |
| times/evaluation_metrics       | 0.000777     |
| times/evaluation_paths         | 5.27         |
| times/timestep_after_hook      | 0.00401      |
| times/timestep_before_hook     | 0.00863      |
| times/train                    | 66.4         |
| timestep                       | 1000         |
| timesteps_total                | 430000       |
| train-steps                    | 430000       |
| training/Q/q1_loss             | 92.157524    |
| training/sac_pi/alpha          | 0.16107193   |
| training/sac_pi/alpha_loss     | -0.043592244 |
| training/sac_pi/logp_pi        | 4.826782     |
| training/sac_pi/pi_entropy     | 3.503976     |
| training/sac_pi/pi_global_norm | 2.0682733    |
| training/sac_pi/policy_loss    | -227.61409   |
| training/sac_pi/std            | 0.5376594    |
| training/sac_pi/valid_num      | 4941.0       |
| training/sac_Q/q1              | 215.42734    |
| training/sac_Q/q2              | 218.11475    |
| training/sac_Q/q2_loss         | 92.19981     |
| training/sac_Q/q_global_norm   | 230.06552    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16530553 |
| epoch                          | 430        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5221.043   |
| evaluation/return-max          | 5243.9697  |
| evaluation/return-min          | 5196.758   |
| evaluation/return-std          | 14.190311  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 80.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46467      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5221.043   |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 222.1272   |
| Q-std                          | 104.88273  |
| Q_loss                         | 99.66663   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 430        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000143   |
| times/epoch_rollout_model      | 545        |
| times/evaluation_metrics       | 0.000869   |
| times/evaluation_paths         | 37.5       |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.00874    |
| times/train                    | 64.7       |
| timestep                       | 1000       |
| timesteps_total                | 431000     |
| train-steps                    | 431000     |
| training/Q/q1_loss             | 104.99938  |
| training/sac_pi/alpha          | 0.16529015 |
| training/sac_pi/alpha_loss     | 0.16971894 |
| training/sac_pi/logp_pi        | 3.9637406  |
| training/sac_pi/pi_entropy     | 3.5006847  |
| training/sac_pi/pi_global_norm | 2.274318   |
| training/sac_pi/policy_loss    | -227.23871 |
| training/sac_pi/std            | 0.48758313 |
| training/sac_pi/valid_num      | 5034.0     |
| training/sac_Q/q1              | 222.36853  |
| training/sac_Q/q2              | 223.25432  |
| training/sac_Q/q2_loss         | 103.75211  |
| training/sac_Q/q_global_norm   | 379.23175  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16244332   |
| epoch                          | 431          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5073.9507    |
| evaluation/return-max          | 5139.9478    |
| evaluation/return-min          | 5007.514     |
| evaluation/return-std          | 38.909355    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.13         |
| model/origin_ret               | 86.3         |
| model/penalty_ret              | 79.9         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46336        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5073.9507    |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 218.56792    |
| Q-std                          | 106.82715    |
| Q_loss                         | 106.11459    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 431          |
| times/epoch_after_hook         | 1.83e-06     |
| times/epoch_before_hook        | 0.000297     |
| times/epoch_rollout_model      | 528          |
| times/evaluation_metrics       | 0.000737     |
| times/evaluation_paths         | 38.5         |
| times/timestep_after_hook      | 0.00409      |
| times/timestep_before_hook     | 0.00894      |
| times/train                    | 64.8         |
| timestep                       | 1000         |
| timesteps_total                | 432000       |
| train-steps                    | 432000       |
| training/Q/q1_loss             | 85.59835     |
| training/sac_pi/alpha          | 0.16241784   |
| training/sac_pi/alpha_loss     | -0.019189246 |
| training/sac_pi/logp_pi        | 4.0280924    |
| training/sac_pi/pi_entropy     | 3.4538987    |
| training/sac_pi/pi_global_norm | 1.621193     |
| training/sac_pi/policy_loss    | -229.22661   |
| training/sac_pi/std            | 0.49409276   |
| training/sac_pi/valid_num      | 4986.0       |
| training/sac_Q/q1              | 222.13477    |
| training/sac_Q/q2              | 222.97725    |
| training/sac_Q/q2_loss         | 84.98159     |
| training/sac_Q/q_global_norm   | 260.70773    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16260795 |
| epoch                          | 432        |
| evaluation/episode-length-avg  | 161        |
| evaluation/episode-length-max  | 163        |
| evaluation/episode-length-min  | 160        |
| evaluation/episode-length-std  | 0.98       |
| evaluation/return-average      | 489.54535  |
| evaluation/return-max          | 496.71542  |
| evaluation/return-min          | 482.6916   |
| evaluation/return-std          | 4.410082   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46336      |
| perf/AverageLength             | 161        |
| perf/AverageReturn             | 489.54535  |
| perf/NormalizedReturn          | 0.106      |
| Q-avg                          | 207.84119  |
| Q-std                          | 124.503586 |
| Q_loss                         | 85.67535   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 432        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000151   |
| times/epoch_rollout_model      | 522        |
| times/evaluation_metrics       | 0.000623   |
| times/evaluation_paths         | 7.13       |
| times/timestep_after_hook      | 0.00347    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 433000     |
| train-steps                    | 433000     |
| training/Q/q1_loss             | 95.49858   |
| training/sac_pi/alpha          | 0.16264066 |
| training/sac_pi/alpha_loss     | 0.1912841  |
| training/sac_pi/logp_pi        | 3.5012684  |
| training/sac_pi/pi_entropy     | 3.3642044  |
| training/sac_pi/pi_global_norm | 1.8762081  |
| training/sac_pi/policy_loss    | -228.9373  |
| training/sac_pi/std            | 0.4506047  |
| training/sac_pi/valid_num      | 5062.0     |
| training/sac_Q/q1              | 226.70976  |
| training/sac_Q/q2              | 227.0507   |
| training/sac_Q/q2_loss         | 93.97571   |
| training/sac_Q/q_global_norm   | 226.91153  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16365805   |
| epoch                          | 433          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5007.8643    |
| evaluation/return-max          | 5052.1104    |
| evaluation/return-min          | 4962.578     |
| evaluation/return-std          | 31.811611    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.01         |
| model/origin_ret               | 84.1         |
| model/penalty_ret              | 79.7         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46423        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5007.8643    |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 202.83908    |
| Q-std                          | 141.21559    |
| Q_loss                         | 101.897224   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 433          |
| times/epoch_after_hook         | 1.75e-06     |
| times/epoch_before_hook        | 0.000292     |
| times/epoch_rollout_model      | 486          |
| times/evaluation_metrics       | 0.000627     |
| times/evaluation_paths         | 36.7         |
| times/timestep_after_hook      | 0.00359      |
| times/timestep_before_hook     | 0.00813      |
| times/train                    | 62           |
| timestep                       | 1000         |
| timesteps_total                | 434000       |
| train-steps                    | 434000       |
| training/Q/q1_loss             | 105.558784   |
| training/sac_pi/alpha          | 0.16369216   |
| training/sac_pi/alpha_loss     | -0.104434945 |
| training/sac_pi/logp_pi        | 4.696374     |
| training/sac_pi/pi_entropy     | 3.5189233    |
| training/sac_pi/pi_global_norm | 1.7786161    |
| training/sac_pi/policy_loss    | -214.41058   |
| training/sac_pi/std            | 0.527878     |
| training/sac_pi/valid_num      | 4943.0       |
| training/sac_Q/q1              | 202.3487     |
| training/sac_Q/q2              | 204.2898     |
| training/sac_Q/q2_loss         | 105.312294   |
| training/sac_Q/q_global_norm   | 214.32727    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1667431   |
| epoch                          | 434         |
| evaluation/episode-length-avg  | 400         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 133         |
| evaluation/episode-length-std  | 393         |
| evaluation/return-average      | 1801.8718   |
| evaluation/return-max          | 5173.3086   |
| evaluation/return-min          | 352.39944   |
| evaluation/return-std          | 2156.7114   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46373       |
| perf/AverageLength             | 400         |
| perf/AverageReturn             | 1801.8718   |
| perf/NormalizedReturn          | 0.392       |
| Q-avg                          | 210.5029    |
| Q-std                          | 130.60954   |
| Q_loss                         | 75.28379    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 434         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000134    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.00071     |
| times/evaluation_paths         | 13.6        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 63.6        |
| timestep                       | 1000        |
| timesteps_total                | 435000      |
| train-steps                    | 435000      |
| training/Q/q1_loss             | 80.23507    |
| training/sac_pi/alpha          | 0.16676295  |
| training/sac_pi/alpha_loss     | -0.31720516 |
| training/sac_pi/logp_pi        | 4.4414697   |
| training/sac_pi/pi_entropy     | 3.5017333   |
| training/sac_pi/pi_global_norm | 1.6252673   |
| training/sac_pi/policy_loss    | -221.83731  |
| training/sac_pi/std            | 0.500387    |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 209.51425   |
| training/sac_Q/q2              | 213.47763   |
| training/sac_Q/q2_loss         | 80.77733    |
| training/sac_Q/q_global_norm   | 270.11234   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16430221  |
| epoch                          | 435         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4980.1387   |
| evaluation/return-max          | 5007.1895   |
| evaluation/return-min          | 4952.2686   |
| evaluation/return-std          | 18.847357   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46415       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4980.1387   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 218.51318   |
| Q-std                          | 103.03627   |
| Q_loss                         | 107.48168   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 435         |
| times/epoch_after_hook         | 1.53e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 526         |
| times/evaluation_metrics       | 0.000543    |
| times/evaluation_paths         | 35.8        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 64.4        |
| timestep                       | 1000        |
| timesteps_total                | 436000      |
| train-steps                    | 436000      |
| training/Q/q1_loss             | 86.81208    |
| training/sac_pi/alpha          | 0.16431016  |
| training/sac_pi/alpha_loss     | -0.16973995 |
| training/sac_pi/logp_pi        | 3.6328208   |
| training/sac_pi/pi_entropy     | 3.3631997   |
| training/sac_pi/pi_global_norm | 1.4674798   |
| training/sac_pi/policy_loss    | -226.13158  |
| training/sac_pi/std            | 0.47178617  |
| training/sac_pi/valid_num      | 5032.0      |
| training/sac_Q/q1              | 218.69121   |
| training/sac_Q/q2              | 219.77185   |
| training/sac_Q/q2_loss         | 87.44943    |
| training/sac_Q/q_global_norm   | 377.11694   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.168757   |
| epoch                          | 436        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4891.9907  |
| evaluation/return-max          | 4922.8223  |
| evaluation/return-min          | 4876.3447  |
| evaluation/return-std          | 14.05531   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46380      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4891.9907  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 208.31302  |
| Q-std                          | 135.49968  |
| Q_loss                         | 78.68399   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 436        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000148   |
| times/epoch_rollout_model      | 517        |
| times/evaluation_metrics       | 0.000614   |
| times/evaluation_paths         | 37.4       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 437000     |
| train-steps                    | 437000     |
| training/Q/q1_loss             | 93.496445  |
| training/sac_pi/alpha          | 0.16874793 |
| training/sac_pi/alpha_loss     | 0.3875413  |
| training/sac_pi/logp_pi        | 4.784973   |
| training/sac_pi/pi_entropy     | 3.2766998  |
| training/sac_pi/pi_global_norm | 1.9821424  |
| training/sac_pi/policy_loss    | -221.84135 |
| training/sac_pi/std            | 0.4903692  |
| training/sac_pi/valid_num      | 4942.0     |
| training/sac_Q/q1              | 207.9957   |
| training/sac_Q/q2              | 209.56064  |
| training/sac_Q/q2_loss         | 93.834114  |
| training/sac_Q/q_global_norm   | 263.76624  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16304272  |
| epoch                          | 437         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4997.2427   |
| evaluation/return-max          | 5073.4956   |
| evaluation/return-min          | 4876.341    |
| evaluation/return-std          | 49.87983    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46331       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4997.2427   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 205.91284   |
| Q-std                          | 136.59816   |
| Q_loss                         | 105.38618   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 437         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000326    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000593    |
| times/evaluation_paths         | 36.7        |
| times/timestep_after_hook      | 0.00354     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 438000      |
| train-steps                    | 438000      |
| training/Q/q1_loss             | 103.364975  |
| training/sac_pi/alpha          | 0.16304925  |
| training/sac_pi/alpha_loss     | -0.03864737 |
| training/sac_pi/logp_pi        | 4.606434    |
| training/sac_pi/pi_entropy     | 3.4819229   |
| training/sac_pi/pi_global_norm | 1.9991856   |
| training/sac_pi/policy_loss    | -221.3131   |
| training/sac_pi/std            | 0.51890546  |
| training/sac_pi/valid_num      | 4877.0      |
| training/sac_Q/q1              | 204.33858   |
| training/sac_Q/q2              | 206.66386   |
| training/sac_Q/q2_loss         | 103.504715  |
| training/sac_Q/q_global_norm   | 306.44098   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1663324   |
| epoch                          | 438         |
| evaluation/episode-length-avg  | 132         |
| evaluation/episode-length-max  | 139         |
| evaluation/episode-length-min  | 130         |
| evaluation/episode-length-std  | 2.91        |
| evaluation/return-average      | 392.1264    |
| evaluation/return-max          | 415.10553   |
| evaluation/return-min          | 381.63208   |
| evaluation/return-std          | 10.415898   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46332       |
| perf/AverageLength             | 132         |
| perf/AverageReturn             | 392.1264    |
| perf/NormalizedReturn          | 0.0851      |
| Q-avg                          | 221.03885   |
| Q-std                          | 123.00954   |
| Q_loss                         | 121.32776   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 438         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000619    |
| times/evaluation_paths         | 6.04        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00834     |
| times/train                    | 61.9        |
| timestep                       | 1000        |
| timesteps_total                | 439000      |
| train-steps                    | 439000      |
| training/Q/q1_loss             | 92.99808    |
| training/sac_pi/alpha          | 0.1663165   |
| training/sac_pi/alpha_loss     | 0.020123051 |
| training/sac_pi/logp_pi        | 4.170903    |
| training/sac_pi/pi_entropy     | 3.290273    |
| training/sac_pi/pi_global_norm | 1.7798522   |
| training/sac_pi/policy_loss    | -218.49693  |
| training/sac_pi/std            | 0.47215378  |
| training/sac_pi/valid_num      | 4965.0      |
| training/sac_Q/q1              | 210.5149    |
| training/sac_Q/q2              | 211.83784   |
| training/sac_Q/q2_loss         | 94.13231    |
| training/sac_Q/q_global_norm   | 197.31331   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16195242   |
| epoch                          | 439          |
| evaluation/episode-length-avg  | 147          |
| evaluation/episode-length-max  | 152          |
| evaluation/episode-length-min  | 140          |
| evaluation/episode-length-std  | 3.94         |
| evaluation/return-average      | 448.91992    |
| evaluation/return-max          | 467.5445     |
| evaluation/return-min          | 423.3548     |
| evaluation/return-std          | 14.298569    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.07         |
| model/origin_ret               | 84.8         |
| model/penalty_ret              | 80.2         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46397        |
| perf/AverageLength             | 147          |
| perf/AverageReturn             | 448.91992    |
| perf/NormalizedReturn          | 0.0974       |
| Q-avg                          | 213.53015    |
| Q-std                          | 121.84219    |
| Q_loss                         | 97.79886     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 439          |
| times/epoch_after_hook         | 1.66e-06     |
| times/epoch_before_hook        | 0.000146     |
| times/epoch_rollout_model      | 486          |
| times/evaluation_metrics       | 0.000598     |
| times/evaluation_paths         | 6.82         |
| times/timestep_after_hook      | 0.0036       |
| times/timestep_before_hook     | 0.00835      |
| times/train                    | 62.1         |
| timestep                       | 1000         |
| timesteps_total                | 440000       |
| train-steps                    | 440000       |
| training/Q/q1_loss             | 115.218185   |
| training/sac_pi/alpha          | 0.16194133   |
| training/sac_pi/alpha_loss     | -0.020182168 |
| training/sac_pi/logp_pi        | 4.8803554    |
| training/sac_pi/pi_entropy     | 3.2108853    |
| training/sac_pi/pi_global_norm | 2.2480683    |
| training/sac_pi/policy_loss    | -231.6164    |
| training/sac_pi/std            | 0.49206284   |
| training/sac_pi/valid_num      | 4892.0       |
| training/sac_Q/q1              | 215.77036    |
| training/sac_Q/q2              | 216.41232    |
| training/sac_Q/q2_loss         | 114.40543    |
| training/sac_Q/q_global_norm   | 227.69534    |
----------------------------------------------------------------------------------
[WARN] 440 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16247322 |
| epoch                          | 440        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4950.279   |
| evaluation/return-max          | 4999.3276  |
| evaluation/return-min          | 4880.9224  |
| evaluation/return-std          | 31.948095  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46417      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4950.279   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 221.27515  |
| Q-std                          | 103.13791  |
| Q_loss                         | 81.043     |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 440        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000187   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000674   |
| times/evaluation_paths         | 35.5       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 63.8       |
| timestep                       | 1000       |
| timesteps_total                | 441000     |
| train-steps                    | 441000     |
| training/Q/q1_loss             | 117.295525 |
| training/sac_pi/alpha          | 0.16249631 |
| training/sac_pi/alpha_loss     | 0.12141056 |
| training/sac_pi/logp_pi        | 3.824852   |
| training/sac_pi/pi_entropy     | 3.3659267  |
| training/sac_pi/pi_global_norm | 1.5632668  |
| training/sac_pi/policy_loss    | -222.59949 |
| training/sac_pi/std            | 0.46441644 |
| training/sac_pi/valid_num      | 5023.0     |
| training/sac_Q/q1              | 218.12068  |
| training/sac_Q/q2              | 219.41519  |
| training/sac_Q/q2_loss         | 116.482704 |
| training/sac_Q/q_global_norm   | 302.32974  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16467836 |
| epoch                          | 441        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5039.1104  |
| evaluation/return-max          | 5164.4688  |
| evaluation/return-min          | 4901.9688  |
| evaluation/return-std          | 87.059944  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46386      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5039.1104  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 212.3508   |
| Q-std                          | 107.83126  |
| Q_loss                         | 104.83276  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 441        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000485   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000661   |
| times/evaluation_paths         | 36.8       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 63         |
| timestep                       | 1000       |
| timesteps_total                | 442000     |
| train-steps                    | 442000     |
| training/Q/q1_loss             | 73.46443   |
| training/sac_pi/alpha          | 0.16461945 |
| training/sac_pi/alpha_loss     | 0.45608193 |
| training/sac_pi/logp_pi        | 4.2400537  |
| training/sac_pi/pi_entropy     | 3.582653   |
| training/sac_pi/pi_global_norm | 1.5501487  |
| training/sac_pi/policy_loss    | -224.96545 |
| training/sac_pi/std            | 0.4992494  |
| training/sac_pi/valid_num      | 5001.0     |
| training/sac_Q/q1              | 217.34204  |
| training/sac_Q/q2              | 217.69699  |
| training/sac_Q/q2_loss         | 73.8175    |
| training/sac_Q/q_global_norm   | 201.36969  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1638978   |
| epoch                          | 442         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5004.334    |
| evaluation/return-max          | 5094.7173   |
| evaluation/return-min          | 4924.6357   |
| evaluation/return-std          | 41.275665   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46302       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5004.334    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 223.99284   |
| Q-std                          | 83.68369    |
| Q_loss                         | 97.344765   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 442         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000146    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000632    |
| times/evaluation_paths         | 37.6        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 69.6        |
| timestep                       | 1000        |
| timesteps_total                | 443000      |
| train-steps                    | 443000      |
| training/Q/q1_loss             | 107.67083   |
| training/sac_pi/alpha          | 0.16394128  |
| training/sac_pi/alpha_loss     | -0.25719282 |
| training/sac_pi/logp_pi        | 4.5528035   |
| training/sac_pi/pi_entropy     | 3.442739    |
| training/sac_pi/pi_global_norm | 2.3329117   |
| training/sac_pi/policy_loss    | -227.226    |
| training/sac_pi/std            | 0.50377905  |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 213.05008   |
| training/sac_Q/q2              | 214.63058   |
| training/sac_Q/q2_loss         | 108.00797   |
| training/sac_Q/q_global_norm   | 215.06561   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16584769 |
| epoch                          | 443        |
| evaluation/episode-length-avg  | 927        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 533        |
| evaluation/episode-length-std  | 146        |
| evaluation/return-average      | 4875.4736  |
| evaluation/return-max          | 5372.79    |
| evaluation/return-min          | 2526.7654  |
| evaluation/return-std          | 865.1799   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46344      |
| perf/AverageLength             | 927        |
| perf/AverageReturn             | 4875.4736  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 214.94116  |
| Q-std                          | 137.50868  |
| Q_loss                         | 93.77185   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 443        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000544   |
| times/evaluation_paths         | 34.7       |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 71.2       |
| timestep                       | 1000       |
| timesteps_total                | 444000     |
| train-steps                    | 444000     |
| training/Q/q1_loss             | 86.99523   |
| training/sac_pi/alpha          | 0.16585745 |
| training/sac_pi/alpha_loss     | 0.20545852 |
| training/sac_pi/logp_pi        | 4.5275645  |
| training/sac_pi/pi_entropy     | 3.57931    |
| training/sac_pi/pi_global_norm | 1.6697836  |
| training/sac_pi/policy_loss    | -223.71486 |
| training/sac_pi/std            | 0.5172994  |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 214.30151  |
| training/sac_Q/q2              | 214.80501  |
| training/sac_Q/q2_loss         | 86.737785  |
| training/sac_Q/q_global_norm   | 303.0275   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16497053 |
| epoch                          | 444        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4971.841   |
| evaluation/return-max          | 5007.1143  |
| evaluation/return-min          | 4944.552   |
| evaluation/return-std          | 17.814949  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46189      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4971.841   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 210.90852  |
| Q-std                          | 135.54207  |
| Q_loss                         | 78.4193    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 444        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000157   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000581   |
| times/evaluation_paths         | 38.3       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 72.7       |
| timestep                       | 1000       |
| timesteps_total                | 445000     |
| train-steps                    | 445000     |
| training/Q/q1_loss             | 105.08828  |
| training/sac_pi/alpha          | 0.16491584 |
| training/sac_pi/alpha_loss     | 0.32136935 |
| training/sac_pi/logp_pi        | 4.309542   |
| training/sac_pi/pi_entropy     | 3.621698   |
| training/sac_pi/pi_global_norm | 1.6865252  |
| training/sac_pi/policy_loss    | -223.25507 |
| training/sac_pi/std            | 0.50736225 |
| training/sac_pi/valid_num      | 4963.0     |
| training/sac_Q/q1              | 214.60645  |
| training/sac_Q/q2              | 213.82486  |
| training/sac_Q/q2_loss         | 104.7197   |
| training/sac_Q/q_global_norm   | 410.98483  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16385895 |
| epoch                          | 445        |
| evaluation/episode-length-avg  | 915        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 151        |
| evaluation/episode-length-std  | 255        |
| evaluation/return-average      | 4327.4937  |
| evaluation/return-max          | 4790.259   |
| evaluation/return-min          | 414.15024  |
| evaluation/return-std          | 1304.5702  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46323      |
| perf/AverageLength             | 915        |
| perf/AverageReturn             | 4327.4937  |
| perf/NormalizedReturn          | 0.942      |
| Q-avg                          | 210.6379   |
| Q-std                          | 132.06348  |
| Q_loss                         | 81.90451   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 445        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000283   |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000462   |
| times/evaluation_paths         | 32.6       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 446000     |
| train-steps                    | 446000     |
| training/Q/q1_loss             | 96.56605   |
| training/sac_pi/alpha          | 0.1638527  |
| training/sac_pi/alpha_loss     | 0.14197177 |
| training/sac_pi/logp_pi        | 3.8888435  |
| training/sac_pi/pi_entropy     | 3.5078368  |
| training/sac_pi/pi_global_norm | 1.5855615  |
| training/sac_pi/policy_loss    | -222.48244 |
| training/sac_pi/std            | 0.49310243 |
| training/sac_pi/valid_num      | 5026.0     |
| training/sac_Q/q1              | 216.73306  |
| training/sac_Q/q2              | 217.59795  |
| training/sac_Q/q2_loss         | 96.048355  |
| training/sac_Q/q_global_norm   | 316.75336  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1645244  |
| epoch                          | 446        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4983.2935  |
| evaluation/return-max          | 5013.1143  |
| evaluation/return-min          | 4953.1465  |
| evaluation/return-std          | 21.344221  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46421      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4983.2935  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 221.61516  |
| Q-std                          | 91.47236   |
| Q_loss                         | 82.395424  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 446        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000573   |
| times/evaluation_paths         | 46.2       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 63.8       |
| timestep                       | 1000       |
| timesteps_total                | 447000     |
| train-steps                    | 447000     |
| training/Q/q1_loss             | 135.56487  |
| training/sac_pi/alpha          | 0.16451153 |
| training/sac_pi/alpha_loss     | 0.30637988 |
| training/sac_pi/logp_pi        | 4.400749   |
| training/sac_pi/pi_entropy     | 3.5825162  |
| training/sac_pi/pi_global_norm | 1.9398018  |
| training/sac_pi/policy_loss    | -220.32463 |
| training/sac_pi/std            | 0.50193393 |
| training/sac_pi/valid_num      | 4974.0     |
| training/sac_Q/q1              | 210.86157  |
| training/sac_Q/q2              | 211.35257  |
| training/sac_Q/q2_loss         | 135.71967  |
| training/sac_Q/q_global_norm   | 267.63843  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16135783  |
| epoch                          | 447         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5145.216    |
| evaluation/return-max          | 5210.0156   |
| evaluation/return-min          | 5046.2725   |
| evaluation/return-std          | 47.83807    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46392       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5145.216    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 218.68652   |
| Q-std                          | 119.73405   |
| Q_loss                         | 83.00087    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 447         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000136    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000575    |
| times/evaluation_paths         | 45.1        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00841     |
| times/train                    | 62.9        |
| timestep                       | 1000        |
| timesteps_total                | 448000      |
| train-steps                    | 448000      |
| training/Q/q1_loss             | 83.90468    |
| training/sac_pi/alpha          | 0.16137601  |
| training/sac_pi/alpha_loss     | -0.44855425 |
| training/sac_pi/logp_pi        | 4.2697      |
| training/sac_pi/pi_entropy     | 3.3538613   |
| training/sac_pi/pi_global_norm | 2.0743725   |
| training/sac_pi/policy_loss    | -227.23697  |
| training/sac_pi/std            | 0.4805936   |
| training/sac_pi/valid_num      | 4943.0      |
| training/sac_Q/q1              | 213.25504   |
| training/sac_Q/q2              | 216.94333   |
| training/sac_Q/q2_loss         | 83.150475   |
| training/sac_Q/q_global_norm   | 280.50064   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1640026  |
| epoch                          | 448        |
| evaluation/episode-length-avg  | 727        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 530        |
| evaluation/episode-length-std  | 159        |
| evaluation/return-average      | 3607.58    |
| evaluation/return-max          | 5202.338   |
| evaluation/return-min          | 2492.0234  |
| evaluation/return-std          | 905.1534   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46547      |
| perf/AverageLength             | 727        |
| perf/AverageReturn             | 3607.58    |
| perf/NormalizedReturn          | 0.785      |
| Q-avg                          | 212.52267  |
| Q-std                          | 105.589424 |
| Q_loss                         | 92.7375    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 448        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000326   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000484   |
| times/evaluation_paths         | 31.6       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00859    |
| times/train                    | 68.7       |
| timestep                       | 1000       |
| timesteps_total                | 449000     |
| train-steps                    | 449000     |
| training/Q/q1_loss             | 99.76846   |
| training/sac_pi/alpha          | 0.1639761  |
| training/sac_pi/alpha_loss     | 0.7335885  |
| training/sac_pi/logp_pi        | 4.1698346  |
| training/sac_pi/pi_entropy     | 3.4449127  |
| training/sac_pi/pi_global_norm | 1.8791187  |
| training/sac_pi/policy_loss    | -222.53241 |
| training/sac_pi/std            | 0.47872975 |
| training/sac_pi/valid_num      | 5007.0     |
| training/sac_Q/q1              | 215.68701  |
| training/sac_Q/q2              | 214.92871  |
| training/sac_Q/q2_loss         | 98.656296  |
| training/sac_Q/q_global_norm   | 304.37653  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16139698 |
| epoch                          | 449        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5027.866   |
| evaluation/return-max          | 5094.7974  |
| evaluation/return-min          | 4936.3057  |
| evaluation/return-std          | 41.54694   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46327      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5027.866   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 214.95573  |
| Q-std                          | 116.7078   |
| Q_loss                         | 105.54756  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 449        |
| times/epoch_after_hook         | 2.1e-06    |
| times/epoch_before_hook        | 0.000322   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000823   |
| times/evaluation_paths         | 34.7       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 68.7       |
| timestep                       | 1000       |
| timesteps_total                | 450000     |
| train-steps                    | 450000     |
| training/Q/q1_loss             | 125.52769  |
| training/sac_pi/alpha          | 0.16139854 |
| training/sac_pi/alpha_loss     | 0.24004251 |
| training/sac_pi/logp_pi        | 5.839789   |
| training/sac_pi/pi_entropy     | 3.4189994  |
| training/sac_pi/pi_global_norm | 2.2866018  |
| training/sac_pi/policy_loss    | -223.40086 |
| training/sac_pi/std            | 0.53877896 |
| training/sac_pi/valid_num      | 4901.0     |
| training/sac_Q/q1              | 202.47812  |
| training/sac_Q/q2              | 206.76042  |
| training/sac_Q/q2_loss         | 125.42058  |
| training/sac_Q/q_global_norm   | 228.08351  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.161685   |
| epoch                          | 450        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4954.907   |
| evaluation/return-max          | 5032.057   |
| evaluation/return-min          | 4817.916   |
| evaluation/return-std          | 58.016205  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46364      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4954.907   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 221.78171  |
| Q-std                          | 118.54923  |
| Q_loss                         | 99.33115   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 450        |
| times/epoch_after_hook         | 3.04e-06   |
| times/epoch_before_hook        | 0.000148   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.00062    |
| times/evaluation_paths         | 45.4       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 451000     |
| train-steps                    | 451000     |
| training/Q/q1_loss             | 90.92054   |
| training/sac_pi/alpha          | 0.16166733 |
| training/sac_pi/alpha_loss     | 0.19382292 |
| training/sac_pi/logp_pi        | 4.4917336  |
| training/sac_pi/pi_entropy     | 3.39733    |
| training/sac_pi/pi_global_norm | 1.7594935  |
| training/sac_pi/policy_loss    | -223.43678 |
| training/sac_pi/std            | 0.5015579  |
| training/sac_pi/valid_num      | 5008.0     |
| training/sac_Q/q1              | 215.123    |
| training/sac_Q/q2              | 216.0498   |
| training/sac_Q/q2_loss         | 91.13992   |
| training/sac_Q/q_global_norm   | 277.63907  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16175768 |
| epoch                          | 451        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5063.192   |
| evaluation/return-max          | 5092.995   |
| evaluation/return-min          | 5033.6074  |
| evaluation/return-std          | 19.18405   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46334      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5063.192   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 206.58357  |
| Q-std                          | 109.826485 |
| Q_loss                         | 96.629295  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 451        |
| times/epoch_after_hook         | 1.59e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000546   |
| times/evaluation_paths         | 41.2       |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 68.4       |
| timestep                       | 1000       |
| timesteps_total                | 452000     |
| train-steps                    | 452000     |
| training/Q/q1_loss             | 93.77935   |
| training/sac_pi/alpha          | 0.16174829 |
| training/sac_pi/alpha_loss     | 0.14503895 |
| training/sac_pi/logp_pi        | 4.3841405  |
| training/sac_pi/pi_entropy     | 3.2505894  |
| training/sac_pi/pi_global_norm | 1.755153   |
| training/sac_pi/policy_loss    | -225.20642 |
| training/sac_pi/std            | 0.484455   |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 212.9915   |
| training/sac_Q/q2              | 214.71623  |
| training/sac_Q/q2_loss         | 93.39106   |
| training/sac_Q/q_global_norm   | 319.46536  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16029842 |
| epoch                          | 452        |
| evaluation/episode-length-avg  | 364        |
| evaluation/episode-length-max  | 938        |
| evaluation/episode-length-min  | 155        |
| evaluation/episode-length-std  | 278        |
| evaluation/return-average      | 1613.448   |
| evaluation/return-max          | 4610.7153  |
| evaluation/return-min          | 508.59708  |
| evaluation/return-std          | 1477.7823  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46381      |
| perf/AverageLength             | 364        |
| perf/AverageReturn             | 1613.448   |
| perf/NormalizedReturn          | 0.351      |
| Q-avg                          | 222.48282  |
| Q-std                          | 96.0594    |
| Q_loss                         | 117.45569  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 452        |
| times/epoch_after_hook         | 2.02e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000538   |
| times/evaluation_paths         | 17         |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 67.9       |
| timestep                       | 1000       |
| timesteps_total                | 453000     |
| train-steps                    | 453000     |
| training/Q/q1_loss             | 115.354355 |
| training/sac_pi/alpha          | 0.1602983  |
| training/sac_pi/alpha_loss     | 0.18854155 |
| training/sac_pi/logp_pi        | 4.694886   |
| training/sac_pi/pi_entropy     | 3.41288    |
| training/sac_pi/pi_global_norm | 1.85589    |
| training/sac_pi/policy_loss    | -221.83899 |
| training/sac_pi/std            | 0.50892866 |
| training/sac_pi/valid_num      | 4916.0     |
| training/sac_Q/q1              | 210.33447  |
| training/sac_Q/q2              | 210.86557  |
| training/sac_Q/q2_loss         | 115.94775  |
| training/sac_Q/q_global_norm   | 262.74167  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16242541 |
| epoch                          | 453        |
| evaluation/episode-length-avg  | 830        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 147        |
| evaluation/episode-length-std  | 340        |
| evaluation/return-average      | 4176.8193  |
| evaluation/return-max          | 5148.7935  |
| evaluation/return-min          | 480.37958  |
| evaluation/return-std          | 1844.969   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.2        |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46570      |
| perf/AverageLength             | 830        |
| perf/AverageReturn             | 4176.8193  |
| perf/NormalizedReturn          | 0.909      |
| Q-avg                          | 211.45142  |
| Q-std                          | 150.70341  |
| Q_loss                         | 87.346214  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 453        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000281   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000549   |
| times/evaluation_paths         | 30.4       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 70.3       |
| timestep                       | 1000       |
| timesteps_total                | 454000     |
| train-steps                    | 454000     |
| training/Q/q1_loss             | 77.889435  |
| training/sac_pi/alpha          | 0.16244876 |
| training/sac_pi/alpha_loss     | -0.2711501 |
| training/sac_pi/logp_pi        | 3.4059021  |
| training/sac_pi/pi_entropy     | 3.1683288  |
| training/sac_pi/pi_global_norm | 2.128139   |
| training/sac_pi/policy_loss    | -226.6926  |
| training/sac_pi/std            | 0.44929045 |
| training/sac_pi/valid_num      | 5009.0     |
| training/sac_Q/q1              | 219.82724  |
| training/sac_Q/q2              | 221.19893  |
| training/sac_Q/q2_loss         | 77.43478   |
| training/sac_Q/q_global_norm   | 267.63055  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16817583 |
| epoch                          | 454        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4858.2627  |
| evaluation/return-max          | 4900.7324  |
| evaluation/return-min          | 4826.3447  |
| evaluation/return-std          | 24.456295  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46580      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4858.2627  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 206.24931  |
| Q-std                          | 111.647545 |
| Q_loss                         | 90.768074  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 454        |
| times/epoch_after_hook         | 1.63e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000606   |
| times/evaluation_paths         | 39.9       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 455000     |
| train-steps                    | 455000     |
| training/Q/q1_loss             | 89.330666  |
| training/sac_pi/alpha          | 0.16812193 |
| training/sac_pi/alpha_loss     | 0.21234305 |
| training/sac_pi/logp_pi        | 3.7993279  |
| training/sac_pi/pi_entropy     | 3.255465   |
| training/sac_pi/pi_global_norm | 1.8663921  |
| training/sac_pi/policy_loss    | -233.95953 |
| training/sac_pi/std            | 0.45716208 |
| training/sac_pi/valid_num      | 5019.0     |
| training/sac_Q/q1              | 228.84854  |
| training/sac_Q/q2              | 228.0666   |
| training/sac_Q/q2_loss         | 88.13751   |
| training/sac_Q/q_global_norm   | 287.451    |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16116883 |
| epoch                          | 455        |
| evaluation/episode-length-avg  | 233        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 141        |
| evaluation/episode-length-std  | 256        |
| evaluation/return-average      | 919.6647   |
| evaluation/return-max          | 4912.4004  |
| evaluation/return-min          | 455.5664   |
| evaluation/return-std          | 1330.9832  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 87         |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46334      |
| perf/AverageLength             | 233        |
| perf/AverageReturn             | 919.6647   |
| perf/NormalizedReturn          | 0.2        |
| Q-avg                          | 212.97139  |
| Q-std                          | 111.54951  |
| Q_loss                         | 103.94699  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 455        |
| times/epoch_after_hook         | 2.13e-06   |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000698   |
| times/evaluation_paths         | 8.16       |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 62.7       |
| timestep                       | 1000       |
| timesteps_total                | 456000     |
| train-steps                    | 456000     |
| training/Q/q1_loss             | 96.72826   |
| training/sac_pi/alpha          | 0.16113387 |
| training/sac_pi/alpha_loss     | 0.4679477  |
| training/sac_pi/logp_pi        | 4.060931   |
| training/sac_pi/pi_entropy     | 3.3223214  |
| training/sac_pi/pi_global_norm | 3.1918764  |
| training/sac_pi/policy_loss    | -225.54726 |
| training/sac_pi/std            | 0.4693301  |
| training/sac_pi/valid_num      | 4967.0     |
| training/sac_Q/q1              | 218.04312  |
| training/sac_Q/q2              | 218.60039  |
| training/sac_Q/q2_loss         | 96.21039   |
| training/sac_Q/q_global_norm   | 259.06683  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16079327  |
| epoch                          | 456         |
| evaluation/episode-length-avg  | 155         |
| evaluation/episode-length-max  | 160         |
| evaluation/episode-length-min  | 151         |
| evaluation/episode-length-std  | 2.36        |
| evaluation/return-average      | 503.94742   |
| evaluation/return-max          | 518.56384   |
| evaluation/return-min          | 491.4456    |
| evaluation/return-std          | 7.594824    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 78.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46376       |
| perf/AverageLength             | 155         |
| perf/AverageReturn             | 503.94742   |
| perf/NormalizedReturn          | 0.109       |
| Q-avg                          | 222.4692    |
| Q-std                          | 103.84788   |
| Q_loss                         | 92.59831    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 456         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 498         |
| times/evaluation_metrics       | 0.000433    |
| times/evaluation_paths         | 5.18        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 61.9        |
| timestep                       | 1000        |
| timesteps_total                | 457000      |
| train-steps                    | 457000      |
| training/Q/q1_loss             | 96.656906   |
| training/sac_pi/alpha          | 0.16081819  |
| training/sac_pi/alpha_loss     | -0.30558348 |
| training/sac_pi/logp_pi        | 4.1885214   |
| training/sac_pi/pi_entropy     | 3.1893399   |
| training/sac_pi/pi_global_norm | 1.7397964   |
| training/sac_pi/policy_loss    | -226.79498  |
| training/sac_pi/std            | 0.47381786  |
| training/sac_pi/valid_num      | 4966.0      |
| training/sac_Q/q1              | 216.1163    |
| training/sac_Q/q2              | 216.70334   |
| training/sac_Q/q2_loss         | 97.825874   |
| training/sac_Q/q_global_norm   | 277.7104    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16558492  |
| epoch                          | 457         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4748.13     |
| evaluation/return-max          | 4878.0264   |
| evaluation/return-min          | 4627.543    |
| evaluation/return-std          | 84.05207    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 83.7        |
| model/penalty_ret              | 78.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46426       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4748.13     |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 214.34541   |
| Q-std                          | 105.1784    |
| Q_loss                         | 91.46535    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 457         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000341    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000645    |
| times/evaluation_paths         | 42.9        |
| times/timestep_after_hook      | 0.00373     |
| times/timestep_before_hook     | 0.00834     |
| times/train                    | 67          |
| timestep                       | 1000        |
| timesteps_total                | 458000      |
| train-steps                    | 458000      |
| training/Q/q1_loss             | 106.84689   |
| training/sac_pi/alpha          | 0.16563495  |
| training/sac_pi/alpha_loss     | -0.12241402 |
| training/sac_pi/logp_pi        | 4.2589927   |
| training/sac_pi/pi_entropy     | 3.651982    |
| training/sac_pi/pi_global_norm | 1.6115034   |
| training/sac_pi/policy_loss    | -221.08188  |
| training/sac_pi/std            | 0.5162968   |
| training/sac_pi/valid_num      | 4928.0      |
| training/sac_Q/q1              | 207.93648   |
| training/sac_Q/q2              | 211.3876    |
| training/sac_Q/q2_loss         | 106.815865  |
| training/sac_Q/q_global_norm   | 321.7107    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16431245  |
| epoch                          | 458         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4930.63     |
| evaluation/return-max          | 5150.858    |
| evaluation/return-min          | 4735.6045   |
| evaluation/return-std          | 130.45027   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46260       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4930.63     |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 223.92453   |
| Q-std                          | 125.75394   |
| Q_loss                         | 81.60595    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 458         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000117    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000668    |
| times/evaluation_paths         | 37          |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 459000      |
| train-steps                    | 459000      |
| training/Q/q1_loss             | 98.18848    |
| training/sac_pi/alpha          | 0.16431496  |
| training/sac_pi/alpha_loss     | 0.022027466 |
| training/sac_pi/logp_pi        | 4.1303587   |
| training/sac_pi/pi_entropy     | 3.4188526   |
| training/sac_pi/pi_global_norm | 1.8442495   |
| training/sac_pi/policy_loss    | -228.47517  |
| training/sac_pi/std            | 0.485134    |
| training/sac_pi/valid_num      | 5005.0      |
| training/sac_Q/q1              | 219.23238   |
| training/sac_Q/q2              | 220.32158   |
| training/sac_Q/q2_loss         | 98.02364    |
| training/sac_Q/q_global_norm   | 216.88072   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15898107  |
| epoch                          | 459         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5099.5146   |
| evaluation/return-max          | 5189.747    |
| evaluation/return-min          | 4984.8447   |
| evaluation/return-std          | 73.39065    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46284       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5099.5146   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 214.781     |
| Q-std                          | 138.62445   |
| Q_loss                         | 92.30139    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 459         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000564    |
| times/evaluation_paths         | 34.9        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 63          |
| timestep                       | 1000        |
| timesteps_total                | 460000      |
| train-steps                    | 460000      |
| training/Q/q1_loss             | 106.43923   |
| training/sac_pi/alpha          | 0.1590205   |
| training/sac_pi/alpha_loss     | -0.50529414 |
| training/sac_pi/logp_pi        | 3.943542    |
| training/sac_pi/pi_entropy     | 3.2933965   |
| training/sac_pi/pi_global_norm | 2.233236    |
| training/sac_pi/policy_loss    | -229.76434  |
| training/sac_pi/std            | 0.46882302  |
| training/sac_pi/valid_num      | 4951.0      |
| training/sac_Q/q1              | 219.72026   |
| training/sac_Q/q2              | 221.18481   |
| training/sac_Q/q2_loss         | 106.905205  |
| training/sac_Q/q_global_norm   | 244.9201    |
---------------------------------------------------------------------------------
[WARN] 460 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16182016  |
| epoch                          | 460         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5077.4077   |
| evaluation/return-max          | 5145.062    |
| evaluation/return-min          | 4954.596    |
| evaluation/return-std          | 59.55389    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46557       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5077.4077   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 222.91597   |
| Q-std                          | 93.18302    |
| Q_loss                         | 90.29118    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 460         |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000566    |
| times/evaluation_paths         | 35.6        |
| times/timestep_after_hook      | 0.00357     |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 63.2        |
| timestep                       | 1000        |
| timesteps_total                | 461000      |
| train-steps                    | 461000      |
| training/Q/q1_loss             | 125.000435  |
| training/sac_pi/alpha          | 0.16185294  |
| training/sac_pi/alpha_loss     | -0.36193067 |
| training/sac_pi/logp_pi        | 3.7681472   |
| training/sac_pi/pi_entropy     | 3.4657273   |
| training/sac_pi/pi_global_norm | 1.8926996   |
| training/sac_pi/policy_loss    | -226.84344  |
| training/sac_pi/std            | 0.49295     |
| training/sac_pi/valid_num      | 4991.0      |
| training/sac_Q/q1              | 217.61484   |
| training/sac_Q/q2              | 218.05997   |
| training/sac_Q/q2_loss         | 124.57578   |
| training/sac_Q/q_global_norm   | 253.2518    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1640218  |
| epoch                          | 461        |
| evaluation/episode-length-avg  | 492        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 146        |
| evaluation/episode-length-std  | 415        |
| evaluation/return-average      | 2350.6394  |
| evaluation/return-max          | 5208.3936  |
| evaluation/return-min          | 476.12268  |
| evaluation/return-std          | 2265.1946  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46303      |
| perf/AverageLength             | 492        |
| perf/AverageReturn             | 2350.6394  |
| perf/NormalizedReturn          | 0.512      |
| Q-avg                          | 211.8167   |
| Q-std                          | 128.3005   |
| Q_loss                         | 104.30184  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 461        |
| times/epoch_after_hook         | 1.58e-06   |
| times/epoch_before_hook        | 0.000272   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000609   |
| times/evaluation_paths         | 22.6       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 462000     |
| train-steps                    | 462000     |
| training/Q/q1_loss             | 84.19435   |
| training/sac_pi/alpha          | 0.16404927 |
| training/sac_pi/alpha_loss     | -0.2843888 |
| training/sac_pi/logp_pi        | 4.964566   |
| training/sac_pi/pi_entropy     | 3.2780728  |
| training/sac_pi/pi_global_norm | 1.7140818  |
| training/sac_pi/policy_loss    | -232.85228 |
| training/sac_pi/std            | 0.49647245 |
| training/sac_pi/valid_num      | 4825.0     |
| training/sac_Q/q1              | 210.74484  |
| training/sac_Q/q2              | 211.5839   |
| training/sac_Q/q2_loss         | 83.21603   |
| training/sac_Q/q_global_norm   | 316.08865  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1587728  |
| epoch                          | 462        |
| evaluation/episode-length-avg  | 139        |
| evaluation/episode-length-max  | 140        |
| evaluation/episode-length-min  | 138        |
| evaluation/episode-length-std  | 0.64       |
| evaluation/return-average      | 456.19855  |
| evaluation/return-max          | 458.6231   |
| evaluation/return-min          | 451.4193   |
| evaluation/return-std          | 2.1446204  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46358      |
| perf/AverageLength             | 139        |
| perf/AverageReturn             | 456.19855  |
| perf/NormalizedReturn          | 0.099      |
| Q-avg                          | 222.86113  |
| Q-std                          | 132.87228  |
| Q_loss                         | 104.20068  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 462        |
| times/epoch_after_hook         | 1.55e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000595   |
| times/evaluation_paths         | 6.14       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 463000     |
| train-steps                    | 463000     |
| training/Q/q1_loss             | 108.52671  |
| training/sac_pi/alpha          | 0.15878128 |
| training/sac_pi/alpha_loss     | 0.12212072 |
| training/sac_pi/logp_pi        | 4.539762   |
| training/sac_pi/pi_entropy     | 3.1683297  |
| training/sac_pi/pi_global_norm | 2.4310012  |
| training/sac_pi/policy_loss    | -226.15733 |
| training/sac_pi/std            | 0.47157833 |
| training/sac_pi/valid_num      | 4979.0     |
| training/sac_Q/q1              | 216.1309   |
| training/sac_Q/q2              | 216.12686  |
| training/sac_Q/q2_loss         | 108.57735  |
| training/sac_Q/q_global_norm   | 214.7897   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1622984  |
| epoch                          | 463        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4860.0796  |
| evaluation/return-max          | 4927.1045  |
| evaluation/return-min          | 4823.3223  |
| evaluation/return-std          | 32.37229   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 78.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46414      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4860.0796  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 212.42554  |
| Q-std                          | 165.41388  |
| Q_loss                         | 86.95066   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 463        |
| times/epoch_after_hook         | 1.99e-06   |
| times/epoch_before_hook        | 0.000279   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000748   |
| times/evaluation_paths         | 35.4       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 62.7       |
| timestep                       | 1000       |
| timesteps_total                | 464000     |
| train-steps                    | 464000     |
| training/Q/q1_loss             | 113.34188  |
| training/sac_pi/alpha          | 0.16223583 |
| training/sac_pi/alpha_loss     | 0.355881   |
| training/sac_pi/logp_pi        | 4.2912836  |
| training/sac_pi/pi_entropy     | 3.5193305  |
| training/sac_pi/pi_global_norm | 1.7431256  |
| training/sac_pi/policy_loss    | -220.11955 |
| training/sac_pi/std            | 0.49913546 |
| training/sac_pi/valid_num      | 4916.0     |
| training/sac_Q/q1              | 207.10287  |
| training/sac_Q/q2              | 209.52014  |
| training/sac_Q/q2_loss         | 114.97869  |
| training/sac_Q/q_global_norm   | 306.9464   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16005264 |
| epoch                          | 464        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4991.868   |
| evaluation/return-max          | 5065.712   |
| evaluation/return-min          | 4913.59    |
| evaluation/return-std          | 42.916134  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.8       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46379      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4991.868   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 213.71927  |
| Q-std                          | 126.843285 |
| Q_loss                         | 91.12714   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 464        |
| times/epoch_after_hook         | 2.26e-06   |
| times/epoch_before_hook        | 0.000146   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000641   |
| times/evaluation_paths         | 36.3       |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 465000     |
| train-steps                    | 465000     |
| training/Q/q1_loss             | 96.76276   |
| training/sac_pi/alpha          | 0.1600874  |
| training/sac_pi/alpha_loss     | -0.0674016 |
| training/sac_pi/logp_pi        | 4.6978064  |
| training/sac_pi/pi_entropy     | 3.198666   |
| training/sac_pi/pi_global_norm | 1.8759816  |
| training/sac_pi/policy_loss    | -221.92262 |
| training/sac_pi/std            | 0.47269502 |
| training/sac_pi/valid_num      | 4958.0     |
| training/sac_Q/q1              | 209.53496  |
| training/sac_Q/q2              | 210.05106  |
| training/sac_Q/q2_loss         | 96.18502   |
| training/sac_Q/q_global_norm   | 289.82175  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16094635  |
| epoch                          | 465         |
| evaluation/episode-length-avg  | 992         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 955         |
| evaluation/episode-length-std  | 16.2        |
| evaluation/return-average      | 5100.412    |
| evaluation/return-max          | 5216.7393   |
| evaluation/return-min          | 4879.552    |
| evaluation/return-std          | 112.18174   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.03        |
| model/origin_ret               | 83.9        |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46311       |
| perf/AverageLength             | 992         |
| perf/AverageReturn             | 5100.412    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 221.59006   |
| Q-std                          | 113.96706   |
| Q_loss                         | 97.964386   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 465         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.00038     |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000621    |
| times/evaluation_paths         | 35.5        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 62.9        |
| timestep                       | 1000        |
| timesteps_total                | 466000      |
| train-steps                    | 466000      |
| training/Q/q1_loss             | 86.91627    |
| training/sac_pi/alpha          | 0.16095687  |
| training/sac_pi/alpha_loss     | -0.13108024 |
| training/sac_pi/logp_pi        | 3.902954    |
| training/sac_pi/pi_entropy     | 3.3946576   |
| training/sac_pi/pi_global_norm | 1.7629579   |
| training/sac_pi/policy_loss    | -221.3058   |
| training/sac_pi/std            | 0.47838676  |
| training/sac_pi/valid_num      | 5024.0      |
| training/sac_Q/q1              | 216.13602   |
| training/sac_Q/q2              | 217.69943   |
| training/sac_Q/q2_loss         | 86.18102    |
| training/sac_Q/q_global_norm   | 187.97107   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16568972 |
| epoch                          | 466        |
| evaluation/episode-length-avg  | 636        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 142        |
| evaluation/episode-length-std  | 334        |
| evaluation/return-average      | 2933.2837  |
| evaluation/return-max          | 4940.3403  |
| evaluation/return-min          | 343.66925  |
| evaluation/return-std          | 1765.4742  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46293      |
| perf/AverageLength             | 636        |
| perf/AverageReturn             | 2933.2837  |
| perf/NormalizedReturn          | 0.639      |
| Q-avg                          | 213.53635  |
| Q-std                          | 128.05493  |
| Q_loss                         | 106.103035 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 466        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000209   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000788   |
| times/evaluation_paths         | 21.9       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00871    |
| times/train                    | 63.6       |
| timestep                       | 1000       |
| timesteps_total                | 467000     |
| train-steps                    | 467000     |
| training/Q/q1_loss             | 100.170944 |
| training/sac_pi/alpha          | 0.16567053 |
| training/sac_pi/alpha_loss     | 0.33603746 |
| training/sac_pi/logp_pi        | 4.167805   |
| training/sac_pi/pi_entropy     | 3.4789672  |
| training/sac_pi/pi_global_norm | 1.510528   |
| training/sac_pi/policy_loss    | -223.32611 |
| training/sac_pi/std            | 0.48618922 |
| training/sac_pi/valid_num      | 5022.0     |
| training/sac_Q/q1              | 217.29243  |
| training/sac_Q/q2              | 219.37692  |
| training/sac_Q/q2_loss         | 98.53422   |
| training/sac_Q/q_global_norm   | 214.16156  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16010436 |
| epoch                          | 467        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5089.7725  |
| evaluation/return-max          | 5120.0283  |
| evaluation/return-min          | 5063.959   |
| evaluation/return-std          | 15.720779  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46349      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5089.7725  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 219.72232  |
| Q-std                          | 110.280334 |
| Q_loss                         | 101.28304  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 467        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000182   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.00067    |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 63.3       |
| timestep                       | 1000       |
| timesteps_total                | 468000     |
| train-steps                    | 468000     |
| training/Q/q1_loss             | 92.84055   |
| training/sac_pi/alpha          | 0.1601053  |
| training/sac_pi/alpha_loss     | 0.27710667 |
| training/sac_pi/logp_pi        | 3.9218469  |
| training/sac_pi/pi_entropy     | 3.3243713  |
| training/sac_pi/pi_global_norm | 1.7112595  |
| training/sac_pi/policy_loss    | -230.46822 |
| training/sac_pi/std            | 0.46601918 |
| training/sac_pi/valid_num      | 5002.0     |
| training/sac_Q/q1              | 223.28226  |
| training/sac_Q/q2              | 224.68936  |
| training/sac_Q/q2_loss         | 92.19528   |
| training/sac_Q/q_global_norm   | 219.21274  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1636822   |
| epoch                          | 468         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4736.3413   |
| evaluation/return-max          | 4925.0977   |
| evaluation/return-min          | 4383.421    |
| evaluation/return-std          | 156.8743    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46316       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4736.3413   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 219.85786   |
| Q-std                          | 126.17646   |
| Q_loss                         | 94.46821    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 468         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000141    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000817    |
| times/evaluation_paths         | 37.7        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 63          |
| timestep                       | 1000        |
| timesteps_total                | 469000      |
| train-steps                    | 469000      |
| training/Q/q1_loss             | 105.27573   |
| training/sac_pi/alpha          | 0.1636841   |
| training/sac_pi/alpha_loss     | 0.028557653 |
| training/sac_pi/logp_pi        | 3.9607563   |
| training/sac_pi/pi_entropy     | 3.316611    |
| training/sac_pi/pi_global_norm | 2.774946    |
| training/sac_pi/policy_loss    | -228.36008  |
| training/sac_pi/std            | 0.47186896  |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 221.81454   |
| training/sac_Q/q2              | 222.23726   |
| training/sac_Q/q2_loss         | 104.78586   |
| training/sac_Q/q_global_norm   | 218.47098   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16042374 |
| epoch                          | 469        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5221.9985  |
| evaluation/return-max          | 5230.491   |
| evaluation/return-min          | 5202.3174  |
| evaluation/return-std          | 8.739622   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46547      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5221.9985  |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 205.2478   |
| Q-std                          | 160.31364  |
| Q_loss                         | 109.28754  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 469        |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.000351   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000676   |
| times/evaluation_paths         | 36.1       |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 63.6       |
| timestep                       | 1000       |
| timesteps_total                | 470000     |
| train-steps                    | 470000     |
| training/Q/q1_loss             | 111.3569   |
| training/sac_pi/alpha          | 0.16035041 |
| training/sac_pi/alpha_loss     | 0.94489545 |
| training/sac_pi/logp_pi        | 4.1914845  |
| training/sac_pi/pi_entropy     | 3.4344983  |
| training/sac_pi/pi_global_norm | 1.9165028  |
| training/sac_pi/policy_loss    | -221.64362 |
| training/sac_pi/std            | 0.48465517 |
| training/sac_pi/valid_num      | 5024.0     |
| training/sac_Q/q1              | 216.3873   |
| training/sac_Q/q2              | 218.21713  |
| training/sac_Q/q2_loss         | 110.611015 |
| training/sac_Q/q_global_norm   | 250.86632  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16194196  |
| epoch                          | 470         |
| evaluation/episode-length-avg  | 605         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 307         |
| evaluation/episode-length-std  | 326         |
| evaluation/return-average      | 2743.4082   |
| evaluation/return-max          | 4864.3623   |
| evaluation/return-min          | 1190.0217   |
| evaluation/return-std          | 1722.062    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46335       |
| perf/AverageLength             | 605         |
| perf/AverageReturn             | 2743.4082   |
| perf/NormalizedReturn          | 0.597       |
| Q-avg                          | 214.97429   |
| Q-std                          | 122.99388   |
| Q_loss                         | 101.62933   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 470         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000158    |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000662    |
| times/evaluation_paths         | 19.6        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 471000      |
| train-steps                    | 471000      |
| training/Q/q1_loss             | 69.20562    |
| training/sac_pi/alpha          | 0.16197592  |
| training/sac_pi/alpha_loss     | -0.47605124 |
| training/sac_pi/logp_pi        | 3.4721057   |
| training/sac_pi/pi_entropy     | 3.42555     |
| training/sac_pi/pi_global_norm | 1.5390872   |
| training/sac_pi/policy_loss    | -229.00427  |
| training/sac_pi/std            | 0.48743004  |
| training/sac_pi/valid_num      | 4971.0      |
| training/sac_Q/q1              | 220.4584    |
| training/sac_Q/q2              | 221.49573   |
| training/sac_Q/q2_loss         | 68.60271    |
| training/sac_Q/q_global_norm   | 168.59961   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16661327 |
| epoch                          | 471        |
| evaluation/episode-length-avg  | 527        |
| evaluation/episode-length-max  | 539        |
| evaluation/episode-length-min  | 461        |
| evaluation/episode-length-std  | 22.1       |
| evaluation/return-average      | 2467.9688  |
| evaluation/return-max          | 2549.6204  |
| evaluation/return-min          | 2104.7434  |
| evaluation/return-std          | 124.003204 |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46249      |
| perf/AverageLength             | 527        |
| perf/AverageReturn             | 2467.9688  |
| perf/NormalizedReturn          | 0.537      |
| Q-avg                          | 221.9349   |
| Q-std                          | 104.759926 |
| Q_loss                         | 101.9634   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 471        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000755   |
| times/evaluation_paths         | 19.4       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 472000     |
| train-steps                    | 472000     |
| training/Q/q1_loss             | 113.087296 |
| training/sac_pi/alpha          | 0.16662067 |
| training/sac_pi/alpha_loss     | 0.13767172 |
| training/sac_pi/logp_pi        | 4.587152   |
| training/sac_pi/pi_entropy     | 3.6669464  |
| training/sac_pi/pi_global_norm | 1.4613639  |
| training/sac_pi/policy_loss    | -220.93994 |
| training/sac_pi/std            | 0.53304857 |
| training/sac_pi/valid_num      | 4983.0     |
| training/sac_Q/q1              | 206.59103  |
| training/sac_Q/q2              | 209.95218  |
| training/sac_Q/q2_loss         | 112.33229  |
| training/sac_Q/q_global_norm   | 259.18875  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16677162  |
| epoch                          | 472         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5305.799    |
| evaluation/return-max          | 5337.066    |
| evaluation/return-min          | 5253.326    |
| evaluation/return-std          | 27.700615   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46344       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5305.799    |
| perf/NormalizedReturn          | 1.16        |
| Q-avg                          | 220.7395    |
| Q-std                          | 119.47621   |
| Q_loss                         | 86.73106    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 472         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000235    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000675    |
| times/evaluation_paths         | 35          |
| times/timestep_after_hook      | 0.00356     |
| times/timestep_before_hook     | 0.00832     |
| times/train                    | 62.7        |
| timestep                       | 1000        |
| timesteps_total                | 473000      |
| train-steps                    | 473000      |
| training/Q/q1_loss             | 128.38727   |
| training/sac_pi/alpha          | 0.16678612  |
| training/sac_pi/alpha_loss     | -0.15689833 |
| training/sac_pi/logp_pi        | 4.0064726   |
| training/sac_pi/pi_entropy     | 3.607534    |
| training/sac_pi/pi_global_norm | 2.028528    |
| training/sac_pi/policy_loss    | -226.87967  |
| training/sac_pi/std            | 0.5048807   |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 216.27718   |
| training/sac_Q/q2              | 218.72794   |
| training/sac_Q/q2_loss         | 130.36145   |
| training/sac_Q/q_global_norm   | 362.4676    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16465211  |
| epoch                          | 473         |
| evaluation/episode-length-avg  | 338         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 154         |
| evaluation/episode-length-std  | 300         |
| evaluation/return-average      | 1380.7766   |
| evaluation/return-max          | 4718.5117   |
| evaluation/return-min          | 482.12155   |
| evaluation/return-std          | 1486.7675   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.8        |
| model/penalty_ret              | 80.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46420       |
| perf/AverageLength             | 338         |
| perf/AverageReturn             | 1380.7766   |
| perf/NormalizedReturn          | 0.3         |
| Q-avg                          | 211.45853   |
| Q-std                          | 112.23831   |
| Q_loss                         | 98.51634    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 473         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000314    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000648    |
| times/evaluation_paths         | 13.3        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00822     |
| times/train                    | 61.5        |
| timestep                       | 1000        |
| timesteps_total                | 474000      |
| train-steps                    | 474000      |
| training/Q/q1_loss             | 110.91475   |
| training/sac_pi/alpha          | 0.1646335   |
| training/sac_pi/alpha_loss     | -0.15462069 |
| training/sac_pi/logp_pi        | 4.3980083   |
| training/sac_pi/pi_entropy     | 3.2325954   |
| training/sac_pi/pi_global_norm | 1.8644645   |
| training/sac_pi/policy_loss    | -227.45544  |
| training/sac_pi/std            | 0.49005398  |
| training/sac_pi/valid_num      | 5005.0      |
| training/sac_Q/q1              | 220.81055   |
| training/sac_Q/q2              | 219.26004   |
| training/sac_Q/q2_loss         | 111.32877   |
| training/sac_Q/q_global_norm   | 212.53111   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1643873  |
| epoch                          | 474        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5214.793   |
| evaluation/return-max          | 5286.2188  |
| evaluation/return-min          | 5147.705   |
| evaluation/return-std          | 38.488155  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.05       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46486      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5214.793   |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 217.74736  |
| Q-std                          | 141.85333  |
| Q_loss                         | 105.10249  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 474        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000716   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00353    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 475000     |
| train-steps                    | 475000     |
| training/Q/q1_loss             | 113.3243   |
| training/sac_pi/alpha          | 0.1643507  |
| training/sac_pi/alpha_loss     | 0.16745612 |
| training/sac_pi/logp_pi        | 4.555975   |
| training/sac_pi/pi_entropy     | 3.60317    |
| training/sac_pi/pi_global_norm | 1.6891798  |
| training/sac_pi/policy_loss    | -224.38431 |
| training/sac_pi/std            | 0.52453107 |
| training/sac_pi/valid_num      | 4892.0     |
| training/sac_Q/q1              | 211.51855  |
| training/sac_Q/q2              | 215.61887  |
| training/sac_Q/q2_loss         | 113.54202  |
| training/sac_Q/q_global_norm   | 401.4958   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16947512  |
| epoch                          | 475         |
| evaluation/episode-length-avg  | 914         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 677         |
| evaluation/episode-length-std  | 117         |
| evaluation/return-average      | 4497.9585   |
| evaluation/return-max          | 4998.9087   |
| evaluation/return-min          | 3227.9446   |
| evaluation/return-std          | 628.24634   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.17        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46494       |
| perf/AverageLength             | 914         |
| perf/AverageReturn             | 4497.9585   |
| perf/NormalizedReturn          | 0.979       |
| Q-avg                          | 214.73828   |
| Q-std                          | 118.7204    |
| Q_loss                         | 98.69368    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 475         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000585    |
| times/evaluation_paths         | 32.8        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 476000      |
| train-steps                    | 476000      |
| training/Q/q1_loss             | 94.085144   |
| training/sac_pi/alpha          | 0.16947076  |
| training/sac_pi/alpha_loss     | 0.031211494 |
| training/sac_pi/logp_pi        | 4.6211348   |
| training/sac_pi/pi_entropy     | 3.26426     |
| training/sac_pi/pi_global_norm | 1.8045275   |
| training/sac_pi/policy_loss    | -226.42383  |
| training/sac_pi/std            | 0.47749683  |
| training/sac_pi/valid_num      | 4977.0      |
| training/sac_Q/q1              | 216.70554   |
| training/sac_Q/q2              | 217.62466   |
| training/sac_Q/q2_loss         | 94.00603    |
| training/sac_Q/q_global_norm   | 247.2831    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15990952  |
| epoch                          | 476         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5160.6807   |
| evaluation/return-max          | 5207.0938   |
| evaluation/return-min          | 5090.2725   |
| evaluation/return-std          | 41.246906   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46225       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5160.6807   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 219.33975   |
| Q-std                          | 131.1936    |
| Q_loss                         | 111.00421   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 476         |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000642    |
| times/evaluation_paths         | 35.4        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00851     |
| times/train                    | 63.1        |
| timestep                       | 1000        |
| timesteps_total                | 477000      |
| train-steps                    | 477000      |
| training/Q/q1_loss             | 77.827576   |
| training/sac_pi/alpha          | 0.15992464  |
| training/sac_pi/alpha_loss     | 0.009987355 |
| training/sac_pi/logp_pi        | 3.8609443   |
| training/sac_pi/pi_entropy     | 3.2925887   |
| training/sac_pi/pi_global_norm | 1.7676452   |
| training/sac_pi/policy_loss    | -234.0264   |
| training/sac_pi/std            | 0.46667472  |
| training/sac_pi/valid_num      | 5001.0      |
| training/sac_Q/q1              | 224.77275   |
| training/sac_Q/q2              | 226.21721   |
| training/sac_Q/q2_loss         | 78.745865   |
| training/sac_Q/q_global_norm   | 287.8258    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16194499  |
| epoch                          | 477         |
| evaluation/episode-length-avg  | 950         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 499         |
| evaluation/episode-length-std  | 150         |
| evaluation/return-average      | 4607.943    |
| evaluation/return-max          | 5001.172    |
| evaluation/return-min          | 2077.2449   |
| evaluation/return-std          | 848.17993   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46526       |
| perf/AverageLength             | 950         |
| perf/AverageReturn             | 4607.943    |
| perf/NormalizedReturn          | 1           |
| Q-avg                          | 222.31396   |
| Q-std                          | 128.09187   |
| Q_loss                         | 104.85922   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 477         |
| times/epoch_after_hook         | 1.62e-06    |
| times/epoch_before_hook        | 0.000286    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000698    |
| times/evaluation_paths         | 34.1        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 63.7        |
| timestep                       | 1000        |
| timesteps_total                | 478000      |
| train-steps                    | 478000      |
| training/Q/q1_loss             | 97.681984   |
| training/sac_pi/alpha          | 0.16196878  |
| training/sac_pi/alpha_loss     | -0.08577683 |
| training/sac_pi/logp_pi        | 4.3943567   |
| training/sac_pi/pi_entropy     | 3.3032334   |
| training/sac_pi/pi_global_norm | 1.9299293   |
| training/sac_pi/policy_loss    | -220.69661  |
| training/sac_pi/std            | 0.48208013  |
| training/sac_pi/valid_num      | 4903.0      |
| training/sac_Q/q1              | 208.35396   |
| training/sac_Q/q2              | 208.08884   |
| training/sac_Q/q2_loss         | 97.73413    |
| training/sac_Q/q_global_norm   | 293.8183    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1640257   |
| epoch                          | 478         |
| evaluation/episode-length-avg  | 152         |
| evaluation/episode-length-max  | 155         |
| evaluation/episode-length-min  | 150         |
| evaluation/episode-length-std  | 1.35        |
| evaluation/return-average      | 481.43124   |
| evaluation/return-max          | 491.28024   |
| evaluation/return-min          | 476.23297   |
| evaluation/return-std          | 4.249296    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 78.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46549       |
| perf/AverageLength             | 152         |
| perf/AverageReturn             | 481.43124   |
| perf/NormalizedReturn          | 0.105       |
| Q-avg                          | 206.17972   |
| Q-std                          | 133.8365    |
| Q_loss                         | 99.83627    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 478         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 503         |
| times/evaluation_metrics       | 0.000615    |
| times/evaluation_paths         | 5.13        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 63.5        |
| timestep                       | 1000        |
| timesteps_total                | 479000      |
| train-steps                    | 479000      |
| training/Q/q1_loss             | 113.796074  |
| training/sac_pi/alpha          | 0.16404945  |
| training/sac_pi/alpha_loss     | -0.42131785 |
| training/sac_pi/logp_pi        | 3.746505    |
| training/sac_pi/pi_entropy     | 3.4359527   |
| training/sac_pi/pi_global_norm | 1.661335    |
| training/sac_pi/policy_loss    | -229.4983   |
| training/sac_pi/std            | 0.4784994   |
| training/sac_pi/valid_num      | 5030.0      |
| training/sac_Q/q1              | 223.30234   |
| training/sac_Q/q2              | 226.36638   |
| training/sac_Q/q2_loss         | 112.98917   |
| training/sac_Q/q_global_norm   | 237.00548   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16564964 |
| epoch                          | 479        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5029.3804  |
| evaluation/return-max          | 5091.5884  |
| evaluation/return-min          | 4976.0957  |
| evaluation/return-std          | 37.503994  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46451      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5029.3804  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 203.76047  |
| Q-std                          | 147.80411  |
| Q_loss                         | 123.53145  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 479        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000558   |
| times/evaluation_paths         | 35.5       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 63.3       |
| timestep                       | 1000       |
| timesteps_total                | 480000     |
| train-steps                    | 480000     |
| training/Q/q1_loss             | 103.48646  |
| training/sac_pi/alpha          | 0.16561133 |
| training/sac_pi/alpha_loss     | 0.47534624 |
| training/sac_pi/logp_pi        | 4.132383   |
| training/sac_pi/pi_entropy     | 3.5339425  |
| training/sac_pi/pi_global_norm | 1.6774082  |
| training/sac_pi/policy_loss    | -224.91676 |
| training/sac_pi/std            | 0.48516527 |
| training/sac_pi/valid_num      | 4998.0     |
| training/sac_Q/q1              | 215.81372  |
| training/sac_Q/q2              | 217.92126  |
| training/sac_Q/q2_loss         | 105.007355 |
| training/sac_Q/q_global_norm   | 232.08441  |
--------------------------------------------------------------------------------
[WARN] 480 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16307096 |
| epoch                          | 480        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5099.628   |
| evaluation/return-max          | 5144.9785  |
| evaluation/return-min          | 5065.93    |
| evaluation/return-std          | 28.540453  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 87.1       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46430      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5099.628   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 219.57524  |
| Q-std                          | 105.832985 |
| Q_loss                         | 93.01677   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 480        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000535   |
| times/evaluation_paths         | 35.5       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 63.2       |
| timestep                       | 1000       |
| timesteps_total                | 481000     |
| train-steps                    | 481000     |
| training/Q/q1_loss             | 90.18758   |
| training/sac_pi/alpha          | 0.16307504 |
| training/sac_pi/alpha_loss     | -0.3279977 |
| training/sac_pi/logp_pi        | 3.511541   |
| training/sac_pi/pi_entropy     | 3.386165   |
| training/sac_pi/pi_global_norm | 1.7136699  |
| training/sac_pi/policy_loss    | -225.33322 |
| training/sac_pi/std            | 0.46508554 |
| training/sac_pi/valid_num      | 5017.0     |
| training/sac_Q/q1              | 220.13004  |
| training/sac_Q/q2              | 220.33943  |
| training/sac_Q/q2_loss         | 89.76352   |
| training/sac_Q/q_global_norm   | 225.28557  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1642682   |
| epoch                          | 481         |
| evaluation/episode-length-avg  | 153         |
| evaluation/episode-length-max  | 160         |
| evaluation/episode-length-min  | 147         |
| evaluation/episode-length-std  | 3.25        |
| evaluation/return-average      | 445.26074   |
| evaluation/return-max          | 467.59875   |
| evaluation/return-min          | 425.0822    |
| evaluation/return-std          | 11.501256   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46349       |
| perf/AverageLength             | 153         |
| perf/AverageReturn             | 445.26074   |
| perf/NormalizedReturn          | 0.0966      |
| Q-avg                          | 222.40585   |
| Q-std                          | 109.44417   |
| Q_loss                         | 118.146225  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 481         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000368    |
| times/epoch_rollout_model      | 510         |
| times/evaluation_metrics       | 0.000612    |
| times/evaluation_paths         | 5.19        |
| times/timestep_after_hook      | 0.0038      |
| times/timestep_before_hook     | 0.00848     |
| times/train                    | 66.9        |
| timestep                       | 1000        |
| timesteps_total                | 482000      |
| train-steps                    | 482000      |
| training/Q/q1_loss             | 99.597466   |
| training/sac_pi/alpha          | 0.16428609  |
| training/sac_pi/alpha_loss     | -0.15771876 |
| training/sac_pi/logp_pi        | 3.6345744   |
| training/sac_pi/pi_entropy     | 3.3264356   |
| training/sac_pi/pi_global_norm | 1.6413474   |
| training/sac_pi/policy_loss    | -229.11107  |
| training/sac_pi/std            | 0.4573514   |
| training/sac_pi/valid_num      | 5008.0      |
| training/sac_Q/q1              | 222.65482   |
| training/sac_Q/q2              | 223.89001   |
| training/sac_Q/q2_loss         | 97.25101    |
| training/sac_Q/q_global_norm   | 190.85007   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.158846   |
| epoch                          | 482        |
| evaluation/episode-length-avg  | 938        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 664        |
| evaluation/episode-length-std  | 106        |
| evaluation/return-average      | 4694.1772  |
| evaluation/return-max          | 5073.0034  |
| evaluation/return-min          | 3202.0032  |
| evaluation/return-std          | 576.5022   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 84.5       |
| model/penalty_ret              | 78.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46449      |
| perf/AverageLength             | 938        |
| perf/AverageReturn             | 4694.1772  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 225.41301  |
| Q-std                          | 105.455734 |
| Q_loss                         | 106.136505 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 482        |
| times/epoch_after_hook         | 3.01e-06   |
| times/epoch_before_hook        | 0.000117   |
| times/epoch_rollout_model      | 538        |
| times/evaluation_metrics       | 0.0007     |
| times/evaluation_paths         | 35.2       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00904    |
| times/train                    | 63.9       |
| timestep                       | 1000       |
| timesteps_total                | 483000     |
| train-steps                    | 483000     |
| training/Q/q1_loss             | 94.1001    |
| training/sac_pi/alpha          | 0.15884906 |
| training/sac_pi/alpha_loss     | 0.18777753 |
| training/sac_pi/logp_pi        | 3.9295495  |
| training/sac_pi/pi_entropy     | 3.5727928  |
| training/sac_pi/pi_global_norm | 1.8982488  |
| training/sac_pi/policy_loss    | -226.19121 |
| training/sac_pi/std            | 0.48554248 |
| training/sac_pi/valid_num      | 5045.0     |
| training/sac_Q/q1              | 220.55452  |
| training/sac_Q/q2              | 222.1269   |
| training/sac_Q/q2_loss         | 93.386696  |
| training/sac_Q/q_global_norm   | 158.68245  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16628338 |
| epoch                          | 483        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4675.132   |
| evaluation/return-max          | 4931.8574  |
| evaluation/return-min          | 4472.8257  |
| evaluation/return-std          | 153.17868  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46281      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4675.132   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 208.0922   |
| Q-std                          | 140.86156  |
| Q_loss                         | 105.66817  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 483        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 535        |
| times/evaluation_metrics       | 0.000584   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 484000     |
| train-steps                    | 484000     |
| training/Q/q1_loss             | 99.34524   |
| training/sac_pi/alpha          | 0.16632254 |
| training/sac_pi/alpha_loss     | -0.3579415 |
| training/sac_pi/logp_pi        | 3.296391   |
| training/sac_pi/pi_entropy     | 3.4520097  |
| training/sac_pi/pi_global_norm | 1.9414848  |
| training/sac_pi/policy_loss    | -229.10696 |
| training/sac_pi/std            | 0.45955664 |
| training/sac_pi/valid_num      | 4997.0     |
| training/sac_Q/q1              | 223.46968  |
| training/sac_Q/q2              | 223.74487  |
| training/sac_Q/q2_loss         | 98.61765   |
| training/sac_Q/q_global_norm   | 251.76808  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1656464   |
| epoch                          | 484         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4668.956    |
| evaluation/return-max          | 4835.4907   |
| evaluation/return-min          | 4594.357    |
| evaluation/return-std          | 80.90614    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46517       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4668.956    |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 211.40242   |
| Q-std                          | 131.5872    |
| Q_loss                         | 108.71186   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 484         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 536         |
| times/evaluation_metrics       | 0.000592    |
| times/evaluation_paths         | 36.2        |
| times/timestep_after_hook      | 0.0039      |
| times/timestep_before_hook     | 0.00846     |
| times/train                    | 62.1        |
| timestep                       | 1000        |
| timesteps_total                | 485000      |
| train-steps                    | 485000      |
| training/Q/q1_loss             | 82.36835    |
| training/sac_pi/alpha          | 0.16565736  |
| training/sac_pi/alpha_loss     | -0.39705765 |
| training/sac_pi/logp_pi        | 3.0351613   |
| training/sac_pi/pi_entropy     | 3.4837844   |
| training/sac_pi/pi_global_norm | 1.9242144   |
| training/sac_pi/policy_loss    | -222.72656  |
| training/sac_pi/std            | 0.459509    |
| training/sac_pi/valid_num      | 5045.0      |
| training/sac_Q/q1              | 219.83789   |
| training/sac_Q/q2              | 220.38321   |
| training/sac_Q/q2_loss         | 83.22391    |
| training/sac_Q/q_global_norm   | 304.10242   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16565262  |
| epoch                          | 485         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4962.4917   |
| evaluation/return-max          | 5045.3184   |
| evaluation/return-min          | 4908.5825   |
| evaluation/return-std          | 37.980755   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46489       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4962.4917   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 221.19836   |
| Q-std                          | 127.88504   |
| Q_loss                         | 94.08771    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 485         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000378    |
| times/epoch_rollout_model      | 516         |
| times/evaluation_metrics       | 0.00105     |
| times/evaluation_paths         | 38          |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00847     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 486000      |
| train-steps                    | 486000      |
| training/Q/q1_loss             | 83.19898    |
| training/sac_pi/alpha          | 0.16563274  |
| training/sac_pi/alpha_loss     | -0.15021135 |
| training/sac_pi/logp_pi        | 3.8286254   |
| training/sac_pi/pi_entropy     | 3.2841048   |
| training/sac_pi/pi_global_norm | 2.0860882   |
| training/sac_pi/policy_loss    | -230.3181   |
| training/sac_pi/std            | 0.46558443  |
| training/sac_pi/valid_num      | 4978.0      |
| training/sac_Q/q1              | 221.99565   |
| training/sac_Q/q2              | 223.96411   |
| training/sac_Q/q2_loss         | 82.412994   |
| training/sac_Q/q_global_norm   | 257.3711    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1629355  |
| epoch                          | 486        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5020.2134  |
| evaluation/return-max          | 5054.165   |
| evaluation/return-min          | 4953.9473  |
| evaluation/return-std          | 31.094242  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 87         |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46456      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5020.2134  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 218.21591  |
| Q-std                          | 98.70442   |
| Q_loss                         | 94.10769   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 486        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 516        |
| times/evaluation_metrics       | 0.000631   |
| times/evaluation_paths         | 34.5       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 487000     |
| train-steps                    | 487000     |
| training/Q/q1_loss             | 110.29098  |
| training/sac_pi/alpha          | 0.16293602 |
| training/sac_pi/alpha_loss     | 0.19080709 |
| training/sac_pi/logp_pi        | 4.8679175  |
| training/sac_pi/pi_entropy     | 3.187392   |
| training/sac_pi/pi_global_norm | 1.8518689  |
| training/sac_pi/policy_loss    | -228.94772 |
| training/sac_pi/std            | 0.48528358 |
| training/sac_pi/valid_num      | 4986.0     |
| training/sac_Q/q1              | 217.67525  |
| training/sac_Q/q2              | 219.25748  |
| training/sac_Q/q2_loss         | 110.93497  |
| training/sac_Q/q_global_norm   | 260.7821   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16569655  |
| epoch                          | 487         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5100.1846   |
| evaluation/return-max          | 5143.235    |
| evaluation/return-min          | 5049.754    |
| evaluation/return-std          | 27.4107     |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46417       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5100.1846   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 212.23177   |
| Q-std                          | 127.68977   |
| Q_loss                         | 90.05682    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 487         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000579    |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 60.3        |
| timestep                       | 1000        |
| timesteps_total                | 488000      |
| train-steps                    | 488000      |
| training/Q/q1_loss             | 122.612274  |
| training/sac_pi/alpha          | 0.16566181  |
| training/sac_pi/alpha_loss     | -0.16021562 |
| training/sac_pi/logp_pi        | 4.495689    |
| training/sac_pi/pi_entropy     | 3.5338225   |
| training/sac_pi/pi_global_norm | 1.9492042   |
| training/sac_pi/policy_loss    | -221.68813  |
| training/sac_pi/std            | 0.51342845  |
| training/sac_pi/valid_num      | 4921.0      |
| training/sac_Q/q1              | 207.93115   |
| training/sac_Q/q2              | 210.62785   |
| training/sac_Q/q2_loss         | 122.84659   |
| training/sac_Q/q_global_norm   | 262.73178   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16201697   |
| epoch                          | 488          |
| evaluation/episode-length-avg  | 411          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 152          |
| evaluation/episode-length-std  | 386          |
| evaluation/return-average      | 1809.002     |
| evaluation/return-max          | 5047.962     |
| evaluation/return-min          | 450.29623    |
| evaluation/return-std          | 2036.9666    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.13         |
| model/origin_ret               | 86.1         |
| model/penalty_ret              | 79.7         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46436        |
| perf/AverageLength             | 411          |
| perf/AverageReturn             | 1809.002     |
| perf/NormalizedReturn          | 0.394        |
| Q-avg                          | 218.69492    |
| Q-std                          | 117.86634    |
| Q_loss                         | 101.50509    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 488          |
| times/epoch_after_hook         | 1.63e-06     |
| times/epoch_before_hook        | 0.000128     |
| times/epoch_rollout_model      | 513          |
| times/evaluation_metrics       | 0.000536     |
| times/evaluation_paths         | 15           |
| times/timestep_after_hook      | 0.00368      |
| times/timestep_before_hook     | 0.0086       |
| times/train                    | 60.9         |
| timestep                       | 1000         |
| timesteps_total                | 489000       |
| train-steps                    | 489000       |
| training/Q/q1_loss             | 93.5362      |
| training/sac_pi/alpha          | 0.1619531    |
| training/sac_pi/alpha_loss     | -0.044547077 |
| training/sac_pi/logp_pi        | 3.661951     |
| training/sac_pi/pi_entropy     | 3.627007     |
| training/sac_pi/pi_global_norm | 1.7138528    |
| training/sac_pi/policy_loss    | -234.9365    |
| training/sac_pi/std            | 0.49396068   |
| training/sac_pi/valid_num      | 4998.0       |
| training/sac_Q/q1              | 228.38713    |
| training/sac_Q/q2              | 229.91324    |
| training/sac_Q/q2_loss         | 93.23301     |
| training/sac_Q/q_global_norm   | 258.83337    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15751433  |
| epoch                          | 489         |
| evaluation/episode-length-avg  | 861         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 563         |
| evaluation/episode-length-std  | 143         |
| evaluation/return-average      | 4040.9282   |
| evaluation/return-max          | 4735.674    |
| evaluation/return-min          | 2513.4163   |
| evaluation/return-std          | 735.98395   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 87.2        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46275       |
| perf/AverageLength             | 861         |
| perf/AverageReturn             | 4040.9282   |
| perf/NormalizedReturn          | 0.88        |
| Q-avg                          | 219.24223   |
| Q-std                          | 113.9176    |
| Q_loss                         | 93.43244    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 489         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000356    |
| times/epoch_rollout_model      | 522         |
| times/evaluation_metrics       | 0.0005      |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 60          |
| timestep                       | 1000        |
| timesteps_total                | 490000      |
| train-steps                    | 490000      |
| training/Q/q1_loss             | 121.24444   |
| training/sac_pi/alpha          | 0.15750535  |
| training/sac_pi/alpha_loss     | -0.24928491 |
| training/sac_pi/logp_pi        | 4.7593374   |
| training/sac_pi/pi_entropy     | 3.5745308   |
| training/sac_pi/pi_global_norm | 3.537485    |
| training/sac_pi/policy_loss    | -225.94273  |
| training/sac_pi/std            | 0.53871703  |
| training/sac_pi/valid_num      | 4946.0      |
| training/sac_Q/q1              | 208.85208   |
| training/sac_Q/q2              | 213.60457   |
| training/sac_Q/q2_loss         | 122.72256   |
| training/sac_Q/q_global_norm   | 272.60727   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15927348 |
| epoch                          | 490        |
| evaluation/episode-length-avg  | 909        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 578        |
| evaluation/episode-length-std  | 160        |
| evaluation/return-average      | 4329.573   |
| evaluation/return-max          | 4865.3174  |
| evaluation/return-min          | 2566.919   |
| evaluation/return-std          | 857.54877  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 79         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46547      |
| perf/AverageLength             | 909        |
| perf/AverageReturn             | 4329.573   |
| perf/NormalizedReturn          | 0.943      |
| Q-avg                          | 212.8593   |
| Q-std                          | 134.81947  |
| Q_loss                         | 114.896065 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 490        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000118   |
| times/epoch_rollout_model      | 506        |
| times/evaluation_metrics       | 0.000497   |
| times/evaluation_paths         | 32.1       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 491000     |
| train-steps                    | 491000     |
| training/Q/q1_loss             | 82.3438    |
| training/sac_pi/alpha          | 0.1592819  |
| training/sac_pi/alpha_loss     | 0.23943534 |
| training/sac_pi/logp_pi        | 5.048427   |
| training/sac_pi/pi_entropy     | 3.1886563  |
| training/sac_pi/pi_global_norm | 1.8403325  |
| training/sac_pi/policy_loss    | -230.28185 |
| training/sac_pi/std            | 0.48033956 |
| training/sac_pi/valid_num      | 4939.0     |
| training/sac_Q/q1              | 218.93887  |
| training/sac_Q/q2              | 222.14316  |
| training/sac_Q/q2_loss         | 80.50443   |
| training/sac_Q/q_global_norm   | 207.36786  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1605624  |
| epoch                          | 491        |
| evaluation/episode-length-avg  | 926        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 263        |
| evaluation/episode-length-std  | 221        |
| evaluation/return-average      | 4578.4644  |
| evaluation/return-max          | 5028.3574  |
| evaluation/return-min          | 972.3179   |
| evaluation/return-std          | 1202.2112  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46315      |
| perf/AverageLength             | 926        |
| perf/AverageReturn             | 4578.4644  |
| perf/NormalizedReturn          | 0.997      |
| Q-avg                          | 215.66574  |
| Q-std                          | 100.367195 |
| Q_loss                         | 103.49083  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 491        |
| times/epoch_after_hook         | 1.63e-06   |
| times/epoch_before_hook        | 0.000139   |
| times/epoch_rollout_model      | 512        |
| times/evaluation_metrics       | 0.000511   |
| times/evaluation_paths         | 33.8       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 492000     |
| train-steps                    | 492000     |
| training/Q/q1_loss             | 125.65009  |
| training/sac_pi/alpha          | 0.16055398 |
| training/sac_pi/alpha_loss     | 0.36375266 |
| training/sac_pi/logp_pi        | 4.2459245  |
| training/sac_pi/pi_entropy     | 3.2074642  |
| training/sac_pi/pi_global_norm | 2.6101944  |
| training/sac_pi/policy_loss    | -227.48186 |
| training/sac_pi/std            | 0.46511143 |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 219.74829  |
| training/sac_Q/q2              | 221.25952  |
| training/sac_Q/q2_loss         | 124.55384  |
| training/sac_Q/q_global_norm   | 256.1593   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1588098   |
| epoch                          | 492         |
| evaluation/episode-length-avg  | 916         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 165         |
| evaluation/episode-length-std  | 250         |
| evaluation/return-average      | 4530.8545   |
| evaluation/return-max          | 5020.488    |
| evaluation/return-min          | 528.2618    |
| evaluation/return-std          | 1334.5273   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46382       |
| perf/AverageLength             | 916         |
| perf/AverageReturn             | 4530.8545   |
| perf/NormalizedReturn          | 0.987       |
| Q-avg                          | 214.2178    |
| Q-std                          | 117.86601   |
| Q_loss                         | 103.962654  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 492         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000112    |
| times/epoch_rollout_model      | 508         |
| times/evaluation_metrics       | 0.000531    |
| times/evaluation_paths         | 33.3        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 493000      |
| train-steps                    | 493000      |
| training/Q/q1_loss             | 112.00412   |
| training/sac_pi/alpha          | 0.15884824  |
| training/sac_pi/alpha_loss     | -0.23690848 |
| training/sac_pi/logp_pi        | 3.773774    |
| training/sac_pi/pi_entropy     | 3.3340707   |
| training/sac_pi/pi_global_norm | 1.7729222   |
| training/sac_pi/policy_loss    | -222.84084  |
| training/sac_pi/std            | 0.4774033   |
| training/sac_pi/valid_num      | 4994.0      |
| training/sac_Q/q1              | 216.04927   |
| training/sac_Q/q2              | 217.4362    |
| training/sac_Q/q2_loss         | 111.274445  |
| training/sac_Q/q_global_norm   | 219.40016   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15998611 |
| epoch                          | 493        |
| evaluation/episode-length-avg  | 164        |
| evaluation/episode-length-max  | 167        |
| evaluation/episode-length-min  | 160        |
| evaluation/episode-length-std  | 2.2        |
| evaluation/return-average      | 526.24915  |
| evaluation/return-max          | 540.3511   |
| evaluation/return-min          | 509.70474  |
| evaluation/return-std          | 8.669486   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46423      |
| perf/AverageLength             | 164        |
| perf/AverageReturn             | 526.24915  |
| perf/NormalizedReturn          | 0.114      |
| Q-avg                          | 226.57864  |
| Q-std                          | 101.475685 |
| Q_loss                         | 100.36174  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 493        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000327   |
| times/epoch_rollout_model      | 509        |
| times/evaluation_metrics       | 0.0006     |
| times/evaluation_paths         | 5.73       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 494000     |
| train-steps                    | 494000     |
| training/Q/q1_loss             | 91.73779   |
| training/sac_pi/alpha          | 0.15998524 |
| training/sac_pi/alpha_loss     | 0.23128894 |
| training/sac_pi/logp_pi        | 3.766065   |
| training/sac_pi/pi_entropy     | 3.335939   |
| training/sac_pi/pi_global_norm | 1.994662   |
| training/sac_pi/policy_loss    | -227.16544 |
| training/sac_pi/std            | 0.4746935  |
| training/sac_pi/valid_num      | 5038.0     |
| training/sac_Q/q1              | 221.35799  |
| training/sac_Q/q2              | 221.8865   |
| training/sac_Q/q2_loss         | 91.69773   |
| training/sac_Q/q_global_norm   | 246.7138   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15855283  |
| epoch                          | 494         |
| evaluation/episode-length-avg  | 941         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 412         |
| evaluation/episode-length-std  | 176         |
| evaluation/return-average      | 4789.377    |
| evaluation/return-max          | 5168.6523   |
| evaluation/return-min          | 1790.606    |
| evaluation/return-std          | 1000.0123   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46562       |
| perf/AverageLength             | 941         |
| perf/AverageReturn             | 4789.377    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 222.1115    |
| Q-std                          | 111.04259   |
| Q_loss                         | 96.727104   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 494         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 524         |
| times/evaluation_metrics       | 0.000654    |
| times/evaluation_paths         | 33.3        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00857     |
| times/train                    | 62.9        |
| timestep                       | 1000        |
| timesteps_total                | 495000      |
| train-steps                    | 495000      |
| training/Q/q1_loss             | 102.08944   |
| training/sac_pi/alpha          | 0.15856954  |
| training/sac_pi/alpha_loss     | -0.28359282 |
| training/sac_pi/logp_pi        | 4.4726233   |
| training/sac_pi/pi_entropy     | 3.468132    |
| training/sac_pi/pi_global_norm | 2.0027926   |
| training/sac_pi/policy_loss    | -229.14967  |
| training/sac_pi/std            | 0.5130266   |
| training/sac_pi/valid_num      | 4890.0      |
| training/sac_Q/q1              | 216.51633   |
| training/sac_Q/q2              | 220.21553   |
| training/sac_Q/q2_loss         | 103.25299   |
| training/sac_Q/q_global_norm   | 249.50568   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1654504  |
| epoch                          | 495        |
| evaluation/episode-length-avg  | 956        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 561        |
| evaluation/episode-length-std  | 132        |
| evaluation/return-average      | 4939.966   |
| evaluation/return-max          | 5280.8877  |
| evaluation/return-min          | 2627.8406  |
| evaluation/return-std          | 771.5588   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46415      |
| perf/AverageLength             | 956        |
| perf/AverageReturn             | 4939.966   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 219.26718  |
| Q-std                          | 113.40774  |
| Q_loss                         | 96.44167   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 495        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000148   |
| times/epoch_rollout_model      | 531        |
| times/evaluation_metrics       | 0.000661   |
| times/evaluation_paths         | 33.2       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00867    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 496000     |
| train-steps                    | 496000     |
| training/Q/q1_loss             | 103.275635 |
| training/sac_pi/alpha          | 0.16542882 |
| training/sac_pi/alpha_loss     | 0.1810116  |
| training/sac_pi/logp_pi        | 3.8195648  |
| training/sac_pi/pi_entropy     | 3.528502   |
| training/sac_pi/pi_global_norm | 1.6033932  |
| training/sac_pi/policy_loss    | -223.59267 |
| training/sac_pi/std            | 0.48774993 |
| training/sac_pi/valid_num      | 5003.0     |
| training/sac_Q/q1              | 215.89188  |
| training/sac_Q/q2              | 216.98604  |
| training/sac_Q/q2_loss         | 102.66887  |
| training/sac_Q/q_global_norm   | 236.13481  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16095266  |
| epoch                          | 496         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5121.7505   |
| evaluation/return-max          | 5267.574    |
| evaluation/return-min          | 4990.034    |
| evaluation/return-std          | 91.56692    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46415       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5121.7505   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 217.0324    |
| Q-std                          | 109.611115  |
| Q_loss                         | 105.3833    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 496         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 518         |
| times/evaluation_metrics       | 0.000645    |
| times/evaluation_paths         | 36.5        |
| times/timestep_after_hook      | 0.00352     |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 497000      |
| train-steps                    | 497000      |
| training/Q/q1_loss             | 86.61271    |
| training/sac_pi/alpha          | 0.16095181  |
| training/sac_pi/alpha_loss     | -0.07602067 |
| training/sac_pi/logp_pi        | 4.5176644   |
| training/sac_pi/pi_entropy     | 3.2419808   |
| training/sac_pi/pi_global_norm | 1.9309099   |
| training/sac_pi/policy_loss    | -229.4431   |
| training/sac_pi/std            | 0.50639975  |
| training/sac_pi/valid_num      | 4967.0      |
| training/sac_Q/q1              | 215.56123   |
| training/sac_Q/q2              | 217.03638   |
| training/sac_Q/q2_loss         | 87.21561    |
| training/sac_Q/q_global_norm   | 226.31317   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16122238 |
| epoch                          | 497        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5199.3     |
| evaluation/return-max          | 5261.71    |
| evaluation/return-min          | 5140.1914  |
| evaluation/return-std          | 40.29361   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46550      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5199.3     |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 219.85806  |
| Q-std                          | 108.54265  |
| Q_loss                         | 88.343735  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 497        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.00032    |
| times/epoch_rollout_model      | 517        |
| times/evaluation_metrics       | 0.000555   |
| times/evaluation_paths         | 46.9       |
| times/timestep_after_hook      | 0.00388    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 498000     |
| train-steps                    | 498000     |
| training/Q/q1_loss             | 92.36188   |
| training/sac_pi/alpha          | 0.16123499 |
| training/sac_pi/alpha_loss     | 0.11912753 |
| training/sac_pi/logp_pi        | 4.477003   |
| training/sac_pi/pi_entropy     | 3.4260452  |
| training/sac_pi/pi_global_norm | 1.7424055  |
| training/sac_pi/policy_loss    | -220.28517 |
| training/sac_pi/std            | 0.50593925 |
| training/sac_pi/valid_num      | 4986.0     |
| training/sac_Q/q1              | 210.48282  |
| training/sac_Q/q2              | 213.31723  |
| training/sac_Q/q2_loss         | 92.418274  |
| training/sac_Q/q_global_norm   | 224.08362  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16102923  |
| epoch                          | 498         |
| evaluation/episode-length-avg  | 917         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 169         |
| evaluation/episode-length-std  | 249         |
| evaluation/return-average      | 4526.7964   |
| evaluation/return-max          | 5163.3145   |
| evaluation/return-min          | 515.39453   |
| evaluation/return-std          | 1339.5107   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.15        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46424       |
| perf/AverageLength             | 917         |
| perf/AverageReturn             | 4526.7964   |
| perf/NormalizedReturn          | 0.986       |
| Q-avg                          | 217.429     |
| Q-std                          | 115.01396   |
| Q_loss                         | 111.51015   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 498         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000512    |
| times/evaluation_paths         | 33.5        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00829     |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 499000      |
| train-steps                    | 499000      |
| training/Q/q1_loss             | 71.75065    |
| training/sac_pi/alpha          | 0.16104801  |
| training/sac_pi/alpha_loss     | -0.11118197 |
| training/sac_pi/logp_pi        | 3.9073608   |
| training/sac_pi/pi_entropy     | 3.1765163   |
| training/sac_pi/pi_global_norm | 1.521718    |
| training/sac_pi/policy_loss    | -229.83315  |
| training/sac_pi/std            | 0.4584177   |
| training/sac_pi/valid_num      | 4997.0      |
| training/sac_Q/q1              | 220.30566   |
| training/sac_Q/q2              | 223.23906   |
| training/sac_Q/q2_loss         | 71.49556    |
| training/sac_Q/q_global_norm   | 188.85037   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15885983  |
| epoch                          | 499         |
| evaluation/episode-length-avg  | 876         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 327         |
| evaluation/episode-length-std  | 248         |
| evaluation/return-average      | 4242.2627   |
| evaluation/return-max          | 4991.534    |
| evaluation/return-min          | 1270.3743   |
| evaluation/return-std          | 1361.4816   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46515       |
| perf/AverageLength             | 876         |
| perf/AverageReturn             | 4242.2627   |
| perf/NormalizedReturn          | 0.924       |
| Q-avg                          | 222.54964   |
| Q-std                          | 97.48693    |
| Q_loss                         | 98.42218    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 499         |
| times/epoch_after_hook         | 1.89e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 537         |
| times/evaluation_metrics       | 0.000534    |
| times/evaluation_paths         | 31.2        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00853     |
| times/train                    | 62.3        |
| timestep                       | 1000        |
| timesteps_total                | 500000      |
| train-steps                    | 500000      |
| training/Q/q1_loss             | 94.13594    |
| training/sac_pi/alpha          | 0.1588347   |
| training/sac_pi/alpha_loss     | -0.16916619 |
| training/sac_pi/logp_pi        | 3.498324    |
| training/sac_pi/pi_entropy     | 3.2922416   |
| training/sac_pi/pi_global_norm | 2.1381378   |
| training/sac_pi/policy_loss    | -232.12468  |
| training/sac_pi/std            | 0.4685641   |
| training/sac_pi/valid_num      | 4975.0      |
| training/sac_Q/q1              | 224.43965   |
| training/sac_Q/q2              | 226.6595    |
| training/sac_Q/q2_loss         | 94.101074   |
| training/sac_Q/q_global_norm   | 239.00458   |
---------------------------------------------------------------------------------
[WARN] 500 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.15941314   |
| epoch                          | 500          |
| evaluation/episode-length-avg  | 166          |
| evaluation/episode-length-max  | 170          |
| evaluation/episode-length-min  | 163          |
| evaluation/episode-length-std  | 2.19         |
| evaluation/return-average      | 537.81024    |
| evaluation/return-max          | 553.82654    |
| evaluation/return-min          | 526.1316     |
| evaluation/return-std          | 8.73796      |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.11         |
| model/origin_ret               | 85.3         |
| model/penalty_ret              | 79.4         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46395        |
| perf/AverageLength             | 166          |
| perf/AverageReturn             | 537.81024    |
| perf/NormalizedReturn          | 0.117        |
| Q-avg                          | 215.23955    |
| Q-std                          | 126.12934    |
| Q_loss                         | 107.34459    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 500          |
| times/epoch_after_hook         | 1.8e-06      |
| times/epoch_before_hook        | 0.000126     |
| times/epoch_rollout_model      | 539          |
| times/evaluation_metrics       | 0.000464     |
| times/evaluation_paths         | 7.84         |
| times/timestep_after_hook      | 0.00366      |
| times/timestep_before_hook     | 0.00839      |
| times/train                    | 61.8         |
| timestep                       | 1000         |
| timesteps_total                | 501000       |
| train-steps                    | 501000       |
| training/Q/q1_loss             | 90.10014     |
| training/sac_pi/alpha          | 0.15940972   |
| training/sac_pi/alpha_loss     | -0.016930243 |
| training/sac_pi/logp_pi        | 3.4708946    |
| training/sac_pi/pi_entropy     | 3.2816825    |
| training/sac_pi/pi_global_norm | 2.36952      |
| training/sac_pi/policy_loss    | -229.78343   |
| training/sac_pi/std            | 0.4498084    |
| training/sac_pi/valid_num      | 5052.0       |
| training/sac_Q/q1              | 226.46619    |
| training/sac_Q/q2              | 227.50444    |
| training/sac_Q/q2_loss         | 90.40663     |
| training/sac_Q/q_global_norm   | 221.8633     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16518924 |
| epoch                          | 501        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4906.0283  |
| evaluation/return-max          | 4979.9756  |
| evaluation/return-min          | 4856.893   |
| evaluation/return-std          | 42.698475  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 78.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46310      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4906.0283  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 222.50134  |
| Q-std                          | 95.8399    |
| Q_loss                         | 91.51849   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 501        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000327   |
| times/epoch_rollout_model      | 505        |
| times/evaluation_metrics       | 0.000606   |
| times/evaluation_paths         | 44.1       |
| times/timestep_after_hook      | 0.00356    |
| times/timestep_before_hook     | 0.00846    |
| times/train                    | 66.8       |
| timestep                       | 1000       |
| timesteps_total                | 502000     |
| train-steps                    | 502000     |
| training/Q/q1_loss             | 102.39007  |
| training/sac_pi/alpha          | 0.16515686 |
| training/sac_pi/alpha_loss     | 0.90392953 |
| training/sac_pi/logp_pi        | 4.336644   |
| training/sac_pi/pi_entropy     | 3.3724027  |
| training/sac_pi/pi_global_norm | 1.7493217  |
| training/sac_pi/policy_loss    | -225.1512  |
| training/sac_pi/std            | 0.47518304 |
| training/sac_pi/valid_num      | 4999.0     |
| training/sac_Q/q1              | 217.84819  |
| training/sac_Q/q2              | 218.84082  |
| training/sac_Q/q2_loss         | 102.63166  |
| training/sac_Q/q_global_norm   | 189.02888  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15955983  |
| epoch                          | 502         |
| evaluation/episode-length-avg  | 936         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 365         |
| evaluation/episode-length-std  | 190         |
| evaluation/return-average      | 4646.409    |
| evaluation/return-max          | 5053.305    |
| evaluation/return-min          | 1518.8474   |
| evaluation/return-std          | 1043.8276   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46487       |
| perf/AverageLength             | 936         |
| perf/AverageReturn             | 4646.409    |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 225.28983   |
| Q-std                          | 117.05377   |
| Q_loss                         | 88.839485   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 502         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 516         |
| times/evaluation_metrics       | 0.000543    |
| times/evaluation_paths         | 32          |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 60.4        |
| timestep                       | 1000        |
| timesteps_total                | 503000      |
| train-steps                    | 503000      |
| training/Q/q1_loss             | 78.4165     |
| training/sac_pi/alpha          | 0.15958117  |
| training/sac_pi/alpha_loss     | -0.44021338 |
| training/sac_pi/logp_pi        | 4.1135125   |
| training/sac_pi/pi_entropy     | 3.3945649   |
| training/sac_pi/pi_global_norm | 1.9110061   |
| training/sac_pi/policy_loss    | -232.5668   |
| training/sac_pi/std            | 0.5010095   |
| training/sac_pi/valid_num      | 4887.0      |
| training/sac_Q/q1              | 217.38712   |
| training/sac_Q/q2              | 218.51474   |
| training/sac_Q/q2_loss         | 78.10762    |
| training/sac_Q/q_global_norm   | 250.28387   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16530098  |
| epoch                          | 503         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5144.208    |
| evaluation/return-max          | 5235.8647   |
| evaluation/return-min          | 5009.082    |
| evaluation/return-std          | 82.46885    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46304       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5144.208    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 217.05098   |
| Q-std                          | 131.54025   |
| Q_loss                         | 87.74589    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 503         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 509         |
| times/evaluation_metrics       | 0.000605    |
| times/evaluation_paths         | 34.2        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00863     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 504000      |
| train-steps                    | 504000      |
| training/Q/q1_loss             | 67.4046     |
| training/sac_pi/alpha          | 0.16531812  |
| training/sac_pi/alpha_loss     | -0.45419383 |
| training/sac_pi/logp_pi        | 4.4476256   |
| training/sac_pi/pi_entropy     | 3.5041656   |
| training/sac_pi/pi_global_norm | 1.5699705   |
| training/sac_pi/policy_loss    | -232.8828   |
| training/sac_pi/std            | 0.5123279   |
| training/sac_pi/valid_num      | 4938.0      |
| training/sac_Q/q1              | 218.36475   |
| training/sac_Q/q2              | 222.02951   |
| training/sac_Q/q2_loss         | 68.55645    |
| training/sac_Q/q_global_norm   | 237.43094   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1618131   |
| epoch                          | 504         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5031.3037   |
| evaluation/return-max          | 5073.459    |
| evaluation/return-min          | 4911.543    |
| evaluation/return-std          | 45.1189     |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46446       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5031.3037   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 227.93774   |
| Q-std                          | 106.800995  |
| Q_loss                         | 109.3295    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 504         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 516         |
| times/evaluation_metrics       | 0.000616    |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00848     |
| times/train                    | 59.4        |
| timestep                       | 1000        |
| timesteps_total                | 505000      |
| train-steps                    | 505000      |
| training/Q/q1_loss             | 98.379745   |
| training/sac_pi/alpha          | 0.16183461  |
| training/sac_pi/alpha_loss     | -0.32355332 |
| training/sac_pi/logp_pi        | 4.275833    |
| training/sac_pi/pi_entropy     | 3.3032956   |
| training/sac_pi/pi_global_norm | 1.7583086   |
| training/sac_pi/policy_loss    | -230.0234   |
| training/sac_pi/std            | 0.4883009   |
| training/sac_pi/valid_num      | 4944.0      |
| training/sac_Q/q1              | 220.14038   |
| training/sac_Q/q2              | 222.14336   |
| training/sac_Q/q2_loss         | 97.75619    |
| training/sac_Q/q_global_norm   | 307.89355   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16432959  |
| epoch                          | 505         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4908.923    |
| evaluation/return-max          | 5015.3823   |
| evaluation/return-min          | 4756.5894   |
| evaluation/return-std          | 81.137344   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 84.3        |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46301       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4908.923    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 214.53178   |
| Q-std                          | 145.06068   |
| Q_loss                         | 104.535164  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 505         |
| times/epoch_after_hook         | 2.05e-06    |
| times/epoch_before_hook        | 0.000272    |
| times/epoch_rollout_model      | 518         |
| times/evaluation_metrics       | 0.000743    |
| times/evaluation_paths         | 43.9        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 68          |
| timestep                       | 1000        |
| timesteps_total                | 506000      |
| train-steps                    | 506000      |
| training/Q/q1_loss             | 118.34638   |
| training/sac_pi/alpha          | 0.16435611  |
| training/sac_pi/alpha_loss     | 0.089316905 |
| training/sac_pi/logp_pi        | 3.6723557   |
| training/sac_pi/pi_entropy     | 3.441106    |
| training/sac_pi/pi_global_norm | 2.3207567   |
| training/sac_pi/policy_loss    | -234.98012  |
| training/sac_pi/std            | 0.47884622  |
| training/sac_pi/valid_num      | 4992.0      |
| training/sac_Q/q1              | 229.36186   |
| training/sac_Q/q2              | 229.51956   |
| training/sac_Q/q2_loss         | 117.94418   |
| training/sac_Q/q_global_norm   | 312.3772    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1681754   |
| epoch                          | 506         |
| evaluation/episode-length-avg  | 847         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 151         |
| evaluation/episode-length-std  | 309         |
| evaluation/return-average      | 4102.6685   |
| evaluation/return-max          | 5142.936    |
| evaluation/return-min          | 355.77606   |
| evaluation/return-std          | 1690.2858   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46362       |
| perf/AverageLength             | 847         |
| perf/AverageReturn             | 4102.6685   |
| perf/NormalizedReturn          | 0.893       |
| Q-avg                          | 209.37715   |
| Q-std                          | 159.95494   |
| Q_loss                         | 105.35608   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 506         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 508         |
| times/evaluation_metrics       | 0.000618    |
| times/evaluation_paths         | 29.5        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 507000      |
| train-steps                    | 507000      |
| training/Q/q1_loss             | 127.83487   |
| training/sac_pi/alpha          | 0.16818158  |
| training/sac_pi/alpha_loss     | -0.15540206 |
| training/sac_pi/logp_pi        | 3.5545774   |
| training/sac_pi/pi_entropy     | 3.482367    |
| training/sac_pi/pi_global_norm | 2.0196693   |
| training/sac_pi/policy_loss    | -234.80273  |
| training/sac_pi/std            | 0.4799108   |
| training/sac_pi/valid_num      | 5032.0      |
| training/sac_Q/q1              | 229.38965   |
| training/sac_Q/q2              | 230.5212    |
| training/sac_Q/q2_loss         | 127.99454   |
| training/sac_Q/q_global_norm   | 284.87115   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16579798  |
| epoch                          | 507         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4908.534    |
| evaluation/return-max          | 4959.465    |
| evaluation/return-min          | 4846.8076   |
| evaluation/return-std          | 35.44649    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46368       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4908.534    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 221.67134   |
| Q-std                          | 121.08141   |
| Q_loss                         | 89.48136    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 507         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 500         |
| times/evaluation_metrics       | 0.000853    |
| times/evaluation_paths         | 36.3        |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.00872     |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 508000      |
| train-steps                    | 508000      |
| training/Q/q1_loss             | 110.38765   |
| training/sac_pi/alpha          | 0.16586578  |
| training/sac_pi/alpha_loss     | -0.32500148 |
| training/sac_pi/logp_pi        | 4.058538    |
| training/sac_pi/pi_entropy     | 3.65717     |
| training/sac_pi/pi_global_norm | 2.156741    |
| training/sac_pi/policy_loss    | -219.02727  |
| training/sac_pi/std            | 0.53666025  |
| training/sac_pi/valid_num      | 4951.0      |
| training/sac_Q/q1              | 206.21724   |
| training/sac_Q/q2              | 207.11353   |
| training/sac_Q/q2_loss         | 110.267685  |
| training/sac_Q/q_global_norm   | 282.6493    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16787818  |
| epoch                          | 508         |
| evaluation/episode-length-avg  | 912         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 606         |
| evaluation/episode-length-std  | 143         |
| evaluation/return-average      | 4615.083    |
| evaluation/return-max          | 5166.8633   |
| evaluation/return-min          | 2835.8247   |
| evaluation/return-std          | 822.3895    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46466       |
| perf/AverageLength             | 912         |
| perf/AverageReturn             | 4615.083    |
| perf/NormalizedReturn          | 1           |
| Q-avg                          | 215.13506   |
| Q-std                          | 103.157906  |
| Q_loss                         | 118.813805  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 508         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000155    |
| times/epoch_rollout_model      | 513         |
| times/evaluation_metrics       | 0.000521    |
| times/evaluation_paths         | 31.5        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 509000      |
| train-steps                    | 509000      |
| training/Q/q1_loss             | 87.769066   |
| training/sac_pi/alpha          | 0.16790518  |
| training/sac_pi/alpha_loss     | -0.22781654 |
| training/sac_pi/logp_pi        | 3.9707665   |
| training/sac_pi/pi_entropy     | 3.6486924   |
| training/sac_pi/pi_global_norm | 2.997908    |
| training/sac_pi/policy_loss    | -226.47746  |
| training/sac_pi/std            | 0.5133998   |
| training/sac_pi/valid_num      | 4947.0      |
| training/sac_Q/q1              | 216.02441   |
| training/sac_Q/q2              | 218.00174   |
| training/sac_Q/q2_loss         | 87.252075   |
| training/sac_Q/q_global_norm   | 203.08852   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16992685  |
| epoch                          | 509         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4978.6177   |
| evaluation/return-max          | 5068.2812   |
| evaluation/return-min          | 4862.857    |
| evaluation/return-std          | 56.437992   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 80.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46607       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4978.6177   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 223.74968   |
| Q-std                          | 115.175255  |
| Q_loss                         | 102.76227   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 509         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.00033     |
| times/epoch_rollout_model      | 521         |
| times/evaluation_metrics       | 0.000519    |
| times/evaluation_paths         | 39.4        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00881     |
| times/train                    | 73.2        |
| timestep                       | 1000        |
| timesteps_total                | 510000      |
| train-steps                    | 510000      |
| training/Q/q1_loss             | 83.55987    |
| training/sac_pi/alpha          | 0.1699625   |
| training/sac_pi/alpha_loss     | -0.30905336 |
| training/sac_pi/logp_pi        | 3.8417993   |
| training/sac_pi/pi_entropy     | 3.4609323   |
| training/sac_pi/pi_global_norm | 2.2011414   |
| training/sac_pi/policy_loss    | -240.3511   |
| training/sac_pi/std            | 0.49121326  |
| training/sac_pi/valid_num      | 5011.0      |
| training/sac_Q/q1              | 234.97275   |
| training/sac_Q/q2              | 235.67082   |
| training/sac_Q/q2_loss         | 83.98977    |
| training/sac_Q/q_global_norm   | 230.0013    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16927789 |
| epoch                          | 510        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4908.329   |
| evaluation/return-max          | 4996.588   |
| evaluation/return-min          | 4810.64    |
| evaluation/return-std          | 63.64028   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46374      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4908.329   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 217.22368  |
| Q-std                          | 97.13685   |
| Q_loss                         | 99.59924   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 510        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000117   |
| times/epoch_rollout_model      | 517        |
| times/evaluation_metrics       | 0.000687   |
| times/evaluation_paths         | 47         |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00857    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 511000     |
| train-steps                    | 511000     |
| training/Q/q1_loss             | 113.84261  |
| training/sac_pi/alpha          | 0.16930914 |
| training/sac_pi/alpha_loss     | 0.05975768 |
| training/sac_pi/logp_pi        | 4.2569     |
| training/sac_pi/pi_entropy     | 3.5378463  |
| training/sac_pi/pi_global_norm | 1.6875696  |
| training/sac_pi/policy_loss    | -220.44713 |
| training/sac_pi/std            | 0.5070226  |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 212.60625  |
| training/sac_Q/q2              | 215.4753   |
| training/sac_Q/q2_loss         | 112.66075  |
| training/sac_Q/q_global_norm   | 262.52744  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16464236 |
| epoch                          | 511        |
| evaluation/episode-length-avg  | 834        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 158        |
| evaluation/episode-length-std  | 333        |
| evaluation/return-average      | 4210.4497  |
| evaluation/return-max          | 5172.8135  |
| evaluation/return-min          | 485.91687  |
| evaluation/return-std          | 1842.9911  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46387      |
| perf/AverageLength             | 834        |
| perf/AverageReturn             | 4210.4497  |
| perf/NormalizedReturn          | 0.917      |
| Q-avg                          | 219.71411  |
| Q-std                          | 142.62381  |
| Q_loss                         | 117.36951  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 511        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000151   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000574   |
| times/evaluation_paths         | 39.1       |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 62.2       |
| timestep                       | 1000       |
| timesteps_total                | 512000     |
| train-steps                    | 512000     |
| training/Q/q1_loss             | 100.59473  |
| training/sac_pi/alpha          | 0.16464475 |
| training/sac_pi/alpha_loss     | -0.1585152 |
| training/sac_pi/logp_pi        | 3.8175042  |
| training/sac_pi/pi_entropy     | 3.3994095  |
| training/sac_pi/pi_global_norm | 2.1993756  |
| training/sac_pi/policy_loss    | -225.43639 |
| training/sac_pi/std            | 0.49373707 |
| training/sac_pi/valid_num      | 4971.0     |
| training/sac_Q/q1              | 218.05864  |
| training/sac_Q/q2              | 219.27148  |
| training/sac_Q/q2_loss         | 101.92291  |
| training/sac_Q/q_global_norm   | 265.66818  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16450776  |
| epoch                          | 512         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4981.958    |
| evaluation/return-max          | 5042.6865   |
| evaluation/return-min          | 4936.6904   |
| evaluation/return-std          | 31.597652   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46408       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4981.958    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 221.78333   |
| Q-std                          | 102.52011   |
| Q_loss                         | 103.0455    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 512         |
| times/epoch_after_hook         | 3.14e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 517         |
| times/evaluation_metrics       | 0.000533    |
| times/evaluation_paths         | 45.9        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 63.7        |
| timestep                       | 1000        |
| timesteps_total                | 513000      |
| train-steps                    | 513000      |
| training/Q/q1_loss             | 99.87779    |
| training/sac_pi/alpha          | 0.16454622  |
| training/sac_pi/alpha_loss     | -0.15552825 |
| training/sac_pi/logp_pi        | 3.9074852   |
| training/sac_pi/pi_entropy     | 3.3631072   |
| training/sac_pi/pi_global_norm | 2.0541995   |
| training/sac_pi/policy_loss    | -227.70029  |
| training/sac_pi/std            | 0.49897054  |
| training/sac_pi/valid_num      | 4969.0      |
| training/sac_Q/q1              | 216.58206   |
| training/sac_Q/q2              | 219.576     |
| training/sac_Q/q2_loss         | 99.99527    |
| training/sac_Q/q_global_norm   | 262.31723   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16669188 |
| epoch                          | 513        |
| evaluation/episode-length-avg  | 876        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 141        |
| evaluation/episode-length-std  | 270        |
| evaluation/return-average      | 4625.582   |
| evaluation/return-max          | 5377.089   |
| evaluation/return-min          | 386.6115   |
| evaluation/return-std          | 1579.7032  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46395      |
| perf/AverageLength             | 876        |
| perf/AverageReturn             | 4625.582   |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 224.26094  |
| Q-std                          | 120.464424 |
| Q_loss                         | 78.57469   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 513        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000324   |
| times/epoch_rollout_model      | 511        |
| times/evaluation_metrics       | 0.000584   |
| times/evaluation_paths         | 32.6       |
| times/timestep_after_hook      | 0.00355    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 514000     |
| train-steps                    | 514000     |
| training/Q/q1_loss             | 102.238945 |
| training/sac_pi/alpha          | 0.16671123 |
| training/sac_pi/alpha_loss     | 0.1980316  |
| training/sac_pi/logp_pi        | 3.6368523  |
| training/sac_pi/pi_entropy     | 3.3805416  |
| training/sac_pi/pi_global_norm | 1.6114737  |
| training/sac_pi/policy_loss    | -224.81009 |
| training/sac_pi/std            | 0.4664489  |
| training/sac_pi/valid_num      | 5042.0     |
| training/sac_Q/q1              | 220.60263  |
| training/sac_Q/q2              | 221.50009  |
| training/sac_Q/q2_loss         | 102.59433  |
| training/sac_Q/q_global_norm   | 235.92668  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16633773 |
| epoch                          | 514        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4579.874   |
| evaluation/return-max          | 4606.8223  |
| evaluation/return-min          | 4533.2334  |
| evaluation/return-std          | 28.969963  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46400      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4579.874   |
| perf/NormalizedReturn          | 0.997      |
| Q-avg                          | 221.05928  |
| Q-std                          | 111.04325  |
| Q_loss                         | 101.673225 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 514        |
| times/epoch_after_hook         | 1.62e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 521        |
| times/evaluation_metrics       | 0.00054    |
| times/evaluation_paths         | 41.3       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 71         |
| timestep                       | 1000       |
| timesteps_total                | 515000     |
| train-steps                    | 515000     |
| training/Q/q1_loss             | 117.34525  |
| training/sac_pi/alpha          | 0.16632578 |
| training/sac_pi/alpha_loss     | 0.13523409 |
| training/sac_pi/logp_pi        | 3.9893692  |
| training/sac_pi/pi_entropy     | 3.4748535  |
| training/sac_pi/pi_global_norm | 1.8122886  |
| training/sac_pi/policy_loss    | -223.28174 |
| training/sac_pi/std            | 0.49760908 |
| training/sac_pi/valid_num      | 5013.0     |
| training/sac_Q/q1              | 217.0512   |
| training/sac_Q/q2              | 218.07095  |
| training/sac_Q/q2_loss         | 115.89279  |
| training/sac_Q/q_global_norm   | 258.06567  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16519192 |
| epoch                          | 515        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4534.449   |
| evaluation/return-max          | 4697.4316  |
| evaluation/return-min          | 4423.2354  |
| evaluation/return-std          | 86.11151   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.19       |
| model/origin_ret               | 86.8       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46461      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4534.449   |
| perf/NormalizedReturn          | 0.987      |
| Q-avg                          | 210.05168  |
| Q-std                          | 129.26424  |
| Q_loss                         | 128.1638   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 515        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000119   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.000518   |
| times/evaluation_paths         | 46.7       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 65.5       |
| timestep                       | 1000       |
| timesteps_total                | 516000     |
| train-steps                    | 516000     |
| training/Q/q1_loss             | 100.956116 |
| training/sac_pi/alpha          | 0.16515526 |
| training/sac_pi/alpha_loss     | 0.48029476 |
| training/sac_pi/logp_pi        | 4.158614   |
| training/sac_pi/pi_entropy     | 3.4384556  |
| training/sac_pi/pi_global_norm | 2.0120237  |
| training/sac_pi/policy_loss    | -226.14366 |
| training/sac_pi/std            | 0.50208944 |
| training/sac_pi/valid_num      | 5005.0     |
| training/sac_Q/q1              | 221.15938  |
| training/sac_Q/q2              | 221.6331   |
| training/sac_Q/q2_loss         | 101.64934  |
| training/sac_Q/q_global_norm   | 234.77617  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16288581 |
| epoch                          | 516        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5034.2744  |
| evaluation/return-max          | 5059.135   |
| evaluation/return-min          | 5007.106   |
| evaluation/return-std          | 18.137724  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46348      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5034.2744  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 223.60344  |
| Q-std                          | 97.88499   |
| Q_loss                         | 99.95867   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 516        |
| times/epoch_after_hook         | 1.61e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 520        |
| times/evaluation_metrics       | 0.000516   |
| times/evaluation_paths         | 43.3       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 70.7       |
| timestep                       | 1000       |
| timesteps_total                | 517000     |
| train-steps                    | 517000     |
| training/Q/q1_loss             | 87.717545  |
| training/sac_pi/alpha          | 0.16286464 |
| training/sac_pi/alpha_loss     | -0.101898  |
| training/sac_pi/logp_pi        | 4.441649   |
| training/sac_pi/pi_entropy     | 3.4290376  |
| training/sac_pi/pi_global_norm | 1.5079736  |
| training/sac_pi/policy_loss    | -226.67543 |
| training/sac_pi/std            | 0.50448805 |
| training/sac_pi/valid_num      | 4913.0     |
| training/sac_Q/q1              | 211.83017  |
| training/sac_Q/q2              | 213.25583  |
| training/sac_Q/q2_loss         | 87.86684   |
| training/sac_Q/q_global_norm   | 279.182    |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1609071  |
| epoch                          | 517        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4941.526   |
| evaluation/return-max          | 4966.09    |
| evaluation/return-min          | 4870.605   |
| evaluation/return-std          | 27.255686  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.18       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46477      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4941.526   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 226.24545  |
| Q-std                          | 110.05108  |
| Q_loss                         | 90.075935  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 517        |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.000585   |
| times/epoch_rollout_model      | 510        |
| times/evaluation_metrics       | 0.000529   |
| times/evaluation_paths         | 37.1       |
| times/timestep_after_hook      | 0.00344    |
| times/timestep_before_hook     | 0.00863    |
| times/train                    | 59.4       |
| timestep                       | 1000       |
| timesteps_total                | 518000     |
| train-steps                    | 518000     |
| training/Q/q1_loss             | 106.067245 |
| training/sac_pi/alpha          | 0.16091862 |
| training/sac_pi/alpha_loss     | -0.5216381 |
| training/sac_pi/logp_pi        | 4.509223   |
| training/sac_pi/pi_entropy     | 3.5136178  |
| training/sac_pi/pi_global_norm | 1.659406   |
| training/sac_pi/policy_loss    | -217.92433 |
| training/sac_pi/std            | 0.52924204 |
| training/sac_pi/valid_num      | 4911.0     |
| training/sac_Q/q1              | 206.31052  |
| training/sac_Q/q2              | 209.13396  |
| training/sac_Q/q2_loss         | 104.58565  |
| training/sac_Q/q_global_norm   | 221.35225  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15767135 |
| epoch                          | 518        |
| evaluation/episode-length-avg  | 326        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 152        |
| evaluation/episode-length-std  | 337        |
| evaluation/return-average      | 1381.144   |
| evaluation/return-max          | 4979.7793  |
| evaluation/return-min          | 468.50977  |
| evaluation/return-std          | 1781.9292  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46509      |
| perf/AverageLength             | 326        |
| perf/AverageReturn             | 1381.144   |
| perf/NormalizedReturn          | 0.301      |
| Q-avg                          | 215.72     |
| Q-std                          | 115.52167  |
| Q_loss                         | 99.33376   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 518        |
| times/epoch_after_hook         | 1.61e-06   |
| times/epoch_before_hook        | 0.000117   |
| times/epoch_rollout_model      | 516        |
| times/evaluation_metrics       | 0.000464   |
| times/evaluation_paths         | 15.2       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 69.8       |
| timestep                       | 1000       |
| timesteps_total                | 519000     |
| train-steps                    | 519000     |
| training/Q/q1_loss             | 112.47032  |
| training/sac_pi/alpha          | 0.1576529  |
| training/sac_pi/alpha_loss     | 0.11403355 |
| training/sac_pi/logp_pi        | 4.71887    |
| training/sac_pi/pi_entropy     | 3.439817   |
| training/sac_pi/pi_global_norm | 2.098536   |
| training/sac_pi/policy_loss    | -220.44173 |
| training/sac_pi/std            | 0.5199122  |
| training/sac_pi/valid_num      | 4888.0     |
| training/sac_Q/q1              | 205.64761  |
| training/sac_Q/q2              | 207.58823  |
| training/sac_Q/q2_loss         | 111.918335 |
| training/sac_Q/q_global_norm   | 284.1358   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16504571 |
| epoch                          | 519        |
| evaluation/episode-length-avg  | 415        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 159        |
| evaluation/episode-length-std  | 383        |
| evaluation/return-average      | 1937.8018  |
| evaluation/return-max          | 5283.883   |
| evaluation/return-min          | 505.8853   |
| evaluation/return-std          | 2156.412   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46432      |
| perf/AverageLength             | 415        |
| perf/AverageReturn             | 1937.8018  |
| perf/NormalizedReturn          | 0.422      |
| Q-avg                          | 221.89275  |
| Q-std                          | 103.4761   |
| Q_loss                         | 88.24254   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 519        |
| times/epoch_after_hook         | 1.87e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.00108    |
| times/evaluation_paths         | 20.1       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00854    |
| times/train                    | 63.8       |
| timestep                       | 1000       |
| timesteps_total                | 520000     |
| train-steps                    | 520000     |
| training/Q/q1_loss             | 115.43512  |
| training/sac_pi/alpha          | 0.16504145 |
| training/sac_pi/alpha_loss     | 0.20180729 |
| training/sac_pi/logp_pi        | 5.1483383  |
| training/sac_pi/pi_entropy     | 3.2850037  |
| training/sac_pi/pi_global_norm | 1.9373682  |
| training/sac_pi/policy_loss    | -221.1153  |
| training/sac_pi/std            | 0.49810225 |
| training/sac_pi/valid_num      | 4906.0     |
| training/sac_Q/q1              | 207.58984  |
| training/sac_Q/q2              | 209.0936   |
| training/sac_Q/q2_loss         | 115.03776  |
| training/sac_Q/q_global_norm   | 256.26123  |
--------------------------------------------------------------------------------
[WARN] 520 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16150077 |
| epoch                          | 520        |
| evaluation/episode-length-avg  | 167        |
| evaluation/episode-length-max  | 169        |
| evaluation/episode-length-min  | 166        |
| evaluation/episode-length-std  | 1.28       |
| evaluation/return-average      | 541.951    |
| evaluation/return-max          | 552.17773  |
| evaluation/return-min          | 529.0053   |
| evaluation/return-std          | 7.855781   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46353      |
| perf/AverageLength             | 167        |
| perf/AverageReturn             | 541.951    |
| perf/NormalizedReturn          | 0.118      |
| Q-avg                          | 208.2268   |
| Q-std                          | 149.30254  |
| Q_loss                         | 112.65843  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 520        |
| times/epoch_after_hook         | 1.61e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 511        |
| times/evaluation_metrics       | 0.000397   |
| times/evaluation_paths         | 8.12       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 62.5       |
| timestep                       | 1000       |
| timesteps_total                | 521000     |
| train-steps                    | 521000     |
| training/Q/q1_loss             | 102.935196 |
| training/sac_pi/alpha          | 0.16148344 |
| training/sac_pi/alpha_loss     | 0.22537145 |
| training/sac_pi/logp_pi        | 3.8015733  |
| training/sac_pi/pi_entropy     | 3.3560302  |
| training/sac_pi/pi_global_norm | 2.0339973  |
| training/sac_pi/policy_loss    | -231.10716 |
| training/sac_pi/std            | 0.4656142  |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 224.00229  |
| training/sac_Q/q2              | 223.88803  |
| training/sac_Q/q2_loss         | 102.450455 |
| training/sac_Q/q_global_norm   | 313.59497  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1603853  |
| epoch                          | 521        |
| evaluation/episode-length-avg  | 156        |
| evaluation/episode-length-max  | 160        |
| evaluation/episode-length-min  | 154        |
| evaluation/episode-length-std  | 1.58       |
| evaluation/return-average      | 495.02435  |
| evaluation/return-max          | 506.28024  |
| evaluation/return-min          | 486.11096  |
| evaluation/return-std          | 5.519466   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46300      |
| perf/AverageLength             | 156        |
| perf/AverageReturn             | 495.02435  |
| perf/NormalizedReturn          | 0.107      |
| Q-avg                          | 220.6853   |
| Q-std                          | 98.72703   |
| Q_loss                         | 100.23178  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 521        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000307   |
| times/epoch_rollout_model      | 515        |
| times/evaluation_metrics       | 0.000396   |
| times/evaluation_paths         | 6.26       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00875    |
| times/train                    | 75.6       |
| timestep                       | 1000       |
| timesteps_total                | 522000     |
| train-steps                    | 522000     |
| training/Q/q1_loss             | 100.489944 |
| training/sac_pi/alpha          | 0.16038695 |
| training/sac_pi/alpha_loss     | 0.15932329 |
| training/sac_pi/logp_pi        | 4.002023   |
| training/sac_pi/pi_entropy     | 3.3552105  |
| training/sac_pi/pi_global_norm | 1.8122644  |
| training/sac_pi/policy_loss    | -220.91362 |
| training/sac_pi/std            | 0.47779623 |
| training/sac_pi/valid_num      | 4962.0     |
| training/sac_Q/q1              | 212.33513  |
| training/sac_Q/q2              | 212.1916   |
| training/sac_Q/q2_loss         | 101.27075  |
| training/sac_Q/q_global_norm   | 194.23343  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16701531  |
| epoch                          | 522         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4863.5083   |
| evaluation/return-max          | 4926.076    |
| evaluation/return-min          | 4795.4507   |
| evaluation/return-std          | 42.37767    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46390       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4863.5083   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 209.04037   |
| Q-std                          | 158.62262   |
| Q_loss                         | 113.702225  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 522         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 7.91e-05    |
| times/epoch_rollout_model      | 509         |
| times/evaluation_metrics       | 0.000669    |
| times/evaluation_paths         | 39.5        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 60.4        |
| timestep                       | 1000        |
| timesteps_total                | 523000      |
| train-steps                    | 523000      |
| training/Q/q1_loss             | 112.34565   |
| training/sac_pi/alpha          | 0.16704303  |
| training/sac_pi/alpha_loss     | -0.31178164 |
| training/sac_pi/logp_pi        | 4.7072115   |
| training/sac_pi/pi_entropy     | 3.321555    |
| training/sac_pi/pi_global_norm | 1.9376712   |
| training/sac_pi/policy_loss    | -230.37964  |
| training/sac_pi/std            | 0.48576635  |
| training/sac_pi/valid_num      | 4927.0      |
| training/sac_Q/q1              | 217.57178   |
| training/sac_Q/q2              | 218.83493   |
| training/sac_Q/q2_loss         | 111.962524  |
| training/sac_Q/q_global_norm   | 318.07547   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1608497   |
| epoch                          | 523         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4952.6567   |
| evaluation/return-max          | 4963.674    |
| evaluation/return-min          | 4940.206    |
| evaluation/return-std          | 5.626589    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46386       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4952.6567   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 212.79716   |
| Q-std                          | 140.26703   |
| Q_loss                         | 102.20109   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 523         |
| times/epoch_after_hook         | 1.63e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 513         |
| times/evaluation_metrics       | 0.000533    |
| times/evaluation_paths         | 47.4        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.0089      |
| times/train                    | 62.6        |
| timestep                       | 1000        |
| timesteps_total                | 524000      |
| train-steps                    | 524000      |
| training/Q/q1_loss             | 136.14818   |
| training/sac_pi/alpha          | 0.1608531   |
| training/sac_pi/alpha_loss     | 0.052607447 |
| training/sac_pi/logp_pi        | 4.3299513   |
| training/sac_pi/pi_entropy     | 3.484024    |
| training/sac_pi/pi_global_norm | 1.7665734   |
| training/sac_pi/policy_loss    | -218.0171   |
| training/sac_pi/std            | 0.507508    |
| training/sac_pi/valid_num      | 4963.0      |
| training/sac_Q/q1              | 207.28764   |
| training/sac_Q/q2              | 208.23161   |
| training/sac_Q/q2_loss         | 136.10092   |
| training/sac_Q/q_global_norm   | 305.88196   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16006655 |
| epoch                          | 524        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4952.3447  |
| evaluation/return-max          | 4971.079   |
| evaluation/return-min          | 4926.3716  |
| evaluation/return-std          | 12.362016  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46431      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4952.3447  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 218.8536   |
| Q-std                          | 119.6411   |
| Q_loss                         | 95.50144   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 524        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 516        |
| times/evaluation_metrics       | 0.000647   |
| times/evaluation_paths         | 45         |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 68.8       |
| timestep                       | 1000       |
| timesteps_total                | 525000     |
| train-steps                    | 525000     |
| training/Q/q1_loss             | 115.28711  |
| training/sac_pi/alpha          | 0.16006877 |
| training/sac_pi/alpha_loss     | -0.3090361 |
| training/sac_pi/logp_pi        | 4.06343    |
| training/sac_pi/pi_entropy     | 3.50372    |
| training/sac_pi/pi_global_norm | 2.3450286  |
| training/sac_pi/policy_loss    | -227.5976  |
| training/sac_pi/std            | 0.51753575 |
| training/sac_pi/valid_num      | 4918.0     |
| training/sac_Q/q1              | 215.49234  |
| training/sac_Q/q2              | 217.71399  |
| training/sac_Q/q2_loss         | 115.374084 |
| training/sac_Q/q_global_norm   | 217.92728  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16534883  |
| epoch                          | 525         |
| evaluation/episode-length-avg  | 917         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 166         |
| evaluation/episode-length-std  | 250         |
| evaluation/return-average      | 4245.6284   |
| evaluation/return-max          | 4753.672    |
| evaluation/return-min          | 522.0175    |
| evaluation/return-std          | 1242.5907   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46456       |
| perf/AverageLength             | 917         |
| perf/AverageReturn             | 4245.6284   |
| perf/NormalizedReturn          | 0.924       |
| Q-avg                          | 210.88681   |
| Q-std                          | 131.71931   |
| Q_loss                         | 98.95937    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 525         |
| times/epoch_after_hook         | 1.61e-06    |
| times/epoch_before_hook        | 0.00034     |
| times/epoch_rollout_model      | 507         |
| times/evaluation_metrics       | 0.000527    |
| times/evaluation_paths         | 32.1        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00856     |
| times/train                    | 62.6        |
| timestep                       | 1000        |
| timesteps_total                | 526000      |
| train-steps                    | 526000      |
| training/Q/q1_loss             | 103.94979   |
| training/sac_pi/alpha          | 0.16534215  |
| training/sac_pi/alpha_loss     | -0.16824825 |
| training/sac_pi/logp_pi        | 4.043872    |
| training/sac_pi/pi_entropy     | 3.4572816   |
| training/sac_pi/pi_global_norm | 1.8058608   |
| training/sac_pi/policy_loss    | -224.33519  |
| training/sac_pi/std            | 0.48903713  |
| training/sac_pi/valid_num      | 5002.0      |
| training/sac_Q/q1              | 213.85904   |
| training/sac_Q/q2              | 215.72563   |
| training/sac_Q/q2_loss         | 104.20752   |
| training/sac_Q/q_global_norm   | 287.4624    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16231893  |
| epoch                          | 526         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4900.7295   |
| evaluation/return-max          | 4938.9536   |
| evaluation/return-min          | 4878.1777   |
| evaluation/return-std          | 18.492264   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.01        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46262       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4900.7295   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 217.85356   |
| Q-std                          | 106.4033    |
| Q_loss                         | 99.61358    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 526         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000658    |
| times/evaluation_paths         | 46.1        |
| times/timestep_after_hook      | 0.00405     |
| times/timestep_before_hook     | 0.00862     |
| times/train                    | 70.3        |
| timestep                       | 1000        |
| timesteps_total                | 527000      |
| train-steps                    | 527000      |
| training/Q/q1_loss             | 104.62321   |
| training/sac_pi/alpha          | 0.16233887  |
| training/sac_pi/alpha_loss     | 0.049607754 |
| training/sac_pi/logp_pi        | 4.973427    |
| training/sac_pi/pi_entropy     | 3.243053    |
| training/sac_pi/pi_global_norm | 1.8822472   |
| training/sac_pi/policy_loss    | -231.335    |
| training/sac_pi/std            | 0.4991888   |
| training/sac_pi/valid_num      | 4975.0      |
| training/sac_Q/q1              | 214.21533   |
| training/sac_Q/q2              | 218.59085   |
| training/sac_Q/q2_loss         | 103.32649   |
| training/sac_Q/q_global_norm   | 232.31421   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16537666 |
| epoch                          | 527        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4777.7705  |
| evaluation/return-max          | 4875.0005  |
| evaluation/return-min          | 4715.0684  |
| evaluation/return-std          | 53.931606  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46357      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4777.7705  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 214.9522   |
| Q-std                          | 138.44958  |
| Q_loss                         | 110.16581  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 527        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000274   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000597   |
| times/evaluation_paths         | 46.9       |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00884    |
| times/train                    | 67.2       |
| timestep                       | 1000       |
| timesteps_total                | 528000     |
| train-steps                    | 528000     |
| training/Q/q1_loss             | 97.83329   |
| training/sac_pi/alpha          | 0.16533433 |
| training/sac_pi/alpha_loss     | 0.62129134 |
| training/sac_pi/logp_pi        | 4.932878   |
| training/sac_pi/pi_entropy     | 3.1205006  |
| training/sac_pi/pi_global_norm | 1.9811802  |
| training/sac_pi/policy_loss    | -236.88689 |
| training/sac_pi/std            | 0.47008693 |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 221.56233  |
| training/sac_Q/q2              | 225.06357  |
| training/sac_Q/q2_loss         | 97.542336  |
| training/sac_Q/q_global_norm   | 218.49278  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1639324  |
| epoch                          | 528        |
| evaluation/episode-length-avg  | 925        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 253        |
| evaluation/episode-length-std  | 224        |
| evaluation/return-average      | 4679.616   |
| evaluation/return-max          | 5191.427   |
| evaluation/return-min          | 940.0896   |
| evaluation/return-std          | 1249.2274  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46347      |
| perf/AverageLength             | 925        |
| perf/AverageReturn             | 4679.616   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 217.92929  |
| Q-std                          | 89.68164   |
| Q_loss                         | 122.97572  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 528        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000535   |
| times/evaluation_paths         | 41.9       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00889    |
| times/train                    | 68.9       |
| timestep                       | 1000       |
| timesteps_total                | 529000     |
| train-steps                    | 529000     |
| training/Q/q1_loss             | 118.34028  |
| training/sac_pi/alpha          | 0.1639196  |
| training/sac_pi/alpha_loss     | 0.42837954 |
| training/sac_pi/logp_pi        | 4.4105783  |
| training/sac_pi/pi_entropy     | 3.2991726  |
| training/sac_pi/pi_global_norm | 2.3163404  |
| training/sac_pi/policy_loss    | -222.33012 |
| training/sac_pi/std            | 0.47395712 |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 210.36899  |
| training/sac_Q/q2              | 212.33989  |
| training/sac_Q/q2_loss         | 117.80081  |
| training/sac_Q/q_global_norm   | 226.31075  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15954597 |
| epoch                          | 529        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4750.4546  |
| evaluation/return-max          | 4878.955   |
| evaluation/return-min          | 4558.4453  |
| evaluation/return-std          | 87.071434  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 78.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46405      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4750.4546  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 213.50443  |
| Q-std                          | 140.34425  |
| Q_loss                         | 111.93647  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 529        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000285   |
| times/epoch_rollout_model      | 503        |
| times/evaluation_metrics       | 0.000635   |
| times/evaluation_paths         | 38         |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 62.8       |
| timestep                       | 1000       |
| timesteps_total                | 530000     |
| train-steps                    | 530000     |
| training/Q/q1_loss             | 121.99436  |
| training/sac_pi/alpha          | 0.15955204 |
| training/sac_pi/alpha_loss     | 0.6226228  |
| training/sac_pi/logp_pi        | 4.9494452  |
| training/sac_pi/pi_entropy     | 3.2460945  |
| training/sac_pi/pi_global_norm | 2.2601955  |
| training/sac_pi/policy_loss    | -221.44768 |
| training/sac_pi/std            | 0.49379635 |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 210.24368  |
| training/sac_Q/q2              | 213.15202  |
| training/sac_Q/q2_loss         | 123.69492  |
| training/sac_Q/q_global_norm   | 304.20016  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15950447 |
| epoch                          | 530        |
| evaluation/episode-length-avg  | 739        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 502        |
| evaluation/episode-length-std  | 184        |
| evaluation/return-average      | 3473.232   |
| evaluation/return-max          | 4858.1445  |
| evaluation/return-min          | 2287.2004  |
| evaluation/return-std          | 936.89594  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46499      |
| perf/AverageLength             | 739        |
| perf/AverageReturn             | 3473.232   |
| perf/NormalizedReturn          | 0.756      |
| Q-avg                          | 220.91422  |
| Q-std                          | 114.17506  |
| Q_loss                         | 115.11691  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 530        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000143   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000723   |
| times/evaluation_paths         | 34.2       |
| times/timestep_after_hook      | 0.00389    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 72.5       |
| timestep                       | 1000       |
| timesteps_total                | 531000     |
| train-steps                    | 531000     |
| training/Q/q1_loss             | 78.90256   |
| training/sac_pi/alpha          | 0.15951462 |
| training/sac_pi/alpha_loss     | -0.6198155 |
| training/sac_pi/logp_pi        | 3.9549637  |
| training/sac_pi/pi_entropy     | 3.352023   |
| training/sac_pi/pi_global_norm | 1.5452881  |
| training/sac_pi/policy_loss    | -231.07008 |
| training/sac_pi/std            | 0.49762288 |
| training/sac_pi/valid_num      | 4940.0     |
| training/sac_Q/q1              | 218.00748  |
| training/sac_Q/q2              | 219.93637  |
| training/sac_Q/q2_loss         | 79.935425  |
| training/sac_Q/q_global_norm   | 264.242    |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15981331  |
| epoch                          | 531         |
| evaluation/episode-length-avg  | 890         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 327         |
| evaluation/episode-length-std  | 218         |
| evaluation/return-average      | 4223.8423   |
| evaluation/return-max          | 4947.1953   |
| evaluation/return-min          | 1276.4971   |
| evaluation/return-std          | 1164.1602   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46416       |
| perf/AverageLength             | 890         |
| perf/AverageReturn             | 4223.8423   |
| perf/NormalizedReturn          | 0.92        |
| Q-avg                          | 229.7491    |
| Q-std                          | 101.026405  |
| Q_loss                         | 85.21724    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 531         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000173    |
| times/epoch_rollout_model      | 504         |
| times/evaluation_metrics       | 0.000657    |
| times/evaluation_paths         | 36.9        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 71          |
| timestep                       | 1000        |
| timesteps_total                | 532000      |
| train-steps                    | 532000      |
| training/Q/q1_loss             | 108.685356  |
| training/sac_pi/alpha          | 0.15981202  |
| training/sac_pi/alpha_loss     | -0.03442887 |
| training/sac_pi/logp_pi        | 4.0818644   |
| training/sac_pi/pi_entropy     | 3.2583985   |
| training/sac_pi/pi_global_norm | 1.9314342   |
| training/sac_pi/policy_loss    | -220.83372  |
| training/sac_pi/std            | 0.47991624  |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 209.502     |
| training/sac_Q/q2              | 212.5072    |
| training/sac_Q/q2_loss         | 108.50671   |
| training/sac_Q/q_global_norm   | 209.01698   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15748295  |
| epoch                          | 532         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5041.1313   |
| evaluation/return-max          | 5116.5947   |
| evaluation/return-min          | 4976.288    |
| evaluation/return-std          | 38.419563   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46533       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5041.1313   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 217.64316   |
| Q-std                          | 95.25908    |
| Q_loss                         | 81.57215    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 532         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000643    |
| times/evaluation_paths         | 44.8        |
| times/timestep_after_hook      | 0.00356     |
| times/timestep_before_hook     | 0.00846     |
| times/train                    | 69.5        |
| timestep                       | 1000        |
| timesteps_total                | 533000      |
| train-steps                    | 533000      |
| training/Q/q1_loss             | 75.11941    |
| training/sac_pi/alpha          | 0.15749595  |
| training/sac_pi/alpha_loss     | -0.25927138 |
| training/sac_pi/logp_pi        | 3.8007483   |
| training/sac_pi/pi_entropy     | 3.3630493   |
| training/sac_pi/pi_global_norm | 1.671738    |
| training/sac_pi/policy_loss    | -229.33766  |
| training/sac_pi/std            | 0.48158538  |
| training/sac_pi/valid_num      | 4964.0      |
| training/sac_Q/q1              | 220.13486   |
| training/sac_Q/q2              | 220.32706   |
| training/sac_Q/q2_loss         | 75.66361    |
| training/sac_Q/q_global_norm   | 223.58968   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16396976 |
| epoch                          | 533        |
| evaluation/episode-length-avg  | 826        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 323        |
| evaluation/episode-length-std  | 269        |
| evaluation/return-average      | 3813.5554  |
| evaluation/return-max          | 4846.2944  |
| evaluation/return-min          | 1179.9395  |
| evaluation/return-std          | 1435.8947  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46505      |
| perf/AverageLength             | 826        |
| perf/AverageReturn             | 3813.5554  |
| perf/NormalizedReturn          | 0.83       |
| Q-avg                          | 218.30008  |
| Q-std                          | 121.7406   |
| Q_loss                         | 89.90366   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 533        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000317   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000712   |
| times/evaluation_paths         | 30.8       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 66.4       |
| timestep                       | 1000       |
| timesteps_total                | 534000     |
| train-steps                    | 534000     |
| training/Q/q1_loss             | 117.30084  |
| training/sac_pi/alpha          | 0.16400273 |
| training/sac_pi/alpha_loss     | -0.2330657 |
| training/sac_pi/logp_pi        | 4.317436   |
| training/sac_pi/pi_entropy     | 3.3981965  |
| training/sac_pi/pi_global_norm | 1.8432702  |
| training/sac_pi/policy_loss    | -227.78125 |
| training/sac_pi/std            | 0.49503765 |
| training/sac_pi/valid_num      | 4979.0     |
| training/sac_Q/q1              | 219.54399  |
| training/sac_Q/q2              | 221.25117  |
| training/sac_Q/q2_loss         | 117.86918  |
| training/sac_Q/q_global_norm   | 337.66608  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1653155  |
| epoch                          | 534        |
| evaluation/episode-length-avg  | 935        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 348        |
| evaluation/episode-length-std  | 196        |
| evaluation/return-average      | 4401.0156  |
| evaluation/return-max          | 4818.085   |
| evaluation/return-min          | 1310.7703  |
| evaluation/return-std          | 1031.6528  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46497      |
| perf/AverageLength             | 935        |
| perf/AverageReturn             | 4401.0156  |
| perf/NormalizedReturn          | 0.958      |
| Q-avg                          | 205.48495  |
| Q-std                          | 152.89716  |
| Q_loss                         | 95.05032   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 534        |
| times/epoch_after_hook         | 1.65e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 508        |
| times/evaluation_metrics       | 0.000708   |
| times/evaluation_paths         | 42.1       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 67.1       |
| timestep                       | 1000       |
| timesteps_total                | 535000     |
| train-steps                    | 535000     |
| training/Q/q1_loss             | 85.59373   |
| training/sac_pi/alpha          | 0.16526471 |
| training/sac_pi/alpha_loss     | -0.1207012 |
| training/sac_pi/logp_pi        | 4.1583886  |
| training/sac_pi/pi_entropy     | 3.229613   |
| training/sac_pi/pi_global_norm | 1.9082252  |
| training/sac_pi/policy_loss    | -226.38318 |
| training/sac_pi/std            | 0.4673563  |
| training/sac_pi/valid_num      | 4994.0     |
| training/sac_Q/q1              | 219.58867  |
| training/sac_Q/q2              | 221.1666   |
| training/sac_Q/q2_loss         | 86.953896  |
| training/sac_Q/q_global_norm   | 223.07191  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16716525 |
| epoch                          | 535        |
| evaluation/episode-length-avg  | 161        |
| evaluation/episode-length-max  | 163        |
| evaluation/episode-length-min  | 159        |
| evaluation/episode-length-std  | 1.1        |
| evaluation/return-average      | 473.4082   |
| evaluation/return-max          | 479.60132  |
| evaluation/return-min          | 464.4722   |
| evaluation/return-std          | 4.3527513  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46494      |
| perf/AverageLength             | 161        |
| perf/AverageReturn             | 473.4082   |
| perf/NormalizedReturn          | 0.103      |
| Q-avg                          | 225.54825  |
| Q-std                          | 106.225136 |
| Q_loss                         | 102.751175 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 535        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000494   |
| times/evaluation_paths         | 7.59       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 64.7       |
| timestep                       | 1000       |
| timesteps_total                | 536000     |
| train-steps                    | 536000     |
| training/Q/q1_loss             | 96.50611   |
| training/sac_pi/alpha          | 0.16716786 |
| training/sac_pi/alpha_loss     | 0.3105263  |
| training/sac_pi/logp_pi        | 4.809009   |
| training/sac_pi/pi_entropy     | 3.3169143  |
| training/sac_pi/pi_global_norm | 1.826099   |
| training/sac_pi/policy_loss    | -222.48734 |
| training/sac_pi/std            | 0.5025322  |
| training/sac_pi/valid_num      | 4953.0     |
| training/sac_Q/q1              | 209.3877   |
| training/sac_Q/q2              | 213.54037  |
| training/sac_Q/q2_loss         | 97.24303   |
| training/sac_Q/q_global_norm   | 327.30298  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16625544 |
| epoch                          | 536        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4976.711   |
| evaluation/return-max          | 5058.3125  |
| evaluation/return-min          | 4919.8945  |
| evaluation/return-std          | 36.56336   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46458      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4976.711   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 216.50786  |
| Q-std                          | 119.619606 |
| Q_loss                         | 85.12134   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 536        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000139   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000653   |
| times/evaluation_paths         | 36.6       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00842    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 537000     |
| train-steps                    | 537000     |
| training/Q/q1_loss             | 76.81882   |
| training/sac_pi/alpha          | 0.16624872 |
| training/sac_pi/alpha_loss     | 0.15233606 |
| training/sac_pi/logp_pi        | 4.4889655  |
| training/sac_pi/pi_entropy     | 3.47387    |
| training/sac_pi/pi_global_norm | 1.5595187  |
| training/sac_pi/policy_loss    | -224.00395 |
| training/sac_pi/std            | 0.48908368 |
| training/sac_pi/valid_num      | 4909.0     |
| training/sac_Q/q1              | 212.06546  |
| training/sac_Q/q2              | 214.19217  |
| training/sac_Q/q2_loss         | 76.54247   |
| training/sac_Q/q_global_norm   | 504.33453  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1628896   |
| epoch                          | 537         |
| evaluation/episode-length-avg  | 978         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 849         |
| evaluation/episode-length-std  | 48          |
| evaluation/return-average      | 4922.2397   |
| evaluation/return-max          | 5155.1377   |
| evaluation/return-min          | 4014.4536   |
| evaluation/return-std          | 343.92328   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.15        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46426       |
| perf/AverageLength             | 978         |
| perf/AverageReturn             | 4922.2397   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 218.44876   |
| Q-std                          | 104.81851   |
| Q_loss                         | 106.658806  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 537         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000331    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000509    |
| times/evaluation_paths         | 38.7        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00852     |
| times/train                    | 74.5        |
| timestep                       | 1000        |
| timesteps_total                | 538000      |
| train-steps                    | 538000      |
| training/Q/q1_loss             | 117.154106  |
| training/sac_pi/alpha          | 0.16287751  |
| training/sac_pi/alpha_loss     | 0.095856644 |
| training/sac_pi/logp_pi        | 4.460526    |
| training/sac_pi/pi_entropy     | 3.3464515   |
| training/sac_pi/pi_global_norm | 2.2882178   |
| training/sac_pi/policy_loss    | -223.52324  |
| training/sac_pi/std            | 0.4858936   |
| training/sac_pi/valid_num      | 4977.0      |
| training/sac_Q/q1              | 213.53105   |
| training/sac_Q/q2              | 216.45422   |
| training/sac_Q/q2_loss         | 116.05641   |
| training/sac_Q/q_global_norm   | 310.69504   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16583736 |
| epoch                          | 538        |
| evaluation/episode-length-avg  | 472        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 164        |
| evaluation/episode-length-std  | 351        |
| evaluation/return-average      | 2054.6536  |
| evaluation/return-max          | 5006.206   |
| evaluation/return-min          | 412.21356  |
| evaluation/return-std          | 1936.2295  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46449      |
| perf/AverageLength             | 472        |
| perf/AverageReturn             | 2054.6536  |
| perf/NormalizedReturn          | 0.447      |
| Q-avg                          | 219.02954  |
| Q-std                          | 128.45694  |
| Q_loss                         | 117.999146 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 538        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000118   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000474   |
| times/evaluation_paths         | 15.7       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 63.5       |
| timestep                       | 1000       |
| timesteps_total                | 539000     |
| train-steps                    | 539000     |
| training/Q/q1_loss             | 100.349754 |
| training/sac_pi/alpha          | 0.16583283 |
| training/sac_pi/alpha_loss     | 0.30084878 |
| training/sac_pi/logp_pi        | 4.4737587  |
| training/sac_pi/pi_entropy     | 3.3842793  |
| training/sac_pi/pi_global_norm | 2.2509499  |
| training/sac_pi/policy_loss    | -227.02827 |
| training/sac_pi/std            | 0.49790943 |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 214.51334  |
| training/sac_Q/q2              | 218.8258   |
| training/sac_Q/q2_loss         | 100.48192  |
| training/sac_Q/q_global_norm   | 260.73788  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1663949   |
| epoch                          | 539         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4840.161    |
| evaluation/return-max          | 4891.1587   |
| evaluation/return-min          | 4756.3936   |
| evaluation/return-std          | 38.530773   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 84          |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46368       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4840.161    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 216.79008   |
| Q-std                          | 150.1381    |
| Q_loss                         | 103.2659    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 539         |
| times/epoch_after_hook         | 2.11e-06    |
| times/epoch_before_hook        | 0.000155    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000667    |
| times/evaluation_paths         | 38.2        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 63.8        |
| timestep                       | 1000        |
| timesteps_total                | 540000      |
| train-steps                    | 540000      |
| training/Q/q1_loss             | 93.42291    |
| training/sac_pi/alpha          | 0.16642745  |
| training/sac_pi/alpha_loss     | -0.11903928 |
| training/sac_pi/logp_pi        | 3.360536    |
| training/sac_pi/pi_entropy     | 3.4717164   |
| training/sac_pi/pi_global_norm | 1.8806223   |
| training/sac_pi/policy_loss    | -225.80223  |
| training/sac_pi/std            | 0.4688715   |
| training/sac_pi/valid_num      | 4971.0      |
| training/sac_Q/q1              | 218.6044    |
| training/sac_Q/q2              | 219.17581   |
| training/sac_Q/q2_loss         | 93.24521    |
| training/sac_Q/q_global_norm   | 196.1957    |
---------------------------------------------------------------------------------
[WARN] 540 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16403937 |
| epoch                          | 540        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5170.979   |
| evaluation/return-max          | 5202.337   |
| evaluation/return-min          | 5131.173   |
| evaluation/return-std          | 21.97089   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46434      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5170.979   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 217.99228  |
| Q-std                          | 134.19128  |
| Q_loss                         | 98.3616    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 540        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000621   |
| times/evaluation_paths         | 37.6       |
| times/timestep_after_hook      | 0.00356    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 541000     |
| train-steps                    | 541000     |
| training/Q/q1_loss             | 94.70837   |
| training/sac_pi/alpha          | 0.16401088 |
| training/sac_pi/alpha_loss     | 0.4054272  |
| training/sac_pi/logp_pi        | 4.478999   |
| training/sac_pi/pi_entropy     | 3.5146523  |
| training/sac_pi/pi_global_norm | 1.5484585  |
| training/sac_pi/policy_loss    | -222.76587 |
| training/sac_pi/std            | 0.5050859  |
| training/sac_pi/valid_num      | 4992.0     |
| training/sac_Q/q1              | 213.43399  |
| training/sac_Q/q2              | 215.449    |
| training/sac_Q/q2_loss         | 94.613464  |
| training/sac_Q/q_global_norm   | 220.24501  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16252717 |
| epoch                          | 541        |
| evaluation/episode-length-avg  | 746        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 150        |
| evaluation/episode-length-std  | 388        |
| evaluation/return-average      | 3795.3345  |
| evaluation/return-max          | 5282.0137  |
| evaluation/return-min          | 457.65457  |
| evaluation/return-std          | 2181.232   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46444      |
| perf/AverageLength             | 746        |
| perf/AverageReturn             | 3795.3345  |
| perf/NormalizedReturn          | 0.826      |
| Q-avg                          | 214.5839   |
| Q-std                          | 117.89247  |
| Q_loss                         | 119.83927  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 541        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000305   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000597   |
| times/evaluation_paths         | 33.9       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00813    |
| times/train                    | 60.9       |
| timestep                       | 1000       |
| timesteps_total                | 542000     |
| train-steps                    | 542000     |
| training/Q/q1_loss             | 88.83592   |
| training/sac_pi/alpha          | 0.16252896 |
| training/sac_pi/alpha_loss     | 0.11721247 |
| training/sac_pi/logp_pi        | 4.6446967  |
| training/sac_pi/pi_entropy     | 3.2739842  |
| training/sac_pi/pi_global_norm | 1.7840255  |
| training/sac_pi/policy_loss    | -233.05602 |
| training/sac_pi/std            | 0.50079364 |
| training/sac_pi/valid_num      | 4963.0     |
| training/sac_Q/q1              | 221.82886  |
| training/sac_Q/q2              | 223.19711  |
| training/sac_Q/q2_loss         | 88.686584  |
| training/sac_Q/q_global_norm   | 216.24364  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17058785 |
| epoch                          | 542        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5074.2847  |
| evaluation/return-max          | 5146.6997  |
| evaluation/return-min          | 4947.205   |
| evaluation/return-std          | 55.33823   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46531      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5074.2847  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 221.26018  |
| Q-std                          | 106.46343  |
| Q_loss                         | 94.6178    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 542        |
| times/epoch_after_hook         | 3.17e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000597   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 543000     |
| train-steps                    | 543000     |
| training/Q/q1_loss             | 94.95423   |
| training/sac_pi/alpha          | 0.17058623 |
| training/sac_pi/alpha_loss     | 0.4269852  |
| training/sac_pi/logp_pi        | 4.1474147  |
| training/sac_pi/pi_entropy     | 3.2763648  |
| training/sac_pi/pi_global_norm | 2.118144   |
| training/sac_pi/policy_loss    | -232.33598 |
| training/sac_pi/std            | 0.46514952 |
| training/sac_pi/valid_num      | 5059.0     |
| training/sac_Q/q1              | 226.77988  |
| training/sac_Q/q2              | 228.9288   |
| training/sac_Q/q2_loss         | 95.82431   |
| training/sac_Q/q_global_norm   | 225.5333   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16615316 |
| epoch                          | 543        |
| evaluation/episode-length-avg  | 827        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 642        |
| evaluation/episode-length-std  | 145        |
| evaluation/return-average      | 4148.9717  |
| evaluation/return-max          | 5203.468   |
| evaluation/return-min          | 3102.2505  |
| evaluation/return-std          | 850.917    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 78.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46372      |
| perf/AverageLength             | 827        |
| perf/AverageReturn             | 4148.9717  |
| perf/NormalizedReturn          | 0.903      |
| Q-avg                          | 211.82275  |
| Q-std                          | 162.72025  |
| Q_loss                         | 76.58661   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 543        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000559   |
| times/evaluation_paths         | 28.8       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 544000     |
| train-steps                    | 544000     |
| training/Q/q1_loss             | 122.483894 |
| training/sac_pi/alpha          | 0.16616078 |
| training/sac_pi/alpha_loss     | -0.4352845 |
| training/sac_pi/logp_pi        | 3.990971   |
| training/sac_pi/pi_entropy     | 3.6805282  |
| training/sac_pi/pi_global_norm | 1.7428237  |
| training/sac_pi/policy_loss    | -233.59532 |
| training/sac_pi/std            | 0.52123386 |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 223.8272   |
| training/sac_Q/q2              | 224.97969  |
| training/sac_Q/q2_loss         | 122.48396  |
| training/sac_Q/q_global_norm   | 185.95505  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16285841  |
| epoch                          | 544         |
| evaluation/episode-length-avg  | 153         |
| evaluation/episode-length-max  | 157         |
| evaluation/episode-length-min  | 151         |
| evaluation/episode-length-std  | 1.54        |
| evaluation/return-average      | 490.13397   |
| evaluation/return-max          | 509.48294   |
| evaluation/return-min          | 482.62143   |
| evaluation/return-std          | 6.995478    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 87.2        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46393       |
| perf/AverageLength             | 153         |
| perf/AverageReturn             | 490.13397   |
| perf/NormalizedReturn          | 0.106       |
| Q-avg                          | 211.78731   |
| Q-std                          | 146.51149   |
| Q_loss                         | 105.98646   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 544         |
| times/epoch_after_hook         | 1.61e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000621    |
| times/evaluation_paths         | 5.26        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00822     |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 545000      |
| train-steps                    | 545000      |
| training/Q/q1_loss             | 98.02552    |
| training/sac_pi/alpha          | 0.16284753  |
| training/sac_pi/alpha_loss     | 0.030256893 |
| training/sac_pi/logp_pi        | 3.5495453   |
| training/sac_pi/pi_entropy     | 3.2062123   |
| training/sac_pi/pi_global_norm | 1.9109724   |
| training/sac_pi/policy_loss    | -230.09027  |
| training/sac_pi/std            | 0.4536359   |
| training/sac_pi/valid_num      | 5022.0      |
| training/sac_Q/q1              | 224.3427    |
| training/sac_Q/q2              | 223.71692   |
| training/sac_Q/q2_loss         | 96.499176   |
| training/sac_Q/q_global_norm   | 162.44156   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16933441  |
| epoch                          | 545         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4848.8643   |
| evaluation/return-max          | 4900.7896   |
| evaluation/return-min          | 4760.1455   |
| evaluation/return-std          | 40.79094    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 80.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46417       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4848.8643   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 230.49792   |
| Q-std                          | 107.868385  |
| Q_loss                         | 89.65905    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 545         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000275    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000643    |
| times/evaluation_paths         | 34.1        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 546000      |
| train-steps                    | 546000      |
| training/Q/q1_loss             | 92.01479    |
| training/sac_pi/alpha          | 0.16933277  |
| training/sac_pi/alpha_loss     | -0.26372954 |
| training/sac_pi/logp_pi        | 4.1216073   |
| training/sac_pi/pi_entropy     | 3.3768563   |
| training/sac_pi/pi_global_norm | 2.7140617   |
| training/sac_pi/policy_loss    | -226.16368  |
| training/sac_pi/std            | 0.49146378  |
| training/sac_pi/valid_num      | 4957.0      |
| training/sac_Q/q1              | 216.54878   |
| training/sac_Q/q2              | 217.60995   |
| training/sac_Q/q2_loss         | 91.31778    |
| training/sac_Q/q_global_norm   | 284.21225   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1671194  |
| epoch                          | 546        |
| evaluation/episode-length-avg  | 745        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 140        |
| evaluation/episode-length-std  | 390        |
| evaluation/return-average      | 3422.1047  |
| evaluation/return-max          | 4780.8477  |
| evaluation/return-min          | 346.49127  |
| evaluation/return-std          | 1988.895   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46443      |
| perf/AverageLength             | 745        |
| perf/AverageReturn             | 3422.1047  |
| perf/NormalizedReturn          | 0.745      |
| Q-avg                          | 214.42871  |
| Q-std                          | 158.71408  |
| Q_loss                         | 101.07236  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 546        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.000573   |
| times/evaluation_paths         | 27.6       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00842    |
| times/train                    | 64.9       |
| timestep                       | 1000       |
| timesteps_total                | 547000     |
| train-steps                    | 547000     |
| training/Q/q1_loss             | 96.94695   |
| training/sac_pi/alpha          | 0.16714126 |
| training/sac_pi/alpha_loss     | 0.09197417 |
| training/sac_pi/logp_pi        | 4.1670504  |
| training/sac_pi/pi_entropy     | 3.5214043  |
| training/sac_pi/pi_global_norm | 2.3011534  |
| training/sac_pi/policy_loss    | -229.91669 |
| training/sac_pi/std            | 0.50023705 |
| training/sac_pi/valid_num      | 4990.0     |
| training/sac_Q/q1              | 218.6995   |
| training/sac_Q/q2              | 218.93169  |
| training/sac_Q/q2_loss         | 95.24586   |
| training/sac_Q/q_global_norm   | 169.14658  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16447587 |
| epoch                          | 547        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4815.0674  |
| evaluation/return-max          | 4942.4766  |
| evaluation/return-min          | 4750.004   |
| evaluation/return-std          | 60.23513   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46368      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4815.0674  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 221.853    |
| Q-std                          | 96.661026  |
| Q_loss                         | 125.79386  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 547        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000648   |
| times/evaluation_paths         | 35.3       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 62.8       |
| timestep                       | 1000       |
| timesteps_total                | 548000     |
| train-steps                    | 548000     |
| training/Q/q1_loss             | 94.314255  |
| training/sac_pi/alpha          | 0.16447228 |
| training/sac_pi/alpha_loss     | 0.3605011  |
| training/sac_pi/logp_pi        | 4.3531847  |
| training/sac_pi/pi_entropy     | 3.1182578  |
| training/sac_pi/pi_global_norm | 2.3071852  |
| training/sac_pi/policy_loss    | -231.96497 |
| training/sac_pi/std            | 0.46463493 |
| training/sac_pi/valid_num      | 5023.0     |
| training/sac_Q/q1              | 224.05249  |
| training/sac_Q/q2              | 226.5678   |
| training/sac_Q/q2_loss         | 95.11515   |
| training/sac_Q/q_global_norm   | 197.15208  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15336218 |
| epoch                          | 548        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4734.8667  |
| evaluation/return-max          | 4790.588   |
| evaluation/return-min          | 4651.563   |
| evaluation/return-std          | 42.886223  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46369      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4734.8667  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 224.85608  |
| Q-std                          | 101.788635 |
| Q_loss                         | 103.82585  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 548        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000147   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000701   |
| times/evaluation_paths         | 36.2       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00848    |
| times/train                    | 65.9       |
| timestep                       | 1000       |
| timesteps_total                | 549000     |
| train-steps                    | 549000     |
| training/Q/q1_loss             | 101.54793  |
| training/sac_pi/alpha          | 0.15335624 |
| training/sac_pi/alpha_loss     | 0.24303456 |
| training/sac_pi/logp_pi        | 4.175152   |
| training/sac_pi/pi_entropy     | 3.2144063  |
| training/sac_pi/pi_global_norm | 1.8905993  |
| training/sac_pi/policy_loss    | -218.72218 |
| training/sac_pi/std            | 0.46156693 |
| training/sac_pi/valid_num      | 5006.0     |
| training/sac_Q/q1              | 213.253    |
| training/sac_Q/q2              | 214.06909  |
| training/sac_Q/q2_loss         | 101.487854 |
| training/sac_Q/q_global_norm   | 288.4761   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16661131 |
| epoch                          | 549        |
| evaluation/episode-length-avg  | 934        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 771        |
| evaluation/episode-length-std  | 101        |
| evaluation/return-average      | 4866.025   |
| evaluation/return-max          | 5309.5576  |
| evaluation/return-min          | 3928.3281  |
| evaluation/return-std          | 586.95306  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46405      |
| perf/AverageLength             | 934        |
| perf/AverageReturn             | 4866.025   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 229.41287  |
| Q-std                          | 111.6303   |
| Q_loss                         | 86.32755   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 549        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000339   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000702   |
| times/evaluation_paths         | 34.1       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 63.7       |
| timestep                       | 1000       |
| timesteps_total                | 550000     |
| train-steps                    | 550000     |
| training/Q/q1_loss             | 98.215164  |
| training/sac_pi/alpha          | 0.16658005 |
| training/sac_pi/alpha_loss     | 0.33759764 |
| training/sac_pi/logp_pi        | 5.2376986  |
| training/sac_pi/pi_entropy     | 3.8594508  |
| training/sac_pi/pi_global_norm | 1.7746954  |
| training/sac_pi/policy_loss    | -222.06636 |
| training/sac_pi/std            | 0.5780394  |
| training/sac_pi/valid_num      | 4909.0     |
| training/sac_Q/q1              | 205.70865  |
| training/sac_Q/q2              | 209.34006  |
| training/sac_Q/q2_loss         | 98.738235  |
| training/sac_Q/q_global_norm   | 171.52997  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16103405 |
| epoch                          | 550        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5223.465   |
| evaluation/return-max          | 5236.0312  |
| evaluation/return-min          | 5207.0903  |
| evaluation/return-std          | 7.766209   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46358      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5223.465   |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 218.70195  |
| Q-std                          | 106.56818  |
| Q_loss                         | 109.715775 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 550        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000154   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.000539   |
| times/evaluation_paths         | 35.4       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00846    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 551000     |
| train-steps                    | 551000     |
| training/Q/q1_loss             | 105.720604 |
| training/sac_pi/alpha          | 0.16099855 |
| training/sac_pi/alpha_loss     | 0.15187061 |
| training/sac_pi/logp_pi        | 4.2609105  |
| training/sac_pi/pi_entropy     | 3.4399517  |
| training/sac_pi/pi_global_norm | 1.7262638  |
| training/sac_pi/policy_loss    | -227.91187 |
| training/sac_pi/std            | 0.49423176 |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 218.41782  |
| training/sac_Q/q2              | 218.38277  |
| training/sac_Q/q2_loss         | 105.35631  |
| training/sac_Q/q_global_norm   | 193.92116  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16007708  |
| epoch                          | 551         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5031.7876   |
| evaluation/return-max          | 5090.0654   |
| evaluation/return-min          | 4945.1133   |
| evaluation/return-std          | 41.542763   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46306       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5031.7876   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 212.96016   |
| Q-std                          | 127.83535   |
| Q_loss                         | 98.744934   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 551         |
| times/epoch_after_hook         | 1.91e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000789    |
| times/evaluation_paths         | 37.4        |
| times/timestep_after_hook      | 0.00383     |
| times/timestep_before_hook     | 0.00887     |
| times/train                    | 64.6        |
| timestep                       | 1000        |
| timesteps_total                | 552000      |
| train-steps                    | 552000      |
| training/Q/q1_loss             | 112.921776  |
| training/sac_pi/alpha          | 0.16005959  |
| training/sac_pi/alpha_loss     | 0.024060283 |
| training/sac_pi/logp_pi        | 3.9604282   |
| training/sac_pi/pi_entropy     | 3.1967933   |
| training/sac_pi/pi_global_norm | 2.5157578   |
| training/sac_pi/policy_loss    | -229.05266  |
| training/sac_pi/std            | 0.4620148   |
| training/sac_pi/valid_num      | 4985.0      |
| training/sac_Q/q1              | 222.25899   |
| training/sac_Q/q2              | 223.03711   |
| training/sac_Q/q2_loss         | 114.48537   |
| training/sac_Q/q_global_norm   | 300.56943   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1692814    |
| epoch                          | 552          |
| evaluation/episode-length-avg  | 983          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 869          |
| evaluation/episode-length-std  | 39.9         |
| evaluation/return-average      | 5211.673     |
| evaluation/return-max          | 5399.613     |
| evaluation/return-min          | 4489.5454    |
| evaluation/return-std          | 258.73276    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.11         |
| model/origin_ret               | 85.5         |
| model/penalty_ret              | 79.9         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46516        |
| perf/AverageLength             | 983          |
| perf/AverageReturn             | 5211.673     |
| perf/NormalizedReturn          | 1.13         |
| Q-avg                          | 219.0291     |
| Q-std                          | 141.64087    |
| Q_loss                         | 98.02547     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 552          |
| times/epoch_after_hook         | 1.67e-06     |
| times/epoch_before_hook        | 0.000173     |
| times/epoch_rollout_model      | 504          |
| times/evaluation_metrics       | 0.000808     |
| times/evaluation_paths         | 36           |
| times/timestep_after_hook      | 0.00367      |
| times/timestep_before_hook     | 0.00832      |
| times/train                    | 62.9         |
| timestep                       | 1000         |
| timesteps_total                | 553000       |
| train-steps                    | 553000       |
| training/Q/q1_loss             | 119.1229     |
| training/sac_pi/alpha          | 0.1693117    |
| training/sac_pi/alpha_loss     | -0.029905107 |
| training/sac_pi/logp_pi        | 4.62977      |
| training/sac_pi/pi_entropy     | 3.5301182    |
| training/sac_pi/pi_global_norm | 2.174434     |
| training/sac_pi/policy_loss    | -226.68147   |
| training/sac_pi/std            | 0.51687324   |
| training/sac_pi/valid_num      | 4945.0       |
| training/sac_Q/q1              | 215.3302     |
| training/sac_Q/q2              | 214.87578    |
| training/sac_Q/q2_loss         | 119.44749    |
| training/sac_Q/q_global_norm   | 239.02464    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16525508  |
| epoch                          | 553         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5115.4175   |
| evaluation/return-max          | 5195.044    |
| evaluation/return-min          | 5067.604    |
| evaluation/return-std          | 41.633446   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46338       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5115.4175   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 223.17978   |
| Q-std                          | 102.78583   |
| Q_loss                         | 73.96378    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 553         |
| times/epoch_after_hook         | 1.61e-06    |
| times/epoch_before_hook        | 0.000363    |
| times/epoch_rollout_model      | 504         |
| times/evaluation_metrics       | 0.000716    |
| times/evaluation_paths         | 35.1        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 63.4        |
| timestep                       | 1000        |
| timesteps_total                | 554000      |
| train-steps                    | 554000      |
| training/Q/q1_loss             | 106.68495   |
| training/sac_pi/alpha          | 0.16525078  |
| training/sac_pi/alpha_loss     | -0.05502665 |
| training/sac_pi/logp_pi        | 5.1177664   |
| training/sac_pi/pi_entropy     | 3.469686    |
| training/sac_pi/pi_global_norm | 2.1953049   |
| training/sac_pi/policy_loss    | -227.58276  |
| training/sac_pi/std            | 0.5489864   |
| training/sac_pi/valid_num      | 4952.0      |
| training/sac_Q/q1              | 213.61113   |
| training/sac_Q/q2              | 214.82076   |
| training/sac_Q/q2_loss         | 106.14234   |
| training/sac_Q/q_global_norm   | 218.41724   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16549845 |
| epoch                          | 554        |
| evaluation/episode-length-avg  | 848        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 412        |
| evaluation/episode-length-std  | 240        |
| evaluation/return-average      | 4015.8137  |
| evaluation/return-max          | 4848.8525  |
| evaluation/return-min          | 1755.8322  |
| evaluation/return-std          | 1238.6412  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 84.4       |
| model/penalty_ret              | 78.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46463      |
| perf/AverageLength             | 848        |
| perf/AverageReturn             | 4015.8137  |
| perf/NormalizedReturn          | 0.874      |
| Q-avg                          | 209.93465  |
| Q-std                          | 127.360306 |
| Q_loss                         | 98.0455    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 554        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.00014    |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000976   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00413    |
| times/timestep_before_hook     | 0.0089     |
| times/train                    | 65.1       |
| timestep                       | 1000       |
| timesteps_total                | 555000     |
| train-steps                    | 555000     |
| training/Q/q1_loss             | 101.64851  |
| training/sac_pi/alpha          | 0.16551402 |
| training/sac_pi/alpha_loss     | 0.29692346 |
| training/sac_pi/logp_pi        | 4.7345176  |
| training/sac_pi/pi_entropy     | 3.4705462  |
| training/sac_pi/pi_global_norm | 2.5101957  |
| training/sac_pi/policy_loss    | -218.97124 |
| training/sac_pi/std            | 0.51787525 |
| training/sac_pi/valid_num      | 4946.0     |
| training/sac_Q/q1              | 206.69707  |
| training/sac_Q/q2              | 208.83269  |
| training/sac_Q/q2_loss         | 101.32178  |
| training/sac_Q/q_global_norm   | 225.78691  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16897175  |
| epoch                          | 555         |
| evaluation/episode-length-avg  | 916         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 737         |
| evaluation/episode-length-std  | 97.8        |
| evaluation/return-average      | 4655.12     |
| evaluation/return-max          | 5286.7227   |
| evaluation/return-min          | 3552.5786   |
| evaluation/return-std          | 586.704     |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.05        |
| model/origin_ret               | 84.1        |
| model/penalty_ret              | 78.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46468       |
| perf/AverageLength             | 916         |
| perf/AverageReturn             | 4655.12     |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 220.66255   |
| Q-std                          | 117.18608   |
| Q_loss                         | 95.77377    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 555         |
| times/epoch_after_hook         | 1.65e-06    |
| times/epoch_before_hook        | 0.000143    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000652    |
| times/evaluation_paths         | 32.8        |
| times/timestep_after_hook      | 0.00353     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 63.6        |
| timestep                       | 1000        |
| timesteps_total                | 556000      |
| train-steps                    | 556000      |
| training/Q/q1_loss             | 115.587524  |
| training/sac_pi/alpha          | 0.1689888   |
| training/sac_pi/alpha_loss     | -0.35545018 |
| training/sac_pi/logp_pi        | 4.494195    |
| training/sac_pi/pi_entropy     | 3.5508018   |
| training/sac_pi/pi_global_norm | 1.5536678   |
| training/sac_pi/policy_loss    | -229.31825  |
| training/sac_pi/std            | 0.51210576  |
| training/sac_pi/valid_num      | 4960.0      |
| training/sac_Q/q1              | 216.1851    |
| training/sac_Q/q2              | 219.61255   |
| training/sac_Q/q2_loss         | 113.253845  |
| training/sac_Q/q_global_norm   | 206.09377   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16729167 |
| epoch                          | 556        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4592.216   |
| evaluation/return-max          | 4651.707   |
| evaluation/return-min          | 4559.6567  |
| evaluation/return-std          | 29.493364  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46085      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4592.216   |
| perf/NormalizedReturn          | 1          |
| Q-avg                          | 222.85791  |
| Q-std                          | 105.77002  |
| Q_loss                         | 103.0799   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 556        |
| times/epoch_after_hook         | 1.89e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000663   |
| times/evaluation_paths         | 36.6       |
| times/timestep_after_hook      | 0.00346    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 557000     |
| train-steps                    | 557000     |
| training/Q/q1_loss             | 105.91013  |
| training/sac_pi/alpha          | 0.16725534 |
| training/sac_pi/alpha_loss     | 0.12796059 |
| training/sac_pi/logp_pi        | 3.8233428  |
| training/sac_pi/pi_entropy     | 3.5928757  |
| training/sac_pi/pi_global_norm | 2.0086677  |
| training/sac_pi/policy_loss    | -225.82097 |
| training/sac_pi/std            | 0.4979971  |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 216.7543   |
| training/sac_Q/q2              | 218.88126  |
| training/sac_Q/q2_loss         | 106.42708  |
| training/sac_Q/q_global_norm   | 210.08128  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1670643  |
| epoch                          | 557        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5085.7285  |
| evaluation/return-max          | 5109.248   |
| evaluation/return-min          | 5058.8193  |
| evaluation/return-std          | 13.769252  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.2        |
| model/origin_ret               | 87.7       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46446      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5085.7285  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 217.13028  |
| Q-std                          | 134.53952  |
| Q_loss                         | 97.75352   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 557        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.0003     |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000578   |
| times/evaluation_paths         | 38.9       |
| times/timestep_after_hook      | 0.00395    |
| times/timestep_before_hook     | 0.00862    |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 558000     |
| train-steps                    | 558000     |
| training/Q/q1_loss             | 108.20437  |
| training/sac_pi/alpha          | 0.16703996 |
| training/sac_pi/alpha_loss     | 0.29754192 |
| training/sac_pi/logp_pi        | 5.050709   |
| training/sac_pi/pi_entropy     | 3.1622047  |
| training/sac_pi/pi_global_norm | 2.442921   |
| training/sac_pi/policy_loss    | -230.14323 |
| training/sac_pi/std            | 0.47391102 |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 218.07812  |
| training/sac_Q/q2              | 220.22124  |
| training/sac_Q/q2_loss         | 107.90552  |
| training/sac_Q/q_global_norm   | 184.57253  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16595611  |
| epoch                          | 558         |
| evaluation/episode-length-avg  | 413         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 158         |
| evaluation/episode-length-std  | 384         |
| evaluation/return-average      | 1945.3118   |
| evaluation/return-max          | 5298.843    |
| evaluation/return-min          | 499.09296   |
| evaluation/return-std          | 2181.5032   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46429       |
| perf/AverageLength             | 413         |
| perf/AverageReturn             | 1945.3118   |
| perf/NormalizedReturn          | 0.423       |
| Q-avg                          | 221.03384   |
| Q-std                          | 125.01783   |
| Q_loss                         | 112.638245  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 558         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000115    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.00055     |
| times/evaluation_paths         | 15.7        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 62          |
| timestep                       | 1000        |
| timesteps_total                | 559000      |
| train-steps                    | 559000      |
| training/Q/q1_loss             | 97.97042    |
| training/sac_pi/alpha          | 0.16597357  |
| training/sac_pi/alpha_loss     | -0.36065423 |
| training/sac_pi/logp_pi        | 4.2436376   |
| training/sac_pi/pi_entropy     | 3.5849838   |
| training/sac_pi/pi_global_norm | 1.7887834   |
| training/sac_pi/policy_loss    | -229.40706  |
| training/sac_pi/std            | 0.5157508   |
| training/sac_pi/valid_num      | 4885.0      |
| training/sac_Q/q1              | 210.9974    |
| training/sac_Q/q2              | 213.35449   |
| training/sac_Q/q2_loss         | 99.02976    |
| training/sac_Q/q_global_norm   | 229.56886   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1650687   |
| epoch                          | 559         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5097.532    |
| evaluation/return-max          | 5223.8613   |
| evaluation/return-min          | 4893.797    |
| evaluation/return-std          | 89.87748    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46336       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5097.532    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 218.87625   |
| Q-std                          | 125.67571   |
| Q_loss                         | 110.63328   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 559         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000599    |
| times/evaluation_paths         | 33.9        |
| times/timestep_after_hook      | 0.0035      |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 60.2        |
| timestep                       | 1000        |
| timesteps_total                | 560000      |
| train-steps                    | 560000      |
| training/Q/q1_loss             | 119.21937   |
| training/sac_pi/alpha          | 0.16504224  |
| training/sac_pi/alpha_loss     | -0.09882738 |
| training/sac_pi/logp_pi        | 4.5077643   |
| training/sac_pi/pi_entropy     | 3.7592978   |
| training/sac_pi/pi_global_norm | 1.9174396   |
| training/sac_pi/policy_loss    | -221.9793   |
| training/sac_pi/std            | 0.55156326  |
| training/sac_pi/valid_num      | 4915.0      |
| training/sac_Q/q1              | 205.29016   |
| training/sac_Q/q2              | 208.76505   |
| training/sac_Q/q2_loss         | 120.36846   |
| training/sac_Q/q_global_norm   | 238.4609    |
---------------------------------------------------------------------------------
[WARN] 560 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16146766 |
| epoch                          | 560        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5139.6743  |
| evaluation/return-max          | 5166.683   |
| evaluation/return-min          | 5118.273   |
| evaluation/return-std          | 18.20091   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 87.4       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46471      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5139.6743  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 206.00386  |
| Q-std                          | 151.76259  |
| Q_loss                         | 113.83908  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 560        |
| times/epoch_after_hook         | 1.65e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.00058    |
| times/evaluation_paths         | 35.5       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 63.4       |
| timestep                       | 1000       |
| timesteps_total                | 561000     |
| train-steps                    | 561000     |
| training/Q/q1_loss             | 93.30628   |
| training/sac_pi/alpha          | 0.16144572 |
| training/sac_pi/alpha_loss     | 0.09601567 |
| training/sac_pi/logp_pi        | 4.4487743  |
| training/sac_pi/pi_entropy     | 3.3751915  |
| training/sac_pi/pi_global_norm | 1.6757869  |
| training/sac_pi/policy_loss    | -225.78244 |
| training/sac_pi/std            | 0.5138634  |
| training/sac_pi/valid_num      | 4955.0     |
| training/sac_Q/q1              | 214.36746  |
| training/sac_Q/q2              | 214.8689   |
| training/sac_Q/q2_loss         | 94.9816    |
| training/sac_Q/q_global_norm   | 194.24342  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16233395  |
| epoch                          | 561         |
| evaluation/episode-length-avg  | 764         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 143         |
| evaluation/episode-length-std  | 278         |
| evaluation/return-average      | 3733.605    |
| evaluation/return-max          | 5096.582    |
| evaluation/return-min          | 323.21887   |
| evaluation/return-std          | 1549.9048   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 78.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46649       |
| perf/AverageLength             | 764         |
| perf/AverageReturn             | 3733.605    |
| perf/NormalizedReturn          | 0.813       |
| Q-avg                          | 225.42395   |
| Q-std                          | 105.008415  |
| Q_loss                         | 96.27669    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 561         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000292    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000631    |
| times/evaluation_paths         | 27.4        |
| times/timestep_after_hook      | 0.00357     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 62.3        |
| timestep                       | 1000        |
| timesteps_total                | 562000      |
| train-steps                    | 562000      |
| training/Q/q1_loss             | 86.48674    |
| training/sac_pi/alpha          | 0.16231309  |
| training/sac_pi/alpha_loss     | 0.056278117 |
| training/sac_pi/logp_pi        | 3.8056724   |
| training/sac_pi/pi_entropy     | 3.4611614   |
| training/sac_pi/pi_global_norm | 1.6686842   |
| training/sac_pi/policy_loss    | -233.4059   |
| training/sac_pi/std            | 0.48818627  |
| training/sac_pi/valid_num      | 4977.0      |
| training/sac_Q/q1              | 225.87654   |
| training/sac_Q/q2              | 226.1357    |
| training/sac_Q/q2_loss         | 87.33804    |
| training/sac_Q/q_global_norm   | 235.66954   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16398647 |
| epoch                          | 562        |
| evaluation/episode-length-avg  | 154        |
| evaluation/episode-length-max  | 160        |
| evaluation/episode-length-min  | 150        |
| evaluation/episode-length-std  | 2.73       |
| evaluation/return-average      | 417.1125   |
| evaluation/return-max          | 444.211    |
| evaluation/return-min          | 404.82092  |
| evaluation/return-std          | 11.12983   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46435      |
| perf/AverageLength             | 154        |
| perf/AverageReturn             | 417.1125   |
| perf/NormalizedReturn          | 0.0905     |
| Q-avg                          | 224.94157  |
| Q-std                          | 88.96898   |
| Q_loss                         | 116.64291  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 562        |
| times/epoch_after_hook         | 1.58e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000604   |
| times/evaluation_paths         | 5.19       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 563000     |
| train-steps                    | 563000     |
| training/Q/q1_loss             | 116.74477  |
| training/sac_pi/alpha          | 0.16400208 |
| training/sac_pi/alpha_loss     | -0.185438  |
| training/sac_pi/logp_pi        | 4.8893003  |
| training/sac_pi/pi_entropy     | 3.2043927  |
| training/sac_pi/pi_global_norm | 1.6554891  |
| training/sac_pi/policy_loss    | -227.08177 |
| training/sac_pi/std            | 0.5042932  |
| training/sac_pi/valid_num      | 4954.0     |
| training/sac_Q/q1              | 215.90068  |
| training/sac_Q/q2              | 217.92268  |
| training/sac_Q/q2_loss         | 116.28376  |
| training/sac_Q/q_global_norm   | 252.47736  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16740811 |
| epoch                          | 563        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4760.0186  |
| evaluation/return-max          | 4821.2383  |
| evaluation/return-min          | 4707.837   |
| evaluation/return-std          | 39.389496  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 78.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46384      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4760.0186  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 217.43181  |
| Q-std                          | 126.40197  |
| Q_loss                         | 82.04776   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 563        |
| times/epoch_after_hook         | 1.96e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000641   |
| times/evaluation_paths         | 35.4       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 564000     |
| train-steps                    | 564000     |
| training/Q/q1_loss             | 117.72345  |
| training/sac_pi/alpha          | 0.16740127 |
| training/sac_pi/alpha_loss     | 0.30618766 |
| training/sac_pi/logp_pi        | 4.305163   |
| training/sac_pi/pi_entropy     | 3.3140793  |
| training/sac_pi/pi_global_norm | 1.9435333  |
| training/sac_pi/policy_loss    | -225.24    |
| training/sac_pi/std            | 0.4833096  |
| training/sac_pi/valid_num      | 4981.0     |
| training/sac_Q/q1              | 216.92085  |
| training/sac_Q/q2              | 218.55997  |
| training/sac_Q/q2_loss         | 117.66543  |
| training/sac_Q/q_global_norm   | 231.60864  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16124469 |
| epoch                          | 564        |
| evaluation/episode-length-avg  | 154        |
| evaluation/episode-length-max  | 156        |
| evaluation/episode-length-min  | 152        |
| evaluation/episode-length-std  | 1.14       |
| evaluation/return-average      | 459.27057  |
| evaluation/return-max          | 465.46912  |
| evaluation/return-min          | 450.8916   |
| evaluation/return-std          | 4.4440804  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46468      |
| perf/AverageLength             | 154        |
| perf/AverageReturn             | 459.27057  |
| perf/NormalizedReturn          | 0.0997     |
| Q-avg                          | 222.40869  |
| Q-std                          | 93.24727   |
| Q_loss                         | 116.0945   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 564        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000514   |
| times/evaluation_paths         | 5.52       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 62.6       |
| timestep                       | 1000       |
| timesteps_total                | 565000     |
| train-steps                    | 565000     |
| training/Q/q1_loss             | 119.31211  |
| training/sac_pi/alpha          | 0.16124155 |
| training/sac_pi/alpha_loss     | 0.1020575  |
| training/sac_pi/logp_pi        | 4.541665   |
| training/sac_pi/pi_entropy     | 3.3941026  |
| training/sac_pi/pi_global_norm | 1.6135826  |
| training/sac_pi/policy_loss    | -220.84857 |
| training/sac_pi/std            | 0.5044638  |
| training/sac_pi/valid_num      | 4962.0     |
| training/sac_Q/q1              | 207.93657  |
| training/sac_Q/q2              | 209.7941   |
| training/sac_Q/q2_loss         | 118.837    |
| training/sac_Q/q_global_norm   | 198.47043  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16479743  |
| epoch                          | 565         |
| evaluation/episode-length-avg  | 321         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 162         |
| evaluation/episode-length-std  | 307         |
| evaluation/return-average      | 1392.6423   |
| evaluation/return-max          | 5204.9873   |
| evaluation/return-min          | 506.8716    |
| evaluation/return-std          | 1710.3717   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46441       |
| perf/AverageLength             | 321         |
| perf/AverageReturn             | 1392.6423   |
| perf/NormalizedReturn          | 0.303       |
| Q-avg                          | 216.85738   |
| Q-std                          | 129.30743   |
| Q_loss                         | 90.62783    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 565         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000319    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000658    |
| times/evaluation_paths         | 12.7        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 566000      |
| train-steps                    | 566000      |
| training/Q/q1_loss             | 121.56943   |
| training/sac_pi/alpha          | 0.16482475  |
| training/sac_pi/alpha_loss     | -0.17976627 |
| training/sac_pi/logp_pi        | 4.4906325   |
| training/sac_pi/pi_entropy     | 3.3744628   |
| training/sac_pi/pi_global_norm | 2.4634435   |
| training/sac_pi/policy_loss    | -225.63495  |
| training/sac_pi/std            | 0.4960848   |
| training/sac_pi/valid_num      | 4973.0      |
| training/sac_Q/q1              | 212.48701   |
| training/sac_Q/q2              | 216.49252   |
| training/sac_Q/q2_loss         | 121.230064  |
| training/sac_Q/q_global_norm   | 345.0439    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16653377 |
| epoch                          | 566        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4982.9443  |
| evaluation/return-max          | 5023.89    |
| evaluation/return-min          | 4925.2236  |
| evaluation/return-std          | 32.444225  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46470      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4982.9443  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 221.478    |
| Q-std                          | 97.6342    |
| Q_loss                         | 105.28067  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 566        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000145   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000615   |
| times/evaluation_paths         | 37.1       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 63.7       |
| timestep                       | 1000       |
| timesteps_total                | 567000     |
| train-steps                    | 567000     |
| training/Q/q1_loss             | 105.46     |
| training/sac_pi/alpha          | 0.16654171 |
| training/sac_pi/alpha_loss     | 0.1224648  |
| training/sac_pi/logp_pi        | 4.0313525  |
| training/sac_pi/pi_entropy     | 3.6646378  |
| training/sac_pi/pi_global_norm | 1.6129302  |
| training/sac_pi/policy_loss    | -217.8312  |
| training/sac_pi/std            | 0.5093427  |
| training/sac_pi/valid_num      | 4947.0     |
| training/sac_Q/q1              | 210.6814   |
| training/sac_Q/q2              | 211.20157  |
| training/sac_Q/q2_loss         | 106.46398  |
| training/sac_Q/q_global_norm   | 244.95973  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16287991 |
| epoch                          | 567        |
| evaluation/episode-length-avg  | 916        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 162        |
| evaluation/episode-length-std  | 251        |
| evaluation/return-average      | 4668.297   |
| evaluation/return-max          | 5170.5703  |
| evaluation/return-min          | 489.64825  |
| evaluation/return-std          | 1393.0883  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46371      |
| perf/AverageLength             | 916        |
| perf/AverageReturn             | 4668.297   |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 214.19902  |
| Q-std                          | 122.49132  |
| Q_loss                         | 78.43223   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 567        |
| times/epoch_after_hook         | 1.61e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000521   |
| times/evaluation_paths         | 35         |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 72.3       |
| timestep                       | 1000       |
| timesteps_total                | 568000     |
| train-steps                    | 568000     |
| training/Q/q1_loss             | 96.27979   |
| training/sac_pi/alpha          | 0.1628686  |
| training/sac_pi/alpha_loss     | 0.08367395 |
| training/sac_pi/logp_pi        | 4.81775    |
| training/sac_pi/pi_entropy     | 3.3588097  |
| training/sac_pi/pi_global_norm | 2.439573   |
| training/sac_pi/policy_loss    | -224.63512 |
| training/sac_pi/std            | 0.50354147 |
| training/sac_pi/valid_num      | 4918.0     |
| training/sac_Q/q1              | 206.9288   |
| training/sac_Q/q2              | 208.07207  |
| training/sac_Q/q2_loss         | 96.41361   |
| training/sac_Q/q_global_norm   | 253.6585   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16077341 |
| epoch                          | 568        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5057.4277  |
| evaluation/return-max          | 5114.5527  |
| evaluation/return-min          | 4995.461   |
| evaluation/return-std          | 28.686277  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46469      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5057.4277  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 226.52995  |
| Q-std                          | 99.619576  |
| Q_loss                         | 88.41587   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 568        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.00051    |
| times/evaluation_paths         | 43.7       |
| times/timestep_after_hook      | 0.00354    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 69         |
| timestep                       | 1000       |
| timesteps_total                | 569000     |
| train-steps                    | 569000     |
| training/Q/q1_loss             | 98.148285  |
| training/sac_pi/alpha          | 0.16075064 |
| training/sac_pi/alpha_loss     | 0.2563057  |
| training/sac_pi/logp_pi        | 4.744565   |
| training/sac_pi/pi_entropy     | 3.2294223  |
| training/sac_pi/pi_global_norm | 1.8554782  |
| training/sac_pi/policy_loss    | -227.8352  |
| training/sac_pi/std            | 0.49712735 |
| training/sac_pi/valid_num      | 4950.0     |
| training/sac_Q/q1              | 214.14218  |
| training/sac_Q/q2              | 220.00728  |
| training/sac_Q/q2_loss         | 98.851456  |
| training/sac_Q/q_global_norm   | 186.70164  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.160985     |
| epoch                          | 569          |
| evaluation/episode-length-avg  | 930          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 601          |
| evaluation/episode-length-std  | 141          |
| evaluation/return-average      | 4776.9043    |
| evaluation/return-max          | 5267.1167    |
| evaluation/return-min          | 2899.7073    |
| evaluation/return-std          | 812.0487     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.15         |
| model/origin_ret               | 86.3         |
| model/penalty_ret              | 79           |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46660        |
| perf/AverageLength             | 930          |
| perf/AverageReturn             | 4776.9043    |
| perf/NormalizedReturn          | 1.04         |
| Q-avg                          | 217.31084    |
| Q-std                          | 122.91706    |
| Q_loss                         | 98.23541     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 569          |
| times/epoch_after_hook         | 1.69e-06     |
| times/epoch_before_hook        | 0.000285     |
| times/epoch_rollout_model      | 478          |
| times/evaluation_metrics       | 0.000517     |
| times/evaluation_paths         | 35.3         |
| times/timestep_after_hook      | 0.00355      |
| times/timestep_before_hook     | 0.00823      |
| times/train                    | 67.1         |
| timestep                       | 1000         |
| timesteps_total                | 570000       |
| train-steps                    | 570000       |
| training/Q/q1_loss             | 97.0792      |
| training/sac_pi/alpha          | 0.16103368   |
| training/sac_pi/alpha_loss     | -0.033660013 |
| training/sac_pi/logp_pi        | 3.9695358    |
| training/sac_pi/pi_entropy     | 3.39253      |
| training/sac_pi/pi_global_norm | 1.738873     |
| training/sac_pi/policy_loss    | -229.3921    |
| training/sac_pi/std            | 0.48783988   |
| training/sac_pi/valid_num      | 4925.0       |
| training/sac_Q/q1              | 220.22925    |
| training/sac_Q/q2              | 221.45193    |
| training/sac_Q/q2_loss         | 96.899826    |
| training/sac_Q/q_global_norm   | 227.05959    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16241118  |
| epoch                          | 570         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4914.971    |
| evaluation/return-max          | 4934.3105   |
| evaluation/return-min          | 4904.645    |
| evaluation/return-std          | 8.401158    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46406       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4914.971    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 221.4458    |
| Q-std                          | 109.103676  |
| Q_loss                         | 95.07814    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 570         |
| times/epoch_after_hook         | 1.57e-06    |
| times/epoch_before_hook        | 0.000115    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000563    |
| times/evaluation_paths         | 37.8        |
| times/timestep_after_hook      | 0.00356     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 72.8        |
| timestep                       | 1000        |
| timesteps_total                | 571000      |
| train-steps                    | 571000      |
| training/Q/q1_loss             | 95.06609    |
| training/sac_pi/alpha          | 0.1624496   |
| training/sac_pi/alpha_loss     | -0.23204185 |
| training/sac_pi/logp_pi        | 4.0357156   |
| training/sac_pi/pi_entropy     | 3.1769164   |
| training/sac_pi/pi_global_norm | 1.6823646   |
| training/sac_pi/policy_loss    | -232.70587  |
| training/sac_pi/std            | 0.48014247  |
| training/sac_pi/valid_num      | 5013.0      |
| training/sac_Q/q1              | 227.00204   |
| training/sac_Q/q2              | 227.97623   |
| training/sac_Q/q2_loss         | 95.40048    |
| training/sac_Q/q_global_norm   | 219.833     |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16311538 |
| epoch                          | 571        |
| evaluation/episode-length-avg  | 151        |
| evaluation/episode-length-max  | 153        |
| evaluation/episode-length-min  | 150        |
| evaluation/episode-length-std  | 0.775      |
| evaluation/return-average      | 463.29453  |
| evaluation/return-max          | 473.92334  |
| evaluation/return-min          | 455.36786  |
| evaluation/return-std          | 4.5669646  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46608      |
| perf/AverageLength             | 151        |
| perf/AverageReturn             | 463.29453  |
| perf/NormalizedReturn          | 0.101      |
| Q-avg                          | 212.40018  |
| Q-std                          | 104.48451  |
| Q_loss                         | 110.81865  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 571        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000113   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000515   |
| times/evaluation_paths         | 5.1        |
| times/timestep_after_hook      | 0.00348    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 572000     |
| train-steps                    | 572000     |
| training/Q/q1_loss             | 107.84163  |
| training/sac_pi/alpha          | 0.16312727 |
| training/sac_pi/alpha_loss     | 0.13694304 |
| training/sac_pi/logp_pi        | 5.2134004  |
| training/sac_pi/pi_entropy     | 3.46334    |
| training/sac_pi/pi_global_norm | 1.9291313  |
| training/sac_pi/policy_loss    | -232.75719 |
| training/sac_pi/std            | 0.5524614  |
| training/sac_pi/valid_num      | 4926.0     |
| training/sac_Q/q1              | 215.6879   |
| training/sac_Q/q2              | 219.41826  |
| training/sac_Q/q2_loss         | 108.377884 |
| training/sac_Q/q_global_norm   | 224.43094  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16148637  |
| epoch                          | 572         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5100.827    |
| evaluation/return-max          | 5153.798    |
| evaluation/return-min          | 5026.8286   |
| evaluation/return-std          | 36.470787   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 81          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46446       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5100.827    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 205.76733   |
| Q-std                          | 159.68768   |
| Q_loss                         | 102.03958   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 572         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000119    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000565    |
| times/evaluation_paths         | 37          |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00829     |
| times/train                    | 63.7        |
| timestep                       | 1000        |
| timesteps_total                | 573000      |
| train-steps                    | 573000      |
| training/Q/q1_loss             | 102.69139   |
| training/sac_pi/alpha          | 0.16147575  |
| training/sac_pi/alpha_loss     | -0.20055918 |
| training/sac_pi/logp_pi        | 3.6643143   |
| training/sac_pi/pi_entropy     | 3.387982    |
| training/sac_pi/pi_global_norm | 1.7207867   |
| training/sac_pi/policy_loss    | -236.55446  |
| training/sac_pi/std            | 0.48403564  |
| training/sac_pi/valid_num      | 4994.0      |
| training/sac_Q/q1              | 228.0024    |
| training/sac_Q/q2              | 228.28531   |
| training/sac_Q/q2_loss         | 102.60964   |
| training/sac_Q/q_global_norm   | 182.7834    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16420552 |
| epoch                          | 573        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4893.472   |
| evaluation/return-max          | 4998.1406  |
| evaluation/return-min          | 4785.308   |
| evaluation/return-std          | 58.012066  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46512      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4893.472   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 227.13681  |
| Q-std                          | 95.45774   |
| Q_loss                         | 96.14834   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 573        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000341   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000619   |
| times/evaluation_paths         | 45.1       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00842    |
| times/train                    | 65.6       |
| timestep                       | 1000       |
| timesteps_total                | 574000     |
| train-steps                    | 574000     |
| training/Q/q1_loss             | 125.15398  |
| training/sac_pi/alpha          | 0.16421591 |
| training/sac_pi/alpha_loss     | -0.3065858 |
| training/sac_pi/logp_pi        | 4.277121   |
| training/sac_pi/pi_entropy     | 3.5554194  |
| training/sac_pi/pi_global_norm | 1.9195442  |
| training/sac_pi/policy_loss    | -227.79012 |
| training/sac_pi/std            | 0.51606375 |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 218.98686  |
| training/sac_Q/q2              | 222.901    |
| training/sac_Q/q2_loss         | 125.09207  |
| training/sac_Q/q_global_norm   | 240.25899  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16700973  |
| epoch                          | 574         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4882.48     |
| evaluation/return-max          | 4919.533    |
| evaluation/return-min          | 4837.818    |
| evaluation/return-std          | 26.359442   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.15        |
| model/origin_ret               | 87.1        |
| model/penalty_ret              | 80.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46435       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4882.48     |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 214.5592    |
| Q-std                          | 174.65854   |
| Q_loss                         | 98.49579    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 574         |
| times/epoch_after_hook         | 2.01e-06    |
| times/epoch_before_hook        | 0.00012     |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000665    |
| times/evaluation_paths         | 42.9        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.0084      |
| times/train                    | 68.4        |
| timestep                       | 1000        |
| timesteps_total                | 575000      |
| train-steps                    | 575000      |
| training/Q/q1_loss             | 95.96947    |
| training/sac_pi/alpha          | 0.16702111  |
| training/sac_pi/alpha_loss     | -0.04769682 |
| training/sac_pi/logp_pi        | 4.2832446   |
| training/sac_pi/pi_entropy     | 3.49377     |
| training/sac_pi/pi_global_norm | 2.3121743   |
| training/sac_pi/policy_loss    | -217.57321  |
| training/sac_pi/std            | 0.5029351   |
| training/sac_pi/valid_num      | 4992.0      |
| training/sac_Q/q1              | 209.28865   |
| training/sac_Q/q2              | 209.43535   |
| training/sac_Q/q2_loss         | 96.3418     |
| training/sac_Q/q_global_norm   | 232.74124   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1597006  |
| epoch                          | 575        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5138.825   |
| evaluation/return-max          | 5169.369   |
| evaluation/return-min          | 5115.377   |
| evaluation/return-std          | 15.526478  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46262      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5138.825   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 211.68742  |
| Q-std                          | 137.54343  |
| Q_loss                         | 122.06536  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 575        |
| times/epoch_after_hook         | 2.81e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000674   |
| times/evaluation_paths         | 35.3       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 63.2       |
| timestep                       | 1000       |
| timesteps_total                | 576000     |
| train-steps                    | 576000     |
| training/Q/q1_loss             | 85.29868   |
| training/sac_pi/alpha          | 0.15967923 |
| training/sac_pi/alpha_loss     | 0.07554564 |
| training/sac_pi/logp_pi        | 4.376456   |
| training/sac_pi/pi_entropy     | 3.3585835  |
| training/sac_pi/pi_global_norm | 1.5107796  |
| training/sac_pi/policy_loss    | -227.2008  |
| training/sac_pi/std            | 0.49017265 |
| training/sac_pi/valid_num      | 5011.0     |
| training/sac_Q/q1              | 216.4708   |
| training/sac_Q/q2              | 219.61406  |
| training/sac_Q/q2_loss         | 85.63704   |
| training/sac_Q/q_global_norm   | 187.83119  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16468981 |
| epoch                          | 576        |
| evaluation/episode-length-avg  | 155        |
| evaluation/episode-length-max  | 159        |
| evaluation/episode-length-min  | 150        |
| evaluation/episode-length-std  | 2.5        |
| evaluation/return-average      | 488.13696  |
| evaluation/return-max          | 499.3958   |
| evaluation/return-min          | 473.25424  |
| evaluation/return-std          | 6.9994507  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46389      |
| perf/AverageLength             | 155        |
| perf/AverageReturn             | 488.13696  |
| perf/NormalizedReturn          | 0.106      |
| Q-avg                          | 217.34055  |
| Q-std                          | 113.71938  |
| Q_loss                         | 96.41521   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 576        |
| times/epoch_after_hook         | 3e-06      |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000548   |
| times/evaluation_paths         | 5.2        |
| times/timestep_after_hook      | 0.00354    |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 577000     |
| train-steps                    | 577000     |
| training/Q/q1_loss             | 102.51322  |
| training/sac_pi/alpha          | 0.16465652 |
| training/sac_pi/alpha_loss     | 0.09544413 |
| training/sac_pi/logp_pi        | 4.218747   |
| training/sac_pi/pi_entropy     | 3.5591297  |
| training/sac_pi/pi_global_norm | 1.6838303  |
| training/sac_pi/policy_loss    | -216.54785 |
| training/sac_pi/std            | 0.5098154  |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 202.90549  |
| training/sac_Q/q2              | 205.94778  |
| training/sac_Q/q2_loss         | 103.81383  |
| training/sac_Q/q_global_norm   | 261.24313  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16431046  |
| epoch                          | 577         |
| evaluation/episode-length-avg  | 494         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 151         |
| evaluation/episode-length-std  | 413         |
| evaluation/return-average      | 2329.1724   |
| evaluation/return-max          | 5096.2637   |
| evaluation/return-min          | 475.33554   |
| evaluation/return-std          | 2246.9395   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 78.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46532       |
| perf/AverageLength             | 494         |
| perf/AverageReturn             | 2329.1724   |
| perf/NormalizedReturn          | 0.507       |
| Q-avg                          | 221.28775   |
| Q-std                          | 170.31874   |
| Q_loss                         | 125.44527   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 577         |
| times/epoch_after_hook         | 1.66e-06    |
| times/epoch_before_hook        | 0.000312    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000514    |
| times/evaluation_paths         | 19          |
| times/timestep_after_hook      | 0.00357     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 62.8        |
| timestep                       | 1000        |
| timesteps_total                | 578000      |
| train-steps                    | 578000      |
| training/Q/q1_loss             | 85.37684    |
| training/sac_pi/alpha          | 0.1643191   |
| training/sac_pi/alpha_loss     | -0.19539568 |
| training/sac_pi/logp_pi        | 4.1581497   |
| training/sac_pi/pi_entropy     | 3.5464394   |
| training/sac_pi/pi_global_norm | 1.6799588   |
| training/sac_pi/policy_loss    | -223.87405  |
| training/sac_pi/std            | 0.5120481   |
| training/sac_pi/valid_num      | 4919.0      |
| training/sac_Q/q1              | 212.2576    |
| training/sac_Q/q2              | 212.10637   |
| training/sac_Q/q2_loss         | 84.63524    |
| training/sac_Q/q_global_norm   | 247.4956    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16462623 |
| epoch                          | 578        |
| evaluation/episode-length-avg  | 326        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 152        |
| evaluation/episode-length-std  | 337        |
| evaluation/return-average      | 1301.6987  |
| evaluation/return-max          | 4557.757   |
| evaluation/return-min          | 473.17603  |
| evaluation/return-std          | 1617.6195  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46461      |
| perf/AverageLength             | 326        |
| perf/AverageReturn             | 1301.6987  |
| perf/NormalizedReturn          | 0.283      |
| Q-avg                          | 219.59038  |
| Q-std                          | 126.986664 |
| Q_loss                         | 76.86663   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 578        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000478   |
| times/evaluation_paths         | 10.4       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 62.9       |
| timestep                       | 1000       |
| timesteps_total                | 579000     |
| train-steps                    | 579000     |
| training/Q/q1_loss             | 109.23641  |
| training/sac_pi/alpha          | 0.16458623 |
| training/sac_pi/alpha_loss     | 0.18095692 |
| training/sac_pi/logp_pi        | 4.5081363  |
| training/sac_pi/pi_entropy     | 3.4968362  |
| training/sac_pi/pi_global_norm | 1.8136634  |
| training/sac_pi/policy_loss    | -233.04214 |
| training/sac_pi/std            | 0.5107621  |
| training/sac_pi/valid_num      | 4912.0     |
| training/sac_Q/q1              | 218.6938   |
| training/sac_Q/q2              | 221.2205   |
| training/sac_Q/q2_loss         | 109.54769  |
| training/sac_Q/q_global_norm   | 231.41422  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16244413  |
| epoch                          | 579         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4496.369    |
| evaluation/return-max          | 4636.4736   |
| evaluation/return-min          | 4428.6895   |
| evaluation/return-std          | 56.06614    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46512       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4496.369    |
| perf/NormalizedReturn          | 0.979       |
| Q-avg                          | 212.65063   |
| Q-std                          | 162.60368   |
| Q_loss                         | 95.91749    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 579         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000145    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.00055     |
| times/evaluation_paths         | 37.2        |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 61.8        |
| timestep                       | 1000        |
| timesteps_total                | 580000      |
| train-steps                    | 580000      |
| training/Q/q1_loss             | 112.49638   |
| training/sac_pi/alpha          | 0.16245317  |
| training/sac_pi/alpha_loss     | -0.36869535 |
| training/sac_pi/logp_pi        | 4.4337573   |
| training/sac_pi/pi_entropy     | 3.459294    |
| training/sac_pi/pi_global_norm | 1.797474    |
| training/sac_pi/policy_loss    | -223.83545  |
| training/sac_pi/std            | 0.5116852   |
| training/sac_pi/valid_num      | 4980.0      |
| training/sac_Q/q1              | 210.41895   |
| training/sac_Q/q2              | 213.86816   |
| training/sac_Q/q2_loss         | 112.16444   |
| training/sac_Q/q_global_norm   | 216.92075   |
---------------------------------------------------------------------------------
[WARN] 580 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.1643181   |
| epoch                          | 580         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4958.612    |
| evaluation/return-max          | 5042.8      |
| evaluation/return-min          | 4881.5996   |
| evaluation/return-std          | 43.395542   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46369       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4958.612    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 212.39987   |
| Q-std                          | 138.86845   |
| Q_loss                         | 100.32153   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 580         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000486    |
| times/evaluation_paths         | 33.8        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00827     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 581000      |
| train-steps                    | 581000      |
| training/Q/q1_loss             | 74.66266    |
| training/sac_pi/alpha          | 0.16432758  |
| training/sac_pi/alpha_loss     | -0.45584366 |
| training/sac_pi/logp_pi        | 4.4067345   |
| training/sac_pi/pi_entropy     | 3.50298     |
| training/sac_pi/pi_global_norm | 1.8865415   |
| training/sac_pi/policy_loss    | -228.60297  |
| training/sac_pi/std            | 0.51683676  |
| training/sac_pi/valid_num      | 4946.0      |
| training/sac_Q/q1              | 215.87871   |
| training/sac_Q/q2              | 218.10953   |
| training/sac_Q/q2_loss         | 75.36989    |
| training/sac_Q/q_global_norm   | 221.64551   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16504924  |
| epoch                          | 581         |
| evaluation/episode-length-avg  | 166         |
| evaluation/episode-length-max  | 169         |
| evaluation/episode-length-min  | 162         |
| evaluation/episode-length-std  | 2.06        |
| evaluation/return-average      | 507.60028   |
| evaluation/return-max          | 523.5762    |
| evaluation/return-min          | 489.25476   |
| evaluation/return-std          | 10.299561   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46428       |
| perf/AverageLength             | 166         |
| perf/AverageReturn             | 507.60028   |
| perf/NormalizedReturn          | 0.11        |
| Q-avg                          | 230.06963   |
| Q-std                          | 137.06056   |
| Q_loss                         | 85.09921    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 581         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000282    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000586    |
| times/evaluation_paths         | 5.78        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 65.6        |
| timestep                       | 1000        |
| timesteps_total                | 582000      |
| train-steps                    | 582000      |
| training/Q/q1_loss             | 82.54782    |
| training/sac_pi/alpha          | 0.16502865  |
| training/sac_pi/alpha_loss     | -0.17681444 |
| training/sac_pi/logp_pi        | 3.2900817   |
| training/sac_pi/pi_entropy     | 3.4596882   |
| training/sac_pi/pi_global_norm | 1.5190183   |
| training/sac_pi/policy_loss    | -228.15681  |
| training/sac_pi/std            | 0.47134832  |
| training/sac_pi/valid_num      | 4974.0      |
| training/sac_Q/q1              | 221.9216    |
| training/sac_Q/q2              | 222.75322   |
| training/sac_Q/q2_loss         | 82.46627    |
| training/sac_Q/q_global_norm   | 230.83792   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1653282   |
| epoch                          | 582         |
| evaluation/episode-length-avg  | 835         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 374         |
| evaluation/episode-length-std  | 255         |
| evaluation/return-average      | 4238.027    |
| evaluation/return-max          | 5272.9326   |
| evaluation/return-min          | 1529.8037   |
| evaluation/return-std          | 1533.9685   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46301       |
| perf/AverageLength             | 835         |
| perf/AverageReturn             | 4238.027    |
| perf/NormalizedReturn          | 0.923       |
| Q-avg                          | 222.52942   |
| Q-std                          | 92.54432    |
| Q_loss                         | 81.942696   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 582         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000625    |
| times/evaluation_paths         | 29.7        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00829     |
| times/train                    | 62.1        |
| timestep                       | 1000        |
| timesteps_total                | 583000      |
| train-steps                    | 583000      |
| training/Q/q1_loss             | 89.6374     |
| training/sac_pi/alpha          | 0.16534334  |
| training/sac_pi/alpha_loss     | 0.006210012 |
| training/sac_pi/logp_pi        | 5.0779366   |
| training/sac_pi/pi_entropy     | 3.656519    |
| training/sac_pi/pi_global_norm | 2.3358133   |
| training/sac_pi/policy_loss    | -217.09581  |
| training/sac_pi/std            | 0.5405956   |
| training/sac_pi/valid_num      | 4938.0      |
| training/sac_Q/q1              | 206.48833   |
| training/sac_Q/q2              | 209.42456   |
| training/sac_Q/q2_loss         | 89.90728    |
| training/sac_Q/q_global_norm   | 237.38428   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16730846 |
| epoch                          | 583        |
| evaluation/episode-length-avg  | 873        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 358        |
| evaluation/episode-length-std  | 255        |
| evaluation/return-average      | 4321.5503  |
| evaluation/return-max          | 5150.134   |
| evaluation/return-min          | 1401.0637  |
| evaluation/return-std          | 1455.1101  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46495      |
| perf/AverageLength             | 873        |
| perf/AverageReturn             | 4321.5503  |
| perf/NormalizedReturn          | 0.941      |
| Q-avg                          | 222.64983  |
| Q-std                          | 132.56506  |
| Q_loss                         | 85.28825   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 583        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000577   |
| times/evaluation_paths         | 31.9       |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 584000     |
| train-steps                    | 584000     |
| training/Q/q1_loss             | 97.77305   |
| training/sac_pi/alpha          | 0.16731675 |
| training/sac_pi/alpha_loss     | 0.13399465 |
| training/sac_pi/logp_pi        | 4.1413603  |
| training/sac_pi/pi_entropy     | 3.312069   |
| training/sac_pi/pi_global_norm | 1.6267345  |
| training/sac_pi/policy_loss    | -227.65392 |
| training/sac_pi/std            | 0.47851712 |
| training/sac_pi/valid_num      | 4958.0     |
| training/sac_Q/q1              | 216.15695  |
| training/sac_Q/q2              | 217.72641  |
| training/sac_Q/q2_loss         | 98.488525  |
| training/sac_Q/q_global_norm   | 207.93329  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16961864 |
| epoch                          | 584        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4749.6016  |
| evaluation/return-max          | 4887.4995  |
| evaluation/return-min          | 4657.298   |
| evaluation/return-std          | 59.937607  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46418      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4749.6016  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 224.57893  |
| Q-std                          | 103.19415  |
| Q_loss                         | 81.31272   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 584        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000585   |
| times/evaluation_paths         | 38         |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 585000     |
| train-steps                    | 585000     |
| training/Q/q1_loss             | 124.43686  |
| training/sac_pi/alpha          | 0.16961138 |
| training/sac_pi/alpha_loss     | 0.3116613  |
| training/sac_pi/logp_pi        | 4.7516723  |
| training/sac_pi/pi_entropy     | 3.6732337  |
| training/sac_pi/pi_global_norm | 2.052663   |
| training/sac_pi/policy_loss    | -225.12512 |
| training/sac_pi/std            | 0.53269076 |
| training/sac_pi/valid_num      | 4960.0     |
| training/sac_Q/q1              | 206.36874  |
| training/sac_Q/q2              | 212.60355  |
| training/sac_Q/q2_loss         | 124.68019  |
| training/sac_Q/q_global_norm   | 340.59982  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16531214  |
| epoch                          | 585         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4509.3506   |
| evaluation/return-max          | 4765.5264   |
| evaluation/return-min          | 4399.255    |
| evaluation/return-std          | 105.262886  |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46429       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4509.3506   |
| perf/NormalizedReturn          | 0.982       |
| Q-avg                          | 218.80167   |
| Q-std                          | 136.84474   |
| Q_loss                         | 86.60944    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 585         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000384    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000514    |
| times/evaluation_paths         | 34.3        |
| times/timestep_after_hook      | 0.00356     |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 64.6        |
| timestep                       | 1000        |
| timesteps_total                | 586000      |
| train-steps                    | 586000      |
| training/Q/q1_loss             | 131.57254   |
| training/sac_pi/alpha          | 0.16533552  |
| training/sac_pi/alpha_loss     | -0.19667539 |
| training/sac_pi/logp_pi        | 4.185071    |
| training/sac_pi/pi_entropy     | 3.5896785   |
| training/sac_pi/pi_global_norm | 2.0537853   |
| training/sac_pi/policy_loss    | -212.17278  |
| training/sac_pi/std            | 0.5182501   |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 204.31255   |
| training/sac_Q/q2              | 205.88179   |
| training/sac_Q/q2_loss         | 132.46835   |
| training/sac_Q/q_global_norm   | 280.6971    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16142802  |
| epoch                          | 586         |
| evaluation/episode-length-avg  | 876         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 748         |
| evaluation/episode-length-std  | 91.2        |
| evaluation/return-average      | 4382.381    |
| evaluation/return-max          | 5148.4688   |
| evaluation/return-min          | 3608.524    |
| evaluation/return-std          | 539.5938    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46337       |
| perf/AverageLength             | 876         |
| perf/AverageReturn             | 4382.381    |
| perf/NormalizedReturn          | 0.954       |
| Q-avg                          | 226.10803   |
| Q-std                          | 91.020096   |
| Q_loss                         | 97.05085    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 586         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000563    |
| times/evaluation_paths         | 30.5        |
| times/timestep_after_hook      | 0.00353     |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 587000      |
| train-steps                    | 587000      |
| training/Q/q1_loss             | 87.27676    |
| training/sac_pi/alpha          | 0.16142608  |
| training/sac_pi/alpha_loss     | -0.23118162 |
| training/sac_pi/logp_pi        | 4.819378    |
| training/sac_pi/pi_entropy     | 3.680114    |
| training/sac_pi/pi_global_norm | 1.6707761   |
| training/sac_pi/policy_loss    | -229.56477  |
| training/sac_pi/std            | 0.5442285   |
| training/sac_pi/valid_num      | 4934.0      |
| training/sac_Q/q1              | 215.15385   |
| training/sac_Q/q2              | 217.61983   |
| training/sac_Q/q2_loss         | 87.44784    |
| training/sac_Q/q_global_norm   | 185.10141   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16183557 |
| epoch                          | 587        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5100.2837  |
| evaluation/return-max          | 5156.877   |
| evaluation/return-min          | 4985.9062  |
| evaluation/return-std          | 49.947006  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.2        |
| model/origin_ret               | 87.6       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46369      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5100.2837  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 215.9386   |
| Q-std                          | 143.97032  |
| Q_loss                         | 97.67345   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 587        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000159   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000606   |
| times/evaluation_paths         | 35.9       |
| times/timestep_after_hook      | 0.00352    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 62.4       |
| timestep                       | 1000       |
| timesteps_total                | 588000     |
| train-steps                    | 588000     |
| training/Q/q1_loss             | 113.18118  |
| training/sac_pi/alpha          | 0.1618145  |
| training/sac_pi/alpha_loss     | -0.0501852 |
| training/sac_pi/logp_pi        | 4.05932    |
| training/sac_pi/pi_entropy     | 3.492759   |
| training/sac_pi/pi_global_norm | 1.7036033  |
| training/sac_pi/policy_loss    | -222.99393 |
| training/sac_pi/std            | 0.49037856 |
| training/sac_pi/valid_num      | 4996.0     |
| training/sac_Q/q1              | 214.47429  |
| training/sac_Q/q2              | 216.16443  |
| training/sac_Q/q2_loss         | 114.29915  |
| training/sac_Q/q_global_norm   | 226.70966  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16500856 |
| epoch                          | 588        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5067.659   |
| evaluation/return-max          | 5105.3516  |
| evaluation/return-min          | 4990.631   |
| evaluation/return-std          | 33.016125  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46425      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5067.659   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 218.27856  |
| Q-std                          | 140.9612   |
| Q_loss                         | 122.65042  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 588        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000527   |
| times/evaluation_paths         | 35.8       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 589000     |
| train-steps                    | 589000     |
| training/Q/q1_loss             | 102.643425 |
| training/sac_pi/alpha          | 0.16497666 |
| training/sac_pi/alpha_loss     | 0.41522285 |
| training/sac_pi/logp_pi        | 4.1640368  |
| training/sac_pi/pi_entropy     | 3.514457   |
| training/sac_pi/pi_global_norm | 2.4014812  |
| training/sac_pi/policy_loss    | -228.8695  |
| training/sac_pi/std            | 0.49848476 |
| training/sac_pi/valid_num      | 4989.0     |
| training/sac_Q/q1              | 220.5028   |
| training/sac_Q/q2              | 221.84688  |
| training/sac_Q/q2_loss         | 102.682365 |
| training/sac_Q/q_global_norm   | 224.04346  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15934592  |
| epoch                          | 589         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4963.218    |
| evaluation/return-max          | 4990.992    |
| evaluation/return-min          | 4912.294    |
| evaluation/return-std          | 22.667812   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 87.1        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46469       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4963.218    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 222.87354   |
| Q-std                          | 111.68385   |
| Q_loss                         | 99.27943    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 589         |
| times/epoch_after_hook         | 1.94e-06    |
| times/epoch_before_hook        | 0.000295    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000671    |
| times/evaluation_paths         | 37.9        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00873     |
| times/train                    | 67.8        |
| timestep                       | 1000        |
| timesteps_total                | 590000      |
| train-steps                    | 590000      |
| training/Q/q1_loss             | 86.113525   |
| training/sac_pi/alpha          | 0.1593468   |
| training/sac_pi/alpha_loss     | 0.026241608 |
| training/sac_pi/logp_pi        | 4.803777    |
| training/sac_pi/pi_entropy     | 3.4251206   |
| training/sac_pi/pi_global_norm | 1.77365     |
| training/sac_pi/policy_loss    | -224.85829  |
| training/sac_pi/std            | 0.50718606  |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 211.66301   |
| training/sac_Q/q2              | 213.13382   |
| training/sac_Q/q2_loss         | 85.480865   |
| training/sac_Q/q_global_norm   | 178.17946   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15938775 |
| epoch                          | 590        |
| evaluation/episode-length-avg  | 744        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 629        |
| evaluation/episode-length-std  | 113        |
| evaluation/return-average      | 3620.314   |
| evaluation/return-max          | 5211.4263  |
| evaluation/return-min          | 2959.7217  |
| evaluation/return-std          | 660.58636  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46572      |
| perf/AverageLength             | 744        |
| perf/AverageReturn             | 3620.314   |
| perf/NormalizedReturn          | 0.788      |
| Q-avg                          | 225.8669   |
| Q-std                          | 98.46082   |
| Q_loss                         | 100.448975 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 590        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000596   |
| times/evaluation_paths         | 27.7       |
| times/timestep_after_hook      | 0.00392    |
| times/timestep_before_hook     | 0.00871    |
| times/train                    | 62.8       |
| timestep                       | 1000       |
| timesteps_total                | 591000     |
| train-steps                    | 591000     |
| training/Q/q1_loss             | 100.07056  |
| training/sac_pi/alpha          | 0.15942115 |
| training/sac_pi/alpha_loss     | 0.12166138 |
| training/sac_pi/logp_pi        | 4.22391    |
| training/sac_pi/pi_entropy     | 3.3054771  |
| training/sac_pi/pi_global_norm | 1.5149689  |
| training/sac_pi/policy_loss    | -234.90504 |
| training/sac_pi/std            | 0.47628355 |
| training/sac_pi/valid_num      | 4989.0     |
| training/sac_Q/q1              | 222.19951  |
| training/sac_Q/q2              | 225.61362  |
| training/sac_Q/q2_loss         | 99.328545  |
| training/sac_Q/q_global_norm   | 289.59464  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16552632 |
| epoch                          | 591        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5012.4644  |
| evaluation/return-max          | 5080.475   |
| evaluation/return-min          | 4868.743   |
| evaluation/return-std          | 70.72384   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 79         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46466      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5012.4644  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 223.36699  |
| Q-std                          | 131.90376  |
| Q_loss                         | 110.056496 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 591        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000239   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000578   |
| times/evaluation_paths         | 34.8       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00852    |
| times/train                    | 62.4       |
| timestep                       | 1000       |
| timesteps_total                | 592000     |
| train-steps                    | 592000     |
| training/Q/q1_loss             | 123.91655  |
| training/sac_pi/alpha          | 0.1655002  |
| training/sac_pi/alpha_loss     | 0.46999666 |
| training/sac_pi/logp_pi        | 3.5784984  |
| training/sac_pi/pi_entropy     | 3.4274974  |
| training/sac_pi/pi_global_norm | 1.8115065  |
| training/sac_pi/policy_loss    | -225.30101 |
| training/sac_pi/std            | 0.46023545 |
| training/sac_pi/valid_num      | 5051.0     |
| training/sac_Q/q1              | 222.46756  |
| training/sac_Q/q2              | 222.77573  |
| training/sac_Q/q2_loss         | 124.1565   |
| training/sac_Q/q_global_norm   | 250.94928  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16418819 |
| epoch                          | 592        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5090.5137  |
| evaluation/return-max          | 5111.7153  |
| evaluation/return-min          | 5071.4023  |
| evaluation/return-std          | 12.6546755 |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46576      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5090.5137  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 214.9393   |
| Q-std                          | 109.8088   |
| Q_loss                         | 92.704834  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 592        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000521   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00354    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 593000     |
| train-steps                    | 593000     |
| training/Q/q1_loss             | 86.08817   |
| training/sac_pi/alpha          | 0.16417852 |
| training/sac_pi/alpha_loss     | 0.22032747 |
| training/sac_pi/logp_pi        | 4.287721   |
| training/sac_pi/pi_entropy     | 3.380616   |
| training/sac_pi/pi_global_norm | 2.4057772  |
| training/sac_pi/policy_loss    | -228.70671 |
| training/sac_pi/std            | 0.50227135 |
| training/sac_pi/valid_num      | 4990.0     |
| training/sac_Q/q1              | 216.68633  |
| training/sac_Q/q2              | 219.28622  |
| training/sac_Q/q2_loss         | 86.177185  |
| training/sac_Q/q_global_norm   | 256.5433   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16654463  |
| epoch                          | 593         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4975.2583   |
| evaluation/return-max          | 5056.17     |
| evaluation/return-min          | 4903.759    |
| evaluation/return-std          | 48.58154    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46503       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4975.2583   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 221.20981   |
| Q-std                          | 140.18468   |
| Q_loss                         | 108.02645   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 593         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000285    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000766    |
| times/evaluation_paths         | 37.4        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00832     |
| times/train                    | 63.2        |
| timestep                       | 1000        |
| timesteps_total                | 594000      |
| train-steps                    | 594000      |
| training/Q/q1_loss             | 84.30731    |
| training/sac_pi/alpha          | 0.1665672   |
| training/sac_pi/alpha_loss     | 0.020605398 |
| training/sac_pi/logp_pi        | 4.4056473   |
| training/sac_pi/pi_entropy     | 3.0124638   |
| training/sac_pi/pi_global_norm | 2.5331383   |
| training/sac_pi/policy_loss    | -223.42593  |
| training/sac_pi/std            | 0.44921842  |
| training/sac_pi/valid_num      | 4942.0      |
| training/sac_Q/q1              | 206.96565   |
| training/sac_Q/q2              | 212.23824   |
| training/sac_Q/q2_loss         | 83.87617    |
| training/sac_Q/q_global_norm   | 276.80518   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16704826 |
| epoch                          | 594        |
| evaluation/episode-length-avg  | 642        |
| evaluation/episode-length-max  | 856        |
| evaluation/episode-length-min  | 321        |
| evaluation/episode-length-std  | 153        |
| evaluation/return-average      | 2955.961   |
| evaluation/return-max          | 4089.8667  |
| evaluation/return-min          | 1219.224   |
| evaluation/return-std          | 838.10675  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46562      |
| perf/AverageLength             | 642        |
| perf/AverageReturn             | 2955.961   |
| perf/NormalizedReturn          | 0.644      |
| Q-avg                          | 220.00671  |
| Q-std                          | 116.06719  |
| Q_loss                         | 110.88756  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 594        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000147   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000541   |
| times/evaluation_paths         | 24.4       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 595000     |
| train-steps                    | 595000     |
| training/Q/q1_loss             | 111.537415 |
| training/sac_pi/alpha          | 0.16707455 |
| training/sac_pi/alpha_loss     | 0.14454971 |
| training/sac_pi/logp_pi        | 4.281616   |
| training/sac_pi/pi_entropy     | 3.5551353  |
| training/sac_pi/pi_global_norm | 2.1706436  |
| training/sac_pi/policy_loss    | -226.79279 |
| training/sac_pi/std            | 0.5061667  |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 211.30757  |
| training/sac_Q/q2              | 213.60147  |
| training/sac_Q/q2_loss         | 109.74688  |
| training/sac_Q/q_global_norm   | 203.41397  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16438396   |
| epoch                          | 595          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5167.3716    |
| evaluation/return-max          | 5268.9385    |
| evaluation/return-min          | 5057.239     |
| evaluation/return-std          | 77.19527     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.11         |
| model/origin_ret               | 86.6         |
| model/penalty_ret              | 80.3         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46307        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5167.3716    |
| perf/NormalizedReturn          | 1.13         |
| Q-avg                          | 205.89693    |
| Q-std                          | 142.98131    |
| Q_loss                         | 133.14635    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 595          |
| times/epoch_after_hook         | 1.68e-06     |
| times/epoch_before_hook        | 0.000128     |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.000557     |
| times/evaluation_paths         | 37.2         |
| times/timestep_after_hook      | 0.00357      |
| times/timestep_before_hook     | 0.00845      |
| times/train                    | 62.6         |
| timestep                       | 1000         |
| timesteps_total                | 596000       |
| train-steps                    | 596000       |
| training/Q/q1_loss             | 97.31213     |
| training/sac_pi/alpha          | 0.16440171   |
| training/sac_pi/alpha_loss     | -0.055298883 |
| training/sac_pi/logp_pi        | 3.8509655    |
| training/sac_pi/pi_entropy     | 3.3644135    |
| training/sac_pi/pi_global_norm | 2.1657655    |
| training/sac_pi/policy_loss    | -219.64394   |
| training/sac_pi/std            | 0.48112747   |
| training/sac_pi/valid_num      | 4991.0       |
| training/sac_Q/q1              | 211.74448    |
| training/sac_Q/q2              | 213.61954    |
| training/sac_Q/q2_loss         | 99.76569     |
| training/sac_Q/q_global_norm   | 170.98726    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16262373 |
| epoch                          | 596        |
| evaluation/episode-length-avg  | 853        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 444        |
| evaluation/episode-length-std  | 226        |
| evaluation/return-average      | 3922.521   |
| evaluation/return-max          | 4728.0376  |
| evaluation/return-min          | 1775.9192  |
| evaluation/return-std          | 1188.0222  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46474      |
| perf/AverageLength             | 853        |
| perf/AverageReturn             | 3922.521   |
| perf/NormalizedReturn          | 0.854      |
| Q-avg                          | 222.24045  |
| Q-std                          | 115.34675  |
| Q_loss                         | 110.04572  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 596        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000578   |
| times/evaluation_paths         | 29.9       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 597000     |
| train-steps                    | 597000     |
| training/Q/q1_loss             | 105.82144  |
| training/sac_pi/alpha          | 0.16262724 |
| training/sac_pi/alpha_loss     | 0.10159432 |
| training/sac_pi/logp_pi        | 4.0427284  |
| training/sac_pi/pi_entropy     | 3.256314   |
| training/sac_pi/pi_global_norm | 1.9362496  |
| training/sac_pi/policy_loss    | -226.42972 |
| training/sac_pi/std            | 0.477517   |
| training/sac_pi/valid_num      | 4971.0     |
| training/sac_Q/q1              | 216.14444  |
| training/sac_Q/q2              | 218.6832   |
| training/sac_Q/q2_loss         | 106.35701  |
| training/sac_Q/q_global_norm   | 212.97446  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16674297 |
| epoch                          | 597        |
| evaluation/episode-length-avg  | 927        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 274        |
| evaluation/episode-length-std  | 218        |
| evaluation/return-average      | 4579.9585  |
| evaluation/return-max          | 5063.4287  |
| evaluation/return-min          | 1028.1526  |
| evaluation/return-std          | 1185.2374  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.04       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46309      |
| perf/AverageLength             | 927        |
| perf/AverageReturn             | 4579.9585  |
| perf/NormalizedReturn          | 0.997      |
| Q-avg                          | 206.9825   |
| Q-std                          | 184.80513  |
| Q_loss                         | 90.54111   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 597        |
| times/epoch_after_hook         | 1.54e-06   |
| times/epoch_before_hook        | 0.00028    |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000614   |
| times/evaluation_paths         | 32.6       |
| times/timestep_after_hook      | 0.00354    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 598000     |
| train-steps                    | 598000     |
| training/Q/q1_loss             | 124.64703  |
| training/sac_pi/alpha          | 0.16673504 |
| training/sac_pi/alpha_loss     | 0.27911553 |
| training/sac_pi/logp_pi        | 4.093478   |
| training/sac_pi/pi_entropy     | 3.373671   |
| training/sac_pi/pi_global_norm | 1.638838   |
| training/sac_pi/policy_loss    | -227.57773 |
| training/sac_pi/std            | 0.4695568  |
| training/sac_pi/valid_num      | 4918.0     |
| training/sac_Q/q1              | 216.35071  |
| training/sac_Q/q2              | 217.33418  |
| training/sac_Q/q2_loss         | 124.249405 |
| training/sac_Q/q_global_norm   | 283.96463  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15956768 |
| epoch                          | 598        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4743.434   |
| evaluation/return-max          | 4872.252   |
| evaluation/return-min          | 4642.9033  |
| evaluation/return-std          | 77.98894   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46386      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4743.434   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 211.32072  |
| Q-std                          | 151.79068  |
| Q_loss                         | 101.1508   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 598        |
| times/epoch_after_hook         | 2.02e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.00063    |
| times/evaluation_paths         | 37.5       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 599000     |
| train-steps                    | 599000     |
| training/Q/q1_loss             | 95.606674  |
| training/sac_pi/alpha          | 0.1595519  |
| training/sac_pi/alpha_loss     | 0.24491446 |
| training/sac_pi/logp_pi        | 4.102585   |
| training/sac_pi/pi_entropy     | 3.3390603  |
| training/sac_pi/pi_global_norm | 1.7651714  |
| training/sac_pi/policy_loss    | -229.80064 |
| training/sac_pi/std            | 0.4851436  |
| training/sac_pi/valid_num      | 4990.0     |
| training/sac_Q/q1              | 221.07295  |
| training/sac_Q/q2              | 223.43794  |
| training/sac_Q/q2_loss         | 94.65651   |
| training/sac_Q/q_global_norm   | 181.56781  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16227213  |
| epoch                          | 599         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4958.7476   |
| evaluation/return-max          | 5017.045    |
| evaluation/return-min          | 4803.14     |
| evaluation/return-std          | 57.04158    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 78.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46246       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4958.7476   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 227.56262   |
| Q-std                          | 136.16167   |
| Q_loss                         | 97.30862    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 599         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.00028     |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000553    |
| times/evaluation_paths         | 36.4        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 62          |
| timestep                       | 1000        |
| timesteps_total                | 600000      |
| train-steps                    | 600000      |
| training/Q/q1_loss             | 79.368195   |
| training/sac_pi/alpha          | 0.16226788  |
| training/sac_pi/alpha_loss     | -0.21767151 |
| training/sac_pi/logp_pi        | 4.1454687   |
| training/sac_pi/pi_entropy     | 3.4095905   |
| training/sac_pi/pi_global_norm | 1.610594    |
| training/sac_pi/policy_loss    | -228.2838   |
| training/sac_pi/std            | 0.5058648   |
| training/sac_pi/valid_num      | 4944.0      |
| training/sac_Q/q1              | 218.35715   |
| training/sac_Q/q2              | 220.70395   |
| training/sac_Q/q2_loss         | 81.60891    |
| training/sac_Q/q_global_norm   | 269.6422    |
---------------------------------------------------------------------------------
[WARN] 600 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16751257  |
| epoch                          | 600         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5001.355    |
| evaluation/return-max          | 5062.882    |
| evaluation/return-min          | 4909.674    |
| evaluation/return-std          | 51.74539    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86          |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46390       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5001.355    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 202.58215   |
| Q-std                          | 199.87126   |
| Q_loss                         | 120.30738   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 600         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000645    |
| times/evaluation_paths         | 38.4        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 62.1        |
| timestep                       | 1000        |
| timesteps_total                | 601000      |
| train-steps                    | 601000      |
| training/Q/q1_loss             | 88.59036    |
| training/sac_pi/alpha          | 0.16748986  |
| training/sac_pi/alpha_loss     | 0.017183097 |
| training/sac_pi/logp_pi        | 4.222554    |
| training/sac_pi/pi_entropy     | 3.549005    |
| training/sac_pi/pi_global_norm | 1.7798564   |
| training/sac_pi/policy_loss    | -230.25142  |
| training/sac_pi/std            | 0.51445323  |
| training/sac_pi/valid_num      | 4954.0      |
| training/sac_Q/q1              | 218.08443   |
| training/sac_Q/q2              | 221.13528   |
| training/sac_Q/q2_loss         | 90.11956    |
| training/sac_Q/q_global_norm   | 214.22798   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16281478 |
| epoch                          | 601        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4880.5503  |
| evaluation/return-max          | 5094.588   |
| evaluation/return-min          | 4701.935   |
| evaluation/return-std          | 112.080734 |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46150      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4880.5503  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 203.80565  |
| Q-std                          | 170.79291  |
| Q_loss                         | 92.734856  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 601        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000293   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000597   |
| times/evaluation_paths         | 35.9       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 602000     |
| train-steps                    | 602000     |
| training/Q/q1_loss             | 94.30774   |
| training/sac_pi/alpha          | 0.16284995 |
| training/sac_pi/alpha_loss     | -0.3686376 |
| training/sac_pi/logp_pi        | 4.012134   |
| training/sac_pi/pi_entropy     | 3.3779442  |
| training/sac_pi/pi_global_norm | 1.87891    |
| training/sac_pi/policy_loss    | -229.92534 |
| training/sac_pi/std            | 0.48690966 |
| training/sac_pi/valid_num      | 4981.0     |
| training/sac_Q/q1              | 219.9548   |
| training/sac_Q/q2              | 221.36763  |
| training/sac_Q/q2_loss         | 93.78201   |
| training/sac_Q/q_global_norm   | 189.36877  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1667224  |
| epoch                          | 602        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5064.1357  |
| evaluation/return-max          | 5137.6807  |
| evaluation/return-min          | 4984.56    |
| evaluation/return-std          | 48.09034   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46365      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5064.1357  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 206.58887  |
| Q-std                          | 124.357765 |
| Q_loss                         | 113.81811  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 602        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.00014    |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000679   |
| times/evaluation_paths         | 35.2       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 62.8       |
| timestep                       | 1000       |
| timesteps_total                | 603000     |
| train-steps                    | 603000     |
| training/Q/q1_loss             | 100.26519  |
| training/sac_pi/alpha          | 0.16670741 |
| training/sac_pi/alpha_loss     | 0.2534235  |
| training/sac_pi/logp_pi        | 4.7004046  |
| training/sac_pi/pi_entropy     | 3.5271049  |
| training/sac_pi/pi_global_norm | 2.3702059  |
| training/sac_pi/policy_loss    | -228.61443 |
| training/sac_pi/std            | 0.5071607  |
| training/sac_pi/valid_num      | 4938.0     |
| training/sac_Q/q1              | 214.20743  |
| training/sac_Q/q2              | 215.24203  |
| training/sac_Q/q2_loss         | 101.05447  |
| training/sac_Q/q_global_norm   | 287.67886  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16332883 |
| epoch                          | 603        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4966.5664  |
| evaluation/return-max          | 5115.1143  |
| evaluation/return-min          | 4881.2456  |
| evaluation/return-std          | 69.28883   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.19       |
| model/origin_ret               | 87.9       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46420      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4966.5664  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 218.7436   |
| Q-std                          | 115.2505   |
| Q_loss                         | 106.90003  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 603        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000549   |
| times/evaluation_paths         | 35.3       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00844    |
| times/train                    | 62.6       |
| timestep                       | 1000       |
| timesteps_total                | 604000     |
| train-steps                    | 604000     |
| training/Q/q1_loss             | 99.18679   |
| training/sac_pi/alpha          | 0.16329756 |
| training/sac_pi/alpha_loss     | 0.36870855 |
| training/sac_pi/logp_pi        | 4.2934456  |
| training/sac_pi/pi_entropy     | 3.3873048  |
| training/sac_pi/pi_global_norm | 1.9451176  |
| training/sac_pi/policy_loss    | -228.41423 |
| training/sac_pi/std            | 0.48557484 |
| training/sac_pi/valid_num      | 4996.0     |
| training/sac_Q/q1              | 221.08101  |
| training/sac_Q/q2              | 221.59294  |
| training/sac_Q/q2_loss         | 100.6116   |
| training/sac_Q/q_global_norm   | 292.01672  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16412689   |
| epoch                          | 604          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4985.6367    |
| evaluation/return-max          | 5069.2607    |
| evaluation/return-min          | 4904.407     |
| evaluation/return-std          | 55.55172     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.1          |
| model/origin_ret               | 85.5         |
| model/penalty_ret              | 79.1         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46472        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4985.6367    |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 208.9488     |
| Q-std                          | 153.83179    |
| Q_loss                         | 96.97642     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 604          |
| times/epoch_after_hook         | 1.88e-06     |
| times/epoch_before_hook        | 0.00013      |
| times/epoch_rollout_model      | 482          |
| times/evaluation_metrics       | 0.000682     |
| times/evaluation_paths         | 35.2         |
| times/timestep_after_hook      | 0.00363      |
| times/timestep_before_hook     | 0.00827      |
| times/train                    | 61.7         |
| timestep                       | 1000         |
| timesteps_total                | 605000       |
| train-steps                    | 605000       |
| training/Q/q1_loss             | 89.138565    |
| training/sac_pi/alpha          | 0.16413312   |
| training/sac_pi/alpha_loss     | -0.057946287 |
| training/sac_pi/logp_pi        | 4.5814567    |
| training/sac_pi/pi_entropy     | 3.332051     |
| training/sac_pi/pi_global_norm | 1.8171455    |
| training/sac_pi/policy_loss    | -235.80156   |
| training/sac_pi/std            | 0.49427637   |
| training/sac_pi/valid_num      | 4958.0       |
| training/sac_Q/q1              | 225.67952    |
| training/sac_Q/q2              | 227.84673    |
| training/sac_Q/q2_loss         | 90.25179     |
| training/sac_Q/q_global_norm   | 241.98975    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16386577 |
| epoch                          | 605        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4924.704   |
| evaluation/return-max          | 5048.084   |
| evaluation/return-min          | 4761.2783  |
| evaluation/return-std          | 83.86419   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46612      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4924.704   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 213.5585   |
| Q-std                          | 122.7475   |
| Q_loss                         | 81.246     |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 605        |
| times/epoch_after_hook         | 1.55e-06   |
| times/epoch_before_hook        | 0.00027    |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000552   |
| times/evaluation_paths         | 35.3       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 59.9       |
| timestep                       | 1000       |
| timesteps_total                | 606000     |
| train-steps                    | 606000     |
| training/Q/q1_loss             | 95.05815   |
| training/sac_pi/alpha          | 0.16386282 |
| training/sac_pi/alpha_loss     | 0.2502355  |
| training/sac_pi/logp_pi        | 4.2811136  |
| training/sac_pi/pi_entropy     | 3.3000512  |
| training/sac_pi/pi_global_norm | 1.684311   |
| training/sac_pi/policy_loss    | -231.73166 |
| training/sac_pi/std            | 0.47441795 |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 220.2441   |
| training/sac_Q/q2              | 223.23703  |
| training/sac_Q/q2_loss         | 96.45312   |
| training/sac_Q/q_global_norm   | 285.04785  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16200505 |
| epoch                          | 606        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4783.5103  |
| evaluation/return-max          | 4930.4316  |
| evaluation/return-min          | 4705.495   |
| evaluation/return-std          | 68.28565   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 87         |
| model/penalty_ret              | 80.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46448      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4783.5103  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 216.53189  |
| Q-std                          | 124.75476  |
| Q_loss                         | 103.588135 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 606        |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000512   |
| times/evaluation_paths         | 35.5       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 63         |
| timestep                       | 1000       |
| timesteps_total                | 607000     |
| train-steps                    | 607000     |
| training/Q/q1_loss             | 120.17758  |
| training/sac_pi/alpha          | 0.16198717 |
| training/sac_pi/alpha_loss     | 0.35609034 |
| training/sac_pi/logp_pi        | 4.700834   |
| training/sac_pi/pi_entropy     | 3.3697815  |
| training/sac_pi/pi_global_norm | 1.6900355  |
| training/sac_pi/policy_loss    | -217.28546 |
| training/sac_pi/std            | 0.48691574 |
| training/sac_pi/valid_num      | 4928.0     |
| training/sac_Q/q1              | 202.66208  |
| training/sac_Q/q2              | 204.37639  |
| training/sac_Q/q2_loss         | 120.59948  |
| training/sac_Q/q_global_norm   | 238.48419  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16509786  |
| epoch                          | 607         |
| evaluation/episode-length-avg  | 661         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 143         |
| evaluation/episode-length-std  | 415         |
| evaluation/return-average      | 3102.1548   |
| evaluation/return-max          | 4982.074    |
| evaluation/return-min          | 349.28934   |
| evaluation/return-std          | 2225.0999   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46459       |
| perf/AverageLength             | 661         |
| perf/AverageReturn             | 3102.1548   |
| perf/NormalizedReturn          | 0.675       |
| Q-avg                          | 230.95769   |
| Q-std                          | 103.81772   |
| Q_loss                         | 82.94208    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 607         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000467    |
| times/evaluation_paths         | 24.9        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 608000      |
| train-steps                    | 608000      |
| training/Q/q1_loss             | 88.416725   |
| training/sac_pi/alpha          | 0.16505976  |
| training/sac_pi/alpha_loss     | -0.14367191 |
| training/sac_pi/logp_pi        | 3.7760456   |
| training/sac_pi/pi_entropy     | 3.4330432   |
| training/sac_pi/pi_global_norm | 1.6725553   |
| training/sac_pi/policy_loss    | -231.07704  |
| training/sac_pi/std            | 0.4745592   |
| training/sac_pi/valid_num      | 4991.0      |
| training/sac_Q/q1              | 222.93623   |
| training/sac_Q/q2              | 223.28964   |
| training/sac_Q/q2_loss         | 88.229485   |
| training/sac_Q/q_global_norm   | 240.63615   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16620794  |
| epoch                          | 608         |
| evaluation/episode-length-avg  | 576         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 148         |
| evaluation/episode-length-std  | 424         |
| evaluation/return-average      | 2612.5781   |
| evaluation/return-max          | 4939.267    |
| evaluation/return-min          | 356.21176   |
| evaluation/return-std          | 2242.2192   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46393       |
| perf/AverageLength             | 576         |
| perf/AverageReturn             | 2612.5781   |
| perf/NormalizedReturn          | 0.569       |
| Q-avg                          | 204.61868   |
| Q-std                          | 134.39864   |
| Q_loss                         | 105.36491   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 608         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.00046     |
| times/evaluation_paths         | 23.6        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.0084      |
| times/train                    | 72          |
| timestep                       | 1000        |
| timesteps_total                | 609000      |
| train-steps                    | 609000      |
| training/Q/q1_loss             | 103.65414   |
| training/sac_pi/alpha          | 0.16621737  |
| training/sac_pi/alpha_loss     | -0.10734835 |
| training/sac_pi/logp_pi        | 3.6896229   |
| training/sac_pi/pi_entropy     | 3.4558074   |
| training/sac_pi/pi_global_norm | 1.702967    |
| training/sac_pi/policy_loss    | -229.22902  |
| training/sac_pi/std            | 0.47332314  |
| training/sac_pi/valid_num      | 4994.0      |
| training/sac_Q/q1              | 221.50053   |
| training/sac_Q/q2              | 222.1688    |
| training/sac_Q/q2_loss         | 103.103836  |
| training/sac_Q/q_global_norm   | 232.62236   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16181432 |
| epoch                          | 609        |
| evaluation/episode-length-avg  | 917        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 173        |
| evaluation/episode-length-std  | 248        |
| evaluation/return-average      | 4410.179   |
| evaluation/return-max          | 4900.4736  |
| evaluation/return-min          | 441.7874   |
| evaluation/return-std          | 1323.3446  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 87.3       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46452      |
| perf/AverageLength             | 917        |
| perf/AverageReturn             | 4410.179   |
| perf/NormalizedReturn          | 0.96       |
| Q-avg                          | 228.20667  |
| Q-std                          | 104.73379  |
| Q_loss                         | 86.03735   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 609        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000275   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000553   |
| times/evaluation_paths         | 33         |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 64.5       |
| timestep                       | 1000       |
| timesteps_total                | 610000     |
| train-steps                    | 610000     |
| training/Q/q1_loss             | 128.71748  |
| training/sac_pi/alpha          | 0.16180195 |
| training/sac_pi/alpha_loss     | 0.408613   |
| training/sac_pi/logp_pi        | 4.7520833  |
| training/sac_pi/pi_entropy     | 3.5587208  |
| training/sac_pi/pi_global_norm | 1.8292767  |
| training/sac_pi/policy_loss    | -215.58447 |
| training/sac_pi/std            | 0.52406037 |
| training/sac_pi/valid_num      | 4947.0     |
| training/sac_Q/q1              | 202.58069  |
| training/sac_Q/q2              | 206.2813   |
| training/sac_Q/q2_loss         | 128.03658  |
| training/sac_Q/q_global_norm   | 228.30803  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16251062  |
| epoch                          | 610         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4802.521    |
| evaluation/return-max          | 4862.8584   |
| evaluation/return-min          | 4698.0005   |
| evaluation/return-std          | 56.07024    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46459       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4802.521    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 231.32451   |
| Q-std                          | 106.42964   |
| Q_loss                         | 75.78673    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 610         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 503         |
| times/evaluation_metrics       | 0.000583    |
| times/evaluation_paths         | 37.1        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 68.1        |
| timestep                       | 1000        |
| timesteps_total                | 611000      |
| train-steps                    | 611000      |
| training/Q/q1_loss             | 123.07273   |
| training/sac_pi/alpha          | 0.16251716  |
| training/sac_pi/alpha_loss     | -0.27762517 |
| training/sac_pi/logp_pi        | 4.0164733   |
| training/sac_pi/pi_entropy     | 3.3677602   |
| training/sac_pi/pi_global_norm | 1.8932081   |
| training/sac_pi/policy_loss    | -230.20284  |
| training/sac_pi/std            | 0.486402    |
| training/sac_pi/valid_num      | 5004.0      |
| training/sac_Q/q1              | 221.61914   |
| training/sac_Q/q2              | 224.58652   |
| training/sac_Q/q2_loss         | 122.880356  |
| training/sac_Q/q_global_norm   | 286.94766   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1615122   |
| epoch                          | 611         |
| evaluation/episode-length-avg  | 581         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 146         |
| evaluation/episode-length-std  | 419         |
| evaluation/return-average      | 2544.7417   |
| evaluation/return-max          | 4774.922    |
| evaluation/return-min          | 320.7742    |
| evaluation/return-std          | 2173.917    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46645       |
| perf/AverageLength             | 581         |
| perf/AverageReturn             | 2544.7417   |
| perf/NormalizedReturn          | 0.554       |
| Q-avg                          | 212.1571    |
| Q-std                          | 175.31175   |
| Q_loss                         | 106.128525  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 611         |
| times/epoch_after_hook         | 1.59e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000595    |
| times/evaluation_paths         | 21          |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.0084      |
| times/train                    | 69          |
| timestep                       | 1000        |
| timesteps_total                | 612000      |
| train-steps                    | 612000      |
| training/Q/q1_loss             | 80.27757    |
| training/sac_pi/alpha          | 0.16151142  |
| training/sac_pi/alpha_loss     | -0.13174058 |
| training/sac_pi/logp_pi        | 4.1573434   |
| training/sac_pi/pi_entropy     | 3.2934144   |
| training/sac_pi/pi_global_norm | 3.2062294   |
| training/sac_pi/policy_loss    | -224.86105  |
| training/sac_pi/std            | 0.49591243  |
| training/sac_pi/valid_num      | 4972.0      |
| training/sac_Q/q1              | 214.83841   |
| training/sac_Q/q2              | 215.00488   |
| training/sac_Q/q2_loss         | 79.82954    |
| training/sac_Q/q_global_norm   | 255.41132   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16076076  |
| epoch                          | 612         |
| evaluation/episode-length-avg  | 984         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 901         |
| evaluation/episode-length-std  | 33.5        |
| evaluation/return-average      | 4758.5723   |
| evaluation/return-max          | 4897.203    |
| evaluation/return-min          | 4393.3      |
| evaluation/return-std          | 161.6207    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46508       |
| perf/AverageLength             | 984         |
| perf/AverageReturn             | 4758.5723   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 216.72852   |
| Q-std                          | 169.87682   |
| Q_loss                         | 106.91764   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 612         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000543    |
| times/evaluation_paths         | 41.8        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 613000      |
| train-steps                    | 613000      |
| training/Q/q1_loss             | 106.747185  |
| training/sac_pi/alpha          | 0.16074888  |
| training/sac_pi/alpha_loss     | 0.071878254 |
| training/sac_pi/logp_pi        | 4.940427    |
| training/sac_pi/pi_entropy     | 3.4970596   |
| training/sac_pi/pi_global_norm | 1.6463395   |
| training/sac_pi/policy_loss    | -229.30344  |
| training/sac_pi/std            | 0.5366543   |
| training/sac_pi/valid_num      | 4973.0      |
| training/sac_Q/q1              | 212.70877   |
| training/sac_Q/q2              | 214.02026   |
| training/sac_Q/q2_loss         | 108.380684  |
| training/sac_Q/q_global_norm   | 241.29784   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16210164  |
| epoch                          | 613         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5063.8193   |
| evaluation/return-max          | 5137.1064   |
| evaluation/return-min          | 5012.1147   |
| evaluation/return-std          | 35.055336   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.15        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46462       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5063.8193   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 227.28235   |
| Q-std                          | 119.67367   |
| Q_loss                         | 81.71749    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 613         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000328    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000538    |
| times/evaluation_paths         | 41.3        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 73.1        |
| timestep                       | 1000        |
| timesteps_total                | 614000      |
| train-steps                    | 614000      |
| training/Q/q1_loss             | 93.984276   |
| training/sac_pi/alpha          | 0.16212766  |
| training/sac_pi/alpha_loss     | -0.33008784 |
| training/sac_pi/logp_pi        | 4.1269574   |
| training/sac_pi/pi_entropy     | 3.3128982   |
| training/sac_pi/pi_global_norm | 1.9084717   |
| training/sac_pi/policy_loss    | -230.79553  |
| training/sac_pi/std            | 0.47429684  |
| training/sac_pi/valid_num      | 4980.0      |
| training/sac_Q/q1              | 220.70242   |
| training/sac_Q/q2              | 220.8335    |
| training/sac_Q/q2_loss         | 93.41596    |
| training/sac_Q/q_global_norm   | 211.31227   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16461895 |
| epoch                          | 614        |
| evaluation/episode-length-avg  | 832        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 159        |
| evaluation/episode-length-std  | 336        |
| evaluation/return-average      | 4076.157   |
| evaluation/return-max          | 5064.477   |
| evaluation/return-min          | 456.04706  |
| evaluation/return-std          | 1806.4689  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46266      |
| perf/AverageLength             | 832        |
| perf/AverageReturn             | 4076.157   |
| perf/NormalizedReturn          | 0.888      |
| Q-avg                          | 217.86111  |
| Q-std                          | 108.434555 |
| Q_loss                         | 102.83387  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 614        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000479   |
| times/evaluation_paths         | 35.8       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 66.9       |
| timestep                       | 1000       |
| timesteps_total                | 615000     |
| train-steps                    | 615000     |
| training/Q/q1_loss             | 104.410194 |
| training/sac_pi/alpha          | 0.16462414 |
| training/sac_pi/alpha_loss     | 0.29546574 |
| training/sac_pi/logp_pi        | 3.884426   |
| training/sac_pi/pi_entropy     | 3.3246658  |
| training/sac_pi/pi_global_norm | 2.2105587  |
| training/sac_pi/policy_loss    | -222.9828  |
| training/sac_pi/std            | 0.46043256 |
| training/sac_pi/valid_num      | 5014.0     |
| training/sac_Q/q1              | 217.82773  |
| training/sac_Q/q2              | 217.48772  |
| training/sac_Q/q2_loss         | 103.77905  |
| training/sac_Q/q_global_norm   | 227.07715  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16724178  |
| epoch                          | 615         |
| evaluation/episode-length-avg  | 863         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 473         |
| evaluation/episode-length-std  | 174         |
| evaluation/return-average      | 4128.1777   |
| evaluation/return-max          | 4887.25     |
| evaluation/return-min          | 2059.9617   |
| evaluation/return-std          | 930.7275    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.17        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46537       |
| perf/AverageLength             | 863         |
| perf/AverageReturn             | 4128.1777   |
| perf/NormalizedReturn          | 0.899       |
| Q-avg                          | 224.81564   |
| Q-std                          | 118.555885  |
| Q_loss                         | 94.62848    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 615         |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000513    |
| times/evaluation_paths         | 40.6        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 64.2        |
| timestep                       | 1000        |
| timesteps_total                | 616000      |
| train-steps                    | 616000      |
| training/Q/q1_loss             | 81.77217    |
| training/sac_pi/alpha          | 0.16720472  |
| training/sac_pi/alpha_loss     | -0.04107897 |
| training/sac_pi/logp_pi        | 4.4326077   |
| training/sac_pi/pi_entropy     | 3.481786    |
| training/sac_pi/pi_global_norm | 2.7454908   |
| training/sac_pi/policy_loss    | -236.4701   |
| training/sac_pi/std            | 0.50723606  |
| training/sac_pi/valid_num      | 4969.0      |
| training/sac_Q/q1              | 226.75542   |
| training/sac_Q/q2              | 227.4043    |
| training/sac_Q/q2_loss         | 81.40054    |
| training/sac_Q/q_global_norm   | 191.25168   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16113026  |
| epoch                          | 616         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5276.542    |
| evaluation/return-max          | 5304.092    |
| evaluation/return-min          | 5245.339    |
| evaluation/return-std          | 20.082157   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46599       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5276.542    |
| perf/NormalizedReturn          | 1.15        |
| Q-avg                          | 211.0922    |
| Q-std                          | 161.54865   |
| Q_loss                         | 106.690605  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 616         |
| times/epoch_after_hook         | 3.48e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000653    |
| times/evaluation_paths         | 35.7        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00817     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 617000      |
| train-steps                    | 617000      |
| training/Q/q1_loss             | 103.36175   |
| training/sac_pi/alpha          | 0.16116598  |
| training/sac_pi/alpha_loss     | -0.57869524 |
| training/sac_pi/logp_pi        | 4.0683794   |
| training/sac_pi/pi_entropy     | 3.5109715   |
| training/sac_pi/pi_global_norm | 1.6379213   |
| training/sac_pi/policy_loss    | -225.68614  |
| training/sac_pi/std            | 0.5112178   |
| training/sac_pi/valid_num      | 4974.0      |
| training/sac_Q/q1              | 214.21758   |
| training/sac_Q/q2              | 215.75339   |
| training/sac_Q/q2_loss         | 102.630455  |
| training/sac_Q/q_global_norm   | 206.98045   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16480882  |
| epoch                          | 617         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5215.133    |
| evaluation/return-max          | 5250.8506   |
| evaluation/return-min          | 5178.9297   |
| evaluation/return-std          | 23.355677   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46414       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5215.133    |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 225.89351   |
| Q-std                          | 90.64014    |
| Q_loss                         | 83.7207     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 617         |
| times/epoch_after_hook         | 1.58e-06    |
| times/epoch_before_hook        | 0.000356    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.00055     |
| times/evaluation_paths         | 41.1        |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00847     |
| times/train                    | 61.5        |
| timestep                       | 1000        |
| timesteps_total                | 618000      |
| train-steps                    | 618000      |
| training/Q/q1_loss             | 91.81503    |
| training/sac_pi/alpha          | 0.16478425  |
| training/sac_pi/alpha_loss     | -0.22493435 |
| training/sac_pi/logp_pi        | 3.9169266   |
| training/sac_pi/pi_entropy     | 3.3901691   |
| training/sac_pi/pi_global_norm | 1.8856012   |
| training/sac_pi/policy_loss    | -222.21965  |
| training/sac_pi/std            | 0.48417836  |
| training/sac_pi/valid_num      | 4992.0      |
| training/sac_Q/q1              | 214.67387   |
| training/sac_Q/q2              | 215.3895    |
| training/sac_Q/q2_loss         | 92.96468    |
| training/sac_Q/q_global_norm   | 205.63254   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16574937   |
| epoch                          | 618          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4958.5127    |
| evaluation/return-max          | 5006.616     |
| evaluation/return-min          | 4846.0957    |
| evaluation/return-std          | 43.55965     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.11         |
| model/origin_ret               | 85.9         |
| model/penalty_ret              | 79.2         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46461        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4958.5127    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 221.57297    |
| Q-std                          | 113.6754     |
| Q_loss                         | 109.23032    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 618          |
| times/epoch_after_hook         | 1.94e-06     |
| times/epoch_before_hook        | 0.000127     |
| times/epoch_rollout_model      | 482          |
| times/evaluation_metrics       | 0.00084      |
| times/evaluation_paths         | 37.6         |
| times/timestep_after_hook      | 0.00364      |
| times/timestep_before_hook     | 0.00822      |
| times/train                    | 62.1         |
| timestep                       | 1000         |
| timesteps_total                | 619000       |
| train-steps                    | 619000       |
| training/Q/q1_loss             | 106.23174    |
| training/sac_pi/alpha          | 0.16576289   |
| training/sac_pi/alpha_loss     | -0.030921271 |
| training/sac_pi/logp_pi        | 4.0910277    |
| training/sac_pi/pi_entropy     | 3.307528     |
| training/sac_pi/pi_global_norm | 1.7356825    |
| training/sac_pi/policy_loss    | -226.94052   |
| training/sac_pi/std            | 0.47575855   |
| training/sac_pi/valid_num      | 4960.0       |
| training/sac_Q/q1              | 218.13724    |
| training/sac_Q/q2              | 220.3635     |
| training/sac_Q/q2_loss         | 106.69736    |
| training/sac_Q/q_global_norm   | 182.03687    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16454971 |
| epoch                          | 619        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5155.629   |
| evaluation/return-max          | 5182.7373  |
| evaluation/return-min          | 5126.89    |
| evaluation/return-std          | 14.303859  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 79         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46323      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5155.629   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 210.7377   |
| Q-std                          | 114.31468  |
| Q_loss                         | 105.1337   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 619        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000608   |
| times/evaluation_paths         | 37.8       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 63.4       |
| timestep                       | 1000       |
| timesteps_total                | 620000     |
| train-steps                    | 620000     |
| training/Q/q1_loss             | 87.913734  |
| training/sac_pi/alpha          | 0.16456647 |
| training/sac_pi/alpha_loss     | -0.4160395 |
| training/sac_pi/logp_pi        | 3.7239864  |
| training/sac_pi/pi_entropy     | 3.3209558  |
| training/sac_pi/pi_global_norm | 1.5642012  |
| training/sac_pi/policy_loss    | -239.41673 |
| training/sac_pi/std            | 0.47943038 |
| training/sac_pi/valid_num      | 4973.0     |
| training/sac_Q/q1              | 229.39835  |
| training/sac_Q/q2              | 231.80644  |
| training/sac_Q/q2_loss         | 87.115974  |
| training/sac_Q/q_global_norm   | 180.12044  |
--------------------------------------------------------------------------------
[WARN] 620 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16875799  |
| epoch                          | 620         |
| evaluation/episode-length-avg  | 664         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 156         |
| evaluation/episode-length-std  | 412         |
| evaluation/return-average      | 3206.5293   |
| evaluation/return-max          | 5054.1123   |
| evaluation/return-min          | 480.7376    |
| evaluation/return-std          | 2213.112    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46212       |
| perf/AverageLength             | 664         |
| perf/AverageReturn             | 3206.5293   |
| perf/NormalizedReturn          | 0.698       |
| Q-avg                          | 215.45529   |
| Q-std                          | 144.2146    |
| Q_loss                         | 103.701035  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 620         |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.00059     |
| times/evaluation_paths         | 21.6        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00833     |
| times/train                    | 61.8        |
| timestep                       | 1000        |
| timesteps_total                | 621000      |
| train-steps                    | 621000      |
| training/Q/q1_loss             | 105.832115  |
| training/sac_pi/alpha          | 0.1687626   |
| training/sac_pi/alpha_loss     | -0.20402773 |
| training/sac_pi/logp_pi        | 4.1478653   |
| training/sac_pi/pi_entropy     | 3.3888288   |
| training/sac_pi/pi_global_norm | 2.0198498   |
| training/sac_pi/policy_loss    | -223.791    |
| training/sac_pi/std            | 0.49383822  |
| training/sac_pi/valid_num      | 4955.0      |
| training/sac_Q/q1              | 211.74646   |
| training/sac_Q/q2              | 213.8741    |
| training/sac_Q/q2_loss         | 106.57607   |
| training/sac_Q/q_global_norm   | 308.64307   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16430572 |
| epoch                          | 621        |
| evaluation/episode-length-avg  | 664        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 155        |
| evaluation/episode-length-std  | 411        |
| evaluation/return-average      | 3189.3862  |
| evaluation/return-max          | 5024.8296  |
| evaluation/return-min          | 463.36774  |
| evaluation/return-std          | 2210.2942  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46386      |
| perf/AverageLength             | 664        |
| perf/AverageReturn             | 3189.3862  |
| perf/NormalizedReturn          | 0.694      |
| Q-avg                          | 212.299    |
| Q-std                          | 170.85551  |
| Q_loss                         | 94.95751   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 621        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000407   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000544   |
| times/evaluation_paths         | 23.5       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 62.4       |
| timestep                       | 1000       |
| timesteps_total                | 622000     |
| train-steps                    | 622000     |
| training/Q/q1_loss             | 99.69685   |
| training/sac_pi/alpha          | 0.1643231  |
| training/sac_pi/alpha_loss     | 0.03375463 |
| training/sac_pi/logp_pi        | 4.477697   |
| training/sac_pi/pi_entropy     | 3.382423   |
| training/sac_pi/pi_global_norm | 2.087527   |
| training/sac_pi/policy_loss    | -230.96262 |
| training/sac_pi/std            | 0.49453232 |
| training/sac_pi/valid_num      | 4999.0     |
| training/sac_Q/q1              | 218.95557  |
| training/sac_Q/q2              | 221.60323  |
| training/sac_Q/q2_loss         | 99.174736  |
| training/sac_Q/q_global_norm   | 205.30948  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15993741 |
| epoch                          | 622        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4978.0625  |
| evaluation/return-max          | 5097.1797  |
| evaluation/return-min          | 4834.753   |
| evaluation/return-std          | 94.417984  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46580      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4978.0625  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 223.2961   |
| Q-std                          | 124.12123  |
| Q_loss                         | 99.396805  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 622        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000584   |
| times/evaluation_paths         | 36.6       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00846    |
| times/train                    | 63.5       |
| timestep                       | 1000       |
| timesteps_total                | 623000     |
| train-steps                    | 623000     |
| training/Q/q1_loss             | 83.124725  |
| training/sac_pi/alpha          | 0.15993057 |
| training/sac_pi/alpha_loss     | 0.23299779 |
| training/sac_pi/logp_pi        | 3.9981022  |
| training/sac_pi/pi_entropy     | 3.245706   |
| training/sac_pi/pi_global_norm | 1.7362388  |
| training/sac_pi/policy_loss    | -233.5221  |
| training/sac_pi/std            | 0.46006748 |
| training/sac_pi/valid_num      | 4973.0     |
| training/sac_Q/q1              | 225.28194  |
| training/sac_Q/q2              | 226.33206  |
| training/sac_Q/q2_loss         | 82.880516  |
| training/sac_Q/q_global_norm   | 236.22568  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16193813 |
| epoch                          | 623        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5011.0967  |
| evaluation/return-max          | 5025.6836  |
| evaluation/return-min          | 4984.6274  |
| evaluation/return-std          | 10.738739  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 78.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46420      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5011.0967  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 209.17883  |
| Q-std                          | 133.64334  |
| Q_loss                         | 102.11117  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 623        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000118   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000582   |
| times/evaluation_paths         | 45.4       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 65.1       |
| timestep                       | 1000       |
| timesteps_total                | 624000     |
| train-steps                    | 624000     |
| training/Q/q1_loss             | 92.923904  |
| training/sac_pi/alpha          | 0.16193186 |
| training/sac_pi/alpha_loss     | 0.1138099  |
| training/sac_pi/logp_pi        | 4.3512383  |
| training/sac_pi/pi_entropy     | 3.3956141  |
| training/sac_pi/pi_global_norm | 1.5757627  |
| training/sac_pi/policy_loss    | -218.51935 |
| training/sac_pi/std            | 0.5007805  |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 207.98091  |
| training/sac_Q/q2              | 207.08969  |
| training/sac_Q/q2_loss         | 93.50281   |
| training/sac_Q/q_global_norm   | 197.58994  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16145512 |
| epoch                          | 624        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4944.3174  |
| evaluation/return-max          | 5011.4395  |
| evaluation/return-min          | 4867.4365  |
| evaluation/return-std          | 49.924873  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46399      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4944.3174  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 207.6434   |
| Q-std                          | 139.77402  |
| Q_loss                         | 127.628105 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 624        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000501   |
| times/evaluation_paths         | 36.9       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 625000     |
| train-steps                    | 625000     |
| training/Q/q1_loss             | 90.04626   |
| training/sac_pi/alpha          | 0.16140755 |
| training/sac_pi/alpha_loss     | 0.5508686  |
| training/sac_pi/logp_pi        | 4.4537935  |
| training/sac_pi/pi_entropy     | 3.362645   |
| training/sac_pi/pi_global_norm | 1.7532762  |
| training/sac_pi/policy_loss    | -224.85266 |
| training/sac_pi/std            | 0.49750462 |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 217.15747  |
| training/sac_Q/q2              | 218.35208  |
| training/sac_Q/q2_loss         | 90.66575   |
| training/sac_Q/q_global_norm   | 170.94098  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1635001   |
| epoch                          | 625         |
| evaluation/episode-length-avg  | 986         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 864         |
| evaluation/episode-length-std  | 40.8        |
| evaluation/return-average      | 5014.671    |
| evaluation/return-max          | 5159.231    |
| evaluation/return-min          | 4189.4863   |
| evaluation/return-std          | 283.46973   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46513       |
| perf/AverageLength             | 986         |
| perf/AverageReturn             | 5014.671    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 221.64331   |
| Q-std                          | 153.33237   |
| Q_loss                         | 86.90999    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 625         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000291    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000532    |
| times/evaluation_paths         | 33.2        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 61.9        |
| timestep                       | 1000        |
| timesteps_total                | 626000      |
| train-steps                    | 626000      |
| training/Q/q1_loss             | 110.629944  |
| training/sac_pi/alpha          | 0.16351418  |
| training/sac_pi/alpha_loss     | -0.29211172 |
| training/sac_pi/logp_pi        | 3.757473    |
| training/sac_pi/pi_entropy     | 3.5378304   |
| training/sac_pi/pi_global_norm | 2.0446284   |
| training/sac_pi/policy_loss    | -231.05147  |
| training/sac_pi/std            | 0.498814    |
| training/sac_pi/valid_num      | 4993.0      |
| training/sac_Q/q1              | 222.75098   |
| training/sac_Q/q2              | 223.88516   |
| training/sac_Q/q2_loss         | 110.92766   |
| training/sac_Q/q_global_norm   | 393.45502   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16153853   |
| epoch                          | 626          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4943.423     |
| evaluation/return-max          | 4981.705     |
| evaluation/return-min          | 4909.3       |
| evaluation/return-std          | 18.72124     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.12         |
| model/origin_ret               | 86.3         |
| model/penalty_ret              | 79.9         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46382        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4943.423     |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 219.99202    |
| Q-std                          | 124.18821    |
| Q_loss                         | 112.84011    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 626          |
| times/epoch_after_hook         | 2.94e-06     |
| times/epoch_before_hook        | 0.000124     |
| times/epoch_rollout_model      | 482          |
| times/evaluation_metrics       | 0.000696     |
| times/evaluation_paths         | 36.4         |
| times/timestep_after_hook      | 0.00355      |
| times/timestep_before_hook     | 0.0102       |
| times/train                    | 62.2         |
| timestep                       | 1000         |
| timesteps_total                | 627000       |
| train-steps                    | 627000       |
| training/Q/q1_loss             | 86.330696    |
| training/sac_pi/alpha          | 0.16153905   |
| training/sac_pi/alpha_loss     | -0.083719455 |
| training/sac_pi/logp_pi        | 4.7886343    |
| training/sac_pi/pi_entropy     | 3.4742439    |
| training/sac_pi/pi_global_norm | 1.8926197    |
| training/sac_pi/policy_loss    | -225.79718   |
| training/sac_pi/std            | 0.52759475   |
| training/sac_pi/valid_num      | 4976.0       |
| training/sac_Q/q1              | 210.91367    |
| training/sac_Q/q2              | 212.19077    |
| training/sac_Q/q2_loss         | 85.751816    |
| training/sac_Q/q_global_norm   | 174.5936     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16670258 |
| epoch                          | 627        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5043.5107  |
| evaluation/return-max          | 5073.56    |
| evaluation/return-min          | 5005.922   |
| evaluation/return-std          | 20.432438  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46516      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5043.5107  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 219.83167  |
| Q-std                          | 179.95389  |
| Q_loss                         | 98.33066   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 627        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000546   |
| times/evaluation_paths         | 36.9       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 628000     |
| train-steps                    | 628000     |
| training/Q/q1_loss             | 114.8584   |
| training/sac_pi/alpha          | 0.16671962 |
| training/sac_pi/alpha_loss     | 0.2130183  |
| training/sac_pi/logp_pi        | 4.566729   |
| training/sac_pi/pi_entropy     | 3.6859202  |
| training/sac_pi/pi_global_norm | 1.772313   |
| training/sac_pi/policy_loss    | -227.8673  |
| training/sac_pi/std            | 0.5408729  |
| training/sac_pi/valid_num      | 4951.0     |
| training/sac_Q/q1              | 214.75058  |
| training/sac_Q/q2              | 212.8304   |
| training/sac_Q/q2_loss         | 115.474045 |
| training/sac_Q/q_global_norm   | 263.93222  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16094054 |
| epoch                          | 628        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4895.85    |
| evaluation/return-max          | 4976.781   |
| evaluation/return-min          | 4759.7617  |
| evaluation/return-std          | 65.4318    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.17       |
| model/origin_ret               | 87         |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46363      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4895.85    |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 216.06213  |
| Q-std                          | 154.83     |
| Q_loss                         | 96.05394   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 628        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000139   |
| times/epoch_rollout_model      | 506        |
| times/evaluation_metrics       | 0.000518   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 629000     |
| train-steps                    | 629000     |
| training/Q/q1_loss             | 115.32479  |
| training/sac_pi/alpha          | 0.16093224 |
| training/sac_pi/alpha_loss     | 0.4300061  |
| training/sac_pi/logp_pi        | 3.5939655  |
| training/sac_pi/pi_entropy     | 3.4374435  |
| training/sac_pi/pi_global_norm | 1.9217347  |
| training/sac_pi/policy_loss    | -226.67317 |
| training/sac_pi/std            | 0.4609671  |
| training/sac_pi/valid_num      | 5018.0     |
| training/sac_Q/q1              | 223.24277  |
| training/sac_Q/q2              | 222.91528  |
| training/sac_Q/q2_loss         | 115.113205 |
| training/sac_Q/q_global_norm   | 261.05148  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16033839 |
| epoch                          | 629        |
| evaluation/episode-length-avg  | 826        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 278        |
| evaluation/episode-length-std  | 287        |
| evaluation/return-average      | 3903.3484  |
| evaluation/return-max          | 4897.675   |
| evaluation/return-min          | 1044.5253  |
| evaluation/return-std          | 1500.8589  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46562      |
| perf/AverageLength             | 826        |
| perf/AverageReturn             | 3903.3484  |
| perf/NormalizedReturn          | 0.85       |
| Q-avg                          | 217.65237  |
| Q-std                          | 143.2527   |
| Q_loss                         | 92.55057   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 629        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000297   |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000484   |
| times/evaluation_paths         | 29.9       |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 630000     |
| train-steps                    | 630000     |
| training/Q/q1_loss             | 98.30064   |
| training/sac_pi/alpha          | 0.16034056 |
| training/sac_pi/alpha_loss     | 0.24013351 |
| training/sac_pi/logp_pi        | 4.2135534  |
| training/sac_pi/pi_entropy     | 3.3597126  |
| training/sac_pi/pi_global_norm | 1.6920526  |
| training/sac_pi/policy_loss    | -229.35686 |
| training/sac_pi/std            | 0.4825633  |
| training/sac_pi/valid_num      | 4990.0     |
| training/sac_Q/q1              | 221.22473  |
| training/sac_Q/q2              | 222.57553  |
| training/sac_Q/q2_loss         | 98.82146   |
| training/sac_Q/q_global_norm   | 236.0963   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15966916 |
| epoch                          | 630        |
| evaluation/episode-length-avg  | 969        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 702        |
| evaluation/episode-length-std  | 89         |
| evaluation/return-average      | 4962.6436  |
| evaluation/return-max          | 5241.677   |
| evaluation/return-min          | 3374.8884  |
| evaluation/return-std          | 532.07874  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46561      |
| perf/AverageLength             | 969        |
| perf/AverageReturn             | 4962.6436  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 223.97559  |
| Q-std                          | 111.67404  |
| Q_loss                         | 106.489494 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 630        |
| times/epoch_after_hook         | 1.63e-06   |
| times/epoch_before_hook        | 0.000111   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000587   |
| times/evaluation_paths         | 34.1       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 631000     |
| train-steps                    | 631000     |
| training/Q/q1_loss             | 91.83268   |
| training/sac_pi/alpha          | 0.15968247 |
| training/sac_pi/alpha_loss     | -0.192579  |
| training/sac_pi/logp_pi        | 3.659637   |
| training/sac_pi/pi_entropy     | 3.5084946  |
| training/sac_pi/pi_global_norm | 1.7274001  |
| training/sac_pi/policy_loss    | -225.21864 |
| training/sac_pi/std            | 0.4893751  |
| training/sac_pi/valid_num      | 5012.0     |
| training/sac_Q/q1              | 219.48564  |
| training/sac_Q/q2              | 220.22041  |
| training/sac_Q/q2_loss         | 92.62566   |
| training/sac_Q/q_global_norm   | 236.53603  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15960145   |
| epoch                          | 631          |
| evaluation/episode-length-avg  | 151          |
| evaluation/episode-length-max  | 160          |
| evaluation/episode-length-min  | 138          |
| evaluation/episode-length-std  | 5.9          |
| evaluation/return-average      | 481.823      |
| evaluation/return-max          | 513.69324    |
| evaluation/return-min          | 435.11975    |
| evaluation/return-std          | 21.844013    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.18         |
| model/origin_ret               | 87.1         |
| model/penalty_ret              | 79.9         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46556        |
| perf/AverageLength             | 151          |
| perf/AverageReturn             | 481.823      |
| perf/NormalizedReturn          | 0.105        |
| Q-avg                          | 215.14278    |
| Q-std                          | 127.10789    |
| Q_loss                         | 107.97411    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 631          |
| times/epoch_after_hook         | 1.71e-06     |
| times/epoch_before_hook        | 0.000124     |
| times/epoch_rollout_model      | 480          |
| times/evaluation_metrics       | 0.000449     |
| times/evaluation_paths         | 5.31         |
| times/timestep_after_hook      | 0.00361      |
| times/timestep_before_hook     | 0.00826      |
| times/train                    | 63.5         |
| timestep                       | 1000         |
| timesteps_total                | 632000       |
| train-steps                    | 632000       |
| training/Q/q1_loss             | 94.943756    |
| training/sac_pi/alpha          | 0.15961255   |
| training/sac_pi/alpha_loss     | -0.023959477 |
| training/sac_pi/logp_pi        | 4.2809477    |
| training/sac_pi/pi_entropy     | 3.4490197    |
| training/sac_pi/pi_global_norm | 1.479735     |
| training/sac_pi/policy_loss    | -225.07854   |
| training/sac_pi/std            | 0.5087655    |
| training/sac_pi/valid_num      | 4918.0       |
| training/sac_Q/q1              | 211.85896    |
| training/sac_Q/q2              | 214.2513     |
| training/sac_Q/q2_loss         | 93.50362     |
| training/sac_Q/q_global_norm   | 290.83087    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16378237 |
| epoch                          | 632        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4801.0347  |
| evaluation/return-max          | 4921.2905  |
| evaluation/return-min          | 4716.1436  |
| evaluation/return-std          | 56.580585  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 84.7       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46557      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4801.0347  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 219.34366  |
| Q-std                          | 126.9893   |
| Q_loss                         | 80.952995  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 632        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000636   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00569    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 633000     |
| train-steps                    | 633000     |
| training/Q/q1_loss             | 75.96599   |
| training/sac_pi/alpha          | 0.16380644 |
| training/sac_pi/alpha_loss     | -0.3320042 |
| training/sac_pi/logp_pi        | 4.2840166  |
| training/sac_pi/pi_entropy     | 3.4994526  |
| training/sac_pi/pi_global_norm | 2.0644045  |
| training/sac_pi/policy_loss    | -227.68349 |
| training/sac_pi/std            | 0.5151264  |
| training/sac_pi/valid_num      | 4928.0     |
| training/sac_Q/q1              | 213.59119  |
| training/sac_Q/q2              | 215.36629  |
| training/sac_Q/q2_loss         | 76.42563   |
| training/sac_Q/q_global_norm   | 211.38757  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15752691  |
| epoch                          | 633         |
| evaluation/episode-length-avg  | 607         |
| evaluation/episode-length-max  | 729         |
| evaluation/episode-length-min  | 493         |
| evaluation/episode-length-std  | 82.5        |
| evaluation/return-average      | 2966.8755   |
| evaluation/return-max          | 3665.913    |
| evaluation/return-min          | 2333.561    |
| evaluation/return-std          | 458.15503   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46507       |
| perf/AverageLength             | 607         |
| perf/AverageReturn             | 2966.8755   |
| perf/NormalizedReturn          | 0.646       |
| Q-avg                          | 221.45639   |
| Q-std                          | 99.84776    |
| Q_loss                         | 87.9197     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 633         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000294    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000509    |
| times/evaluation_paths         | 22.1        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 63.6        |
| timestep                       | 1000        |
| timesteps_total                | 634000      |
| train-steps                    | 634000      |
| training/Q/q1_loss             | 99.83706    |
| training/sac_pi/alpha          | 0.15751363  |
| training/sac_pi/alpha_loss     | 0.029623756 |
| training/sac_pi/logp_pi        | 3.8080738   |
| training/sac_pi/pi_entropy     | 3.3305879   |
| training/sac_pi/pi_global_norm | 1.6139667   |
| training/sac_pi/policy_loss    | -234.92618  |
| training/sac_pi/std            | 0.4750005   |
| training/sac_pi/valid_num      | 5037.0      |
| training/sac_Q/q1              | 229.54243   |
| training/sac_Q/q2              | 229.10995   |
| training/sac_Q/q2_loss         | 99.36947    |
| training/sac_Q/q_global_norm   | 251.68466   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16004868 |
| epoch                          | 634        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5167.992   |
| evaluation/return-max          | 5248.3237  |
| evaluation/return-min          | 5123.3013  |
| evaluation/return-std          | 40.2145    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.21       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46541      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5167.992   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 229.03096  |
| Q-std                          | 139.82887  |
| Q_loss                         | 72.15607   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 634        |
| times/epoch_after_hook         | 2.07e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.00157    |
| times/evaluation_paths         | 35.2       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 635000     |
| train-steps                    | 635000     |
| training/Q/q1_loss             | 109.317726 |
| training/sac_pi/alpha          | 0.16003475 |
| training/sac_pi/alpha_loss     | 0.6097917  |
| training/sac_pi/logp_pi        | 4.5331316  |
| training/sac_pi/pi_entropy     | 3.4202027  |
| training/sac_pi/pi_global_norm | 1.8520303  |
| training/sac_pi/policy_loss    | -227.22852 |
| training/sac_pi/std            | 0.4908977  |
| training/sac_pi/valid_num      | 4905.0     |
| training/sac_Q/q1              | 216.2601   |
| training/sac_Q/q2              | 211.34024  |
| training/sac_Q/q2_loss         | 109.274796 |
| training/sac_Q/q_global_norm   | 309.70435  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16080995 |
| epoch                          | 635        |
| evaluation/episode-length-avg  | 878        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 624        |
| evaluation/episode-length-std  | 138        |
| evaluation/return-average      | 4449.095   |
| evaluation/return-max          | 5295.7056  |
| evaluation/return-min          | 3047.6677  |
| evaluation/return-std          | 771.5284   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46515      |
| perf/AverageLength             | 878        |
| perf/AverageReturn             | 4449.095   |
| perf/NormalizedReturn          | 0.969      |
| Q-avg                          | 214.07382  |
| Q-std                          | 173.31859  |
| Q_loss                         | 96.27001   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 635        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000149   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000509   |
| times/evaluation_paths         | 31.1       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00844    |
| times/train                    | 63.8       |
| timestep                       | 1000       |
| timesteps_total                | 636000     |
| train-steps                    | 636000     |
| training/Q/q1_loss             | 92.38148   |
| training/sac_pi/alpha          | 0.16077928 |
| training/sac_pi/alpha_loss     | 0.6598724  |
| training/sac_pi/logp_pi        | 3.986362   |
| training/sac_pi/pi_entropy     | 3.392099   |
| training/sac_pi/pi_global_norm | 1.7440076  |
| training/sac_pi/policy_loss    | -228.57635 |
| training/sac_pi/std            | 0.46527    |
| training/sac_pi/valid_num      | 5041.0     |
| training/sac_Q/q1              | 225.77847  |
| training/sac_Q/q2              | 225.55803  |
| training/sac_Q/q2_loss         | 92.33927   |
| training/sac_Q/q_global_norm   | 201.55664  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16246563  |
| epoch                          | 636         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5215.175    |
| evaluation/return-max          | 5289.9307   |
| evaluation/return-min          | 5141.0938   |
| evaluation/return-std          | 47.526794   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46417       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5215.175    |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 214.21121   |
| Q-std                          | 201.69647   |
| Q_loss                         | 96.790924   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 636         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000119    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000596    |
| times/evaluation_paths         | 36.3        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 637000      |
| train-steps                    | 637000      |
| training/Q/q1_loss             | 96.74071    |
| training/sac_pi/alpha          | 0.16245385  |
| training/sac_pi/alpha_loss     | -0.38884825 |
| training/sac_pi/logp_pi        | 3.9734306   |
| training/sac_pi/pi_entropy     | 3.2823753   |
| training/sac_pi/pi_global_norm | 2.2878911   |
| training/sac_pi/policy_loss    | -237.46783  |
| training/sac_pi/std            | 0.4891101   |
| training/sac_pi/valid_num      | 5018.0      |
| training/sac_Q/q1              | 229.05734   |
| training/sac_Q/q2              | 229.31616   |
| training/sac_Q/q2_loss         | 95.46989    |
| training/sac_Q/q_global_norm   | 230.38914   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16422702 |
| epoch                          | 637        |
| evaluation/episode-length-avg  | 568        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 136        |
| evaluation/episode-length-std  | 432        |
| evaluation/return-average      | 2731.1504  |
| evaluation/return-max          | 5098.3643  |
| evaluation/return-min          | 367.34567  |
| evaluation/return-std          | 2354.2517  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46608      |
| perf/AverageLength             | 568        |
| perf/AverageReturn             | 2731.1504  |
| perf/NormalizedReturn          | 0.595      |
| Q-avg                          | 228.00656  |
| Q-std                          | 104.24082  |
| Q_loss                         | 82.44601   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 637        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000389   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.000855   |
| times/evaluation_paths         | 20.2       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00856    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 638000     |
| train-steps                    | 638000     |
| training/Q/q1_loss             | 82.706     |
| training/sac_pi/alpha          | 0.1642017  |
| training/sac_pi/alpha_loss     | 0.15076113 |
| training/sac_pi/logp_pi        | 4.8877387  |
| training/sac_pi/pi_entropy     | 3.3705544  |
| training/sac_pi/pi_global_norm | 1.6198182  |
| training/sac_pi/policy_loss    | -232.61984 |
| training/sac_pi/std            | 0.508649   |
| training/sac_pi/valid_num      | 4915.0     |
| training/sac_Q/q1              | 212.81894  |
| training/sac_Q/q2              | 212.5019   |
| training/sac_Q/q2_loss         | 81.31538   |
| training/sac_Q/q_global_norm   | 235.39015  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16780362  |
| epoch                          | 638         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4917.995    |
| evaluation/return-max          | 4946.296    |
| evaluation/return-min          | 4901.8877   |
| evaluation/return-std          | 15.065175   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.17        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46463       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4917.995    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 210.60979   |
| Q-std                          | 153.57516   |
| Q_loss                         | 81.10807    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 638         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000666    |
| times/evaluation_paths         | 36.4        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00857     |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 639000      |
| train-steps                    | 639000      |
| training/Q/q1_loss             | 92.63646    |
| training/sac_pi/alpha          | 0.16783278  |
| training/sac_pi/alpha_loss     | -0.21975689 |
| training/sac_pi/logp_pi        | 3.9142342   |
| training/sac_pi/pi_entropy     | 3.497289    |
| training/sac_pi/pi_global_norm | 1.9302075   |
| training/sac_pi/policy_loss    | -232.482    |
| training/sac_pi/std            | 0.49544257  |
| training/sac_pi/valid_num      | 5025.0      |
| training/sac_Q/q1              | 224.32718   |
| training/sac_Q/q2              | 226.8068    |
| training/sac_Q/q2_loss         | 92.44409    |
| training/sac_Q/q_global_norm   | 340.32654   |
---------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.16252778    |
| epoch                          | 639           |
| evaluation/episode-length-avg  | 992           |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 917           |
| evaluation/episode-length-std  | 24.9          |
| evaluation/return-average      | 4885.2046     |
| evaluation/return-max          | 5035.7256     |
| evaluation/return-min          | 4448.5127     |
| evaluation/return-std          | 157.78001     |
| model/max_penalty              | 7.24          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 3.16          |
| model/origin_ret               | 86.7          |
| model/penalty_ret              | 80.3          |
| model/val_loss                 | 0.40512508    |
| model/valid_num                | 46552         |
| perf/AverageLength             | 992           |
| perf/AverageReturn             | 4885.2046     |
| perf/NormalizedReturn          | 1.06          |
| Q-avg                          | 221.88899     |
| Q-std                          | 111.25864     |
| Q_loss                         | 93.564064     |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 639           |
| times/epoch_after_hook         | 1.72e-06      |
| times/epoch_before_hook        | 0.000147      |
| times/epoch_rollout_model      | 481           |
| times/evaluation_metrics       | 0.000607      |
| times/evaluation_paths         | 34.1          |
| times/timestep_after_hook      | 0.00364       |
| times/timestep_before_hook     | 0.00837       |
| times/train                    | 62.4          |
| timestep                       | 1000          |
| timesteps_total                | 640000        |
| train-steps                    | 640000        |
| training/Q/q1_loss             | 105.838524    |
| training/sac_pi/alpha          | 0.162515      |
| training/sac_pi/alpha_loss     | -0.0009397075 |
| training/sac_pi/logp_pi        | 3.5797412     |
| training/sac_pi/pi_entropy     | 3.355725      |
| training/sac_pi/pi_global_norm | 1.8456448     |
| training/sac_pi/policy_loss    | -230.73573    |
| training/sac_pi/std            | 0.4630492     |
| training/sac_pi/valid_num      | 4984.0        |
| training/sac_Q/q1              | 224.99336     |
| training/sac_Q/q2              | 224.49654     |
| training/sac_Q/q2_loss         | 106.121185    |
| training/sac_Q/q_global_norm   | 225.17296     |
-----------------------------------------------------------------------------------
[WARN] 640 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.1590468   |
| epoch                          | 640         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4677.3228   |
| evaluation/return-max          | 4712.1436   |
| evaluation/return-min          | 4590.256    |
| evaluation/return-std          | 32.352974   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 84.8        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46445       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4677.3228   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 219.40244   |
| Q-std                          | 137.37672   |
| Q_loss                         | 101.26916   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 640         |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000521    |
| times/evaluation_paths         | 34.8        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00848     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 641000      |
| train-steps                    | 641000      |
| training/Q/q1_loss             | 120.25634   |
| training/sac_pi/alpha          | 0.1590504   |
| training/sac_pi/alpha_loss     | -0.15542312 |
| training/sac_pi/logp_pi        | 4.8555512   |
| training/sac_pi/pi_entropy     | 3.690007    |
| training/sac_pi/pi_global_norm | 2.6667683   |
| training/sac_pi/policy_loss    | -224.8353   |
| training/sac_pi/std            | 0.560821    |
| training/sac_pi/valid_num      | 4899.0      |
| training/sac_Q/q1              | 204.88443   |
| training/sac_Q/q2              | 204.75673   |
| training/sac_Q/q2_loss         | 121.4222    |
| training/sac_Q/q_global_norm   | 233.14899   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16421327  |
| epoch                          | 641         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5116.861    |
| evaluation/return-max          | 5174.41     |
| evaluation/return-min          | 4965.4434   |
| evaluation/return-std          | 59.858387   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86          |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46426       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5116.861    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 224.07224   |
| Q-std                          | 114.75987   |
| Q_loss                         | 90.96439    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 641         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000319    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000544    |
| times/evaluation_paths         | 35          |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00838     |
| times/train                    | 59.9        |
| timestep                       | 1000        |
| timesteps_total                | 642000      |
| train-steps                    | 642000      |
| training/Q/q1_loss             | 86.20783    |
| training/sac_pi/alpha          | 0.16422652  |
| training/sac_pi/alpha_loss     | -0.13138504 |
| training/sac_pi/logp_pi        | 3.6490269   |
| training/sac_pi/pi_entropy     | 3.4756866   |
| training/sac_pi/pi_global_norm | 2.7131367   |
| training/sac_pi/policy_loss    | -234.02756  |
| training/sac_pi/std            | 0.48328686  |
| training/sac_pi/valid_num      | 4989.0      |
| training/sac_Q/q1              | 227.56987   |
| training/sac_Q/q2              | 228.73955   |
| training/sac_Q/q2_loss         | 86.4494     |
| training/sac_Q/q_global_norm   | 211.98875   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16098332  |
| epoch                          | 642         |
| evaluation/episode-length-avg  | 749         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 160         |
| evaluation/episode-length-std  | 384         |
| evaluation/return-average      | 3778.7212   |
| evaluation/return-max          | 5271.585    |
| evaluation/return-min          | 469.94406   |
| evaluation/return-std          | 2157.0696   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46467       |
| perf/AverageLength             | 749         |
| perf/AverageReturn             | 3778.7212   |
| perf/NormalizedReturn          | 0.823       |
| Q-avg                          | 212.77556   |
| Q-std                          | 143.01344   |
| Q_loss                         | 80.70139    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 642         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000519    |
| times/evaluation_paths         | 26.9        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00834     |
| times/train                    | 62.7        |
| timestep                       | 1000        |
| timesteps_total                | 643000      |
| train-steps                    | 643000      |
| training/Q/q1_loss             | 80.28644    |
| training/sac_pi/alpha          | 0.16101451  |
| training/sac_pi/alpha_loss     | -0.23712727 |
| training/sac_pi/logp_pi        | 4.0797772   |
| training/sac_pi/pi_entropy     | 3.378383    |
| training/sac_pi/pi_global_norm | 1.7947556   |
| training/sac_pi/policy_loss    | -228.81348  |
| training/sac_pi/std            | 0.4850586   |
| training/sac_pi/valid_num      | 4998.0      |
| training/sac_Q/q1              | 220.42856   |
| training/sac_Q/q2              | 220.89766   |
| training/sac_Q/q2_loss         | 80.126236   |
| training/sac_Q/q_global_norm   | 184.94475   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17001781 |
| epoch                          | 643        |
| evaluation/episode-length-avg  | 992        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 915        |
| evaluation/episode-length-std  | 25.5       |
| evaluation/return-average      | 4926.0156  |
| evaluation/return-max          | 5041.873   |
| evaluation/return-min          | 4522.0938  |
| evaluation/return-std          | 143.30067  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46485      |
| perf/AverageLength             | 992        |
| perf/AverageReturn             | 4926.0156  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 220.81499  |
| Q-std                          | 130.23268  |
| Q_loss                         | 98.93919   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 643        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000565   |
| times/evaluation_paths         | 33.9       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 644000     |
| train-steps                    | 644000     |
| training/Q/q1_loss             | 105.69685  |
| training/sac_pi/alpha          | 0.16996796 |
| training/sac_pi/alpha_loss     | 0.4670421  |
| training/sac_pi/logp_pi        | 4.085502   |
| training/sac_pi/pi_entropy     | 3.516021   |
| training/sac_pi/pi_global_norm | 1.9228127  |
| training/sac_pi/policy_loss    | -229.3922  |
| training/sac_pi/std            | 0.4767766  |
| training/sac_pi/valid_num      | 4993.0     |
| training/sac_Q/q1              | 220.3232   |
| training/sac_Q/q2              | 222.37155  |
| training/sac_Q/q2_loss         | 106.7126   |
| training/sac_Q/q_global_norm   | 253.91461  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16313136 |
| epoch                          | 644        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5209.8013  |
| evaluation/return-max          | 5287.769   |
| evaluation/return-min          | 4979.621   |
| evaluation/return-std          | 82.77706   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46362      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5209.8013  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 218.7438   |
| Q-std                          | 139.64645  |
| Q_loss                         | 104.08289  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 644        |
| times/epoch_after_hook         | 1.97e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000495   |
| times/evaluation_paths         | 37.5       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 645000     |
| train-steps                    | 645000     |
| training/Q/q1_loss             | 115.19652  |
| training/sac_pi/alpha          | 0.16312264 |
| training/sac_pi/alpha_loss     | 0.52452433 |
| training/sac_pi/logp_pi        | 4.940453   |
| training/sac_pi/pi_entropy     | 3.6118035  |
| training/sac_pi/pi_global_norm | 1.7585958  |
| training/sac_pi/policy_loss    | -216.75548 |
| training/sac_pi/std            | 0.53584665 |
| training/sac_pi/valid_num      | 4844.0     |
| training/sac_Q/q1              | 192.26823  |
| training/sac_Q/q2              | 195.9268   |
| training/sac_Q/q2_loss         | 117.03833  |
| training/sac_Q/q_global_norm   | 260.52148  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16071516 |
| epoch                          | 645        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4956.503   |
| evaluation/return-max          | 5115.716   |
| evaluation/return-min          | 4846.5776  |
| evaluation/return-std          | 86.19467   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46487      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4956.503   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 210.17447  |
| Q-std                          | 129.96742  |
| Q_loss                         | 101.33339  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 645        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000286   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000568   |
| times/evaluation_paths         | 34.1       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00852    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 646000     |
| train-steps                    | 646000     |
| training/Q/q1_loss             | 99.688194  |
| training/sac_pi/alpha          | 0.16073576 |
| training/sac_pi/alpha_loss     | 0.09863009 |
| training/sac_pi/logp_pi        | 3.9126396  |
| training/sac_pi/pi_entropy     | 3.3312042  |
| training/sac_pi/pi_global_norm | 1.8908584  |
| training/sac_pi/policy_loss    | -224.05905 |
| training/sac_pi/std            | 0.47965875 |
| training/sac_pi/valid_num      | 5025.0     |
| training/sac_Q/q1              | 217.51279  |
| training/sac_Q/q2              | 217.31133  |
| training/sac_Q/q2_loss         | 100.292435 |
| training/sac_Q/q_global_norm   | 239.59627  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1614697   |
| epoch                          | 646         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5183.493    |
| evaluation/return-max          | 5252.002    |
| evaluation/return-min          | 5080.1704   |
| evaluation/return-std          | 48.847183   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46449       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5183.493    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 219.37007   |
| Q-std                          | 158.52626   |
| Q_loss                         | 103.19084   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 646         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000651    |
| times/evaluation_paths         | 35.4        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00863     |
| times/train                    | 63.6        |
| timestep                       | 1000        |
| timesteps_total                | 647000      |
| train-steps                    | 647000      |
| training/Q/q1_loss             | 93.90901    |
| training/sac_pi/alpha          | 0.16148919  |
| training/sac_pi/alpha_loss     | -0.35915974 |
| training/sac_pi/logp_pi        | 3.7062593   |
| training/sac_pi/pi_entropy     | 3.584378    |
| training/sac_pi/pi_global_norm | 1.5928319   |
| training/sac_pi/policy_loss    | -226.84013  |
| training/sac_pi/std            | 0.48394933  |
| training/sac_pi/valid_num      | 4976.0      |
| training/sac_Q/q1              | 217.94296   |
| training/sac_Q/q2              | 219.92795   |
| training/sac_Q/q2_loss         | 94.16495    |
| training/sac_Q/q_global_norm   | 316.98776   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16055922  |
| epoch                          | 647         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4897.518    |
| evaluation/return-max          | 4946.8687   |
| evaluation/return-min          | 4768.6484   |
| evaluation/return-std          | 52.05013    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46253       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4897.518    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 213.43753   |
| Q-std                          | 136.27827   |
| Q_loss                         | 90.67397    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 647         |
| times/epoch_after_hook         | 1.56e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000544    |
| times/evaluation_paths         | 34.8        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 63.2        |
| timestep                       | 1000        |
| timesteps_total                | 648000      |
| train-steps                    | 648000      |
| training/Q/q1_loss             | 71.39336    |
| training/sac_pi/alpha          | 0.16055498  |
| training/sac_pi/alpha_loss     | -0.35920826 |
| training/sac_pi/logp_pi        | 3.6644294   |
| training/sac_pi/pi_entropy     | 3.3150303   |
| training/sac_pi/pi_global_norm | 1.7364843   |
| training/sac_pi/policy_loss    | -230.06871  |
| training/sac_pi/std            | 0.47258422  |
| training/sac_pi/valid_num      | 4994.0      |
| training/sac_Q/q1              | 220.40805   |
| training/sac_Q/q2              | 221.2906    |
| training/sac_Q/q2_loss         | 70.55366    |
| training/sac_Q/q_global_norm   | 250.31955   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16254328 |
| epoch                          | 648        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4827.993   |
| evaluation/return-max          | 5012.6445  |
| evaluation/return-min          | 4639.8613  |
| evaluation/return-std          | 134.51018  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46310      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4827.993   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 216.89241  |
| Q-std                          | 163.33759  |
| Q_loss                         | 105.21112  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 648        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000143   |
| times/epoch_rollout_model      | 517        |
| times/evaluation_metrics       | 0.000602   |
| times/evaluation_paths         | 35         |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00875    |
| times/train                    | 64.5       |
| timestep                       | 1000       |
| timesteps_total                | 649000     |
| train-steps                    | 649000     |
| training/Q/q1_loss             | 102.848465 |
| training/sac_pi/alpha          | 0.16253872 |
| training/sac_pi/alpha_loss     | 0.22114785 |
| training/sac_pi/logp_pi        | 4.2516     |
| training/sac_pi/pi_entropy     | 3.4316826  |
| training/sac_pi/pi_global_norm | 1.4694282  |
| training/sac_pi/policy_loss    | -223.72894 |
| training/sac_pi/std            | 0.49655476 |
| training/sac_pi/valid_num      | 4967.0     |
| training/sac_Q/q1              | 214.50967  |
| training/sac_Q/q2              | 215.82681  |
| training/sac_Q/q2_loss         | 102.7757   |
| training/sac_Q/q_global_norm   | 284.71765  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15709136  |
| epoch                          | 649         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4808.361    |
| evaluation/return-max          | 4848.3965   |
| evaluation/return-min          | 4724.3545   |
| evaluation/return-std          | 39.84445    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46575       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4808.361    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 208.3226    |
| Q-std                          | 210.40031   |
| Q_loss                         | 104.18121   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 649         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000301    |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000717    |
| times/evaluation_paths         | 37.7        |
| times/timestep_after_hook      | 0.00385     |
| times/timestep_before_hook     | 0.00879     |
| times/train                    | 64.7        |
| timestep                       | 1000        |
| timesteps_total                | 650000      |
| train-steps                    | 650000      |
| training/Q/q1_loss             | 109.59523   |
| training/sac_pi/alpha          | 0.15706123  |
| training/sac_pi/alpha_loss     | -0.10915716 |
| training/sac_pi/logp_pi        | 5.1235476   |
| training/sac_pi/pi_entropy     | 3.6580708   |
| training/sac_pi/pi_global_norm | 1.6921295   |
| training/sac_pi/policy_loss    | -220.49765  |
| training/sac_pi/std            | 0.5692756   |
| training/sac_pi/valid_num      | 4896.0      |
| training/sac_Q/q1              | 196.74583   |
| training/sac_Q/q2              | 201.74968   |
| training/sac_Q/q2_loss         | 110.32211   |
| training/sac_Q/q_global_norm   | 226.24873   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16016354  |
| epoch                          | 650         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4984.3877   |
| evaluation/return-max          | 5136.6455   |
| evaluation/return-min          | 4739.7236   |
| evaluation/return-std          | 134.25673   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46513       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4984.3877   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 220.17984   |
| Q-std                          | 109.39038   |
| Q_loss                         | 100.23262   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 650         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000324    |
| times/epoch_rollout_model      | 501         |
| times/evaluation_metrics       | 0.000523    |
| times/evaluation_paths         | 35          |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.00858     |
| times/train                    | 64.2        |
| timestep                       | 1000        |
| timesteps_total                | 651000      |
| train-steps                    | 651000      |
| training/Q/q1_loss             | 110.14563   |
| training/sac_pi/alpha          | 0.16020143  |
| training/sac_pi/alpha_loss     | -0.15130427 |
| training/sac_pi/logp_pi        | 4.020846    |
| training/sac_pi/pi_entropy     | 3.5208683   |
| training/sac_pi/pi_global_norm | 1.7611623   |
| training/sac_pi/policy_loss    | -224.01576  |
| training/sac_pi/std            | 0.5040162   |
| training/sac_pi/valid_num      | 4965.0      |
| training/sac_Q/q1              | 215.4041    |
| training/sac_Q/q2              | 213.74121   |
| training/sac_Q/q2_loss         | 109.560684  |
| training/sac_Q/q_global_norm   | 243.41797   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16145833 |
| epoch                          | 651        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5067.9756  |
| evaluation/return-max          | 5091.586   |
| evaluation/return-min          | 5045.8467  |
| evaluation/return-std          | 14.3148775 |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 78.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46574      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5067.9756  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 218.58415  |
| Q-std                          | 177.50018  |
| Q_loss                         | 70.33965   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 651        |
| times/epoch_after_hook         | 1.59e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000605   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00341    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 59         |
| timestep                       | 1000       |
| timesteps_total                | 652000     |
| train-steps                    | 652000     |
| training/Q/q1_loss             | 95.20224   |
| training/sac_pi/alpha          | 0.16144928 |
| training/sac_pi/alpha_loss     | 0.2914545  |
| training/sac_pi/logp_pi        | 3.7821133  |
| training/sac_pi/pi_entropy     | 3.2816925  |
| training/sac_pi/pi_global_norm | 1.8592823  |
| training/sac_pi/policy_loss    | -223.29935 |
| training/sac_pi/std            | 0.45122063 |
| training/sac_pi/valid_num      | 5013.0     |
| training/sac_Q/q1              | 218.7526   |
| training/sac_Q/q2              | 219.37192  |
| training/sac_Q/q2_loss         | 95.29514   |
| training/sac_Q/q_global_norm   | 390.6281   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15866293 |
| epoch                          | 652        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5048.523   |
| evaluation/return-max          | 5113.92    |
| evaluation/return-min          | 4922.667   |
| evaluation/return-std          | 55.9339    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46543      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5048.523   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 218.38785  |
| Q-std                          | 176.14969  |
| Q_loss                         | 85.35218   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 652        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000589   |
| times/evaluation_paths         | 34.4       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 653000     |
| train-steps                    | 653000     |
| training/Q/q1_loss             | 89.968254  |
| training/sac_pi/alpha          | 0.15864925 |
| training/sac_pi/alpha_loss     | 0.08289387 |
| training/sac_pi/logp_pi        | 4.578795   |
| training/sac_pi/pi_entropy     | 3.3790526  |
| training/sac_pi/pi_global_norm | 2.0837789  |
| training/sac_pi/policy_loss    | -230.77893 |
| training/sac_pi/std            | 0.4983978  |
| training/sac_pi/valid_num      | 4909.0     |
| training/sac_Q/q1              | 219.02979  |
| training/sac_Q/q2              | 218.65047  |
| training/sac_Q/q2_loss         | 89.79415   |
| training/sac_Q/q_global_norm   | 205.04376  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16362685 |
| epoch                          | 653        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5087.214   |
| evaluation/return-max          | 5106.9233  |
| evaluation/return-min          | 5059.839   |
| evaluation/return-std          | 12.790956  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46442      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5087.214   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 221.35556  |
| Q-std                          | 138.63159  |
| Q_loss                         | 100.73132  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 653        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000279   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000585   |
| times/evaluation_paths         | 35         |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00809    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 654000     |
| train-steps                    | 654000     |
| training/Q/q1_loss             | 110.8476   |
| training/sac_pi/alpha          | 0.16360888 |
| training/sac_pi/alpha_loss     | 0.5700795  |
| training/sac_pi/logp_pi        | 4.9059987  |
| training/sac_pi/pi_entropy     | 3.4096413  |
| training/sac_pi/pi_global_norm | 2.1548998  |
| training/sac_pi/policy_loss    | -217.74358 |
| training/sac_pi/std            | 0.4978421  |
| training/sac_pi/valid_num      | 4985.0     |
| training/sac_Q/q1              | 206.47928  |
| training/sac_Q/q2              | 207.8182   |
| training/sac_Q/q2_loss         | 110.28202  |
| training/sac_Q/q_global_norm   | 242.98532  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16292502  |
| epoch                          | 654         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5071.156    |
| evaluation/return-max          | 5136.8516   |
| evaluation/return-min          | 5027.7256   |
| evaluation/return-std          | 35.535793   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.15        |
| model/origin_ret               | 86.8        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46427       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5071.156    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 218.52193   |
| Q-std                          | 127.850525  |
| Q_loss                         | 93.71466    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 654         |
| times/epoch_after_hook         | 3.36e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.00055     |
| times/evaluation_paths         | 37.5        |
| times/timestep_after_hook      | 0.00357     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 62.3        |
| timestep                       | 1000        |
| timesteps_total                | 655000      |
| train-steps                    | 655000      |
| training/Q/q1_loss             | 94.65309    |
| training/sac_pi/alpha          | 0.1629361   |
| training/sac_pi/alpha_loss     | -0.12902053 |
| training/sac_pi/logp_pi        | 4.257697    |
| training/sac_pi/pi_entropy     | 3.611608    |
| training/sac_pi/pi_global_norm | 1.935323    |
| training/sac_pi/policy_loss    | -229.92134  |
| training/sac_pi/std            | 0.51918817  |
| training/sac_pi/valid_num      | 4945.0      |
| training/sac_Q/q1              | 220.56454   |
| training/sac_Q/q2              | 220.51567   |
| training/sac_Q/q2_loss         | 96.01824    |
| training/sac_Q/q_global_norm   | 297.56967   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15983367   |
| epoch                          | 655          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4667.9766    |
| evaluation/return-max          | 4866.1074    |
| evaluation/return-min          | 4439.708     |
| evaluation/return-std          | 127.71381    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.11         |
| model/origin_ret               | 86.2         |
| model/penalty_ret              | 79.6         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46530        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4667.9766    |
| perf/NormalizedReturn          | 1.02         |
| Q-avg                          | 224.75626    |
| Q-std                          | 101.5901     |
| Q_loss                         | 105.67402    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 655          |
| times/epoch_after_hook         | 1.62e-06     |
| times/epoch_before_hook        | 0.000152     |
| times/epoch_rollout_model      | 482          |
| times/evaluation_metrics       | 0.000534     |
| times/evaluation_paths         | 34.4         |
| times/timestep_after_hook      | 0.00365      |
| times/timestep_before_hook     | 0.00823      |
| times/train                    | 60.2         |
| timestep                       | 1000         |
| timesteps_total                | 656000       |
| train-steps                    | 656000       |
| training/Q/q1_loss             | 109.088684   |
| training/sac_pi/alpha          | 0.15982664   |
| training/sac_pi/alpha_loss     | 0.0009026297 |
| training/sac_pi/logp_pi        | 4.533513     |
| training/sac_pi/pi_entropy     | 3.2986856    |
| training/sac_pi/pi_global_norm | 1.7482226    |
| training/sac_pi/policy_loss    | -233.05917   |
| training/sac_pi/std            | 0.4829385    |
| training/sac_pi/valid_num      | 4989.0       |
| training/sac_Q/q1              | 224.3711     |
| training/sac_Q/q2              | 224.81088    |
| training/sac_Q/q2_loss         | 109.75531    |
| training/sac_Q/q_global_norm   | 344.5486     |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16362165  |
| epoch                          | 656         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4851.062    |
| evaluation/return-max          | 4950.1343   |
| evaluation/return-min          | 4756.252    |
| evaluation/return-std          | 75.8856     |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46555       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4851.062    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 215.37886   |
| Q-std                          | 157.14082   |
| Q_loss                         | 105.46783   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 656         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000569    |
| times/evaluation_paths         | 37.9        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 61.9        |
| timestep                       | 1000        |
| timesteps_total                | 657000      |
| train-steps                    | 657000      |
| training/Q/q1_loss             | 88.35819    |
| training/sac_pi/alpha          | 0.16361791  |
| training/sac_pi/alpha_loss     | -0.12557581 |
| training/sac_pi/logp_pi        | 3.5244756   |
| training/sac_pi/pi_entropy     | 3.544597    |
| training/sac_pi/pi_global_norm | 1.6336751   |
| training/sac_pi/policy_loss    | -230.12383  |
| training/sac_pi/std            | 0.4845197   |
| training/sac_pi/valid_num      | 5019.0      |
| training/sac_Q/q1              | 221.86617   |
| training/sac_Q/q2              | 223.2709    |
| training/sac_Q/q2_loss         | 88.486305   |
| training/sac_Q/q_global_norm   | 189.56657   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16304503 |
| epoch                          | 657        |
| evaluation/episode-length-avg  | 800        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 332        |
| evaluation/episode-length-std  | 306        |
| evaluation/return-average      | 4016.2039  |
| evaluation/return-max          | 5272.792   |
| evaluation/return-min          | 1341.4604  |
| evaluation/return-std          | 1747.347   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46410      |
| perf/AverageLength             | 800        |
| perf/AverageReturn             | 4016.2039  |
| perf/NormalizedReturn          | 0.875      |
| Q-avg                          | 219.0196   |
| Q-std                          | 103.916374 |
| Q_loss                         | 93.811905  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 657        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000339   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000812   |
| times/evaluation_paths         | 29.8       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 658000     |
| train-steps                    | 658000     |
| training/Q/q1_loss             | 110.59921  |
| training/sac_pi/alpha          | 0.1630652  |
| training/sac_pi/alpha_loss     | 0.40268314 |
| training/sac_pi/logp_pi        | 4.1235704  |
| training/sac_pi/pi_entropy     | 3.3485188  |
| training/sac_pi/pi_global_norm | 1.8951014  |
| training/sac_pi/policy_loss    | -228.59044 |
| training/sac_pi/std            | 0.47193792 |
| training/sac_pi/valid_num      | 5019.0     |
| training/sac_Q/q1              | 222.24716  |
| training/sac_Q/q2              | 222.90771  |
| training/sac_Q/q2_loss         | 110.14279  |
| training/sac_Q/q_global_norm   | 255.02032  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1591439  |
| epoch                          | 658        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4814.446   |
| evaluation/return-max          | 4862.83    |
| evaluation/return-min          | 4751.565   |
| evaluation/return-std          | 39.137558  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46416      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4814.446   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 223.30376  |
| Q-std                          | 149.4086   |
| Q_loss                         | 97.08823   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 658        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000679   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 659000     |
| train-steps                    | 659000     |
| training/Q/q1_loss             | 109.21441  |
| training/sac_pi/alpha          | 0.1591413  |
| training/sac_pi/alpha_loss     | 0.5312295  |
| training/sac_pi/logp_pi        | 4.2262883  |
| training/sac_pi/pi_entropy     | 3.1811051  |
| training/sac_pi/pi_global_norm | 2.099168   |
| training/sac_pi/policy_loss    | -227.42702 |
| training/sac_pi/std            | 0.4648339  |
| training/sac_pi/valid_num      | 5006.0     |
| training/sac_Q/q1              | 218.43857  |
| training/sac_Q/q2              | 219.63972  |
| training/sac_Q/q2_loss         | 108.94041  |
| training/sac_Q/q_global_norm   | 257.90247  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16421193  |
| epoch                          | 659         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5102.302    |
| evaluation/return-max          | 5164.757    |
| evaluation/return-min          | 5053.8916   |
| evaluation/return-std          | 33.722237   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46552       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5102.302    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 222.42981   |
| Q-std                          | 99.31407    |
| Q_loss                         | 103.63368   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 659         |
| times/epoch_after_hook         | 1.62e-06    |
| times/epoch_before_hook        | 0.00015     |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.00053     |
| times/evaluation_paths         | 34.4        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00834     |
| times/train                    | 62          |
| timestep                       | 1000        |
| timesteps_total                | 660000      |
| train-steps                    | 660000      |
| training/Q/q1_loss             | 101.67712   |
| training/sac_pi/alpha          | 0.16423233  |
| training/sac_pi/alpha_loss     | -0.21737789 |
| training/sac_pi/logp_pi        | 3.9893632   |
| training/sac_pi/pi_entropy     | 3.4403243   |
| training/sac_pi/pi_global_norm | 1.9163995   |
| training/sac_pi/policy_loss    | -224.43533  |
| training/sac_pi/std            | 0.48803252  |
| training/sac_pi/valid_num      | 5026.0      |
| training/sac_Q/q1              | 215.90646   |
| training/sac_Q/q2              | 215.03232   |
| training/sac_Q/q2_loss         | 102.56923   |
| training/sac_Q/q_global_norm   | 246.70876   |
---------------------------------------------------------------------------------
[WARN] 660 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16838013 |
| epoch                          | 660        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5112.782   |
| evaluation/return-max          | 5184.977   |
| evaluation/return-min          | 5030.3135  |
| evaluation/return-std          | 44.293106  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46480      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5112.782   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 211.87387  |
| Q-std                          | 157.90974  |
| Q_loss                         | 109.378235 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 660        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000758   |
| times/evaluation_paths         | 35.2       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 63.5       |
| timestep                       | 1000       |
| timesteps_total                | 661000     |
| train-steps                    | 661000     |
| training/Q/q1_loss             | 100.79382  |
| training/sac_pi/alpha          | 0.16835982 |
| training/sac_pi/alpha_loss     | 0.15252294 |
| training/sac_pi/logp_pi        | 4.756627   |
| training/sac_pi/pi_entropy     | 3.547255   |
| training/sac_pi/pi_global_norm | 2.207994   |
| training/sac_pi/policy_loss    | -226.01727 |
| training/sac_pi/std            | 0.51012385 |
| training/sac_pi/valid_num      | 4907.0     |
| training/sac_Q/q1              | 209.04834  |
| training/sac_Q/q2              | 212.9045   |
| training/sac_Q/q2_loss         | 100.60894  |
| training/sac_Q/q_global_norm   | 282.87543  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16499798 |
| epoch                          | 661        |
| evaluation/episode-length-avg  | 988        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 884        |
| evaluation/episode-length-std  | 34.8       |
| evaluation/return-average      | 5053.7144  |
| evaluation/return-max          | 5215.926   |
| evaluation/return-min          | 4382.5386  |
| evaluation/return-std          | 231.13202  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46439      |
| perf/AverageLength             | 988        |
| perf/AverageReturn             | 5053.7144  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 210.23154  |
| Q-std                          | 186.22556  |
| Q_loss                         | 94.228935  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 661        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000291   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000632   |
| times/evaluation_paths         | 38.2       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00847    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 662000     |
| train-steps                    | 662000     |
| training/Q/q1_loss             | 90.799446  |
| training/sac_pi/alpha          | 0.16503935 |
| training/sac_pi/alpha_loss     | -0.4741526 |
| training/sac_pi/logp_pi        | 3.7220886  |
| training/sac_pi/pi_entropy     | 3.404902   |
| training/sac_pi/pi_global_norm | 2.0145924  |
| training/sac_pi/policy_loss    | -225.0004  |
| training/sac_pi/std            | 0.47956216 |
| training/sac_pi/valid_num      | 5014.0     |
| training/sac_Q/q1              | 211.15764  |
| training/sac_Q/q2              | 211.85747  |
| training/sac_Q/q2_loss         | 90.70035   |
| training/sac_Q/q_global_norm   | 212.4643   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16218796 |
| epoch                          | 662        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5096.7305  |
| evaluation/return-max          | 5127.7373  |
| evaluation/return-min          | 5016.748   |
| evaluation/return-std          | 34.851177  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46502      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5096.7305  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 220.22775  |
| Q-std                          | 134.75168  |
| Q_loss                         | 101.36386  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 662        |
| times/epoch_after_hook         | 3.1e-06    |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000741   |
| times/evaluation_paths         | 35.1       |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 59.9       |
| timestep                       | 1000       |
| timesteps_total                | 663000     |
| train-steps                    | 663000     |
| training/Q/q1_loss             | 102.212585 |
| training/sac_pi/alpha          | 0.16215472 |
| training/sac_pi/alpha_loss     | 0.2682006  |
| training/sac_pi/logp_pi        | 4.3910446  |
| training/sac_pi/pi_entropy     | 3.5300732  |
| training/sac_pi/pi_global_norm | 1.7542762  |
| training/sac_pi/policy_loss    | -233.70134 |
| training/sac_pi/std            | 0.50587666 |
| training/sac_pi/valid_num      | 4976.0     |
| training/sac_Q/q1              | 219.92403  |
| training/sac_Q/q2              | 223.52298  |
| training/sac_Q/q2_loss         | 103.507935 |
| training/sac_Q/q_global_norm   | 295.0604   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15687041 |
| epoch                          | 663        |
| evaluation/episode-length-avg  | 836        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 619        |
| evaluation/episode-length-std  | 142        |
| evaluation/return-average      | 4088.5884  |
| evaluation/return-max          | 5062.039   |
| evaluation/return-min          | 2867.9634  |
| evaluation/return-std          | 791.9436   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 87.7       |
| model/penalty_ret              | 80.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46363      |
| perf/AverageLength             | 836        |
| perf/AverageReturn             | 4088.5884  |
| perf/NormalizedReturn          | 0.89       |
| Q-avg                          | 209.79324  |
| Q-std                          | 148.4099   |
| Q_loss                         | 97.699524  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 663        |
| times/epoch_after_hook         | 2.18e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000574   |
| times/evaluation_paths         | 32.3       |
| times/timestep_after_hook      | 0.0038     |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 61.1       |
| timestep                       | 1000       |
| timesteps_total                | 664000     |
| train-steps                    | 664000     |
| training/Q/q1_loss             | 94.91753   |
| training/sac_pi/alpha          | 0.15687832 |
| training/sac_pi/alpha_loss     | -0.1359692 |
| training/sac_pi/logp_pi        | 4.36735    |
| training/sac_pi/pi_entropy     | 3.2146919  |
| training/sac_pi/pi_global_norm | 2.4266932  |
| training/sac_pi/policy_loss    | -229.5896  |
| training/sac_pi/std            | 0.47956073 |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 220.19534  |
| training/sac_Q/q2              | 220.31013  |
| training/sac_Q/q2_loss         | 94.423836  |
| training/sac_Q/q_global_norm   | 203.73485  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15752143 |
| epoch                          | 664        |
| evaluation/episode-length-avg  | 676        |
| evaluation/episode-length-max  | 959        |
| evaluation/episode-length-min  | 577        |
| evaluation/episode-length-std  | 111        |
| evaluation/return-average      | 3368.6882  |
| evaluation/return-max          | 4963.6895  |
| evaluation/return-min          | 2837.8662  |
| evaluation/return-std          | 633.0394   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46439      |
| perf/AverageLength             | 676        |
| perf/AverageReturn             | 3368.6882  |
| perf/NormalizedReturn          | 0.733      |
| Q-avg                          | 225.70341  |
| Q-std                          | 91.734276  |
| Q_loss                         | 107.04882  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 664        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000747   |
| times/evaluation_paths         | 24.4       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00843    |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 665000     |
| train-steps                    | 665000     |
| training/Q/q1_loss             | 112.48479  |
| training/sac_pi/alpha          | 0.15750645 |
| training/sac_pi/alpha_loss     | 0.0747408  |
| training/sac_pi/logp_pi        | 4.5042334  |
| training/sac_pi/pi_entropy     | 3.2971718  |
| training/sac_pi/pi_global_norm | 1.7804773  |
| training/sac_pi/policy_loss    | -227.90208 |
| training/sac_pi/std            | 0.4930934  |
| training/sac_pi/valid_num      | 4943.0     |
| training/sac_Q/q1              | 214.28764  |
| training/sac_Q/q2              | 217.22661  |
| training/sac_Q/q2_loss         | 112.9805   |
| training/sac_Q/q_global_norm   | 223.9235   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15799262 |
| epoch                          | 665        |
| evaluation/episode-length-avg  | 917        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 167        |
| evaluation/episode-length-std  | 250        |
| evaluation/return-average      | 4654.6     |
| evaluation/return-max          | 5253.016   |
| evaluation/return-min          | 528.7441   |
| evaluation/return-std          | 1378.5089  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46363      |
| perf/AverageLength             | 917        |
| perf/AverageReturn             | 4654.6     |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 211.8424   |
| Q-std                          | 121.792656 |
| Q_loss                         | 98.606316  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 665        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000285   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000555   |
| times/evaluation_paths         | 31.5       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 666000     |
| train-steps                    | 666000     |
| training/Q/q1_loss             | 90.1688    |
| training/sac_pi/alpha          | 0.15796967 |
| training/sac_pi/alpha_loss     | 0.37614524 |
| training/sac_pi/logp_pi        | 5.2090974  |
| training/sac_pi/pi_entropy     | 3.424951   |
| training/sac_pi/pi_global_norm | 1.7983179  |
| training/sac_pi/policy_loss    | -222.16019 |
| training/sac_pi/std            | 0.5111606  |
| training/sac_pi/valid_num      | 4930.0     |
| training/sac_Q/q1              | 210.09189  |
| training/sac_Q/q2              | 211.41919  |
| training/sac_Q/q2_loss         | 90.364525  |
| training/sac_Q/q_global_norm   | 197.05333  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16003336  |
| epoch                          | 666         |
| evaluation/episode-length-avg  | 932         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 316         |
| evaluation/episode-length-std  | 205         |
| evaluation/return-average      | 4693.8135   |
| evaluation/return-max          | 5186.1675   |
| evaluation/return-min          | 1267.3219   |
| evaluation/return-std          | 1144.7808   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 80.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46365       |
| perf/AverageLength             | 932         |
| perf/AverageReturn             | 4693.8135   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 208.48872   |
| Q-std                          | 132.22621   |
| Q_loss                         | 96.21545    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 666         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000681    |
| times/evaluation_paths         | 33.6        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00832     |
| times/train                    | 62.6        |
| timestep                       | 1000        |
| timesteps_total                | 667000      |
| train-steps                    | 667000      |
| training/Q/q1_loss             | 94.12486    |
| training/sac_pi/alpha          | 0.16003111  |
| training/sac_pi/alpha_loss     | -0.06648927 |
| training/sac_pi/logp_pi        | 4.081357    |
| training/sac_pi/pi_entropy     | 3.3588376   |
| training/sac_pi/pi_global_norm | 2.0239098   |
| training/sac_pi/policy_loss    | -235.49312  |
| training/sac_pi/std            | 0.47662818  |
| training/sac_pi/valid_num      | 4958.0      |
| training/sac_Q/q1              | 225.50835   |
| training/sac_Q/q2              | 226.67221   |
| training/sac_Q/q2_loss         | 92.49656    |
| training/sac_Q/q_global_norm   | 220.78593   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1555193   |
| epoch                          | 667         |
| evaluation/episode-length-avg  | 577         |
| evaluation/episode-length-max  | 701         |
| evaluation/episode-length-min  | 523         |
| evaluation/episode-length-std  | 61.3        |
| evaluation/return-average      | 2661.4556   |
| evaluation/return-max          | 3247.9      |
| evaluation/return-min          | 2368.8755   |
| evaluation/return-std          | 320.15646   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46257       |
| perf/AverageLength             | 577         |
| perf/AverageReturn             | 2661.4556   |
| perf/NormalizedReturn          | 0.579       |
| Q-avg                          | 215.54056   |
| Q-std                          | 149.76724   |
| Q_loss                         | 89.30986    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 667         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000525    |
| times/evaluation_paths         | 21.4        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00853     |
| times/train                    | 64.7        |
| timestep                       | 1000        |
| timesteps_total                | 668000      |
| train-steps                    | 668000      |
| training/Q/q1_loss             | 91.75831    |
| training/sac_pi/alpha          | 0.1555298   |
| training/sac_pi/alpha_loss     | 0.014507432 |
| training/sac_pi/logp_pi        | 4.700461    |
| training/sac_pi/pi_entropy     | 3.537452    |
| training/sac_pi/pi_global_norm | 1.7143557   |
| training/sac_pi/policy_loss    | -222.52844  |
| training/sac_pi/std            | 0.52335745  |
| training/sac_pi/valid_num      | 4953.0      |
| training/sac_Q/q1              | 206.4484    |
| training/sac_Q/q2              | 211.33589   |
| training/sac_Q/q2_loss         | 92.85871    |
| training/sac_Q/q_global_norm   | 186.46211   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1621565  |
| epoch                          | 668        |
| evaluation/episode-length-avg  | 716        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 285        |
| evaluation/episode-length-std  | 347        |
| evaluation/return-average      | 3328.816   |
| evaluation/return-max          | 4950.1133  |
| evaluation/return-min          | 1026.2694  |
| evaluation/return-std          | 1860.1598  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46485      |
| perf/AverageLength             | 716        |
| perf/AverageReturn             | 3328.816   |
| perf/NormalizedReturn          | 0.725      |
| Q-avg                          | 206.62544  |
| Q-std                          | 160.60707  |
| Q_loss                         | 118.291016 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 668        |
| times/epoch_after_hook         | 1.62e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000562   |
| times/evaluation_paths         | 29.5       |
| times/timestep_after_hook      | 0.00385    |
| times/timestep_before_hook     | 0.00881    |
| times/train                    | 72.3       |
| timestep                       | 1000       |
| timesteps_total                | 669000     |
| train-steps                    | 669000     |
| training/Q/q1_loss             | 117.981865 |
| training/sac_pi/alpha          | 0.16215275 |
| training/sac_pi/alpha_loss     | 0.22612144 |
| training/sac_pi/logp_pi        | 4.221877   |
| training/sac_pi/pi_entropy     | 3.5904503  |
| training/sac_pi/pi_global_norm | 2.0935647  |
| training/sac_pi/policy_loss    | -220.31377 |
| training/sac_pi/std            | 0.5184206  |
| training/sac_pi/valid_num      | 4948.0     |
| training/sac_Q/q1              | 211.38103  |
| training/sac_Q/q2              | 211.59586  |
| training/sac_Q/q2_loss         | 118.95301  |
| training/sac_Q/q_global_norm   | 247.8118   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1620695   |
| epoch                          | 669         |
| evaluation/episode-length-avg  | 670         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 314         |
| evaluation/episode-length-std  | 330         |
| evaluation/return-average      | 3204.7742   |
| evaluation/return-max          | 5082.4473   |
| evaluation/return-min          | 1245.708    |
| evaluation/return-std          | 1829.1862   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.06        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46555       |
| perf/AverageLength             | 670         |
| perf/AverageReturn             | 3204.7742   |
| perf/NormalizedReturn          | 0.698       |
| Q-avg                          | 209.40215   |
| Q-std                          | 171.40756   |
| Q_loss                         | 97.629486   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 669         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000278    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000479    |
| times/evaluation_paths         | 32.2        |
| times/timestep_after_hook      | 0.00628     |
| times/timestep_before_hook     | 0.00862     |
| times/train                    | 77.9        |
| timestep                       | 1000        |
| timesteps_total                | 670000      |
| train-steps                    | 670000      |
| training/Q/q1_loss             | 101.89295   |
| training/sac_pi/alpha          | 0.16207325  |
| training/sac_pi/alpha_loss     | 0.026367255 |
| training/sac_pi/logp_pi        | 3.6235726   |
| training/sac_pi/pi_entropy     | 3.3493361   |
| training/sac_pi/pi_global_norm | 2.2627563   |
| training/sac_pi/policy_loss    | -224.7489   |
| training/sac_pi/std            | 0.45845515  |
| training/sac_pi/valid_num      | 5037.0      |
| training/sac_Q/q1              | 220.64389   |
| training/sac_Q/q2              | 220.42484   |
| training/sac_Q/q2_loss         | 100.82434   |
| training/sac_Q/q_global_norm   | 219.37032   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16073725 |
| epoch                          | 670        |
| evaluation/episode-length-avg  | 972        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 725        |
| evaluation/episode-length-std  | 82.5       |
| evaluation/return-average      | 5020.2627  |
| evaluation/return-max          | 5264.082   |
| evaluation/return-min          | 3562.4739  |
| evaluation/return-std          | 490.32584  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46391      |
| perf/AverageLength             | 972        |
| perf/AverageReturn             | 5020.2627  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 215.5134   |
| Q-std                          | 146.43169  |
| Q_loss                         | 110.396286 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 670        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000116   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000628   |
| times/evaluation_paths         | 44.8       |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.0086     |
| times/train                    | 74         |
| timestep                       | 1000       |
| timesteps_total                | 671000     |
| train-steps                    | 671000     |
| training/Q/q1_loss             | 107.909515 |
| training/sac_pi/alpha          | 0.16072401 |
| training/sac_pi/alpha_loss     | 0.08729165 |
| training/sac_pi/logp_pi        | 4.0092     |
| training/sac_pi/pi_entropy     | 3.5279427  |
| training/sac_pi/pi_global_norm | 1.8439008  |
| training/sac_pi/policy_loss    | -231.77065 |
| training/sac_pi/std            | 0.49783102 |
| training/sac_pi/valid_num      | 4972.0     |
| training/sac_Q/q1              | 218.43741  |
| training/sac_Q/q2              | 220.67744  |
| training/sac_Q/q2_loss         | 108.06265  |
| training/sac_Q/q_global_norm   | 289.94012  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16468017  |
| epoch                          | 671         |
| evaluation/episode-length-avg  | 236         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 149         |
| evaluation/episode-length-std  | 255         |
| evaluation/return-average      | 930.2705    |
| evaluation/return-max          | 5195.833    |
| evaluation/return-min          | 444.57172   |
| evaluation/return-std          | 1421.869    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 80.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46321       |
| perf/AverageLength             | 236         |
| perf/AverageReturn             | 930.2705    |
| perf/NormalizedReturn          | 0.202       |
| Q-avg                          | 219.49924   |
| Q-std                          | 148.56868   |
| Q_loss                         | 106.65775   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 671         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000467    |
| times/evaluation_paths         | 11.6        |
| times/timestep_after_hook      | 0.00379     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 73          |
| timestep                       | 1000        |
| timesteps_total                | 672000      |
| train-steps                    | 672000      |
| training/Q/q1_loss             | 76.38705    |
| training/sac_pi/alpha          | 0.16468567  |
| training/sac_pi/alpha_loss     | -0.14626078 |
| training/sac_pi/logp_pi        | 4.072578    |
| training/sac_pi/pi_entropy     | 3.4727302   |
| training/sac_pi/pi_global_norm | 2.284864    |
| training/sac_pi/policy_loss    | -232.42845  |
| training/sac_pi/std            | 0.50493366  |
| training/sac_pi/valid_num      | 5018.0      |
| training/sac_Q/q1              | 224.04375   |
| training/sac_Q/q2              | 226.0295    |
| training/sac_Q/q2_loss         | 82.35874    |
| training/sac_Q/q_global_norm   | 334.467     |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16071127   |
| epoch                          | 672          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4951.657     |
| evaluation/return-max          | 5036.553     |
| evaluation/return-min          | 4877.347     |
| evaluation/return-std          | 46.761494    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.11         |
| model/origin_ret               | 85           |
| model/penalty_ret              | 79.1         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46482        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4951.657     |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 225.32938    |
| Q-std                          | 113.61956    |
| Q_loss                         | 94.47297     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 672          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.000124     |
| times/epoch_rollout_model      | 496          |
| times/evaluation_metrics       | 0.000508     |
| times/evaluation_paths         | 39.8         |
| times/timestep_after_hook      | 0.00381      |
| times/timestep_before_hook     | 0.00856      |
| times/train                    | 71.8         |
| timestep                       | 1000         |
| timesteps_total                | 673000       |
| train-steps                    | 673000       |
| training/Q/q1_loss             | 93.61045     |
| training/sac_pi/alpha          | 0.16072187   |
| training/sac_pi/alpha_loss     | -0.024859974 |
| training/sac_pi/logp_pi        | 4.7799377    |
| training/sac_pi/pi_entropy     | 3.3969765    |
| training/sac_pi/pi_global_norm | 2.835147     |
| training/sac_pi/policy_loss    | -227.15787   |
| training/sac_pi/std            | 0.50405085   |
| training/sac_pi/valid_num      | 4944.0       |
| training/sac_Q/q1              | 211.36104    |
| training/sac_Q/q2              | 215.6195     |
| training/sac_Q/q2_loss         | 92.992935    |
| training/sac_Q/q_global_norm   | 232.34073    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16145676  |
| epoch                          | 673         |
| evaluation/episode-length-avg  | 969         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 694         |
| evaluation/episode-length-std  | 91.8        |
| evaluation/return-average      | 4497.377    |
| evaluation/return-max          | 4888.047    |
| evaluation/return-min          | 3123.1777   |
| evaluation/return-std          | 468.66745   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46368       |
| perf/AverageLength             | 969         |
| perf/AverageReturn             | 4497.377    |
| perf/NormalizedReturn          | 0.979       |
| Q-avg                          | 220.42331   |
| Q-std                          | 119.76068   |
| Q_loss                         | 100.66626   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 673         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000301    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000543    |
| times/evaluation_paths         | 34.2        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 62.7        |
| timestep                       | 1000        |
| timesteps_total                | 674000      |
| train-steps                    | 674000      |
| training/Q/q1_loss             | 69.459015   |
| training/sac_pi/alpha          | 0.16145305  |
| training/sac_pi/alpha_loss     | -0.08053481 |
| training/sac_pi/logp_pi        | 3.9554      |
| training/sac_pi/pi_entropy     | 3.1446977   |
| training/sac_pi/pi_global_norm | 1.6577214   |
| training/sac_pi/policy_loss    | -234.73434  |
| training/sac_pi/std            | 0.46354467  |
| training/sac_pi/valid_num      | 5008.0      |
| training/sac_Q/q1              | 224.25638   |
| training/sac_Q/q2              | 226.86128   |
| training/sac_Q/q2_loss         | 67.95746    |
| training/sac_Q/q_global_norm   | 212.86829   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16292925  |
| epoch                          | 674         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5051.5723   |
| evaluation/return-max          | 5132.7715   |
| evaluation/return-min          | 4952.1143   |
| evaluation/return-std          | 50.826584   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 84.2        |
| model/penalty_ret              | 78.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46590       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5051.5723   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 230.52893   |
| Q-std                          | 129.64949   |
| Q_loss                         | 62.539104   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 674         |
| times/epoch_after_hook         | 2.98e-06    |
| times/epoch_before_hook        | 0.00011     |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000607    |
| times/evaluation_paths         | 34.1        |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00829     |
| times/train                    | 61.5        |
| timestep                       | 1000        |
| timesteps_total                | 675000      |
| train-steps                    | 675000      |
| training/Q/q1_loss             | 104.40409   |
| training/sac_pi/alpha          | 0.16291365  |
| training/sac_pi/alpha_loss     | -0.11818359 |
| training/sac_pi/logp_pi        | 4.5858216   |
| training/sac_pi/pi_entropy     | 3.5367432   |
| training/sac_pi/pi_global_norm | 1.9626586   |
| training/sac_pi/policy_loss    | -234.82486  |
| training/sac_pi/std            | 0.52957666  |
| training/sac_pi/valid_num      | 4994.0      |
| training/sac_Q/q1              | 224.35446   |
| training/sac_Q/q2              | 223.96509   |
| training/sac_Q/q2_loss         | 103.95491   |
| training/sac_Q/q_global_norm   | 230.31773   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15964815 |
| epoch                          | 675        |
| evaluation/episode-length-avg  | 973        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 726        |
| evaluation/episode-length-std  | 82.2       |
| evaluation/return-average      | 4915.3706  |
| evaluation/return-max          | 5217.4717  |
| evaluation/return-min          | 3407.951   |
| evaluation/return-std          | 511.6438   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46535      |
| perf/AverageLength             | 973        |
| perf/AverageReturn             | 4915.3706  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 221.68501  |
| Q-std                          | 136.8571   |
| Q_loss                         | 98.61667   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 675        |
| times/epoch_after_hook         | 3.25e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 504        |
| times/evaluation_metrics       | 0.000567   |
| times/evaluation_paths         | 33.6       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 676000     |
| train-steps                    | 676000     |
| training/Q/q1_loss             | 92.57885   |
| training/sac_pi/alpha          | 0.15972482 |
| training/sac_pi/alpha_loss     | -0.5263056 |
| training/sac_pi/logp_pi        | 3.8948016  |
| training/sac_pi/pi_entropy     | 3.3883088  |
| training/sac_pi/pi_global_norm | 1.7130208  |
| training/sac_pi/policy_loss    | -225.72066 |
| training/sac_pi/std            | 0.49881658 |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 212.4854   |
| training/sac_Q/q2              | 217.0167   |
| training/sac_Q/q2_loss         | 92.59512   |
| training/sac_Q/q_global_norm   | 202.8941   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16459744  |
| epoch                          | 676         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5092.14     |
| evaluation/return-max          | 5198.458    |
| evaluation/return-min          | 5019.5693   |
| evaluation/return-std          | 62.37685    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46466       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5092.14     |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 215.11272   |
| Q-std                          | 154.703     |
| Q_loss                         | 102.21138   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 676         |
| times/epoch_after_hook         | 1.59e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000541    |
| times/evaluation_paths         | 35.7        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00838     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 677000      |
| train-steps                    | 677000      |
| training/Q/q1_loss             | 103.79299   |
| training/sac_pi/alpha          | 0.1646357   |
| training/sac_pi/alpha_loss     | -0.24139945 |
| training/sac_pi/logp_pi        | 4.549983    |
| training/sac_pi/pi_entropy     | 3.405281    |
| training/sac_pi/pi_global_norm | 2.0836637   |
| training/sac_pi/policy_loss    | -228.29774  |
| training/sac_pi/std            | 0.5190903   |
| training/sac_pi/valid_num      | 4920.0      |
| training/sac_Q/q1              | 212.67654   |
| training/sac_Q/q2              | 214.22539   |
| training/sac_Q/q2_loss         | 103.92115   |
| training/sac_Q/q_global_norm   | 319.11856   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15998651 |
| epoch                          | 677        |
| evaluation/episode-length-avg  | 898        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 625        |
| evaluation/episode-length-std  | 139        |
| evaluation/return-average      | 4304.3823  |
| evaluation/return-max          | 5173.999   |
| evaluation/return-min          | 2906.8652  |
| evaluation/return-std          | 772.1631   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46435      |
| perf/AverageLength             | 898        |
| perf/AverageReturn             | 4304.3823  |
| perf/NormalizedReturn          | 0.937      |
| Q-avg                          | 211.10649  |
| Q-std                          | 207.3669   |
| Q_loss                         | 83.90921   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 677        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000289   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000604   |
| times/evaluation_paths         | 32.1       |
| times/timestep_after_hook      | 0.00375    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 63.2       |
| timestep                       | 1000       |
| timesteps_total                | 678000     |
| train-steps                    | 678000     |
| training/Q/q1_loss             | 93.87447   |
| training/sac_pi/alpha          | 0.15999839 |
| training/sac_pi/alpha_loss     | -0.4828483 |
| training/sac_pi/logp_pi        | 4.074569   |
| training/sac_pi/pi_entropy     | 3.231723   |
| training/sac_pi/pi_global_norm | 1.8104761  |
| training/sac_pi/policy_loss    | -226.6682  |
| training/sac_pi/std            | 0.47220963 |
| training/sac_pi/valid_num      | 4957.0     |
| training/sac_Q/q1              | 215.94475  |
| training/sac_Q/q2              | 217.06831  |
| training/sac_Q/q2_loss         | 94.864876  |
| training/sac_Q/q_global_norm   | 267.20618  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15595646  |
| epoch                          | 678         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5034.209    |
| evaluation/return-max          | 5128.689    |
| evaluation/return-min          | 4994.4023   |
| evaluation/return-std          | 37.439575   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46360       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5034.209    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 216.01596   |
| Q-std                          | 140.43765   |
| Q_loss                         | 87.32544    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 678         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000604    |
| times/evaluation_paths         | 37.3        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00833     |
| times/train                    | 64.5        |
| timestep                       | 1000        |
| timesteps_total                | 679000      |
| train-steps                    | 679000      |
| training/Q/q1_loss             | 133.32013   |
| training/sac_pi/alpha          | 0.15595405  |
| training/sac_pi/alpha_loss     | -0.05480011 |
| training/sac_pi/logp_pi        | 3.5980086   |
| training/sac_pi/pi_entropy     | 3.2915587   |
| training/sac_pi/pi_global_norm | 1.7035258   |
| training/sac_pi/policy_loss    | -238.38373  |
| training/sac_pi/std            | 0.46383715  |
| training/sac_pi/valid_num      | 5055.0      |
| training/sac_Q/q1              | 232.852     |
| training/sac_Q/q2              | 233.64348   |
| training/sac_Q/q2_loss         | 133.14351   |
| training/sac_Q/q_global_norm   | 210.81438   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.159415   |
| epoch                          | 679        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4903.8975  |
| evaluation/return-max          | 4952.635   |
| evaluation/return-min          | 4829.6504  |
| evaluation/return-std          | 36.25529   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46425      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4903.8975  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 213.73999  |
| Q-std                          | 102.99744  |
| Q_loss                         | 108.88174  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 679        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.00014    |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000572   |
| times/evaluation_paths         | 34.3       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 680000     |
| train-steps                    | 680000     |
| training/Q/q1_loss             | 117.21342  |
| training/sac_pi/alpha          | 0.159419   |
| training/sac_pi/alpha_loss     | 0.36576232 |
| training/sac_pi/logp_pi        | 4.1268215  |
| training/sac_pi/pi_entropy     | 3.2640464  |
| training/sac_pi/pi_global_norm | 1.8848261  |
| training/sac_pi/policy_loss    | -231.49243 |
| training/sac_pi/std            | 0.47567272 |
| training/sac_pi/valid_num      | 5002.0     |
| training/sac_Q/q1              | 224.81128  |
| training/sac_Q/q2              | 224.89546  |
| training/sac_Q/q2_loss         | 116.89124  |
| training/sac_Q/q_global_norm   | 255.34706  |
--------------------------------------------------------------------------------
[WARN] 680 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16308247  |
| epoch                          | 680         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4823.2627   |
| evaluation/return-max          | 4962.7285   |
| evaluation/return-min          | 4755.2046   |
| evaluation/return-std          | 66.19501    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46522       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4823.2627   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 209.54288   |
| Q-std                          | 120.11414   |
| Q_loss                         | 92.91869    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 680         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000217    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000691    |
| times/evaluation_paths         | 36.9        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 61.2        |
| timestep                       | 1000        |
| timesteps_total                | 681000      |
| train-steps                    | 681000      |
| training/Q/q1_loss             | 97.98926    |
| training/sac_pi/alpha          | 0.16311887  |
| training/sac_pi/alpha_loss     | -0.26354182 |
| training/sac_pi/logp_pi        | 3.6910923   |
| training/sac_pi/pi_entropy     | 3.439099    |
| training/sac_pi/pi_global_norm | 1.7523857   |
| training/sac_pi/policy_loss    | -224.43896  |
| training/sac_pi/std            | 0.48769125  |
| training/sac_pi/valid_num      | 5046.0      |
| training/sac_Q/q1              | 216.858     |
| training/sac_Q/q2              | 219.04805   |
| training/sac_Q/q2_loss         | 99.079834   |
| training/sac_Q/q_global_norm   | 206.08862   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1649819  |
| epoch                          | 681        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4987.8604  |
| evaluation/return-max          | 5066.38    |
| evaluation/return-min          | 4944.4336  |
| evaluation/return-std          | 42.122696  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46328      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4987.8604  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 226.80087  |
| Q-std                          | 95.8627    |
| Q_loss                         | 105.57793  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 681        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000282   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000752   |
| times/evaluation_paths         | 36.2       |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 60         |
| timestep                       | 1000       |
| timesteps_total                | 682000     |
| train-steps                    | 682000     |
| training/Q/q1_loss             | 114.821175 |
| training/sac_pi/alpha          | 0.16495733 |
| training/sac_pi/alpha_loss     | 0.6115241  |
| training/sac_pi/logp_pi        | 4.143387   |
| training/sac_pi/pi_entropy     | 3.3782048  |
| training/sac_pi/pi_global_norm | 1.8428514  |
| training/sac_pi/policy_loss    | -222.64668 |
| training/sac_pi/std            | 0.4785433  |
| training/sac_pi/valid_num      | 4970.0     |
| training/sac_Q/q1              | 211.00052  |
| training/sac_Q/q2              | 214.59824  |
| training/sac_Q/q2_loss         | 112.827415 |
| training/sac_Q/q_global_norm   | 276.12183  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17018136  |
| epoch                          | 682         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5031.583    |
| evaluation/return-max          | 5097.028    |
| evaluation/return-min          | 4973.532    |
| evaluation/return-std          | 41.109135   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46384       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5031.583    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 222.66098   |
| Q-std                          | 145.48734   |
| Q_loss                         | 80.5329     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 682         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000201    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000618    |
| times/evaluation_paths         | 36          |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00822     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 683000      |
| train-steps                    | 683000      |
| training/Q/q1_loss             | 112.95178   |
| training/sac_pi/alpha          | 0.17015517  |
| training/sac_pi/alpha_loss     | -0.07014052 |
| training/sac_pi/logp_pi        | 4.1384764   |
| training/sac_pi/pi_entropy     | 3.3505013   |
| training/sac_pi/pi_global_norm | 2.2304788   |
| training/sac_pi/policy_loss    | -225.06078  |
| training/sac_pi/std            | 0.47344795  |
| training/sac_pi/valid_num      | 4992.0      |
| training/sac_Q/q1              | 218.10127   |
| training/sac_Q/q2              | 217.89487   |
| training/sac_Q/q2_loss         | 112.740685  |
| training/sac_Q/q_global_norm   | 302.96448   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1666072   |
| epoch                          | 683         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4863.757    |
| evaluation/return-max          | 4953.4746   |
| evaluation/return-min          | 4733.7056   |
| evaluation/return-std          | 65.63233    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46421       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4863.757    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 215.9605    |
| Q-std                          | 155.3429    |
| Q_loss                         | 103.357285  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 683         |
| times/epoch_after_hook         | 3.37e-06    |
| times/epoch_before_hook        | 0.000107    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000631    |
| times/evaluation_paths         | 34          |
| times/timestep_after_hook      | 0.00354     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 59.8        |
| timestep                       | 1000        |
| timesteps_total                | 684000      |
| train-steps                    | 684000      |
| training/Q/q1_loss             | 103.779144  |
| training/sac_pi/alpha          | 0.16661188  |
| training/sac_pi/alpha_loss     | -0.25584617 |
| training/sac_pi/logp_pi        | 4.248281    |
| training/sac_pi/pi_entropy     | 3.5426338   |
| training/sac_pi/pi_global_norm | 2.2348719   |
| training/sac_pi/policy_loss    | -221.57646  |
| training/sac_pi/std            | 0.5239454   |
| training/sac_pi/valid_num      | 4958.0      |
| training/sac_Q/q1              | 205.83134   |
| training/sac_Q/q2              | 210.7944    |
| training/sac_Q/q2_loss         | 104.73429   |
| training/sac_Q/q_global_norm   | 196.11676   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16457364 |
| epoch                          | 684        |
| evaluation/episode-length-avg  | 971        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 710        |
| evaluation/episode-length-std  | 87         |
| evaluation/return-average      | 4891.0884  |
| evaluation/return-max          | 5119.0625  |
| evaluation/return-min          | 3365.4465  |
| evaluation/return-std          | 509.90146  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46512      |
| perf/AverageLength             | 971        |
| perf/AverageReturn             | 4891.0884  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 223.88644  |
| Q-std                          | 98.69044   |
| Q_loss                         | 98.05359   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 684        |
| times/epoch_after_hook         | 1.61e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000648   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 62.8       |
| timestep                       | 1000       |
| timesteps_total                | 685000     |
| train-steps                    | 685000     |
| training/Q/q1_loss             | 107.657234 |
| training/sac_pi/alpha          | 0.1645729  |
| training/sac_pi/alpha_loss     | 0.2445882  |
| training/sac_pi/logp_pi        | 3.8027916  |
| training/sac_pi/pi_entropy     | 3.3671832  |
| training/sac_pi/pi_global_norm | 1.7084898  |
| training/sac_pi/policy_loss    | -227.06439 |
| training/sac_pi/std            | 0.46852872 |
| training/sac_pi/valid_num      | 5055.0     |
| training/sac_Q/q1              | 220.53256  |
| training/sac_Q/q2              | 221.45378  |
| training/sac_Q/q2_loss         | 111.060684 |
| training/sac_Q/q_global_norm   | 257.5359   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16277167  |
| epoch                          | 685         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5256.668    |
| evaluation/return-max          | 5282.169    |
| evaluation/return-min          | 5181.125    |
| evaluation/return-std          | 28.208256   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 87.2        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46288       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5256.668    |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 217.5563    |
| Q-std                          | 121.9399    |
| Q_loss                         | 117.489235  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 685         |
| times/epoch_after_hook         | 1.63e-06    |
| times/epoch_before_hook        | 0.000284    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000547    |
| times/evaluation_paths         | 35.5        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00843     |
| times/train                    | 60.5        |
| timestep                       | 1000        |
| timesteps_total                | 686000      |
| train-steps                    | 686000      |
| training/Q/q1_loss             | 84.567085   |
| training/sac_pi/alpha          | 0.16281237  |
| training/sac_pi/alpha_loss     | -0.25963312 |
| training/sac_pi/logp_pi        | 4.2167554   |
| training/sac_pi/pi_entropy     | 3.4818923   |
| training/sac_pi/pi_global_norm | 2.2382312   |
| training/sac_pi/policy_loss    | -231.63722  |
| training/sac_pi/std            | 0.49358103  |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 214.70874   |
| training/sac_Q/q2              | 218.62589   |
| training/sac_Q/q2_loss         | 84.603004   |
| training/sac_Q/q_global_norm   | 195.04636   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16262522   |
| epoch                          | 686          |
| evaluation/episode-length-avg  | 904          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 322          |
| evaluation/episode-length-std  | 212          |
| evaluation/return-average      | 4189.9326    |
| evaluation/return-max          | 4821.9976    |
| evaluation/return-min          | 1118.7273    |
| evaluation/return-std          | 1132.7217    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.08         |
| model/origin_ret               | 84.7         |
| model/penalty_ret              | 79.9         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46416        |
| perf/AverageLength             | 904          |
| perf/AverageReturn             | 4189.9326    |
| perf/NormalizedReturn          | 0.912        |
| Q-avg                          | 217.2972     |
| Q-std                          | 135.0941     |
| Q_loss                         | 98.35315     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 686          |
| times/epoch_after_hook         | 1.61e-06     |
| times/epoch_before_hook        | 0.000119     |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.00054      |
| times/evaluation_paths         | 31           |
| times/timestep_after_hook      | 0.00361      |
| times/timestep_before_hook     | 0.00838      |
| times/train                    | 64.5         |
| timestep                       | 1000         |
| timesteps_total                | 687000       |
| train-steps                    | 687000       |
| training/Q/q1_loss             | 89.69111     |
| training/sac_pi/alpha          | 0.16264035   |
| training/sac_pi/alpha_loss     | -0.027466057 |
| training/sac_pi/logp_pi        | 4.325921     |
| training/sac_pi/pi_entropy     | 3.1864285    |
| training/sac_pi/pi_global_norm | 1.5855138    |
| training/sac_pi/policy_loss    | -234.93825   |
| training/sac_pi/std            | 0.4570243    |
| training/sac_pi/valid_num      | 4955.0       |
| training/sac_Q/q1              | 218.10742    |
| training/sac_Q/q2              | 222.32353    |
| training/sac_Q/q2_loss         | 89.458694    |
| training/sac_Q/q_global_norm   | 219.64787    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16355184  |
| epoch                          | 687         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5249.616    |
| evaluation/return-max          | 5309.1416   |
| evaluation/return-min          | 5218.3457   |
| evaluation/return-std          | 26.043953   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 80.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46478       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5249.616    |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 213.42883   |
| Q-std                          | 118.03503   |
| Q_loss                         | 112.834274  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 687         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000119    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.00067     |
| times/evaluation_paths         | 40.1        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00841     |
| times/train                    | 65.2        |
| timestep                       | 1000        |
| timesteps_total                | 688000      |
| train-steps                    | 688000      |
| training/Q/q1_loss             | 114.7053    |
| training/sac_pi/alpha          | 0.16355288  |
| training/sac_pi/alpha_loss     | -0.26547712 |
| training/sac_pi/logp_pi        | 4.023294    |
| training/sac_pi/pi_entropy     | 3.4961548   |
| training/sac_pi/pi_global_norm | 1.6353514   |
| training/sac_pi/policy_loss    | -225.17154  |
| training/sac_pi/std            | 0.49974605  |
| training/sac_pi/valid_num      | 4955.0      |
| training/sac_Q/q1              | 214.44234   |
| training/sac_Q/q2              | 216.6128    |
| training/sac_Q/q2_loss         | 115.27545   |
| training/sac_Q/q_global_norm   | 219.66786   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16224949 |
| epoch                          | 688        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4876.583   |
| evaluation/return-max          | 5014.6406  |
| evaluation/return-min          | 4690.508   |
| evaluation/return-std          | 82.002785  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46456      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4876.583   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 204.68776  |
| Q-std                          | 165.00162  |
| Q_loss                         | 112.03513  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 688        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000166   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000661   |
| times/evaluation_paths         | 37.8       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00856    |
| times/train                    | 67.7       |
| timestep                       | 1000       |
| timesteps_total                | 689000     |
| train-steps                    | 689000     |
| training/Q/q1_loss             | 91.577705  |
| training/sac_pi/alpha          | 0.16224883 |
| training/sac_pi/alpha_loss     | 0.13233869 |
| training/sac_pi/logp_pi        | 4.5071883  |
| training/sac_pi/pi_entropy     | 3.1958208  |
| training/sac_pi/pi_global_norm | 2.043417   |
| training/sac_pi/policy_loss    | -229.03053 |
| training/sac_pi/std            | 0.48042864 |
| training/sac_pi/valid_num      | 5003.0     |
| training/sac_Q/q1              | 219.56404  |
| training/sac_Q/q2              | 222.1005   |
| training/sac_Q/q2_loss         | 92.336105  |
| training/sac_Q/q_global_norm   | 255.00233  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16558003  |
| epoch                          | 689         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4900.313    |
| evaluation/return-max          | 4945.962    |
| evaluation/return-min          | 4785.776    |
| evaluation/return-std          | 41.672745   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46398       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4900.313    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 216.38791   |
| Q-std                          | 140.91074   |
| Q_loss                         | 128.61716   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 689         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000351    |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000601    |
| times/evaluation_paths         | 42.4        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00832     |
| times/train                    | 68.3        |
| timestep                       | 1000        |
| timesteps_total                | 690000      |
| train-steps                    | 690000      |
| training/Q/q1_loss             | 92.92469    |
| training/sac_pi/alpha          | 0.16558674  |
| training/sac_pi/alpha_loss     | 0.005965886 |
| training/sac_pi/logp_pi        | 4.366008    |
| training/sac_pi/pi_entropy     | 3.3944328   |
| training/sac_pi/pi_global_norm | 1.8126273   |
| training/sac_pi/policy_loss    | -228.2681   |
| training/sac_pi/std            | 0.48724887  |
| training/sac_pi/valid_num      | 4931.0      |
| training/sac_Q/q1              | 213.05986   |
| training/sac_Q/q2              | 217.51791   |
| training/sac_Q/q2_loss         | 93.32666    |
| training/sac_Q/q_global_norm   | 282.88547   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16367507   |
| epoch                          | 690          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5109.744     |
| evaluation/return-max          | 5174.4316    |
| evaluation/return-min          | 5042.877     |
| evaluation/return-std          | 39.34045     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.11         |
| model/origin_ret               | 86           |
| model/penalty_ret              | 79.4         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46371        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5109.744     |
| perf/NormalizedReturn          | 1.11         |
| Q-avg                          | 216.21855    |
| Q-std                          | 125.7218     |
| Q_loss                         | 92.6802      |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 690          |
| times/epoch_after_hook         | 1.9e-06      |
| times/epoch_before_hook        | 0.000146     |
| times/epoch_rollout_model      | 496          |
| times/evaluation_metrics       | 0.000758     |
| times/evaluation_paths         | 42.6         |
| times/timestep_after_hook      | 0.00389      |
| times/timestep_before_hook     | 0.00859      |
| times/train                    | 73.7         |
| timestep                       | 1000         |
| timesteps_total                | 691000       |
| train-steps                    | 691000       |
| training/Q/q1_loss             | 87.303856    |
| training/sac_pi/alpha          | 0.16366991   |
| training/sac_pi/alpha_loss     | -0.016829407 |
| training/sac_pi/logp_pi        | 3.6706605    |
| training/sac_pi/pi_entropy     | 3.2322516    |
| training/sac_pi/pi_global_norm | 1.8152276    |
| training/sac_pi/policy_loss    | -230.82977   |
| training/sac_pi/std            | 0.45351502   |
| training/sac_pi/valid_num      | 5041.0       |
| training/sac_Q/q1              | 224.94202    |
| training/sac_Q/q2              | 225.75471    |
| training/sac_Q/q2_loss         | 87.01314     |
| training/sac_Q/q_global_norm   | 263.74335    |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15974675   |
| epoch                          | 691          |
| evaluation/episode-length-avg  | 312          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 132          |
| evaluation/episode-length-std  | 344          |
| evaluation/return-average      | 1362.258     |
| evaluation/return-max          | 5346.4873    |
| evaluation/return-min          | 344.08936    |
| evaluation/return-std          | 1990.4006    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.16         |
| model/origin_ret               | 86.7         |
| model/penalty_ret              | 79.3         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46505        |
| perf/AverageLength             | 312          |
| perf/AverageReturn             | 1362.258     |
| perf/NormalizedReturn          | 0.296        |
| Q-avg                          | 217.48181    |
| Q-std                          | 110.14939    |
| Q_loss                         | 95.37582     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 691          |
| times/epoch_after_hook         | 1.62e-06     |
| times/epoch_before_hook        | 0.00014      |
| times/epoch_rollout_model      | 502          |
| times/evaluation_metrics       | 0.000451     |
| times/evaluation_paths         | 14.1         |
| times/timestep_after_hook      | 0.00371      |
| times/timestep_before_hook     | 0.00851      |
| times/train                    | 72.2         |
| timestep                       | 1000         |
| timesteps_total                | 692000       |
| train-steps                    | 692000       |
| training/Q/q1_loss             | 102.118576   |
| training/sac_pi/alpha          | 0.15973428   |
| training/sac_pi/alpha_loss     | -0.028267765 |
| training/sac_pi/logp_pi        | 3.4994903    |
| training/sac_pi/pi_entropy     | 3.45511      |
| training/sac_pi/pi_global_norm | 1.6310279    |
| training/sac_pi/policy_loss    | -226.93242   |
| training/sac_pi/std            | 0.47913128   |
| training/sac_pi/valid_num      | 4962.0       |
| training/sac_Q/q1              | 218.31876    |
| training/sac_Q/q2              | 219.47592    |
| training/sac_Q/q2_loss         | 104.4147     |
| training/sac_Q/q_global_norm   | 182.88223    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15613505 |
| epoch                          | 692        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4883.2056  |
| evaluation/return-max          | 4930.038   |
| evaluation/return-min          | 4850.3633  |
| evaluation/return-std          | 27.996576  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 87         |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46386      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4883.2056  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 212.01346  |
| Q-std                          | 125.90225  |
| Q_loss                         | 100.66636  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 692        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 9.61e-05   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000667   |
| times/evaluation_paths         | 39.9       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00849    |
| times/train                    | 70.8       |
| timestep                       | 1000       |
| timesteps_total                | 693000     |
| train-steps                    | 693000     |
| training/Q/q1_loss             | 86.68838   |
| training/sac_pi/alpha          | 0.15616207 |
| training/sac_pi/alpha_loss     | -0.3160794 |
| training/sac_pi/logp_pi        | 4.6150613  |
| training/sac_pi/pi_entropy     | 3.5559528  |
| training/sac_pi/pi_global_norm | 1.3258986  |
| training/sac_pi/policy_loss    | -222.73705 |
| training/sac_pi/std            | 0.54061985 |
| training/sac_pi/valid_num      | 4910.0     |
| training/sac_Q/q1              | 201.94986  |
| training/sac_Q/q2              | 203.48196  |
| training/sac_Q/q2_loss         | 86.21633   |
| training/sac_Q/q_global_norm   | 181.52563  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16417418  |
| epoch                          | 693         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4962.649    |
| evaluation/return-max          | 5053.551    |
| evaluation/return-min          | 4821.4277   |
| evaluation/return-std          | 61.291565   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46573       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4962.649    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 211.92883   |
| Q-std                          | 169.81993   |
| Q_loss                         | 103.18289   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 693         |
| times/epoch_after_hook         | 2e-06       |
| times/epoch_before_hook        | 0.000287    |
| times/epoch_rollout_model      | 492         |
| times/evaluation_metrics       | 0.000577    |
| times/evaluation_paths         | 39.8        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00834     |
| times/train                    | 70.6        |
| timestep                       | 1000        |
| timesteps_total                | 694000      |
| train-steps                    | 694000      |
| training/Q/q1_loss             | 83.25601    |
| training/sac_pi/alpha          | 0.16415684  |
| training/sac_pi/alpha_loss     | -0.08330649 |
| training/sac_pi/logp_pi        | 3.4229934   |
| training/sac_pi/pi_entropy     | 3.3802853   |
| training/sac_pi/pi_global_norm | 1.6445248   |
| training/sac_pi/policy_loss    | -234.78168  |
| training/sac_pi/std            | 0.46464294  |
| training/sac_pi/valid_num      | 4999.0      |
| training/sac_Q/q1              | 229.22208   |
| training/sac_Q/q2              | 229.00703   |
| training/sac_Q/q2_loss         | 83.24427    |
| training/sac_Q/q_global_norm   | 175.89963   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16247715  |
| epoch                          | 694         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4880.218    |
| evaluation/return-max          | 4984.041    |
| evaluation/return-min          | 4825.857    |
| evaluation/return-std          | 50.65951    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46528       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4880.218    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 228.05449   |
| Q-std                          | 131.80904   |
| Q_loss                         | 81.89384    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 694         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.000608    |
| times/evaluation_paths         | 41          |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 67.9        |
| timestep                       | 1000        |
| timesteps_total                | 695000      |
| train-steps                    | 695000      |
| training/Q/q1_loss             | 103.9235    |
| training/sac_pi/alpha          | 0.1625062   |
| training/sac_pi/alpha_loss     | -0.27475533 |
| training/sac_pi/logp_pi        | 4.1248155   |
| training/sac_pi/pi_entropy     | 3.457377    |
| training/sac_pi/pi_global_norm | 1.5737753   |
| training/sac_pi/policy_loss    | -220.34589  |
| training/sac_pi/std            | 0.51088697  |
| training/sac_pi/valid_num      | 4959.0      |
| training/sac_Q/q1              | 210.84229   |
| training/sac_Q/q2              | 210.81216   |
| training/sac_Q/q2_loss         | 103.23738   |
| training/sac_Q/q_global_norm   | 275.86432   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17017588  |
| epoch                          | 695         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5201.2876   |
| evaluation/return-max          | 5248.8525   |
| evaluation/return-min          | 5128.266    |
| evaluation/return-std          | 34.146233   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46535       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5201.2876   |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 224.00359   |
| Q-std                          | 144.63538   |
| Q_loss                         | 91.08232    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 695         |
| times/epoch_after_hook         | 1.97e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000607    |
| times/evaluation_paths         | 40.3        |
| times/timestep_after_hook      | 0.00388     |
| times/timestep_before_hook     | 0.00838     |
| times/train                    | 72.6        |
| timestep                       | 1000        |
| timesteps_total                | 696000      |
| train-steps                    | 696000      |
| training/Q/q1_loss             | 99.14897    |
| training/sac_pi/alpha          | 0.17018737  |
| training/sac_pi/alpha_loss     | -0.14306349 |
| training/sac_pi/logp_pi        | 3.9665375   |
| training/sac_pi/pi_entropy     | 3.51305     |
| training/sac_pi/pi_global_norm | 1.7095749   |
| training/sac_pi/policy_loss    | -230.51411  |
| training/sac_pi/std            | 0.5154198   |
| training/sac_pi/valid_num      | 4933.0      |
| training/sac_Q/q1              | 218.51575   |
| training/sac_Q/q2              | 220.71677   |
| training/sac_Q/q2_loss         | 98.11126    |
| training/sac_Q/q_global_norm   | 215.3848    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16570982  |
| epoch                          | 696         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4832.464    |
| evaluation/return-max          | 4971.6494   |
| evaluation/return-min          | 4730.1826   |
| evaluation/return-std          | 73.83086    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46531       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4832.464    |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 208.08194   |
| Q-std                          | 161.79291   |
| Q_loss                         | 103.244995  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 696         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000144    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000715    |
| times/evaluation_paths         | 43.2        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 67.8        |
| timestep                       | 1000        |
| timesteps_total                | 697000      |
| train-steps                    | 697000      |
| training/Q/q1_loss             | 108.95175   |
| training/sac_pi/alpha          | 0.16570282  |
| training/sac_pi/alpha_loss     | 0.037542928 |
| training/sac_pi/logp_pi        | 5.206159    |
| training/sac_pi/pi_entropy     | 3.5748754   |
| training/sac_pi/pi_global_norm | 1.7969016   |
| training/sac_pi/policy_loss    | -222.86937  |
| training/sac_pi/std            | 0.56151813  |
| training/sac_pi/valid_num      | 4930.0      |
| training/sac_Q/q1              | 203.10257   |
| training/sac_Q/q2              | 208.5726    |
| training/sac_Q/q2_loss         | 106.78403   |
| training/sac_Q/q_global_norm   | 239.02446   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.167193   |
| epoch                          | 697        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5098.272   |
| evaluation/return-max          | 5122.7773  |
| evaluation/return-min          | 5062.7     |
| evaluation/return-std          | 17.244087  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46353      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5098.272   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 221.61069  |
| Q-std                          | 134.98938  |
| Q_loss                         | 81.685486  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 697        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000313   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000637   |
| times/evaluation_paths         | 41.9       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 67.9       |
| timestep                       | 1000       |
| timesteps_total                | 698000     |
| train-steps                    | 698000     |
| training/Q/q1_loss             | 115.38325  |
| training/sac_pi/alpha          | 0.16718471 |
| training/sac_pi/alpha_loss     | 0.4886138  |
| training/sac_pi/logp_pi        | 4.207554   |
| training/sac_pi/pi_entropy     | 3.3497958  |
| training/sac_pi/pi_global_norm | 1.6892291  |
| training/sac_pi/policy_loss    | -226.48514 |
| training/sac_pi/std            | 0.47511306 |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 216.24825  |
| training/sac_Q/q2              | 218.55424  |
| training/sac_Q/q2_loss         | 114.835236 |
| training/sac_Q/q_global_norm   | 219.64604  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16013597  |
| epoch                          | 698         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4678.2563   |
| evaluation/return-max          | 4868.865    |
| evaluation/return-min          | 4531.014    |
| evaluation/return-std          | 93.48907    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 78.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46165       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4678.2563   |
| perf/NormalizedReturn          | 1.02        |
| Q-avg                          | 213.52888   |
| Q-std                          | 130.17047   |
| Q_loss                         | 86.76646    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 698         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000141    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.00078     |
| times/evaluation_paths         | 40.4        |
| times/timestep_after_hook      | 0.00389     |
| times/timestep_before_hook     | 0.00856     |
| times/train                    | 70.1        |
| timestep                       | 1000        |
| timesteps_total                | 699000      |
| train-steps                    | 699000      |
| training/Q/q1_loss             | 105.01179   |
| training/sac_pi/alpha          | 0.16015477  |
| training/sac_pi/alpha_loss     | -0.34926406 |
| training/sac_pi/logp_pi        | 4.112635    |
| training/sac_pi/pi_entropy     | 3.3955162   |
| training/sac_pi/pi_global_norm | 1.7278247   |
| training/sac_pi/policy_loss    | -216.5085   |
| training/sac_pi/std            | 0.49821517  |
| training/sac_pi/valid_num      | 4942.0      |
| training/sac_Q/q1              | 199.59178   |
| training/sac_Q/q2              | 201.10283   |
| training/sac_Q/q2_loss         | 106.8072    |
| training/sac_Q/q_global_norm   | 230.22758   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1576459    |
| epoch                          | 699          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5132.5835    |
| evaluation/return-max          | 5175.047     |
| evaluation/return-min          | 4978.4995    |
| evaluation/return-std          | 56.54254     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.1          |
| model/origin_ret               | 85.4         |
| model/penalty_ret              | 78.9         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46441        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5132.5835    |
| perf/NormalizedReturn          | 1.12         |
| Q-avg                          | 217.33952    |
| Q-std                          | 129.66351    |
| Q_loss                         | 100.0758     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 699          |
| times/epoch_after_hook         | 3.18e-06     |
| times/epoch_before_hook        | 0.000187     |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.000622     |
| times/evaluation_paths         | 39.3         |
| times/timestep_after_hook      | 0.0037       |
| times/timestep_before_hook     | 0.00836      |
| times/train                    | 69.1         |
| timestep                       | 1000         |
| timesteps_total                | 700000       |
| train-steps                    | 700000       |
| training/Q/q1_loss             | 116.04065    |
| training/sac_pi/alpha          | 0.15765105   |
| training/sac_pi/alpha_loss     | -0.042036816 |
| training/sac_pi/logp_pi        | 3.8348644    |
| training/sac_pi/pi_entropy     | 3.2717369    |
| training/sac_pi/pi_global_norm | 2.0270672    |
| training/sac_pi/policy_loss    | -228.79634   |
| training/sac_pi/std            | 0.46342522   |
| training/sac_pi/valid_num      | 5009.0       |
| training/sac_Q/q1              | 220.85376    |
| training/sac_Q/q2              | 220.57175    |
| training/sac_Q/q2_loss         | 117.347824   |
| training/sac_Q/q_global_norm   | 425.14792    |
----------------------------------------------------------------------------------
[WARN] 700 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.15848829  |
| epoch                          | 700         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4958.25     |
| evaluation/return-max          | 5001.358    |
| evaluation/return-min          | 4884.6875   |
| evaluation/return-std          | 38.127655   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46557       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4958.25     |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 221.72119   |
| Q-std                          | 160.47937   |
| Q_loss                         | 98.69409    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 700         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000163    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000588    |
| times/evaluation_paths         | 45          |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.0086      |
| times/train                    | 69.3        |
| timestep                       | 1000        |
| timesteps_total                | 701000      |
| train-steps                    | 701000      |
| training/Q/q1_loss             | 106.107216  |
| training/sac_pi/alpha          | 0.15845488  |
| training/sac_pi/alpha_loss     | 0.124025926 |
| training/sac_pi/logp_pi        | 3.9080405   |
| training/sac_pi/pi_entropy     | 3.2588317   |
| training/sac_pi/pi_global_norm | 1.6821975   |
| training/sac_pi/policy_loss    | -225.97922  |
| training/sac_pi/std            | 0.46845457  |
| training/sac_pi/valid_num      | 4979.0      |
| training/sac_Q/q1              | 216.37651   |
| training/sac_Q/q2              | 218.83662   |
| training/sac_Q/q2_loss         | 107.294876  |
| training/sac_Q/q_global_norm   | 236.61633   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16133016 |
| epoch                          | 701        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4940.9136  |
| evaluation/return-max          | 5027.7275  |
| evaluation/return-min          | 4878.6147  |
| evaluation/return-std          | 35.163643  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46571      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4940.9136  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 219.5988   |
| Q-std                          | 113.045296 |
| Q_loss                         | 90.275826  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 701        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000455   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000622   |
| times/evaluation_paths         | 41.8       |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00846    |
| times/train                    | 67.3       |
| timestep                       | 1000       |
| timesteps_total                | 702000     |
| train-steps                    | 702000     |
| training/Q/q1_loss             | 89.68077   |
| training/sac_pi/alpha          | 0.16134693 |
| training/sac_pi/alpha_loss     | -0.4523765 |
| training/sac_pi/logp_pi        | 3.5798259  |
| training/sac_pi/pi_entropy     | 3.4354522  |
| training/sac_pi/pi_global_norm | 1.8463229  |
| training/sac_pi/policy_loss    | -232.35626 |
| training/sac_pi/std            | 0.48350683 |
| training/sac_pi/valid_num      | 4997.0     |
| training/sac_Q/q1              | 222.94868  |
| training/sac_Q/q2              | 223.70549  |
| training/sac_Q/q2_loss         | 89.33926   |
| training/sac_Q/q_global_norm   | 197.30045  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16113752 |
| epoch                          | 702        |
| evaluation/episode-length-avg  | 911        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 651        |
| evaluation/episode-length-std  | 124        |
| evaluation/return-average      | 4536.458   |
| evaluation/return-max          | 5109.9414  |
| evaluation/return-min          | 3134.8376  |
| evaluation/return-std          | 662.61273  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46601      |
| perf/AverageLength             | 911        |
| perf/AverageReturn             | 4536.458   |
| perf/NormalizedReturn          | 0.988      |
| Q-avg                          | 221.69064  |
| Q-std                          | 124.06142  |
| Q_loss                         | 87.02478   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 702        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000139   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000812   |
| times/evaluation_paths         | 39.2       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00857    |
| times/train                    | 72.6       |
| timestep                       | 1000       |
| timesteps_total                | 703000     |
| train-steps                    | 703000     |
| training/Q/q1_loss             | 78.37833   |
| training/sac_pi/alpha          | 0.16112147 |
| training/sac_pi/alpha_loss     | 0.17114371 |
| training/sac_pi/logp_pi        | 4.245316   |
| training/sac_pi/pi_entropy     | 3.41008    |
| training/sac_pi/pi_global_norm | 1.7959797  |
| training/sac_pi/policy_loss    | -223.4288  |
| training/sac_pi/std            | 0.50538516 |
| training/sac_pi/valid_num      | 4976.0     |
| training/sac_Q/q1              | 207.49918  |
| training/sac_Q/q2              | 209.40923  |
| training/sac_Q/q2_loss         | 77.88687   |
| training/sac_Q/q_global_norm   | 282.6379   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16770928 |
| epoch                          | 703        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5165.2095  |
| evaluation/return-max          | 5213.5913  |
| evaluation/return-min          | 5144.1733  |
| evaluation/return-std          | 20.503887  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46622      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5165.2095  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 219.1556   |
| Q-std                          | 128.43188  |
| Q_loss                         | 103.70745  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 703        |
| times/epoch_after_hook         | 1.62e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000674   |
| times/evaluation_paths         | 38.8       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00842    |
| times/train                    | 65.6       |
| timestep                       | 1000       |
| timesteps_total                | 704000     |
| train-steps                    | 704000     |
| training/Q/q1_loss             | 105.52925  |
| training/sac_pi/alpha          | 0.16772397 |
| training/sac_pi/alpha_loss     | 0.38670227 |
| training/sac_pi/logp_pi        | 4.692685   |
| training/sac_pi/pi_entropy     | 3.4904346  |
| training/sac_pi/pi_global_norm | 1.3589877  |
| training/sac_pi/policy_loss    | -229.18007 |
| training/sac_pi/std            | 0.50310117 |
| training/sac_pi/valid_num      | 5009.0     |
| training/sac_Q/q1              | 219.25525  |
| training/sac_Q/q2              | 221.90169  |
| training/sac_Q/q2_loss         | 105.88119  |
| training/sac_Q/q_global_norm   | 198.53372  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16515517  |
| epoch                          | 704         |
| evaluation/episode-length-avg  | 978         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 776         |
| evaluation/episode-length-std  | 67.2        |
| evaluation/return-average      | 4642.644    |
| evaluation/return-max          | 4853.4365   |
| evaluation/return-min          | 3631.1643   |
| evaluation/return-std          | 341.31848   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86.8        |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46371       |
| perf/AverageLength             | 978         |
| perf/AverageReturn             | 4642.644    |
| perf/NormalizedReturn          | 1.01        |
| Q-avg                          | 225.52994   |
| Q-std                          | 119.65205   |
| Q_loss                         | 102.47141   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 704         |
| times/epoch_after_hook         | 1.66e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 519         |
| times/evaluation_metrics       | 0.000611    |
| times/evaluation_paths         | 41          |
| times/timestep_after_hook      | 0.00378     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 72.5        |
| timestep                       | 1000        |
| timesteps_total                | 705000      |
| train-steps                    | 705000      |
| training/Q/q1_loss             | 77.44594    |
| training/sac_pi/alpha          | 0.16514197  |
| training/sac_pi/alpha_loss     | 0.034268055 |
| training/sac_pi/logp_pi        | 3.5531418   |
| training/sac_pi/pi_entropy     | 3.5729184   |
| training/sac_pi/pi_global_norm | 1.8078996   |
| training/sac_pi/policy_loss    | -227.6412   |
| training/sac_pi/std            | 0.4812593   |
| training/sac_pi/valid_num      | 5029.0      |
| training/sac_Q/q1              | 222.9064    |
| training/sac_Q/q2              | 223.32312   |
| training/sac_Q/q2_loss         | 77.9142     |
| training/sac_Q/q_global_norm   | 185.42978   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15893443  |
| epoch                          | 705         |
| evaluation/episode-length-avg  | 967         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 673         |
| evaluation/episode-length-std  | 98.1        |
| evaluation/return-average      | 4935.118    |
| evaluation/return-max          | 5213.665    |
| evaluation/return-min          | 3233.0476   |
| evaluation/return-std          | 570.1837    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46352       |
| perf/AverageLength             | 967         |
| perf/AverageReturn             | 4935.118    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 203.94064   |
| Q-std                          | 195.06758   |
| Q_loss                         | 105.33313   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 705         |
| times/epoch_after_hook         | 1.93e-06    |
| times/epoch_before_hook        | 0.000318    |
| times/epoch_rollout_model      | 490         |
| times/evaluation_metrics       | 0.00076     |
| times/evaluation_paths         | 42.4        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 70.4        |
| timestep                       | 1000        |
| timesteps_total                | 706000      |
| train-steps                    | 706000      |
| training/Q/q1_loss             | 95.01075    |
| training/sac_pi/alpha          | 0.15894291  |
| training/sac_pi/alpha_loss     | 0.004306488 |
| training/sac_pi/logp_pi        | 4.088708    |
| training/sac_pi/pi_entropy     | 3.3158982   |
| training/sac_pi/pi_global_norm | 1.6018251   |
| training/sac_pi/policy_loss    | -227.29652  |
| training/sac_pi/std            | 0.48656747  |
| training/sac_pi/valid_num      | 4939.0      |
| training/sac_Q/q1              | 215.04916   |
| training/sac_Q/q2              | 216.14859   |
| training/sac_Q/q2_loss         | 95.78092    |
| training/sac_Q/q_global_norm   | 207.2458    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15400006 |
| epoch                          | 706        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4974.377   |
| evaluation/return-max          | 5144.7275  |
| evaluation/return-min          | 4896.25    |
| evaluation/return-std          | 79.47133   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46538      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4974.377   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 225.22017  |
| Q-std                          | 139.06511  |
| Q_loss                         | 87.70526   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 706        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000166   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000552   |
| times/evaluation_paths         | 36.3       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00846    |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 707000     |
| train-steps                    | 707000     |
| training/Q/q1_loss             | 73.36139   |
| training/sac_pi/alpha          | 0.15398854 |
| training/sac_pi/alpha_loss     | 0.13881098 |
| training/sac_pi/logp_pi        | 3.835439   |
| training/sac_pi/pi_entropy     | 3.1868432  |
| training/sac_pi/pi_global_norm | 1.8576728  |
| training/sac_pi/policy_loss    | -231.27048 |
| training/sac_pi/std            | 0.47143823 |
| training/sac_pi/valid_num      | 4987.0     |
| training/sac_Q/q1              | 222.93999  |
| training/sac_Q/q2              | 225.41821  |
| training/sac_Q/q2_loss         | 71.81839   |
| training/sac_Q/q_global_norm   | 303.50314  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15902221 |
| epoch                          | 707        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4822.8706  |
| evaluation/return-max          | 4940.1484  |
| evaluation/return-min          | 4707.1646  |
| evaluation/return-std          | 64.13218   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46372      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4822.8706  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 204.47295  |
| Q-std                          | 163.03104  |
| Q_loss                         | 96.6695    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 707        |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000687   |
| times/evaluation_paths         | 43.1       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 72.8       |
| timestep                       | 1000       |
| timesteps_total                | 708000     |
| train-steps                    | 708000     |
| training/Q/q1_loss             | 105.54331  |
| training/sac_pi/alpha          | 0.1590199  |
| training/sac_pi/alpha_loss     | 0.26885253 |
| training/sac_pi/logp_pi        | 4.06523    |
| training/sac_pi/pi_entropy     | 3.3436108  |
| training/sac_pi/pi_global_norm | 2.4503002  |
| training/sac_pi/policy_loss    | -227.92932 |
| training/sac_pi/std            | 0.4787718  |
| training/sac_pi/valid_num      | 4986.0     |
| training/sac_Q/q1              | 216.62344  |
| training/sac_Q/q2              | 219.77156  |
| training/sac_Q/q2_loss         | 105.21483  |
| training/sac_Q/q_global_norm   | 201.36554  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16173531 |
| epoch                          | 708        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5014.0674  |
| evaluation/return-max          | 5037.146   |
| evaluation/return-min          | 4987.901   |
| evaluation/return-std          | 17.642323  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46344      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5014.0674  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 214.47702  |
| Q-std                          | 121.889046 |
| Q_loss                         | 96.64818   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 708        |
| times/epoch_after_hook         | 3.39e-06   |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000827   |
| times/evaluation_paths         | 40.5       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00854    |
| times/train                    | 70         |
| timestep                       | 1000       |
| timesteps_total                | 709000     |
| train-steps                    | 709000     |
| training/Q/q1_loss             | 95.78109   |
| training/sac_pi/alpha          | 0.16172262 |
| training/sac_pi/alpha_loss     | -0.2057864 |
| training/sac_pi/logp_pi        | 4.6557794  |
| training/sac_pi/pi_entropy     | 3.3417916  |
| training/sac_pi/pi_global_norm | 2.2546787  |
| training/sac_pi/policy_loss    | -231.0778  |
| training/sac_pi/std            | 0.49691936 |
| training/sac_pi/valid_num      | 4947.0     |
| training/sac_Q/q1              | 214.87192  |
| training/sac_Q/q2              | 218.0391   |
| training/sac_Q/q2_loss         | 96.60917   |
| training/sac_Q/q_global_norm   | 240.0309   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15827273 |
| epoch                          | 709        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4992.961   |
| evaluation/return-max          | 5149.88    |
| evaluation/return-min          | 4884.1543  |
| evaluation/return-std          | 87.87415   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46418      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4992.961   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 226.07878  |
| Q-std                          | 115.36498  |
| Q_loss                         | 87.969696  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 709        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000331   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000727   |
| times/evaluation_paths         | 42.3       |
| times/timestep_after_hook      | 0.0039     |
| times/timestep_before_hook     | 0.00842    |
| times/train                    | 70         |
| timestep                       | 1000       |
| timesteps_total                | 710000     |
| train-steps                    | 710000     |
| training/Q/q1_loss             | 100.95367  |
| training/sac_pi/alpha          | 0.1582903  |
| training/sac_pi/alpha_loss     | -0.0724454 |
| training/sac_pi/logp_pi        | 4.63242    |
| training/sac_pi/pi_entropy     | 3.4261947  |
| training/sac_pi/pi_global_norm | 1.8044932  |
| training/sac_pi/policy_loss    | -230.93321 |
| training/sac_pi/std            | 0.5158719  |
| training/sac_pi/valid_num      | 4984.0     |
| training/sac_Q/q1              | 220.47192  |
| training/sac_Q/q2              | 220.22774  |
| training/sac_Q/q2_loss         | 102.352745 |
| training/sac_Q/q_global_norm   | 208.00757  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15940662 |
| epoch                          | 710        |
| evaluation/episode-length-avg  | 962        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 618        |
| evaluation/episode-length-std  | 115        |
| evaluation/return-average      | 4778.6455  |
| evaluation/return-max          | 5135.2793  |
| evaluation/return-min          | 2834.567   |
| evaluation/return-std          | 658.64777  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46394      |
| perf/AverageLength             | 962        |
| perf/AverageReturn             | 4778.6455  |
| perf/NormalizedReturn          | 1.04       |
| Q-avg                          | 223.45361  |
| Q-std                          | 150.51233  |
| Q_loss                         | 107.082664 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 710        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000564   |
| times/evaluation_paths         | 40.8       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 68.7       |
| timestep                       | 1000       |
| timesteps_total                | 711000     |
| train-steps                    | 711000     |
| training/Q/q1_loss             | 129.30203  |
| training/sac_pi/alpha          | 0.15940638 |
| training/sac_pi/alpha_loss     | 0.4433787  |
| training/sac_pi/logp_pi        | 4.9104967  |
| training/sac_pi/pi_entropy     | 3.4169984  |
| training/sac_pi/pi_global_norm | 2.1746738  |
| training/sac_pi/policy_loss    | -223.13902 |
| training/sac_pi/std            | 0.5012365  |
| training/sac_pi/valid_num      | 4956.0     |
| training/sac_Q/q1              | 203.40198  |
| training/sac_Q/q2              | 205.85986  |
| training/sac_Q/q2_loss         | 128.96083  |
| training/sac_Q/q_global_norm   | 411.99655  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1642509  |
| epoch                          | 711        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4998.0713  |
| evaluation/return-max          | 5017.493   |
| evaluation/return-min          | 4971.733   |
| evaluation/return-std          | 12.719076  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46348      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4998.0713  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 212.1417   |
| Q-std                          | 165.46465  |
| Q_loss                         | 95.08406   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 711        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.00014    |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000655   |
| times/evaluation_paths         | 42.2       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00857    |
| times/train                    | 71.1       |
| timestep                       | 1000       |
| timesteps_total                | 712000     |
| train-steps                    | 712000     |
| training/Q/q1_loss             | 123.80437  |
| training/sac_pi/alpha          | 0.1642588  |
| training/sac_pi/alpha_loss     | 0.38123885 |
| training/sac_pi/logp_pi        | 4.6642494  |
| training/sac_pi/pi_entropy     | 3.3580222  |
| training/sac_pi/pi_global_norm | 1.7810909  |
| training/sac_pi/policy_loss    | -230.47957 |
| training/sac_pi/std            | 0.49227765 |
| training/sac_pi/valid_num      | 4980.0     |
| training/sac_Q/q1              | 214.75308  |
| training/sac_Q/q2              | 218.1397   |
| training/sac_Q/q2_loss         | 123.25348  |
| training/sac_Q/q_global_norm   | 284.77188  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16330718  |
| epoch                          | 712         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5077.25     |
| evaluation/return-max          | 5121.408    |
| evaluation/return-min          | 5024.4062   |
| evaluation/return-std          | 31.155392   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46469       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5077.25     |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 213.62296   |
| Q-std                          | 184.84825   |
| Q_loss                         | 94.550766   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 712         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000591    |
| times/evaluation_paths         | 44.4        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 71.7        |
| timestep                       | 1000        |
| timesteps_total                | 713000      |
| train-steps                    | 713000      |
| training/Q/q1_loss             | 108.0788    |
| training/sac_pi/alpha          | 0.16330814  |
| training/sac_pi/alpha_loss     | -0.27255598 |
| training/sac_pi/logp_pi        | 4.3535314   |
| training/sac_pi/pi_entropy     | 3.6839275   |
| training/sac_pi/pi_global_norm | 1.5364226   |
| training/sac_pi/policy_loss    | -229.88666  |
| training/sac_pi/std            | 0.53419244  |
| training/sac_pi/valid_num      | 4870.0      |
| training/sac_Q/q1              | 209.71347   |
| training/sac_Q/q2              | 211.43344   |
| training/sac_Q/q2_loss         | 108.533485  |
| training/sac_Q/q_global_norm   | 234.4595    |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1608048    |
| epoch                          | 713          |
| evaluation/episode-length-avg  | 946          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 455          |
| evaluation/episode-length-std  | 164          |
| evaluation/return-average      | 4547.9385    |
| evaluation/return-max          | 4993.385     |
| evaluation/return-min          | 1951.4072    |
| evaluation/return-std          | 869.662      |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.14         |
| model/origin_ret               | 86.8         |
| model/penalty_ret              | 79.5         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46343        |
| perf/AverageLength             | 946          |
| perf/AverageReturn             | 4547.9385    |
| perf/NormalizedReturn          | 0.99         |
| Q-avg                          | 221.07051    |
| Q-std                          | 111.432976   |
| Q_loss                         | 87.4112      |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 713          |
| times/epoch_after_hook         | 1.74e-06     |
| times/epoch_before_hook        | 0.000281     |
| times/epoch_rollout_model      | 492          |
| times/evaluation_metrics       | 0.000568     |
| times/evaluation_paths         | 41.7         |
| times/timestep_after_hook      | 0.00375      |
| times/timestep_before_hook     | 0.00835      |
| times/train                    | 73.4         |
| timestep                       | 1000         |
| timesteps_total                | 714000       |
| train-steps                    | 714000       |
| training/Q/q1_loss             | 111.64919    |
| training/sac_pi/alpha          | 0.1608215    |
| training/sac_pi/alpha_loss     | -0.030674458 |
| training/sac_pi/logp_pi        | 4.938178     |
| training/sac_pi/pi_entropy     | 3.3336854    |
| training/sac_pi/pi_global_norm | 1.6525589    |
| training/sac_pi/policy_loss    | -220.53864   |
| training/sac_pi/std            | 0.48916066   |
| training/sac_pi/valid_num      | 4886.0       |
| training/sac_Q/q1              | 203.96365    |
| training/sac_Q/q2              | 207.41142    |
| training/sac_Q/q2_loss         | 112.765915   |
| training/sac_Q/q_global_norm   | 296.4881     |
----------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16279374   |
| epoch                          | 714          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5163.1143    |
| evaluation/return-max          | 5196.5674    |
| evaluation/return-min          | 5134.4854    |
| evaluation/return-std          | 17.187517    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.14         |
| model/origin_ret               | 85.9         |
| model/penalty_ret              | 79.7         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46417        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5163.1143    |
| perf/NormalizedReturn          | 1.12         |
| Q-avg                          | 211.5457     |
| Q-std                          | 154.54489    |
| Q_loss                         | 117.712135   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 714          |
| times/epoch_after_hook         | 1.61e-06     |
| times/epoch_before_hook        | 0.000126     |
| times/epoch_rollout_model      | 488          |
| times/evaluation_metrics       | 0.000634     |
| times/evaluation_paths         | 41.6         |
| times/timestep_after_hook      | 0.0038       |
| times/timestep_before_hook     | 0.00844      |
| times/train                    | 70.6         |
| timestep                       | 1000         |
| timesteps_total                | 715000       |
| train-steps                    | 715000       |
| training/Q/q1_loss             | 105.39192    |
| training/sac_pi/alpha          | 0.16280629   |
| training/sac_pi/alpha_loss     | -0.121303365 |
| training/sac_pi/logp_pi        | 3.7737656    |
| training/sac_pi/pi_entropy     | 3.5792346    |
| training/sac_pi/pi_global_norm | 1.627153     |
| training/sac_pi/policy_loss    | -218.29417   |
| training/sac_pi/std            | 0.494395     |
| training/sac_pi/valid_num      | 5015.0       |
| training/sac_Q/q1              | 209.89343    |
| training/sac_Q/q2              | 212.98804    |
| training/sac_Q/q2_loss         | 105.782974   |
| training/sac_Q/q_global_norm   | 223.7585     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15600516 |
| epoch                          | 715        |
| evaluation/episode-length-avg  | 865        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 324        |
| evaluation/episode-length-std  | 269        |
| evaluation/return-average      | 4365.8794  |
| evaluation/return-max          | 5194.379   |
| evaluation/return-min          | 1273.9094  |
| evaluation/return-std          | 1539.6423  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46363      |
| perf/AverageLength             | 865        |
| perf/AverageReturn             | 4365.8794  |
| perf/NormalizedReturn          | 0.951      |
| Q-avg                          | 206.93753  |
| Q-std                          | 209.94371  |
| Q_loss                         | 118.78329  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 715        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.00052    |
| times/evaluation_paths         | 36.2       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00854    |
| times/train                    | 69.2       |
| timestep                       | 1000       |
| timesteps_total                | 716000     |
| train-steps                    | 716000     |
| training/Q/q1_loss             | 109.14564  |
| training/sac_pi/alpha          | 0.15598844 |
| training/sac_pi/alpha_loss     | 0.28742024 |
| training/sac_pi/logp_pi        | 3.9227097  |
| training/sac_pi/pi_entropy     | 3.1684008  |
| training/sac_pi/pi_global_norm | 1.5499743  |
| training/sac_pi/policy_loss    | -231.43402 |
| training/sac_pi/std            | 0.4516711  |
| training/sac_pi/valid_num      | 5057.0     |
| training/sac_Q/q1              | 225.53157  |
| training/sac_Q/q2              | 226.58139  |
| training/sac_Q/q2_loss         | 108.921745 |
| training/sac_Q/q_global_norm   | 292.47995  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16212524 |
| epoch                          | 716        |
| evaluation/episode-length-avg  | 975        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 782        |
| evaluation/episode-length-std  | 65         |
| evaluation/return-average      | 4829.461   |
| evaluation/return-max          | 5119.01    |
| evaluation/return-min          | 3744.268   |
| evaluation/return-std          | 372.37003  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 78.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46331      |
| perf/AverageLength             | 975        |
| perf/AverageReturn             | 4829.461   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 221.92696  |
| Q-std                          | 133.02353  |
| Q_loss                         | 102.09885  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 716        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.000119   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000659   |
| times/evaluation_paths         | 41         |
| times/timestep_after_hook      | 0.00379    |
| times/timestep_before_hook     | 0.00856    |
| times/train                    | 70.8       |
| timestep                       | 1000       |
| timesteps_total                | 717000     |
| train-steps                    | 717000     |
| training/Q/q1_loss             | 122.66188  |
| training/sac_pi/alpha          | 0.16213033 |
| training/sac_pi/alpha_loss     | -0.5047232 |
| training/sac_pi/logp_pi        | 4.902631   |
| training/sac_pi/pi_entropy     | 3.412784   |
| training/sac_pi/pi_global_norm | 1.8038639  |
| training/sac_pi/policy_loss    | -231.9399  |
| training/sac_pi/std            | 0.5261916  |
| training/sac_pi/valid_num      | 4908.0     |
| training/sac_Q/q1              | 211.59692  |
| training/sac_Q/q2              | 214.48071  |
| training/sac_Q/q2_loss         | 122.82516  |
| training/sac_Q/q_global_norm   | 296.9488   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15595564  |
| epoch                          | 717         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5242.4893   |
| evaluation/return-max          | 5295.617    |
| evaluation/return-min          | 5079.79     |
| evaluation/return-std          | 56.615944   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46580       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5242.4893   |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 227.03218   |
| Q-std                          | 133.2566    |
| Q_loss                         | 92.486145   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 717         |
| times/epoch_after_hook         | 3.12e-06    |
| times/epoch_before_hook        | 0.000339    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000962    |
| times/evaluation_paths         | 41.7        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 70.7        |
| timestep                       | 1000        |
| timesteps_total                | 718000      |
| train-steps                    | 718000      |
| training/Q/q1_loss             | 85.42939    |
| training/sac_pi/alpha          | 0.15597436  |
| training/sac_pi/alpha_loss     | -0.11852814 |
| training/sac_pi/logp_pi        | 3.2112343   |
| training/sac_pi/pi_entropy     | 3.3659782   |
| training/sac_pi/pi_global_norm | 1.6492879   |
| training/sac_pi/policy_loss    | -234.68501  |
| training/sac_pi/std            | 0.45559984  |
| training/sac_pi/valid_num      | 5039.0      |
| training/sac_Q/q1              | 231.3895    |
| training/sac_Q/q2              | 231.35571   |
| training/sac_Q/q2_loss         | 85.404076   |
| training/sac_Q/q_global_norm   | 176.49063   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16099308  |
| epoch                          | 718         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4947.156    |
| evaluation/return-max          | 5067.407    |
| evaluation/return-min          | 4866.474    |
| evaluation/return-std          | 61.226936   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86          |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46427       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4947.156    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 214.42648   |
| Q-std                          | 152.00934   |
| Q_loss                         | 80.87691    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 718         |
| times/epoch_after_hook         | 1.6e-06     |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000593    |
| times/evaluation_paths         | 39.4        |
| times/timestep_after_hook      | 0.00409     |
| times/timestep_before_hook     | 0.00886     |
| times/train                    | 68.9        |
| timestep                       | 1000        |
| timesteps_total                | 719000      |
| train-steps                    | 719000      |
| training/Q/q1_loss             | 85.7895     |
| training/sac_pi/alpha          | 0.16101445  |
| training/sac_pi/alpha_loss     | -0.11292813 |
| training/sac_pi/logp_pi        | 4.5025554   |
| training/sac_pi/pi_entropy     | 3.387815    |
| training/sac_pi/pi_global_norm | 1.9817305   |
| training/sac_pi/policy_loss    | -229.7738   |
| training/sac_pi/std            | 0.5175075   |
| training/sac_pi/valid_num      | 4962.0      |
| training/sac_Q/q1              | 216.98901   |
| training/sac_Q/q2              | 220.56006   |
| training/sac_Q/q2_loss         | 85.527626   |
| training/sac_Q/q_global_norm   | 260.14096   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16530615  |
| epoch                          | 719         |
| evaluation/episode-length-avg  | 966         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 659         |
| evaluation/episode-length-std  | 102         |
| evaluation/return-average      | 5042.2      |
| evaluation/return-max          | 5340.925    |
| evaluation/return-min          | 3286.934    |
| evaluation/return-std          | 589.82623   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46374       |
| perf/AverageLength             | 966         |
| perf/AverageReturn             | 5042.2      |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 225.81538   |
| Q-std                          | 133.76512   |
| Q_loss                         | 80.61025    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 719         |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000116    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000651    |
| times/evaluation_paths         | 42.1        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00867     |
| times/train                    | 71.3        |
| timestep                       | 1000        |
| timesteps_total                | 720000      |
| train-steps                    | 720000      |
| training/Q/q1_loss             | 100.35227   |
| training/sac_pi/alpha          | 0.16533206  |
| training/sac_pi/alpha_loss     | 0.030563828 |
| training/sac_pi/logp_pi        | 3.785797    |
| training/sac_pi/pi_entropy     | 3.4325309   |
| training/sac_pi/pi_global_norm | 1.7674129   |
| training/sac_pi/policy_loss    | -228.03627  |
| training/sac_pi/std            | 0.4772511   |
| training/sac_pi/valid_num      | 5024.0      |
| training/sac_Q/q1              | 220.25415   |
| training/sac_Q/q2              | 221.84024   |
| training/sac_Q/q2_loss         | 99.75359    |
| training/sac_Q/q_global_norm   | 188.78055   |
---------------------------------------------------------------------------------
[WARN] 720 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.16012867   |
| epoch                          | 720          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5188.24      |
| evaluation/return-max          | 5215.193     |
| evaluation/return-min          | 5159.26      |
| evaluation/return-std          | 15.43929     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.14         |
| model/origin_ret               | 86.3         |
| model/penalty_ret              | 80           |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46428        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5188.24      |
| perf/NormalizedReturn          | 1.13         |
| Q-avg                          | 223.46297    |
| Q-std                          | 146.6967     |
| Q_loss                         | 83.57573     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 720          |
| times/epoch_after_hook         | 1.93e-06     |
| times/epoch_before_hook        | 0.000144     |
| times/epoch_rollout_model      | 485          |
| times/evaluation_metrics       | 0.000593     |
| times/evaluation_paths         | 42.2         |
| times/timestep_after_hook      | 0.00359      |
| times/timestep_before_hook     | 0.00909      |
| times/train                    | 69.4         |
| timestep                       | 1000         |
| timesteps_total                | 721000       |
| train-steps                    | 721000       |
| training/Q/q1_loss             | 96.36177     |
| training/sac_pi/alpha          | 0.16013564   |
| training/sac_pi/alpha_loss     | -0.030111866 |
| training/sac_pi/logp_pi        | 4.3330545    |
| training/sac_pi/pi_entropy     | 3.3532715    |
| training/sac_pi/pi_global_norm | 1.7755927    |
| training/sac_pi/policy_loss    | -230.18192   |
| training/sac_pi/std            | 0.48594862   |
| training/sac_pi/valid_num      | 4953.0       |
| training/sac_Q/q1              | 216.8433     |
| training/sac_Q/q2              | 218.59958    |
| training/sac_Q/q2_loss         | 95.64645     |
| training/sac_Q/q_global_norm   | 184.52971    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1650907   |
| epoch                          | 721         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5250.1304   |
| evaluation/return-max          | 5276.915    |
| evaluation/return-min          | 5227.917    |
| evaluation/return-std          | 15.626473   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46472       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5250.1304   |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 222.72205   |
| Q-std                          | 137.69879   |
| Q_loss                         | 99.168526   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 721         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000282    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000516    |
| times/evaluation_paths         | 46.1        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 69          |
| timestep                       | 1000        |
| timesteps_total                | 722000      |
| train-steps                    | 722000      |
| training/Q/q1_loss             | 92.17848    |
| training/sac_pi/alpha          | 0.16507638  |
| training/sac_pi/alpha_loss     | -0.27314386 |
| training/sac_pi/logp_pi        | 4.602756    |
| training/sac_pi/pi_entropy     | 3.598233    |
| training/sac_pi/pi_global_norm | 1.8980385   |
| training/sac_pi/policy_loss    | -232.34082  |
| training/sac_pi/std            | 0.5439535   |
| training/sac_pi/valid_num      | 4944.0      |
| training/sac_Q/q1              | 208.18839   |
| training/sac_Q/q2              | 216.28911   |
| training/sac_Q/q2_loss         | 90.624725   |
| training/sac_Q/q_global_norm   | 274.9467    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16101192 |
| epoch                          | 722        |
| evaluation/episode-length-avg  | 581        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 159        |
| evaluation/episode-length-std  | 419        |
| evaluation/return-average      | 2906.526   |
| evaluation/return-max          | 5344.241   |
| evaluation/return-min          | 508.1642   |
| evaluation/return-std          | 2385.6392  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46405      |
| perf/AverageLength             | 581        |
| perf/AverageReturn             | 2906.526   |
| perf/NormalizedReturn          | 0.633      |
| Q-avg                          | 215.33496  |
| Q-std                          | 145.10587  |
| Q_loss                         | 109.240425 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 722        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000678   |
| times/evaluation_paths         | 24.2       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 68.2       |
| timestep                       | 1000       |
| timesteps_total                | 723000     |
| train-steps                    | 723000     |
| training/Q/q1_loss             | 105.16555  |
| training/sac_pi/alpha          | 0.16103175 |
| training/sac_pi/alpha_loss     | 0.38882333 |
| training/sac_pi/logp_pi        | 4.162861   |
| training/sac_pi/pi_entropy     | 3.4300354  |
| training/sac_pi/pi_global_norm | 1.6553893  |
| training/sac_pi/policy_loss    | -224.19171 |
| training/sac_pi/std            | 0.48863754 |
| training/sac_pi/valid_num      | 4945.0     |
| training/sac_Q/q1              | 213.00864  |
| training/sac_Q/q2              | 212.87285  |
| training/sac_Q/q2_loss         | 105.428406 |
| training/sac_Q/q_global_norm   | 214.70186  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15982527  |
| epoch                          | 723         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5167.9795   |
| evaluation/return-max          | 5207.17     |
| evaluation/return-min          | 5080.9404   |
| evaluation/return-std          | 40.219467   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.15        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 78.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46577       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5167.9795   |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 218.41231   |
| Q-std                          | 115.35744   |
| Q_loss                         | 99.99317    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 723         |
| times/epoch_after_hook         | 1.59e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000501    |
| times/evaluation_paths         | 38.3        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 64          |
| timestep                       | 1000        |
| timesteps_total                | 724000      |
| train-steps                    | 724000      |
| training/Q/q1_loss             | 93.774826   |
| training/sac_pi/alpha          | 0.15981396  |
| training/sac_pi/alpha_loss     | -0.16079558 |
| training/sac_pi/logp_pi        | 4.6009893   |
| training/sac_pi/pi_entropy     | 3.2883155   |
| training/sac_pi/pi_global_norm | 1.8934767   |
| training/sac_pi/policy_loss    | -236.17422  |
| training/sac_pi/std            | 0.50092995  |
| training/sac_pi/valid_num      | 4952.0      |
| training/sac_Q/q1              | 218.54532   |
| training/sac_Q/q2              | 222.93648   |
| training/sac_Q/q2_loss         | 95.57534    |
| training/sac_Q/q_global_norm   | 230.41415   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1601545   |
| epoch                          | 724         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5040.144    |
| evaluation/return-max          | 5189.4634   |
| evaluation/return-min          | 4881.6465   |
| evaluation/return-std          | 102.20797   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46392       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5040.144    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 217.19807   |
| Q-std                          | 205.73987   |
| Q_loss                         | 102.02803   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 724         |
| times/epoch_after_hook         | 1.95e-06    |
| times/epoch_before_hook        | 0.00012     |
| times/epoch_rollout_model      | 487         |
| times/evaluation_metrics       | 0.000717    |
| times/evaluation_paths         | 35.7        |
| times/timestep_after_hook      | 0.00356     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 63.2        |
| timestep                       | 1000        |
| timesteps_total                | 725000      |
| train-steps                    | 725000      |
| training/Q/q1_loss             | 87.52541    |
| training/sac_pi/alpha          | 0.16021076  |
| training/sac_pi/alpha_loss     | -0.37507945 |
| training/sac_pi/logp_pi        | 4.0874715   |
| training/sac_pi/pi_entropy     | 3.168509    |
| training/sac_pi/pi_global_norm | 1.8090087   |
| training/sac_pi/policy_loss    | -235.34404  |
| training/sac_pi/std            | 0.45698687  |
| training/sac_pi/valid_num      | 4966.0      |
| training/sac_Q/q1              | 220.95427   |
| training/sac_Q/q2              | 223.42001   |
| training/sac_Q/q2_loss         | 87.01462    |
| training/sac_Q/q_global_norm   | 392.7119    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16373713 |
| epoch                          | 725        |
| evaluation/episode-length-avg  | 895        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 692        |
| evaluation/episode-length-std  | 96.6       |
| evaluation/return-average      | 4168.1865  |
| evaluation/return-max          | 4806.046   |
| evaluation/return-min          | 3071.5605  |
| evaluation/return-std          | 519.4158   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46527      |
| perf/AverageLength             | 895        |
| perf/AverageReturn             | 4168.1865  |
| perf/NormalizedReturn          | 0.908      |
| Q-avg                          | 223.84097  |
| Q-std                          | 98.88945   |
| Q_loss                         | 75.77122   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 725        |
| times/epoch_after_hook         | 3.37e-06   |
| times/epoch_before_hook        | 0.000278   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000558   |
| times/evaluation_paths         | 31.7       |
| times/timestep_after_hook      | 0.00355    |
| times/timestep_before_hook     | 0.00845    |
| times/train                    | 62.5       |
| timestep                       | 1000       |
| timesteps_total                | 726000     |
| train-steps                    | 726000     |
| training/Q/q1_loss             | 134.03827  |
| training/sac_pi/alpha          | 0.16373223 |
| training/sac_pi/alpha_loss     | 0.43246722 |
| training/sac_pi/logp_pi        | 5.180812   |
| training/sac_pi/pi_entropy     | 3.4610696  |
| training/sac_pi/pi_global_norm | 1.6832743  |
| training/sac_pi/policy_loss    | -215.60757 |
| training/sac_pi/std            | 0.51407653 |
| training/sac_pi/valid_num      | 4879.0     |
| training/sac_Q/q1              | 200.70174  |
| training/sac_Q/q2              | 200.45064  |
| training/sac_Q/q2_loss         | 134.81972  |
| training/sac_Q/q_global_norm   | 254.50465  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15530153   |
| epoch                          | 726          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4832.6436    |
| evaluation/return-max          | 4995.7188    |
| evaluation/return-min          | 4714.4443    |
| evaluation/return-std          | 97.58119     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.17         |
| model/origin_ret               | 86.8         |
| model/penalty_ret              | 79.3         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46544        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4832.6436    |
| perf/NormalizedReturn          | 1.05         |
| Q-avg                          | 208.8643     |
| Q-std                          | 190.86432    |
| Q_loss                         | 88.32419     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 726          |
| times/epoch_after_hook         | 1.59e-06     |
| times/epoch_before_hook        | 0.000124     |
| times/epoch_rollout_model      | 482          |
| times/evaluation_metrics       | 0.000582     |
| times/evaluation_paths         | 35.7         |
| times/timestep_after_hook      | 0.00366      |
| times/timestep_before_hook     | 0.00843      |
| times/train                    | 63.3         |
| timestep                       | 1000         |
| timesteps_total                | 727000       |
| train-steps                    | 727000       |
| training/Q/q1_loss             | 98.04611     |
| training/sac_pi/alpha          | 0.15531737   |
| training/sac_pi/alpha_loss     | -0.099598184 |
| training/sac_pi/logp_pi        | 4.3648405    |
| training/sac_pi/pi_entropy     | 3.3699448    |
| training/sac_pi/pi_global_norm | 2.1118808    |
| training/sac_pi/policy_loss    | -234.64572   |
| training/sac_pi/std            | 0.510191     |
| training/sac_pi/valid_num      | 4929.0       |
| training/sac_Q/q1              | 217.78079    |
| training/sac_Q/q2              | 218.84106    |
| training/sac_Q/q2_loss         | 97.67141     |
| training/sac_Q/q_global_norm   | 302.8431     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15827906 |
| epoch                          | 727        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4975.8135  |
| evaluation/return-max          | 5026.3364  |
| evaluation/return-min          | 4925.8906  |
| evaluation/return-std          | 33.00177   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46571      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4975.8135  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 216.36267  |
| Q-std                          | 132.68979  |
| Q_loss                         | 128.62894  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 727        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.00054    |
| times/evaluation_paths         | 35.8       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 62.5       |
| timestep                       | 1000       |
| timesteps_total                | 728000     |
| train-steps                    | 728000     |
| training/Q/q1_loss             | 92.95029   |
| training/sac_pi/alpha          | 0.15828693 |
| training/sac_pi/alpha_loss     | 0.24001555 |
| training/sac_pi/logp_pi        | 4.2570114  |
| training/sac_pi/pi_entropy     | 3.3289921  |
| training/sac_pi/pi_global_norm | 1.9199508  |
| training/sac_pi/policy_loss    | -233.3663  |
| training/sac_pi/std            | 0.47868648 |
| training/sac_pi/valid_num      | 4927.0     |
| training/sac_Q/q1              | 219.53992  |
| training/sac_Q/q2              | 223.04968  |
| training/sac_Q/q2_loss         | 93.50284   |
| training/sac_Q/q_global_norm   | 292.8762   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15808988  |
| epoch                          | 728         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4907.5747   |
| evaluation/return-max          | 5109.347    |
| evaluation/return-min          | 4824.593    |
| evaluation/return-std          | 93.310165   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 86.4        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46348       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4907.5747   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 216.67583   |
| Q-std                          | 174.30318   |
| Q_loss                         | 107.74894   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 728         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000512    |
| times/evaluation_paths         | 37.7        |
| times/timestep_after_hook      | 0.00354     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 65.4        |
| timestep                       | 1000        |
| timesteps_total                | 729000      |
| train-steps                    | 729000      |
| training/Q/q1_loss             | 102.39597   |
| training/sac_pi/alpha          | 0.15807737  |
| training/sac_pi/alpha_loss     | -0.37653166 |
| training/sac_pi/logp_pi        | 4.7976274   |
| training/sac_pi/pi_entropy     | 3.5064023   |
| training/sac_pi/pi_global_norm | 2.011338    |
| training/sac_pi/policy_loss    | -231.67401  |
| training/sac_pi/std            | 0.53021425  |
| training/sac_pi/valid_num      | 4917.0      |
| training/sac_Q/q1              | 212.9888    |
| training/sac_Q/q2              | 215.23872   |
| training/sac_Q/q2_loss         | 102.57356   |
| training/sac_Q/q_global_norm   | 163.40001   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1605323   |
| epoch                          | 729         |
| evaluation/episode-length-avg  | 865         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 313         |
| evaluation/episode-length-std  | 269         |
| evaluation/return-average      | 3959.5383   |
| evaluation/return-max          | 4711.5195   |
| evaluation/return-min          | 1204.7236   |
| evaluation/return-std          | 1356.1455   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46394       |
| perf/AverageLength             | 865         |
| perf/AverageReturn             | 3959.5383   |
| perf/NormalizedReturn          | 0.862       |
| Q-avg                          | 207.23706   |
| Q-std                          | 207.3608    |
| Q_loss                         | 92.281425   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 729         |
| times/epoch_after_hook         | 1.66e-06    |
| times/epoch_before_hook        | 0.000283    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000626    |
| times/evaluation_paths         | 31.5        |
| times/timestep_after_hook      | 0.00356     |
| times/timestep_before_hook     | 0.00833     |
| times/train                    | 58.2        |
| timestep                       | 1000        |
| timesteps_total                | 730000      |
| train-steps                    | 730000      |
| training/Q/q1_loss             | 118.36405   |
| training/sac_pi/alpha          | 0.1605339   |
| training/sac_pi/alpha_loss     | 0.100850835 |
| training/sac_pi/logp_pi        | 4.2585373   |
| training/sac_pi/pi_entropy     | 3.369269    |
| training/sac_pi/pi_global_norm | 1.8907032   |
| training/sac_pi/policy_loss    | -227.48746  |
| training/sac_pi/std            | 0.4876719   |
| training/sac_pi/valid_num      | 5001.0      |
| training/sac_Q/q1              | 215.85495   |
| training/sac_Q/q2              | 218.00882   |
| training/sac_Q/q2_loss         | 119.959755  |
| training/sac_Q/q_global_norm   | 245.39607   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16156043 |
| epoch                          | 730        |
| evaluation/episode-length-avg  | 888        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 426        |
| evaluation/episode-length-std  | 224        |
| evaluation/return-average      | 4291.327   |
| evaluation/return-max          | 5019.1963  |
| evaluation/return-min          | 1736.6042  |
| evaluation/return-std          | 1251.992   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46454      |
| perf/AverageLength             | 888        |
| perf/AverageReturn             | 4291.327   |
| perf/NormalizedReturn          | 0.934      |
| Q-avg                          | 213.23804  |
| Q-std                          | 129.76178  |
| Q_loss                         | 101.19161  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 730        |
| times/epoch_after_hook         | 1.57e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000608   |
| times/evaluation_paths         | 40.2       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 731000     |
| train-steps                    | 731000     |
| training/Q/q1_loss             | 102.388374 |
| training/sac_pi/alpha          | 0.16156918 |
| training/sac_pi/alpha_loss     | 0.15900242 |
| training/sac_pi/logp_pi        | 4.3974633  |
| training/sac_pi/pi_entropy     | 3.2043157  |
| training/sac_pi/pi_global_norm | 2.2826903  |
| training/sac_pi/policy_loss    | -230.54868 |
| training/sac_pi/std            | 0.47390386 |
| training/sac_pi/valid_num      | 4967.0     |
| training/sac_Q/q1              | 212.83418  |
| training/sac_Q/q2              | 216.38115  |
| training/sac_Q/q2_loss         | 102.5087   |
| training/sac_Q/q_global_norm   | 227.08286  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16357553  |
| epoch                          | 731         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4896.354    |
| evaluation/return-max          | 4939.129    |
| evaluation/return-min          | 4862.3203   |
| evaluation/return-std          | 26.786306   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46537       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4896.354    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 220.47697   |
| Q-std                          | 108.0932    |
| Q_loss                         | 138.43152   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 731         |
| times/epoch_after_hook         | 1.65e-06    |
| times/epoch_before_hook        | 0.000211    |
| times/epoch_rollout_model      | 488         |
| times/evaluation_metrics       | 0.000516    |
| times/evaluation_paths         | 49.4        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 63.6        |
| timestep                       | 1000        |
| timesteps_total                | 732000      |
| train-steps                    | 732000      |
| training/Q/q1_loss             | 91.392944   |
| training/sac_pi/alpha          | 0.16359635  |
| training/sac_pi/alpha_loss     | -0.36618719 |
| training/sac_pi/logp_pi        | 3.4148662   |
| training/sac_pi/pi_entropy     | 3.438828    |
| training/sac_pi/pi_global_norm | 1.5612133   |
| training/sac_pi/policy_loss    | -235.36917  |
| training/sac_pi/std            | 0.4774419   |
| training/sac_pi/valid_num      | 5015.0      |
| training/sac_Q/q1              | 229.43867   |
| training/sac_Q/q2              | 230.35318   |
| training/sac_Q/q2_loss         | 92.409546   |
| training/sac_Q/q_global_norm   | 356.62445   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16516837 |
| epoch                          | 732        |
| evaluation/episode-length-avg  | 680        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 166        |
| evaluation/episode-length-std  | 393        |
| evaluation/return-average      | 3352.0562  |
| evaluation/return-max          | 5216.1943  |
| evaluation/return-min          | 520.85364  |
| evaluation/return-std          | 2186.957   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46660      |
| perf/AverageLength             | 680        |
| perf/AverageReturn             | 3352.0562  |
| perf/NormalizedReturn          | 0.73       |
| Q-avg                          | 219.19168  |
| Q-std                          | 192.10405  |
| Q_loss                         | 97.84939   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 732        |
| times/epoch_after_hook         | 1.65e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000572   |
| times/evaluation_paths         | 31.6       |
| times/timestep_after_hook      | 0.00375    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 63.5       |
| timestep                       | 1000       |
| timesteps_total                | 733000     |
| train-steps                    | 733000     |
| training/Q/q1_loss             | 120.472466 |
| training/sac_pi/alpha          | 0.16512075 |
| training/sac_pi/alpha_loss     | 0.3968098  |
| training/sac_pi/logp_pi        | 4.495565   |
| training/sac_pi/pi_entropy     | 3.4071152  |
| training/sac_pi/pi_global_norm | 2.1188638  |
| training/sac_pi/policy_loss    | -223.39288 |
| training/sac_pi/std            | 0.48754108 |
| training/sac_pi/valid_num      | 4989.0     |
| training/sac_Q/q1              | 214.4844   |
| training/sac_Q/q2              | 213.60869  |
| training/sac_Q/q2_loss         | 120.73724  |
| training/sac_Q/q_global_norm   | 288.87997  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16116244  |
| epoch                          | 733         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5285.1265   |
| evaluation/return-max          | 5323.333    |
| evaluation/return-min          | 5250.5674   |
| evaluation/return-std          | 20.65545    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 78.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46439       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5285.1265   |
| perf/NormalizedReturn          | 1.15        |
| Q-avg                          | 225.54048   |
| Q-std                          | 118.98194   |
| Q_loss                         | 94.78602    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 733         |
| times/epoch_after_hook         | 1.59e-06    |
| times/epoch_before_hook        | 0.000277    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000584    |
| times/evaluation_paths         | 38.6        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00833     |
| times/train                    | 70.4        |
| timestep                       | 1000        |
| timesteps_total                | 734000      |
| train-steps                    | 734000      |
| training/Q/q1_loss             | 101.72273   |
| training/sac_pi/alpha          | 0.16114059  |
| training/sac_pi/alpha_loss     | -0.05758089 |
| training/sac_pi/logp_pi        | 4.785011    |
| training/sac_pi/pi_entropy     | 3.457955    |
| training/sac_pi/pi_global_norm | 1.8402846   |
| training/sac_pi/policy_loss    | -230.89172  |
| training/sac_pi/std            | 0.51660055  |
| training/sac_pi/valid_num      | 4957.0      |
| training/sac_Q/q1              | 216.33772   |
| training/sac_Q/q2              | 219.43552   |
| training/sac_Q/q2_loss         | 101.81894   |
| training/sac_Q/q_global_norm   | 216.51334   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16422819  |
| epoch                          | 734         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5255.942    |
| evaluation/return-max          | 5382.1416   |
| evaluation/return-min          | 5027.9727   |
| evaluation/return-std          | 144.53517   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.15        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46495       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5255.942    |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 212.72482   |
| Q-std                          | 213.1295    |
| Q_loss                         | 106.388405  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 734         |
| times/epoch_after_hook         | 1.95e-06    |
| times/epoch_before_hook        | 0.000129    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.00058     |
| times/evaluation_paths         | 36.7        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00827     |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 735000      |
| train-steps                    | 735000      |
| training/Q/q1_loss             | 121.484505  |
| training/sac_pi/alpha          | 0.16422825  |
| training/sac_pi/alpha_loss     | -0.08873228 |
| training/sac_pi/logp_pi        | 4.1957126   |
| training/sac_pi/pi_entropy     | 3.5038338   |
| training/sac_pi/pi_global_norm | 1.8174101   |
| training/sac_pi/policy_loss    | -216.81165  |
| training/sac_pi/std            | 0.49702612  |
| training/sac_pi/valid_num      | 4974.0      |
| training/sac_Q/q1              | 207.39302   |
| training/sac_Q/q2              | 209.054     |
| training/sac_Q/q2_loss         | 120.4514    |
| training/sac_Q/q_global_norm   | 219.53049   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16363889  |
| epoch                          | 735         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5107.9272   |
| evaluation/return-max          | 5215.6343   |
| evaluation/return-min          | 5037.7007   |
| evaluation/return-std          | 44.69357    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46326       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5107.9272   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 223.68912   |
| Q-std                          | 136.29088   |
| Q_loss                         | 96.55348    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 735         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000665    |
| times/evaluation_paths         | 35.1        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.0084      |
| times/train                    | 62.6        |
| timestep                       | 1000        |
| timesteps_total                | 736000      |
| train-steps                    | 736000      |
| training/Q/q1_loss             | 119.74481   |
| training/sac_pi/alpha          | 0.16366665  |
| training/sac_pi/alpha_loss     | 0.104298726 |
| training/sac_pi/logp_pi        | 5.075139    |
| training/sac_pi/pi_entropy     | 3.559719    |
| training/sac_pi/pi_global_norm | 1.7828054   |
| training/sac_pi/policy_loss    | -230.83315  |
| training/sac_pi/std            | 0.5439718   |
| training/sac_pi/valid_num      | 4903.0      |
| training/sac_Q/q1              | 212.94963   |
| training/sac_Q/q2              | 213.93198   |
| training/sac_Q/q2_loss         | 118.96048   |
| training/sac_Q/q_global_norm   | 305.63263   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16525607   |
| epoch                          | 736          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5048.198     |
| evaluation/return-max          | 5118.122     |
| evaluation/return-min          | 4952.0293    |
| evaluation/return-std          | 53.444668    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.03         |
| model/origin_ret               | 84.8         |
| model/penalty_ret              | 79.1         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46350        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5048.198     |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 210.00085    |
| Q-std                          | 211.51253    |
| Q_loss                         | 115.8368     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 736          |
| times/epoch_after_hook         | 1.84e-06     |
| times/epoch_before_hook        | 0.000124     |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.000615     |
| times/evaluation_paths         | 34.7         |
| times/timestep_after_hook      | 0.00367      |
| times/timestep_before_hook     | 0.00827      |
| times/train                    | 62.6         |
| timestep                       | 1000         |
| timesteps_total                | 737000       |
| train-steps                    | 737000       |
| training/Q/q1_loss             | 89.27787     |
| training/sac_pi/alpha          | 0.16524553   |
| training/sac_pi/alpha_loss     | -0.058296144 |
| training/sac_pi/logp_pi        | 3.9041176    |
| training/sac_pi/pi_entropy     | 3.3219943    |
| training/sac_pi/pi_global_norm | 1.722703     |
| training/sac_pi/policy_loss    | -229.37073   |
| training/sac_pi/std            | 0.4859828    |
| training/sac_pi/valid_num      | 4998.0       |
| training/sac_Q/q1              | 221.24976    |
| training/sac_Q/q2              | 222.91924    |
| training/sac_Q/q2_loss         | 89.46032     |
| training/sac_Q/q_global_norm   | 218.58524    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16678286 |
| epoch                          | 737        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5230.3027  |
| evaluation/return-max          | 5289.7812  |
| evaluation/return-min          | 5178.147   |
| evaluation/return-std          | 32.6802    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46391      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5230.3027  |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 218.88533  |
| Q-std                          | 148.0889   |
| Q_loss                         | 104.88256  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 737        |
| times/epoch_after_hook         | 1.62e-06   |
| times/epoch_before_hook        | 0.000282   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000575   |
| times/evaluation_paths         | 47.5       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 63.6       |
| timestep                       | 1000       |
| timesteps_total                | 738000     |
| train-steps                    | 738000     |
| training/Q/q1_loss             | 116.974174 |
| training/sac_pi/alpha          | 0.16679664 |
| training/sac_pi/alpha_loss     | 0.09243469 |
| training/sac_pi/logp_pi        | 4.6530037  |
| training/sac_pi/pi_entropy     | 3.2902725  |
| training/sac_pi/pi_global_norm | 1.6872094  |
| training/sac_pi/policy_loss    | -229.94737 |
| training/sac_pi/std            | 0.48582277 |
| training/sac_pi/valid_num      | 4969.0     |
| training/sac_Q/q1              | 216.07149  |
| training/sac_Q/q2              | 215.09111  |
| training/sac_Q/q2_loss         | 116.83389  |
| training/sac_Q/q_global_norm   | 236.0366   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16048758  |
| epoch                          | 738         |
| evaluation/episode-length-avg  | 833         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 163         |
| evaluation/episode-length-std  | 334         |
| evaluation/return-average      | 4056.64     |
| evaluation/return-max          | 5008.335    |
| evaluation/return-min          | 541.04626   |
| evaluation/return-std          | 1756.6415   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46215       |
| perf/AverageLength             | 833         |
| perf/AverageReturn             | 4056.64     |
| perf/NormalizedReturn          | 0.883       |
| Q-avg                          | 214.90262   |
| Q-std                          | 136.91069   |
| Q_loss                         | 97.29107    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 738         |
| times/epoch_after_hook         | 1.62e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000619    |
| times/evaluation_paths         | 30.6        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 61          |
| timestep                       | 1000        |
| timesteps_total                | 739000      |
| train-steps                    | 739000      |
| training/Q/q1_loss             | 112.09803   |
| training/sac_pi/alpha          | 0.1605257   |
| training/sac_pi/alpha_loss     | -0.23187174 |
| training/sac_pi/logp_pi        | 4.5864687   |
| training/sac_pi/pi_entropy     | 3.3815022   |
| training/sac_pi/pi_global_norm | 2.007691    |
| training/sac_pi/policy_loss    | -227.99597  |
| training/sac_pi/std            | 0.51400137  |
| training/sac_pi/valid_num      | 4938.0      |
| training/sac_Q/q1              | 207.96098   |
| training/sac_Q/q2              | 211.30945   |
| training/sac_Q/q2_loss         | 111.65497   |
| training/sac_Q/q_global_norm   | 276.98102   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15978737 |
| epoch                          | 739        |
| evaluation/episode-length-avg  | 335        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 166        |
| evaluation/episode-length-std  | 333        |
| evaluation/return-average      | 1488.1124  |
| evaluation/return-max          | 5257.291   |
| evaluation/return-min          | 535.6909   |
| evaluation/return-std          | 1876.7266  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46584      |
| perf/AverageLength             | 335        |
| perf/AverageReturn             | 1488.1124  |
| perf/NormalizedReturn          | 0.324      |
| Q-avg                          | 226.27945  |
| Q-std                          | 124.92223  |
| Q_loss                         | 81.82416   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 739        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000577   |
| times/evaluation_paths         | 13.2       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 740000     |
| train-steps                    | 740000     |
| training/Q/q1_loss             | 105.45171  |
| training/sac_pi/alpha          | 0.15976547 |
| training/sac_pi/alpha_loss     | 0.4569088  |
| training/sac_pi/logp_pi        | 3.648763   |
| training/sac_pi/pi_entropy     | 3.3040924  |
| training/sac_pi/pi_global_norm | 1.7098235  |
| training/sac_pi/policy_loss    | -226.58665 |
| training/sac_pi/std            | 0.4522769  |
| training/sac_pi/valid_num      | 5000.0     |
| training/sac_Q/q1              | 218.74448  |
| training/sac_Q/q2              | 220.44351  |
| training/sac_Q/q2_loss         | 105.17861  |
| training/sac_Q/q_global_norm   | 198.1499   |
--------------------------------------------------------------------------------
[WARN] 740 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.15910369 |
| epoch                          | 740        |
| evaluation/episode-length-avg  | 722        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 169        |
| evaluation/episode-length-std  | 244        |
| evaluation/return-average      | 3539.6921  |
| evaluation/return-max          | 5293.158   |
| evaluation/return-min          | 535.55835  |
| evaluation/return-std          | 1372.5608  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46555      |
| perf/AverageLength             | 722        |
| perf/AverageReturn             | 3539.6921  |
| perf/NormalizedReturn          | 0.771      |
| Q-avg                          | 225.53625  |
| Q-std                          | 144.45601  |
| Q_loss                         | 85.0341    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 740        |
| times/epoch_after_hook         | 1.58e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 24.4       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 61         |
| timestep                       | 1000       |
| timesteps_total                | 741000     |
| train-steps                    | 741000     |
| training/Q/q1_loss             | 98.73896   |
| training/sac_pi/alpha          | 0.15910695 |
| training/sac_pi/alpha_loss     | -0.2596517 |
| training/sac_pi/logp_pi        | 4.3983407  |
| training/sac_pi/pi_entropy     | 3.3768902  |
| training/sac_pi/pi_global_norm | 2.4127915  |
| training/sac_pi/policy_loss    | -231.48282 |
| training/sac_pi/std            | 0.51936746 |
| training/sac_pi/valid_num      | 4896.0     |
| training/sac_Q/q1              | 209.94295  |
| training/sac_Q/q2              | 212.03142  |
| training/sac_Q/q2_loss         | 98.752815  |
| training/sac_Q/q_global_norm   | 257.47256  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16091411  |
| epoch                          | 741         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5172.72     |
| evaluation/return-max          | 5234.042    |
| evaluation/return-min          | 5108.2266   |
| evaluation/return-std          | 41.214745   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 78.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46575       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5172.72     |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 223.0564    |
| Q-std                          | 173.65126   |
| Q_loss                         | 102.799416  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 741         |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000287    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000647    |
| times/evaluation_paths         | 34.4        |
| times/timestep_after_hook      | 0.0035      |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 61.7        |
| timestep                       | 1000        |
| timesteps_total                | 742000      |
| train-steps                    | 742000      |
| training/Q/q1_loss             | 114.53325   |
| training/sac_pi/alpha          | 0.16094159  |
| training/sac_pi/alpha_loss     | -0.30438477 |
| training/sac_pi/logp_pi        | 4.658503    |
| training/sac_pi/pi_entropy     | 3.4694648   |
| training/sac_pi/pi_global_norm | 1.7155626   |
| training/sac_pi/policy_loss    | -227.68143  |
| training/sac_pi/std            | 0.52879643  |
| training/sac_pi/valid_num      | 4951.0      |
| training/sac_Q/q1              | 211.34908   |
| training/sac_Q/q2              | 213.67859   |
| training/sac_Q/q2_loss         | 116.067535  |
| training/sac_Q/q_global_norm   | 316.8413    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16427279  |
| epoch                          | 742         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5181.8525   |
| evaluation/return-max          | 5289.7583   |
| evaluation/return-min          | 5101.217    |
| evaluation/return-std          | 66.837      |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46260       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5181.8525   |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 220.88052   |
| Q-std                          | 133.67342   |
| Q_loss                         | 98.42408    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 742         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.00052     |
| times/evaluation_paths         | 35.7        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 63.1        |
| timestep                       | 1000        |
| timesteps_total                | 743000      |
| train-steps                    | 743000      |
| training/Q/q1_loss             | 89.96451    |
| training/sac_pi/alpha          | 0.16431251  |
| training/sac_pi/alpha_loss     | -0.19683638 |
| training/sac_pi/logp_pi        | 4.4311438   |
| training/sac_pi/pi_entropy     | 3.7141826   |
| training/sac_pi/pi_global_norm | 1.8334981   |
| training/sac_pi/policy_loss    | -229.87837  |
| training/sac_pi/std            | 0.5426285   |
| training/sac_pi/valid_num      | 4969.0      |
| training/sac_Q/q1              | 221.06233   |
| training/sac_Q/q2              | 219.89697   |
| training/sac_Q/q2_loss         | 90.77637    |
| training/sac_Q/q_global_norm   | 319.2433    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16453958  |
| epoch                          | 743         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5062.899    |
| evaluation/return-max          | 5173.402    |
| evaluation/return-min          | 4960.0      |
| evaluation/return-std          | 84.28264    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46399       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5062.899    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 215.9268    |
| Q-std                          | 138.79857   |
| Q_loss                         | 128.89137   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 743         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.00058     |
| times/evaluation_paths         | 35.5        |
| times/timestep_after_hook      | 0.00356     |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 744000      |
| train-steps                    | 744000      |
| training/Q/q1_loss             | 115.096176  |
| training/sac_pi/alpha          | 0.16454497  |
| training/sac_pi/alpha_loss     | -0.14792243 |
| training/sac_pi/logp_pi        | 4.8803453   |
| training/sac_pi/pi_entropy     | 3.3261864   |
| training/sac_pi/pi_global_norm | 2.1294274   |
| training/sac_pi/policy_loss    | -226.63007  |
| training/sac_pi/std            | 0.50680625  |
| training/sac_pi/valid_num      | 4909.0      |
| training/sac_Q/q1              | 209.45349   |
| training/sac_Q/q2              | 211.49922   |
| training/sac_Q/q2_loss         | 115.46282   |
| training/sac_Q/q_global_norm   | 232.60782   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16060948   |
| epoch                          | 744          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4990.278     |
| evaluation/return-max          | 5069.9365    |
| evaluation/return-min          | 4883.49      |
| evaluation/return-std          | 56.099403    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.09         |
| model/origin_ret               | 85.2         |
| model/penalty_ret              | 79.3         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46441        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4990.278     |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 213.55801    |
| Q-std                          | 114.178474   |
| Q_loss                         | 117.15387    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 744          |
| times/epoch_after_hook         | 1.81e-06     |
| times/epoch_before_hook        | 0.000127     |
| times/epoch_rollout_model      | 482          |
| times/evaluation_metrics       | 0.000563     |
| times/evaluation_paths         | 35.6         |
| times/timestep_after_hook      | 0.00361      |
| times/timestep_before_hook     | 0.00807      |
| times/train                    | 62.3         |
| timestep                       | 1000         |
| timesteps_total                | 745000       |
| train-steps                    | 745000       |
| training/Q/q1_loss             | 87.54908     |
| training/sac_pi/alpha          | 0.16064811   |
| training/sac_pi/alpha_loss     | -0.023534317 |
| training/sac_pi/logp_pi        | 3.840306     |
| training/sac_pi/pi_entropy     | 3.440165     |
| training/sac_pi/pi_global_norm | 1.8790839    |
| training/sac_pi/policy_loss    | -221.96811   |
| training/sac_pi/std            | 0.4910465    |
| training/sac_pi/valid_num      | 4969.0       |
| training/sac_Q/q1              | 212.7424     |
| training/sac_Q/q2              | 213.81348    |
| training/sac_Q/q2_loss         | 87.36974     |
| training/sac_Q/q_global_norm   | 207.60628    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16538668 |
| epoch                          | 745        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4927.803   |
| evaluation/return-max          | 5007.2246  |
| evaluation/return-min          | 4872.27    |
| evaluation/return-std          | 33.010952  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46440      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4927.803   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 204.00696  |
| Q-std                          | 214.18097  |
| Q_loss                         | 80.51654   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 745        |
| times/epoch_after_hook         | 3.32e-06   |
| times/epoch_before_hook        | 0.000321   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000595   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 746000     |
| train-steps                    | 746000     |
| training/Q/q1_loss             | 108.50529  |
| training/sac_pi/alpha          | 0.16534275 |
| training/sac_pi/alpha_loss     | 0.24972764 |
| training/sac_pi/logp_pi        | 5.1494813  |
| training/sac_pi/pi_entropy     | 3.411409   |
| training/sac_pi/pi_global_norm | 1.4957879  |
| training/sac_pi/policy_loss    | -224.84521 |
| training/sac_pi/std            | 0.52237266 |
| training/sac_pi/valid_num      | 4939.0     |
| training/sac_Q/q1              | 207.52222  |
| training/sac_Q/q2              | 210.84811  |
| training/sac_Q/q2_loss         | 108.64164  |
| training/sac_Q/q_global_norm   | 209.87706  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1608854  |
| epoch                          | 746        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5141.2725  |
| evaluation/return-max          | 5191.367   |
| evaluation/return-min          | 5095.961   |
| evaluation/return-std          | 33.060043  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46426      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5141.2725  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 222.20682  |
| Q-std                          | 109.65163  |
| Q_loss                         | 105.445274 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 746        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000634   |
| times/evaluation_paths         | 35.4       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 747000     |
| train-steps                    | 747000     |
| training/Q/q1_loss             | 81.62191   |
| training/sac_pi/alpha          | 0.16087204 |
| training/sac_pi/alpha_loss     | -0.4538959 |
| training/sac_pi/logp_pi        | 3.6184876  |
| training/sac_pi/pi_entropy     | 3.482329   |
| training/sac_pi/pi_global_norm | 1.721127   |
| training/sac_pi/policy_loss    | -222.88959 |
| training/sac_pi/std            | 0.48634905 |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 215.47842  |
| training/sac_Q/q2              | 215.08969  |
| training/sac_Q/q2_loss         | 83.365295  |
| training/sac_Q/q_global_norm   | 199.3069   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15848762  |
| epoch                          | 747         |
| evaluation/episode-length-avg  | 871         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 592         |
| evaluation/episode-length-std  | 166         |
| evaluation/return-average      | 4260.4937   |
| evaluation/return-max          | 5009.209    |
| evaluation/return-min          | 2714.2202   |
| evaluation/return-std          | 930.22974   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46499       |
| perf/AverageLength             | 871         |
| perf/AverageReturn             | 4260.4937   |
| perf/NormalizedReturn          | 0.928       |
| Q-avg                          | 221.76578   |
| Q-std                          | 102.03325   |
| Q_loss                         | 81.17844    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 747         |
| times/epoch_after_hook         | 1.84e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000585    |
| times/evaluation_paths         | 29.8        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 748000      |
| train-steps                    | 748000      |
| training/Q/q1_loss             | 87.05757    |
| training/sac_pi/alpha          | 0.15848166  |
| training/sac_pi/alpha_loss     | -0.24645117 |
| training/sac_pi/logp_pi        | 4.950777    |
| training/sac_pi/pi_entropy     | 3.3260555   |
| training/sac_pi/pi_global_norm | 1.6713725   |
| training/sac_pi/policy_loss    | -226.87267  |
| training/sac_pi/std            | 0.49832833  |
| training/sac_pi/valid_num      | 4912.0      |
| training/sac_Q/q1              | 209.34952   |
| training/sac_Q/q2              | 211.55302   |
| training/sac_Q/q2_loss         | 86.08752    |
| training/sac_Q/q_global_norm   | 256.3853    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16040024 |
| epoch                          | 748        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5054.418   |
| evaluation/return-max          | 5109.809   |
| evaluation/return-min          | 4963.8677  |
| evaluation/return-std          | 44.098503  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 80.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46454      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5054.418   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 219.13681  |
| Q-std                          | 104.61043  |
| Q_loss                         | 110.70706  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 748        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 9.94e-05   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000669   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 749000     |
| train-steps                    | 749000     |
| training/Q/q1_loss             | 122.72847  |
| training/sac_pi/alpha          | 0.16039309 |
| training/sac_pi/alpha_loss     | 0.0177792  |
| training/sac_pi/logp_pi        | 4.227693   |
| training/sac_pi/pi_entropy     | 3.350736   |
| training/sac_pi/pi_global_norm | 1.772045   |
| training/sac_pi/policy_loss    | -217.91794 |
| training/sac_pi/std            | 0.4954632  |
| training/sac_pi/valid_num      | 4998.0     |
| training/sac_Q/q1              | 205.44492  |
| training/sac_Q/q2              | 206.16415  |
| training/sac_Q/q2_loss         | 121.923355 |
| training/sac_Q/q_global_norm   | 299.19995  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1576374   |
| epoch                          | 749         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5115.2246   |
| evaluation/return-max          | 5186.1064   |
| evaluation/return-min          | 4942.8965   |
| evaluation/return-std          | 70.26759    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46470       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5115.2246   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 230.76944   |
| Q-std                          | 125.42884   |
| Q_loss                         | 101.8796    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 749         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000286    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000592    |
| times/evaluation_paths         | 36.6        |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00827     |
| times/train                    | 60.8        |
| timestep                       | 1000        |
| timesteps_total                | 750000      |
| train-steps                    | 750000      |
| training/Q/q1_loss             | 108.76666   |
| training/sac_pi/alpha          | 0.15764764  |
| training/sac_pi/alpha_loss     | 0.058685295 |
| training/sac_pi/logp_pi        | 3.9376545   |
| training/sac_pi/pi_entropy     | 3.4494438   |
| training/sac_pi/pi_global_norm | 1.9135257   |
| training/sac_pi/policy_loss    | -226.9852   |
| training/sac_pi/std            | 0.50146955  |
| training/sac_pi/valid_num      | 4941.0      |
| training/sac_Q/q1              | 216.5938    |
| training/sac_Q/q2              | 216.61905   |
| training/sac_Q/q2_loss         | 109.35551   |
| training/sac_Q/q_global_norm   | 213.13394   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16172245   |
| epoch                          | 750          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5191.1733    |
| evaluation/return-max          | 5221.2515    |
| evaluation/return-min          | 5116.9854    |
| evaluation/return-std          | 31.472519    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.12         |
| model/origin_ret               | 84.9         |
| model/penalty_ret              | 79.3         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46490        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5191.1733    |
| perf/NormalizedReturn          | 1.13         |
| Q-avg                          | 212.09416    |
| Q-std                          | 120.071686   |
| Q_loss                         | 119.97056    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 750          |
| times/epoch_after_hook         | 1.67e-06     |
| times/epoch_before_hook        | 0.000122     |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.000458     |
| times/evaluation_paths         | 33.2         |
| times/timestep_after_hook      | 0.00364      |
| times/timestep_before_hook     | 0.00814      |
| times/train                    | 60.6         |
| timestep                       | 1000         |
| timesteps_total                | 751000       |
| train-steps                    | 751000       |
| training/Q/q1_loss             | 99.68175     |
| training/sac_pi/alpha          | 0.16170487   |
| training/sac_pi/alpha_loss     | -0.053683016 |
| training/sac_pi/logp_pi        | 3.9437943    |
| training/sac_pi/pi_entropy     | 3.3908658    |
| training/sac_pi/pi_global_norm | 1.5240417    |
| training/sac_pi/policy_loss    | -229.39633   |
| training/sac_pi/std            | 0.47196704   |
| training/sac_pi/valid_num      | 4935.0       |
| training/sac_Q/q1              | 216.68523    |
| training/sac_Q/q2              | 217.75935    |
| training/sac_Q/q2_loss         | 99.13756     |
| training/sac_Q/q_global_norm   | 205.35577    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15864757 |
| epoch                          | 751        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5372.059   |
| evaluation/return-max          | 5401.2812  |
| evaluation/return-min          | 5349.1445  |
| evaluation/return-std          | 17.38047   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46293      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5372.059   |
| perf/NormalizedReturn          | 1.17       |
| Q-avg                          | 224.9353   |
| Q-std                          | 132.64958  |
| Q_loss                         | 101.974815 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 751        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 9e-05      |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000635   |
| times/evaluation_paths         | 36.9       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 752000     |
| train-steps                    | 752000     |
| training/Q/q1_loss             | 127.6885   |
| training/sac_pi/alpha          | 0.15862662 |
| training/sac_pi/alpha_loss     | 0.21522637 |
| training/sac_pi/logp_pi        | 3.8936763  |
| training/sac_pi/pi_entropy     | 3.4296997  |
| training/sac_pi/pi_global_norm | 1.6655412  |
| training/sac_pi/policy_loss    | -228.22443 |
| training/sac_pi/std            | 0.47623786 |
| training/sac_pi/valid_num      | 5006.0     |
| training/sac_Q/q1              | 215.7413   |
| training/sac_Q/q2              | 218.26155  |
| training/sac_Q/q2_loss         | 126.82904  |
| training/sac_Q/q_global_norm   | 232.11153  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15732375 |
| epoch                          | 752        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5106.802   |
| evaluation/return-max          | 5265.6235  |
| evaluation/return-min          | 4877.96    |
| evaluation/return-std          | 104.25548  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46467      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5106.802   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 221.89627  |
| Q-std                          | 154.0995   |
| Q_loss                         | 94.403114  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 752        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000834   |
| times/evaluation_paths         | 34.8       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 60.6       |
| timestep                       | 1000       |
| timesteps_total                | 753000     |
| train-steps                    | 753000     |
| training/Q/q1_loss             | 104.8676   |
| training/sac_pi/alpha          | 0.15732376 |
| training/sac_pi/alpha_loss     | -0.22305   |
| training/sac_pi/logp_pi        | 3.9735236  |
| training/sac_pi/pi_entropy     | 3.2319398  |
| training/sac_pi/pi_global_norm | 1.9904859  |
| training/sac_pi/policy_loss    | -231.33551 |
| training/sac_pi/std            | 0.47594935 |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 219.731    |
| training/sac_Q/q2              | 221.10616  |
| training/sac_Q/q2_loss         | 105.28253  |
| training/sac_Q/q_global_norm   | 274.1099   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16153862   |
| epoch                          | 753          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5343.3115    |
| evaluation/return-max          | 5407.5337    |
| evaluation/return-min          | 5017.659     |
| evaluation/return-std          | 109.86139    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.1          |
| model/origin_ret               | 85.1         |
| model/penalty_ret              | 79.9         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46516        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5343.3115    |
| perf/NormalizedReturn          | 1.16         |
| Q-avg                          | 217.24316    |
| Q-std                          | 111.59758    |
| Q_loss                         | 99.73249     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 753          |
| times/epoch_after_hook         | 1.84e-06     |
| times/epoch_before_hook        | 0.000284     |
| times/epoch_rollout_model      | 484          |
| times/evaluation_metrics       | 0.000616     |
| times/evaluation_paths         | 34           |
| times/timestep_after_hook      | 0.00363      |
| times/timestep_before_hook     | 0.00825      |
| times/train                    | 60.7         |
| timestep                       | 1000         |
| timesteps_total                | 754000       |
| train-steps                    | 754000       |
| training/Q/q1_loss             | 104.71578    |
| training/sac_pi/alpha          | 0.16152216   |
| training/sac_pi/alpha_loss     | -0.058397055 |
| training/sac_pi/logp_pi        | 3.9849257    |
| training/sac_pi/pi_entropy     | 3.5417264    |
| training/sac_pi/pi_global_norm | 1.6375895    |
| training/sac_pi/policy_loss    | -220.91383   |
| training/sac_pi/std            | 0.50007737   |
| training/sac_pi/valid_num      | 4963.0       |
| training/sac_Q/q1              | 208.93062    |
| training/sac_Q/q2              | 211.16988    |
| training/sac_Q/q2_loss         | 104.04037    |
| training/sac_Q/q_global_norm   | 295.85443    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16659439 |
| epoch                          | 754        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4834.5127  |
| evaluation/return-max          | 4906.7725  |
| evaluation/return-min          | 4749.491   |
| evaluation/return-std          | 42.389732  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46302      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4834.5127  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 212.1313   |
| Q-std                          | 170.98303  |
| Q_loss                         | 112.11142  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 754        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000148   |
| times/epoch_rollout_model      | 491        |
| times/evaluation_metrics       | 0.000497   |
| times/evaluation_paths         | 34.8       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00806    |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 755000     |
| train-steps                    | 755000     |
| training/Q/q1_loss             | 107.55197  |
| training/sac_pi/alpha          | 0.16663909 |
| training/sac_pi/alpha_loss     | 0.19791013 |
| training/sac_pi/logp_pi        | 3.7898757  |
| training/sac_pi/pi_entropy     | 3.4023197  |
| training/sac_pi/pi_global_norm | 1.669047   |
| training/sac_pi/policy_loss    | -226.06897 |
| training/sac_pi/std            | 0.48029342 |
| training/sac_pi/valid_num      | 5022.0     |
| training/sac_Q/q1              | 219.82129  |
| training/sac_Q/q2              | 220.62784  |
| training/sac_Q/q2_loss         | 107.56061  |
| training/sac_Q/q_global_norm   | 205.83852  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16438837  |
| epoch                          | 755         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5332.9116   |
| evaluation/return-max          | 5381.4473   |
| evaluation/return-min          | 5003.1597   |
| evaluation/return-std          | 110.434875  |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46455       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5332.9116   |
| perf/NormalizedReturn          | 1.16        |
| Q-avg                          | 204.77342   |
| Q-std                          | 210.94362   |
| Q_loss                         | 118.84397   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 755         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.00012     |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000562    |
| times/evaluation_paths         | 35.7        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00838     |
| times/train                    | 60.4        |
| timestep                       | 1000        |
| timesteps_total                | 756000      |
| train-steps                    | 756000      |
| training/Q/q1_loss             | 98.407745   |
| training/sac_pi/alpha          | 0.1644138   |
| training/sac_pi/alpha_loss     | -0.09054305 |
| training/sac_pi/logp_pi        | 4.4706106   |
| training/sac_pi/pi_entropy     | 3.3402221   |
| training/sac_pi/pi_global_norm | 1.9484578   |
| training/sac_pi/policy_loss    | -227.86116  |
| training/sac_pi/std            | 0.4984307   |
| training/sac_pi/valid_num      | 4984.0      |
| training/sac_Q/q1              | 210.80173   |
| training/sac_Q/q2              | 214.06035   |
| training/sac_Q/q2_loss         | 100.10749   |
| training/sac_Q/q_global_norm   | 327.02713   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16912524 |
| epoch                          | 756        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5087.884   |
| evaluation/return-max          | 5159.075   |
| evaluation/return-min          | 5058.8633  |
| evaluation/return-std          | 27.120316  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46439      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5087.884   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 206.06721  |
| Q-std                          | 165.9665   |
| Q_loss                         | 101.43289  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 756        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000588   |
| times/evaluation_paths         | 34.8       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 757000     |
| train-steps                    | 757000     |
| training/Q/q1_loss             | 106.86419  |
| training/sac_pi/alpha          | 0.16908498 |
| training/sac_pi/alpha_loss     | 0.38005638 |
| training/sac_pi/logp_pi        | 4.3804045  |
| training/sac_pi/pi_entropy     | 3.4862676  |
| training/sac_pi/pi_global_norm | 2.2466083  |
| training/sac_pi/policy_loss    | -218.94994 |
| training/sac_pi/std            | 0.4988156  |
| training/sac_pi/valid_num      | 5008.0     |
| training/sac_Q/q1              | 206.43474  |
| training/sac_Q/q2              | 208.44943  |
| training/sac_Q/q2_loss         | 107.84371  |
| training/sac_Q/q_global_norm   | 270.53857  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16726576  |
| epoch                          | 757         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4813.1045   |
| evaluation/return-max          | 4915.1562   |
| evaluation/return-min          | 4726.092    |
| evaluation/return-std          | 52.60717    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 78.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46498       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4813.1045   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 210.2987    |
| Q-std                          | 186.71175   |
| Q_loss                         | 92.2595     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 757         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.00029     |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.00055     |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 60.4        |
| timestep                       | 1000        |
| timesteps_total                | 758000      |
| train-steps                    | 758000      |
| training/Q/q1_loss             | 105.45722   |
| training/sac_pi/alpha          | 0.16726495  |
| training/sac_pi/alpha_loss     | -0.09787122 |
| training/sac_pi/logp_pi        | 4.520674    |
| training/sac_pi/pi_entropy     | 3.3652434   |
| training/sac_pi/pi_global_norm | 1.71232     |
| training/sac_pi/policy_loss    | -227.70377  |
| training/sac_pi/std            | 0.5099039   |
| training/sac_pi/valid_num      | 4943.0      |
| training/sac_Q/q1              | 207.71016   |
| training/sac_Q/q2              | 211.78596   |
| training/sac_Q/q2_loss         | 104.66092   |
| training/sac_Q/q_global_norm   | 237.20695   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16581213 |
| epoch                          | 758        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4962.548   |
| evaluation/return-max          | 5148.209   |
| evaluation/return-min          | 4647.0874  |
| evaluation/return-std          | 160.82411  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46477      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4962.548   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 215.07051  |
| Q-std                          | 185.48062  |
| Q_loss                         | 101.61022  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 758        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000571   |
| times/evaluation_paths         | 35.4       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 62.5       |
| timestep                       | 1000       |
| timesteps_total                | 759000     |
| train-steps                    | 759000     |
| training/Q/q1_loss             | 100.2344   |
| training/sac_pi/alpha          | 0.16584432 |
| training/sac_pi/alpha_loss     | 0.06697155 |
| training/sac_pi/logp_pi        | 4.0879254  |
| training/sac_pi/pi_entropy     | 3.3529625  |
| training/sac_pi/pi_global_norm | 1.5715475  |
| training/sac_pi/policy_loss    | -228.31651 |
| training/sac_pi/std            | 0.47531706 |
| training/sac_pi/valid_num      | 5031.0     |
| training/sac_Q/q1              | 222.88872  |
| training/sac_Q/q2              | 222.72237  |
| training/sac_Q/q2_loss         | 100.8592   |
| training/sac_Q/q_global_norm   | 270.8701   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16478997 |
| epoch                          | 759        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5210.8955  |
| evaluation/return-max          | 5351.0513  |
| evaluation/return-min          | 5082.164   |
| evaluation/return-std          | 89.96453   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46513      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5210.8955  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 219.85832  |
| Q-std                          | 113.013885 |
| Q_loss                         | 101.26508  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 759        |
| times/epoch_after_hook         | 1.97e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000674   |
| times/evaluation_paths         | 34.2       |
| times/timestep_after_hook      | 0.00356    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 760000     |
| train-steps                    | 760000     |
| training/Q/q1_loss             | 94.283356  |
| training/sac_pi/alpha          | 0.16479653 |
| training/sac_pi/alpha_loss     | 0.25983286 |
| training/sac_pi/logp_pi        | 4.185669   |
| training/sac_pi/pi_entropy     | 3.4022584  |
| training/sac_pi/pi_global_norm | 2.6434076  |
| training/sac_pi/policy_loss    | -233.1759  |
| training/sac_pi/std            | 0.4893708  |
| training/sac_pi/valid_num      | 4997.0     |
| training/sac_Q/q1              | 223.9878   |
| training/sac_Q/q2              | 224.57442  |
| training/sac_Q/q2_loss         | 94.79094   |
| training/sac_Q/q_global_norm   | 319.5094   |
--------------------------------------------------------------------------------
[WARN] 760 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.1588735  |
| epoch                          | 760        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5167.081   |
| evaluation/return-max          | 5256.83    |
| evaluation/return-min          | 5065.387   |
| evaluation/return-std          | 58.04069   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46435      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5167.081   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 209.43925  |
| Q-std                          | 152.68028  |
| Q_loss                         | 119.59474  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 760        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.00052    |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 761000     |
| train-steps                    | 761000     |
| training/Q/q1_loss             | 96.70332   |
| training/sac_pi/alpha          | 0.15888457 |
| training/sac_pi/alpha_loss     | 0.23414516 |
| training/sac_pi/logp_pi        | 3.9922314  |
| training/sac_pi/pi_entropy     | 3.364254   |
| training/sac_pi/pi_global_norm | 1.9910554  |
| training/sac_pi/policy_loss    | -222.74829 |
| training/sac_pi/std            | 0.48051345 |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 209.57549  |
| training/sac_Q/q2              | 211.86783  |
| training/sac_Q/q2_loss         | 96.14326   |
| training/sac_Q/q_global_norm   | 175.43382  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16384692  |
| epoch                          | 761         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5005.331    |
| evaluation/return-max          | 5208.455    |
| evaluation/return-min          | 4844.2246   |
| evaluation/return-std          | 117.80954   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 78.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46392       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5005.331    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 207.5852    |
| Q-std                          | 171.61452   |
| Q_loss                         | 108.96663   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 761         |
| times/epoch_after_hook         | 2.9e-06     |
| times/epoch_before_hook        | 0.000276    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000571    |
| times/evaluation_paths         | 36.5        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00839     |
| times/train                    | 60.1        |
| timestep                       | 1000        |
| timesteps_total                | 762000      |
| train-steps                    | 762000      |
| training/Q/q1_loss             | 102.11831   |
| training/sac_pi/alpha          | 0.16385321  |
| training/sac_pi/alpha_loss     | -0.08878912 |
| training/sac_pi/logp_pi        | 4.98919     |
| training/sac_pi/pi_entropy     | 3.3900528   |
| training/sac_pi/pi_global_norm | 1.7637762   |
| training/sac_pi/policy_loss    | -227.80638  |
| training/sac_pi/std            | 0.5181946   |
| training/sac_pi/valid_num      | 4920.0      |
| training/sac_Q/q1              | 209.05331   |
| training/sac_Q/q2              | 209.0563    |
| training/sac_Q/q2_loss         | 102.95499   |
| training/sac_Q/q_global_norm   | 256.4037    |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16355373   |
| epoch                          | 762          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5008.6396    |
| evaluation/return-max          | 5045.372     |
| evaluation/return-min          | 4925.598     |
| evaluation/return-std          | 32.6757      |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.11         |
| model/origin_ret               | 85.4         |
| model/penalty_ret              | 79           |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46412        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5008.6396    |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 208.76787    |
| Q-std                          | 184.95045    |
| Q_loss                         | 109.242805   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 762          |
| times/epoch_after_hook         | 1.8e-06      |
| times/epoch_before_hook        | 0.000131     |
| times/epoch_rollout_model      | 489          |
| times/evaluation_metrics       | 0.000602     |
| times/evaluation_paths         | 35           |
| times/timestep_after_hook      | 0.00371      |
| times/timestep_before_hook     | 0.00828      |
| times/train                    | 59.8         |
| timestep                       | 1000         |
| timesteps_total                | 763000       |
| train-steps                    | 763000       |
| training/Q/q1_loss             | 103.70825    |
| training/sac_pi/alpha          | 0.1635547    |
| training/sac_pi/alpha_loss     | -0.116230436 |
| training/sac_pi/logp_pi        | 3.979838     |
| training/sac_pi/pi_entropy     | 3.2337792    |
| training/sac_pi/pi_global_norm | 2.3308349    |
| training/sac_pi/policy_loss    | -221.61444   |
| training/sac_pi/std            | 0.4724231    |
| training/sac_pi/valid_num      | 4970.0       |
| training/sac_Q/q1              | 209.89636    |
| training/sac_Q/q2              | 211.56963    |
| training/sac_Q/q2_loss         | 102.88218    |
| training/sac_Q/q_global_norm   | 356.53732    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1631092  |
| epoch                          | 763        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5068.6533  |
| evaluation/return-max          | 5130.7285  |
| evaluation/return-min          | 5008.4463  |
| evaluation/return-std          | 42.972595  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 84.8       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46457      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5068.6533  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 211.04358  |
| Q-std                          | 147.86736  |
| Q_loss                         | 99.52898   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 763        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000529   |
| times/evaluation_paths         | 34.9       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 62.5       |
| timestep                       | 1000       |
| timesteps_total                | 764000     |
| train-steps                    | 764000     |
| training/Q/q1_loss             | 111.05081  |
| training/sac_pi/alpha          | 0.16311175 |
| training/sac_pi/alpha_loss     | 0.42576325 |
| training/sac_pi/logp_pi        | 4.4344616  |
| training/sac_pi/pi_entropy     | 3.450108   |
| training/sac_pi/pi_global_norm | 1.7965314  |
| training/sac_pi/policy_loss    | -221.80038 |
| training/sac_pi/std            | 0.5053574  |
| training/sac_pi/valid_num      | 4989.0     |
| training/sac_Q/q1              | 212.88899  |
| training/sac_Q/q2              | 214.29903  |
| training/sac_Q/q2_loss         | 110.340775 |
| training/sac_Q/q_global_norm   | 287.0204   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1665531  |
| epoch                          | 764        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5188.9976  |
| evaluation/return-max          | 5274.829   |
| evaluation/return-min          | 5092.9834  |
| evaluation/return-std          | 47.496292  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46463      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5188.9976  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 221.37637  |
| Q-std                          | 131.53783  |
| Q_loss                         | 113.61595  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 764        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 64         |
| timestep                       | 1000       |
| timesteps_total                | 765000     |
| train-steps                    | 765000     |
| training/Q/q1_loss             | 107.81031  |
| training/sac_pi/alpha          | 0.16659635 |
| training/sac_pi/alpha_loss     | -0.6481028 |
| training/sac_pi/logp_pi        | 4.956097   |
| training/sac_pi/pi_entropy     | 3.6952965  |
| training/sac_pi/pi_global_norm | 1.822338   |
| training/sac_pi/policy_loss    | -231.72815 |
| training/sac_pi/std            | 0.5701369  |
| training/sac_pi/valid_num      | 4873.0     |
| training/sac_Q/q1              | 211.33134  |
| training/sac_Q/q2              | 212.98946  |
| training/sac_Q/q2_loss         | 107.72955  |
| training/sac_Q/q_global_norm   | 291.15936  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17046346 |
| epoch                          | 765        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5181.763   |
| evaluation/return-max          | 5249.7275  |
| evaluation/return-min          | 5088.8457  |
| evaluation/return-std          | 46.19474   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46227      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5181.763   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 230.6445   |
| Q-std                          | 88.27852   |
| Q_loss                         | 97.94552   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 765        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000288   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000552   |
| times/evaluation_paths         | 35.8       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 766000     |
| train-steps                    | 766000     |
| training/Q/q1_loss             | 109.54036  |
| training/sac_pi/alpha          | 0.17044792 |
| training/sac_pi/alpha_loss     | 0.19517133 |
| training/sac_pi/logp_pi        | 4.5185843  |
| training/sac_pi/pi_entropy     | 3.5502312  |
| training/sac_pi/pi_global_norm | 1.6495869  |
| training/sac_pi/policy_loss    | -234.03539 |
| training/sac_pi/std            | 0.5121136  |
| training/sac_pi/valid_num      | 4960.0     |
| training/sac_Q/q1              | 221.84993  |
| training/sac_Q/q2              | 221.45749  |
| training/sac_Q/q2_loss         | 109.11872  |
| training/sac_Q/q_global_norm   | 238.42834  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16449629 |
| epoch                          | 766        |
| evaluation/episode-length-avg  | 928        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 600        |
| evaluation/episode-length-std  | 130        |
| evaluation/return-average      | 4685.8486  |
| evaluation/return-max          | 5143.0254  |
| evaluation/return-min          | 2864.146   |
| evaluation/return-std          | 711.0913   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 87         |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46263      |
| perf/AverageLength             | 928        |
| perf/AverageReturn             | 4685.8486  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 207.06503  |
| Q-std                          | 218.60037  |
| Q_loss                         | 97.41124   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 766        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000555   |
| times/evaluation_paths         | 36.1       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 767000     |
| train-steps                    | 767000     |
| training/Q/q1_loss             | 114.61929  |
| training/sac_pi/alpha          | 0.16455261 |
| training/sac_pi/alpha_loss     | -0.2581534 |
| training/sac_pi/logp_pi        | 3.7011807  |
| training/sac_pi/pi_entropy     | 3.611668   |
| training/sac_pi/pi_global_norm | 2.1267211  |
| training/sac_pi/policy_loss    | -231.14992 |
| training/sac_pi/std            | 0.49661478 |
| training/sac_pi/valid_num      | 4991.0     |
| training/sac_Q/q1              | 221.4456   |
| training/sac_Q/q2              | 222.6088   |
| training/sac_Q/q2_loss         | 114.976    |
| training/sac_Q/q_global_norm   | 219.6967   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16018246  |
| epoch                          | 767         |
| evaluation/episode-length-avg  | 410         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 156         |
| evaluation/episode-length-std  | 386         |
| evaluation/return-average      | 1868.2946   |
| evaluation/return-max          | 5122.6694   |
| evaluation/return-min          | 488.32672   |
| evaluation/return-std          | 2100.0862   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46350       |
| perf/AverageLength             | 410         |
| perf/AverageReturn             | 1868.2946   |
| perf/NormalizedReturn          | 0.407       |
| Q-avg                          | 215.83963   |
| Q-std                          | 110.69958   |
| Q_loss                         | 119.58468   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 767         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000468    |
| times/evaluation_paths         | 19.4        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00824     |
| times/train                    | 66.9        |
| timestep                       | 1000        |
| timesteps_total                | 768000      |
| train-steps                    | 768000      |
| training/Q/q1_loss             | 108.0348    |
| training/sac_pi/alpha          | 0.16017313  |
| training/sac_pi/alpha_loss     | -0.13803957 |
| training/sac_pi/logp_pi        | 4.8895187   |
| training/sac_pi/pi_entropy     | 3.412133    |
| training/sac_pi/pi_global_norm | 1.6212682   |
| training/sac_pi/policy_loss    | -227.13951  |
| training/sac_pi/std            | 0.53189284  |
| training/sac_pi/valid_num      | 4952.0      |
| training/sac_Q/q1              | 211.22104   |
| training/sac_Q/q2              | 212.91617   |
| training/sac_Q/q2_loss         | 107.613266  |
| training/sac_Q/q_global_norm   | 165.57802   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16382198 |
| epoch                          | 768        |
| evaluation/episode-length-avg  | 916        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 161        |
| evaluation/episode-length-std  | 252        |
| evaluation/return-average      | 4578.033   |
| evaluation/return-max          | 5110.134   |
| evaluation/return-min          | 524.8642   |
| evaluation/return-std          | 1352.2927  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46582      |
| perf/AverageLength             | 916        |
| perf/AverageReturn             | 4578.033   |
| perf/NormalizedReturn          | 0.997      |
| Q-avg                          | 213.75064  |
| Q-std                          | 159.04384  |
| Q_loss                         | 100.26253  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 768        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000608   |
| times/evaluation_paths         | 42.7       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 61.2       |
| timestep                       | 1000       |
| timesteps_total                | 769000     |
| train-steps                    | 769000     |
| training/Q/q1_loss             | 99.91186   |
| training/sac_pi/alpha          | 0.16381043 |
| training/sac_pi/alpha_loss     | -0.2890228 |
| training/sac_pi/logp_pi        | 3.8485234  |
| training/sac_pi/pi_entropy     | 3.6478164  |
| training/sac_pi/pi_global_norm | 1.6781389  |
| training/sac_pi/policy_loss    | -226.81442 |
| training/sac_pi/std            | 0.522473   |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 216.26616  |
| training/sac_Q/q2              | 218.49438  |
| training/sac_Q/q2_loss         | 99.89428   |
| training/sac_Q/q_global_norm   | 230.16565  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16576378 |
| epoch                          | 769        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5103.7754  |
| evaluation/return-max          | 5159.618   |
| evaluation/return-min          | 5023.168   |
| evaluation/return-std          | 39.83206   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46370      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5103.7754  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 220.2629   |
| Q-std                          | 106.63471  |
| Q_loss                         | 108.407845 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 769        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000295   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.0005     |
| times/evaluation_paths         | 39.6       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 72         |
| timestep                       | 1000       |
| timesteps_total                | 770000     |
| train-steps                    | 770000     |
| training/Q/q1_loss             | 106.36012  |
| training/sac_pi/alpha          | 0.1657657  |
| training/sac_pi/alpha_loss     | 0.27049068 |
| training/sac_pi/logp_pi        | 3.6604278  |
| training/sac_pi/pi_entropy     | 3.4010758  |
| training/sac_pi/pi_global_norm | 1.5731418  |
| training/sac_pi/policy_loss    | -232.0713  |
| training/sac_pi/std            | 0.4767298  |
| training/sac_pi/valid_num      | 5016.0     |
| training/sac_Q/q1              | 226.64633  |
| training/sac_Q/q2              | 227.302    |
| training/sac_Q/q2_loss         | 106.080605 |
| training/sac_Q/q_global_norm   | 190.87189  |
--------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.16491802    |
| epoch                          | 770           |
| evaluation/episode-length-avg  | 1e+03         |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 1000          |
| evaluation/episode-length-std  | 0             |
| evaluation/return-average      | 5125.9663     |
| evaluation/return-max          | 5181.508      |
| evaluation/return-min          | 5015.6533     |
| evaluation/return-std          | 43.871643     |
| model/max_penalty              | 7.24          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 3.17          |
| model/origin_ret               | 86.4          |
| model/penalty_ret              | 79.2          |
| model/val_loss                 | 0.40512508    |
| model/valid_num                | 46586         |
| perf/AverageLength             | 1e+03         |
| perf/AverageReturn             | 5125.9663     |
| perf/NormalizedReturn          | 1.12          |
| Q-avg                          | 217.16867     |
| Q-std                          | 151.2751      |
| Q_loss                         | 111.82036     |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 770           |
| times/epoch_after_hook         | 1.68e-06      |
| times/epoch_before_hook        | 0.000131      |
| times/epoch_rollout_model      | 477           |
| times/evaluation_metrics       | 0.0006        |
| times/evaluation_paths         | 42.2          |
| times/timestep_after_hook      | 0.00367       |
| times/timestep_before_hook     | 0.00829       |
| times/train                    | 69            |
| timestep                       | 1000          |
| timesteps_total                | 771000        |
| train-steps                    | 771000        |
| training/Q/q1_loss             | 102.03742     |
| training/sac_pi/alpha          | 0.16490036    |
| training/sac_pi/alpha_loss     | -0.0044383924 |
| training/sac_pi/logp_pi        | 3.733827      |
| training/sac_pi/pi_entropy     | 3.620901      |
| training/sac_pi/pi_global_norm | 2.3092759     |
| training/sac_pi/policy_loss    | -223.36842    |
| training/sac_pi/std            | 0.49473915    |
| training/sac_pi/valid_num      | 5015.0        |
| training/sac_Q/q1              | 216.01636     |
| training/sac_Q/q2              | 217.2604      |
| training/sac_Q/q2_loss         | 101.373245    |
| training/sac_Q/q_global_norm   | 284.07147     |
-----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1646192   |
| epoch                          | 771         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5216.9214   |
| evaluation/return-max          | 5258.2627   |
| evaluation/return-min          | 5141.1934   |
| evaluation/return-std          | 32.012547   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 87.4        |
| model/penalty_ret              | 80.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46257       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5216.9214   |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 215.6864    |
| Q-std                          | 137.62361   |
| Q_loss                         | 106.44837   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 771         |
| times/epoch_after_hook         | 1.52e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000625    |
| times/evaluation_paths         | 34.9        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 60          |
| timestep                       | 1000        |
| timesteps_total                | 772000      |
| train-steps                    | 772000      |
| training/Q/q1_loss             | 112.09571   |
| training/sac_pi/alpha          | 0.16461153  |
| training/sac_pi/alpha_loss     | -0.10212993 |
| training/sac_pi/logp_pi        | 4.238767    |
| training/sac_pi/pi_entropy     | 3.3560104   |
| training/sac_pi/pi_global_norm | 2.4033568   |
| training/sac_pi/policy_loss    | -228.14949  |
| training/sac_pi/std            | 0.48921096  |
| training/sac_pi/valid_num      | 4997.0      |
| training/sac_Q/q1              | 212.998     |
| training/sac_Q/q2              | 216.59048   |
| training/sac_Q/q2_loss         | 112.42817   |
| training/sac_Q/q_global_norm   | 244.4768    |
---------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.16922283    |
| epoch                          | 772           |
| evaluation/episode-length-avg  | 1e+03         |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 1000          |
| evaluation/episode-length-std  | 0             |
| evaluation/return-average      | 5227.324      |
| evaluation/return-max          | 5292.1157     |
| evaluation/return-min          | 5182.8574     |
| evaluation/return-std          | 30.763796     |
| model/max_penalty              | 7.24          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 3.06          |
| model/origin_ret               | 85.3          |
| model/penalty_ret              | 79.6          |
| model/val_loss                 | 0.40512508    |
| model/valid_num                | 46317         |
| perf/AverageLength             | 1e+03         |
| perf/AverageReturn             | 5227.324      |
| perf/NormalizedReturn          | 1.14          |
| Q-avg                          | 216.4257      |
| Q-std                          | 147.76471     |
| Q_loss                         | 105.19784     |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 772           |
| times/epoch_after_hook         | 1.76e-06      |
| times/epoch_before_hook        | 0.000251      |
| times/epoch_rollout_model      | 483           |
| times/evaluation_metrics       | 0.000566      |
| times/evaluation_paths         | 34.9          |
| times/timestep_after_hook      | 0.00364       |
| times/timestep_before_hook     | 0.00839       |
| times/train                    | 61.2          |
| timestep                       | 1000          |
| timesteps_total                | 773000        |
| train-steps                    | 773000        |
| training/Q/q1_loss             | 110.96784     |
| training/sac_pi/alpha          | 0.16921134    |
| training/sac_pi/alpha_loss     | -0.0109916525 |
| training/sac_pi/logp_pi        | 4.680114      |
| training/sac_pi/pi_entropy     | 3.6473038     |
| training/sac_pi/pi_global_norm | 1.8065548     |
| training/sac_pi/policy_loss    | -221.38245    |
| training/sac_pi/std            | 0.5387042     |
| training/sac_pi/valid_num      | 4952.0        |
| training/sac_Q/q1              | 203.50418     |
| training/sac_Q/q2              | 207.84143     |
| training/sac_Q/q2_loss         | 110.69308     |
| training/sac_Q/q_global_norm   | 264.9096      |
-----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16329935  |
| epoch                          | 773         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5011.0474   |
| evaluation/return-max          | 5139.3247   |
| evaluation/return-min          | 4840.1963   |
| evaluation/return-std          | 81.40931    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.17        |
| model/origin_ret               | 87.2        |
| model/penalty_ret              | 80.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46409       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5011.0474   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 213.7688    |
| Q-std                          | 156.07976   |
| Q_loss                         | 91.17833    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 773         |
| times/epoch_after_hook         | 1.85e-06    |
| times/epoch_before_hook        | 0.000304    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000599    |
| times/evaluation_paths         | 45.6        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00833     |
| times/train                    | 62.2        |
| timestep                       | 1000        |
| timesteps_total                | 774000      |
| train-steps                    | 774000      |
| training/Q/q1_loss             | 100.20641   |
| training/sac_pi/alpha          | 0.16330104  |
| training/sac_pi/alpha_loss     | 0.028730145 |
| training/sac_pi/logp_pi        | 4.419543    |
| training/sac_pi/pi_entropy     | 3.2159905   |
| training/sac_pi/pi_global_norm | 2.5340135   |
| training/sac_pi/policy_loss    | -226.86655  |
| training/sac_pi/std            | 0.48201296  |
| training/sac_pi/valid_num      | 4921.0      |
| training/sac_Q/q1              | 210.5936    |
| training/sac_Q/q2              | 215.15451   |
| training/sac_Q/q2_loss         | 100.24189   |
| training/sac_Q/q_global_norm   | 207.96852   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16018848 |
| epoch                          | 774        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4995.1865  |
| evaluation/return-max          | 5077.6924  |
| evaluation/return-min          | 4842.537   |
| evaluation/return-std          | 69.57277   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 78.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46517      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4995.1865  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 218.20273  |
| Q-std                          | 113.08726  |
| Q_loss                         | 80.41203   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 774        |
| times/epoch_after_hook         | 1.59e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.00052    |
| times/evaluation_paths         | 46.9       |
| times/timestep_after_hook      | 0.00353    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 61.7       |
| timestep                       | 1000       |
| timesteps_total                | 775000     |
| train-steps                    | 775000     |
| training/Q/q1_loss             | 93.80195   |
| training/sac_pi/alpha          | 0.16016093 |
| training/sac_pi/alpha_loss     | 0.08066029 |
| training/sac_pi/logp_pi        | 3.7891116  |
| training/sac_pi/pi_entropy     | 3.2233956  |
| training/sac_pi/pi_global_norm | 3.4256716  |
| training/sac_pi/policy_loss    | -227.04176 |
| training/sac_pi/std            | 0.46309236 |
| training/sac_pi/valid_num      | 4963.0     |
| training/sac_Q/q1              | 214.79468  |
| training/sac_Q/q2              | 217.05078  |
| training/sac_Q/q2_loss         | 95.10051   |
| training/sac_Q/q_global_norm   | 260.41342  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16501446  |
| epoch                          | 775         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4903.3774   |
| evaluation/return-max          | 5094.695    |
| evaluation/return-min          | 4716.884    |
| evaluation/return-std          | 122.97339   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46476       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4903.3774   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 215.41267   |
| Q-std                          | 110.94641   |
| Q_loss                         | 107.2581    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 775         |
| times/epoch_after_hook         | 1.6e-06     |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000557    |
| times/evaluation_paths         | 33.5        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 59.5        |
| timestep                       | 1000        |
| timesteps_total                | 776000      |
| train-steps                    | 776000      |
| training/Q/q1_loss             | 107.99853   |
| training/sac_pi/alpha          | 0.16504319  |
| training/sac_pi/alpha_loss     | -0.14069049 |
| training/sac_pi/logp_pi        | 4.100019    |
| training/sac_pi/pi_entropy     | 3.456958    |
| training/sac_pi/pi_global_norm | 1.9852778   |
| training/sac_pi/policy_loss    | -225.91568  |
| training/sac_pi/std            | 0.5050642   |
| training/sac_pi/valid_num      | 4926.0      |
| training/sac_Q/q1              | 211.49727   |
| training/sac_Q/q2              | 211.53413   |
| training/sac_Q/q2_loss         | 108.62728   |
| training/sac_Q/q_global_norm   | 232.18126   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16362695 |
| epoch                          | 776        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5120.1455  |
| evaluation/return-max          | 5218.964   |
| evaluation/return-min          | 5037.6826  |
| evaluation/return-std          | 64.44433   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 78.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46305      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5120.1455  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 214.08154  |
| Q-std                          | 136.65019  |
| Q_loss                         | 113.596855 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 776        |
| times/epoch_after_hook         | 1.65e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000576   |
| times/evaluation_paths         | 37.1       |
| times/timestep_after_hook      | 0.0035     |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 777000     |
| train-steps                    | 777000     |
| training/Q/q1_loss             | 104.06854  |
| training/sac_pi/alpha          | 0.1636592  |
| training/sac_pi/alpha_loss     | 0.11031112 |
| training/sac_pi/logp_pi        | 3.8196125  |
| training/sac_pi/pi_entropy     | 3.3698876  |
| training/sac_pi/pi_global_norm | 2.3577273  |
| training/sac_pi/policy_loss    | -228.56487 |
| training/sac_pi/std            | 0.48117357 |
| training/sac_pi/valid_num      | 4974.0     |
| training/sac_Q/q1              | 215.56755  |
| training/sac_Q/q2              | 218.99529  |
| training/sac_Q/q2_loss         | 103.688354 |
| training/sac_Q/q_global_norm   | 233.19456  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15897708  |
| epoch                          | 777         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5285.405    |
| evaluation/return-max          | 5512.1353   |
| evaluation/return-min          | 5133.1787   |
| evaluation/return-std          | 119.08524   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46561       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5285.405    |
| perf/NormalizedReturn          | 1.15        |
| Q-avg                          | 216.89482   |
| Q-std                          | 140.77835   |
| Q_loss                         | 95.49652    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 777         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000292    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000513    |
| times/evaluation_paths         | 37.8        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00822     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 778000      |
| train-steps                    | 778000      |
| training/Q/q1_loss             | 100.33519   |
| training/sac_pi/alpha          | 0.15894923  |
| training/sac_pi/alpha_loss     | -0.16018374 |
| training/sac_pi/logp_pi        | 4.4458256   |
| training/sac_pi/pi_entropy     | 3.3733888   |
| training/sac_pi/pi_global_norm | 1.5801171   |
| training/sac_pi/policy_loss    | -227.95581  |
| training/sac_pi/std            | 0.5084218   |
| training/sac_pi/valid_num      | 5004.0      |
| training/sac_Q/q1              | 212.70683   |
| training/sac_Q/q2              | 218.53418   |
| training/sac_Q/q2_loss         | 99.887886   |
| training/sac_Q/q_global_norm   | 213.45819   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16405427 |
| epoch                          | 778        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5290.267   |
| evaluation/return-max          | 5315.1855  |
| evaluation/return-min          | 5232.7686  |
| evaluation/return-std          | 21.072218  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46317      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5290.267   |
| perf/NormalizedReturn          | 1.15       |
| Q-avg                          | 220.19983  |
| Q-std                          | 122.10877  |
| Q_loss                         | 99.66493   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 778        |
| times/epoch_after_hook         | 2.87e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000535   |
| times/evaluation_paths         | 36.1       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 60         |
| timestep                       | 1000       |
| timesteps_total                | 779000     |
| train-steps                    | 779000     |
| training/Q/q1_loss             | 121.09703  |
| training/sac_pi/alpha          | 0.1640586  |
| training/sac_pi/alpha_loss     | 0.14766341 |
| training/sac_pi/logp_pi        | 3.9919357  |
| training/sac_pi/pi_entropy     | 3.4679928  |
| training/sac_pi/pi_global_norm | 1.7886084  |
| training/sac_pi/policy_loss    | -226.44061 |
| training/sac_pi/std            | 0.48511925 |
| training/sac_pi/valid_num      | 4986.0     |
| training/sac_Q/q1              | 215.51372  |
| training/sac_Q/q2              | 219.44951  |
| training/sac_Q/q2_loss         | 121.61491  |
| training/sac_Q/q_global_norm   | 188.37242  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16250007 |
| epoch                          | 779        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5134.455   |
| evaluation/return-max          | 5165.9946  |
| evaluation/return-min          | 5058.4307  |
| evaluation/return-std          | 29.549868  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.18       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46385      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5134.455   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 217.39865  |
| Q-std                          | 130.16785  |
| Q_loss                         | 133.8921   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 779        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000487   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 780000     |
| train-steps                    | 780000     |
| training/Q/q1_loss             | 118.56362  |
| training/sac_pi/alpha          | 0.16244707 |
| training/sac_pi/alpha_loss     | 0.32457593 |
| training/sac_pi/logp_pi        | 4.162181   |
| training/sac_pi/pi_entropy     | 3.490057   |
| training/sac_pi/pi_global_norm | 1.6626767  |
| training/sac_pi/policy_loss    | -227.92783 |
| training/sac_pi/std            | 0.5100877  |
| training/sac_pi/valid_num      | 4974.0     |
| training/sac_Q/q1              | 213.75186  |
| training/sac_Q/q2              | 215.50761  |
| training/sac_Q/q2_loss         | 119.356544 |
| training/sac_Q/q_global_norm   | 285.01352  |
--------------------------------------------------------------------------------
[WARN] 780 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.15930736 |
| epoch                          | 780        |
| evaluation/episode-length-avg  | 832        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 159        |
| evaluation/episode-length-std  | 336        |
| evaluation/return-average      | 4177.641   |
| evaluation/return-max          | 5154.0757  |
| evaluation/return-min          | 455.81036  |
| evaluation/return-std          | 1858.1338  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46331      |
| perf/AverageLength             | 832        |
| perf/AverageReturn             | 4177.641   |
| perf/NormalizedReturn          | 0.91       |
| Q-avg                          | 202.02164  |
| Q-std                          | 172.0291   |
| Q_loss                         | 109.83959  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 780        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000654   |
| times/evaluation_paths         | 28.7       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 781000     |
| train-steps                    | 781000     |
| training/Q/q1_loss             | 110.09968  |
| training/sac_pi/alpha          | 0.15926765 |
| training/sac_pi/alpha_loss     | 0.41665295 |
| training/sac_pi/logp_pi        | 4.854879   |
| training/sac_pi/pi_entropy     | 3.20061    |
| training/sac_pi/pi_global_norm | 1.8854601  |
| training/sac_pi/policy_loss    | -224.85014 |
| training/sac_pi/std            | 0.47571653 |
| training/sac_pi/valid_num      | 4909.0     |
| training/sac_Q/q1              | 208.23788  |
| training/sac_Q/q2              | 207.79166  |
| training/sac_Q/q2_loss         | 111.378334 |
| training/sac_Q/q_global_norm   | 241.42691  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16205133  |
| epoch                          | 781         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5104.7583   |
| evaluation/return-max          | 5147.177    |
| evaluation/return-min          | 5073.252    |
| evaluation/return-std          | 19.94814    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 85.1        |
| model/penalty_ret              | 78.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46584       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5104.7583   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 207.21858   |
| Q-std                          | 138.81207   |
| Q_loss                         | 89.53228    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 781         |
| times/epoch_after_hook         | 1.66e-06    |
| times/epoch_before_hook        | 0.000276    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.000561    |
| times/evaluation_paths         | 33.5        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 782000      |
| train-steps                    | 782000      |
| training/Q/q1_loss             | 73.87543    |
| training/sac_pi/alpha          | 0.16204098  |
| training/sac_pi/alpha_loss     | 0.014010072 |
| training/sac_pi/logp_pi        | 3.942393    |
| training/sac_pi/pi_entropy     | 3.2250504   |
| training/sac_pi/pi_global_norm | 1.955575    |
| training/sac_pi/policy_loss    | -230.72148  |
| training/sac_pi/std            | 0.46325633  |
| training/sac_pi/valid_num      | 5011.0      |
| training/sac_Q/q1              | 221.28923   |
| training/sac_Q/q2              | 222.93442   |
| training/sac_Q/q2_loss         | 74.11056    |
| training/sac_Q/q_global_norm   | 139.4181    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16046281  |
| epoch                          | 782         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4773.0435   |
| evaluation/return-max          | 4856.3467   |
| evaluation/return-min          | 4721.034    |
| evaluation/return-std          | 42.289078   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46501       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4773.0435   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 219.28134   |
| Q-std                          | 143.36537   |
| Q_loss                         | 114.18605   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 782         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000501    |
| times/evaluation_paths         | 35.1        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00829     |
| times/train                    | 60.3        |
| timestep                       | 1000        |
| timesteps_total                | 783000      |
| train-steps                    | 783000      |
| training/Q/q1_loss             | 106.95245   |
| training/sac_pi/alpha          | 0.16045547  |
| training/sac_pi/alpha_loss     | -0.08841926 |
| training/sac_pi/logp_pi        | 4.888489    |
| training/sac_pi/pi_entropy     | 3.3389263   |
| training/sac_pi/pi_global_norm | 1.6821195   |
| training/sac_pi/policy_loss    | -230.42854  |
| training/sac_pi/std            | 0.5015668   |
| training/sac_pi/valid_num      | 4893.0      |
| training/sac_Q/q1              | 210.23555   |
| training/sac_Q/q2              | 213.87138   |
| training/sac_Q/q2_loss         | 107.7413    |
| training/sac_Q/q_global_norm   | 243.1428    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1631776  |
| epoch                          | 783        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5034.5264  |
| evaluation/return-max          | 5124.879   |
| evaluation/return-min          | 4925.7695  |
| evaluation/return-std          | 64.37393   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46630      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5034.5264  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 214.52144  |
| Q-std                          | 140.64255  |
| Q_loss                         | 93.40301   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 783        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000112   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000496   |
| times/evaluation_paths         | 36.3       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 59.5       |
| timestep                       | 1000       |
| timesteps_total                | 784000     |
| train-steps                    | 784000     |
| training/Q/q1_loss             | 119.93289  |
| training/sac_pi/alpha          | 0.16315795 |
| training/sac_pi/alpha_loss     | 0.41300097 |
| training/sac_pi/logp_pi        | 4.3465667  |
| training/sac_pi/pi_entropy     | 3.6380825  |
| training/sac_pi/pi_global_norm | 1.81029    |
| training/sac_pi/policy_loss    | -225.07147 |
| training/sac_pi/std            | 0.5212514  |
| training/sac_pi/valid_num      | 4934.0     |
| training/sac_Q/q1              | 208.50737  |
| training/sac_Q/q2              | 210.32036  |
| training/sac_Q/q2_loss         | 118.79023  |
| training/sac_Q/q_global_norm   | 186.45663  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16106278 |
| epoch                          | 784        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5198.717   |
| evaluation/return-max          | 5314.6885  |
| evaluation/return-min          | 5067.801   |
| evaluation/return-std          | 72.129944  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46389      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5198.717   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 222.13098  |
| Q-std                          | 152.89003  |
| Q_loss                         | 105.27468  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 784        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000573   |
| times/evaluation_paths         | 34.1       |
| times/timestep_after_hook      | 0.00349    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 60.7       |
| timestep                       | 1000       |
| timesteps_total                | 785000     |
| train-steps                    | 785000     |
| training/Q/q1_loss             | 113.951096 |
| training/sac_pi/alpha          | 0.16106941 |
| training/sac_pi/alpha_loss     | 0.2135458  |
| training/sac_pi/logp_pi        | 4.569362   |
| training/sac_pi/pi_entropy     | 3.3933263  |
| training/sac_pi/pi_global_norm | 1.7779639  |
| training/sac_pi/policy_loss    | -228.43767 |
| training/sac_pi/std            | 0.50428027 |
| training/sac_pi/valid_num      | 4987.0     |
| training/sac_Q/q1              | 212.11124  |
| training/sac_Q/q2              | 218.24277  |
| training/sac_Q/q2_loss         | 113.74284  |
| training/sac_Q/q_global_norm   | 186.30836  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1627096   |
| epoch                          | 785         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5350.121    |
| evaluation/return-max          | 5430.9062   |
| evaluation/return-min          | 5169.956    |
| evaluation/return-std          | 96.94501    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46518       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5350.121    |
| perf/NormalizedReturn          | 1.17        |
| Q-avg                          | 211.70248   |
| Q-std                          | 141.7833    |
| Q_loss                         | 93.42314    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 785         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000283    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000611    |
| times/evaluation_paths         | 37          |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 60          |
| timestep                       | 1000        |
| timesteps_total                | 786000      |
| train-steps                    | 786000      |
| training/Q/q1_loss             | 109.27245   |
| training/sac_pi/alpha          | 0.16270088  |
| training/sac_pi/alpha_loss     | 0.052166294 |
| training/sac_pi/logp_pi        | 4.1655846   |
| training/sac_pi/pi_entropy     | 3.4757228   |
| training/sac_pi/pi_global_norm | 1.6273421   |
| training/sac_pi/policy_loss    | -228.3995   |
| training/sac_pi/std            | 0.48587596  |
| training/sac_pi/valid_num      | 5019.0      |
| training/sac_Q/q1              | 221.44756   |
| training/sac_Q/q2              | 223.99483   |
| training/sac_Q/q2_loss         | 109.65082   |
| training/sac_Q/q_global_norm   | 211.252     |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16501409  |
| epoch                          | 786         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5094.2773   |
| evaluation/return-max          | 5215.5513   |
| evaluation/return-min          | 4990.8574   |
| evaluation/return-std          | 68.38389    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86          |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46372       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5094.2773   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 218.88565   |
| Q-std                          | 137.50328   |
| Q_loss                         | 100.711655  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 786         |
| times/epoch_after_hook         | 3.09e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000575    |
| times/evaluation_paths         | 33.4        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 60.5        |
| timestep                       | 1000        |
| timesteps_total                | 787000      |
| train-steps                    | 787000      |
| training/Q/q1_loss             | 118.40588   |
| training/sac_pi/alpha          | 0.1650104   |
| training/sac_pi/alpha_loss     | -0.13227609 |
| training/sac_pi/logp_pi        | 3.6886287   |
| training/sac_pi/pi_entropy     | 3.3224473   |
| training/sac_pi/pi_global_norm | 2.2181756   |
| training/sac_pi/policy_loss    | -239.20651  |
| training/sac_pi/std            | 0.47642434  |
| training/sac_pi/valid_num      | 4992.0      |
| training/sac_Q/q1              | 230.16634   |
| training/sac_Q/q2              | 231.58379   |
| training/sac_Q/q2_loss         | 115.62356   |
| training/sac_Q/q_global_norm   | 198.30887   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16438803   |
| epoch                          | 787          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5142.4355    |
| evaluation/return-max          | 5214.593     |
| evaluation/return-min          | 5080.1973    |
| evaluation/return-std          | 45.0201      |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.11         |
| model/origin_ret               | 86.1         |
| model/penalty_ret              | 79.8         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46487        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5142.4355    |
| perf/NormalizedReturn          | 1.12         |
| Q-avg                          | 220.5927     |
| Q-std                          | 182.223      |
| Q_loss                         | 76.7314      |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 787          |
| times/epoch_after_hook         | 1.7e-06      |
| times/epoch_before_hook        | 0.000125     |
| times/epoch_rollout_model      | 482          |
| times/evaluation_metrics       | 0.000611     |
| times/evaluation_paths         | 37.3         |
| times/timestep_after_hook      | 0.00369      |
| times/timestep_before_hook     | 0.00842      |
| times/train                    | 59.8         |
| timestep                       | 1000         |
| timesteps_total                | 788000       |
| train-steps                    | 788000       |
| training/Q/q1_loss             | 90.30265     |
| training/sac_pi/alpha          | 0.16439076   |
| training/sac_pi/alpha_loss     | -0.121279225 |
| training/sac_pi/logp_pi        | 5.175185     |
| training/sac_pi/pi_entropy     | 3.575812     |
| training/sac_pi/pi_global_norm | 2.0873125    |
| training/sac_pi/policy_loss    | -226.41463   |
| training/sac_pi/std            | 0.55755234   |
| training/sac_pi/valid_num      | 4902.0       |
| training/sac_Q/q1              | 206.8837     |
| training/sac_Q/q2              | 208.9211     |
| training/sac_Q/q2_loss         | 89.42567     |
| training/sac_Q/q_global_norm   | 244.59312    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16219568 |
| epoch                          | 788        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5235.919   |
| evaluation/return-max          | 5297.0815  |
| evaluation/return-min          | 5186.3076  |
| evaluation/return-std          | 28.35343   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46467      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5235.919   |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 223.11874  |
| Q-std                          | 128.43877  |
| Q_loss                         | 83.16896   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 788        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000137   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000596   |
| times/evaluation_paths         | 34.1       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 59.2       |
| timestep                       | 1000       |
| timesteps_total                | 789000     |
| train-steps                    | 789000     |
| training/Q/q1_loss             | 122.48384  |
| training/sac_pi/alpha          | 0.1621765  |
| training/sac_pi/alpha_loss     | 0.5870083  |
| training/sac_pi/logp_pi        | 4.847122   |
| training/sac_pi/pi_entropy     | 3.518906   |
| training/sac_pi/pi_global_norm | 1.8441728  |
| training/sac_pi/policy_loss    | -228.487   |
| training/sac_pi/std            | 0.5243304  |
| training/sac_pi/valid_num      | 4970.0     |
| training/sac_Q/q1              | 215.74251  |
| training/sac_Q/q2              | 218.0664   |
| training/sac_Q/q2_loss         | 124.19434  |
| training/sac_Q/q_global_norm   | 308.63632  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16537273   |
| epoch                          | 789          |
| evaluation/episode-length-avg  | 832          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 159          |
| evaluation/episode-length-std  | 336          |
| evaluation/return-average      | 4133.0796    |
| evaluation/return-max          | 5122.503     |
| evaluation/return-min          | 438.72504    |
| evaluation/return-std          | 1844.3713    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.16         |
| model/origin_ret               | 86.3         |
| model/penalty_ret              | 79.5         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46633        |
| perf/AverageLength             | 832          |
| perf/AverageReturn             | 4133.0796    |
| perf/NormalizedReturn          | 0.9          |
| Q-avg                          | 217.27768    |
| Q-std                          | 166.11491    |
| Q_loss                         | 98.84724     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 789          |
| times/epoch_after_hook         | 1.79e-06     |
| times/epoch_before_hook        | 0.000281     |
| times/epoch_rollout_model      | 481          |
| times/evaluation_metrics       | 0.000524     |
| times/evaluation_paths         | 29.6         |
| times/timestep_after_hook      | 0.00361      |
| times/timestep_before_hook     | 0.00829      |
| times/train                    | 61.3         |
| timestep                       | 1000         |
| timesteps_total                | 790000       |
| train-steps                    | 790000       |
| training/Q/q1_loss             | 95.6136      |
| training/sac_pi/alpha          | 0.16534323   |
| training/sac_pi/alpha_loss     | 0.0065925117 |
| training/sac_pi/logp_pi        | 4.444247     |
| training/sac_pi/pi_entropy     | 3.579504     |
| training/sac_pi/pi_global_norm | 1.6360512    |
| training/sac_pi/policy_loss    | -223.46103   |
| training/sac_pi/std            | 0.5077969    |
| training/sac_pi/valid_num      | 4974.0       |
| training/sac_Q/q1              | 209.20987    |
| training/sac_Q/q2              | 211.53084    |
| training/sac_Q/q2_loss         | 94.62226     |
| training/sac_Q/q_global_norm   | 251.94885    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1646599   |
| epoch                          | 790         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5125.8115   |
| evaluation/return-max          | 5163.133    |
| evaluation/return-min          | 5071.8916   |
| evaluation/return-std          | 26.83728    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.15        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46435       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5125.8115   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 202.14893   |
| Q-std                          | 189.95096   |
| Q_loss                         | 109.77524   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 790         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000518    |
| times/evaluation_paths         | 34.1        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.0082      |
| times/train                    | 60.1        |
| timestep                       | 1000        |
| timesteps_total                | 791000      |
| train-steps                    | 791000      |
| training/Q/q1_loss             | 95.34654    |
| training/sac_pi/alpha          | 0.1647026   |
| training/sac_pi/alpha_loss     | -0.29790652 |
| training/sac_pi/logp_pi        | 3.9539394   |
| training/sac_pi/pi_entropy     | 3.5757422   |
| training/sac_pi/pi_global_norm | 1.6581404   |
| training/sac_pi/policy_loss    | -228.44421  |
| training/sac_pi/std            | 0.49408212  |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 219.32246   |
| training/sac_Q/q2              | 220.18839   |
| training/sac_Q/q2_loss         | 94.92231    |
| training/sac_Q/q_global_norm   | 267.92197   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.161605   |
| epoch                          | 791        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5139.089   |
| evaluation/return-max          | 5276.419   |
| evaluation/return-min          | 5016.52    |
| evaluation/return-std          | 80.58662   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 80.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46376      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5139.089   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 210.28     |
| Q-std                          | 141.64072  |
| Q_loss                         | 107.22649  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 791        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000594   |
| times/evaluation_paths         | 35.6       |
| times/timestep_after_hook      | 0.00351    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 59.7       |
| timestep                       | 1000       |
| timesteps_total                | 792000     |
| train-steps                    | 792000     |
| training/Q/q1_loss             | 97.178154  |
| training/sac_pi/alpha          | 0.1616133  |
| training/sac_pi/alpha_loss     | -0.408114  |
| training/sac_pi/logp_pi        | 4.455905   |
| training/sac_pi/pi_entropy     | 3.319571   |
| training/sac_pi/pi_global_norm | 2.1352675  |
| training/sac_pi/policy_loss    | -234.5314  |
| training/sac_pi/std            | 0.50741756 |
| training/sac_pi/valid_num      | 4951.0     |
| training/sac_Q/q1              | 218.36996  |
| training/sac_Q/q2              | 220.99722  |
| training/sac_Q/q2_loss         | 96.2868    |
| training/sac_Q/q_global_norm   | 204.29967  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16040732 |
| epoch                          | 792        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4646.479   |
| evaluation/return-max          | 5046.2925  |
| evaluation/return-min          | 4465.077   |
| evaluation/return-std          | 217.28003  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46487      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4646.479   |
| perf/NormalizedReturn          | 1.01       |
| Q-avg                          | 223.85701  |
| Q-std                          | 170.84506  |
| Q_loss                         | 73.28191   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 792        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000603   |
| times/evaluation_paths         | 34.9       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 793000     |
| train-steps                    | 793000     |
| training/Q/q1_loss             | 111.230865 |
| training/sac_pi/alpha          | 0.16039631 |
| training/sac_pi/alpha_loss     | 0.36852738 |
| training/sac_pi/logp_pi        | 4.8113427  |
| training/sac_pi/pi_entropy     | 3.5928025  |
| training/sac_pi/pi_global_norm | 1.8894958  |
| training/sac_pi/policy_loss    | -219.18068 |
| training/sac_pi/std            | 0.52813184 |
| training/sac_pi/valid_num      | 4962.0     |
| training/sac_Q/q1              | 202.03273  |
| training/sac_Q/q2              | 206.5686   |
| training/sac_Q/q2_loss         | 110.4966   |
| training/sac_Q/q_global_norm   | 175.2371   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1620133   |
| epoch                          | 793         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5029.4805   |
| evaluation/return-max          | 5155.2334   |
| evaluation/return-min          | 4561.8765   |
| evaluation/return-std          | 186.04378   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.15        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46434       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5029.4805   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 220.00974   |
| Q-std                          | 153.86176   |
| Q_loss                         | 93.40808    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 793         |
| times/epoch_after_hook         | 3.43e-06    |
| times/epoch_before_hook        | 0.000327    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000497    |
| times/evaluation_paths         | 33.5        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00829     |
| times/train                    | 61.1        |
| timestep                       | 1000        |
| timesteps_total                | 794000      |
| train-steps                    | 794000      |
| training/Q/q1_loss             | 80.89815    |
| training/sac_pi/alpha          | 0.16203699  |
| training/sac_pi/alpha_loss     | -0.21889557 |
| training/sac_pi/logp_pi        | 3.5735984   |
| training/sac_pi/pi_entropy     | 3.4468079   |
| training/sac_pi/pi_global_norm | 2.113082    |
| training/sac_pi/policy_loss    | -233.59904  |
| training/sac_pi/std            | 0.48758665  |
| training/sac_pi/valid_num      | 5008.0      |
| training/sac_Q/q1              | 224.9509    |
| training/sac_Q/q2              | 224.78906   |
| training/sac_Q/q2_loss         | 82.219536   |
| training/sac_Q/q_global_norm   | 220.16171   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16625655  |
| epoch                          | 794         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4908.5024   |
| evaluation/return-max          | 4935.3164   |
| evaluation/return-min          | 4877.1777   |
| evaluation/return-std          | 17.901926   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46442       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4908.5024   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 219.55948   |
| Q-std                          | 137.59807   |
| Q_loss                         | 98.57905    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 794         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000119    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000611    |
| times/evaluation_paths         | 35.6        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 62.4        |
| timestep                       | 1000        |
| timesteps_total                | 795000      |
| train-steps                    | 795000      |
| training/Q/q1_loss             | 119.91048   |
| training/sac_pi/alpha          | 0.16626646  |
| training/sac_pi/alpha_loss     | -0.06983561 |
| training/sac_pi/logp_pi        | 4.2393064   |
| training/sac_pi/pi_entropy     | 3.3962739   |
| training/sac_pi/pi_global_norm | 1.9192206   |
| training/sac_pi/policy_loss    | -229.72522  |
| training/sac_pi/std            | 0.49840125  |
| training/sac_pi/valid_num      | 4973.0      |
| training/sac_Q/q1              | 218.1228    |
| training/sac_Q/q2              | 220.21689   |
| training/sac_Q/q2_loss         | 120.29658   |
| training/sac_Q/q_global_norm   | 230.12767   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16880311 |
| epoch                          | 795        |
| evaluation/episode-length-avg  | 930        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 305        |
| evaluation/episode-length-std  | 208        |
| evaluation/return-average      | 4349.6465  |
| evaluation/return-max          | 4810.959   |
| evaluation/return-min          | 1165.9744  |
| evaluation/return-std          | 1062.6082  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46461      |
| perf/AverageLength             | 930        |
| perf/AverageReturn             | 4349.6465  |
| perf/NormalizedReturn          | 0.947      |
| Q-avg                          | 222.0688   |
| Q-std                          | 120.31611  |
| Q_loss                         | 91.554405  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 795        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000146   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000727   |
| times/evaluation_paths         | 34.1       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 59.4       |
| timestep                       | 1000       |
| timesteps_total                | 796000     |
| train-steps                    | 796000     |
| training/Q/q1_loss             | 89.86681   |
| training/sac_pi/alpha          | 0.16881652 |
| training/sac_pi/alpha_loss     | 0.13971907 |
| training/sac_pi/logp_pi        | 4.1216917  |
| training/sac_pi/pi_entropy     | 3.4365792  |
| training/sac_pi/pi_global_norm | 1.6120117  |
| training/sac_pi/policy_loss    | -230.4477  |
| training/sac_pi/std            | 0.48314318 |
| training/sac_pi/valid_num      | 4944.0     |
| training/sac_Q/q1              | 217.45425  |
| training/sac_Q/q2              | 220.504    |
| training/sac_Q/q2_loss         | 90.118935  |
| training/sac_Q/q_global_norm   | 192.27974  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15949649 |
| epoch                          | 796        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4936.8594  |
| evaluation/return-max          | 5040.256   |
| evaluation/return-min          | 4879.008   |
| evaluation/return-std          | 49.20701   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46410      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4936.8594  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 209.27567  |
| Q-std                          | 143.08453  |
| Q_loss                         | 107.451614 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 796        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000167   |
| times/epoch_rollout_model      | 516        |
| times/evaluation_metrics       | 0.000743   |
| times/evaluation_paths         | 37         |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 797000     |
| train-steps                    | 797000     |
| training/Q/q1_loss             | 90.42708   |
| training/sac_pi/alpha          | 0.15951496 |
| training/sac_pi/alpha_loss     | 0.16484459 |
| training/sac_pi/logp_pi        | 4.401534   |
| training/sac_pi/pi_entropy     | 3.5118008  |
| training/sac_pi/pi_global_norm | 1.9540569  |
| training/sac_pi/policy_loss    | -226.97028 |
| training/sac_pi/std            | 0.5240418  |
| training/sac_pi/valid_num      | 4967.0     |
| training/sac_Q/q1              | 216.39458  |
| training/sac_Q/q2              | 215.93399  |
| training/sac_Q/q2_loss         | 91.983665  |
| training/sac_Q/q_global_norm   | 178.87126  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.1606196    |
| epoch                          | 797          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5163.5127    |
| evaluation/return-max          | 5194.6123    |
| evaluation/return-min          | 5107.8906    |
| evaluation/return-std          | 26.131153    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.06         |
| model/origin_ret               | 85.2         |
| model/penalty_ret              | 79.6         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46477        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5163.5127    |
| perf/NormalizedReturn          | 1.12         |
| Q-avg                          | 211.75623    |
| Q-std                          | 180.69363    |
| Q_loss                         | 93.38488     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 797          |
| times/epoch_after_hook         | 1.7e-06      |
| times/epoch_before_hook        | 0.000372     |
| times/epoch_rollout_model      | 522          |
| times/evaluation_metrics       | 0.00058      |
| times/evaluation_paths         | 38.3         |
| times/timestep_after_hook      | 0.00395      |
| times/timestep_before_hook     | 0.0119       |
| times/train                    | 67.7         |
| timestep                       | 1000         |
| timesteps_total                | 798000       |
| train-steps                    | 798000       |
| training/Q/q1_loss             | 95.26574     |
| training/sac_pi/alpha          | 0.16062172   |
| training/sac_pi/alpha_loss     | -0.028477225 |
| training/sac_pi/logp_pi        | 4.2617164    |
| training/sac_pi/pi_entropy     | 3.5212123    |
| training/sac_pi/pi_global_norm | 1.8327754    |
| training/sac_pi/policy_loss    | -229.05367   |
| training/sac_pi/std            | 0.5066097    |
| training/sac_pi/valid_num      | 4968.0       |
| training/sac_Q/q1              | 218.61319    |
| training/sac_Q/q2              | 218.03369    |
| training/sac_Q/q2_loss         | 94.64826     |
| training/sac_Q/q_global_norm   | 229.06342    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16703078  |
| epoch                          | 798         |
| evaluation/episode-length-avg  | 583         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 165         |
| evaluation/episode-length-std  | 417         |
| evaluation/return-average      | 2850.286    |
| evaluation/return-max          | 5254.228    |
| evaluation/return-min          | 547.3457    |
| evaluation/return-std          | 2299.4534   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46446       |
| perf/AverageLength             | 583         |
| perf/AverageReturn             | 2850.286    |
| perf/NormalizedReturn          | 0.621       |
| Q-avg                          | 212.10757   |
| Q-std                          | 123.60233   |
| Q_loss                         | 124.49496   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 798         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 517         |
| times/evaluation_metrics       | 0.000622    |
| times/evaluation_paths         | 21.9        |
| times/timestep_after_hook      | 0.00418     |
| times/timestep_before_hook     | 0.0088      |
| times/train                    | 66.1        |
| timestep                       | 1000        |
| timesteps_total                | 799000      |
| train-steps                    | 799000      |
| training/Q/q1_loss             | 107.11397   |
| training/sac_pi/alpha          | 0.16704601  |
| training/sac_pi/alpha_loss     | -0.34726003 |
| training/sac_pi/logp_pi        | 3.7318192   |
| training/sac_pi/pi_entropy     | 3.602404    |
| training/sac_pi/pi_global_norm | 1.718531    |
| training/sac_pi/policy_loss    | -234.09969  |
| training/sac_pi/std            | 0.4992521   |
| training/sac_pi/valid_num      | 5026.0      |
| training/sac_Q/q1              | 226.9605    |
| training/sac_Q/q2              | 226.43034   |
| training/sac_Q/q2_loss         | 107.82125   |
| training/sac_Q/q_global_norm   | 233.12436   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16214155  |
| epoch                          | 799         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5052.9185   |
| evaluation/return-max          | 5125.079    |
| evaluation/return-min          | 4967.639    |
| evaluation/return-std          | 54.363785   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.17        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46590       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5052.9185   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 211.87166   |
| Q-std                          | 139.10931   |
| Q_loss                         | 104.66111   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 799         |
| times/epoch_after_hook         | 1.82e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 520         |
| times/evaluation_metrics       | 0.000606    |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 63.8        |
| timestep                       | 1000        |
| timesteps_total                | 800000      |
| train-steps                    | 800000      |
| training/Q/q1_loss             | 103.4702    |
| training/sac_pi/alpha          | 0.16214707  |
| training/sac_pi/alpha_loss     | -0.14662442 |
| training/sac_pi/logp_pi        | 4.568572    |
| training/sac_pi/pi_entropy     | 3.354979    |
| training/sac_pi/pi_global_norm | 1.5920457   |
| training/sac_pi/policy_loss    | -232.6746   |
| training/sac_pi/std            | 0.4916147   |
| training/sac_pi/valid_num      | 4981.0      |
| training/sac_Q/q1              | 224.89949   |
| training/sac_Q/q2              | 225.9559    |
| training/sac_Q/q2_loss         | 103.29384   |
| training/sac_Q/q_global_norm   | 206.60515   |
---------------------------------------------------------------------------------
[WARN] 800 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16483465  |
| epoch                          | 800         |
| evaluation/episode-length-avg  | 826         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 129         |
| evaluation/episode-length-std  | 348         |
| evaluation/return-average      | 4167.7188   |
| evaluation/return-max          | 5171.5625   |
| evaluation/return-min          | 337.44574   |
| evaluation/return-std          | 1914.1367   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 85.8        |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46412       |
| perf/AverageLength             | 826         |
| perf/AverageReturn             | 4167.7188   |
| perf/NormalizedReturn          | 0.908       |
| Q-avg                          | 230.87643   |
| Q-std                          | 101.87591   |
| Q_loss                         | 95.85308    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 800         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000152    |
| times/epoch_rollout_model      | 528         |
| times/evaluation_metrics       | 0.000653    |
| times/evaluation_paths         | 28.8        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 65          |
| timestep                       | 1000        |
| timesteps_total                | 801000      |
| train-steps                    | 801000      |
| training/Q/q1_loss             | 87.83313    |
| training/sac_pi/alpha          | 0.16483793  |
| training/sac_pi/alpha_loss     | -0.15926082 |
| training/sac_pi/logp_pi        | 3.6941037   |
| training/sac_pi/pi_entropy     | 3.4665844   |
| training/sac_pi/pi_global_norm | 1.9252526   |
| training/sac_pi/policy_loss    | -234.95815  |
| training/sac_pi/std            | 0.48174137  |
| training/sac_pi/valid_num      | 4960.0      |
| training/sac_Q/q1              | 222.43076   |
| training/sac_Q/q2              | 224.17505   |
| training/sac_Q/q2_loss         | 90.39851    |
| training/sac_Q/q_global_norm   | 260.7539    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15576717  |
| epoch                          | 801         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4957.1133   |
| evaluation/return-max          | 5051.5664   |
| evaluation/return-min          | 4858.794    |
| evaluation/return-std          | 62.33282    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46405       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4957.1133   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 221.2396    |
| Q-std                          | 118.09456   |
| Q_loss                         | 123.23875   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 801         |
| times/epoch_after_hook         | 3.19e-06    |
| times/epoch_before_hook        | 0.00032     |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000586    |
| times/evaluation_paths         | 37.3        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00849     |
| times/train                    | 63.3        |
| timestep                       | 1000        |
| timesteps_total                | 802000      |
| train-steps                    | 802000      |
| training/Q/q1_loss             | 101.21802   |
| training/sac_pi/alpha          | 0.15573265  |
| training/sac_pi/alpha_loss     | 0.026903987 |
| training/sac_pi/logp_pi        | 4.483532    |
| training/sac_pi/pi_entropy     | 3.2725492   |
| training/sac_pi/pi_global_norm | 1.6836264   |
| training/sac_pi/policy_loss    | -226.97394  |
| training/sac_pi/std            | 0.4926634   |
| training/sac_pi/valid_num      | 4954.0      |
| training/sac_Q/q1              | 214.01456   |
| training/sac_Q/q2              | 213.95808   |
| training/sac_Q/q2_loss         | 100.741325  |
| training/sac_Q/q_global_norm   | 207.00015   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1623381  |
| epoch                          | 802        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5077.8066  |
| evaluation/return-max          | 5183.389   |
| evaluation/return-min          | 4966.9917  |
| evaluation/return-std          | 74.208664  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46335      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5077.8066  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 211.06546  |
| Q-std                          | 137.1709   |
| Q_loss                         | 99.38615   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 802        |
| times/epoch_after_hook         | 1.91e-06   |
| times/epoch_before_hook        | 0.00016    |
| times/epoch_rollout_model      | 528        |
| times/evaluation_metrics       | 0.000994   |
| times/evaluation_paths         | 36.6       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00872    |
| times/train                    | 62.8       |
| timestep                       | 1000       |
| timesteps_total                | 803000     |
| train-steps                    | 803000     |
| training/Q/q1_loss             | 100.35095  |
| training/sac_pi/alpha          | 0.16232139 |
| training/sac_pi/alpha_loss     | 0.4020759  |
| training/sac_pi/logp_pi        | 3.6504464  |
| training/sac_pi/pi_entropy     | 3.4149384  |
| training/sac_pi/pi_global_norm | 1.6429865  |
| training/sac_pi/policy_loss    | -222.62828 |
| training/sac_pi/std            | 0.4671921  |
| training/sac_pi/valid_num      | 4991.0     |
| training/sac_Q/q1              | 217.548    |
| training/sac_Q/q2              | 218.19067  |
| training/sac_Q/q2_loss         | 100.958275 |
| training/sac_Q/q_global_norm   | 192.2437   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16226132 |
| epoch                          | 803        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5096.808   |
| evaluation/return-max          | 5167.0425  |
| evaluation/return-min          | 5044.382   |
| evaluation/return-std          | 34.908688  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46501      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5096.808   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 220.73804  |
| Q-std                          | 108.14055  |
| Q_loss                         | 93.59962   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 803        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.00016    |
| times/epoch_rollout_model      | 532        |
| times/evaluation_metrics       | 0.000598   |
| times/evaluation_paths         | 37.1       |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 62.1       |
| timestep                       | 1000       |
| timesteps_total                | 804000     |
| train-steps                    | 804000     |
| training/Q/q1_loss             | 117.24026  |
| training/sac_pi/alpha          | 0.16225033 |
| training/sac_pi/alpha_loss     | 0.2131366  |
| training/sac_pi/logp_pi        | 5.524977   |
| training/sac_pi/pi_entropy     | 3.6181946  |
| training/sac_pi/pi_global_norm | 1.8261093  |
| training/sac_pi/policy_loss    | -226.21495 |
| training/sac_pi/std            | 0.5742773  |
| training/sac_pi/valid_num      | 4914.0     |
| training/sac_Q/q1              | 206.729    |
| training/sac_Q/q2              | 213.82185  |
| training/sac_Q/q2_loss         | 116.4416   |
| training/sac_Q/q_global_norm   | 235.16411  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16672255  |
| epoch                          | 804         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5151.2114   |
| evaluation/return-max          | 5177.0596   |
| evaluation/return-min          | 5124.7764   |
| evaluation/return-std          | 15.527358   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46481       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5151.2114   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 220.73787   |
| Q-std                          | 115.435814  |
| Q_loss                         | 116.76503   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 804         |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000562    |
| times/evaluation_paths         | 38.1        |
| times/timestep_after_hook      | 0.00392     |
| times/timestep_before_hook     | 0.0084      |
| times/train                    | 63.5        |
| timestep                       | 1000        |
| timesteps_total                | 805000      |
| train-steps                    | 805000      |
| training/Q/q1_loss             | 101.68981   |
| training/sac_pi/alpha          | 0.1667446   |
| training/sac_pi/alpha_loss     | -0.24519263 |
| training/sac_pi/logp_pi        | 4.5056252   |
| training/sac_pi/pi_entropy     | 3.4195676   |
| training/sac_pi/pi_global_norm | 1.7636662   |
| training/sac_pi/policy_loss    | -227.56696  |
| training/sac_pi/std            | 0.49915618  |
| training/sac_pi/valid_num      | 4899.0      |
| training/sac_Q/q1              | 211.76912   |
| training/sac_Q/q2              | 212.39755   |
| training/sac_Q/q2_loss         | 101.1897    |
| training/sac_Q/q_global_norm   | 331.30328   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16406554  |
| epoch                          | 805         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5208.155    |
| evaluation/return-max          | 5227.3896   |
| evaluation/return-min          | 5176.1963   |
| evaluation/return-std          | 18.897907   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46356       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5208.155    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 214.26518   |
| Q-std                          | 127.051765  |
| Q_loss                         | 69.05591    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 805         |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000588    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000726    |
| times/evaluation_paths         | 37.7        |
| times/timestep_after_hook      | 0.00378     |
| times/timestep_before_hook     | 0.00859     |
| times/train                    | 62.1        |
| timestep                       | 1000        |
| timesteps_total                | 806000      |
| train-steps                    | 806000      |
| training/Q/q1_loss             | 99.49542    |
| training/sac_pi/alpha          | 0.16406046  |
| training/sac_pi/alpha_loss     | -0.23383118 |
| training/sac_pi/logp_pi        | 4.234418    |
| training/sac_pi/pi_entropy     | 3.5404212   |
| training/sac_pi/pi_global_norm | 2.025119    |
| training/sac_pi/policy_loss    | -230.58215  |
| training/sac_pi/std            | 0.51190275  |
| training/sac_pi/valid_num      | 4921.0      |
| training/sac_Q/q1              | 215.83633   |
| training/sac_Q/q2              | 220.07217   |
| training/sac_Q/q2_loss         | 99.97276    |
| training/sac_Q/q_global_norm   | 326.7219    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1596826   |
| epoch                          | 806         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5270.7925   |
| evaluation/return-max          | 5322.464    |
| evaluation/return-min          | 5160.3564   |
| evaluation/return-std          | 57.330933   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46485       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5270.7925   |
| perf/NormalizedReturn          | 1.15        |
| Q-avg                          | 209.08365   |
| Q-std                          | 192.32529   |
| Q_loss                         | 111.13046   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 806         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.00014     |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000535    |
| times/evaluation_paths         | 36.1        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00855     |
| times/train                    | 63.8        |
| timestep                       | 1000        |
| timesteps_total                | 807000      |
| train-steps                    | 807000      |
| training/Q/q1_loss             | 110.49528   |
| training/sac_pi/alpha          | 0.15969701  |
| training/sac_pi/alpha_loss     | 0.025593918 |
| training/sac_pi/logp_pi        | 3.8229966   |
| training/sac_pi/pi_entropy     | 3.3504238   |
| training/sac_pi/pi_global_norm | 2.0023825   |
| training/sac_pi/policy_loss    | -229.50696  |
| training/sac_pi/std            | 0.47748956  |
| training/sac_pi/valid_num      | 4977.0      |
| training/sac_Q/q1              | 221.75623   |
| training/sac_Q/q2              | 223.80386   |
| training/sac_Q/q2_loss         | 109.69273   |
| training/sac_Q/q_global_norm   | 309.2886    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16324134  |
| epoch                          | 807         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4898.9297   |
| evaluation/return-max          | 5061.616    |
| evaluation/return-min          | 4749.897    |
| evaluation/return-std          | 79.64665    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46527       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4898.9297   |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 204.999     |
| Q-std                          | 143.01729   |
| Q_loss                         | 113.84693   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 807         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.00014     |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000538    |
| times/evaluation_paths         | 36.4        |
| times/timestep_after_hook      | 0.00381     |
| times/timestep_before_hook     | 0.0085      |
| times/train                    | 62.9        |
| timestep                       | 1000        |
| timesteps_total                | 808000      |
| train-steps                    | 808000      |
| training/Q/q1_loss             | 96.03213    |
| training/sac_pi/alpha          | 0.16323644  |
| training/sac_pi/alpha_loss     | -0.17840523 |
| training/sac_pi/logp_pi        | 3.8284745   |
| training/sac_pi/pi_entropy     | 3.624684    |
| training/sac_pi/pi_global_norm | 1.9018513   |
| training/sac_pi/policy_loss    | -220.6829   |
| training/sac_pi/std            | 0.49656036  |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 210.42416   |
| training/sac_Q/q2              | 210.67526   |
| training/sac_Q/q2_loss         | 96.3287     |
| training/sac_Q/q_global_norm   | 258.73288   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1582609  |
| epoch                          | 808        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5139.044   |
| evaluation/return-max          | 5225.402   |
| evaluation/return-min          | 5083.799   |
| evaluation/return-std          | 42.03571   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46558      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5139.044   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 207.63118  |
| Q-std                          | 219.87552  |
| Q_loss                         | 107.997375 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 808        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 35         |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 62.7       |
| timestep                       | 1000       |
| timesteps_total                | 809000     |
| train-steps                    | 809000     |
| training/Q/q1_loss             | 87.36666   |
| training/sac_pi/alpha          | 0.15824127 |
| training/sac_pi/alpha_loss     | 0.21975447 |
| training/sac_pi/logp_pi        | 4.026864   |
| training/sac_pi/pi_entropy     | 3.323354   |
| training/sac_pi/pi_global_norm | 2.03382    |
| training/sac_pi/policy_loss    | -225.70168 |
| training/sac_pi/std            | 0.48015973 |
| training/sac_pi/valid_num      | 4995.0     |
| training/sac_Q/q1              | 218.1101   |
| training/sac_Q/q2              | 219.37175  |
| training/sac_Q/q2_loss         | 87.85512   |
| training/sac_Q/q_global_norm   | 200.8307   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16064924   |
| epoch                          | 809          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4912.0767    |
| evaluation/return-max          | 5035.3184    |
| evaluation/return-min          | 4785.4824    |
| evaluation/return-std          | 65.797554    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.12         |
| model/origin_ret               | 86           |
| model/penalty_ret              | 79.6         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46465        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4912.0767    |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 207.67383    |
| Q-std                          | 151.15253    |
| Q_loss                         | 106.22849    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 809          |
| times/epoch_after_hook         | 1.79e-06     |
| times/epoch_before_hook        | 0.000285     |
| times/epoch_rollout_model      | 487          |
| times/evaluation_metrics       | 0.00061      |
| times/evaluation_paths         | 39.4         |
| times/timestep_after_hook      | 0.00362      |
| times/timestep_before_hook     | 0.0082       |
| times/train                    | 76.5         |
| timestep                       | 1000         |
| timesteps_total                | 810000       |
| train-steps                    | 810000       |
| training/Q/q1_loss             | 97.350395    |
| training/sac_pi/alpha          | 0.1606529    |
| training/sac_pi/alpha_loss     | -0.109045625 |
| training/sac_pi/logp_pi        | 4.006788     |
| training/sac_pi/pi_entropy     | 3.4847207    |
| training/sac_pi/pi_global_norm | 2.4386597    |
| training/sac_pi/policy_loss    | -227.12097   |
| training/sac_pi/std            | 0.49654543   |
| training/sac_pi/valid_num      | 4987.0       |
| training/sac_Q/q1              | 218.91118    |
| training/sac_Q/q2              | 219.80826    |
| training/sac_Q/q2_loss         | 97.41445     |
| training/sac_Q/q_global_norm   | 393.5298     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16159345 |
| epoch                          | 810        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4894.4126  |
| evaluation/return-max          | 5013.224   |
| evaluation/return-min          | 4763.4004  |
| evaluation/return-std          | 73.43361   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46439      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4894.4126  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 211.6278   |
| Q-std                          | 163.86975  |
| Q_loss                         | 117.938446 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 810        |
| times/epoch_after_hook         | 1.85e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 494        |
| times/evaluation_metrics       | 0.00059    |
| times/evaluation_paths         | 58.9       |
| times/timestep_after_hook      | 0.00375    |
| times/timestep_before_hook     | 0.00857    |
| times/train                    | 77.7       |
| timestep                       | 1000       |
| timesteps_total                | 811000     |
| train-steps                    | 811000     |
| training/Q/q1_loss             | 103.47077  |
| training/sac_pi/alpha          | 0.16160461 |
| training/sac_pi/alpha_loss     | 0.07412555 |
| training/sac_pi/logp_pi        | 3.7378974  |
| training/sac_pi/pi_entropy     | 3.4364018  |
| training/sac_pi/pi_global_norm | 1.9546514  |
| training/sac_pi/policy_loss    | -228.00235 |
| training/sac_pi/std            | 0.4837738  |
| training/sac_pi/valid_num      | 4996.0     |
| training/sac_Q/q1              | 219.15971  |
| training/sac_Q/q2              | 220.28511  |
| training/sac_Q/q2_loss         | 102.43273  |
| training/sac_Q/q_global_norm   | 229.1912   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.161392   |
| epoch                          | 811        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5251.126   |
| evaluation/return-max          | 5323.9604  |
| evaluation/return-min          | 4997.592   |
| evaluation/return-std          | 94.3321    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46385      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5251.126   |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 212.08565  |
| Q-std                          | 242.7442   |
| Q_loss                         | 89.76677   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 811        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000591   |
| times/evaluation_paths         | 50.1       |
| times/timestep_after_hook      | 0.005      |
| times/timestep_before_hook     | 0.00853    |
| times/train                    | 74.5       |
| timestep                       | 1000       |
| timesteps_total                | 812000     |
| train-steps                    | 812000     |
| training/Q/q1_loss             | 125.92493  |
| training/sac_pi/alpha          | 0.1613606  |
| training/sac_pi/alpha_loss     | 0.5684194  |
| training/sac_pi/logp_pi        | 3.971566   |
| training/sac_pi/pi_entropy     | 3.4300857  |
| training/sac_pi/pi_global_norm | 1.7019494  |
| training/sac_pi/policy_loss    | -229.39897 |
| training/sac_pi/std            | 0.48133475 |
| training/sac_pi/valid_num      | 5026.0     |
| training/sac_Q/q1              | 224.08955  |
| training/sac_Q/q2              | 223.96121  |
| training/sac_Q/q2_loss         | 124.75801  |
| training/sac_Q/q_global_norm   | 194.95923  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16275473 |
| epoch                          | 812        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4953.204   |
| evaluation/return-max          | 4993.8926  |
| evaluation/return-min          | 4897.65    |
| evaluation/return-std          | 28.363054  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.18       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46477      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4953.204   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 213.41873  |
| Q-std                          | 141.65506  |
| Q_loss                         | 90.47098   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 812        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.00132    |
| times/evaluation_paths         | 53.7       |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00872    |
| times/train                    | 78.7       |
| timestep                       | 1000       |
| timesteps_total                | 813000     |
| train-steps                    | 813000     |
| training/Q/q1_loss             | 73.60114   |
| training/sac_pi/alpha          | 0.16272193 |
| training/sac_pi/alpha_loss     | 0.268865   |
| training/sac_pi/logp_pi        | 4.258689   |
| training/sac_pi/pi_entropy     | 3.4355316  |
| training/sac_pi/pi_global_norm | 1.7055191  |
| training/sac_pi/policy_loss    | -229.57843 |
| training/sac_pi/std            | 0.48877704 |
| training/sac_pi/valid_num      | 4998.0     |
| training/sac_Q/q1              | 213.5074   |
| training/sac_Q/q2              | 217.99275  |
| training/sac_Q/q2_loss         | 75.09545   |
| training/sac_Q/q_global_norm   | 281.82202  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1624516   |
| epoch                          | 813         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5243.358    |
| evaluation/return-max          | 5334.2407   |
| evaluation/return-min          | 5159.9414   |
| evaluation/return-std          | 52.598778   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46410       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5243.358    |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 200.41776   |
| Q-std                          | 178.07318   |
| Q_loss                         | 115.36886   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 813         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000323    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000723    |
| times/evaluation_paths         | 38.9        |
| times/timestep_after_hook      | 0.00381     |
| times/timestep_before_hook     | 0.00857     |
| times/train                    | 69.5        |
| timestep                       | 1000        |
| timesteps_total                | 814000      |
| train-steps                    | 814000      |
| training/Q/q1_loss             | 89.34897    |
| training/sac_pi/alpha          | 0.16245285  |
| training/sac_pi/alpha_loss     | -0.13188384 |
| training/sac_pi/logp_pi        | 3.8345933   |
| training/sac_pi/pi_entropy     | 3.4596086   |
| training/sac_pi/pi_global_norm | 2.5065875   |
| training/sac_pi/policy_loss    | -223.71881  |
| training/sac_pi/std            | 0.49577188  |
| training/sac_pi/valid_num      | 4981.0      |
| training/sac_Q/q1              | 211.84592   |
| training/sac_Q/q2              | 214.15767   |
| training/sac_Q/q2_loss         | 89.56649    |
| training/sac_Q/q_global_norm   | 240.17084   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16390838   |
| epoch                          | 814          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5160.932     |
| evaluation/return-max          | 5217.5957    |
| evaluation/return-min          | 5110.9424    |
| evaluation/return-std          | 40.76389     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.15         |
| model/origin_ret               | 85.8         |
| model/penalty_ret              | 78.8         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46567        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5160.932     |
| perf/NormalizedReturn          | 1.12         |
| Q-avg                          | 225.82584    |
| Q-std                          | 125.12131    |
| Q_loss                         | 99.09052     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 814          |
| times/epoch_after_hook         | 1.64e-06     |
| times/epoch_before_hook        | 0.000131     |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.00062      |
| times/evaluation_paths         | 35           |
| times/timestep_after_hook      | 0.00359      |
| times/timestep_before_hook     | 0.00807      |
| times/train                    | 60.4         |
| timestep                       | 1000         |
| timesteps_total                | 815000       |
| train-steps                    | 815000       |
| training/Q/q1_loss             | 99.31205     |
| training/sac_pi/alpha          | 0.16393487   |
| training/sac_pi/alpha_loss     | -0.038077846 |
| training/sac_pi/logp_pi        | 4.0849895    |
| training/sac_pi/pi_entropy     | 3.5646834    |
| training/sac_pi/pi_global_norm | 1.9372352    |
| training/sac_pi/policy_loss    | -226.37325   |
| training/sac_pi/std            | 0.5144508    |
| training/sac_pi/valid_num      | 5006.0       |
| training/sac_Q/q1              | 215.63867    |
| training/sac_Q/q2              | 217.11313    |
| training/sac_Q/q2_loss         | 98.89501     |
| training/sac_Q/q_global_norm   | 260.47546    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15723127 |
| epoch                          | 815        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5195.927   |
| evaluation/return-max          | 5224.3926  |
| evaluation/return-min          | 5140.0537  |
| evaluation/return-std          | 22.999805  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 78.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46542      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5195.927   |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 226.33627  |
| Q-std                          | 125.7212   |
| Q_loss                         | 116.9834   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 815        |
| times/epoch_after_hook         | 1.59e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.00053    |
| times/evaluation_paths         | 37.8       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 61.6       |
| timestep                       | 1000       |
| timesteps_total                | 816000     |
| train-steps                    | 816000     |
| training/Q/q1_loss             | 100.96283  |
| training/sac_pi/alpha          | 0.15724376 |
| training/sac_pi/alpha_loss     | 0.13792518 |
| training/sac_pi/logp_pi        | 4.9774275  |
| training/sac_pi/pi_entropy     | 3.2453563  |
| training/sac_pi/pi_global_norm | 1.8306502  |
| training/sac_pi/policy_loss    | -232.43645 |
| training/sac_pi/std            | 0.50272936 |
| training/sac_pi/valid_num      | 4953.0     |
| training/sac_Q/q1              | 212.70615  |
| training/sac_Q/q2              | 218.28528  |
| training/sac_Q/q2_loss         | 100.93547  |
| training/sac_Q/q_global_norm   | 357.16135  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1574567  |
| epoch                          | 816        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5018.784   |
| evaluation/return-max          | 5055.6567  |
| evaluation/return-min          | 4959.0283  |
| evaluation/return-std          | 27.213482  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46352      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5018.784   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 216.7771   |
| Q-std                          | 141.48842  |
| Q_loss                         | 80.68708   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 816        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000135   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.0006     |
| times/evaluation_paths         | 35.1       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 62.2       |
| timestep                       | 1000       |
| timesteps_total                | 817000     |
| train-steps                    | 817000     |
| training/Q/q1_loss             | 106.90267  |
| training/sac_pi/alpha          | 0.15742996 |
| training/sac_pi/alpha_loss     | 0.37536564 |
| training/sac_pi/logp_pi        | 4.1683593  |
| training/sac_pi/pi_entropy     | 3.3848584  |
| training/sac_pi/pi_global_norm | 1.9148282  |
| training/sac_pi/policy_loss    | -221.24797 |
| training/sac_pi/std            | 0.4824787  |
| training/sac_pi/valid_num      | 4998.0     |
| training/sac_Q/q1              | 212.33008  |
| training/sac_Q/q2              | 214.02261  |
| training/sac_Q/q2_loss         | 106.07444  |
| training/sac_Q/q_global_norm   | 202.61024  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1574175   |
| epoch                          | 817         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5127.802    |
| evaluation/return-max          | 5168.711    |
| evaluation/return-min          | 5054.1436   |
| evaluation/return-std          | 34.175804   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 86.9        |
| model/penalty_ret              | 80.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46413       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5127.802    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 223.47343   |
| Q-std                          | 162.54704   |
| Q_loss                         | 86.91489    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 817         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000292    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000519    |
| times/evaluation_paths         | 38.6        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 63.2        |
| timestep                       | 1000        |
| timesteps_total                | 818000      |
| train-steps                    | 818000      |
| training/Q/q1_loss             | 101.40043   |
| training/sac_pi/alpha          | 0.15740949  |
| training/sac_pi/alpha_loss     | -0.21541679 |
| training/sac_pi/logp_pi        | 3.773156    |
| training/sac_pi/pi_entropy     | 3.3472905   |
| training/sac_pi/pi_global_norm | 1.6710393   |
| training/sac_pi/policy_loss    | -230.28467  |
| training/sac_pi/std            | 0.4744248   |
| training/sac_pi/valid_num      | 5019.0      |
| training/sac_Q/q1              | 223.95454   |
| training/sac_Q/q2              | 224.28252   |
| training/sac_Q/q2_loss         | 100.54356   |
| training/sac_Q/q_global_norm   | 247.65027   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15873045   |
| epoch                          | 818          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5075.946     |
| evaluation/return-max          | 5157.4365    |
| evaluation/return-min          | 5004.6597    |
| evaluation/return-std          | 51.487083    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.12         |
| model/origin_ret               | 84.9         |
| model/penalty_ret              | 79.1         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46564        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5075.946     |
| perf/NormalizedReturn          | 1.11         |
| Q-avg                          | 215.57597    |
| Q-std                          | 127.67924    |
| Q_loss                         | 91.93979     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 818          |
| times/epoch_after_hook         | 1.7e-06      |
| times/epoch_before_hook        | 0.000114     |
| times/epoch_rollout_model      | 483          |
| times/evaluation_metrics       | 0.000521     |
| times/evaluation_paths         | 33.4         |
| times/timestep_after_hook      | 0.0037       |
| times/timestep_before_hook     | 0.00827      |
| times/train                    | 62.6         |
| timestep                       | 1000         |
| timesteps_total                | 819000       |
| train-steps                    | 819000       |
| training/Q/q1_loss             | 91.98602     |
| training/sac_pi/alpha          | 0.15874292   |
| training/sac_pi/alpha_loss     | -0.025847185 |
| training/sac_pi/logp_pi        | 3.806165     |
| training/sac_pi/pi_entropy     | 3.3773446    |
| training/sac_pi/pi_global_norm | 1.5742416    |
| training/sac_pi/policy_loss    | -230.33414   |
| training/sac_pi/std            | 0.4710722    |
| training/sac_pi/valid_num      | 5025.0       |
| training/sac_Q/q1              | 224.96465    |
| training/sac_Q/q2              | 225.5217     |
| training/sac_Q/q2_loss         | 91.50644     |
| training/sac_Q/q_global_norm   | 235.66533    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16079167 |
| epoch                          | 819        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5204.1743  |
| evaluation/return-max          | 5246.1626  |
| evaluation/return-min          | 5169.6826  |
| evaluation/return-std          | 21.49183   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.06       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46381      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5204.1743  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 214.4017   |
| Q-std                          | 191.83206  |
| Q_loss                         | 112.00937  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 819        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.00054    |
| times/evaluation_paths         | 36.8       |
| times/timestep_after_hook      | 0.00354    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 820000     |
| train-steps                    | 820000     |
| training/Q/q1_loss             | 90.86774   |
| training/sac_pi/alpha          | 0.16074847 |
| training/sac_pi/alpha_loss     | 0.18092342 |
| training/sac_pi/logp_pi        | 4.2469893  |
| training/sac_pi/pi_entropy     | 3.5254905  |
| training/sac_pi/pi_global_norm | 1.7770779  |
| training/sac_pi/policy_loss    | -225.77596 |
| training/sac_pi/std            | 0.5143575  |
| training/sac_pi/valid_num      | 4993.0     |
| training/sac_Q/q1              | 209.66898  |
| training/sac_Q/q2              | 212.04851  |
| training/sac_Q/q2_loss         | 91.841965  |
| training/sac_Q/q_global_norm   | 319.7257   |
--------------------------------------------------------------------------------
[WARN] 820 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.1621507  |
| epoch                          | 820        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4987.0933  |
| evaluation/return-max          | 5037.835   |
| evaluation/return-min          | 4936.949   |
| evaluation/return-std          | 34.37803   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46497      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4987.0933  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 215.2666   |
| Q-std                          | 191.51324  |
| Q_loss                         | 105.64529  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 820        |
| times/epoch_after_hook         | 1.64e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000527   |
| times/evaluation_paths         | 34.6       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 61.4       |
| timestep                       | 1000       |
| timesteps_total                | 821000     |
| train-steps                    | 821000     |
| training/Q/q1_loss             | 106.58861  |
| training/sac_pi/alpha          | 0.1621192  |
| training/sac_pi/alpha_loss     | 0.50139916 |
| training/sac_pi/logp_pi        | 4.5680428  |
| training/sac_pi/pi_entropy     | 3.3814366  |
| training/sac_pi/pi_global_norm | 1.9564815  |
| training/sac_pi/policy_loss    | -235.70155 |
| training/sac_pi/std            | 0.5023721  |
| training/sac_pi/valid_num      | 4987.0     |
| training/sac_Q/q1              | 224.748    |
| training/sac_Q/q2              | 226.43985  |
| training/sac_Q/q2_loss         | 106.5533   |
| training/sac_Q/q_global_norm   | 194.13289  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16005293 |
| epoch                          | 821        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4846.936   |
| evaluation/return-max          | 4984.3096  |
| evaluation/return-min          | 4776.1836  |
| evaluation/return-std          | 70.85474   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46439      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4846.936   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 212.09526  |
| Q-std                          | 145.97601  |
| Q_loss                         | 85.145065  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 821        |
| times/epoch_after_hook         | 1.62e-06   |
| times/epoch_before_hook        | 0.000288   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000792   |
| times/evaluation_paths         | 35.8       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 63         |
| timestep                       | 1000       |
| timesteps_total                | 822000     |
| train-steps                    | 822000     |
| training/Q/q1_loss             | 104.85789  |
| training/sac_pi/alpha          | 0.16000657 |
| training/sac_pi/alpha_loss     | 0.20494607 |
| training/sac_pi/logp_pi        | 4.7269325  |
| training/sac_pi/pi_entropy     | 3.5044065  |
| training/sac_pi/pi_global_norm | 2.6366959  |
| training/sac_pi/policy_loss    | -234.46352 |
| training/sac_pi/std            | 0.5322294  |
| training/sac_pi/valid_num      | 4926.0     |
| training/sac_Q/q1              | 213.96701  |
| training/sac_Q/q2              | 217.45142  |
| training/sac_Q/q2_loss         | 104.57012  |
| training/sac_Q/q_global_norm   | 222.32095  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16233811 |
| epoch                          | 822        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5026.7925  |
| evaluation/return-max          | 5107.9697  |
| evaluation/return-min          | 4963.075   |
| evaluation/return-std          | 49.206776  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46489      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5026.7925  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 221.56802  |
| Q-std                          | 144.43306  |
| Q_loss                         | 95.47939   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 822        |
| times/epoch_after_hook         | 1.59e-06   |
| times/epoch_before_hook        | 0.000134   |
| times/epoch_rollout_model      | 485        |
| times/evaluation_metrics       | 0.000626   |
| times/evaluation_paths         | 35.9       |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 62.3       |
| timestep                       | 1000       |
| timesteps_total                | 823000     |
| train-steps                    | 823000     |
| training/Q/q1_loss             | 110.79182  |
| training/sac_pi/alpha          | 0.16236085 |
| training/sac_pi/alpha_loss     | 0.18640625 |
| training/sac_pi/logp_pi        | 4.4032083  |
| training/sac_pi/pi_entropy     | 3.2466202  |
| training/sac_pi/pi_global_norm | 1.716363   |
| training/sac_pi/policy_loss    | -236.02216 |
| training/sac_pi/std            | 0.46778426 |
| training/sac_pi/valid_num      | 4965.0     |
| training/sac_Q/q1              | 221.87439  |
| training/sac_Q/q2              | 223.76372  |
| training/sac_Q/q2_loss         | 111.39611  |
| training/sac_Q/q_global_norm   | 229.19035  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16237128   |
| epoch                          | 823          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4865.254     |
| evaluation/return-max          | 5087.549     |
| evaluation/return-min          | 4727.1777    |
| evaluation/return-std          | 122.453926   |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.09         |
| model/origin_ret               | 85.8         |
| model/penalty_ret              | 79.8         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46384        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4865.254     |
| perf/NormalizedReturn          | 1.06         |
| Q-avg                          | 214.46553    |
| Q-std                          | 203.76797    |
| Q_loss                         | 119.41068    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 823          |
| times/epoch_after_hook         | 1.78e-06     |
| times/epoch_before_hook        | 0.00013      |
| times/epoch_rollout_model      | 490          |
| times/evaluation_metrics       | 0.000654     |
| times/evaluation_paths         | 34.3         |
| times/timestep_after_hook      | 0.00371      |
| times/timestep_before_hook     | 0.00821      |
| times/train                    | 62.6         |
| timestep                       | 1000         |
| timesteps_total                | 824000       |
| train-steps                    | 824000       |
| training/Q/q1_loss             | 104.95952    |
| training/sac_pi/alpha          | 0.16238129   |
| training/sac_pi/alpha_loss     | -0.064714104 |
| training/sac_pi/logp_pi        | 4.363818     |
| training/sac_pi/pi_entropy     | 3.606984     |
| training/sac_pi/pi_global_norm | 1.7256262    |
| training/sac_pi/policy_loss    | -231.75119   |
| training/sac_pi/std            | 0.536799     |
| training/sac_pi/valid_num      | 4951.0       |
| training/sac_Q/q1              | 213.46318    |
| training/sac_Q/q2              | 218.89336    |
| training/sac_Q/q2_loss         | 104.89586    |
| training/sac_Q/q_global_norm   | 261.97784    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15616783 |
| epoch                          | 824        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5037.8677  |
| evaluation/return-max          | 5049.3633  |
| evaluation/return-min          | 5026.9805  |
| evaluation/return-std          | 7.083048   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.18       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46473      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5037.8677  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 216.86736  |
| Q-std                          | 115.110374 |
| Q_loss                         | 90.885254  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 824        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000525   |
| times/evaluation_paths         | 38.9       |
| times/timestep_after_hook      | 0.00376    |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 65.5       |
| timestep                       | 1000       |
| timesteps_total                | 825000     |
| train-steps                    | 825000     |
| training/Q/q1_loss             | 90.91333   |
| training/sac_pi/alpha          | 0.15615779 |
| training/sac_pi/alpha_loss     | 0.09704573 |
| training/sac_pi/logp_pi        | 4.1402483  |
| training/sac_pi/pi_entropy     | 3.471421   |
| training/sac_pi/pi_global_norm | 2.1656291  |
| training/sac_pi/policy_loss    | -226.94197 |
| training/sac_pi/std            | 0.5116934  |
| training/sac_pi/valid_num      | 4963.0     |
| training/sac_Q/q1              | 212.65268  |
| training/sac_Q/q2              | 216.41635  |
| training/sac_Q/q2_loss         | 89.98763   |
| training/sac_Q/q_global_norm   | 239.3135   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1632034  |
| epoch                          | 825        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4928.766   |
| evaluation/return-max          | 5031.084   |
| evaluation/return-min          | 4875.878   |
| evaluation/return-std          | 51.647434  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46473      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4928.766   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 228.71121  |
| Q-std                          | 126.24608  |
| Q_loss                         | 95.58248   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 825        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000308   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000565   |
| times/evaluation_paths         | 38.3       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 62.2       |
| timestep                       | 1000       |
| timesteps_total                | 826000     |
| train-steps                    | 826000     |
| training/Q/q1_loss             | 104.580345 |
| training/sac_pi/alpha          | 0.16318151 |
| training/sac_pi/alpha_loss     | 0.31228256 |
| training/sac_pi/logp_pi        | 4.6224413  |
| training/sac_pi/pi_entropy     | 3.4170387  |
| training/sac_pi/pi_global_norm | 2.0340755  |
| training/sac_pi/policy_loss    | -229.51132 |
| training/sac_pi/std            | 0.50811577 |
| training/sac_pi/valid_num      | 4971.0     |
| training/sac_Q/q1              | 214.20993  |
| training/sac_Q/q2              | 218.25371  |
| training/sac_Q/q2_loss         | 105.06341  |
| training/sac_Q/q_global_norm   | 353.48383  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16029567  |
| epoch                          | 826         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4861.4253   |
| evaluation/return-max          | 4929.6787   |
| evaluation/return-min          | 4753.826    |
| evaluation/return-std          | 46.653107   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.17        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46439       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4861.4253   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 223.62459   |
| Q-std                          | 141.4239    |
| Q_loss                         | 77.72015    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 826         |
| times/epoch_after_hook         | 3.16e-06    |
| times/epoch_before_hook        | 0.000159    |
| times/epoch_rollout_model      | 484         |
| times/evaluation_metrics       | 0.00062     |
| times/evaluation_paths         | 36.7        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 62.3        |
| timestep                       | 1000        |
| timesteps_total                | 827000      |
| train-steps                    | 827000      |
| training/Q/q1_loss             | 78.40617    |
| training/sac_pi/alpha          | 0.16029365  |
| training/sac_pi/alpha_loss     | -0.05369546 |
| training/sac_pi/logp_pi        | 4.008973    |
| training/sac_pi/pi_entropy     | 3.4360871   |
| training/sac_pi/pi_global_norm | 2.0338876   |
| training/sac_pi/policy_loss    | -232.3861   |
| training/sac_pi/std            | 0.48656955  |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 220.50032   |
| training/sac_Q/q2              | 225.02852   |
| training/sac_Q/q2_loss         | 78.88772    |
| training/sac_Q/q_global_norm   | 234.28175   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16373183 |
| epoch                          | 827        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4938.186   |
| evaluation/return-max          | 4967.0205  |
| evaluation/return-min          | 4897.3955  |
| evaluation/return-std          | 23.57904   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46460      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4938.186   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 212.06616  |
| Q-std                          | 238.8213   |
| Q_loss                         | 91.63915   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 827        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000601   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00857    |
| times/train                    | 63.5       |
| timestep                       | 1000       |
| timesteps_total                | 828000     |
| train-steps                    | 828000     |
| training/Q/q1_loss             | 111.55576  |
| training/sac_pi/alpha          | 0.16371523 |
| training/sac_pi/alpha_loss     | 0.27017078 |
| training/sac_pi/logp_pi        | 4.1008406  |
| training/sac_pi/pi_entropy     | 3.4661345  |
| training/sac_pi/pi_global_norm | 1.781332   |
| training/sac_pi/policy_loss    | -228.70178 |
| training/sac_pi/std            | 0.49618798 |
| training/sac_pi/valid_num      | 4964.0     |
| training/sac_Q/q1              | 218.22481  |
| training/sac_Q/q2              | 220.2574   |
| training/sac_Q/q2_loss         | 111.18575  |
| training/sac_Q/q_global_norm   | 281.75952  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16166149  |
| epoch                          | 828         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4926.873    |
| evaluation/return-max          | 5006.088    |
| evaluation/return-min          | 4852.379    |
| evaluation/return-std          | 45.564606   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46514       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4926.873    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 225.6145    |
| Q-std                          | 127.38369   |
| Q_loss                         | 76.75601    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 828         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000701    |
| times/evaluation_paths         | 38.9        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 68.5        |
| timestep                       | 1000        |
| timesteps_total                | 829000      |
| train-steps                    | 829000      |
| training/Q/q1_loss             | 98.94182    |
| training/sac_pi/alpha          | 0.1616874   |
| training/sac_pi/alpha_loss     | -0.19230407 |
| training/sac_pi/logp_pi        | 3.8931649   |
| training/sac_pi/pi_entropy     | 3.366729    |
| training/sac_pi/pi_global_norm | 2.008068    |
| training/sac_pi/policy_loss    | -224.15019  |
| training/sac_pi/std            | 0.4747307   |
| training/sac_pi/valid_num      | 4933.0      |
| training/sac_Q/q1              | 213.4041    |
| training/sac_Q/q2              | 214.85112   |
| training/sac_Q/q2_loss         | 98.52328    |
| training/sac_Q/q_global_norm   | 250.83449   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16949171 |
| epoch                          | 829        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4692.2554  |
| evaluation/return-max          | 4732.0396  |
| evaluation/return-min          | 4645.663   |
| evaluation/return-std          | 26.574291  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46529      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4692.2554  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 207.19052  |
| Q-std                          | 188.14027  |
| Q_loss                         | 100.266754 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 829        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000291   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000575   |
| times/evaluation_paths         | 38.1       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00828    |
| times/train                    | 63.3       |
| timestep                       | 1000       |
| timesteps_total                | 830000     |
| train-steps                    | 830000     |
| training/Q/q1_loss             | 106.69749  |
| training/sac_pi/alpha          | 0.16945498 |
| training/sac_pi/alpha_loss     | 0.24872354 |
| training/sac_pi/logp_pi        | 3.9771984  |
| training/sac_pi/pi_entropy     | 3.599214   |
| training/sac_pi/pi_global_norm | 1.4928228  |
| training/sac_pi/policy_loss    | -232.51459 |
| training/sac_pi/std            | 0.4947185  |
| training/sac_pi/valid_num      | 4961.0     |
| training/sac_Q/q1              | 221.55473  |
| training/sac_Q/q2              | 224.10947  |
| training/sac_Q/q2_loss         | 105.0541   |
| training/sac_Q/q_global_norm   | 218.09798  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15972129  |
| epoch                          | 830         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5260.7847   |
| evaluation/return-max          | 5321.477    |
| evaluation/return-min          | 5192.1113   |
| evaluation/return-std          | 46.260506   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.17        |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46454       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5260.7847   |
| perf/NormalizedReturn          | 1.15        |
| Q-avg                          | 212.33017   |
| Q-std                          | 174.86803   |
| Q_loss                         | 110.16109   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 830         |
| times/epoch_after_hook         | 1.57e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000519    |
| times/evaluation_paths         | 36.1        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 60.4        |
| timestep                       | 1000        |
| timesteps_total                | 831000      |
| train-steps                    | 831000      |
| training/Q/q1_loss             | 116.53929   |
| training/sac_pi/alpha          | 0.15973091  |
| training/sac_pi/alpha_loss     | 0.038482524 |
| training/sac_pi/logp_pi        | 4.1417146   |
| training/sac_pi/pi_entropy     | 3.324489    |
| training/sac_pi/pi_global_norm | 2.0243163   |
| training/sac_pi/policy_loss    | -227.77182  |
| training/sac_pi/std            | 0.48458996  |
| training/sac_pi/valid_num      | 5019.0      |
| training/sac_Q/q1              | 216.89738   |
| training/sac_Q/q2              | 221.11722   |
| training/sac_Q/q2_loss         | 115.46065   |
| training/sac_Q/q_global_norm   | 222.78181   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16406235  |
| epoch                          | 831         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5234.4424   |
| evaluation/return-max          | 5295.1143   |
| evaluation/return-min          | 5121.049    |
| evaluation/return-std          | 44.45636    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46608       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5234.4424   |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 219.45053   |
| Q-std                          | 151.55872   |
| Q_loss                         | 92.850494   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 831         |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000582    |
| times/evaluation_paths         | 38.7        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 60.5        |
| timestep                       | 1000        |
| timesteps_total                | 832000      |
| train-steps                    | 832000      |
| training/Q/q1_loss             | 83.047516   |
| training/sac_pi/alpha          | 0.16408771  |
| training/sac_pi/alpha_loss     | -0.23834245 |
| training/sac_pi/logp_pi        | 3.8407142   |
| training/sac_pi/pi_entropy     | 3.4410267   |
| training/sac_pi/pi_global_norm | 1.6861209   |
| training/sac_pi/policy_loss    | -230.95013  |
| training/sac_pi/std            | 0.48508027  |
| training/sac_pi/valid_num      | 5031.0      |
| training/sac_Q/q1              | 224.18501   |
| training/sac_Q/q2              | 223.85909   |
| training/sac_Q/q2_loss         | 83.674065   |
| training/sac_Q/q_global_norm   | 175.69864   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16054003 |
| epoch                          | 832        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5052.1025  |
| evaluation/return-max          | 5226.412   |
| evaluation/return-min          | 4885.8906  |
| evaluation/return-std          | 124.62168  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46578      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5052.1025  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 230.14082  |
| Q-std                          | 112.05305  |
| Q_loss                         | 93.50218   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 832        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000685   |
| times/evaluation_paths         | 39.8       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00832    |
| times/train                    | 72.9       |
| timestep                       | 1000       |
| timesteps_total                | 833000     |
| train-steps                    | 833000     |
| training/Q/q1_loss             | 99.88649   |
| training/sac_pi/alpha          | 0.16052689 |
| training/sac_pi/alpha_loss     | 0.25058937 |
| training/sac_pi/logp_pi        | 4.79663    |
| training/sac_pi/pi_entropy     | 3.4954731  |
| training/sac_pi/pi_global_norm | 1.767875   |
| training/sac_pi/policy_loss    | -222.66707 |
| training/sac_pi/std            | 0.5128489  |
| training/sac_pi/valid_num      | 4966.0     |
| training/sac_Q/q1              | 209.19534  |
| training/sac_Q/q2              | 209.73979  |
| training/sac_Q/q2_loss         | 100.041084 |
| training/sac_Q/q_global_norm   | 229.93442  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15964401   |
| epoch                          | 833          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4973.4688    |
| evaluation/return-max          | 5012.884     |
| evaluation/return-min          | 4935.985     |
| evaluation/return-std          | 21.49444     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.12         |
| model/origin_ret               | 85.7         |
| model/penalty_ret              | 79.4         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46429        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4973.4688    |
| perf/NormalizedReturn          | 1.08         |
| Q-avg                          | 217.74712    |
| Q-std                          | 141.46593    |
| Q_loss                         | 96.59847     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 833          |
| times/epoch_after_hook         | 1.7e-06      |
| times/epoch_before_hook        | 0.000346     |
| times/epoch_rollout_model      | 480          |
| times/evaluation_metrics       | 0.000517     |
| times/evaluation_paths         | 35.7         |
| times/timestep_after_hook      | 0.00365      |
| times/timestep_before_hook     | 0.00819      |
| times/train                    | 60.4         |
| timestep                       | 1000         |
| timesteps_total                | 834000       |
| train-steps                    | 834000       |
| training/Q/q1_loss             | 86.66486     |
| training/sac_pi/alpha          | 0.15962264   |
| training/sac_pi/alpha_loss     | -0.019086737 |
| training/sac_pi/logp_pi        | 4.4397516    |
| training/sac_pi/pi_entropy     | 3.3327727    |
| training/sac_pi/pi_global_norm | 2.2011642    |
| training/sac_pi/policy_loss    | -231.01784   |
| training/sac_pi/std            | 0.5070562    |
| training/sac_pi/valid_num      | 4940.0       |
| training/sac_Q/q1              | 213.41635    |
| training/sac_Q/q2              | 212.63931    |
| training/sac_Q/q2_loss         | 87.66945     |
| training/sac_Q/q_global_norm   | 177.27202    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15879889 |
| epoch                          | 834        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4957.615   |
| evaluation/return-max          | 5112.1646  |
| evaluation/return-min          | 4836.028   |
| evaluation/return-std          | 96.86978   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46509      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4957.615   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 203.68492  |
| Q-std                          | 229.48943  |
| Q_loss                         | 103.72231  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 834        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000142   |
| times/epoch_rollout_model      | 517        |
| times/evaluation_metrics       | 0.000543   |
| times/evaluation_paths         | 34.5       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 835000     |
| train-steps                    | 835000     |
| training/Q/q1_loss             | 95.34002   |
| training/sac_pi/alpha          | 0.15876204 |
| training/sac_pi/alpha_loss     | 0.19766662 |
| training/sac_pi/logp_pi        | 3.7717042  |
| training/sac_pi/pi_entropy     | 3.3600068  |
| training/sac_pi/pi_global_norm | 1.8545524  |
| training/sac_pi/policy_loss    | -234.57991 |
| training/sac_pi/std            | 0.47823158 |
| training/sac_pi/valid_num      | 5031.0     |
| training/sac_Q/q1              | 225.1178   |
| training/sac_Q/q2              | 226.78304  |
| training/sac_Q/q2_loss         | 95.33896   |
| training/sac_Q/q_global_norm   | 244.55775  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15891513   |
| epoch                          | 835          |
| evaluation/episode-length-avg  | 828          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 136          |
| evaluation/episode-length-std  | 345          |
| evaluation/return-average      | 4123.1357    |
| evaluation/return-max          | 5090.0576    |
| evaluation/return-min          | 360.1328     |
| evaluation/return-std          | 1878.0513    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.15         |
| model/origin_ret               | 86.1         |
| model/penalty_ret              | 78.9         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46532        |
| perf/AverageLength             | 828          |
| perf/AverageReturn             | 4123.1357    |
| perf/NormalizedReturn          | 0.898        |
| Q-avg                          | 223.26492    |
| Q-std                          | 156.6812     |
| Q_loss                         | 83.176926    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 835          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.000123     |
| times/epoch_rollout_model      | 511          |
| times/evaluation_metrics       | 0.000585     |
| times/evaluation_paths         | 29.2         |
| times/timestep_after_hook      | 0.00371      |
| times/timestep_before_hook     | 0.00845      |
| times/train                    | 61.3         |
| timestep                       | 1000         |
| timesteps_total                | 836000       |
| train-steps                    | 836000       |
| training/Q/q1_loss             | 105.31297    |
| training/sac_pi/alpha          | 0.15892215   |
| training/sac_pi/alpha_loss     | -0.016792666 |
| training/sac_pi/logp_pi        | 4.812089     |
| training/sac_pi/pi_entropy     | 3.6051       |
| training/sac_pi/pi_global_norm | 1.9091772    |
| training/sac_pi/policy_loss    | -225.47516   |
| training/sac_pi/std            | 0.54701495   |
| training/sac_pi/valid_num      | 4905.0       |
| training/sac_Q/q1              | 203.33662    |
| training/sac_Q/q2              | 209.94626    |
| training/sac_Q/q2_loss         | 106.23188    |
| training/sac_Q/q_global_norm   | 297.48724    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16308443  |
| epoch                          | 836         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4890.497    |
| evaluation/return-max          | 4973.3647   |
| evaluation/return-min          | 4802.9697   |
| evaluation/return-std          | 42.925953   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46430       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4890.497    |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 227.86685   |
| Q-std                          | 136.6657    |
| Q_loss                         | 96.21788    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 836         |
| times/epoch_after_hook         | 1.54e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 507         |
| times/evaluation_metrics       | 0.000529    |
| times/evaluation_paths         | 38          |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 72.4        |
| timestep                       | 1000        |
| timesteps_total                | 837000      |
| train-steps                    | 837000      |
| training/Q/q1_loss             | 88.32366    |
| training/sac_pi/alpha          | 0.16311343  |
| training/sac_pi/alpha_loss     | -0.26840144 |
| training/sac_pi/logp_pi        | 4.2489448   |
| training/sac_pi/pi_entropy     | 3.6007984   |
| training/sac_pi/pi_global_norm | 1.9126868   |
| training/sac_pi/policy_loss    | -230.04326  |
| training/sac_pi/std            | 0.5184327   |
| training/sac_pi/valid_num      | 5010.0      |
| training/sac_Q/q1              | 215.04346   |
| training/sac_Q/q2              | 219.56726   |
| training/sac_Q/q2_loss         | 88.0801     |
| training/sac_Q/q_global_norm   | 188.73048   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1605511  |
| epoch                          | 837        |
| evaluation/episode-length-avg  | 916        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 163        |
| evaluation/episode-length-std  | 251        |
| evaluation/return-average      | 4438.232   |
| evaluation/return-max          | 4939.9697  |
| evaluation/return-min          | 481.4796   |
| evaluation/return-std          | 1319.1189  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46402      |
| perf/AverageLength             | 916        |
| perf/AverageReturn             | 4438.232   |
| perf/NormalizedReturn          | 0.966      |
| Q-avg                          | 217.62735  |
| Q-std                          | 118.74191  |
| Q_loss                         | 102.11526  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 837        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000326   |
| times/epoch_rollout_model      | 525        |
| times/evaluation_metrics       | 0.000526   |
| times/evaluation_paths         | 31         |
| times/timestep_after_hook      | 0.00354    |
| times/timestep_before_hook     | 0.00839    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 838000     |
| train-steps                    | 838000     |
| training/Q/q1_loss             | 107.21894  |
| training/sac_pi/alpha          | 0.16056456 |
| training/sac_pi/alpha_loss     | 0.1388945  |
| training/sac_pi/logp_pi        | 3.8771186  |
| training/sac_pi/pi_entropy     | 3.2663186  |
| training/sac_pi/pi_global_norm | 1.9424797  |
| training/sac_pi/policy_loss    | -229.89893 |
| training/sac_pi/std            | 0.46747133 |
| training/sac_pi/valid_num      | 5009.0     |
| training/sac_Q/q1              | 217.9334   |
| training/sac_Q/q2              | 220.21318  |
| training/sac_Q/q2_loss         | 108.35733  |
| training/sac_Q/q_global_norm   | 258.6703   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16389973 |
| epoch                          | 838        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5084.4775  |
| evaluation/return-max          | 5132.933   |
| evaluation/return-min          | 5045.3467  |
| evaluation/return-std          | 28.786747  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46459      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5084.4775  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 229.92847  |
| Q-std                          | 91.00448   |
| Q_loss                         | 96.930405  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 838        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 517        |
| times/evaluation_metrics       | 0.000564   |
| times/evaluation_paths         | 37.5       |
| times/timestep_after_hook      | 0.00377    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 839000     |
| train-steps                    | 839000     |
| training/Q/q1_loss             | 82.70723   |
| training/sac_pi/alpha          | 0.16388059 |
| training/sac_pi/alpha_loss     | 0.19472757 |
| training/sac_pi/logp_pi        | 5.4689455  |
| training/sac_pi/pi_entropy     | 3.677285   |
| training/sac_pi/pi_global_norm | 1.6392884  |
| training/sac_pi/policy_loss    | -228.10611 |
| training/sac_pi/std            | 0.5909359  |
| training/sac_pi/valid_num      | 4875.0     |
| training/sac_Q/q1              | 205.16196  |
| training/sac_Q/q2              | 210.51872  |
| training/sac_Q/q2_loss         | 81.78441   |
| training/sac_Q/q_global_norm   | 181.17639  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16772951  |
| epoch                          | 839         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5177.8223   |
| evaluation/return-max          | 5213.619    |
| evaluation/return-min          | 5132.2183   |
| evaluation/return-std          | 26.976881   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.15        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46507       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5177.8223   |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 215.95187   |
| Q-std                          | 151.90251   |
| Q_loss                         | 103.9657    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 839         |
| times/epoch_after_hook         | 1.61e-06    |
| times/epoch_before_hook        | 0.000132    |
| times/epoch_rollout_model      | 504         |
| times/evaluation_metrics       | 0.000539    |
| times/evaluation_paths         | 37.6        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00851     |
| times/train                    | 60.2        |
| timestep                       | 1000        |
| timesteps_total                | 840000      |
| train-steps                    | 840000      |
| training/Q/q1_loss             | 119.28398   |
| training/sac_pi/alpha          | 0.16777423  |
| training/sac_pi/alpha_loss     | -0.24379173 |
| training/sac_pi/logp_pi        | 5.0318356   |
| training/sac_pi/pi_entropy     | 3.5843887   |
| training/sac_pi/pi_global_norm | 2.3141959   |
| training/sac_pi/policy_loss    | -225.24931  |
| training/sac_pi/std            | 0.54608226  |
| training/sac_pi/valid_num      | 4935.0      |
| training/sac_Q/q1              | 202.3262    |
| training/sac_Q/q2              | 212.22607   |
| training/sac_Q/q2_loss         | 119.67794   |
| training/sac_Q/q_global_norm   | 287.6052    |
---------------------------------------------------------------------------------
[WARN] 840 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.16909511  |
| epoch                          | 840         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5059.5923   |
| evaluation/return-max          | 5127.368    |
| evaluation/return-min          | 4953.86     |
| evaluation/return-std          | 52.302227   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.07        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46548       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5059.5923   |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 208.10295   |
| Q-std                          | 173.97565   |
| Q_loss                         | 115.84602   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 840         |
| times/epoch_after_hook         | 1.61e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 517         |
| times/evaluation_metrics       | 0.000599    |
| times/evaluation_paths         | 37.9        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 70.9        |
| timestep                       | 1000        |
| timesteps_total                | 841000      |
| train-steps                    | 841000      |
| training/Q/q1_loss             | 87.508194   |
| training/sac_pi/alpha          | 0.16911787  |
| training/sac_pi/alpha_loss     | -0.20462377 |
| training/sac_pi/logp_pi        | 4.3380394   |
| training/sac_pi/pi_entropy     | 3.4773414   |
| training/sac_pi/pi_global_norm | 1.6858007   |
| training/sac_pi/policy_loss    | -234.20853  |
| training/sac_pi/std            | 0.4959379   |
| training/sac_pi/valid_num      | 4903.0      |
| training/sac_Q/q1              | 217.5004    |
| training/sac_Q/q2              | 223.47684   |
| training/sac_Q/q2_loss         | 87.38006    |
| training/sac_Q/q_global_norm   | 265.13925   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16659981 |
| epoch                          | 841        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5429.296   |
| evaluation/return-max          | 5464.18    |
| evaluation/return-min          | 5391.6904  |
| evaluation/return-std          | 25.996563  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 80         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46591      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5429.296   |
| perf/NormalizedReturn          | 1.18       |
| Q-avg                          | 228.02676  |
| Q-std                          | 99.252754  |
| Q_loss                         | 116.956055 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 841        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000271   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.00057    |
| times/evaluation_paths         | 36.7       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 842000     |
| train-steps                    | 842000     |
| training/Q/q1_loss             | 108.204124 |
| training/sac_pi/alpha          | 0.16663112 |
| training/sac_pi/alpha_loss     | 0.20938529 |
| training/sac_pi/logp_pi        | 3.985295   |
| training/sac_pi/pi_entropy     | 3.3858342  |
| training/sac_pi/pi_global_norm | 1.6342261  |
| training/sac_pi/policy_loss    | -234.25343 |
| training/sac_pi/std            | 0.46298096 |
| training/sac_pi/valid_num      | 5027.0     |
| training/sac_Q/q1              | 222.34615  |
| training/sac_Q/q2              | 226.47574  |
| training/sac_Q/q2_loss         | 107.883606 |
| training/sac_Q/q_global_norm   | 282.86307  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16901083   |
| epoch                          | 842          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5029.1357    |
| evaluation/return-max          | 5147.673     |
| evaluation/return-min          | 4919.66      |
| evaluation/return-std          | 69.41862     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.12         |
| model/origin_ret               | 86.5         |
| model/penalty_ret              | 79           |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46287        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5029.1357    |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 214.97623    |
| Q-std                          | 137.14441    |
| Q_loss                         | 115.3561     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 842          |
| times/epoch_after_hook         | 1.76e-06     |
| times/epoch_before_hook        | 0.000123     |
| times/epoch_rollout_model      | 509          |
| times/evaluation_metrics       | 0.000595     |
| times/evaluation_paths         | 35.6         |
| times/timestep_after_hook      | 0.00361      |
| times/timestep_before_hook     | 0.00826      |
| times/train                    | 60           |
| timestep                       | 1000         |
| timesteps_total                | 843000       |
| train-steps                    | 843000       |
| training/Q/q1_loss             | 93.18087     |
| training/sac_pi/alpha          | 0.16902198   |
| training/sac_pi/alpha_loss     | -0.034294147 |
| training/sac_pi/logp_pi        | 3.33307      |
| training/sac_pi/pi_entropy     | 3.4034004    |
| training/sac_pi/pi_global_norm | 2.1640897    |
| training/sac_pi/policy_loss    | -230.97131   |
| training/sac_pi/std            | 0.45884416   |
| training/sac_pi/valid_num      | 5003.0       |
| training/sac_Q/q1              | 224.08667    |
| training/sac_Q/q2              | 224.98662    |
| training/sac_Q/q2_loss         | 92.42594     |
| training/sac_Q/q_global_norm   | 280.29562    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16173343  |
| epoch                          | 843         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4954.585    |
| evaluation/return-max          | 5167.2295   |
| evaluation/return-min          | 4868.2344   |
| evaluation/return-std          | 85.55082    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46520       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4954.585    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 214.68318   |
| Q-std                          | 152.69176   |
| Q_loss                         | 107.895424  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 843         |
| times/epoch_after_hook         | 1.72e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 503         |
| times/evaluation_metrics       | 0.00066     |
| times/evaluation_paths         | 37.1        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00832     |
| times/train                    | 59.5        |
| timestep                       | 1000        |
| timesteps_total                | 844000      |
| train-steps                    | 844000      |
| training/Q/q1_loss             | 105.69186   |
| training/sac_pi/alpha          | 0.16174214  |
| training/sac_pi/alpha_loss     | -0.12937248 |
| training/sac_pi/logp_pi        | 4.3170314   |
| training/sac_pi/pi_entropy     | 3.3857217   |
| training/sac_pi/pi_global_norm | 1.6491402   |
| training/sac_pi/policy_loss    | -224.61313  |
| training/sac_pi/std            | 0.48904726  |
| training/sac_pi/valid_num      | 4938.0      |
| training/sac_Q/q1              | 209.05844   |
| training/sac_Q/q2              | 212.19653   |
| training/sac_Q/q2_loss         | 106.58013   |
| training/sac_Q/q_global_norm   | 256.16428   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16225916  |
| epoch                          | 844         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5093.419    |
| evaluation/return-max          | 5207.6523   |
| evaluation/return-min          | 5012.262    |
| evaluation/return-std          | 66.66497    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46465       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5093.419    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 223.4885    |
| Q-std                          | 117.236496  |
| Q_loss                         | 80.592575   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 844         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000112    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000601    |
| times/evaluation_paths         | 42.6        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 65.8        |
| timestep                       | 1000        |
| timesteps_total                | 845000      |
| train-steps                    | 845000      |
| training/Q/q1_loss             | 108.780914  |
| training/sac_pi/alpha          | 0.16225788  |
| training/sac_pi/alpha_loss     | -0.26559842 |
| training/sac_pi/logp_pi        | 3.875557    |
| training/sac_pi/pi_entropy     | 3.5095794   |
| training/sac_pi/pi_global_norm | 1.7816483   |
| training/sac_pi/policy_loss    | -227.66855  |
| training/sac_pi/std            | 0.49608618  |
| training/sac_pi/valid_num      | 4955.0      |
| training/sac_Q/q1              | 212.62735   |
| training/sac_Q/q2              | 215.56438   |
| training/sac_Q/q2_loss         | 108.23754   |
| training/sac_Q/q_global_norm   | 291.60843   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1632505   |
| epoch                          | 845         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5081.8467   |
| evaluation/return-max          | 5164.063    |
| evaluation/return-min          | 4984.418    |
| evaluation/return-std          | 55.83497    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 78.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46428       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5081.8467   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 224.29794   |
| Q-std                          | 119.16151   |
| Q_loss                         | 105.59665   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 845         |
| times/epoch_after_hook         | 1.68e-06    |
| times/epoch_before_hook        | 0.000281    |
| times/epoch_rollout_model      | 514         |
| times/evaluation_metrics       | 0.000571    |
| times/evaluation_paths         | 34.5        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00812     |
| times/train                    | 67.5        |
| timestep                       | 1000        |
| timesteps_total                | 846000      |
| train-steps                    | 846000      |
| training/Q/q1_loss             | 108.56848   |
| training/sac_pi/alpha          | 0.16327748  |
| training/sac_pi/alpha_loss     | -0.16749787 |
| training/sac_pi/logp_pi        | 3.9969482   |
| training/sac_pi/pi_entropy     | 3.504882    |
| training/sac_pi/pi_global_norm | 1.7042708   |
| training/sac_pi/policy_loss    | -224.76161  |
| training/sac_pi/std            | 0.49986637  |
| training/sac_pi/valid_num      | 4976.0      |
| training/sac_Q/q1              | 212.22104   |
| training/sac_Q/q2              | 214.26514   |
| training/sac_Q/q2_loss         | 108.47798   |
| training/sac_Q/q_global_norm   | 245.6955    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16519405 |
| epoch                          | 846        |
| evaluation/episode-length-avg  | 748        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 159        |
| evaluation/episode-length-std  | 385        |
| evaluation/return-average      | 3576.3113  |
| evaluation/return-max          | 4941.6123  |
| evaluation/return-min          | 529.1687   |
| evaluation/return-std          | 1989.7135  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46350      |
| perf/AverageLength             | 748        |
| perf/AverageReturn             | 3576.3113  |
| perf/NormalizedReturn          | 0.779      |
| Q-avg                          | 212.201    |
| Q-std                          | 151.56973  |
| Q_loss                         | 98.02622   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 846        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000124   |
| times/epoch_rollout_model      | 535        |
| times/evaluation_metrics       | 0.00054    |
| times/evaluation_paths         | 26.1       |
| times/timestep_after_hook      | 0.00393    |
| times/timestep_before_hook     | 0.00862    |
| times/train                    | 67         |
| timestep                       | 1000       |
| timesteps_total                | 847000     |
| train-steps                    | 847000     |
| training/Q/q1_loss             | 109.9672   |
| training/sac_pi/alpha          | 0.1651627  |
| training/sac_pi/alpha_loss     | 0.4569072  |
| training/sac_pi/logp_pi        | 5.1984262  |
| training/sac_pi/pi_entropy     | 3.4588532  |
| training/sac_pi/pi_global_norm | 2.1233478  |
| training/sac_pi/policy_loss    | -234.58203 |
| training/sac_pi/std            | 0.53525907 |
| training/sac_pi/valid_num      | 4960.0     |
| training/sac_Q/q1              | 214.56625  |
| training/sac_Q/q2              | 220.98813  |
| training/sac_Q/q2_loss         | 110.43077  |
| training/sac_Q/q_global_norm   | 185.08199  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16523828 |
| epoch                          | 847        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4878.407   |
| evaluation/return-max          | 4983.865   |
| evaluation/return-min          | 4678.57    |
| evaluation/return-std          | 84.36644   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 87.1       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46454      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4878.407   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 216.48172  |
| Q-std                          | 131.63228  |
| Q_loss                         | 100.45488  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 847        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000114   |
| times/epoch_rollout_model      | 516        |
| times/evaluation_metrics       | 0.000628   |
| times/evaluation_paths         | 34.9       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 62.2       |
| timestep                       | 1000       |
| timesteps_total                | 848000     |
| train-steps                    | 848000     |
| training/Q/q1_loss             | 110.552765 |
| training/sac_pi/alpha          | 0.16526978 |
| training/sac_pi/alpha_loss     | -0.2998221 |
| training/sac_pi/logp_pi        | 4.2970176  |
| training/sac_pi/pi_entropy     | 3.4711998  |
| training/sac_pi/pi_global_norm | 2.0760345  |
| training/sac_pi/policy_loss    | -223.853   |
| training/sac_pi/std            | 0.50861293 |
| training/sac_pi/valid_num      | 4961.0     |
| training/sac_Q/q1              | 210.35806  |
| training/sac_Q/q2              | 216.36404  |
| training/sac_Q/q2_loss         | 111.18222  |
| training/sac_Q/q_global_norm   | 174.77443  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16155204  |
| epoch                          | 848         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5032.69     |
| evaluation/return-max          | 5146.4395   |
| evaluation/return-min          | 4966.751    |
| evaluation/return-std          | 46.993706   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46425       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5032.69     |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 224.55356   |
| Q-std                          | 129.17795   |
| Q_loss                         | 96.81648    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 848         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 513         |
| times/evaluation_metrics       | 0.000509    |
| times/evaluation_paths         | 41.9        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 68.6        |
| timestep                       | 1000        |
| timesteps_total                | 849000      |
| train-steps                    | 849000      |
| training/Q/q1_loss             | 81.04266    |
| training/sac_pi/alpha          | 0.16156507  |
| training/sac_pi/alpha_loss     | -0.14464842 |
| training/sac_pi/logp_pi        | 4.2262244   |
| training/sac_pi/pi_entropy     | 3.4096503   |
| training/sac_pi/pi_global_norm | 1.3601469   |
| training/sac_pi/policy_loss    | -239.01884  |
| training/sac_pi/std            | 0.50329226  |
| training/sac_pi/valid_num      | 4990.0      |
| training/sac_Q/q1              | 226.66617   |
| training/sac_Q/q2              | 226.47806   |
| training/sac_Q/q2_loss         | 81.24044    |
| training/sac_Q/q_global_norm   | 215.06723   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16410841   |
| epoch                          | 849          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5265.3267    |
| evaluation/return-max          | 5311.16      |
| evaluation/return-min          | 5211.991     |
| evaluation/return-std          | 33.12726     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.1          |
| model/origin_ret               | 86           |
| model/penalty_ret              | 79.3         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46295        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5265.3267    |
| perf/NormalizedReturn          | 1.15         |
| Q-avg                          | 217.42314    |
| Q-std                          | 110.96714    |
| Q_loss                         | 113.54502    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 849          |
| times/epoch_after_hook         | 1.65e-06     |
| times/epoch_before_hook        | 0.000278     |
| times/epoch_rollout_model      | 502          |
| times/evaluation_metrics       | 0.000499     |
| times/evaluation_paths         | 35.6         |
| times/timestep_after_hook      | 0.00361      |
| times/timestep_before_hook     | 0.00824      |
| times/train                    | 65.6         |
| timestep                       | 1000         |
| timesteps_total                | 850000       |
| train-steps                    | 850000       |
| training/Q/q1_loss             | 100.21278    |
| training/sac_pi/alpha          | 0.16411157   |
| training/sac_pi/alpha_loss     | -0.070745654 |
| training/sac_pi/logp_pi        | 4.1321144    |
| training/sac_pi/pi_entropy     | 3.3955529    |
| training/sac_pi/pi_global_norm | 1.8212837    |
| training/sac_pi/policy_loss    | -223.18288   |
| training/sac_pi/std            | 0.48820183   |
| training/sac_pi/valid_num      | 4969.0       |
| training/sac_Q/q1              | 213.08134    |
| training/sac_Q/q2              | 216.1182     |
| training/sac_Q/q2_loss         | 99.896805    |
| training/sac_Q/q_global_norm   | 291.88132    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16470008 |
| epoch                          | 850        |
| evaluation/episode-length-avg  | 934        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 725        |
| evaluation/episode-length-std  | 104        |
| evaluation/return-average      | 4733.767   |
| evaluation/return-max          | 5253.9307  |
| evaluation/return-min          | 3592.129   |
| evaluation/return-std          | 609.5504   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46444      |
| perf/AverageLength             | 934        |
| perf/AverageReturn             | 4733.767   |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 215.1593   |
| Q-std                          | 187.12634  |
| Q_loss                         | 79.9645    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 850        |
| times/epoch_after_hook         | 2.01e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 511        |
| times/evaluation_metrics       | 0.000584   |
| times/evaluation_paths         | 35.2       |
| times/timestep_after_hook      | 0.00407    |
| times/timestep_before_hook     | 0.00858    |
| times/train                    | 67.7       |
| timestep                       | 1000       |
| timesteps_total                | 851000     |
| train-steps                    | 851000     |
| training/Q/q1_loss             | 103.92431  |
| training/sac_pi/alpha          | 0.16469085 |
| training/sac_pi/alpha_loss     | 0.28406802 |
| training/sac_pi/logp_pi        | 3.7584426  |
| training/sac_pi/pi_entropy     | 3.4061694  |
| training/sac_pi/pi_global_norm | 1.5668943  |
| training/sac_pi/policy_loss    | -230.99829 |
| training/sac_pi/std            | 0.47090727 |
| training/sac_pi/valid_num      | 4963.0     |
| training/sac_Q/q1              | 223.66898  |
| training/sac_Q/q2              | 222.86299  |
| training/sac_Q/q2_loss         | 102.786995 |
| training/sac_Q/q_global_norm   | 284.79715  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15866144 |
| epoch                          | 851        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5191.7754  |
| evaluation/return-max          | 5299.624   |
| evaluation/return-min          | 5092.3975  |
| evaluation/return-std          | 61.43707   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 79         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46480      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5191.7754  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 212.88016  |
| Q-std                          | 140.30379  |
| Q_loss                         | 95.84296   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 851        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000679   |
| times/evaluation_paths         | 33.3       |
| times/timestep_after_hook      | 0.00346    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 63.3       |
| timestep                       | 1000       |
| timesteps_total                | 852000     |
| train-steps                    | 852000     |
| training/Q/q1_loss             | 90.05671   |
| training/sac_pi/alpha          | 0.15862289 |
| training/sac_pi/alpha_loss     | 0.3312783  |
| training/sac_pi/logp_pi        | 4.2325263  |
| training/sac_pi/pi_entropy     | 3.2831142  |
| training/sac_pi/pi_global_norm | 2.402778   |
| training/sac_pi/policy_loss    | -228.86668 |
| training/sac_pi/std            | 0.47593918 |
| training/sac_pi/valid_num      | 5009.0     |
| training/sac_Q/q1              | 219.8331   |
| training/sac_Q/q2              | 221.65019  |
| training/sac_Q/q2_loss         | 90.41398   |
| training/sac_Q/q_global_norm   | 185.34065  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16166054 |
| epoch                          | 852        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5171.1484  |
| evaluation/return-max          | 5249.2686  |
| evaluation/return-min          | 5107.6655  |
| evaluation/return-std          | 45.793755  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 78.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46502      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5171.1484  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 226.0507   |
| Q-std                          | 99.16027   |
| Q_loss                         | 87.46521   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 852        |
| times/epoch_after_hook         | 1.92e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 499        |
| times/evaluation_metrics       | 0.000571   |
| times/evaluation_paths         | 46         |
| times/timestep_after_hook      | 0.00352    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 63.4       |
| timestep                       | 1000       |
| timesteps_total                | 853000     |
| train-steps                    | 853000     |
| training/Q/q1_loss             | 103.818695 |
| training/sac_pi/alpha          | 0.16167809 |
| training/sac_pi/alpha_loss     | -0.2660263 |
| training/sac_pi/logp_pi        | 3.8716989  |
| training/sac_pi/pi_entropy     | 3.4620793  |
| training/sac_pi/pi_global_norm | 1.646873   |
| training/sac_pi/policy_loss    | -229.09282 |
| training/sac_pi/std            | 0.48674616 |
| training/sac_pi/valid_num      | 5006.0     |
| training/sac_Q/q1              | 221.48637  |
| training/sac_Q/q2              | 223.48007  |
| training/sac_Q/q2_loss         | 102.13151  |
| training/sac_Q/q_global_norm   | 234.25421  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16539408  |
| epoch                          | 853         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5179.339    |
| evaluation/return-max          | 5252.782    |
| evaluation/return-min          | 5057.757    |
| evaluation/return-std          | 65.80994    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46454       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5179.339    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 223.50217   |
| Q-std                          | 125.60175   |
| Q_loss                         | 113.27698   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 853         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000272    |
| times/epoch_rollout_model      | 512         |
| times/evaluation_metrics       | 0.000604    |
| times/evaluation_paths         | 36.4        |
| times/timestep_after_hook      | 0.00354     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 66.4        |
| timestep                       | 1000        |
| timesteps_total                | 854000      |
| train-steps                    | 854000      |
| training/Q/q1_loss             | 104.03156   |
| training/sac_pi/alpha          | 0.16539116  |
| training/sac_pi/alpha_loss     | -0.40290475 |
| training/sac_pi/logp_pi        | 3.6870587   |
| training/sac_pi/pi_entropy     | 3.5296981   |
| training/sac_pi/pi_global_norm | 1.5770011   |
| training/sac_pi/policy_loss    | -227.09085  |
| training/sac_pi/std            | 0.48763612  |
| training/sac_pi/valid_num      | 4905.0      |
| training/sac_Q/q1              | 212.4148    |
| training/sac_Q/q2              | 213.91772   |
| training/sac_Q/q2_loss         | 103.42901   |
| training/sac_Q/q_global_norm   | 208.27289   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16564147 |
| epoch                          | 854        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5110.4873  |
| evaluation/return-max          | 5163.1875  |
| evaluation/return-min          | 5027.9277  |
| evaluation/return-std          | 46.061554  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46650      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5110.4873  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 216.7255   |
| Q-std                          | 193.11104  |
| Q_loss                         | 110.124344 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 854        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000627   |
| times/evaluation_paths         | 38         |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00831    |
| times/train                    | 69.2       |
| timestep                       | 1000       |
| timesteps_total                | 855000     |
| train-steps                    | 855000     |
| training/Q/q1_loss             | 82.632     |
| training/sac_pi/alpha          | 0.1656794  |
| training/sac_pi/alpha_loss     | -0.1061425 |
| training/sac_pi/logp_pi        | 3.971949   |
| training/sac_pi/pi_entropy     | 3.3929772  |
| training/sac_pi/pi_global_norm | 1.4181865  |
| training/sac_pi/policy_loss    | -227.73495 |
| training/sac_pi/std            | 0.47395906 |
| training/sac_pi/valid_num      | 4995.0     |
| training/sac_Q/q1              | 222.31303  |
| training/sac_Q/q2              | 222.52185  |
| training/sac_Q/q2_loss         | 83.289536  |
| training/sac_Q/q_global_norm   | 217.93681  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16169867 |
| epoch                          | 855        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4995.8384  |
| evaluation/return-max          | 5257.2524  |
| evaluation/return-min          | 4743.7397  |
| evaluation/return-std          | 209.7048   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 78.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46515      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4995.8384  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 215.04053  |
| Q-std                          | 113.61495  |
| Q_loss                         | 111.683304 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 855        |
| times/epoch_after_hook         | 1.82e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000625   |
| times/evaluation_paths         | 35.6       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 69.2       |
| timestep                       | 1000       |
| timesteps_total                | 856000     |
| train-steps                    | 856000     |
| training/Q/q1_loss             | 96.709564  |
| training/sac_pi/alpha          | 0.16170233 |
| training/sac_pi/alpha_loss     | 0.09209455 |
| training/sac_pi/logp_pi        | 4.08792    |
| training/sac_pi/pi_entropy     | 3.4903083  |
| training/sac_pi/pi_global_norm | 1.885318   |
| training/sac_pi/policy_loss    | -233.18083 |
| training/sac_pi/std            | 0.4985537  |
| training/sac_pi/valid_num      | 5020.0     |
| training/sac_Q/q1              | 222.2168   |
| training/sac_Q/q2              | 223.91162  |
| training/sac_Q/q2_loss         | 97.32948   |
| training/sac_Q/q_global_norm   | 241.70374  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16065054   |
| epoch                          | 856          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5049.8003    |
| evaluation/return-max          | 5198.6025    |
| evaluation/return-min          | 5003.502     |
| evaluation/return-std          | 54.04909     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.1          |
| model/origin_ret               | 85.7         |
| model/penalty_ret              | 79.2         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46371        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5049.8003    |
| perf/NormalizedReturn          | 1.1          |
| Q-avg                          | 225.97758    |
| Q-std                          | 146.37234    |
| Q_loss                         | 75.820366    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 856          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.000134     |
| times/epoch_rollout_model      | 481          |
| times/evaluation_metrics       | 0.000541     |
| times/evaluation_paths         | 46.3         |
| times/timestep_after_hook      | 0.00359      |
| times/timestep_before_hook     | 0.00838      |
| times/train                    | 63.8         |
| timestep                       | 1000         |
| timesteps_total                | 857000       |
| train-steps                    | 857000       |
| training/Q/q1_loss             | 99.19748     |
| training/sac_pi/alpha          | 0.16064876   |
| training/sac_pi/alpha_loss     | -0.034965433 |
| training/sac_pi/logp_pi        | 4.3799925    |
| training/sac_pi/pi_entropy     | 3.4614372    |
| training/sac_pi/pi_global_norm | 1.5702735    |
| training/sac_pi/policy_loss    | -231.65625   |
| training/sac_pi/std            | 0.51356435   |
| training/sac_pi/valid_num      | 4980.0       |
| training/sac_Q/q1              | 216.0886     |
| training/sac_Q/q2              | 219.78296    |
| training/sac_Q/q2_loss         | 98.017426    |
| training/sac_Q/q_global_norm   | 221.0531     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16197936 |
| epoch                          | 857        |
| evaluation/episode-length-avg  | 954        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 538        |
| evaluation/episode-length-std  | 139        |
| evaluation/return-average      | 4849.1543  |
| evaluation/return-max          | 5274.3296  |
| evaluation/return-min          | 2467.271   |
| evaluation/return-std          | 801.8626   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46548      |
| perf/AverageLength             | 954        |
| perf/AverageReturn             | 4849.1543  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 218.27432  |
| Q-std                          | 129.34456  |
| Q_loss                         | 91.761536  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 857        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000376   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000455   |
| times/evaluation_paths         | 37.6       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 67.4       |
| timestep                       | 1000       |
| timesteps_total                | 858000     |
| train-steps                    | 858000     |
| training/Q/q1_loss             | 88.752396  |
| training/sac_pi/alpha          | 0.16196671 |
| training/sac_pi/alpha_loss     | -0.2949294 |
| training/sac_pi/logp_pi        | 3.9391243  |
| training/sac_pi/pi_entropy     | 3.637136   |
| training/sac_pi/pi_global_norm | 1.5667833  |
| training/sac_pi/policy_loss    | -231.5097  |
| training/sac_pi/std            | 0.5124098  |
| training/sac_pi/valid_num      | 4975.0     |
| training/sac_Q/q1              | 219.85269  |
| training/sac_Q/q2              | 221.36621  |
| training/sac_Q/q2_loss         | 87.73647   |
| training/sac_Q/q_global_norm   | 234.25075  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16061968  |
| epoch                          | 858         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5073.411    |
| evaluation/return-max          | 5113.6514   |
| evaluation/return-min          | 5040.2393   |
| evaluation/return-std          | 24.339596   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46505       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5073.411    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 214.84367   |
| Q-std                          | 147.5741    |
| Q_loss                         | 111.7931    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 858         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 9.05e-05    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000734    |
| times/evaluation_paths         | 37.6        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.00841     |
| times/train                    | 68.2        |
| timestep                       | 1000        |
| timesteps_total                | 859000      |
| train-steps                    | 859000      |
| training/Q/q1_loss             | 85.900986   |
| training/sac_pi/alpha          | 0.16064706  |
| training/sac_pi/alpha_loss     | -0.24372932 |
| training/sac_pi/logp_pi        | 3.3457427   |
| training/sac_pi/pi_entropy     | 3.2900383   |
| training/sac_pi/pi_global_norm | 1.7778021   |
| training/sac_pi/policy_loss    | -231.42235  |
| training/sac_pi/std            | 0.45650253  |
| training/sac_pi/valid_num      | 5014.0      |
| training/sac_Q/q1              | 226.73967   |
| training/sac_Q/q2              | 227.27133   |
| training/sac_Q/q2_loss         | 88.193634   |
| training/sac_Q/q_global_norm   | 282.00003   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16510472  |
| epoch                          | 859         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4980.85     |
| evaluation/return-max          | 5034.2285   |
| evaluation/return-min          | 4885.0303   |
| evaluation/return-std          | 47.031685   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46694       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4980.85     |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 215.51694   |
| Q-std                          | 121.142914  |
| Q_loss                         | 91.59077    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 859         |
| times/epoch_after_hook         | 3.09e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000574    |
| times/evaluation_paths         | 39.8        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00832     |
| times/train                    | 73.5        |
| timestep                       | 1000        |
| timesteps_total                | 860000      |
| train-steps                    | 860000      |
| training/Q/q1_loss             | 97.204956   |
| training/sac_pi/alpha          | 0.16512279  |
| training/sac_pi/alpha_loss     | -0.16094744 |
| training/sac_pi/logp_pi        | 4.1645875   |
| training/sac_pi/pi_entropy     | 3.706314    |
| training/sac_pi/pi_global_norm | 1.5132725   |
| training/sac_pi/policy_loss    | -220.30556  |
| training/sac_pi/std            | 0.5249564   |
| training/sac_pi/valid_num      | 4948.0      |
| training/sac_Q/q1              | 206.93796   |
| training/sac_Q/q2              | 208.70064   |
| training/sac_Q/q2_loss         | 97.352745   |
| training/sac_Q/q_global_norm   | 193.6305    |
---------------------------------------------------------------------------------
[WARN] 860 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.1601198   |
| epoch                          | 860         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5052.624    |
| evaluation/return-max          | 5254.052    |
| evaluation/return-min          | 4877.617    |
| evaluation/return-std          | 143.86641   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46586       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5052.624    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 205.70059   |
| Q-std                          | 184.1912    |
| Q_loss                         | 100.047165  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 860         |
| times/epoch_after_hook         | 2.59e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.00095     |
| times/evaluation_paths         | 45.3        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 861000      |
| train-steps                    | 861000      |
| training/Q/q1_loss             | 108.882126  |
| training/sac_pi/alpha          | 0.16011906  |
| training/sac_pi/alpha_loss     | -0.04472025 |
| training/sac_pi/logp_pi        | 4.8104987   |
| training/sac_pi/pi_entropy     | 3.510812    |
| training/sac_pi/pi_global_norm | 2.1278517   |
| training/sac_pi/policy_loss    | -219.24641  |
| training/sac_pi/std            | 0.5166639   |
| training/sac_pi/valid_num      | 4919.0      |
| training/sac_Q/q1              | 204.82889   |
| training/sac_Q/q2              | 206.08272   |
| training/sac_Q/q2_loss         | 107.528305  |
| training/sac_Q/q_global_norm   | 203.1484    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16375573  |
| epoch                          | 861         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5161.957    |
| evaluation/return-max          | 5205.6265   |
| evaluation/return-min          | 5121.923    |
| evaluation/return-std          | 24.21895    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46537       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5161.957    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 222.44675   |
| Q-std                          | 156.31113   |
| Q_loss                         | 86.014915   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 861         |
| times/epoch_after_hook         | 1.86e-06    |
| times/epoch_before_hook        | 0.000829    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000733    |
| times/evaluation_paths         | 37.9        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 66.9        |
| timestep                       | 1000        |
| timesteps_total                | 862000      |
| train-steps                    | 862000      |
| training/Q/q1_loss             | 84.45634    |
| training/sac_pi/alpha          | 0.16376615  |
| training/sac_pi/alpha_loss     | -0.21510693 |
| training/sac_pi/logp_pi        | 4.1520386   |
| training/sac_pi/pi_entropy     | 3.552634    |
| training/sac_pi/pi_global_norm | 1.8254746   |
| training/sac_pi/policy_loss    | -237.44228  |
| training/sac_pi/std            | 0.5076682   |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 221.73474   |
| training/sac_Q/q2              | 226.91476   |
| training/sac_Q/q2_loss         | 83.61621    |
| training/sac_Q/q_global_norm   | 176.51515   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16208866 |
| epoch                          | 862        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5178.0493  |
| evaluation/return-max          | 5314.802   |
| evaluation/return-min          | 4746.6235  |
| evaluation/return-std          | 204.36588  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.3       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46484      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5178.0493  |
| perf/NormalizedReturn          | 1.13       |
| Q-avg                          | 216.82779  |
| Q-std                          | 153.4456   |
| Q_loss                         | 115.092064 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 862        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000133   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000526   |
| times/evaluation_paths         | 39         |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 66.7       |
| timestep                       | 1000       |
| timesteps_total                | 863000     |
| train-steps                    | 863000     |
| training/Q/q1_loss             | 101.00297  |
| training/sac_pi/alpha          | 0.16204241 |
| training/sac_pi/alpha_loss     | 0.35448477 |
| training/sac_pi/logp_pi        | 3.8116157  |
| training/sac_pi/pi_entropy     | 3.2733033  |
| training/sac_pi/pi_global_norm | 2.0344348  |
| training/sac_pi/policy_loss    | -230.34892 |
| training/sac_pi/std            | 0.46075782 |
| training/sac_pi/valid_num      | 5037.0     |
| training/sac_Q/q1              | 223.64778  |
| training/sac_Q/q2              | 225.21846  |
| training/sac_Q/q2_loss         | 101.17781  |
| training/sac_Q/q_global_norm   | 174.96767  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15622042  |
| epoch                          | 863         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5118.385    |
| evaluation/return-max          | 5313.365    |
| evaluation/return-min          | 4839.285    |
| evaluation/return-std          | 161.2685    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46465       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5118.385    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 212.77744   |
| Q-std                          | 162.60101   |
| Q_loss                         | 90.31722    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 863         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000133    |
| times/epoch_rollout_model      | 480         |
| times/evaluation_metrics       | 0.000501    |
| times/evaluation_paths         | 33.5        |
| times/timestep_after_hook      | 0.00362     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 66.9        |
| timestep                       | 1000        |
| timesteps_total                | 864000      |
| train-steps                    | 864000      |
| training/Q/q1_loss             | 94.482056   |
| training/sac_pi/alpha          | 0.15623812  |
| training/sac_pi/alpha_loss     | -0.29171184 |
| training/sac_pi/logp_pi        | 4.324216    |
| training/sac_pi/pi_entropy     | 3.492279    |
| training/sac_pi/pi_global_norm | 2.0826104   |
| training/sac_pi/policy_loss    | -234.74191  |
| training/sac_pi/std            | 0.52363825  |
| training/sac_pi/valid_num      | 4950.0      |
| training/sac_Q/q1              | 213.89517   |
| training/sac_Q/q2              | 217.49878   |
| training/sac_Q/q2_loss         | 93.669846   |
| training/sac_Q/q_global_norm   | 211.3128    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15162879  |
| epoch                          | 864         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4911.576    |
| evaluation/return-max          | 4983.467    |
| evaluation/return-min          | 4769.9863   |
| evaluation/return-std          | 62.36782    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.15        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46408       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4911.576    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 220.12212   |
| Q-std                          | 165.65172   |
| Q_loss                         | 84.65983    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 864         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000512    |
| times/evaluation_paths         | 48.5        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00838     |
| times/train                    | 66.6        |
| timestep                       | 1000        |
| timesteps_total                | 865000      |
| train-steps                    | 865000      |
| training/Q/q1_loss             | 103.47932   |
| training/sac_pi/alpha          | 0.15163748  |
| training/sac_pi/alpha_loss     | -0.26253697 |
| training/sac_pi/logp_pi        | 4.8211284   |
| training/sac_pi/pi_entropy     | 3.4555938   |
| training/sac_pi/pi_global_norm | 2.015442    |
| training/sac_pi/policy_loss    | -228.92838  |
| training/sac_pi/std            | 0.5502717   |
| training/sac_pi/valid_num      | 4930.0      |
| training/sac_Q/q1              | 206.48154   |
| training/sac_Q/q2              | 212.66129   |
| training/sac_Q/q2_loss         | 103.59872   |
| training/sac_Q/q_global_norm   | 342.21237   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15237172 |
| epoch                          | 865        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4828.655   |
| evaluation/return-max          | 4875.1323  |
| evaluation/return-min          | 4766.8584  |
| evaluation/return-std          | 35.97525   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.08       |
| model/origin_ret               | 84.9       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46621      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4828.655   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 219.12024  |
| Q-std                          | 207.97827  |
| Q_loss                         | 93.91913   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 865        |
| times/epoch_after_hook         | 2.08e-06   |
| times/epoch_before_hook        | 0.00034    |
| times/epoch_rollout_model      | 476        |
| times/evaluation_metrics       | 0.000544   |
| times/evaluation_paths         | 38.8       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.0108     |
| times/train                    | 65.6       |
| timestep                       | 1000       |
| timesteps_total                | 866000     |
| train-steps                    | 866000     |
| training/Q/q1_loss             | 116.97256  |
| training/sac_pi/alpha          | 0.15237251 |
| training/sac_pi/alpha_loss     | 0.4140581  |
| training/sac_pi/logp_pi        | 4.643874   |
| training/sac_pi/pi_entropy     | 3.5014958  |
| training/sac_pi/pi_global_norm | 2.0972822  |
| training/sac_pi/policy_loss    | -229.41356 |
| training/sac_pi/std            | 0.52121335 |
| training/sac_pi/valid_num      | 4983.0     |
| training/sac_Q/q1              | 212.68498  |
| training/sac_Q/q2              | 218.13126  |
| training/sac_Q/q2_loss         | 118.41193  |
| training/sac_Q/q_global_norm   | 288.87158  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15911947 |
| epoch                          | 866        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4909.9033  |
| evaluation/return-max          | 5023.3066  |
| evaluation/return-min          | 4769.587   |
| evaluation/return-std          | 77.80786   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46442      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4909.9033  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 221.72568  |
| Q-std                          | 190.7923   |
| Q_loss                         | 105.80011  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 866        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000131   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000562   |
| times/evaluation_paths         | 37.3       |
| times/timestep_after_hook      | 0.00353    |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 65.6       |
| timestep                       | 1000       |
| timesteps_total                | 867000     |
| train-steps                    | 867000     |
| training/Q/q1_loss             | 91.401596  |
| training/sac_pi/alpha          | 0.1591513  |
| training/sac_pi/alpha_loss     | -0.1707697 |
| training/sac_pi/logp_pi        | 4.069278   |
| training/sac_pi/pi_entropy     | 3.4551835  |
| training/sac_pi/pi_global_norm | 1.601718   |
| training/sac_pi/policy_loss    | -235.26805 |
| training/sac_pi/std            | 0.48798895 |
| training/sac_pi/valid_num      | 4963.0     |
| training/sac_Q/q1              | 228.22685  |
| training/sac_Q/q2              | 229.14888  |
| training/sac_Q/q2_loss         | 93.033295  |
| training/sac_Q/q_global_norm   | 219.45616  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15916279 |
| epoch                          | 867        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5092.0366  |
| evaluation/return-max          | 5145.961   |
| evaluation/return-min          | 5053.6816  |
| evaluation/return-std          | 24.518942  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 79.6       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46628      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5092.0366  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 197.68588  |
| Q-std                          | 199.33559  |
| Q_loss                         | 102.47497  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 867        |
| times/epoch_after_hook         | 1.81e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000596   |
| times/evaluation_paths         | 34.9       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00842    |
| times/train                    | 66.9       |
| timestep                       | 1000       |
| timesteps_total                | 868000     |
| train-steps                    | 868000     |
| training/Q/q1_loss             | 71.92748   |
| training/sac_pi/alpha          | 0.15919065 |
| training/sac_pi/alpha_loss     | -0.117401  |
| training/sac_pi/logp_pi        | 3.9367995  |
| training/sac_pi/pi_entropy     | 3.4264932  |
| training/sac_pi/pi_global_norm | 1.8941938  |
| training/sac_pi/policy_loss    | -235.07967 |
| training/sac_pi/std            | 0.4926447  |
| training/sac_pi/valid_num      | 5005.0     |
| training/sac_Q/q1              | 226.96748  |
| training/sac_Q/q2              | 229.20747  |
| training/sac_Q/q2_loss         | 72.50464   |
| training/sac_Q/q_global_norm   | 266.4045   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16337478  |
| epoch                          | 868         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4892.956    |
| evaluation/return-max          | 4976.631    |
| evaluation/return-min          | 4775.7734   |
| evaluation/return-std          | 68.12388    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.15        |
| model/origin_ret               | 86.1        |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46589       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4892.956    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 214.23674   |
| Q-std                          | 182.83221   |
| Q_loss                         | 95.00464    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 868         |
| times/epoch_after_hook         | 2.08e-06    |
| times/epoch_before_hook        | 0.000112    |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000683    |
| times/evaluation_paths         | 45.6        |
| times/timestep_after_hook      | 0.00375     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 65.8        |
| timestep                       | 1000        |
| timesteps_total                | 869000      |
| train-steps                    | 869000      |
| training/Q/q1_loss             | 107.2775    |
| training/sac_pi/alpha          | 0.16340326  |
| training/sac_pi/alpha_loss     | 0.015739916 |
| training/sac_pi/logp_pi        | 4.0992174   |
| training/sac_pi/pi_entropy     | 3.4532456   |
| training/sac_pi/pi_global_norm | 1.6460376   |
| training/sac_pi/policy_loss    | -228.33401  |
| training/sac_pi/std            | 0.49889958  |
| training/sac_pi/valid_num      | 4999.0      |
| training/sac_Q/q1              | 215.68279   |
| training/sac_Q/q2              | 217.04199   |
| training/sac_Q/q2_loss         | 105.892204  |
| training/sac_Q/q_global_norm   | 294.86713   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16596459  |
| epoch                          | 869         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4950.707    |
| evaluation/return-max          | 4978.0146   |
| evaluation/return-min          | 4929.614    |
| evaluation/return-std          | 16.630606   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 78.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46518       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4950.707    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 224.98111   |
| Q-std                          | 160.78148   |
| Q_loss                         | 85.61222    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 869         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000287    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000565    |
| times/evaluation_paths         | 37.4        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 66.3        |
| timestep                       | 1000        |
| timesteps_total                | 870000      |
| train-steps                    | 870000      |
| training/Q/q1_loss             | 83.591934   |
| training/sac_pi/alpha          | 0.16598195  |
| training/sac_pi/alpha_loss     | -0.18219468 |
| training/sac_pi/logp_pi        | 3.6186433   |
| training/sac_pi/pi_entropy     | 3.3802674   |
| training/sac_pi/pi_global_norm | 1.6217114   |
| training/sac_pi/policy_loss    | -236.87184  |
| training/sac_pi/std            | 0.4752029   |
| training/sac_pi/valid_num      | 4988.0      |
| training/sac_Q/q1              | 229.00986   |
| training/sac_Q/q2              | 228.56685   |
| training/sac_Q/q2_loss         | 83.95452    |
| training/sac_Q/q_global_norm   | 391.99725   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1604412  |
| epoch                          | 870        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5041.0083  |
| evaluation/return-max          | 5079.4565  |
| evaluation/return-min          | 4985.5093  |
| evaluation/return-std          | 22.546661  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 79         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46598      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5041.0083  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 217.70503  |
| Q-std                          | 133.66748  |
| Q_loss                         | 91.287415  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 870        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.00013    |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000601   |
| times/evaluation_paths         | 37.2       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.00918    |
| times/train                    | 66.5       |
| timestep                       | 1000       |
| timesteps_total                | 871000     |
| train-steps                    | 871000     |
| training/Q/q1_loss             | 94.48794   |
| training/sac_pi/alpha          | 0.16038522 |
| training/sac_pi/alpha_loss     | 0.39820147 |
| training/sac_pi/logp_pi        | 4.0570908  |
| training/sac_pi/pi_entropy     | 3.3167362  |
| training/sac_pi/pi_global_norm | 1.6459515  |
| training/sac_pi/policy_loss    | -238.83354 |
| training/sac_pi/std            | 0.4795427  |
| training/sac_pi/valid_num      | 5012.0     |
| training/sac_Q/q1              | 228.40076  |
| training/sac_Q/q2              | 228.77515  |
| training/sac_Q/q2_loss         | 95.0401    |
| training/sac_Q/q_global_norm   | 257.44327  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1592761   |
| epoch                          | 871         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5090.718    |
| evaluation/return-max          | 5133.384    |
| evaluation/return-min          | 5030.4717   |
| evaluation/return-std          | 35.994633   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 78.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46466       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5090.718    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 219.63602   |
| Q-std                          | 113.10004   |
| Q_loss                         | 121.37522   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 871         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000677    |
| times/evaluation_paths         | 34.9        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 69.6        |
| timestep                       | 1000        |
| timesteps_total                | 872000      |
| train-steps                    | 872000      |
| training/Q/q1_loss             | 103.948006  |
| training/sac_pi/alpha          | 0.15932313  |
| training/sac_pi/alpha_loss     | -0.19127835 |
| training/sac_pi/logp_pi        | 4.7334247   |
| training/sac_pi/pi_entropy     | 3.3875275   |
| training/sac_pi/pi_global_norm | 1.5572677   |
| training/sac_pi/policy_loss    | -230.73811  |
| training/sac_pi/std            | 0.51375127  |
| training/sac_pi/valid_num      | 4919.0      |
| training/sac_Q/q1              | 211.77042   |
| training/sac_Q/q2              | 215.35605   |
| training/sac_Q/q2_loss         | 103.66756   |
| training/sac_Q/q_global_norm   | 212.24597   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16269311 |
| epoch                          | 872        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5017.2744  |
| evaluation/return-max          | 5047.799   |
| evaluation/return-min          | 4977.5854  |
| evaluation/return-std          | 23.169342  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46476      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5017.2744  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 224.94414  |
| Q-std                          | 93.468475  |
| Q_loss                         | 94.928986  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 872        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000149   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.00054    |
| times/evaluation_paths         | 47.7       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 63.5       |
| timestep                       | 1000       |
| timesteps_total                | 873000     |
| train-steps                    | 873000     |
| training/Q/q1_loss             | 111.97727  |
| training/sac_pi/alpha          | 0.16270679 |
| training/sac_pi/alpha_loss     | 0.06419762 |
| training/sac_pi/logp_pi        | 4.80658    |
| training/sac_pi/pi_entropy     | 3.3574378  |
| training/sac_pi/pi_global_norm | 2.0067372  |
| training/sac_pi/policy_loss    | -222.664   |
| training/sac_pi/std            | 0.49513558 |
| training/sac_pi/valid_num      | 4911.0     |
| training/sac_Q/q1              | 209.49081  |
| training/sac_Q/q2              | 214.50577  |
| training/sac_Q/q2_loss         | 111.26387  |
| training/sac_Q/q_global_norm   | 201.49886  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16385005  |
| epoch                          | 873         |
| evaluation/episode-length-avg  | 419         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 170         |
| evaluation/episode-length-std  | 380         |
| evaluation/return-average      | 1926.127    |
| evaluation/return-max          | 5119.241    |
| evaluation/return-min          | 556.10254   |
| evaluation/return-std          | 2087.8904   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46523       |
| perf/AverageLength             | 419         |
| perf/AverageReturn             | 1926.127    |
| perf/NormalizedReturn          | 0.419       |
| Q-avg                          | 217.92595   |
| Q-std                          | 188.23486   |
| Q_loss                         | 93.249054   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 873         |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000281    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000457    |
| times/evaluation_paths         | 16.6        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00832     |
| times/train                    | 65.3        |
| timestep                       | 1000        |
| timesteps_total                | 874000      |
| train-steps                    | 874000      |
| training/Q/q1_loss             | 98.72916    |
| training/sac_pi/alpha          | 0.16385512  |
| training/sac_pi/alpha_loss     | -0.29677072 |
| training/sac_pi/logp_pi        | 3.881314    |
| training/sac_pi/pi_entropy     | 3.480954    |
| training/sac_pi/pi_global_norm | 1.6802723   |
| training/sac_pi/policy_loss    | -227.6887   |
| training/sac_pi/std            | 0.48981762  |
| training/sac_pi/valid_num      | 5001.0      |
| training/sac_Q/q1              | 214.2253    |
| training/sac_Q/q2              | 217.24052   |
| training/sac_Q/q2_loss         | 96.515015   |
| training/sac_Q/q_global_norm   | 227.09833   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16921668 |
| epoch                          | 874        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4956.429   |
| evaluation/return-max          | 4999.813   |
| evaluation/return-min          | 4876.994   |
| evaluation/return-std          | 33.020515  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46489      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4956.429   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 212.73059  |
| Q-std                          | 164.57054  |
| Q_loss                         | 100.78672  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 874        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000117   |
| times/epoch_rollout_model      | 479        |
| times/evaluation_metrics       | 0.000571   |
| times/evaluation_paths         | 38.1       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 73.3       |
| timestep                       | 1000       |
| timesteps_total                | 875000     |
| train-steps                    | 875000     |
| training/Q/q1_loss             | 86.66346   |
| training/sac_pi/alpha          | 0.16919865 |
| training/sac_pi/alpha_loss     | 0.11025432 |
| training/sac_pi/logp_pi        | 3.680163   |
| training/sac_pi/pi_entropy     | 3.4934494  |
| training/sac_pi/pi_global_norm | 2.1591995  |
| training/sac_pi/policy_loss    | -238.14473 |
| training/sac_pi/std            | 0.47941515 |
| training/sac_pi/valid_num      | 5006.0     |
| training/sac_Q/q1              | 229.5477   |
| training/sac_Q/q2              | 230.2955   |
| training/sac_Q/q2_loss         | 87.03093   |
| training/sac_Q/q_global_norm   | 185.14508  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16735648 |
| epoch                          | 875        |
| evaluation/episode-length-avg  | 963        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 752        |
| evaluation/episode-length-std  | 79.4       |
| evaluation/return-average      | 4885.4814  |
| evaluation/return-max          | 5241.7     |
| evaluation/return-min          | 3731.5815  |
| evaluation/return-std          | 456.6563   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 87.1       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46447      |
| perf/AverageLength             | 963        |
| perf/AverageReturn             | 4885.4814  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 219.15068  |
| Q-std                          | 143.04463  |
| Q_loss                         | 100.888405 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 875        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000248   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000497   |
| times/evaluation_paths         | 35.7       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 71.6       |
| timestep                       | 1000       |
| timesteps_total                | 876000     |
| train-steps                    | 876000     |
| training/Q/q1_loss             | 100.50639  |
| training/sac_pi/alpha          | 0.16736011 |
| training/sac_pi/alpha_loss     | 0.21740063 |
| training/sac_pi/logp_pi        | 4.4713583  |
| training/sac_pi/pi_entropy     | 3.5160403  |
| training/sac_pi/pi_global_norm | 1.9158632  |
| training/sac_pi/policy_loss    | -234.32623 |
| training/sac_pi/std            | 0.51872766 |
| training/sac_pi/valid_num      | 4958.0     |
| training/sac_Q/q1              | 224.20125  |
| training/sac_Q/q2              | 224.6497   |
| training/sac_Q/q2_loss         | 99.82969   |
| training/sac_Q/q_global_norm   | 203.16878  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16753066  |
| epoch                          | 876         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4928.586    |
| evaluation/return-max          | 4984.546    |
| evaluation/return-min          | 4795.9443   |
| evaluation/return-std          | 52.422882   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.4        |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46405       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4928.586    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 217.09148   |
| Q-std                          | 152.92679   |
| Q_loss                         | 97.54384    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 876         |
| times/epoch_after_hook         | 1.81e-06    |
| times/epoch_before_hook        | 0.000128    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000534    |
| times/evaluation_paths         | 46.1        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 58.8        |
| timestep                       | 1000        |
| timesteps_total                | 877000      |
| train-steps                    | 877000      |
| training/Q/q1_loss             | 88.89572    |
| training/sac_pi/alpha          | 0.16757372  |
| training/sac_pi/alpha_loss     | -0.42839584 |
| training/sac_pi/logp_pi        | 3.3016028   |
| training/sac_pi/pi_entropy     | 3.4646537   |
| training/sac_pi/pi_global_norm | 1.3990909   |
| training/sac_pi/policy_loss    | -231.67815  |
| training/sac_pi/std            | 0.47575486  |
| training/sac_pi/valid_num      | 5031.0      |
| training/sac_Q/q1              | 226.12776   |
| training/sac_Q/q2              | 224.93022   |
| training/sac_Q/q2_loss         | 89.27395    |
| training/sac_Q/q_global_norm   | 158.48323   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16199201 |
| epoch                          | 877        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4919.0303  |
| evaluation/return-max          | 4998.591   |
| evaluation/return-min          | 4810.7617  |
| evaluation/return-std          | 60.187466  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.3       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46491      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4919.0303  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 208.59897  |
| Q-std                          | 180.40262  |
| Q_loss                         | 124.84298  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 877        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.00036    |
| times/epoch_rollout_model      | 475        |
| times/evaluation_metrics       | 0.000636   |
| times/evaluation_paths         | 37         |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 69.9       |
| timestep                       | 1000       |
| timesteps_total                | 878000     |
| train-steps                    | 878000     |
| training/Q/q1_loss             | 111.194046 |
| training/sac_pi/alpha          | 0.16201226 |
| training/sac_pi/alpha_loss     | -0.3506681 |
| training/sac_pi/logp_pi        | 4.312931   |
| training/sac_pi/pi_entropy     | 3.6108944  |
| training/sac_pi/pi_global_norm | 1.8692052  |
| training/sac_pi/policy_loss    | -230.47668 |
| training/sac_pi/std            | 0.52556056 |
| training/sac_pi/valid_num      | 4963.0     |
| training/sac_Q/q1              | 209.07954  |
| training/sac_Q/q2              | 212.77104  |
| training/sac_Q/q2_loss         | 110.53439  |
| training/sac_Q/q_global_norm   | 237.25388  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16799447   |
| epoch                          | 878          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5015.286     |
| evaluation/return-max          | 5095.4688    |
| evaluation/return-min          | 4913.5283    |
| evaluation/return-std          | 50.903206    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.11         |
| model/origin_ret               | 84.9         |
| model/penalty_ret              | 78.8         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46534        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5015.286     |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 212.94162    |
| Q-std                          | 180.3562     |
| Q_loss                         | 103.80872    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 878          |
| times/epoch_after_hook         | 1.72e-06     |
| times/epoch_before_hook        | 0.000149     |
| times/epoch_rollout_model      | 475          |
| times/evaluation_metrics       | 0.000525     |
| times/evaluation_paths         | 37.9         |
| times/timestep_after_hook      | 0.00373      |
| times/timestep_before_hook     | 0.00851      |
| times/train                    | 71           |
| timestep                       | 1000         |
| timesteps_total                | 879000       |
| train-steps                    | 879000       |
| training/Q/q1_loss             | 102.59975    |
| training/sac_pi/alpha          | 0.16800612   |
| training/sac_pi/alpha_loss     | -0.022204699 |
| training/sac_pi/logp_pi        | 3.4547973    |
| training/sac_pi/pi_entropy     | 3.4581115    |
| training/sac_pi/pi_global_norm | 2.0155528    |
| training/sac_pi/policy_loss    | -224.16446   |
| training/sac_pi/std            | 0.46716633   |
| training/sac_pi/valid_num      | 4987.0       |
| training/sac_Q/q1              | 215.19418    |
| training/sac_Q/q2              | 217.1937     |
| training/sac_Q/q2_loss         | 101.202354   |
| training/sac_Q/q_global_norm   | 179.40944    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1682011   |
| epoch                          | 879         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5243.0225   |
| evaluation/return-max          | 5275.95     |
| evaluation/return-min          | 5195.418    |
| evaluation/return-std          | 20.219173   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 78.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46481       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5243.0225   |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 219.28946   |
| Q-std                          | 157.58902   |
| Q_loss                         | 88.53952    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 879         |
| times/epoch_after_hook         | 1.92e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 476         |
| times/evaluation_metrics       | 0.000532    |
| times/evaluation_paths         | 37.1        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.00852     |
| times/train                    | 71          |
| timestep                       | 1000        |
| timesteps_total                | 880000      |
| train-steps                    | 880000      |
| training/Q/q1_loss             | 87.77368    |
| training/sac_pi/alpha          | 0.1681938   |
| training/sac_pi/alpha_loss     | 0.074473836 |
| training/sac_pi/logp_pi        | 3.8544059   |
| training/sac_pi/pi_entropy     | 3.5280476   |
| training/sac_pi/pi_global_norm | 1.6289228   |
| training/sac_pi/policy_loss    | -225.0967   |
| training/sac_pi/std            | 0.48742166  |
| training/sac_pi/valid_num      | 4998.0      |
| training/sac_Q/q1              | 217.85303   |
| training/sac_Q/q2              | 217.68555   |
| training/sac_Q/q2_loss         | 88.03715    |
| training/sac_Q/q_global_norm   | 219.71976   |
---------------------------------------------------------------------------------
[WARN] 880 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.17037855  |
| epoch                          | 880         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4970.774    |
| evaluation/return-max          | 5081.8047   |
| evaluation/return-min          | 4869.0293   |
| evaluation/return-std          | 68.76737    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 78.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46391       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4970.774    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 210.45805   |
| Q-std                          | 172.58266   |
| Q_loss                         | 86.78785    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 880         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 477         |
| times/evaluation_metrics       | 0.000581    |
| times/evaluation_paths         | 47.3        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00839     |
| times/train                    | 60.9        |
| timestep                       | 1000        |
| timesteps_total                | 881000      |
| train-steps                    | 881000      |
| training/Q/q1_loss             | 92.07217    |
| training/sac_pi/alpha          | 0.17036992  |
| training/sac_pi/alpha_loss     | -0.20712347 |
| training/sac_pi/logp_pi        | 4.240714    |
| training/sac_pi/pi_entropy     | 3.5668724   |
| training/sac_pi/pi_global_norm | 1.8613846   |
| training/sac_pi/policy_loss    | -231.88225  |
| training/sac_pi/std            | 0.52366906  |
| training/sac_pi/valid_num      | 4970.0      |
| training/sac_Q/q1              | 214.91716   |
| training/sac_Q/q2              | 216.6578    |
| training/sac_Q/q2_loss         | 93.31472    |
| training/sac_Q/q_global_norm   | 220.97324   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.17051451   |
| epoch                          | 881          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4894.123     |
| evaluation/return-max          | 4940.7373    |
| evaluation/return-min          | 4838.9546    |
| evaluation/return-std          | 29.921524    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.13         |
| model/origin_ret               | 85.7         |
| model/penalty_ret              | 79           |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46527        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4894.123     |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 215.82149    |
| Q-std                          | 163.01013    |
| Q_loss                         | 112.33481    |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 881          |
| times/epoch_after_hook         | 1.71e-06     |
| times/epoch_before_hook        | 0.000281     |
| times/epoch_rollout_model      | 475          |
| times/evaluation_metrics       | 0.000705     |
| times/evaluation_paths         | 37.8         |
| times/timestep_after_hook      | 0.0037       |
| times/timestep_before_hook     | 0.0082       |
| times/train                    | 69.7         |
| timestep                       | 1000         |
| timesteps_total                | 882000       |
| train-steps                    | 882000       |
| training/Q/q1_loss             | 90.299515    |
| training/sac_pi/alpha          | 0.17051141   |
| training/sac_pi/alpha_loss     | -0.023684144 |
| training/sac_pi/logp_pi        | 3.74171      |
| training/sac_pi/pi_entropy     | 3.558036     |
| training/sac_pi/pi_global_norm | 2.0106742    |
| training/sac_pi/policy_loss    | -225.0777    |
| training/sac_pi/std            | 0.48913676   |
| training/sac_pi/valid_num      | 5021.0       |
| training/sac_Q/q1              | 218.1511     |
| training/sac_Q/q2              | 220.80264    |
| training/sac_Q/q2_loss         | 90.098175    |
| training/sac_Q/q_global_norm   | 190.91045    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16573326 |
| epoch                          | 882        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5112.061   |
| evaluation/return-max          | 5139.9863  |
| evaluation/return-min          | 5084.754   |
| evaluation/return-std          | 16.99787   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 80.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46432      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5112.061   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 215.03842  |
| Q-std                          | 155.29967  |
| Q_loss                         | 79.51238   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 882        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000138   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000659   |
| times/evaluation_paths         | 37.4       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 69.8       |
| timestep                       | 1000       |
| timesteps_total                | 883000     |
| train-steps                    | 883000     |
| training/Q/q1_loss             | 85.26743   |
| training/sac_pi/alpha          | 0.16572174 |
| training/sac_pi/alpha_loss     | 0.07563505 |
| training/sac_pi/logp_pi        | 4.197025   |
| training/sac_pi/pi_entropy     | 3.2959588  |
| training/sac_pi/pi_global_norm | 2.0148056  |
| training/sac_pi/policy_loss    | -231.3701  |
| training/sac_pi/std            | 0.47457382 |
| training/sac_pi/valid_num      | 4928.0     |
| training/sac_Q/q1              | 216.8949   |
| training/sac_Q/q2              | 219.93083  |
| training/sac_Q/q2_loss         | 84.9266    |
| training/sac_Q/q_global_norm   | 202.71399  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16389576  |
| epoch                          | 883         |
| evaluation/episode-length-avg  | 793         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 306         |
| evaluation/episode-length-std  | 317         |
| evaluation/return-average      | 3905.7585   |
| evaluation/return-max          | 5096.4805   |
| evaluation/return-min          | 1196.5947   |
| evaluation/return-std          | 1766.6156   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46488       |
| perf/AverageLength             | 793         |
| perf/AverageReturn             | 3905.7585   |
| perf/NormalizedReturn          | 0.85        |
| Q-avg                          | 226.01665   |
| Q-std                          | 101.594185  |
| Q_loss                         | 96.80556    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 883         |
| times/epoch_after_hook         | 1.55e-06    |
| times/epoch_before_hook        | 0.000143    |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000543    |
| times/evaluation_paths         | 30.1        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00814     |
| times/train                    | 71.5        |
| timestep                       | 1000        |
| timesteps_total                | 884000      |
| train-steps                    | 884000      |
| training/Q/q1_loss             | 84.06857    |
| training/sac_pi/alpha          | 0.16389315  |
| training/sac_pi/alpha_loss     | 0.039290056 |
| training/sac_pi/logp_pi        | 4.1792655   |
| training/sac_pi/pi_entropy     | 3.5662262   |
| training/sac_pi/pi_global_norm | 1.8507581   |
| training/sac_pi/policy_loss    | -230.17653  |
| training/sac_pi/std            | 0.5220698   |
| training/sac_pi/valid_num      | 4953.0      |
| training/sac_Q/q1              | 216.06161   |
| training/sac_Q/q2              | 219.26189   |
| training/sac_Q/q2_loss         | 83.75835    |
| training/sac_Q/q_global_norm   | 171.45413   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16570054  |
| epoch                          | 884         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4996.065    |
| evaluation/return-max          | 5044.797    |
| evaluation/return-min          | 4927.004    |
| evaluation/return-std          | 32.787243   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46434       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4996.065    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 219.8532    |
| Q-std                          | 204.39996   |
| Q_loss                         | 89.14101    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 884         |
| times/epoch_after_hook         | 1.65e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 481         |
| times/evaluation_metrics       | 0.000639    |
| times/evaluation_paths         | 47.1        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 885000      |
| train-steps                    | 885000      |
| training/Q/q1_loss             | 95.1075     |
| training/sac_pi/alpha          | 0.16571565  |
| training/sac_pi/alpha_loss     | -0.25862387 |
| training/sac_pi/logp_pi        | 3.9173007   |
| training/sac_pi/pi_entropy     | 3.5153508   |
| training/sac_pi/pi_global_norm | 1.5074092   |
| training/sac_pi/policy_loss    | -228.68541  |
| training/sac_pi/std            | 0.5011982   |
| training/sac_pi/valid_num      | 4995.0      |
| training/sac_Q/q1              | 218.11337   |
| training/sac_Q/q2              | 218.26897   |
| training/sac_Q/q2_loss         | 95.87082    |
| training/sac_Q/q_global_norm   | 199.67809   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16920751  |
| epoch                          | 885         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5213.8765   |
| evaluation/return-max          | 5336.2456   |
| evaluation/return-min          | 5115.2275   |
| evaluation/return-std          | 75.64604    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.04        |
| model/origin_ret               | 84.5        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46352       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5213.8765   |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 209.98795   |
| Q-std                          | 181.0736    |
| Q_loss                         | 107.945724  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 885         |
| times/epoch_after_hook         | 3.04e-06    |
| times/epoch_before_hook        | 0.000285    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000607    |
| times/evaluation_paths         | 36          |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 67.1        |
| timestep                       | 1000        |
| timesteps_total                | 886000      |
| train-steps                    | 886000      |
| training/Q/q1_loss             | 108.253624  |
| training/sac_pi/alpha          | 0.16921967  |
| training/sac_pi/alpha_loss     | -0.10564828 |
| training/sac_pi/logp_pi        | 4.5955253   |
| training/sac_pi/pi_entropy     | 3.6553757   |
| training/sac_pi/pi_global_norm | 1.7250705   |
| training/sac_pi/policy_loss    | -229.2924   |
| training/sac_pi/std            | 0.52835816  |
| training/sac_pi/valid_num      | 4900.0      |
| training/sac_Q/q1              | 204.77434   |
| training/sac_Q/q2              | 207.95076   |
| training/sac_Q/q2_loss         | 107.98635   |
| training/sac_Q/q_global_norm   | 193.10771   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.17184652 |
| epoch                          | 886        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4823.993   |
| evaluation/return-max          | 4867.4395  |
| evaluation/return-min          | 4806.2085  |
| evaluation/return-std          | 18.247467  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46610      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4823.993   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 211.54935  |
| Q-std                          | 215.0454   |
| Q_loss                         | 104.382645 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 886        |
| times/epoch_after_hook         | 1.66e-06   |
| times/epoch_before_hook        | 0.000142   |
| times/epoch_rollout_model      | 495        |
| times/evaluation_metrics       | 0.000575   |
| times/evaluation_paths         | 38.3       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 69.2       |
| timestep                       | 1000       |
| timesteps_total                | 887000     |
| train-steps                    | 887000     |
| training/Q/q1_loss             | 99.21861   |
| training/sac_pi/alpha          | 0.17184119 |
| training/sac_pi/alpha_loss     | 0.13901389 |
| training/sac_pi/logp_pi        | 4.301464   |
| training/sac_pi/pi_entropy     | 3.6102557  |
| training/sac_pi/pi_global_norm | 1.6102442  |
| training/sac_pi/policy_loss    | -221.21323 |
| training/sac_pi/std            | 0.5051728  |
| training/sac_pi/valid_num      | 4989.0     |
| training/sac_Q/q1              | 202.90988  |
| training/sac_Q/q2              | 206.71179  |
| training/sac_Q/q2_loss         | 100.3046   |
| training/sac_Q/q_global_norm   | 212.8051   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16495264 |
| epoch                          | 887        |
| evaluation/episode-length-avg  | 930        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 298        |
| evaluation/episode-length-std  | 211        |
| evaluation/return-average      | 4506.337   |
| evaluation/return-max          | 4939.804   |
| evaluation/return-min          | 1134.323   |
| evaluation/return-std          | 1125.5588  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 78.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46445      |
| perf/AverageLength             | 930        |
| perf/AverageReturn             | 4506.337   |
| perf/NormalizedReturn          | 0.981      |
| Q-avg                          | 213.73132  |
| Q-std                          | 247.26755  |
| Q_loss                         | 90.305084  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 887        |
| times/epoch_after_hook         | 1.94e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000548   |
| times/evaluation_paths         | 33.1       |
| times/timestep_after_hook      | 0.00363    |
| times/timestep_before_hook     | 0.00824    |
| times/train                    | 69.4       |
| timestep                       | 1000       |
| timesteps_total                | 888000     |
| train-steps                    | 888000     |
| training/Q/q1_loss             | 124.21796  |
| training/sac_pi/alpha          | 0.16493748 |
| training/sac_pi/alpha_loss     | 0.2852061  |
| training/sac_pi/logp_pi        | 4.493074   |
| training/sac_pi/pi_entropy     | 3.3271973  |
| training/sac_pi/pi_global_norm | 1.7344885  |
| training/sac_pi/policy_loss    | -229.73474 |
| training/sac_pi/std            | 0.48469532 |
| training/sac_pi/valid_num      | 4989.0     |
| training/sac_Q/q1              | 214.45938  |
| training/sac_Q/q2              | 217.46313  |
| training/sac_Q/q2_loss         | 122.79575  |
| training/sac_Q/q_global_norm   | 223.80748  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16462506 |
| epoch                          | 888        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4902.9077  |
| evaluation/return-max          | 5008.418   |
| evaluation/return-min          | 4748.5747  |
| evaluation/return-std          | 69.99373   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85         |
| model/penalty_ret              | 78.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46446      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4902.9077  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 212.87569  |
| Q-std                          | 163.78047  |
| Q_loss                         | 96.97655   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 888        |
| times/epoch_after_hook         | 1.84e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 489        |
| times/evaluation_metrics       | 0.000626   |
| times/evaluation_paths         | 46.2       |
| times/timestep_after_hook      | 0.00355    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 62.8       |
| timestep                       | 1000       |
| timesteps_total                | 889000     |
| train-steps                    | 889000     |
| training/Q/q1_loss             | 96.930435  |
| training/sac_pi/alpha          | 0.1646505  |
| training/sac_pi/alpha_loss     | 0.142118   |
| training/sac_pi/logp_pi        | 4.11827    |
| training/sac_pi/pi_entropy     | 3.4450588  |
| training/sac_pi/pi_global_norm | 1.604383   |
| training/sac_pi/policy_loss    | -226.56291 |
| training/sac_pi/std            | 0.4847844  |
| training/sac_pi/valid_num      | 5005.0     |
| training/sac_Q/q1              | 216.19109  |
| training/sac_Q/q2              | 216.4541   |
| training/sac_Q/q2_loss         | 97.188736  |
| training/sac_Q/q_global_norm   | 206.77055  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1608896  |
| epoch                          | 889        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5045.5127  |
| evaluation/return-max          | 5152.6406  |
| evaluation/return-min          | 4976.1655  |
| evaluation/return-std          | 42.656643  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 79         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46517      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5045.5127  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 212.76628  |
| Q-std                          | 137.15463  |
| Q_loss                         | 103.25545  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 889        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000283   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000588   |
| times/evaluation_paths         | 35.9       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 64.8       |
| timestep                       | 1000       |
| timesteps_total                | 890000     |
| train-steps                    | 890000     |
| training/Q/q1_loss             | 95.203316  |
| training/sac_pi/alpha          | 0.16089016 |
| training/sac_pi/alpha_loss     | 0.21495327 |
| training/sac_pi/logp_pi        | 3.9542649  |
| training/sac_pi/pi_entropy     | 3.154181   |
| training/sac_pi/pi_global_norm | 1.9075482  |
| training/sac_pi/policy_loss    | -234.47334 |
| training/sac_pi/std            | 0.45968932 |
| training/sac_pi/valid_num      | 5050.0     |
| training/sac_Q/q1              | 225.8531   |
| training/sac_Q/q2              | 227.6545   |
| training/sac_Q/q2_loss         | 95.65593   |
| training/sac_Q/q_global_norm   | 219.01443  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15921676 |
| epoch                          | 890        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5130.116   |
| evaluation/return-max          | 5158.3164  |
| evaluation/return-min          | 5017.764   |
| evaluation/return-std          | 40.45604   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46617      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5130.116   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 217.07658  |
| Q-std                          | 237.03444  |
| Q_loss                         | 85.960976  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 890        |
| times/epoch_after_hook         | 1.76e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000571   |
| times/evaluation_paths         | 38.3       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00844    |
| times/train                    | 69.6       |
| timestep                       | 1000       |
| timesteps_total                | 891000     |
| train-steps                    | 891000     |
| training/Q/q1_loss             | 98.389046  |
| training/sac_pi/alpha          | 0.1591861  |
| training/sac_pi/alpha_loss     | 0.17931692 |
| training/sac_pi/logp_pi        | 4.1250253  |
| training/sac_pi/pi_entropy     | 3.4541633  |
| training/sac_pi/pi_global_norm | 1.955552   |
| training/sac_pi/policy_loss    | -230.39793 |
| training/sac_pi/std            | 0.49185097 |
| training/sac_pi/valid_num      | 4921.0     |
| training/sac_Q/q1              | 218.20088  |
| training/sac_Q/q2              | 217.37173  |
| training/sac_Q/q2_loss         | 98.32479   |
| training/sac_Q/q_global_norm   | 236.89388  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15737669 |
| epoch                          | 891        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4900.4956  |
| evaluation/return-max          | 5009.458   |
| evaluation/return-min          | 4650.4854  |
| evaluation/return-std          | 106.01403  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46604      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4900.4956  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 219.0812   |
| Q-std                          | 119.29752  |
| Q_loss                         | 104.99876  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 891        |
| times/epoch_after_hook         | 1.62e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000531   |
| times/evaluation_paths         | 35.2       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 68.9       |
| timestep                       | 1000       |
| timesteps_total                | 892000     |
| train-steps                    | 892000     |
| training/Q/q1_loss             | 102.7791   |
| training/sac_pi/alpha          | 0.15735541 |
| training/sac_pi/alpha_loss     | 0.15823014 |
| training/sac_pi/logp_pi        | 4.6996145  |
| training/sac_pi/pi_entropy     | 3.3863997  |
| training/sac_pi/pi_global_norm | 1.6127428  |
| training/sac_pi/policy_loss    | -225.74612 |
| training/sac_pi/std            | 0.4917127  |
| training/sac_pi/valid_num      | 4958.0     |
| training/sac_Q/q1              | 214.73645  |
| training/sac_Q/q2              | 216.42435  |
| training/sac_Q/q2_loss         | 103.37931  |
| training/sac_Q/q_global_norm   | 245.14885  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15896344  |
| epoch                          | 892         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5118.37     |
| evaluation/return-max          | 5196.743    |
| evaluation/return-min          | 4963.509    |
| evaluation/return-std          | 62.654716   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 78.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46627       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5118.37     |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 220.00322   |
| Q-std                          | 158.10747   |
| Q_loss                         | 94.65023    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 892         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 496         |
| times/evaluation_metrics       | 0.000547    |
| times/evaluation_paths         | 47.1        |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 893000      |
| train-steps                    | 893000      |
| training/Q/q1_loss             | 79.21367    |
| training/sac_pi/alpha          | 0.15898667  |
| training/sac_pi/alpha_loss     | -0.21367554 |
| training/sac_pi/logp_pi        | 3.7613437   |
| training/sac_pi/pi_entropy     | 3.4763355   |
| training/sac_pi/pi_global_norm | 1.7135687   |
| training/sac_pi/policy_loss    | -230.70238  |
| training/sac_pi/std            | 0.48960787  |
| training/sac_pi/valid_num      | 4997.0      |
| training/sac_Q/q1              | 222.86203   |
| training/sac_Q/q2              | 222.39633   |
| training/sac_Q/q2_loss         | 79.255424   |
| training/sac_Q/q_global_norm   | 161.28624   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15844277 |
| epoch                          | 893        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5086.892   |
| evaluation/return-max          | 5238.8696  |
| evaluation/return-min          | 4810.042   |
| evaluation/return-std          | 118.86328  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46486      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5086.892   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 213.3658   |
| Q-std                          | 151.38106  |
| Q_loss                         | 93.476944  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 893        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.0003     |
| times/epoch_rollout_model      | 515        |
| times/evaluation_metrics       | 0.000684   |
| times/evaluation_paths         | 45.3       |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00858    |
| times/train                    | 72.6       |
| timestep                       | 1000       |
| timesteps_total                | 894000     |
| train-steps                    | 894000     |
| training/Q/q1_loss             | 109.56152  |
| training/sac_pi/alpha          | 0.15843941 |
| training/sac_pi/alpha_loss     | 0.2824227  |
| training/sac_pi/logp_pi        | 4.184298   |
| training/sac_pi/pi_entropy     | 3.3730311  |
| training/sac_pi/pi_global_norm | 1.9004904  |
| training/sac_pi/policy_loss    | -233.08708 |
| training/sac_pi/std            | 0.49287707 |
| training/sac_pi/valid_num      | 4985.0     |
| training/sac_Q/q1              | 223.07832  |
| training/sac_Q/q2              | 226.65738  |
| training/sac_Q/q2_loss         | 110.42896  |
| training/sac_Q/q_global_norm   | 225.42455  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1591283  |
| epoch                          | 894        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5281.4375  |
| evaluation/return-max          | 5357.3984  |
| evaluation/return-min          | 5080.454   |
| evaluation/return-std          | 74.79526   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46579      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5281.4375  |
| perf/NormalizedReturn          | 1.15       |
| Q-avg                          | 211.05864  |
| Q-std                          | 199.30353  |
| Q_loss                         | 108.50456  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 894        |
| times/epoch_after_hook         | 1.83e-06   |
| times/epoch_before_hook        | 0.000146   |
| times/epoch_rollout_model      | 507        |
| times/evaluation_metrics       | 0.000627   |
| times/evaluation_paths         | 37         |
| times/timestep_after_hook      | 0.00408    |
| times/timestep_before_hook     | 0.00876    |
| times/train                    | 68.9       |
| timestep                       | 1000       |
| timesteps_total                | 895000     |
| train-steps                    | 895000     |
| training/Q/q1_loss             | 75.90596   |
| training/sac_pi/alpha          | 0.15917028 |
| training/sac_pi/alpha_loss     | -0.5976592 |
| training/sac_pi/logp_pi        | 3.870036   |
| training/sac_pi/pi_entropy     | 3.5260415  |
| training/sac_pi/pi_global_norm | 2.2621005  |
| training/sac_pi/policy_loss    | -234.08055 |
| training/sac_pi/std            | 0.5018619  |
| training/sac_pi/valid_num      | 5014.0     |
| training/sac_Q/q1              | 224.58804  |
| training/sac_Q/q2              | 225.36728  |
| training/sac_Q/q2_loss         | 77.13456   |
| training/sac_Q/q_global_norm   | 214.50377  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16097362 |
| epoch                          | 895        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5040.952   |
| evaluation/return-max          | 5093.806   |
| evaluation/return-min          | 4946.908   |
| evaluation/return-std          | 49.8319    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46496      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5040.952   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 216.22998  |
| Q-std                          | 127.31191  |
| Q_loss                         | 106.450264 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 895        |
| times/epoch_after_hook         | 1.93e-06   |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 532        |
| times/evaluation_metrics       | 0.000628   |
| times/evaluation_paths         | 39.5       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00866    |
| times/train                    | 62.7       |
| timestep                       | 1000       |
| timesteps_total                | 896000     |
| train-steps                    | 896000     |
| training/Q/q1_loss             | 108.97227  |
| training/sac_pi/alpha          | 0.16100532 |
| training/sac_pi/alpha_loss     | 0.10789107 |
| training/sac_pi/logp_pi        | 3.961084   |
| training/sac_pi/pi_entropy     | 3.4072738  |
| training/sac_pi/pi_global_norm | 1.6121268  |
| training/sac_pi/policy_loss    | -233.15733 |
| training/sac_pi/std            | 0.47958824 |
| training/sac_pi/valid_num      | 4988.0     |
| training/sac_Q/q1              | 223.05331  |
| training/sac_Q/q2              | 224.9574   |
| training/sac_Q/q2_loss         | 108.53022  |
| training/sac_Q/q_global_norm   | 190.0154   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15921888 |
| epoch                          | 896        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5059.061   |
| evaluation/return-max          | 5139.8906  |
| evaluation/return-min          | 4988.119   |
| evaluation/return-std          | 53.363125  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 84.6       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46457      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5059.061   |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 222.02588  |
| Q-std                          | 188.48361  |
| Q_loss                         | 84.27664   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 896        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000132   |
| times/epoch_rollout_model      | 498        |
| times/evaluation_metrics       | 0.000565   |
| times/evaluation_paths         | 39.2       |
| times/timestep_after_hook      | 0.00355    |
| times/timestep_before_hook     | 0.00838    |
| times/train                    | 71.5       |
| timestep                       | 1000       |
| timesteps_total                | 897000     |
| train-steps                    | 897000     |
| training/Q/q1_loss             | 93.141136  |
| training/sac_pi/alpha          | 0.15921591 |
| training/sac_pi/alpha_loss     | 0.21889284 |
| training/sac_pi/logp_pi        | 4.721377   |
| training/sac_pi/pi_entropy     | 3.4305224  |
| training/sac_pi/pi_global_norm | 2.0379074  |
| training/sac_pi/policy_loss    | -228.38347 |
| training/sac_pi/std            | 0.5076219  |
| training/sac_pi/valid_num      | 4944.0     |
| training/sac_Q/q1              | 212.32007  |
| training/sac_Q/q2              | 213.38663  |
| training/sac_Q/q2_loss         | 92.49416   |
| training/sac_Q/q_global_norm   | 246.8063   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16268156  |
| epoch                          | 897         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5008.8945   |
| evaluation/return-max          | 5127.724    |
| evaluation/return-min          | 4883.787    |
| evaluation/return-std          | 76.701294   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46431       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5008.8945   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 217.40591   |
| Q-std                          | 129.79985   |
| Q_loss                         | 92.64195    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 897         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.00033     |
| times/epoch_rollout_model      | 489         |
| times/evaluation_metrics       | 0.000612    |
| times/evaluation_paths         | 37          |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00844     |
| times/train                    | 73.2        |
| timestep                       | 1000        |
| timesteps_total                | 898000      |
| train-steps                    | 898000      |
| training/Q/q1_loss             | 100.42009   |
| training/sac_pi/alpha          | 0.16266829  |
| training/sac_pi/alpha_loss     | -0.11849403 |
| training/sac_pi/logp_pi        | 4.4070024   |
| training/sac_pi/pi_entropy     | 3.5418906   |
| training/sac_pi/pi_global_norm | 1.7339263   |
| training/sac_pi/policy_loss    | -230.5712   |
| training/sac_pi/std            | 0.5134869   |
| training/sac_pi/valid_num      | 4912.0      |
| training/sac_Q/q1              | 211.73335   |
| training/sac_Q/q2              | 215.82202   |
| training/sac_Q/q2_loss         | 100.49785   |
| training/sac_Q/q_global_norm   | 229.20924   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16573289  |
| epoch                          | 898         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5070.157    |
| evaluation/return-max          | 5094.46     |
| evaluation/return-min          | 5033.6445   |
| evaluation/return-std          | 18.313654   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46442       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5070.157    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 224.8912    |
| Q-std                          | 136.50116   |
| Q_loss                         | 92.46762    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 898         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.000692    |
| times/evaluation_paths         | 43.4        |
| times/timestep_after_hook      | 0.00356     |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 65.8        |
| timestep                       | 1000        |
| timesteps_total                | 899000      |
| train-steps                    | 899000      |
| training/Q/q1_loss             | 69.26053    |
| training/sac_pi/alpha          | 0.16568641  |
| training/sac_pi/alpha_loss     | -0.14271618 |
| training/sac_pi/logp_pi        | 3.4890723   |
| training/sac_pi/pi_entropy     | 3.5123925   |
| training/sac_pi/pi_global_norm | 1.5767657   |
| training/sac_pi/policy_loss    | -228.94223  |
| training/sac_pi/std            | 0.47382152  |
| training/sac_pi/valid_num      | 5014.0      |
| training/sac_Q/q1              | 222.45166   |
| training/sac_Q/q2              | 223.75977   |
| training/sac_Q/q2_loss         | 69.38963    |
| training/sac_Q/q_global_norm   | 286.8053    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15947442  |
| epoch                          | 899         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4971.152    |
| evaluation/return-max          | 5200.5767   |
| evaluation/return-min          | 4848.2256   |
| evaluation/return-std          | 104.175606  |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 87.1        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46388       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4971.152    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 214.49223   |
| Q-std                          | 153.47044   |
| Q_loss                         | 115.19863   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 899         |
| times/epoch_after_hook         | 1.74e-06    |
| times/epoch_before_hook        | 0.000123    |
| times/epoch_rollout_model      | 507         |
| times/evaluation_metrics       | 0.000562    |
| times/evaluation_paths         | 44.1        |
| times/timestep_after_hook      | 0.00395     |
| times/timestep_before_hook     | 0.00883     |
| times/train                    | 62.3        |
| timestep                       | 1000        |
| timesteps_total                | 900000      |
| train-steps                    | 900000      |
| training/Q/q1_loss             | 102.44477   |
| training/sac_pi/alpha          | 0.15948138  |
| training/sac_pi/alpha_loss     | -0.06933496 |
| training/sac_pi/logp_pi        | 4.1808405   |
| training/sac_pi/pi_entropy     | 3.5676205   |
| training/sac_pi/pi_global_norm | 1.529237    |
| training/sac_pi/policy_loss    | -221.4218   |
| training/sac_pi/std            | 0.5273568   |
| training/sac_pi/valid_num      | 4954.0      |
| training/sac_Q/q1              | 209.61679   |
| training/sac_Q/q2              | 212.83699   |
| training/sac_Q/q2_loss         | 101.65947   |
| training/sac_Q/q_global_norm   | 291.1397    |
---------------------------------------------------------------------------------
[WARN] 900 : sync: start
---------------------------------------------------------------------------------
| alpha                          | 0.15683436  |
| epoch                          | 900         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4987.424    |
| evaluation/return-max          | 5373.2437   |
| evaluation/return-min          | 4835.665    |
| evaluation/return-std          | 163.74983   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 78.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46455       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4987.424    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 219.41379   |
| Q-std                          | 142.88687   |
| Q_loss                         | 76.546036   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 900         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000125    |
| times/epoch_rollout_model      | 497         |
| times/evaluation_metrics       | 0.000837    |
| times/evaluation_paths         | 35.3        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00831     |
| times/train                    | 62.1        |
| timestep                       | 1000        |
| timesteps_total                | 901000      |
| train-steps                    | 901000      |
| training/Q/q1_loss             | 107.27916   |
| training/sac_pi/alpha          | 0.15686922  |
| training/sac_pi/alpha_loss     | -0.43040988 |
| training/sac_pi/logp_pi        | 4.326773    |
| training/sac_pi/pi_entropy     | 3.491407    |
| training/sac_pi/pi_global_norm | 1.8698024   |
| training/sac_pi/policy_loss    | -228.69955  |
| training/sac_pi/std            | 0.5347063   |
| training/sac_pi/valid_num      | 4904.0      |
| training/sac_Q/q1              | 209.63338   |
| training/sac_Q/q2              | 213.61533   |
| training/sac_Q/q2_loss         | 106.3523    |
| training/sac_Q/q_global_norm   | 205.87105   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15997562 |
| epoch                          | 901        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5054.2397  |
| evaluation/return-max          | 5266.69    |
| evaluation/return-min          | 4937.1914  |
| evaluation/return-std          | 93.61777   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.18       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 78.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46641      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5054.2397  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 218.7929   |
| Q-std                          | 191.91193  |
| Q_loss                         | 106.75204  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 901        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000342   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.0006     |
| times/evaluation_paths         | 36.9       |
| times/timestep_after_hook      | 0.00372    |
| times/timestep_before_hook     | 0.00827    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 902000     |
| train-steps                    | 902000     |
| training/Q/q1_loss             | 96.8232    |
| training/sac_pi/alpha          | 0.15999997 |
| training/sac_pi/alpha_loss     | 0.13192007 |
| training/sac_pi/logp_pi        | 4.6320815  |
| training/sac_pi/pi_entropy     | 3.208168   |
| training/sac_pi/pi_global_norm | 1.774228   |
| training/sac_pi/policy_loss    | -227.76471 |
| training/sac_pi/std            | 0.5001743  |
| training/sac_pi/valid_num      | 4948.0     |
| training/sac_Q/q1              | 210.20088  |
| training/sac_Q/q2              | 215.60318  |
| training/sac_Q/q2_loss         | 95.8991    |
| training/sac_Q/q_global_norm   | 184.16913  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16312063   |
| epoch                          | 902          |
| evaluation/episode-length-avg  | 867          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 487          |
| evaluation/episode-length-std  | 206          |
| evaluation/return-average      | 4315.624     |
| evaluation/return-max          | 5350.33      |
| evaluation/return-min          | 2223.1934    |
| evaluation/return-std          | 1170.5168    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.09         |
| model/origin_ret               | 84.7         |
| model/penalty_ret              | 78.9         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46572        |
| perf/AverageLength             | 867          |
| perf/AverageReturn             | 4315.624     |
| perf/NormalizedReturn          | 0.94         |
| Q-avg                          | 226.56021    |
| Q-std                          | 144.1646     |
| Q_loss                         | 79.16521     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 902          |
| times/epoch_after_hook         | 3.38e-06     |
| times/epoch_before_hook        | 0.000125     |
| times/epoch_rollout_model      | 491          |
| times/evaluation_metrics       | 0.000495     |
| times/evaluation_paths         | 31.4         |
| times/timestep_after_hook      | 0.00354      |
| times/timestep_before_hook     | 0.00833      |
| times/train                    | 59.8         |
| timestep                       | 1000         |
| timesteps_total                | 903000       |
| train-steps                    | 903000       |
| training/Q/q1_loss             | 112.90159    |
| training/sac_pi/alpha          | 0.16311842   |
| training/sac_pi/alpha_loss     | -0.055623453 |
| training/sac_pi/logp_pi        | 3.7637353    |
| training/sac_pi/pi_entropy     | 3.3621726    |
| training/sac_pi/pi_global_norm | 1.807684     |
| training/sac_pi/policy_loss    | -227.48146   |
| training/sac_pi/std            | 0.47769466   |
| training/sac_pi/valid_num      | 5038.0       |
| training/sac_Q/q1              | 218.19003    |
| training/sac_Q/q2              | 221.91641    |
| training/sac_Q/q2_loss         | 113.495125   |
| training/sac_Q/q_global_norm   | 211.3269     |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1645825   |
| epoch                          | 903         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5205.0312   |
| evaluation/return-max          | 5242.5684   |
| evaluation/return-min          | 5158.318    |
| evaluation/return-std          | 24.297043   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.18        |
| model/origin_ret               | 86.8        |
| model/penalty_ret              | 78.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46558       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5205.0312   |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 216.84457   |
| Q-std                          | 177.51302   |
| Q_loss                         | 79.70401    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 903         |
| times/epoch_after_hook         | 1.78e-06    |
| times/epoch_before_hook        | 0.000101    |
| times/epoch_rollout_model      | 507         |
| times/evaluation_metrics       | 0.000597    |
| times/evaluation_paths         | 35.1        |
| times/timestep_after_hook      | 0.00357     |
| times/timestep_before_hook     | 0.00845     |
| times/train                    | 58.6        |
| timestep                       | 1000        |
| timesteps_total                | 904000      |
| train-steps                    | 904000      |
| training/Q/q1_loss             | 70.67573    |
| training/sac_pi/alpha          | 0.16457058  |
| training/sac_pi/alpha_loss     | -0.11511399 |
| training/sac_pi/logp_pi        | 3.727578    |
| training/sac_pi/pi_entropy     | 3.4176533   |
| training/sac_pi/pi_global_norm | 1.8851444   |
| training/sac_pi/policy_loss    | -238.63974  |
| training/sac_pi/std            | 0.47073588  |
| training/sac_pi/valid_num      | 4997.0      |
| training/sac_Q/q1              | 227.99643   |
| training/sac_Q/q2              | 230.46451   |
| training/sac_Q/q2_loss         | 71.15491    |
| training/sac_Q/q_global_norm   | 158.85023   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1625537  |
| epoch                          | 904        |
| evaluation/episode-length-avg  | 986        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 862        |
| evaluation/episode-length-std  | 41.4       |
| evaluation/return-average      | 5109.317   |
| evaluation/return-max          | 5336.133   |
| evaluation/return-min          | 4476.8877  |
| evaluation/return-std          | 254.98897  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.17       |
| model/origin_ret               | 87.8       |
| model/penalty_ret              | 80.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46551      |
| perf/AverageLength             | 986        |
| perf/AverageReturn             | 5109.317   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 215.89091  |
| Q-std                          | 144.62917  |
| Q_loss                         | 80.177086  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 904        |
| times/epoch_after_hook         | 1.72e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 509        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 33.9       |
| times/timestep_after_hook      | 0.00354    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 905000     |
| train-steps                    | 905000     |
| training/Q/q1_loss             | 90.759735  |
| training/sac_pi/alpha          | 0.16256264 |
| training/sac_pi/alpha_loss     | 0.03077512 |
| training/sac_pi/logp_pi        | 3.8672588  |
| training/sac_pi/pi_entropy     | 3.4611466  |
| training/sac_pi/pi_global_norm | 1.5167736  |
| training/sac_pi/policy_loss    | -230.02098 |
| training/sac_pi/std            | 0.48582116 |
| training/sac_pi/valid_num      | 4973.0     |
| training/sac_Q/q1              | 215.5068   |
| training/sac_Q/q2              | 218.30185  |
| training/sac_Q/q2_loss         | 91.13157   |
| training/sac_Q/q_global_norm   | 170.0395   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1635805  |
| epoch                          | 905        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5163.3135  |
| evaluation/return-max          | 5181.5205  |
| evaluation/return-min          | 5149.521   |
| evaluation/return-std          | 9.510365   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46659      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5163.3135  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 217.30002  |
| Q-std                          | 184.9554   |
| Q_loss                         | 83.88224   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 905        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000279   |
| times/epoch_rollout_model      | 502        |
| times/evaluation_metrics       | 0.000801   |
| times/evaluation_paths         | 36.6       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00857    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 906000     |
| train-steps                    | 906000     |
| training/Q/q1_loss             | 89.85482   |
| training/sac_pi/alpha          | 0.16357704 |
| training/sac_pi/alpha_loss     | 0.1352727  |
| training/sac_pi/logp_pi        | 4.369884   |
| training/sac_pi/pi_entropy     | 3.280809   |
| training/sac_pi/pi_global_norm | 1.9733225  |
| training/sac_pi/policy_loss    | -242.82849 |
| training/sac_pi/std            | 0.4890808  |
| training/sac_pi/valid_num      | 4978.0     |
| training/sac_Q/q1              | 228.6051   |
| training/sac_Q/q2              | 227.47725  |
| training/sac_Q/q2_loss         | 89.74951   |
| training/sac_Q/q_global_norm   | 261.77884  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15737113  |
| epoch                          | 906         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5155.0703   |
| evaluation/return-max          | 5241.033    |
| evaluation/return-min          | 5068.3066   |
| evaluation/return-std          | 51.39089    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46417       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5155.0703   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 209.74658   |
| Q-std                          | 164.97813   |
| Q_loss                         | 103.57836   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 906         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000148    |
| times/epoch_rollout_model      | 534         |
| times/evaluation_metrics       | 0.000665    |
| times/evaluation_paths         | 35.7        |
| times/timestep_after_hook      | 0.00412     |
| times/timestep_before_hook     | 0.00853     |
| times/train                    | 62.8        |
| timestep                       | 1000        |
| timesteps_total                | 907000      |
| train-steps                    | 907000      |
| training/Q/q1_loss             | 94.237335   |
| training/sac_pi/alpha          | 0.15733325  |
| training/sac_pi/alpha_loss     | 0.045911245 |
| training/sac_pi/logp_pi        | 5.0417786   |
| training/sac_pi/pi_entropy     | 3.3333416   |
| training/sac_pi/pi_global_norm | 2.0624092   |
| training/sac_pi/policy_loss    | -237.35443  |
| training/sac_pi/std            | 0.5283589   |
| training/sac_pi/valid_num      | 4918.0      |
| training/sac_Q/q1              | 211.91489   |
| training/sac_Q/q2              | 215.60762   |
| training/sac_Q/q2_loss         | 94.9762     |
| training/sac_Q/q_global_norm   | 240.79868   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15927614   |
| epoch                          | 907          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5152.1685    |
| evaluation/return-max          | 5191.1963    |
| evaluation/return-min          | 5109.328     |
| evaluation/return-std          | 20.23714     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.19         |
| model/origin_ret               | 86.8         |
| model/penalty_ret              | 79           |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46627        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5152.1685    |
| perf/NormalizedReturn          | 1.12         |
| Q-avg                          | 214.37497    |
| Q-std                          | 165.69579    |
| Q_loss                         | 93.93311     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 907          |
| times/epoch_after_hook         | 1.83e-06     |
| times/epoch_before_hook        | 0.000171     |
| times/epoch_rollout_model      | 542          |
| times/evaluation_metrics       | 0.000658     |
| times/evaluation_paths         | 46.3         |
| times/timestep_after_hook      | 0.00383      |
| times/timestep_before_hook     | 0.00844      |
| times/train                    | 65.2         |
| timestep                       | 1000         |
| timesteps_total                | 908000       |
| train-steps                    | 908000       |
| training/Q/q1_loss             | 106.31741    |
| training/sac_pi/alpha          | 0.1592816    |
| training/sac_pi/alpha_loss     | -0.074132785 |
| training/sac_pi/logp_pi        | 4.1090665    |
| training/sac_pi/pi_entropy     | 3.3183856    |
| training/sac_pi/pi_global_norm | 2.0430799    |
| training/sac_pi/policy_loss    | -232.47684   |
| training/sac_pi/std            | 0.4710191    |
| training/sac_pi/valid_num      | 4987.0       |
| training/sac_Q/q1              | 224.34409    |
| training/sac_Q/q2              | 224.1296     |
| training/sac_Q/q2_loss         | 105.60333    |
| training/sac_Q/q_global_norm   | 283.79626    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16340733  |
| epoch                          | 908         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4788.8223   |
| evaluation/return-max          | 4905.158    |
| evaluation/return-min          | 4734.6074   |
| evaluation/return-std          | 57.00452    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 85.5        |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46561       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4788.8223   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 223.17268   |
| Q-std                          | 138.62096   |
| Q_loss                         | 94.54929    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 908         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 559         |
| times/evaluation_metrics       | 0.000712    |
| times/evaluation_paths         | 47.2        |
| times/timestep_after_hook      | 0.00385     |
| times/timestep_before_hook     | 0.00838     |
| times/train                    | 63.9        |
| timestep                       | 1000        |
| timesteps_total                | 909000      |
| train-steps                    | 909000      |
| training/Q/q1_loss             | 110.170906  |
| training/sac_pi/alpha          | 0.16341     |
| training/sac_pi/alpha_loss     | 0.093717866 |
| training/sac_pi/logp_pi        | 4.076768    |
| training/sac_pi/pi_entropy     | 3.5346215   |
| training/sac_pi/pi_global_norm | 1.9109893   |
| training/sac_pi/policy_loss    | -228.50151  |
| training/sac_pi/std            | 0.49085304  |
| training/sac_pi/valid_num      | 5028.0      |
| training/sac_Q/q1              | 218.5815    |
| training/sac_Q/q2              | 221.04233   |
| training/sac_Q/q2_loss         | 110.89116   |
| training/sac_Q/q_global_norm   | 188.83607   |
---------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.16386087    |
| epoch                          | 909           |
| evaluation/episode-length-avg  | 1e+03         |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 1000          |
| evaluation/episode-length-std  | 0             |
| evaluation/return-average      | 5130.3823     |
| evaluation/return-max          | 5215.556      |
| evaluation/return-min          | 4970.2837     |
| evaluation/return-std          | 76.70052      |
| model/max_penalty              | 7.24          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 3.18          |
| model/origin_ret               | 86.7          |
| model/penalty_ret              | 79.9          |
| model/val_loss                 | 0.40512508    |
| model/valid_num                | 46525         |
| perf/AverageLength             | 1e+03         |
| perf/AverageReturn             | 5130.3823     |
| perf/NormalizedReturn          | 1.12          |
| Q-avg                          | 221.10318     |
| Q-std                          | 172.57063     |
| Q_loss                         | 88.59684      |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 909           |
| times/epoch_after_hook         | 1.7e-06       |
| times/epoch_before_hook        | 0.000348      |
| times/epoch_rollout_model      | 522           |
| times/evaluation_metrics       | 0.000552      |
| times/evaluation_paths         | 35.7          |
| times/timestep_after_hook      | 0.00365       |
| times/timestep_before_hook     | 0.00829       |
| times/train                    | 68.9          |
| timestep                       | 1000          |
| timesteps_total                | 910000        |
| train-steps                    | 910000        |
| training/Q/q1_loss             | 89.562805     |
| training/sac_pi/alpha          | 0.16382217    |
| training/sac_pi/alpha_loss     | -0.0076950993 |
| training/sac_pi/logp_pi        | 4.4491053     |
| training/sac_pi/pi_entropy     | 3.4954429     |
| training/sac_pi/pi_global_norm | 1.770984      |
| training/sac_pi/policy_loss    | -224.5996     |
| training/sac_pi/std            | 0.5046324     |
| training/sac_pi/valid_num      | 4970.0        |
| training/sac_Q/q1              | 213.75041     |
| training/sac_Q/q2              | 215.26506     |
| training/sac_Q/q2_loss         | 91.24271      |
| training/sac_Q/q_global_norm   | 277.005       |
-----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16377515  |
| epoch                          | 910         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5074.676    |
| evaluation/return-max          | 5144.6567   |
| evaluation/return-min          | 4970.108    |
| evaluation/return-std          | 57.750576   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46505       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5074.676    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 217.51285   |
| Q-std                          | 183.2957    |
| Q_loss                         | 135.70522   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 910         |
| times/epoch_after_hook         | 8.56e-06    |
| times/epoch_before_hook        | 0.00013     |
| times/epoch_rollout_model      | 525         |
| times/evaluation_metrics       | 0.000689    |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00842     |
| times/train                    | 66.3        |
| timestep                       | 1000        |
| timesteps_total                | 911000      |
| train-steps                    | 911000      |
| training/Q/q1_loss             | 116.326965  |
| training/sac_pi/alpha          | 0.16379371  |
| training/sac_pi/alpha_loss     | 0.118362494 |
| training/sac_pi/logp_pi        | 3.9812057   |
| training/sac_pi/pi_entropy     | 3.5025895   |
| training/sac_pi/pi_global_norm | 1.7350463   |
| training/sac_pi/policy_loss    | -236.54834  |
| training/sac_pi/std            | 0.48046207  |
| training/sac_pi/valid_num      | 5021.0      |
| training/sac_Q/q1              | 228.7255    |
| training/sac_Q/q2              | 229.99854   |
| training/sac_Q/q2_loss         | 115.402596  |
| training/sac_Q/q_global_norm   | 234.25635   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16173905 |
| epoch                          | 911        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5072.4644  |
| evaluation/return-max          | 5242.126   |
| evaluation/return-min          | 4988.314   |
| evaluation/return-std          | 76.49307   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.2       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46552      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5072.4644  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 219.03352  |
| Q-std                          | 124.00444  |
| Q_loss                         | 109.80259  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 911        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000144   |
| times/epoch_rollout_model      | 514        |
| times/evaluation_metrics       | 0.000498   |
| times/evaluation_paths         | 32.4       |
| times/timestep_after_hook      | 0.00356    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 65.8       |
| timestep                       | 1000       |
| timesteps_total                | 912000     |
| train-steps                    | 912000     |
| training/Q/q1_loss             | 109.630615 |
| training/sac_pi/alpha          | 0.16175002 |
| training/sac_pi/alpha_loss     | 0.25141963 |
| training/sac_pi/logp_pi        | 4.8973503  |
| training/sac_pi/pi_entropy     | 3.183193   |
| training/sac_pi/pi_global_norm | 1.8420635  |
| training/sac_pi/policy_loss    | -216.99757 |
| training/sac_pi/std            | 0.47572967 |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 206.72224  |
| training/sac_Q/q2              | 203.54933  |
| training/sac_Q/q2_loss         | 109.99281  |
| training/sac_Q/q_global_norm   | 283.58023  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16238461   |
| epoch                          | 912          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4895.9478    |
| evaluation/return-max          | 4974.8193    |
| evaluation/return-min          | 4841.6743    |
| evaluation/return-std          | 49.724102    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.13         |
| model/origin_ret               | 85.8         |
| model/penalty_ret              | 79.5         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46574        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4895.9478    |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 220.55229    |
| Q-std                          | 169.30368    |
| Q_loss                         | 86.91324     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 912          |
| times/epoch_after_hook         | 1.75e-06     |
| times/epoch_before_hook        | 0.000109     |
| times/epoch_rollout_model      | 523          |
| times/evaluation_metrics       | 0.000558     |
| times/evaluation_paths         | 45.2         |
| times/timestep_after_hook      | 0.0036       |
| times/timestep_before_hook     | 0.00814      |
| times/train                    | 62.9         |
| timestep                       | 1000         |
| timesteps_total                | 913000       |
| train-steps                    | 913000       |
| training/Q/q1_loss             | 88.23214     |
| training/sac_pi/alpha          | 0.16238518   |
| training/sac_pi/alpha_loss     | -0.107842326 |
| training/sac_pi/logp_pi        | 3.5510268    |
| training/sac_pi/pi_entropy     | 3.527675     |
| training/sac_pi/pi_global_norm | 1.4472146    |
| training/sac_pi/policy_loss    | -236.70654   |
| training/sac_pi/std            | 0.49037015   |
| training/sac_pi/valid_num      | 4942.0       |
| training/sac_Q/q1              | 225.19756    |
| training/sac_Q/q2              | 224.89743    |
| training/sac_Q/q2_loss         | 87.42624     |
| training/sac_Q/q_global_norm   | 157.55136    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15850413  |
| epoch                          | 913         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5214.3257   |
| evaluation/return-max          | 5239.943    |
| evaluation/return-min          | 5180.501    |
| evaluation/return-std          | 21.123062   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 78.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46465       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5214.3257   |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 217.91203   |
| Q-std                          | 166.41208   |
| Q_loss                         | 85.532684   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 913         |
| times/epoch_after_hook         | 1.79e-06    |
| times/epoch_before_hook        | 0.000333    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000581    |
| times/evaluation_paths         | 35.4        |
| times/timestep_after_hook      | 0.00354     |
| times/timestep_before_hook     | 0.00815     |
| times/train                    | 67.8        |
| timestep                       | 1000        |
| timesteps_total                | 914000      |
| train-steps                    | 914000      |
| training/Q/q1_loss             | 115.025154  |
| training/sac_pi/alpha          | 0.15851857  |
| training/sac_pi/alpha_loss     | -0.19721079 |
| training/sac_pi/logp_pi        | 4.463559    |
| training/sac_pi/pi_entropy     | 3.3856614   |
| training/sac_pi/pi_global_norm | 1.4429026   |
| training/sac_pi/policy_loss    | -223.73499  |
| training/sac_pi/std            | 0.49500784  |
| training/sac_pi/valid_num      | 4977.0      |
| training/sac_Q/q1              | 211.45898   |
| training/sac_Q/q2              | 212.15385   |
| training/sac_Q/q2_loss         | 114.67992   |
| training/sac_Q/q_global_norm   | 209.12848   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16056633  |
| epoch                          | 914         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5037.116    |
| evaluation/return-max          | 5074.084    |
| evaluation/return-min          | 5014.578    |
| evaluation/return-std          | 17.7899     |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 80          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46553       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5037.116    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 225.41704   |
| Q-std                          | 118.37714   |
| Q_loss                         | 97.329094   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 914         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 521         |
| times/evaluation_metrics       | 0.000596    |
| times/evaluation_paths         | 36.5        |
| times/timestep_after_hook      | 0.00355     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 69.8        |
| timestep                       | 1000        |
| timesteps_total                | 915000      |
| train-steps                    | 915000      |
| training/Q/q1_loss             | 98.59354    |
| training/sac_pi/alpha          | 0.16057293  |
| training/sac_pi/alpha_loss     | -0.20303605 |
| training/sac_pi/logp_pi        | 4.5364866   |
| training/sac_pi/pi_entropy     | 3.3679204   |
| training/sac_pi/pi_global_norm | 1.4702225   |
| training/sac_pi/policy_loss    | -237.28014  |
| training/sac_pi/std            | 0.5082568   |
| training/sac_pi/valid_num      | 4898.0      |
| training/sac_Q/q1              | 217.06721   |
| training/sac_Q/q2              | 221.58598   |
| training/sac_Q/q2_loss         | 98.69586    |
| training/sac_Q/q_global_norm   | 367.51297   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15332927  |
| epoch                          | 915         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5003.544    |
| evaluation/return-max          | 5048.2637   |
| evaluation/return-min          | 4959.351    |
| evaluation/return-std          | 25.02074    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46575       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5003.544    |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 229.80838   |
| Q-std                          | 149.29196   |
| Q_loss                         | 76.06711    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 915         |
| times/epoch_after_hook         | 1.61e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 511         |
| times/evaluation_metrics       | 0.000483    |
| times/evaluation_paths         | 36.1        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 73.5        |
| timestep                       | 1000        |
| timesteps_total                | 916000      |
| train-steps                    | 916000      |
| training/Q/q1_loss             | 113.84742   |
| training/sac_pi/alpha          | 0.15331718  |
| training/sac_pi/alpha_loss     | -0.14822188 |
| training/sac_pi/logp_pi        | 3.981284    |
| training/sac_pi/pi_entropy     | 3.3327682   |
| training/sac_pi/pi_global_norm | 2.1489668   |
| training/sac_pi/policy_loss    | -231.86441  |
| training/sac_pi/std            | 0.4858643   |
| training/sac_pi/valid_num      | 4981.0      |
| training/sac_Q/q1              | 219.09367   |
| training/sac_Q/q2              | 218.93466   |
| training/sac_Q/q2_loss         | 114.073555  |
| training/sac_Q/q_global_norm   | 266.88403   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16597453  |
| epoch                          | 916         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4989.2163   |
| evaluation/return-max          | 5096.993    |
| evaluation/return-min          | 4910.2285   |
| evaluation/return-std          | 63.99449    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46549       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4989.2163   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 224.48921   |
| Q-std                          | 127.21885   |
| Q_loss                         | 72.33738    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 916         |
| times/epoch_after_hook         | 1.69e-06    |
| times/epoch_before_hook        | 0.000112    |
| times/epoch_rollout_model      | 513         |
| times/evaluation_metrics       | 0.000589    |
| times/evaluation_paths         | 40.8        |
| times/timestep_after_hook      | 0.0035      |
| times/timestep_before_hook     | 0.00807     |
| times/train                    | 58.4        |
| timestep                       | 1000        |
| timesteps_total                | 917000      |
| train-steps                    | 917000      |
| training/Q/q1_loss             | 101.52141   |
| training/sac_pi/alpha          | 0.1659784   |
| training/sac_pi/alpha_loss     | -0.41374362 |
| training/sac_pi/logp_pi        | 3.914817    |
| training/sac_pi/pi_entropy     | 3.6387665   |
| training/sac_pi/pi_global_norm | 1.5861331   |
| training/sac_pi/policy_loss    | -225.29407  |
| training/sac_pi/std            | 0.5075459   |
| training/sac_pi/valid_num      | 4975.0      |
| training/sac_Q/q1              | 212.4582    |
| training/sac_Q/q2              | 214.3732    |
| training/sac_Q/q2_loss         | 101.441444  |
| training/sac_Q/q_global_norm   | 184.59877   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16213098  |
| epoch                          | 917         |
| evaluation/episode-length-avg  | 833         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 165         |
| evaluation/episode-length-std  | 334         |
| evaluation/return-average      | 4106.789    |
| evaluation/return-max          | 5054.3735   |
| evaluation/return-min          | 529.3307    |
| evaluation/return-std          | 1788.6102   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86.8        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46425       |
| perf/AverageLength             | 833         |
| perf/AverageReturn             | 4106.789    |
| perf/NormalizedReturn          | 0.894       |
| Q-avg                          | 226.72778   |
| Q-std                          | 158.53056   |
| Q_loss                         | 107.471504  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 917         |
| times/epoch_after_hook         | 1.7e-06     |
| times/epoch_before_hook        | 0.000312    |
| times/epoch_rollout_model      | 525         |
| times/evaluation_metrics       | 0.000766    |
| times/evaluation_paths         | 30.8        |
| times/timestep_after_hook      | 0.0035      |
| times/timestep_before_hook     | 0.00819     |
| times/train                    | 74.6        |
| timestep                       | 1000        |
| timesteps_total                | 918000      |
| train-steps                    | 918000      |
| training/Q/q1_loss             | 103.435425  |
| training/sac_pi/alpha          | 0.16215515  |
| training/sac_pi/alpha_loss     | -0.18461768 |
| training/sac_pi/logp_pi        | 4.8049936   |
| training/sac_pi/pi_entropy     | 3.5594852   |
| training/sac_pi/pi_global_norm | 1.8490736   |
| training/sac_pi/policy_loss    | -228.97818  |
| training/sac_pi/std            | 0.5531063   |
| training/sac_pi/valid_num      | 4848.0      |
| training/sac_Q/q1              | 207.74068   |
| training/sac_Q/q2              | 211.42143   |
| training/sac_Q/q2_loss         | 102.9344    |
| training/sac_Q/q_global_norm   | 249.48686   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16500369 |
| epoch                          | 918        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4894.6074  |
| evaluation/return-max          | 5016.8887  |
| evaluation/return-min          | 4845.552   |
| evaluation/return-std          | 53.49802   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.07       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79         |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46491      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4894.6074  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 217.99002  |
| Q-std                          | 150.77292  |
| Q_loss                         | 109.461655 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 918        |
| times/epoch_after_hook         | 1.63e-06   |
| times/epoch_before_hook        | 0.00018    |
| times/epoch_rollout_model      | 525        |
| times/evaluation_metrics       | 0.000699   |
| times/evaluation_paths         | 37.2       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.0083     |
| times/train                    | 73.6       |
| timestep                       | 1000       |
| timesteps_total                | 919000     |
| train-steps                    | 919000     |
| training/Q/q1_loss             | 108.80855  |
| training/sac_pi/alpha          | 0.16497253 |
| training/sac_pi/alpha_loss     | 0.3482884  |
| training/sac_pi/logp_pi        | 4.9366317  |
| training/sac_pi/pi_entropy     | 3.4427562  |
| training/sac_pi/pi_global_norm | 1.5752351  |
| training/sac_pi/policy_loss    | -232.91931 |
| training/sac_pi/std            | 0.5082517  |
| training/sac_pi/valid_num      | 4872.0     |
| training/sac_Q/q1              | 201.01962  |
| training/sac_Q/q2              | 206.16768  |
| training/sac_Q/q2_loss         | 109.95713  |
| training/sac_Q/q_global_norm   | 247.13507  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16553582  |
| epoch                          | 919         |
| evaluation/episode-length-avg  | 927         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 266         |
| evaluation/episode-length-std  | 220         |
| evaluation/return-average      | 4798.664    |
| evaluation/return-max          | 5244.0635   |
| evaluation/return-min          | 1026.8735   |
| evaluation/return-std          | 1257.638    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46356       |
| perf/AverageLength             | 927         |
| perf/AverageReturn             | 4798.664    |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 211.89531   |
| Q-std                          | 148.84406   |
| Q_loss                         | 96.84805    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 919         |
| times/epoch_after_hook         | 1.73e-06    |
| times/epoch_before_hook        | 0.000106    |
| times/epoch_rollout_model      | 508         |
| times/evaluation_metrics       | 0.000582    |
| times/evaluation_paths         | 34.5        |
| times/timestep_after_hook      | 0.00355     |
| times/timestep_before_hook     | 0.00823     |
| times/train                    | 74.3        |
| timestep                       | 1000        |
| timesteps_total                | 920000      |
| train-steps                    | 920000      |
| training/Q/q1_loss             | 101.515495  |
| training/sac_pi/alpha          | 0.16557276  |
| training/sac_pi/alpha_loss     | -0.14431188 |
| training/sac_pi/logp_pi        | 4.211637    |
| training/sac_pi/pi_entropy     | 3.4300067   |
| training/sac_pi/pi_global_norm | 2.1541624   |
| training/sac_pi/policy_loss    | -227.48514  |
| training/sac_pi/std            | 0.48623028  |
| training/sac_pi/valid_num      | 4928.0      |
| training/sac_Q/q1              | 213.51411   |
| training/sac_Q/q2              | 213.58366   |
| training/sac_Q/q2_loss         | 102.3359    |
| training/sac_Q/q_global_norm   | 206.08875   |
---------------------------------------------------------------------------------
[WARN] 920 : sync: start
----------------------------------------------------------------------------------
| alpha                          | 0.16449788   |
| epoch                          | 920          |
| evaluation/episode-length-avg  | 917          |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 168          |
| evaluation/episode-length-std  | 250          |
| evaluation/return-average      | 4582.282     |
| evaluation/return-max          | 5084.8174    |
| evaluation/return-min          | 551.64465    |
| evaluation/return-std          | 1344.1322    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.07         |
| model/origin_ret               | 85.1         |
| model/penalty_ret              | 79.7         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46491        |
| perf/AverageLength             | 917          |
| perf/AverageReturn             | 4582.282     |
| perf/NormalizedReturn          | 0.998        |
| Q-avg                          | 214.50293    |
| Q-std                          | 165.93063    |
| Q_loss                         | 119.6432     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 920          |
| times/epoch_after_hook         | 1.77e-06     |
| times/epoch_before_hook        | 0.000102     |
| times/epoch_rollout_model      | 520          |
| times/evaluation_metrics       | 0.000564     |
| times/evaluation_paths         | 42.4         |
| times/timestep_after_hook      | 0.00366      |
| times/timestep_before_hook     | 0.00824      |
| times/train                    | 59.2         |
| timestep                       | 1000         |
| timesteps_total                | 921000       |
| train-steps                    | 921000       |
| training/Q/q1_loss             | 102.87689    |
| training/sac_pi/alpha          | 0.16446006   |
| training/sac_pi/alpha_loss     | -0.061242662 |
| training/sac_pi/logp_pi        | 4.3183165    |
| training/sac_pi/pi_entropy     | 3.4671314    |
| training/sac_pi/pi_global_norm | 1.7420343    |
| training/sac_pi/policy_loss    | -230.70795   |
| training/sac_pi/std            | 0.50567675   |
| training/sac_pi/valid_num      | 4978.0       |
| training/sac_Q/q1              | 218.58481    |
| training/sac_Q/q2              | 219.09958    |
| training/sac_Q/q2_loss         | 103.37477    |
| training/sac_Q/q_global_norm   | 181.39427    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1623929  |
| epoch                          | 921        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5098.3384  |
| evaluation/return-max          | 5172.911   |
| evaluation/return-min          | 4991.4717  |
| evaluation/return-std          | 56.978405  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 87         |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46449      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5098.3384  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 213.36743  |
| Q-std                          | 171.88889  |
| Q_loss                         | 97.80142   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 921        |
| times/epoch_after_hook         | 1.74e-06   |
| times/epoch_before_hook        | 0.000323   |
| times/epoch_rollout_model      | 521        |
| times/evaluation_metrics       | 0.000672   |
| times/evaluation_paths         | 34.3       |
| times/timestep_after_hook      | 0.00357    |
| times/timestep_before_hook     | 0.00806    |
| times/train                    | 66.3       |
| timestep                       | 1000       |
| timesteps_total                | 922000     |
| train-steps                    | 922000     |
| training/Q/q1_loss             | 104.82024  |
| training/sac_pi/alpha          | 0.16241619 |
| training/sac_pi/alpha_loss     | -0.2491991 |
| training/sac_pi/logp_pi        | 4.554677   |
| training/sac_pi/pi_entropy     | 3.4379227  |
| training/sac_pi/pi_global_norm | 1.8168803  |
| training/sac_pi/policy_loss    | -227.81023 |
| training/sac_pi/std            | 0.5117013  |
| training/sac_pi/valid_num      | 4919.0     |
| training/sac_Q/q1              | 216.83171  |
| training/sac_Q/q2              | 218.79536  |
| training/sac_Q/q2_loss         | 104.5007   |
| training/sac_Q/q_global_norm   | 259.35455  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16231395 |
| epoch                          | 922        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4892.1016  |
| evaluation/return-max          | 5004.7153  |
| evaluation/return-min          | 4851.131   |
| evaluation/return-std          | 42.791943  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46517      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4892.1016  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 222.1054   |
| Q-std                          | 129.21341  |
| Q_loss                         | 89.7975    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 922        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000165   |
| times/epoch_rollout_model      | 510        |
| times/evaluation_metrics       | 0.000598   |
| times/evaluation_paths         | 34.9       |
| times/timestep_after_hook      | 0.00354    |
| times/timestep_before_hook     | 0.008      |
| times/train                    | 65.9       |
| timestep                       | 1000       |
| timesteps_total                | 923000     |
| train-steps                    | 923000     |
| training/Q/q1_loss             | 93.58411   |
| training/sac_pi/alpha          | 0.16226186 |
| training/sac_pi/alpha_loss     | 0.28397226 |
| training/sac_pi/logp_pi        | 3.5897279  |
| training/sac_pi/pi_entropy     | 3.479962   |
| training/sac_pi/pi_global_norm | 1.6948689  |
| training/sac_pi/policy_loss    | -225.61215 |
| training/sac_pi/std            | 0.47939226 |
| training/sac_pi/valid_num      | 4955.0     |
| training/sac_Q/q1              | 213.88016  |
| training/sac_Q/q2              | 214.57182  |
| training/sac_Q/q2_loss         | 95.40094   |
| training/sac_Q/q_global_norm   | 268.5495   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1678204  |
| epoch                          | 923        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5113.3877  |
| evaluation/return-max          | 5149.6206  |
| evaluation/return-min          | 5066.201   |
| evaluation/return-std          | 22.875605  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46597      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5113.3877  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 222.8875   |
| Q-std                          | 144.10701  |
| Q_loss                         | 90.44381   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 923        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 506        |
| times/evaluation_metrics       | 0.000522   |
| times/evaluation_paths         | 34.1       |
| times/timestep_after_hook      | 0.00364    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 67.9       |
| timestep                       | 1000       |
| timesteps_total                | 924000     |
| train-steps                    | 924000     |
| training/Q/q1_loss             | 110.207306 |
| training/sac_pi/alpha          | 0.1678254  |
| training/sac_pi/alpha_loss     | 0.17639032 |
| training/sac_pi/logp_pi        | 5.0600524  |
| training/sac_pi/pi_entropy     | 3.358855   |
| training/sac_pi/pi_global_norm | 2.1419623  |
| training/sac_pi/policy_loss    | -230.55312 |
| training/sac_pi/std            | 0.5060156  |
| training/sac_pi/valid_num      | 4843.0     |
| training/sac_Q/q1              | 212.20976  |
| training/sac_Q/q2              | 211.36728  |
| training/sac_Q/q2_loss         | 110.93095  |
| training/sac_Q/q_global_norm   | 248.07611  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16498588 |
| epoch                          | 924        |
| evaluation/episode-length-avg  | 991        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 911        |
| evaluation/episode-length-std  | 26.7       |
| evaluation/return-average      | 4946.7285  |
| evaluation/return-max          | 5064.564   |
| evaluation/return-min          | 4453.253   |
| evaluation/return-std          | 168.28526  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46480      |
| perf/AverageLength             | 991        |
| perf/AverageReturn             | 4946.7285  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 223.7139   |
| Q-std                          | 145.91846  |
| Q_loss                         | 112.09324  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 924        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 505        |
| times/evaluation_metrics       | 0.000536   |
| times/evaluation_paths         | 45.4       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00819    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 925000     |
| train-steps                    | 925000     |
| training/Q/q1_loss             | 95.42027   |
| training/sac_pi/alpha          | 0.16502978 |
| training/sac_pi/alpha_loss     | 0.09420028 |
| training/sac_pi/logp_pi        | 3.7083344  |
| training/sac_pi/pi_entropy     | 3.412164   |
| training/sac_pi/pi_global_norm | 2.4642723  |
| training/sac_pi/policy_loss    | -235.13052 |
| training/sac_pi/std            | 0.47535497 |
| training/sac_pi/valid_num      | 4981.0     |
| training/sac_Q/q1              | 228.5026   |
| training/sac_Q/q2              | 228.89517  |
| training/sac_Q/q2_loss         | 95.6402    |
| training/sac_Q/q_global_norm   | 201.73114  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16563621  |
| epoch                          | 925         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4786.5986   |
| evaluation/return-max          | 4967.5547   |
| evaluation/return-min          | 4673.9565   |
| evaluation/return-std          | 98.15711    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46503       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4786.5986   |
| perf/NormalizedReturn          | 1.04        |
| Q-avg                          | 223.07832   |
| Q-std                          | 173.34123   |
| Q_loss                         | 97.81534    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 925         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000309    |
| times/epoch_rollout_model      | 505         |
| times/evaluation_metrics       | 0.000537    |
| times/evaluation_paths         | 35.1        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00826     |
| times/train                    | 68          |
| timestep                       | 1000        |
| timesteps_total                | 926000      |
| train-steps                    | 926000      |
| training/Q/q1_loss             | 88.68061    |
| training/sac_pi/alpha          | 0.16561049  |
| training/sac_pi/alpha_loss     | -0.19237375 |
| training/sac_pi/logp_pi        | 3.921173    |
| training/sac_pi/pi_entropy     | 3.3786511   |
| training/sac_pi/pi_global_norm | 2.4967027   |
| training/sac_pi/policy_loss    | -233.8796   |
| training/sac_pi/std            | 0.48483053  |
| training/sac_pi/valid_num      | 5005.0      |
| training/sac_Q/q1              | 224.5343    |
| training/sac_Q/q2              | 225.3147    |
| training/sac_Q/q2_loss         | 86.89879    |
| training/sac_Q/q_global_norm   | 247.9415    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16194212  |
| epoch                          | 926         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4971.439    |
| evaluation/return-max          | 4994.5464   |
| evaluation/return-min          | 4936.9453   |
| evaluation/return-std          | 19.53181    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.18        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 79.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46535       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4971.439    |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 224.24031   |
| Q-std                          | 134.48085   |
| Q_loss                         | 87.40408    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 926         |
| times/epoch_after_hook         | 3.06e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 499         |
| times/evaluation_metrics       | 0.00054     |
| times/evaluation_paths         | 35.9        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00804     |
| times/train                    | 67.9        |
| timestep                       | 1000        |
| timesteps_total                | 927000      |
| train-steps                    | 927000      |
| training/Q/q1_loss             | 97.737915   |
| training/sac_pi/alpha          | 0.16194794  |
| training/sac_pi/alpha_loss     | -0.16832928 |
| training/sac_pi/logp_pi        | 4.531121    |
| training/sac_pi/pi_entropy     | 3.5988777   |
| training/sac_pi/pi_global_norm | 1.3450991   |
| training/sac_pi/policy_loss    | -232.5531   |
| training/sac_pi/std            | 0.55701923  |
| training/sac_pi/valid_num      | 4897.0      |
| training/sac_Q/q1              | 214.12032   |
| training/sac_Q/q2              | 215.56772   |
| training/sac_Q/q2_loss         | 99.33333    |
| training/sac_Q/q_global_norm   | 223.5865    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1613141  |
| epoch                          | 927        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4974.197   |
| evaluation/return-max          | 5006.0757  |
| evaluation/return-min          | 4942.1934  |
| evaluation/return-std          | 20.31469   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46577      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4974.197   |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 229.99576  |
| Q-std                          | 133.89273  |
| Q_loss                         | 96.22645   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 927        |
| times/epoch_after_hook         | 3.23e-06   |
| times/epoch_before_hook        | 0.000122   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000574   |
| times/evaluation_paths         | 34.4       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 69.2       |
| timestep                       | 1000       |
| timesteps_total                | 928000     |
| train-steps                    | 928000     |
| training/Q/q1_loss             | 103.80723  |
| training/sac_pi/alpha          | 0.16134092 |
| training/sac_pi/alpha_loss     | -0.058218  |
| training/sac_pi/logp_pi        | 3.7988198  |
| training/sac_pi/pi_entropy     | 3.47778    |
| training/sac_pi/pi_global_norm | 1.5069714  |
| training/sac_pi/policy_loss    | -226.3788  |
| training/sac_pi/std            | 0.4939142  |
| training/sac_pi/valid_num      | 5039.0     |
| training/sac_Q/q1              | 219.10542  |
| training/sac_Q/q2              | 218.97417  |
| training/sac_Q/q2_loss         | 103.06858  |
| training/sac_Q/q_global_norm   | 190.24834  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.163952   |
| epoch                          | 928        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4918.2695  |
| evaluation/return-max          | 4997.923   |
| evaluation/return-min          | 4782.759   |
| evaluation/return-std          | 58.828712  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46459      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4918.2695  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 221.50693  |
| Q-std                          | 135.1583   |
| Q_loss                         | 69.82334   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 928        |
| times/epoch_after_hook         | 1.65e-06   |
| times/epoch_before_hook        | 0.000115   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000564   |
| times/evaluation_paths         | 46.8       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.00823    |
| times/train                    | 60.3       |
| timestep                       | 1000       |
| timesteps_total                | 929000     |
| train-steps                    | 929000     |
| training/Q/q1_loss             | 95.60314   |
| training/sac_pi/alpha          | 0.1639611  |
| training/sac_pi/alpha_loss     | 0.1909418  |
| training/sac_pi/logp_pi        | 4.490487   |
| training/sac_pi/pi_entropy     | 3.5744324  |
| training/sac_pi/pi_global_norm | 1.8137611  |
| training/sac_pi/policy_loss    | -230.11603 |
| training/sac_pi/std            | 0.5123471  |
| training/sac_pi/valid_num      | 4986.0     |
| training/sac_Q/q1              | 214.92514  |
| training/sac_Q/q2              | 218.64624  |
| training/sac_Q/q2_loss         | 96.18464   |
| training/sac_Q/q_global_norm   | 281.94586  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16587345  |
| epoch                          | 929         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5144.733    |
| evaluation/return-max          | 5191.699    |
| evaluation/return-min          | 5081.5186   |
| evaluation/return-std          | 40.008366   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46353       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5144.733    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 225.27756   |
| Q-std                          | 127.77184   |
| Q_loss                         | 87.85548    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 929         |
| times/epoch_after_hook         | 1.98e-06    |
| times/epoch_before_hook        | 0.000325    |
| times/epoch_rollout_model      | 508         |
| times/evaluation_metrics       | 0.000553    |
| times/evaluation_paths         | 34.6        |
| times/timestep_after_hook      | 0.00365     |
| times/timestep_before_hook     | 0.00802     |
| times/train                    | 66.3        |
| timestep                       | 1000        |
| timesteps_total                | 930000      |
| train-steps                    | 930000      |
| training/Q/q1_loss             | 90.83605    |
| training/sac_pi/alpha          | 0.16589656  |
| training/sac_pi/alpha_loss     | 0.062449638 |
| training/sac_pi/logp_pi        | 4.2153845   |
| training/sac_pi/pi_entropy     | 3.4612641   |
| training/sac_pi/pi_global_norm | 2.053624    |
| training/sac_pi/policy_loss    | -232.35947  |
| training/sac_pi/std            | 0.50253075  |
| training/sac_pi/valid_num      | 4989.0      |
| training/sac_Q/q1              | 219.46042   |
| training/sac_Q/q2              | 221.80147   |
| training/sac_Q/q2_loss         | 90.007454   |
| training/sac_Q/q_global_norm   | 166.99893   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16207309 |
| epoch                          | 930        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5092.462   |
| evaluation/return-max          | 5126.7344  |
| evaluation/return-min          | 5055.9033  |
| evaluation/return-std          | 20.24612   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46317      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5092.462   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 219.85893  |
| Q-std                          | 113.0039   |
| Q_loss                         | 109.77373  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 930        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000531   |
| times/evaluation_paths         | 37.1       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00808    |
| times/train                    | 70.9       |
| timestep                       | 1000       |
| timesteps_total                | 931000     |
| train-steps                    | 931000     |
| training/Q/q1_loss             | 111.03074  |
| training/sac_pi/alpha          | 0.1621035  |
| training/sac_pi/alpha_loss     | 0.07404116 |
| training/sac_pi/logp_pi        | 4.3531885  |
| training/sac_pi/pi_entropy     | 3.457908   |
| training/sac_pi/pi_global_norm | 1.7579138  |
| training/sac_pi/policy_loss    | -227.81274 |
| training/sac_pi/std            | 0.5054704  |
| training/sac_pi/valid_num      | 4973.0     |
| training/sac_Q/q1              | 212.38394  |
| training/sac_Q/q2              | 216.35478  |
| training/sac_Q/q2_loss         | 111.71966  |
| training/sac_Q/q_global_norm   | 192.12016  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16612369 |
| epoch                          | 931        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5154.8657  |
| evaluation/return-max          | 5262.17    |
| evaluation/return-min          | 4970.7354  |
| evaluation/return-std          | 97.83217   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46555      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5154.8657  |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 209.68205  |
| Q-std                          | 194.27858  |
| Q_loss                         | 138.66692  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 931        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000149   |
| times/epoch_rollout_model      | 487        |
| times/evaluation_metrics       | 0.000446   |
| times/evaluation_paths         | 36.2       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00818    |
| times/train                    | 72.2       |
| timestep                       | 1000       |
| timesteps_total                | 932000     |
| train-steps                    | 932000     |
| training/Q/q1_loss             | 91.00287   |
| training/sac_pi/alpha          | 0.16607502 |
| training/sac_pi/alpha_loss     | 0.14173187 |
| training/sac_pi/logp_pi        | 4.082142   |
| training/sac_pi/pi_entropy     | 3.434976   |
| training/sac_pi/pi_global_norm | 1.5732315  |
| training/sac_pi/policy_loss    | -224.32526 |
| training/sac_pi/std            | 0.4775795  |
| training/sac_pi/valid_num      | 4930.0     |
| training/sac_Q/q1              | 211.05952  |
| training/sac_Q/q2              | 212.30489  |
| training/sac_Q/q2_loss         | 90.97955   |
| training/sac_Q/q_global_norm   | 205.89352  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16111654  |
| epoch                          | 932         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5296.506    |
| evaluation/return-max          | 5330.249    |
| evaluation/return-min          | 5266.2627   |
| evaluation/return-std          | 18.562714   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.19        |
| model/origin_ret               | 87.4        |
| model/penalty_ret              | 79.7        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46478       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5296.506    |
| perf/NormalizedReturn          | 1.15        |
| Q-avg                          | 217.27335   |
| Q-std                          | 180.36552   |
| Q_loss                         | 102.46491   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 932         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 8.32e-05    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000588    |
| times/evaluation_paths         | 41.4        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00816     |
| times/train                    | 58.6        |
| timestep                       | 1000        |
| timesteps_total                | 933000      |
| train-steps                    | 933000      |
| training/Q/q1_loss             | 94.59463    |
| training/sac_pi/alpha          | 0.16108814  |
| training/sac_pi/alpha_loss     | -0.19125809 |
| training/sac_pi/logp_pi        | 4.1764584   |
| training/sac_pi/pi_entropy     | 3.4472187   |
| training/sac_pi/pi_global_norm | 1.7915114   |
| training/sac_pi/policy_loss    | -229.96695  |
| training/sac_pi/std            | 0.49884117  |
| training/sac_pi/valid_num      | 4951.0      |
| training/sac_Q/q1              | 212.32101   |
| training/sac_Q/q2              | 215.54216   |
| training/sac_Q/q2_loss         | 94.570366   |
| training/sac_Q/q_global_norm   | 200.20355   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16207248 |
| epoch                          | 933        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5078.548   |
| evaluation/return-max          | 5209.7456  |
| evaluation/return-min          | 4963.6553  |
| evaluation/return-std          | 64.05734   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46528      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5078.548   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 215.73938  |
| Q-std                          | 177.25514  |
| Q_loss                         | 103.43748  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 933        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000295   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000597   |
| times/evaluation_paths         | 37.2       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00821    |
| times/train                    | 71.7       |
| timestep                       | 1000       |
| timesteps_total                | 934000     |
| train-steps                    | 934000     |
| training/Q/q1_loss             | 98.3386    |
| training/sac_pi/alpha          | 0.16203633 |
| training/sac_pi/alpha_loss     | 0.6427443  |
| training/sac_pi/logp_pi        | 4.357196   |
| training/sac_pi/pi_entropy     | 3.5556533  |
| training/sac_pi/pi_global_norm | 1.7027587  |
| training/sac_pi/policy_loss    | -231.52216 |
| training/sac_pi/std            | 0.49800968 |
| training/sac_pi/valid_num      | 4952.0     |
| training/sac_Q/q1              | 216.43759  |
| training/sac_Q/q2              | 219.76346  |
| training/sac_Q/q2_loss         | 99.92112   |
| training/sac_Q/q_global_norm   | 195.34416  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15289566 |
| epoch                          | 934        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4836.7256  |
| evaluation/return-max          | 5040.587   |
| evaluation/return-min          | 4723.78    |
| evaluation/return-std          | 84.56511   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.17       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46552      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4836.7256  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 223.14413  |
| Q-std                          | 121.32824  |
| Q_loss                         | 95.09177   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 934        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000115   |
| times/epoch_rollout_model      | 492        |
| times/evaluation_metrics       | 0.000561   |
| times/evaluation_paths         | 38.8       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00814    |
| times/train                    | 73.2       |
| timestep                       | 1000       |
| timesteps_total                | 935000     |
| train-steps                    | 935000     |
| training/Q/q1_loss             | 104.60592  |
| training/sac_pi/alpha          | 0.15287386 |
| training/sac_pi/alpha_loss     | 0.26285827 |
| training/sac_pi/logp_pi        | 4.195326   |
| training/sac_pi/pi_entropy     | 3.2359529  |
| training/sac_pi/pi_global_norm | 1.7248135  |
| training/sac_pi/policy_loss    | -232.08746 |
| training/sac_pi/std            | 0.46930152 |
| training/sac_pi/valid_num      | 5001.0     |
| training/sac_Q/q1              | 222.12451  |
| training/sac_Q/q2              | 224.11533  |
| training/sac_Q/q2_loss         | 102.790726 |
| training/sac_Q/q_global_norm   | 186.53043  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.15619259   |
| epoch                          | 935          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5182.0186    |
| evaluation/return-max          | 5202.404     |
| evaluation/return-min          | 5163.195     |
| evaluation/return-std          | 10.586726    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.12         |
| model/origin_ret               | 85.3         |
| model/penalty_ret              | 79.3         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46675        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5182.0186    |
| perf/NormalizedReturn          | 1.13         |
| Q-avg                          | 207.95662    |
| Q-std                          | 156.44238    |
| Q_loss                         | 109.002335   |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 935          |
| times/epoch_after_hook         | 1.63e-06     |
| times/epoch_before_hook        | 0.000125     |
| times/epoch_rollout_model      | 495          |
| times/evaluation_metrics       | 0.000592     |
| times/evaluation_paths         | 36.6         |
| times/timestep_after_hook      | 0.00365      |
| times/timestep_before_hook     | 0.00809      |
| times/train                    | 72.8         |
| timestep                       | 1000         |
| timesteps_total                | 936000       |
| train-steps                    | 936000       |
| training/Q/q1_loss             | 91.70148     |
| training/sac_pi/alpha          | 0.1562144    |
| training/sac_pi/alpha_loss     | -0.015174179 |
| training/sac_pi/logp_pi        | 4.359482     |
| training/sac_pi/pi_entropy     | 3.339695     |
| training/sac_pi/pi_global_norm | 1.9817126    |
| training/sac_pi/policy_loss    | -232.19673   |
| training/sac_pi/std            | 0.50643146   |
| training/sac_pi/valid_num      | 4993.0       |
| training/sac_Q/q1              | 213.76566    |
| training/sac_Q/q2              | 218.7009     |
| training/sac_Q/q2_loss         | 90.873085    |
| training/sac_Q/q_global_norm   | 193.38544    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16069674 |
| epoch                          | 936        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4985.129   |
| evaluation/return-max          | 5163.4023  |
| evaluation/return-min          | 4817.6514  |
| evaluation/return-std          | 114.77266  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.2       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46576      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4985.129   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 219.92053  |
| Q-std                          | 139.84328  |
| Q_loss                         | 113.52646  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 936        |
| times/epoch_after_hook         | 1.65e-06   |
| times/epoch_before_hook        | 0.000113   |
| times/epoch_rollout_model      | 488        |
| times/evaluation_metrics       | 0.000509   |
| times/evaluation_paths         | 46.9       |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 60.8       |
| timestep                       | 1000       |
| timesteps_total                | 937000     |
| train-steps                    | 937000     |
| training/Q/q1_loss             | 116.70741  |
| training/sac_pi/alpha          | 0.16066441 |
| training/sac_pi/alpha_loss     | 0.34512562 |
| training/sac_pi/logp_pi        | 4.3835526  |
| training/sac_pi/pi_entropy     | 3.4242706  |
| training/sac_pi/pi_global_norm | 2.0922966  |
| training/sac_pi/policy_loss    | -237.12013 |
| training/sac_pi/std            | 0.50225234 |
| training/sac_pi/valid_num      | 4988.0     |
| training/sac_Q/q1              | 226.83566  |
| training/sac_Q/q2              | 224.37349  |
| training/sac_Q/q2_loss         | 114.994965 |
| training/sac_Q/q_global_norm   | 234.01662  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1584174  |
| epoch                          | 937        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4994.6006  |
| evaluation/return-max          | 5301.2383  |
| evaluation/return-min          | 4751.892   |
| evaluation/return-std          | 177.6842   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 78.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46466      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4994.6006  |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 215.43845  |
| Q-std                          | 210.22527  |
| Q_loss                         | 103.96627  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 937        |
| times/epoch_after_hook         | 1.69e-06   |
| times/epoch_before_hook        | 0.000327   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000627   |
| times/evaluation_paths         | 35.7       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00807    |
| times/train                    | 65         |
| timestep                       | 1000       |
| timesteps_total                | 938000     |
| train-steps                    | 938000     |
| training/Q/q1_loss             | 89.16003   |
| training/sac_pi/alpha          | 0.15842833 |
| training/sac_pi/alpha_loss     | 0.18527526 |
| training/sac_pi/logp_pi        | 4.5472136  |
| training/sac_pi/pi_entropy     | 3.4483504  |
| training/sac_pi/pi_global_norm | 1.6730568  |
| training/sac_pi/policy_loss    | -232.47849 |
| training/sac_pi/std            | 0.5253817  |
| training/sac_pi/valid_num      | 4961.0     |
| training/sac_Q/q1              | 218.78801  |
| training/sac_Q/q2              | 222.14944  |
| training/sac_Q/q2_loss         | 88.66844   |
| training/sac_Q/q_global_norm   | 207.07614  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15630908  |
| epoch                          | 938         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5272.212    |
| evaluation/return-max          | 5377.1357   |
| evaluation/return-min          | 5204.3105   |
| evaluation/return-std          | 61.356136   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46585       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5272.212    |
| perf/NormalizedReturn          | 1.15        |
| Q-avg                          | 217.59824   |
| Q-std                          | 124.15912   |
| Q_loss                         | 100.60899   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 938         |
| times/epoch_after_hook         | 1.66e-06    |
| times/epoch_before_hook        | 0.000124    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000571    |
| times/evaluation_paths         | 36.1        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 65.4        |
| timestep                       | 1000        |
| timesteps_total                | 939000      |
| train-steps                    | 939000      |
| training/Q/q1_loss             | 103.6852    |
| training/sac_pi/alpha          | 0.15632081  |
| training/sac_pi/alpha_loss     | -0.19084969 |
| training/sac_pi/logp_pi        | 4.7469664   |
| training/sac_pi/pi_entropy     | 3.3824344   |
| training/sac_pi/pi_global_norm | 1.8202274   |
| training/sac_pi/policy_loss    | -227.52567  |
| training/sac_pi/std            | 0.51766855  |
| training/sac_pi/valid_num      | 4933.0      |
| training/sac_Q/q1              | 209.54594   |
| training/sac_Q/q2              | 208.54004   |
| training/sac_Q/q2_loss         | 104.430084  |
| training/sac_Q/q_global_norm   | 232.17856   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16065928 |
| epoch                          | 939        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5110.788   |
| evaluation/return-max          | 5210.1426  |
| evaluation/return-min          | 5054.158   |
| evaluation/return-std          | 40.041595  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86         |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46476      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5110.788   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 228.56454  |
| Q-std                          | 137.78294  |
| Q_loss                         | 99.91907   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 939        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000145   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.000493   |
| times/evaluation_paths         | 33.2       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 65.5       |
| timestep                       | 1000       |
| timesteps_total                | 940000     |
| train-steps                    | 940000     |
| training/Q/q1_loss             | 93.52655   |
| training/sac_pi/alpha          | 0.16064271 |
| training/sac_pi/alpha_loss     | 0.12064883 |
| training/sac_pi/logp_pi        | 4.139596   |
| training/sac_pi/pi_entropy     | 3.4072623  |
| training/sac_pi/pi_global_norm | 1.5405108  |
| training/sac_pi/policy_loss    | -234.29378 |
| training/sac_pi/std            | 0.483901   |
| training/sac_pi/valid_num      | 4977.0     |
| training/sac_Q/q1              | 220.92676  |
| training/sac_Q/q2              | 222.51733  |
| training/sac_Q/q2_loss         | 93.548416  |
| training/sac_Q/q_global_norm   | 201.56187  |
--------------------------------------------------------------------------------
[WARN] 940 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.15747985 |
| epoch                          | 940        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4807.1006  |
| evaluation/return-max          | 4931.1494  |
| evaluation/return-min          | 4720.1436  |
| evaluation/return-std          | 62.49809   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46462      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4807.1006  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 211.58139  |
| Q-std                          | 216.04596  |
| Q_loss                         | 90.23359   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 940        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 505        |
| times/evaluation_metrics       | 0.000767   |
| times/evaluation_paths         | 45         |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.0082     |
| times/train                    | 60.4       |
| timestep                       | 1000       |
| timesteps_total                | 941000     |
| train-steps                    | 941000     |
| training/Q/q1_loss             | 101.63255  |
| training/sac_pi/alpha          | 0.15748933 |
| training/sac_pi/alpha_loss     | 0.14221346 |
| training/sac_pi/logp_pi        | 3.902232   |
| training/sac_pi/pi_entropy     | 3.2752564  |
| training/sac_pi/pi_global_norm | 1.8448535  |
| training/sac_pi/policy_loss    | -222.78621 |
| training/sac_pi/std            | 0.472776   |
| training/sac_pi/valid_num      | 4971.0     |
| training/sac_Q/q1              | 214.6208   |
| training/sac_Q/q2              | 213.32031  |
| training/sac_Q/q2_loss         | 100.56142  |
| training/sac_Q/q_global_norm   | 208.63899  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16083544 |
| epoch                          | 941        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4937.2217  |
| evaluation/return-max          | 5153.2627  |
| evaluation/return-min          | 4793.964   |
| evaluation/return-std          | 129.70969  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46561      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4937.2217  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 222.13606  |
| Q-std                          | 180.73865  |
| Q_loss                         | 99.336876  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 941        |
| times/epoch_after_hook         | 1.95e-06   |
| times/epoch_before_hook        | 0.00036    |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000797   |
| times/evaluation_paths         | 36.6       |
| times/timestep_after_hook      | 0.00358    |
| times/timestep_before_hook     | 0.00812    |
| times/train                    | 70.1       |
| timestep                       | 1000       |
| timesteps_total                | 942000     |
| train-steps                    | 942000     |
| training/Q/q1_loss             | 86.29961   |
| training/sac_pi/alpha          | 0.1608032  |
| training/sac_pi/alpha_loss     | 0.06912167 |
| training/sac_pi/logp_pi        | 4.901761   |
| training/sac_pi/pi_entropy     | 3.3732917  |
| training/sac_pi/pi_global_norm | 1.5480648  |
| training/sac_pi/policy_loss    | -228.19801 |
| training/sac_pi/std            | 0.5014366  |
| training/sac_pi/valid_num      | 4958.0     |
| training/sac_Q/q1              | 216.33826  |
| training/sac_Q/q2              | 217.47275  |
| training/sac_Q/q2_loss         | 86.98385   |
| training/sac_Q/q_global_norm   | 217.33682  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16405126 |
| epoch                          | 942        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5017.138   |
| evaluation/return-max          | 5114.962   |
| evaluation/return-min          | 4949.3096  |
| evaluation/return-std          | 46.055164  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46519      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5017.138   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 224.81656  |
| Q-std                          | 137.41658  |
| Q_loss                         | 82.330925  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 942        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000159   |
| times/epoch_rollout_model      | 496        |
| times/evaluation_metrics       | 0.000544   |
| times/evaluation_paths         | 38.9       |
| times/timestep_after_hook      | 0.00362    |
| times/timestep_before_hook     | 0.00817    |
| times/train                    | 74         |
| timestep                       | 1000       |
| timesteps_total                | 943000     |
| train-steps                    | 943000     |
| training/Q/q1_loss             | 92.10082   |
| training/sac_pi/alpha          | 0.16407119 |
| training/sac_pi/alpha_loss     | -0.4646524 |
| training/sac_pi/logp_pi        | 4.1292486  |
| training/sac_pi/pi_entropy     | 3.5725365  |
| training/sac_pi/pi_global_norm | 1.6533786  |
| training/sac_pi/policy_loss    | -234.17467 |
| training/sac_pi/std            | 0.5199394  |
| training/sac_pi/valid_num      | 4922.0     |
| training/sac_Q/q1              | 218.7666   |
| training/sac_Q/q2              | 219.89114  |
| training/sac_Q/q2_loss         | 92.664185  |
| training/sac_Q/q_global_norm   | 330.7568   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16361804   |
| epoch                          | 943          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5267.6587    |
| evaluation/return-max          | 5350.55      |
| evaluation/return-min          | 5042.56      |
| evaluation/return-std          | 85.77604     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.21         |
| model/origin_ret               | 87.4         |
| model/penalty_ret              | 79.4         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46592        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5267.6587    |
| perf/NormalizedReturn          | 1.15         |
| Q-avg                          | 234.4581     |
| Q-std                          | 96.87436     |
| Q_loss                         | 99.32262     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 943          |
| times/epoch_after_hook         | 1.68e-06     |
| times/epoch_before_hook        | 0.000123     |
| times/epoch_rollout_model      | 487          |
| times/evaluation_metrics       | 0.000556     |
| times/evaluation_paths         | 35.7         |
| times/timestep_after_hook      | 0.00359      |
| times/timestep_before_hook     | 0.00807      |
| times/train                    | 71.8         |
| timestep                       | 1000         |
| timesteps_total                | 944000       |
| train-steps                    | 944000       |
| training/Q/q1_loss             | 84.46048     |
| training/sac_pi/alpha          | 0.16362533   |
| training/sac_pi/alpha_loss     | 0.0013928991 |
| training/sac_pi/logp_pi        | 4.0187426    |
| training/sac_pi/pi_entropy     | 3.3027282    |
| training/sac_pi/pi_global_norm | 2.112183     |
| training/sac_pi/policy_loss    | -227.67209   |
| training/sac_pi/std            | 0.47334835   |
| training/sac_pi/valid_num      | 5031.0       |
| training/sac_Q/q1              | 218.92505    |
| training/sac_Q/q2              | 221.95642    |
| training/sac_Q/q2_loss         | 84.716896    |
| training/sac_Q/q_global_norm   | 198.3303     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15497108 |
| epoch                          | 944        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5082.9985  |
| evaluation/return-max          | 5132.7217  |
| evaluation/return-min          | 5038.1514  |
| evaluation/return-std          | 28.049124  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 78.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46480      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5082.9985  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 214.65872  |
| Q-std                          | 175.61067  |
| Q_loss                         | 107.579865 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 944        |
| times/epoch_after_hook         | 1.79e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000562   |
| times/evaluation_paths         | 39.6       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 945000     |
| train-steps                    | 945000     |
| training/Q/q1_loss             | 93.55786   |
| training/sac_pi/alpha          | 0.15495285 |
| training/sac_pi/alpha_loss     | 0.42223218 |
| training/sac_pi/logp_pi        | 4.2303863  |
| training/sac_pi/pi_entropy     | 3.2939541  |
| training/sac_pi/pi_global_norm | 2.2084942  |
| training/sac_pi/policy_loss    | -238.80835 |
| training/sac_pi/std            | 0.47828674 |
| training/sac_pi/valid_num      | 4972.0     |
| training/sac_Q/q1              | 229.23328  |
| training/sac_Q/q2              | 230.7551   |
| training/sac_Q/q2_loss         | 92.660995  |
| training/sac_Q/q_global_norm   | 284.7695   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15881476  |
| epoch                          | 945         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4852.5796   |
| evaluation/return-max          | 5167.2715   |
| evaluation/return-min          | 4745.3115   |
| evaluation/return-std          | 119.11558   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.12        |
| model/origin_ret               | 85.9        |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46537       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4852.5796   |
| perf/NormalizedReturn          | 1.06        |
| Q-avg                          | 216.4537    |
| Q-std                          | 158.2493    |
| Q_loss                         | 112.00995   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 945         |
| times/epoch_after_hook         | 2.21e-06    |
| times/epoch_before_hook        | 0.000313    |
| times/epoch_rollout_model      | 493         |
| times/evaluation_metrics       | 0.000861    |
| times/evaluation_paths         | 38.5        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00809     |
| times/train                    | 72.3        |
| timestep                       | 1000        |
| timesteps_total                | 946000      |
| train-steps                    | 946000      |
| training/Q/q1_loss             | 116.289314  |
| training/sac_pi/alpha          | 0.1587849   |
| training/sac_pi/alpha_loss     | 0.058323152 |
| training/sac_pi/logp_pi        | 4.4255476   |
| training/sac_pi/pi_entropy     | 3.3925755   |
| training/sac_pi/pi_global_norm | 1.8649329   |
| training/sac_pi/policy_loss    | -218.95683  |
| training/sac_pi/std            | 0.4946513   |
| training/sac_pi/valid_num      | 4998.0      |
| training/sac_Q/q1              | 206.37471   |
| training/sac_Q/q2              | 207.0719    |
| training/sac_Q/q2_loss         | 115.71229   |
| training/sac_Q/q_global_norm   | 252.01662   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1553359  |
| epoch                          | 946        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4818.3584  |
| evaluation/return-max          | 4915.619   |
| evaluation/return-min          | 4669.5615  |
| evaluation/return-std          | 68.64073   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46419      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4818.3584  |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 219.6585   |
| Q-std                          | 130.46994  |
| Q_loss                         | 81.33932   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 946        |
| times/epoch_after_hook         | 1.78e-06   |
| times/epoch_before_hook        | 0.000121   |
| times/epoch_rollout_model      | 500        |
| times/evaluation_metrics       | 0.000625   |
| times/evaluation_paths         | 37.7       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00826    |
| times/train                    | 73.7       |
| timestep                       | 1000       |
| timesteps_total                | 947000     |
| train-steps                    | 947000     |
| training/Q/q1_loss             | 111.90461  |
| training/sac_pi/alpha          | 0.15530165 |
| training/sac_pi/alpha_loss     | 0.27527377 |
| training/sac_pi/logp_pi        | 4.0834756  |
| training/sac_pi/pi_entropy     | 3.3769257  |
| training/sac_pi/pi_global_norm | 2.19438    |
| training/sac_pi/policy_loss    | -228.50708 |
| training/sac_pi/std            | 0.48433483 |
| training/sac_pi/valid_num      | 5017.0     |
| training/sac_Q/q1              | 221.73764  |
| training/sac_Q/q2              | 222.6      |
| training/sac_Q/q2_loss         | 111.08461  |
| training/sac_Q/q_global_norm   | 233.93436  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16269606  |
| epoch                          | 947         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5037.579    |
| evaluation/return-max          | 5118.732    |
| evaluation/return-min          | 4972.4287   |
| evaluation/return-std          | 47.675526   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 84.7        |
| model/penalty_ret              | 79.9        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46592       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5037.579    |
| perf/NormalizedReturn          | 1.1         |
| Q-avg                          | 229.55399   |
| Q-std                          | 106.16124   |
| Q_loss                         | 93.28205    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 947         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000144    |
| times/epoch_rollout_model      | 511         |
| times/evaluation_metrics       | 0.000499    |
| times/evaluation_paths         | 36.7        |
| times/timestep_after_hook      | 0.0037      |
| times/timestep_before_hook     | 0.0083      |
| times/train                    | 73.8        |
| timestep                       | 1000        |
| timesteps_total                | 948000      |
| train-steps                    | 948000      |
| training/Q/q1_loss             | 82.91358    |
| training/sac_pi/alpha          | 0.16270289  |
| training/sac_pi/alpha_loss     | 0.043896176 |
| training/sac_pi/logp_pi        | 3.8941808   |
| training/sac_pi/pi_entropy     | 3.4789524   |
| training/sac_pi/pi_global_norm | 2.6572533   |
| training/sac_pi/policy_loss    | -230.23895  |
| training/sac_pi/std            | 0.48477998  |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 216.23177   |
| training/sac_Q/q2              | 218.38452   |
| training/sac_Q/q2_loss         | 84.781975   |
| training/sac_Q/q_global_norm   | 229.11174   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16441634 |
| epoch                          | 948        |
| evaluation/episode-length-avg  | 944        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 682        |
| evaluation/episode-length-std  | 109        |
| evaluation/return-average      | 4568.6494  |
| evaluation/return-max          | 4903.826   |
| evaluation/return-min          | 3217.7942  |
| evaluation/return-std          | 546.0999   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.5       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46361      |
| perf/AverageLength             | 944        |
| perf/AverageReturn             | 4568.6494  |
| perf/NormalizedReturn          | 0.995      |
| Q-avg                          | 226.47983  |
| Q-std                          | 130.05043  |
| Q_loss                         | 87.66194   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 948        |
| times/epoch_after_hook         | 1.61e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 497        |
| times/evaluation_metrics       | 0.00062    |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00816    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 949000     |
| train-steps                    | 949000     |
| training/Q/q1_loss             | 112.41732  |
| training/sac_pi/alpha          | 0.16439044 |
| training/sac_pi/alpha_loss     | 0.1948517  |
| training/sac_pi/logp_pi        | 3.8343291  |
| training/sac_pi/pi_entropy     | 3.7801297  |
| training/sac_pi/pi_global_norm | 1.6810738  |
| training/sac_pi/policy_loss    | -222.81216 |
| training/sac_pi/std            | 0.51416904 |
| training/sac_pi/valid_num      | 5021.0     |
| training/sac_Q/q1              | 214.71587  |
| training/sac_Q/q2              | 215.6897   |
| training/sac_Q/q2_loss         | 111.87951  |
| training/sac_Q/q_global_norm   | 219.33846  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15887554 |
| epoch                          | 949        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5005.582   |
| evaluation/return-max          | 5087.87    |
| evaluation/return-min          | 4864.877   |
| evaluation/return-std          | 67.70337   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.16       |
| model/origin_ret               | 87         |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46479      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5005.582   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 213.63693  |
| Q-std                          | 190.81133  |
| Q_loss                         | 105.45124  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 949        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000349   |
| times/epoch_rollout_model      | 509        |
| times/evaluation_metrics       | 0.000487   |
| times/evaluation_paths         | 38.1       |
| times/timestep_after_hook      | 0.00361    |
| times/timestep_before_hook     | 0.0117     |
| times/train                    | 74.9       |
| timestep                       | 1000       |
| timesteps_total                | 950000     |
| train-steps                    | 950000     |
| training/Q/q1_loss             | 106.71774  |
| training/sac_pi/alpha          | 0.15886718 |
| training/sac_pi/alpha_loss     | 0.39723796 |
| training/sac_pi/logp_pi        | 4.2964253  |
| training/sac_pi/pi_entropy     | 3.5324044  |
| training/sac_pi/pi_global_norm | 1.5896788  |
| training/sac_pi/policy_loss    | -228.54234 |
| training/sac_pi/std            | 0.5043039  |
| training/sac_pi/valid_num      | 4941.0     |
| training/sac_Q/q1              | 215.26314  |
| training/sac_Q/q2              | 215.92374  |
| training/sac_Q/q2_loss         | 106.8992   |
| training/sac_Q/q_global_norm   | 339.45908  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15975931  |
| epoch                          | 950         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5088.998    |
| evaluation/return-max          | 5128.402    |
| evaluation/return-min          | 5043.2705   |
| evaluation/return-std          | 28.000149   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46492       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5088.998    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 222.08005   |
| Q-std                          | 171.45615   |
| Q_loss                         | 83.84274    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 950         |
| times/epoch_after_hook         | 2.17e-06    |
| times/epoch_before_hook        | 0.000105    |
| times/epoch_rollout_model      | 512         |
| times/evaluation_metrics       | 0.000535    |
| times/evaluation_paths         | 37.6        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00808     |
| times/train                    | 74.7        |
| timestep                       | 1000        |
| timesteps_total                | 951000      |
| train-steps                    | 951000      |
| training/Q/q1_loss             | 97.48691    |
| training/sac_pi/alpha          | 0.15979378  |
| training/sac_pi/alpha_loss     | -0.24333088 |
| training/sac_pi/logp_pi        | 3.8208575   |
| training/sac_pi/pi_entropy     | 3.453589    |
| training/sac_pi/pi_global_norm | 1.5753425   |
| training/sac_pi/policy_loss    | -232.5385   |
| training/sac_pi/std            | 0.49159274  |
| training/sac_pi/valid_num      | 4975.0      |
| training/sac_Q/q1              | 219.95609   |
| training/sac_Q/q2              | 221.56845   |
| training/sac_Q/q2_loss         | 96.611435   |
| training/sac_Q/q_global_norm   | 203.43224   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16259705  |
| epoch                          | 951         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5188.828    |
| evaluation/return-max          | 5297.1045   |
| evaluation/return-min          | 5134.378    |
| evaluation/return-std          | 43.764187   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 85          |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46387       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5188.828    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 214.16507   |
| Q-std                          | 166.8822    |
| Q_loss                         | 100.656845  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 951         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 508         |
| times/evaluation_metrics       | 0.000778    |
| times/evaluation_paths         | 37.2        |
| times/timestep_after_hook      | 0.00369     |
| times/timestep_before_hook     | 0.00825     |
| times/train                    | 73.6        |
| timestep                       | 1000        |
| timesteps_total                | 952000      |
| train-steps                    | 952000      |
| training/Q/q1_loss             | 117.34468   |
| training/sac_pi/alpha          | 0.16257925  |
| training/sac_pi/alpha_loss     | 0.060570445 |
| training/sac_pi/logp_pi        | 4.3680773   |
| training/sac_pi/pi_entropy     | 3.6381614   |
| training/sac_pi/pi_global_norm | 1.848861    |
| training/sac_pi/policy_loss    | -228.02225  |
| training/sac_pi/std            | 0.52585006  |
| training/sac_pi/valid_num      | 4956.0      |
| training/sac_Q/q1              | 212.73941   |
| training/sac_Q/q2              | 214.27798   |
| training/sac_Q/q2_loss         | 117.22006   |
| training/sac_Q/q_global_norm   | 304.15692   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16383345 |
| epoch                          | 952        |
| evaluation/episode-length-avg  | 990        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 900        |
| evaluation/episode-length-std  | 30         |
| evaluation/return-average      | 5083.903   |
| evaluation/return-max          | 5219.826   |
| evaluation/return-min          | 4498.755   |
| evaluation/return-std          | 198.77216  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.17       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 78.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46613      |
| perf/AverageLength             | 990        |
| perf/AverageReturn             | 5083.903   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 215.19067  |
| Q-std                          | 144.87189  |
| Q_loss                         | 101.66865  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 952        |
| times/epoch_after_hook         | 1.55e-06   |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 493        |
| times/evaluation_metrics       | 0.000566   |
| times/evaluation_paths         | 43.4       |
| times/timestep_after_hook      | 0.00355    |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 59.3       |
| timestep                       | 1000       |
| timesteps_total                | 953000     |
| train-steps                    | 953000     |
| training/Q/q1_loss             | 105.11954  |
| training/sac_pi/alpha          | 0.16385163 |
| training/sac_pi/alpha_loss     | 0.11833779 |
| training/sac_pi/logp_pi        | 3.867482   |
| training/sac_pi/pi_entropy     | 3.4361215  |
| training/sac_pi/pi_global_norm | 1.886752   |
| training/sac_pi/policy_loss    | -223.37042 |
| training/sac_pi/std            | 0.4794873  |
| training/sac_pi/valid_num      | 4998.0     |
| training/sac_Q/q1              | 215.27548  |
| training/sac_Q/q2              | 215.57748  |
| training/sac_Q/q2_loss         | 106.19407  |
| training/sac_Q/q_global_norm   | 225.7201   |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16166745 |
| epoch                          | 953        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5212.2217  |
| evaluation/return-max          | 5315.0625  |
| evaluation/return-min          | 5161.9844  |
| evaluation/return-std          | 42.52672   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46434      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5212.2217  |
| perf/NormalizedReturn          | 1.14       |
| Q-avg                          | 212.39938  |
| Q-std                          | 188.49428  |
| Q_loss                         | 101.472626 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 953        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000274   |
| times/epoch_rollout_model      | 490        |
| times/evaluation_metrics       | 0.000556   |
| times/evaluation_paths         | 40.2       |
| times/timestep_after_hook      | 0.00355    |
| times/timestep_before_hook     | 0.00834    |
| times/train                    | 73.7       |
| timestep                       | 1000       |
| timesteps_total                | 954000     |
| train-steps                    | 954000     |
| training/Q/q1_loss             | 128.01976  |
| training/sac_pi/alpha          | 0.1616601  |
| training/sac_pi/alpha_loss     | 0.18771897 |
| training/sac_pi/logp_pi        | 4.7639694  |
| training/sac_pi/pi_entropy     | 3.5128326  |
| training/sac_pi/pi_global_norm | 1.5182467  |
| training/sac_pi/policy_loss    | -230.2638  |
| training/sac_pi/std            | 0.5243471  |
| training/sac_pi/valid_num      | 4948.0     |
| training/sac_Q/q1              | 216.21172  |
| training/sac_Q/q2              | 218.11899  |
| training/sac_Q/q2_loss         | 128.19917  |
| training/sac_Q/q_global_norm   | 250.16942  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.17112277  |
| epoch                          | 954         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5147.0874   |
| evaluation/return-max          | 5273.2266   |
| evaluation/return-min          | 5022.9204   |
| evaluation/return-std          | 69.26557    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46425       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5147.0874   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 224.04648   |
| Q-std                          | 153.41849   |
| Q_loss                         | 86.40684    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 954         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 491         |
| times/evaluation_metrics       | 0.000653    |
| times/evaluation_paths         | 37.4        |
| times/timestep_after_hook      | 0.00361     |
| times/timestep_before_hook     | 0.00827     |
| times/train                    | 75.1        |
| timestep                       | 1000        |
| timesteps_total                | 955000      |
| train-steps                    | 955000      |
| training/Q/q1_loss             | 88.87298    |
| training/sac_pi/alpha          | 0.1711471   |
| training/sac_pi/alpha_loss     | -0.42424724 |
| training/sac_pi/logp_pi        | 3.9465008   |
| training/sac_pi/pi_entropy     | 3.6137676   |
| training/sac_pi/pi_global_norm | 1.7562917   |
| training/sac_pi/policy_loss    | -232.89223  |
| training/sac_pi/std            | 0.5144619   |
| training/sac_pi/valid_num      | 5016.0      |
| training/sac_Q/q1              | 222.39853   |
| training/sac_Q/q2              | 224.21333   |
| training/sac_Q/q2_loss         | 88.877365   |
| training/sac_Q/q_global_norm   | 185.73828   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16701826 |
| epoch                          | 955        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5109.3374  |
| evaluation/return-max          | 5171.6606  |
| evaluation/return-min          | 5048.4883  |
| evaluation/return-std          | 29.019999  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 78.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46346      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5109.3374  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 216.42197  |
| Q-std                          | 197.79094  |
| Q_loss                         | 89.28629   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 955        |
| times/epoch_after_hook         | 1.7e-06    |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 517        |
| times/evaluation_metrics       | 0.000537   |
| times/evaluation_paths         | 38         |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00833    |
| times/train                    | 74.7       |
| timestep                       | 1000       |
| timesteps_total                | 956000     |
| train-steps                    | 956000     |
| training/Q/q1_loss             | 74.25206   |
| training/sac_pi/alpha          | 0.16702212 |
| training/sac_pi/alpha_loss     | 0.15870902 |
| training/sac_pi/logp_pi        | 4.2258444  |
| training/sac_pi/pi_entropy     | 3.3808467  |
| training/sac_pi/pi_global_norm | 1.6661536  |
| training/sac_pi/policy_loss    | -229.61899 |
| training/sac_pi/std            | 0.47409132 |
| training/sac_pi/valid_num      | 4949.0     |
| training/sac_Q/q1              | 215.54276  |
| training/sac_Q/q2              | 215.86533  |
| training/sac_Q/q2_loss         | 73.956276  |
| training/sac_Q/q_global_norm   | 192.08679  |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16147506   |
| epoch                          | 956          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 4911.513     |
| evaluation/return-max          | 4944.6104    |
| evaluation/return-min          | 4865.5176    |
| evaluation/return-std          | 28.166248    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.13         |
| model/origin_ret               | 86           |
| model/penalty_ret              | 79           |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46536        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 4911.513     |
| perf/NormalizedReturn          | 1.07         |
| Q-avg                          | 213.05388    |
| Q-std                          | 138.24205    |
| Q_loss                         | 88.93228     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 956          |
| times/epoch_after_hook         | 2e-06        |
| times/epoch_before_hook        | 8.77e-05     |
| times/epoch_rollout_model      | 498          |
| times/evaluation_metrics       | 0.000582     |
| times/evaluation_paths         | 35.9         |
| times/timestep_after_hook      | 0.00357      |
| times/timestep_before_hook     | 0.00815      |
| times/train                    | 58.7         |
| timestep                       | 1000         |
| timesteps_total                | 957000       |
| train-steps                    | 957000       |
| training/Q/q1_loss             | 105.203156   |
| training/sac_pi/alpha          | 0.16148897   |
| training/sac_pi/alpha_loss     | 0.0053392807 |
| training/sac_pi/logp_pi        | 4.109055     |
| training/sac_pi/pi_entropy     | 3.3165913    |
| training/sac_pi/pi_global_norm | 1.8117183    |
| training/sac_pi/policy_loss    | -239.60724   |
| training/sac_pi/std            | 0.4743525    |
| training/sac_pi/valid_num      | 4982.0       |
| training/sac_Q/q1              | 228.43803    |
| training/sac_Q/q2              | 227.87875    |
| training/sac_Q/q2_loss         | 105.674416   |
| training/sac_Q/q_global_norm   | 209.69894    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16720566  |
| epoch                          | 957         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5091.8047   |
| evaluation/return-max          | 5115.064    |
| evaluation/return-min          | 5073.6445   |
| evaluation/return-std          | 11.0509405  |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.09        |
| model/origin_ret               | 85.3        |
| model/penalty_ret              | 78.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46586       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5091.8047   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 215.9644    |
| Q-std                          | 124.235855  |
| Q_loss                         | 90.52858    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 957         |
| times/epoch_after_hook         | 1.75e-06    |
| times/epoch_before_hook        | 0.000263    |
| times/epoch_rollout_model      | 501         |
| times/evaluation_metrics       | 0.000504    |
| times/evaluation_paths         | 41.8        |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00821     |
| times/train                    | 66          |
| timestep                       | 1000        |
| timesteps_total                | 958000      |
| train-steps                    | 958000      |
| training/Q/q1_loss             | 85.71478    |
| training/sac_pi/alpha          | 0.16716869  |
| training/sac_pi/alpha_loss     | -0.05444781 |
| training/sac_pi/logp_pi        | 5.2059455   |
| training/sac_pi/pi_entropy     | 3.6232746   |
| training/sac_pi/pi_global_norm | 1.8426915   |
| training/sac_pi/policy_loss    | -233.12968  |
| training/sac_pi/std            | 0.55735     |
| training/sac_pi/valid_num      | 4937.0      |
| training/sac_Q/q1              | 213.58585   |
| training/sac_Q/q2              | 212.3146    |
| training/sac_Q/q2_loss         | 85.52031    |
| training/sac_Q/q_global_norm   | 208.53616   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1657803  |
| epoch                          | 958        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4916.7603  |
| evaluation/return-max          | 4989.051   |
| evaluation/return-min          | 4815.4624  |
| evaluation/return-std          | 45.245667  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 78.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46414      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4916.7603  |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 216.49529  |
| Q-std                          | 189.2203   |
| Q_loss                         | 92.963684  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 958        |
| times/epoch_after_hook         | 3.2e-06    |
| times/epoch_before_hook        | 0.000115   |
| times/epoch_rollout_model      | 516        |
| times/evaluation_metrics       | 0.00059    |
| times/evaluation_paths         | 41.4       |
| times/timestep_after_hook      | 0.00366    |
| times/timestep_before_hook     | 0.0084     |
| times/train                    | 68.5       |
| timestep                       | 1000       |
| timesteps_total                | 959000     |
| train-steps                    | 959000     |
| training/Q/q1_loss             | 88.73241   |
| training/sac_pi/alpha          | 0.16574174 |
| training/sac_pi/alpha_loss     | 0.2549587  |
| training/sac_pi/logp_pi        | 3.8887508  |
| training/sac_pi/pi_entropy     | 3.4171128  |
| training/sac_pi/pi_global_norm | 1.6543483  |
| training/sac_pi/policy_loss    | -232.11174 |
| training/sac_pi/std            | 0.47355258 |
| training/sac_pi/valid_num      | 5036.0     |
| training/sac_Q/q1              | 224.88766  |
| training/sac_Q/q2              | 225.59277  |
| training/sac_Q/q2_loss         | 89.24649   |
| training/sac_Q/q_global_norm   | 258.58173  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16301398 |
| epoch                          | 959        |
| evaluation/episode-length-avg  | 981        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 808        |
| evaluation/episode-length-std  | 57.6       |
| evaluation/return-average      | 4673.7456  |
| evaluation/return-max          | 4966.996   |
| evaluation/return-min          | 3622.8672  |
| evaluation/return-std          | 360.5334   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.9       |
| model/penalty_ret              | 79.8       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46310      |
| perf/AverageLength             | 981        |
| perf/AverageReturn             | 4673.7456  |
| perf/NormalizedReturn          | 1.02       |
| Q-avg                          | 213.19919  |
| Q-std                          | 113.464806 |
| Q_loss                         | 85.1543    |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 959        |
| times/epoch_after_hook         | 1.75e-06   |
| times/epoch_before_hook        | 0.000118   |
| times/epoch_rollout_model      | 511        |
| times/evaluation_metrics       | 0.00048    |
| times/evaluation_paths         | 39         |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00829    |
| times/train                    | 69         |
| timestep                       | 1000       |
| timesteps_total                | 960000     |
| train-steps                    | 960000     |
| training/Q/q1_loss             | 95.1051    |
| training/sac_pi/alpha          | 0.16299996 |
| training/sac_pi/alpha_loss     | 0.29104242 |
| training/sac_pi/logp_pi        | 4.2052794  |
| training/sac_pi/pi_entropy     | 3.2148316  |
| training/sac_pi/pi_global_norm | 2.1616104  |
| training/sac_pi/policy_loss    | -225.70679 |
| training/sac_pi/std            | 0.4588773  |
| training/sac_pi/valid_num      | 5033.0     |
| training/sac_Q/q1              | 215.52905  |
| training/sac_Q/q2              | 215.29106  |
| training/sac_Q/q2_loss         | 94.79344   |
| training/sac_Q/q_global_norm   | 274.43646  |
--------------------------------------------------------------------------------
[WARN] 960 : sync: start
--------------------------------------------------------------------------------
| alpha                          | 0.16111465 |
| epoch                          | 960        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5107.302   |
| evaluation/return-max          | 5173.153   |
| evaluation/return-min          | 5006.165   |
| evaluation/return-std          | 56.13384   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.4       |
| model/penalty_ret              | 78.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46474      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5107.302   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 207.39705  |
| Q-std                          | 263.444    |
| Q_loss                         | 100.605225 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 960        |
| times/epoch_after_hook         | 1.62e-06   |
| times/epoch_before_hook        | 0.000123   |
| times/epoch_rollout_model      | 519        |
| times/evaluation_metrics       | 0.000501   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00365    |
| times/timestep_before_hook     | 0.00822    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 961000     |
| train-steps                    | 961000     |
| training/Q/q1_loss             | 82.20677   |
| training/sac_pi/alpha          | 0.16111651 |
| training/sac_pi/alpha_loss     | 0.05826012 |
| training/sac_pi/logp_pi        | 3.7214806  |
| training/sac_pi/pi_entropy     | 3.4710205  |
| training/sac_pi/pi_global_norm | 1.6818287  |
| training/sac_pi/policy_loss    | -225.00723 |
| training/sac_pi/std            | 0.4698676  |
| training/sac_pi/valid_num      | 4982.0     |
| training/sac_Q/q1              | 217.61624  |
| training/sac_Q/q2              | 215.84375  |
| training/sac_Q/q2_loss         | 82.68512   |
| training/sac_Q/q_global_norm   | 240.5621   |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16073556  |
| epoch                          | 961         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5103.0093   |
| evaluation/return-max          | 5123.273    |
| evaluation/return-min          | 5036.925    |
| evaluation/return-std          | 24.621729   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46497       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5103.0093   |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 221.75797   |
| Q-std                          | 180.44827   |
| Q_loss                         | 107.72865   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 961         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000322    |
| times/epoch_rollout_model      | 520         |
| times/evaluation_metrics       | 0.000759    |
| times/evaluation_paths         | 36.8        |
| times/timestep_after_hook      | 0.00359     |
| times/timestep_before_hook     | 0.00813     |
| times/train                    | 68.9        |
| timestep                       | 1000        |
| timesteps_total                | 962000      |
| train-steps                    | 962000      |
| training/Q/q1_loss             | 73.39093    |
| training/sac_pi/alpha          | 0.16070691  |
| training/sac_pi/alpha_loss     | 0.021367462 |
| training/sac_pi/logp_pi        | 4.1270037   |
| training/sac_pi/pi_entropy     | 3.3115692   |
| training/sac_pi/pi_global_norm | 2.0204215   |
| training/sac_pi/policy_loss    | -232.1736   |
| training/sac_pi/std            | 0.4747118   |
| training/sac_pi/valid_num      | 4943.0      |
| training/sac_Q/q1              | 215.58452   |
| training/sac_Q/q2              | 219.05869   |
| training/sac_Q/q2_loss         | 74.232864   |
| training/sac_Q/q_global_norm   | 300.71536   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15856695  |
| epoch                          | 962         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4970.4053   |
| evaluation/return-max          | 5292.659    |
| evaluation/return-min          | 4733.182    |
| evaluation/return-std          | 170.2956    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.7        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46575       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4970.4053   |
| perf/NormalizedReturn          | 1.08        |
| Q-avg                          | 212.32913   |
| Q-std                          | 213.80806   |
| Q_loss                         | 90.1152     |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 962         |
| times/epoch_after_hook         | 1.71e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 530         |
| times/evaluation_metrics       | 0.00051     |
| times/evaluation_paths         | 33.9        |
| times/timestep_after_hook      | 0.00363     |
| times/timestep_before_hook     | 0.00818     |
| times/train                    | 59.9        |
| timestep                       | 1000        |
| timesteps_total                | 963000      |
| train-steps                    | 963000      |
| training/Q/q1_loss             | 83.51878    |
| training/sac_pi/alpha          | 0.15858336  |
| training/sac_pi/alpha_loss     | -0.58444345 |
| training/sac_pi/logp_pi        | 3.46204     |
| training/sac_pi/pi_entropy     | 3.3512235   |
| training/sac_pi/pi_global_norm | 1.8518147   |
| training/sac_pi/policy_loss    | -232.73123  |
| training/sac_pi/std            | 0.4684325   |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 225.6545    |
| training/sac_Q/q2              | 225.66191   |
| training/sac_Q/q2_loss         | 83.8132     |
| training/sac_Q/q_global_norm   | 213.67657   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16179478  |
| epoch                          | 963         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5099.505    |
| evaluation/return-max          | 5254.871    |
| evaluation/return-min          | 4996.301    |
| evaluation/return-std          | 85.0611     |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.17        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46479       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5099.505    |
| perf/NormalizedReturn          | 1.11        |
| Q-avg                          | 218.64304   |
| Q-std                          | 142.96893   |
| Q_loss                         | 127.2457    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 963         |
| times/epoch_after_hook         | 1.63e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 527         |
| times/evaluation_metrics       | 0.000534    |
| times/evaluation_paths         | 37.4        |
| times/timestep_after_hook      | 0.00358     |
| times/timestep_before_hook     | 0.00811     |
| times/train                    | 58.6        |
| timestep                       | 1000        |
| timesteps_total                | 964000      |
| train-steps                    | 964000      |
| training/Q/q1_loss             | 96.628075   |
| training/sac_pi/alpha          | 0.16177425  |
| training/sac_pi/alpha_loss     | 0.080137014 |
| training/sac_pi/logp_pi        | 4.2454095   |
| training/sac_pi/pi_entropy     | 3.5432403   |
| training/sac_pi/pi_global_norm | 1.9697134   |
| training/sac_pi/policy_loss    | -233.72488  |
| training/sac_pi/std            | 0.49707642  |
| training/sac_pi/valid_num      | 4983.0      |
| training/sac_Q/q1              | 222.93526   |
| training/sac_Q/q2              | 223.24556   |
| training/sac_Q/q2_loss         | 97.0325     |
| training/sac_Q/q_global_norm   | 190.8853    |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16137315 |
| epoch                          | 964        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4853.4766  |
| evaluation/return-max          | 4927.5156  |
| evaluation/return-min          | 4689.884   |
| evaluation/return-std          | 69.717636  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.9       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46394      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4853.4766  |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 214.76074  |
| Q-std                          | 214.44298  |
| Q_loss                         | 83.58699   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 964        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 527        |
| times/evaluation_metrics       | 0.000796   |
| times/evaluation_paths         | 36         |
| times/timestep_after_hook      | 0.00404    |
| times/timestep_before_hook     | 0.00889    |
| times/train                    | 65.4       |
| timestep                       | 1000       |
| timesteps_total                | 965000     |
| train-steps                    | 965000     |
| training/Q/q1_loss             | 85.95723   |
| training/sac_pi/alpha          | 0.1613332  |
| training/sac_pi/alpha_loss     | 0.05078391 |
| training/sac_pi/logp_pi        | 3.8349159  |
| training/sac_pi/pi_entropy     | 3.3939595  |
| training/sac_pi/pi_global_norm | 1.7574879  |
| training/sac_pi/policy_loss    | -238.01999 |
| training/sac_pi/std            | 0.48602146 |
| training/sac_pi/valid_num      | 5002.0     |
| training/sac_Q/q1              | 231.27812  |
| training/sac_Q/q2              | 233.60855  |
| training/sac_Q/q2_loss         | 86.29806   |
| training/sac_Q/q_global_norm   | 219.99324  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16212246  |
| epoch                          | 965         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4826.8447   |
| evaluation/return-max          | 4918.3564   |
| evaluation/return-min          | 4740.4756   |
| evaluation/return-std          | 49.29592    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.14        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46551       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4826.8447   |
| perf/NormalizedReturn          | 1.05        |
| Q-avg                          | 218.35757   |
| Q-std                          | 121.94644   |
| Q_loss                         | 110.405235  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 965         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000385    |
| times/epoch_rollout_model      | 494         |
| times/evaluation_metrics       | 0.000627    |
| times/evaluation_paths         | 35.3        |
| times/timestep_after_hook      | 0.00376     |
| times/timestep_before_hook     | 0.00856     |
| times/train                    | 65          |
| timestep                       | 1000        |
| timesteps_total                | 966000      |
| train-steps                    | 966000      |
| training/Q/q1_loss             | 103.72549   |
| training/sac_pi/alpha          | 0.16210185  |
| training/sac_pi/alpha_loss     | 0.011081878 |
| training/sac_pi/logp_pi        | 3.4474647   |
| training/sac_pi/pi_entropy     | 3.5858269   |
| training/sac_pi/pi_global_norm | 1.5760081   |
| training/sac_pi/policy_loss    | -226.80627  |
| training/sac_pi/std            | 0.48073828  |
| training/sac_pi/valid_num      | 5024.0      |
| training/sac_Q/q1              | 220.10735   |
| training/sac_Q/q2              | 220.46445   |
| training/sac_Q/q2_loss         | 103.37993   |
| training/sac_Q/q_global_norm   | 215.3074    |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16218844   |
| epoch                          | 966          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5005.115     |
| evaluation/return-max          | 5091.384     |
| evaluation/return-min          | 4939.2217    |
| evaluation/return-std          | 41.88579     |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.07         |
| model/origin_ret               | 85.1         |
| model/penalty_ret              | 78.8         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46412        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5005.115     |
| perf/NormalizedReturn          | 1.09         |
| Q-avg                          | 218.72522    |
| Q-std                          | 119.126335   |
| Q_loss                         | 94.29304     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 966          |
| times/epoch_after_hook         | 3.03e-06     |
| times/epoch_before_hook        | 0.000145     |
| times/epoch_rollout_model      | 504          |
| times/evaluation_metrics       | 0.000637     |
| times/evaluation_paths         | 35.3         |
| times/timestep_after_hook      | 0.00362      |
| times/timestep_before_hook     | 0.00839      |
| times/train                    | 63           |
| timestep                       | 1000         |
| timesteps_total                | 967000       |
| train-steps                    | 967000       |
| training/Q/q1_loss             | 113.325134   |
| training/sac_pi/alpha          | 0.16216043   |
| training/sac_pi/alpha_loss     | -0.031047639 |
| training/sac_pi/logp_pi        | 4.685827     |
| training/sac_pi/pi_entropy     | 3.3884017    |
| training/sac_pi/pi_global_norm | 1.6433342    |
| training/sac_pi/policy_loss    | -234.5819    |
| training/sac_pi/std            | 0.5201815    |
| training/sac_pi/valid_num      | 4973.0       |
| training/sac_Q/q1              | 217.63896    |
| training/sac_Q/q2              | 217.89717    |
| training/sac_Q/q2_loss         | 114.15463    |
| training/sac_Q/q_global_norm   | 215.9082     |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16167042 |
| epoch                          | 967        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4856.914   |
| evaluation/return-max          | 4990.4736  |
| evaluation/return-min          | 4727.6855  |
| evaluation/return-std          | 88.833244  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85.1       |
| model/penalty_ret              | 79.2       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46474      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4856.914   |
| perf/NormalizedReturn          | 1.06       |
| Q-avg                          | 201.86667  |
| Q-std                          | 155.68974  |
| Q_loss                         | 122.63905  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 967        |
| times/epoch_after_hook         | 1.8e-06    |
| times/epoch_before_hook        | 0.000144   |
| times/epoch_rollout_model      | 505        |
| times/evaluation_metrics       | 0.000642   |
| times/evaluation_paths         | 36.7       |
| times/timestep_after_hook      | 0.00374    |
| times/timestep_before_hook     | 0.00844    |
| times/train                    | 61.3       |
| timestep                       | 1000       |
| timesteps_total                | 968000     |
| train-steps                    | 968000     |
| training/Q/q1_loss             | 89.07041   |
| training/sac_pi/alpha          | 0.16164404 |
| training/sac_pi/alpha_loss     | 0.1573647  |
| training/sac_pi/logp_pi        | 3.8735757  |
| training/sac_pi/pi_entropy     | 3.4465542  |
| training/sac_pi/pi_global_norm | 1.5128638  |
| training/sac_pi/policy_loss    | -227.40248 |
| training/sac_pi/std            | 0.48375353 |
| training/sac_pi/valid_num      | 5022.0     |
| training/sac_Q/q1              | 221.05212  |
| training/sac_Q/q2              | 222.29324  |
| training/sac_Q/q2_loss         | 88.8987    |
| training/sac_Q/q_global_norm   | 194.22838  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16503403  |
| epoch                          | 968         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5247.6396   |
| evaluation/return-max          | 5276.7793   |
| evaluation/return-min          | 5228.126    |
| evaluation/return-std          | 16.017653   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.17        |
| model/origin_ret               | 86.5        |
| model/penalty_ret              | 79.1        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46546       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5247.6396   |
| perf/NormalizedReturn          | 1.14        |
| Q-avg                          | 218.61496   |
| Q-std                          | 189.71211   |
| Q_loss                         | 102.50821   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 968         |
| times/epoch_after_hook         | 1.83e-06    |
| times/epoch_before_hook        | 0.000122    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000668    |
| times/evaluation_paths         | 35.3        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00839     |
| times/train                    | 61.9        |
| timestep                       | 1000        |
| timesteps_total                | 969000      |
| train-steps                    | 969000      |
| training/Q/q1_loss             | 94.838844   |
| training/sac_pi/alpha          | 0.16503629  |
| training/sac_pi/alpha_loss     | -0.24150611 |
| training/sac_pi/logp_pi        | 4.7811394   |
| training/sac_pi/pi_entropy     | 3.7072678   |
| training/sac_pi/pi_global_norm | 1.918402    |
| training/sac_pi/policy_loss    | -232.3633   |
| training/sac_pi/std            | 0.5601787   |
| training/sac_pi/valid_num      | 4925.0      |
| training/sac_Q/q1              | 210.00533   |
| training/sac_Q/q2              | 213.10225   |
| training/sac_Q/q2_loss         | 96.07449    |
| training/sac_Q/q_global_norm   | 235.45087   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16044867  |
| epoch                          | 969         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5120.794    |
| evaluation/return-max          | 5206.3213   |
| evaluation/return-min          | 5012.9287   |
| evaluation/return-std          | 52.82134    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.15        |
| model/origin_ret               | 86.6        |
| model/penalty_ret              | 79.6        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46531       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5120.794    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 228.11755   |
| Q-std                          | 123.61901   |
| Q_loss                         | 82.63696    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 969         |
| times/epoch_after_hook         | 1.65e-06    |
| times/epoch_before_hook        | 0.00036     |
| times/epoch_rollout_model      | 502         |
| times/evaluation_metrics       | 0.000689    |
| times/evaluation_paths         | 34.8        |
| times/timestep_after_hook      | 0.00366     |
| times/timestep_before_hook     | 0.0084      |
| times/train                    | 61.4        |
| timestep                       | 1000        |
| timesteps_total                | 970000      |
| train-steps                    | 970000      |
| training/Q/q1_loss             | 87.318924   |
| training/sac_pi/alpha          | 0.16046634  |
| training/sac_pi/alpha_loss     | -0.27525663 |
| training/sac_pi/logp_pi        | 4.2956533   |
| training/sac_pi/pi_entropy     | 3.4997337   |
| training/sac_pi/pi_global_norm | 1.8278289   |
| training/sac_pi/policy_loss    | -228.264    |
| training/sac_pi/std            | 0.5109      |
| training/sac_pi/valid_num      | 4951.0      |
| training/sac_Q/q1              | 215.50911   |
| training/sac_Q/q2              | 217.19194   |
| training/sac_Q/q2_loss         | 87.48338    |
| training/sac_Q/q_global_norm   | 182.07233   |
---------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16231112   |
| epoch                          | 970          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5102.4756    |
| evaluation/return-max          | 5275.2607    |
| evaluation/return-min          | 5004.854     |
| evaluation/return-std          | 80.607056    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.13         |
| model/origin_ret               | 85.6         |
| model/penalty_ret              | 78.9         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46440        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5102.4756    |
| perf/NormalizedReturn          | 1.11         |
| Q-avg                          | 226.33826    |
| Q-std                          | 112.191956   |
| Q_loss                         | 85.40306     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 970          |
| times/epoch_after_hook         | 1.68e-06     |
| times/epoch_before_hook        | 0.000136     |
| times/epoch_rollout_model      | 488          |
| times/evaluation_metrics       | 0.000552     |
| times/evaluation_paths         | 34.3         |
| times/timestep_after_hook      | 0.00361      |
| times/timestep_before_hook     | 0.00831      |
| times/train                    | 62.4         |
| timestep                       | 1000         |
| timesteps_total                | 971000       |
| train-steps                    | 971000       |
| training/Q/q1_loss             | 100.2917     |
| training/sac_pi/alpha          | 0.16230401   |
| training/sac_pi/alpha_loss     | -0.055486113 |
| training/sac_pi/logp_pi        | 4.116866     |
| training/sac_pi/pi_entropy     | 3.5141563    |
| training/sac_pi/pi_global_norm | 1.712403     |
| training/sac_pi/policy_loss    | -223.45673   |
| training/sac_pi/std            | 0.501344     |
| training/sac_pi/valid_num      | 5008.0       |
| training/sac_Q/q1              | 211.6134     |
| training/sac_Q/q2              | 211.40483    |
| training/sac_Q/q2_loss         | 100.28044    |
| training/sac_Q/q_global_norm   | 254.31812    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.1667971   |
| epoch                          | 971         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5004.2163   |
| evaluation/return-max          | 5149.645    |
| evaluation/return-min          | 4812.576    |
| evaluation/return-std          | 118.52718   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 85.7        |
| model/penalty_ret              | 78.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46422       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5004.2163   |
| perf/NormalizedReturn          | 1.09        |
| Q-avg                          | 204.74835   |
| Q-std                          | 197.27423   |
| Q_loss                         | 113.36935   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 971         |
| times/epoch_after_hook         | 1.77e-06    |
| times/epoch_before_hook        | 0.000127    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000603    |
| times/evaluation_paths         | 36.7        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00835     |
| times/train                    | 59.3        |
| timestep                       | 1000        |
| timesteps_total                | 972000      |
| train-steps                    | 972000      |
| training/Q/q1_loss             | 74.44215    |
| training/sac_pi/alpha          | 0.16680805  |
| training/sac_pi/alpha_loss     | -0.02171042 |
| training/sac_pi/logp_pi        | 3.432116    |
| training/sac_pi/pi_entropy     | 3.5172393   |
| training/sac_pi/pi_global_norm | 1.7990983   |
| training/sac_pi/policy_loss    | -232.05663  |
| training/sac_pi/std            | 0.47032183  |
| training/sac_pi/valid_num      | 5029.0      |
| training/sac_Q/q1              | 224.39941   |
| training/sac_Q/q2              | 223.59111   |
| training/sac_Q/q2_loss         | 75.875374   |
| training/sac_Q/q_global_norm   | 148.16615   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16640179  |
| epoch                          | 972         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5142.446    |
| evaluation/return-max          | 5168.707    |
| evaluation/return-min          | 5099.0615   |
| evaluation/return-std          | 19.79127    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.11        |
| model/origin_ret               | 85.6        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46586       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5142.446    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 204.89844   |
| Q-std                          | 174.8353    |
| Q_loss                         | 99.17168    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 972         |
| times/epoch_after_hook         | 1.88e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000661    |
| times/evaluation_paths         | 37.4        |
| times/timestep_after_hook      | 0.00368     |
| times/timestep_before_hook     | 0.00828     |
| times/train                    | 59.9        |
| timestep                       | 1000        |
| timesteps_total                | 973000      |
| train-steps                    | 973000      |
| training/Q/q1_loss             | 85.075645   |
| training/sac_pi/alpha          | 0.1664383   |
| training/sac_pi/alpha_loss     | -0.43404976 |
| training/sac_pi/logp_pi        | 4.759404    |
| training/sac_pi/pi_entropy     | 3.5742886   |
| training/sac_pi/pi_global_norm | 1.8522925   |
| training/sac_pi/policy_loss    | -230.35555  |
| training/sac_pi/std            | 0.51855546  |
| training/sac_pi/valid_num      | 4903.0      |
| training/sac_Q/q1              | 215.06316   |
| training/sac_Q/q2              | 214.10825   |
| training/sac_Q/q2_loss         | 86.57168    |
| training/sac_Q/q_global_norm   | 229.41072   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16241299 |
| epoch                          | 973        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5082.5986  |
| evaluation/return-max          | 5202.5195  |
| evaluation/return-min          | 4948.7886  |
| evaluation/return-std          | 89.961235  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.12       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46466      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5082.5986  |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 214.36954  |
| Q-std                          | 201.0135   |
| Q_loss                         | 110.37663  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 973        |
| times/epoch_after_hook         | 1.9e-06    |
| times/epoch_before_hook        | 0.000284   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000674   |
| times/evaluation_paths         | 34.4       |
| times/timestep_after_hook      | 0.0036     |
| times/timestep_before_hook     | 0.00837    |
| times/train                    | 59.9       |
| timestep                       | 1000       |
| timesteps_total                | 974000     |
| train-steps                    | 974000     |
| training/Q/q1_loss             | 106.66694  |
| training/sac_pi/alpha          | 0.16241509 |
| training/sac_pi/alpha_loss     | 0.18654765 |
| training/sac_pi/logp_pi        | 4.018647   |
| training/sac_pi/pi_entropy     | 3.3480537  |
| training/sac_pi/pi_global_norm | 2.1457834  |
| training/sac_pi/policy_loss    | -228.99046 |
| training/sac_pi/std            | 0.47653195 |
| training/sac_pi/valid_num      | 5010.0     |
| training/sac_Q/q1              | 217.79971  |
| training/sac_Q/q2              | 217.23782  |
| training/sac_Q/q2_loss         | 105.589645 |
| training/sac_Q/q_global_norm   | 197.65126  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16768233 |
| epoch                          | 974        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4920.876   |
| evaluation/return-max          | 5041.6562  |
| evaluation/return-min          | 4876.5957  |
| evaluation/return-std          | 48.448532  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.09       |
| model/origin_ret               | 85         |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46588      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4920.876   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 214.86462  |
| Q-std                          | 164.54451  |
| Q_loss                         | 97.691536  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 974        |
| times/epoch_after_hook         | 1.6e-06    |
| times/epoch_before_hook        | 0.000145   |
| times/epoch_rollout_model      | 484        |
| times/evaluation_metrics       | 0.000662   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 61.8       |
| timestep                       | 1000       |
| timesteps_total                | 975000     |
| train-steps                    | 975000     |
| training/Q/q1_loss             | 101.88656  |
| training/sac_pi/alpha          | 0.1676813  |
| training/sac_pi/alpha_loss     | 0.1378009  |
| training/sac_pi/logp_pi        | 4.423847   |
| training/sac_pi/pi_entropy     | 3.475467   |
| training/sac_pi/pi_global_norm | 1.6561099  |
| training/sac_pi/policy_loss    | -232.2061  |
| training/sac_pi/std            | 0.5106917  |
| training/sac_pi/valid_num      | 4968.0     |
| training/sac_Q/q1              | 217.96762  |
| training/sac_Q/q2              | 220.18697  |
| training/sac_Q/q2_loss         | 101.57289  |
| training/sac_Q/q_global_norm   | 196.10336  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1683393  |
| epoch                          | 975        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5045.7324  |
| evaluation/return-max          | 5138.15    |
| evaluation/return-min          | 4978.75    |
| evaluation/return-std          | 55.2915    |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86.1       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46547      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5045.7324  |
| perf/NormalizedReturn          | 1.1        |
| Q-avg                          | 227.01181  |
| Q-std                          | 188.72583  |
| Q_loss                         | 96.33159   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 975        |
| times/epoch_after_hook         | 3e-06      |
| times/epoch_before_hook        | 0.000126   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.000625   |
| times/evaluation_paths         | 35.2       |
| times/timestep_after_hook      | 0.00359    |
| times/timestep_before_hook     | 0.0085     |
| times/train                    | 59.2       |
| timestep                       | 1000       |
| timesteps_total                | 976000     |
| train-steps                    | 976000     |
| training/Q/q1_loss             | 113.908264 |
| training/sac_pi/alpha          | 0.168328   |
| training/sac_pi/alpha_loss     | -0.2688326 |
| training/sac_pi/logp_pi        | 4.196826   |
| training/sac_pi/pi_entropy     | 3.5839925  |
| training/sac_pi/pi_global_norm | 1.8262457  |
| training/sac_pi/policy_loss    | -230.28569 |
| training/sac_pi/std            | 0.5163346  |
| training/sac_pi/valid_num      | 4949.0     |
| training/sac_Q/q1              | 208.6726   |
| training/sac_Q/q2              | 209.43987  |
| training/sac_Q/q2_loss         | 111.90982  |
| training/sac_Q/q_global_norm   | 259.9655   |
--------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
| alpha                          | 0.16524605    |
| epoch                          | 976           |
| evaluation/episode-length-avg  | 1e+03         |
| evaluation/episode-length-max  | 1000          |
| evaluation/episode-length-min  | 1000          |
| evaluation/episode-length-std  | 0             |
| evaluation/return-average      | 4935.232      |
| evaluation/return-max          | 4984.5845     |
| evaluation/return-min          | 4877.56       |
| evaluation/return-std          | 33.526997     |
| model/max_penalty              | 7.24          |
| model/mean_rollout_length      | 20            |
| model/mean_rollout_reward      | 3.06          |
| model/origin_ret               | 84.8          |
| model/penalty_ret              | 79.3          |
| model/val_loss                 | 0.40512508    |
| model/valid_num                | 46496         |
| perf/AverageLength             | 1e+03         |
| perf/AverageReturn             | 4935.232      |
| perf/NormalizedReturn          | 1.07          |
| Q-avg                          | 215.1569      |
| Q-std                          | 186.92288     |
| Q_loss                         | 76.945404     |
| sampler/episodes               | 0             |
| sampler/last-path-return       | 0             |
| sampler/max-path-return        | -inf          |
| sampler/pool-size              | 1000000       |
| sampler/total-samples          | 0             |
| time-step                      | 976           |
| times/epoch_after_hook         | 1.68e-06      |
| times/epoch_before_hook        | 0.000126      |
| times/epoch_rollout_model      | 479           |
| times/evaluation_metrics       | 0.000599      |
| times/evaluation_paths         | 35.6          |
| times/timestep_after_hook      | 0.00372       |
| times/timestep_before_hook     | 0.00834       |
| times/train                    | 59.2          |
| timestep                       | 1000          |
| timesteps_total                | 977000        |
| train-steps                    | 977000        |
| training/Q/q1_loss             | 97.28873      |
| training/sac_pi/alpha          | 0.16525207    |
| training/sac_pi/alpha_loss     | -0.0028956118 |
| training/sac_pi/logp_pi        | 4.144815      |
| training/sac_pi/pi_entropy     | 3.3508048     |
| training/sac_pi/pi_global_norm | 1.4650869     |
| training/sac_pi/policy_loss    | -229.85118    |
| training/sac_pi/std            | 0.48208708    |
| training/sac_pi/valid_num      | 4949.0        |
| training/sac_Q/q1              | 215.11162     |
| training/sac_Q/q2              | 214.98624     |
| training/sac_Q/q2_loss         | 96.59937      |
| training/sac_Q/q_global_norm   | 243.91556     |
-----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16799061 |
| epoch                          | 977        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4955.0283  |
| evaluation/return-max          | 5025.0     |
| evaluation/return-min          | 4869.295   |
| evaluation/return-std          | 49.45083   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.13       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46506      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4955.0283  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 217.3612   |
| Q-std                          | 123.85096  |
| Q_loss                         | 91.96424   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 977        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000324   |
| times/epoch_rollout_model      | 477        |
| times/evaluation_metrics       | 0.000735   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00382    |
| times/timestep_before_hook     | 0.00861    |
| times/train                    | 63.7       |
| timestep                       | 1000       |
| timesteps_total                | 978000     |
| train-steps                    | 978000     |
| training/Q/q1_loss             | 99.8984    |
| training/sac_pi/alpha          | 0.16799852 |
| training/sac_pi/alpha_loss     | 0.13243273 |
| training/sac_pi/logp_pi        | 3.8821511  |
| training/sac_pi/pi_entropy     | 3.462476   |
| training/sac_pi/pi_global_norm | 1.6862175  |
| training/sac_pi/policy_loss    | -232.0141  |
| training/sac_pi/std            | 0.49313036 |
| training/sac_pi/valid_num      | 5016.0     |
| training/sac_Q/q1              | 222.92839  |
| training/sac_Q/q2              | 224.0969   |
| training/sac_Q/q2_loss         | 99.38988   |
| training/sac_Q/q_global_norm   | 236.5134   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16177294   |
| epoch                          | 978          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5128.882     |
| evaluation/return-max          | 5196.306     |
| evaluation/return-min          | 4939.707     |
| evaluation/return-std          | 71.566444    |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.11         |
| model/origin_ret               | 85.8         |
| model/penalty_ret              | 79.4         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46524        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5128.882     |
| perf/NormalizedReturn          | 1.12         |
| Q-avg                          | 229.71451    |
| Q-std                          | 106.20351    |
| Q_loss                         | 95.31552     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 978          |
| times/epoch_after_hook         | 1.68e-06     |
| times/epoch_before_hook        | 0.000127     |
| times/epoch_rollout_model      | 479          |
| times/evaluation_metrics       | 0.000824     |
| times/evaluation_paths         | 34.8         |
| times/timestep_after_hook      | 0.00365      |
| times/timestep_before_hook     | 0.00856      |
| times/train                    | 62.1         |
| timestep                       | 1000         |
| timesteps_total                | 979000       |
| train-steps                    | 979000       |
| training/Q/q1_loss             | 100.482086   |
| training/sac_pi/alpha          | 0.16177113   |
| training/sac_pi/alpha_loss     | -0.029912211 |
| training/sac_pi/logp_pi        | 4.7990355    |
| training/sac_pi/pi_entropy     | 3.3989513    |
| training/sac_pi/pi_global_norm | 1.8372945    |
| training/sac_pi/policy_loss    | -230.61589   |
| training/sac_pi/std            | 0.511195     |
| training/sac_pi/valid_num      | 4977.0       |
| training/sac_Q/q1              | 206.35971    |
| training/sac_Q/q2              | 209.50362    |
| training/sac_Q/q2_loss         | 102.20108    |
| training/sac_Q/q_global_norm   | 208.69717    |
----------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16290948 |
| epoch                          | 979        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4518.712   |
| evaluation/return-max          | 4790.0635  |
| evaluation/return-min          | 4425.3276  |
| evaluation/return-std          | 120.69616  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 85.6       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46379      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4518.712   |
| perf/NormalizedReturn          | 0.984      |
| Q-avg                          | 215.79263  |
| Q-std                          | 196.70146  |
| Q_loss                         | 98.49147   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 979        |
| times/epoch_after_hook         | 1.71e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 482        |
| times/evaluation_metrics       | 0.000686   |
| times/evaluation_paths         | 36.5       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00863    |
| times/train                    | 59.8       |
| timestep                       | 1000       |
| timesteps_total                | 980000     |
| train-steps                    | 980000     |
| training/Q/q1_loss             | 108.29     |
| training/sac_pi/alpha          | 0.1629097  |
| training/sac_pi/alpha_loss     | 0.36725578 |
| training/sac_pi/logp_pi        | 4.216447   |
| training/sac_pi/pi_entropy     | 3.438839   |
| training/sac_pi/pi_global_norm | 2.1672237  |
| training/sac_pi/policy_loss    | -232.31294 |
| training/sac_pi/std            | 0.48324007 |
| training/sac_pi/valid_num      | 5005.0     |
| training/sac_Q/q1              | 222.96762  |
| training/sac_Q/q2              | 225.76802  |
| training/sac_Q/q2_loss         | 109.10913  |
| training/sac_Q/q_global_norm   | 301.30884  |
--------------------------------------------------------------------------------
[WARN] 980 : sync: start
------------------------------------------------------------------------------------
| alpha                          | 0.16452397     |
| epoch                          | 980            |
| evaluation/episode-length-avg  | 1e+03          |
| evaluation/episode-length-max  | 1000           |
| evaluation/episode-length-min  | 1000           |
| evaluation/episode-length-std  | 0              |
| evaluation/return-average      | 5018.85        |
| evaluation/return-max          | 5084.421       |
| evaluation/return-min          | 4948.5615      |
| evaluation/return-std          | 39.860287      |
| model/max_penalty              | 7.24           |
| model/mean_rollout_length      | 20             |
| model/mean_rollout_reward      | 3.17           |
| model/origin_ret               | 86.1           |
| model/penalty_ret              | 79.2           |
| model/val_loss                 | 0.40512508     |
| model/valid_num                | 46483          |
| perf/AverageLength             | 1e+03          |
| perf/AverageReturn             | 5018.85        |
| perf/NormalizedReturn          | 1.09           |
| Q-avg                          | 218.8503       |
| Q-std                          | 176.05232      |
| Q_loss                         | 97.293335      |
| sampler/episodes               | 0              |
| sampler/last-path-return       | 0              |
| sampler/max-path-return        | -inf           |
| sampler/pool-size              | 1000000        |
| sampler/total-samples          | 0              |
| time-step                      | 980            |
| times/epoch_after_hook         | 1.67e-06       |
| times/epoch_before_hook        | 0.000133       |
| times/epoch_rollout_model      | 480            |
| times/evaluation_metrics       | 0.000623       |
| times/evaluation_paths         | 38.3           |
| times/timestep_after_hook      | 0.00383        |
| times/timestep_before_hook     | 0.00845        |
| times/train                    | 61.2           |
| timestep                       | 1000           |
| timesteps_total                | 981000         |
| train-steps                    | 981000         |
| training/Q/q1_loss             | 97.90148       |
| training/sac_pi/alpha          | 0.16452907     |
| training/sac_pi/alpha_loss     | -0.00036172252 |
| training/sac_pi/logp_pi        | 4.316025       |
| training/sac_pi/pi_entropy     | 3.4383178      |
| training/sac_pi/pi_global_norm | 1.6114936      |
| training/sac_pi/policy_loss    | -234.72298     |
| training/sac_pi/std            | 0.4982711      |
| training/sac_pi/valid_num      | 4977.0         |
| training/sac_Q/q1              | 219.88106      |
| training/sac_Q/q2              | 223.66995      |
| training/sac_Q/q2_loss         | 97.984024      |
| training/sac_Q/q_global_norm   | 238.53827      |
------------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.15772083  |
| epoch                          | 981         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5138.796    |
| evaluation/return-max          | 5217.3574   |
| evaluation/return-min          | 4839.795    |
| evaluation/return-std          | 116.35522   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 85.2        |
| model/penalty_ret              | 78.5        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46516       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5138.796    |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 214.13391   |
| Q-std                          | 195.95573   |
| Q_loss                         | 105.40446   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 981         |
| times/epoch_after_hook         | 1.65e-06    |
| times/epoch_before_hook        | 0.00028     |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000624    |
| times/evaluation_paths         | 34.5        |
| times/timestep_after_hook      | 0.00367     |
| times/timestep_before_hook     | 0.00851     |
| times/train                    | 63.4        |
| timestep                       | 1000        |
| timesteps_total                | 982000      |
| train-steps                    | 982000      |
| training/Q/q1_loss             | 102.57322   |
| training/sac_pi/alpha          | 0.15771453  |
| training/sac_pi/alpha_loss     | -0.13071212 |
| training/sac_pi/logp_pi        | 3.4710114   |
| training/sac_pi/pi_entropy     | 3.3055038   |
| training/sac_pi/pi_global_norm | 2.0398095   |
| training/sac_pi/policy_loss    | -229.50967  |
| training/sac_pi/std            | 0.4514213   |
| training/sac_pi/valid_num      | 5023.0      |
| training/sac_Q/q1              | 223.29985   |
| training/sac_Q/q2              | 223.27524   |
| training/sac_Q/q2_loss         | 103.14955   |
| training/sac_Q/q_global_norm   | 197.18266   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.15792978 |
| epoch                          | 982        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4959.1216  |
| evaluation/return-max          | 5170.45    |
| evaluation/return-min          | 4751.7314  |
| evaluation/return-std          | 137.71472  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.17       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46556      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4959.1216  |
| perf/NormalizedReturn          | 1.08       |
| Q-avg                          | 199.4915   |
| Q-std                          | 176.52892  |
| Q_loss                         | 100.40543  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 982        |
| times/epoch_after_hook         | 1.56e-06   |
| times/epoch_before_hook        | 0.000129   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000604   |
| times/evaluation_paths         | 36.4       |
| times/timestep_after_hook      | 0.00371    |
| times/timestep_before_hook     | 0.00866    |
| times/train                    | 64.5       |
| timestep                       | 1000       |
| timesteps_total                | 983000     |
| train-steps                    | 983000     |
| training/Q/q1_loss             | 98.14918   |
| training/sac_pi/alpha          | 0.15793988 |
| training/sac_pi/alpha_loss     | -0.3974633 |
| training/sac_pi/logp_pi        | 3.9543278  |
| training/sac_pi/pi_entropy     | 3.2960591  |
| training/sac_pi/pi_global_norm | 1.811722   |
| training/sac_pi/policy_loss    | -239.89568 |
| training/sac_pi/std            | 0.4903601  |
| training/sac_pi/valid_num      | 4987.0     |
| training/sac_Q/q1              | 225.62125  |
| training/sac_Q/q2              | 225.58614  |
| training/sac_Q/q2_loss         | 98.68506   |
| training/sac_Q/q_global_norm   | 289.10608  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.161191   |
| epoch                          | 983        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4819.023   |
| evaluation/return-max          | 4882.587   |
| evaluation/return-min          | 4772.33    |
| evaluation/return-std          | 29.370869  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.7       |
| model/penalty_ret              | 79.7       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46494      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4819.023   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 221.7181   |
| Q-std                          | 139.54248  |
| Q_loss                         | 76.45174   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 983        |
| times/epoch_after_hook         | 1.77e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.000582   |
| times/evaluation_paths         | 36.7       |
| times/timestep_after_hook      | 0.00369    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 59.9       |
| timestep                       | 1000       |
| timesteps_total                | 984000     |
| train-steps                    | 984000     |
| training/Q/q1_loss             | 107.53353  |
| training/sac_pi/alpha          | 0.1611789  |
| training/sac_pi/alpha_loss     | 0.10636345 |
| training/sac_pi/logp_pi        | 4.218381   |
| training/sac_pi/pi_entropy     | 3.544667   |
| training/sac_pi/pi_global_norm | 1.8799939  |
| training/sac_pi/policy_loss    | -232.80444 |
| training/sac_pi/std            | 0.51631963 |
| training/sac_pi/valid_num      | 4945.0     |
| training/sac_Q/q1              | 219.77812  |
| training/sac_Q/q2              | 219.85771  |
| training/sac_Q/q2_loss         | 108.253716 |
| training/sac_Q/q_global_norm   | 197.3519   |
--------------------------------------------------------------------------------
----------------------------------------------------------------------------------
| alpha                          | 0.16372178   |
| epoch                          | 984          |
| evaluation/episode-length-avg  | 1e+03        |
| evaluation/episode-length-max  | 1000         |
| evaluation/episode-length-min  | 1000         |
| evaluation/episode-length-std  | 0            |
| evaluation/return-average      | 5249.997     |
| evaluation/return-max          | 5352.469     |
| evaluation/return-min          | 5061.7134    |
| evaluation/return-std          | 98.4819      |
| model/max_penalty              | 7.24         |
| model/mean_rollout_length      | 20           |
| model/mean_rollout_reward      | 3.1          |
| model/origin_ret               | 85.3         |
| model/penalty_ret              | 79.2         |
| model/val_loss                 | 0.40512508   |
| model/valid_num                | 46583        |
| perf/AverageLength             | 1e+03        |
| perf/AverageReturn             | 5249.997     |
| perf/NormalizedReturn          | 1.14         |
| Q-avg                          | 226.06192    |
| Q-std                          | 176.35019    |
| Q_loss                         | 90.81248     |
| sampler/episodes               | 0            |
| sampler/last-path-return       | 0            |
| sampler/max-path-return        | -inf         |
| sampler/pool-size              | 1000000      |
| sampler/total-samples          | 0            |
| time-step                      | 984          |
| times/epoch_after_hook         | 1.79e-06     |
| times/epoch_before_hook        | 0.000131     |
| times/epoch_rollout_model      | 514          |
| times/evaluation_metrics       | 0.000507     |
| times/evaluation_paths         | 35.5         |
| times/timestep_after_hook      | 0.00367      |
| times/timestep_before_hook     | 0.0085       |
| times/train                    | 59.3         |
| timestep                       | 1000         |
| timesteps_total                | 985000       |
| train-steps                    | 985000       |
| training/Q/q1_loss             | 94.66758     |
| training/sac_pi/alpha          | 0.1637079    |
| training/sac_pi/alpha_loss     | -0.061600875 |
| training/sac_pi/logp_pi        | 4.524027     |
| training/sac_pi/pi_entropy     | 3.549424     |
| training/sac_pi/pi_global_norm | 1.8031164    |
| training/sac_pi/policy_loss    | -230.69498   |
| training/sac_pi/std            | 0.52158934   |
| training/sac_pi/valid_num      | 4957.0       |
| training/sac_Q/q1              | 218.98105    |
| training/sac_Q/q2              | 221.6208     |
| training/sac_Q/q2_loss         | 94.23376     |
| training/sac_Q/q_global_norm   | 185.88322    |
----------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16483003  |
| epoch                          | 985         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5316.1606   |
| evaluation/return-max          | 5345.4854   |
| evaluation/return-min          | 5271.218    |
| evaluation/return-std          | 18.824648   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.18        |
| model/origin_ret               | 86.9        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46403       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5316.1606   |
| perf/NormalizedReturn          | 1.16        |
| Q-avg                          | 223.79947   |
| Q-std                          | 155.65535   |
| Q_loss                         | 108.37447   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 985         |
| times/epoch_after_hook         | 1.56e-06    |
| times/epoch_before_hook        | 0.000271    |
| times/epoch_rollout_model      | 485         |
| times/evaluation_metrics       | 0.000617    |
| times/evaluation_paths         | 34.5        |
| times/timestep_after_hook      | 0.00376     |
| times/timestep_before_hook     | 0.00848     |
| times/train                    | 59.3        |
| timestep                       | 1000        |
| timesteps_total                | 986000      |
| train-steps                    | 986000      |
| training/Q/q1_loss             | 92.995705   |
| training/sac_pi/alpha          | 0.16482686  |
| training/sac_pi/alpha_loss     | 0.037813764 |
| training/sac_pi/logp_pi        | 4.7489424   |
| training/sac_pi/pi_entropy     | 3.3881805   |
| training/sac_pi/pi_global_norm | 2.1275785   |
| training/sac_pi/policy_loss    | -229.89034  |
| training/sac_pi/std            | 0.4964154   |
| training/sac_pi/valid_num      | 4940.0      |
| training/sac_Q/q1              | 207.43388   |
| training/sac_Q/q2              | 211.41121   |
| training/sac_Q/q2_loss         | 93.98961    |
| training/sac_Q/q_global_norm   | 229.62564   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16646601  |
| epoch                          | 986         |
| evaluation/episode-length-avg  | 747         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 447         |
| evaluation/episode-length-std  | 256         |
| evaluation/return-average      | 3464.5977   |
| evaluation/return-max          | 4908.6245   |
| evaluation/return-min          | 2003.3497   |
| evaluation/return-std          | 1257.927    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 86          |
| model/penalty_ret              | 79.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46384       |
| perf/AverageLength             | 747         |
| perf/AverageReturn             | 3464.5977   |
| perf/NormalizedReturn          | 0.754       |
| Q-avg                          | 223.37097   |
| Q-std                          | 109.55783   |
| Q_loss                         | 103.512436  |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 986         |
| times/epoch_after_hook         | 1.87e-06    |
| times/epoch_before_hook        | 0.000126    |
| times/epoch_rollout_model      | 495         |
| times/evaluation_metrics       | 0.000546    |
| times/evaluation_paths         | 26.5        |
| times/timestep_after_hook      | 0.00374     |
| times/timestep_before_hook     | 0.00836     |
| times/train                    | 61.3        |
| timestep                       | 1000        |
| timesteps_total                | 987000      |
| train-steps                    | 987000      |
| training/Q/q1_loss             | 106.223404  |
| training/sac_pi/alpha          | 0.16645938  |
| training/sac_pi/alpha_loss     | -0.12632914 |
| training/sac_pi/logp_pi        | 4.6355762   |
| training/sac_pi/pi_entropy     | 3.6655297   |
| training/sac_pi/pi_global_norm | 1.6290497   |
| training/sac_pi/policy_loss    | -222.63321  |
| training/sac_pi/std            | 0.52225626  |
| training/sac_pi/valid_num      | 4980.0      |
| training/sac_Q/q1              | 206.19795   |
| training/sac_Q/q2              | 209.57893   |
| training/sac_Q/q2_loss         | 107.08401   |
| training/sac_Q/q_global_norm   | 217.41351   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16625866 |
| epoch                          | 987        |
| evaluation/episode-length-avg  | 926        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 259        |
| evaluation/episode-length-std  | 222        |
| evaluation/return-average      | 4751.5117  |
| evaluation/return-max          | 5217.171   |
| evaluation/return-min          | 974.37146  |
| evaluation/return-std          | 1259.6792  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.18       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 79.9       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46327      |
| perf/AverageLength             | 926        |
| perf/AverageReturn             | 4751.5117  |
| perf/NormalizedReturn          | 1.03       |
| Q-avg                          | 217.38448  |
| Q-std                          | 158.56122  |
| Q_loss                         | 104.099396 |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 987        |
| times/epoch_after_hook         | 1.97e-06   |
| times/epoch_before_hook        | 0.000128   |
| times/epoch_rollout_model      | 483        |
| times/evaluation_metrics       | 0.000648   |
| times/evaluation_paths         | 32.7       |
| times/timestep_after_hook      | 0.00378    |
| times/timestep_before_hook     | 0.00835    |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 988000     |
| train-steps                    | 988000     |
| training/Q/q1_loss             | 103.6181   |
| training/sac_pi/alpha          | 0.16627535 |
| training/sac_pi/alpha_loss     | 0.10381629 |
| training/sac_pi/logp_pi        | 4.521371   |
| training/sac_pi/pi_entropy     | 3.502858   |
| training/sac_pi/pi_global_norm | 1.6971292  |
| training/sac_pi/policy_loss    | -225.29771 |
| training/sac_pi/std            | 0.5174317  |
| training/sac_pi/valid_num      | 4912.0     |
| training/sac_Q/q1              | 207.09297  |
| training/sac_Q/q2              | 207.64453  |
| training/sac_Q/q2_loss         | 101.88609  |
| training/sac_Q/q_global_norm   | 218.688    |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.1629339  |
| epoch                          | 988        |
| evaluation/episode-length-avg  | 714        |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 279        |
| evaluation/episode-length-std  | 350        |
| evaluation/return-average      | 3402.5435  |
| evaluation/return-max          | 5079.42    |
| evaluation/return-min          | 1060.4155  |
| evaluation/return-std          | 1897.9961  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 85.8       |
| model/penalty_ret              | 79.3       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46649      |
| perf/AverageLength             | 714        |
| perf/AverageReturn             | 3402.5435  |
| perf/NormalizedReturn          | 0.741      |
| Q-avg                          | 212.2717   |
| Q-std                          | 207.0566   |
| Q_loss                         | 111.3468   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 988        |
| times/epoch_after_hook         | 1.73e-06   |
| times/epoch_before_hook        | 0.000136   |
| times/epoch_rollout_model      | 513        |
| times/evaluation_metrics       | 0.00056    |
| times/evaluation_paths         | 25.6       |
| times/timestep_after_hook      | 0.00383    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 63.1       |
| timestep                       | 1000       |
| timesteps_total                | 989000     |
| train-steps                    | 989000     |
| training/Q/q1_loss             | 111.75347  |
| training/sac_pi/alpha          | 0.1628987  |
| training/sac_pi/alpha_loss     | 0.38518873 |
| training/sac_pi/logp_pi        | 4.401709   |
| training/sac_pi/pi_entropy     | 3.513881   |
| training/sac_pi/pi_global_norm | 2.0895786  |
| training/sac_pi/policy_loss    | -224.7618  |
| training/sac_pi/std            | 0.5032093  |
| training/sac_pi/valid_num      | 4983.0     |
| training/sac_Q/q1              | 213.90666  |
| training/sac_Q/q2              | 214.13599  |
| training/sac_Q/q2_loss         | 111.05765  |
| training/sac_Q/q_global_norm   | 216.92563  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16875646  |
| epoch                          | 989         |
| evaluation/episode-length-avg  | 812         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 285         |
| evaluation/episode-length-std  | 295         |
| evaluation/return-average      | 3910.8608   |
| evaluation/return-max          | 5137.366    |
| evaluation/return-min          | 1093.4788   |
| evaluation/return-std          | 1582.441    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.1         |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 79          |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46547       |
| perf/AverageLength             | 812         |
| perf/AverageReturn             | 3910.8608   |
| perf/NormalizedReturn          | 0.852       |
| Q-avg                          | 213.9133    |
| Q-std                          | 136.40631   |
| Q_loss                         | 75.59955    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 989         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000288    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000526    |
| times/evaluation_paths         | 28.6        |
| times/timestep_after_hook      | 0.00377     |
| times/timestep_before_hook     | 0.00852     |
| times/train                    | 61.9        |
| timestep                       | 1000        |
| timesteps_total                | 990000      |
| train-steps                    | 990000      |
| training/Q/q1_loss             | 83.071945   |
| training/sac_pi/alpha          | 0.1687644   |
| training/sac_pi/alpha_loss     | -0.29273573 |
| training/sac_pi/logp_pi        | 3.817883    |
| training/sac_pi/pi_entropy     | 3.4019032   |
| training/sac_pi/pi_global_norm | 1.6079997   |
| training/sac_pi/policy_loss    | -240.33606  |
| training/sac_pi/std            | 0.4883093   |
| training/sac_pi/valid_num      | 5031.0      |
| training/sac_Q/q1              | 226.50327   |
| training/sac_Q/q2              | 226.40474   |
| training/sac_Q/q2_loss         | 83.55864    |
| training/sac_Q/q_global_norm   | 147.42702   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16821234  |
| epoch                          | 990         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5185.143    |
| evaluation/return-max          | 5223.156    |
| evaluation/return-min          | 5161.099    |
| evaluation/return-std          | 22.82468    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 84.6        |
| model/penalty_ret              | 78.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46415       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5185.143    |
| perf/NormalizedReturn          | 1.13        |
| Q-avg                          | 216.98593   |
| Q-std                          | 196.69147   |
| Q_loss                         | 84.93307    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 990         |
| times/epoch_after_hook         | 1.76e-06    |
| times/epoch_before_hook        | 0.000135    |
| times/epoch_rollout_model      | 483         |
| times/evaluation_metrics       | 0.000538    |
| times/evaluation_paths         | 34.7        |
| times/timestep_after_hook      | 0.00378     |
| times/timestep_before_hook     | 0.00866     |
| times/train                    | 63.4        |
| timestep                       | 1000        |
| timesteps_total                | 991000      |
| train-steps                    | 991000      |
| training/Q/q1_loss             | 107.44764   |
| training/sac_pi/alpha          | 0.16821763  |
| training/sac_pi/alpha_loss     | -0.08851866 |
| training/sac_pi/logp_pi        | 4.009565    |
| training/sac_pi/pi_entropy     | 3.3901858   |
| training/sac_pi/pi_global_norm | 1.4610399   |
| training/sac_pi/policy_loss    | -231.18417  |
| training/sac_pi/std            | 0.475676    |
| training/sac_pi/valid_num      | 4968.0      |
| training/sac_Q/q1              | 215.66318   |
| training/sac_Q/q2              | 214.42387   |
| training/sac_Q/q2_loss         | 108.599335  |
| training/sac_Q/q_global_norm   | 231.36726   |
---------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16152424 |
| epoch                          | 991        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4932.471   |
| evaluation/return-max          | 5052.655   |
| evaluation/return-min          | 4807.388   |
| evaluation/return-std          | 73.01698   |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86.6       |
| model/penalty_ret              | 79.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46515      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4932.471   |
| perf/NormalizedReturn          | 1.07       |
| Q-avg                          | 215.99504  |
| Q-std                          | 204.1903   |
| Q_loss                         | 128.62442  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 991        |
| times/epoch_after_hook         | 3.18e-06   |
| times/epoch_before_hook        | 0.000233   |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.00059    |
| times/evaluation_paths         | 34.4       |
| times/timestep_after_hook      | 0.0037     |
| times/timestep_before_hook     | 0.00825    |
| times/train                    | 60.5       |
| timestep                       | 1000       |
| timesteps_total                | 992000     |
| train-steps                    | 992000     |
| training/Q/q1_loss             | 104.63457  |
| training/sac_pi/alpha          | 0.16150586 |
| training/sac_pi/alpha_loss     | 0.4680834  |
| training/sac_pi/logp_pi        | 4.512295   |
| training/sac_pi/pi_entropy     | 3.287906   |
| training/sac_pi/pi_global_norm | 1.9023256  |
| training/sac_pi/policy_loss    | -226.39862 |
| training/sac_pi/std            | 0.47016513 |
| training/sac_pi/valid_num      | 4917.0     |
| training/sac_Q/q1              | 206.93344  |
| training/sac_Q/q2              | 208.36047  |
| training/sac_Q/q2_loss         | 104.344826 |
| training/sac_Q/q_global_norm   | 209.24738  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16279414 |
| epoch                          | 992        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5109.708   |
| evaluation/return-max          | 5151.5615  |
| evaluation/return-min          | 5026.52    |
| evaluation/return-std          | 38.741936  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.11       |
| model/origin_ret               | 85.5       |
| model/penalty_ret              | 78.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46536      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5109.708   |
| perf/NormalizedReturn          | 1.11       |
| Q-avg                          | 212.87776  |
| Q-std                          | 198.75308  |
| Q_loss                         | 125.95387  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 992        |
| times/epoch_after_hook         | 1.67e-06   |
| times/epoch_before_hook        | 0.000127   |
| times/epoch_rollout_model      | 478        |
| times/evaluation_metrics       | 0.0005     |
| times/evaluation_paths         | 36.5       |
| times/timestep_after_hook      | 0.00373    |
| times/timestep_before_hook     | 0.00841    |
| times/train                    | 60.1       |
| timestep                       | 1000       |
| timesteps_total                | 993000     |
| train-steps                    | 993000     |
| training/Q/q1_loss             | 124.877335 |
| training/sac_pi/alpha          | 0.16279459 |
| training/sac_pi/alpha_loss     | 0.250929   |
| training/sac_pi/logp_pi        | 4.808629   |
| training/sac_pi/pi_entropy     | 3.544044   |
| training/sac_pi/pi_global_norm | 1.713153   |
| training/sac_pi/policy_loss    | -231.27501 |
| training/sac_pi/std            | 0.53109914 |
| training/sac_pi/valid_num      | 4948.0     |
| training/sac_Q/q1              | 208.52945  |
| training/sac_Q/q2              | 212.49185  |
| training/sac_Q/q2_loss         | 124.49353  |
| training/sac_Q/q_global_norm   | 229.67775  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16296719 |
| epoch                          | 993        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 4836.464   |
| evaluation/return-max          | 4951.3154  |
| evaluation/return-min          | 4767.4985  |
| evaluation/return-std          | 62.751343  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.15       |
| model/origin_ret               | 86.4       |
| model/penalty_ret              | 79.5       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46437      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 4836.464   |
| perf/NormalizedReturn          | 1.05       |
| Q-avg                          | 213.8448   |
| Q-std                          | 201.36867  |
| Q_loss                         | 86.03679   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 993        |
| times/epoch_after_hook         | 1.68e-06   |
| times/epoch_before_hook        | 0.000291   |
| times/epoch_rollout_model      | 486        |
| times/evaluation_metrics       | 0.000559   |
| times/evaluation_paths         | 36.2       |
| times/timestep_after_hook      | 0.00368    |
| times/timestep_before_hook     | 0.00857    |
| times/train                    | 59.6       |
| timestep                       | 1000       |
| timesteps_total                | 994000     |
| train-steps                    | 994000     |
| training/Q/q1_loss             | 82.741905  |
| training/sac_pi/alpha          | 0.16293351 |
| training/sac_pi/alpha_loss     | 0.26447898 |
| training/sac_pi/logp_pi        | 4.444705   |
| training/sac_pi/pi_entropy     | 3.6603515  |
| training/sac_pi/pi_global_norm | 1.8051037  |
| training/sac_pi/policy_loss    | -228.1144  |
| training/sac_pi/std            | 0.534227   |
| training/sac_pi/valid_num      | 4915.0     |
| training/sac_Q/q1              | 211.3272   |
| training/sac_Q/q2              | 211.31485  |
| training/sac_Q/q2_loss         | 83.32645   |
| training/sac_Q/q_global_norm   | 202.74654  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16307023 |
| epoch                          | 994        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5017.934   |
| evaluation/return-max          | 5067.5425  |
| evaluation/return-min          | 4964.172   |
| evaluation/return-std          | 29.140543  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.14       |
| model/origin_ret               | 86.7       |
| model/penalty_ret              | 79.4       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46555      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5017.934   |
| perf/NormalizedReturn          | 1.09       |
| Q-avg                          | 230.42105  |
| Q-std                          | 129.89955  |
| Q_loss                         | 84.34834   |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 994        |
| times/epoch_after_hook         | 1.58e-06   |
| times/epoch_before_hook        | 0.00012    |
| times/epoch_rollout_model      | 480        |
| times/evaluation_metrics       | 0.00051    |
| times/evaluation_paths         | 36.3       |
| times/timestep_after_hook      | 0.00367    |
| times/timestep_before_hook     | 0.00836    |
| times/train                    | 61.9       |
| timestep                       | 1000       |
| timesteps_total                | 995000     |
| train-steps                    | 995000     |
| training/Q/q1_loss             | 98.21266   |
| training/sac_pi/alpha          | 0.16310577 |
| training/sac_pi/alpha_loss     | 0.06407672 |
| training/sac_pi/logp_pi        | 3.9087265  |
| training/sac_pi/pi_entropy     | 3.5933356  |
| training/sac_pi/pi_global_norm | 1.5274643  |
| training/sac_pi/policy_loss    | -228.06137 |
| training/sac_pi/std            | 0.5033669  |
| training/sac_pi/valid_num      | 5005.0     |
| training/sac_Q/q1              | 219.7867   |
| training/sac_Q/q2              | 218.0262   |
| training/sac_Q/q2_loss         | 98.0231    |
| training/sac_Q/q_global_norm   | 201.00961  |
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
| alpha                          | 0.16326232 |
| epoch                          | 995        |
| evaluation/episode-length-avg  | 1e+03      |
| evaluation/episode-length-max  | 1000       |
| evaluation/episode-length-min  | 1000       |
| evaluation/episode-length-std  | 0          |
| evaluation/return-average      | 5150.016   |
| evaluation/return-max          | 5178.961   |
| evaluation/return-min          | 5117.3164  |
| evaluation/return-std          | 16.062138  |
| model/max_penalty              | 7.24       |
| model/mean_rollout_length      | 20         |
| model/mean_rollout_reward      | 3.1        |
| model/origin_ret               | 86         |
| model/penalty_ret              | 80.1       |
| model/val_loss                 | 0.40512508 |
| model/valid_num                | 46414      |
| perf/AverageLength             | 1e+03      |
| perf/AverageReturn             | 5150.016   |
| perf/NormalizedReturn          | 1.12       |
| Q-avg                          | 215.74673  |
| Q-std                          | 170.58055  |
| Q_loss                         | 100.84941  |
| sampler/episodes               | 0          |
| sampler/last-path-return       | 0          |
| sampler/max-path-return        | -inf       |
| sampler/pool-size              | 1000000    |
| sampler/total-samples          | 0          |
| time-step                      | 995        |
| times/epoch_after_hook         | 1.88e-06   |
| times/epoch_before_hook        | 0.000125   |
| times/epoch_rollout_model      | 481        |
| times/evaluation_metrics       | 0.000561   |
| times/evaluation_paths         | 35.4       |
| times/timestep_after_hook      | 0.00375    |
| times/timestep_before_hook     | 0.00858    |
| times/train                    | 62         |
| timestep                       | 1000       |
| timesteps_total                | 996000     |
| train-steps                    | 996000     |
| training/Q/q1_loss             | 87.728096  |
| training/sac_pi/alpha          | 0.16327    |
| training/sac_pi/alpha_loss     | 0.0352953  |
| training/sac_pi/logp_pi        | 4.899678   |
| training/sac_pi/pi_entropy     | 3.5902932  |
| training/sac_pi/pi_global_norm | 1.894326   |
| training/sac_pi/policy_loss    | -226.04431 |
| training/sac_pi/std            | 0.5416338  |
| training/sac_pi/valid_num      | 4883.0     |
| training/sac_Q/q1              | 202.93217  |
| training/sac_Q/q2              | 203.46712  |
| training/sac_Q/q2_loss         | 88.305305  |
| training/sac_Q/q_global_norm   | 329.69147  |
--------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16131453  |
| epoch                          | 996         |
| evaluation/episode-length-avg  | 656         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 134         |
| evaluation/episode-length-std  | 421         |
| evaluation/return-average      | 3164.659    |
| evaluation/return-max          | 5213.001    |
| evaluation/return-min          | 343.13263   |
| evaluation/return-std          | 2292.0605   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.3        |
| model/penalty_ret              | 79.4        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46645       |
| perf/AverageLength             | 656         |
| perf/AverageReturn             | 3164.659    |
| perf/NormalizedReturn          | 0.689       |
| Q-avg                          | 215.68015   |
| Q-std                          | 151.93613   |
| Q_loss                         | 110.31014   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 996         |
| times/epoch_after_hook         | 1.8e-06     |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 482         |
| times/evaluation_metrics       | 0.000519    |
| times/evaluation_paths         | 21.4        |
| times/timestep_after_hook      | 0.0036      |
| times/timestep_before_hook     | 0.00832     |
| times/train                    | 60.6        |
| timestep                       | 1000        |
| timesteps_total                | 997000      |
| train-steps                    | 997000      |
| training/Q/q1_loss             | 96.771255   |
| training/sac_pi/alpha          | 0.16131507  |
| training/sac_pi/alpha_loss     | 0.024962682 |
| training/sac_pi/logp_pi        | 4.341216    |
| training/sac_pi/pi_entropy     | 3.4553406   |
| training/sac_pi/pi_global_norm | 1.6974248   |
| training/sac_pi/policy_loss    | -223.53949  |
| training/sac_pi/std            | 0.5030976   |
| training/sac_pi/valid_num      | 4951.0      |
| training/sac_Q/q1              | 212.61458   |
| training/sac_Q/q2              | 212.38443   |
| training/sac_Q/q2_loss         | 95.89449    |
| training/sac_Q/q_global_norm   | 209.68637   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16387643  |
| epoch                          | 997         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 5164.8916   |
| evaluation/return-max          | 5291.387    |
| evaluation/return-min          | 5042.916    |
| evaluation/return-std          | 72.86297    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.13        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 79.2        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46422       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 5164.8916   |
| perf/NormalizedReturn          | 1.12        |
| Q-avg                          | 220.7863    |
| Q-std                          | 130.50433   |
| Q_loss                         | 91.077675   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 997         |
| times/epoch_after_hook         | 1.67e-06    |
| times/epoch_before_hook        | 0.00029     |
| times/epoch_rollout_model      | 478         |
| times/evaluation_metrics       | 0.000573    |
| times/evaluation_paths         | 35.1        |
| times/timestep_after_hook      | 0.00372     |
| times/timestep_before_hook     | 0.00869     |
| times/train                    | 60.7        |
| timestep                       | 1000        |
| timesteps_total                | 998000      |
| train-steps                    | 998000      |
| training/Q/q1_loss             | 105.332954  |
| training/sac_pi/alpha          | 0.16387872  |
| training/sac_pi/alpha_loss     | 0.011108584 |
| training/sac_pi/logp_pi        | 4.05249     |
| training/sac_pi/pi_entropy     | 3.6837583   |
| training/sac_pi/pi_global_norm | 1.5307542   |
| training/sac_pi/policy_loss    | -230.01656  |
| training/sac_pi/std            | 0.51058453  |
| training/sac_pi/valid_num      | 5015.0      |
| training/sac_Q/q1              | 217.81812   |
| training/sac_Q/q2              | 220.68318   |
| training/sac_Q/q2_loss         | 105.42369   |
| training/sac_Q/q_global_norm   | 206.59726   |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16217183  |
| epoch                          | 998         |
| evaluation/episode-length-avg  | 946         |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 458         |
| evaluation/episode-length-std  | 163         |
| evaluation/return-average      | 4726.2803   |
| evaluation/return-max          | 5116.782    |
| evaluation/return-min          | 1926.6492   |
| evaluation/return-std          | 935.5435    |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.16        |
| model/origin_ret               | 86.2        |
| model/penalty_ret              | 79.3        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46589       |
| perf/AverageLength             | 946         |
| perf/AverageReturn             | 4726.2803   |
| perf/NormalizedReturn          | 1.03        |
| Q-avg                          | 218.9187    |
| Q-std                          | 125.07141   |
| Q_loss                         | 92.514046   |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 998         |
| times/epoch_after_hook         | 1.64e-06    |
| times/epoch_before_hook        | 0.000121    |
| times/epoch_rollout_model      | 479         |
| times/evaluation_metrics       | 0.000537    |
| times/evaluation_paths         | 35.1        |
| times/timestep_after_hook      | 0.00364     |
| times/timestep_before_hook     | 0.00837     |
| times/train                    | 59.6        |
| timestep                       | 1000        |
| timesteps_total                | 999000      |
| train-steps                    | 999000      |
| training/Q/q1_loss             | 103.01227   |
| training/sac_pi/alpha          | 0.16220382  |
| training/sac_pi/alpha_loss     | -0.14665493 |
| training/sac_pi/logp_pi        | 3.856666    |
| training/sac_pi/pi_entropy     | 3.5063674   |
| training/sac_pi/pi_global_norm | 1.8363414   |
| training/sac_pi/policy_loss    | -226.84235  |
| training/sac_pi/std            | 0.49092048  |
| training/sac_pi/valid_num      | 5006.0      |
| training/sac_Q/q1              | 218.5306    |
| training/sac_Q/q2              | 218.52437   |
| training/sac_Q/q2_loss         | 103.79638   |
| training/sac_Q/q_global_norm   | 216.8856    |
---------------------------------------------------------------------------------
---------------------------------------------------------------------------------
| alpha                          | 0.16434518  |
| epoch                          | 999         |
| evaluation/episode-length-avg  | 1e+03       |
| evaluation/episode-length-max  | 1000        |
| evaluation/episode-length-min  | 1000        |
| evaluation/episode-length-std  | 0           |
| evaluation/return-average      | 4893.033    |
| evaluation/return-max          | 5000.7153   |
| evaluation/return-min          | 4837.039    |
| evaluation/return-std          | 43.747818   |
| model/max_penalty              | 7.24        |
| model/mean_rollout_length      | 20          |
| model/mean_rollout_reward      | 3.08        |
| model/origin_ret               | 84.9        |
| model/penalty_ret              | 78.8        |
| model/val_loss                 | 0.40512508  |
| model/valid_num                | 46407       |
| perf/AverageLength             | 1e+03       |
| perf/AverageReturn             | 4893.033    |
| perf/NormalizedReturn          | 1.07        |
| Q-avg                          | 221.18033   |
| Q-std                          | 126.422356  |
| Q_loss                         | 98.01382    |
| sampler/episodes               | 0           |
| sampler/last-path-return       | 0           |
| sampler/max-path-return        | -inf        |
| sampler/pool-size              | 1000000     |
| sampler/total-samples          | 0           |
| time-step                      | 999         |
| times/epoch_after_hook         | 1.9e-06     |
| times/epoch_before_hook        | 0.000131    |
| times/epoch_rollout_model      | 486         |
| times/evaluation_metrics       | 0.000594    |
| times/evaluation_paths         | 34.6        |
| times/timestep_after_hook      | 0.00371     |
| times/timestep_before_hook     | 0.00852     |
| times/train                    | 62.6        |
| timestep                       | 1000        |
| timesteps_total                | 1000000     |
| train-steps                    | 1000000     |
| training/Q/q1_loss             | 96.14569    |
| training/sac_pi/alpha          | 0.16435757  |
| training/sac_pi/alpha_loss     | -0.06890567 |
| training/sac_pi/logp_pi        | 4.462833    |
| training/sac_pi/pi_entropy     | 3.69809     |
| training/sac_pi/pi_global_norm | 1.6688166   |
| training/sac_pi/policy_loss    | -224.35303  |
| training/sac_pi/std            | 0.52237844  |
| training/sac_pi/valid_num      | 4944.0      |
| training/sac_Q/q1              | 207.15852   |
| training/sac_Q/q2              | 209.29866   |
| training/sac_Q/q2_loss         | 97.08293    |
| training/sac_Q/q_global_norm   | 220.97682   |
---------------------------------------------------------------------------------
